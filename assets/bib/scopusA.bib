Scopus
EXPORT DATE: 19 January 2025

@ARTICLE{Al-Ansari202567,
	author = {Al-Ansari, Noor and Al-Thani, Dena and Bahameish, Mariam},
	title = {The Influence of Social Networking Usage Experience and Activity on Preferences of Explainable Artificial Intelligence (XAI) Representation Methods in a Hate Speech Detection System},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15437 LNCS},
	pages = {67 – 77},
	doi = {10.1007/978-981-96-0567-5_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211955639&doi=10.1007%2f978-981-96-0567-5_6&partnerID=40&md5=df7518cba4ea4800a35d4d36426b55b7},
	affiliations = {College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar},
	abstract = {Hate speech is widespread across social media platforms, where users can influence others positively or negatively through simple actions like typing. These platforms use AI to personalize content, and explainable AI (XAI) is integrated to clarify AI decision-making for users. While progress has been made in aligning XAI with user expectations through human-computer interaction (HCI) methods, the study of hate speech detection within XAI remains limited. This study investigated how social media experience and activity influence user preferences for XAI representation methods. Focusing on the Arab world, it introduces a high-fidelity prototype Arabic hate speech detection system and evaluates preferred XAI methods. Data were collected through subjective and objective measures, including Social Media Activity and Social Networking Usage Questionnaires on user preferences of XAI representation methods. The results show that active social media use correlates with social networking experience (SNUQpositive: r = .40, SNUQnegative = .23) and time spent on platforms (r = .22); however, mediation analysis found that hours spent did not influence XAI preference. Future research could explore additional factors affecting XAI preferences. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Explainable artificial intelligence; hate speech; XAI preference},
	keywords = {Decision making; Social networking (online); Detection system; Explainable artificial intelligence; Hate speech; Representation method; Social media; Social-networking; Speech detection; Usage experience; User's preferences; XAI preference; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 25th International Conference on Web Information Systems Engineering, WISE 2024; Conference date: 2 December 2024 through 5 December 2024; Conference code: 323489}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Peng and Dong, Lijia and Zhao, Xinlei and Lei, Weimin and Zhang, Wei},
	title = {An end-to-end framework for real-time violent behavior detection based on 2D CNNs},
	year = {2024},
	journal = {Journal of Real-Time Image Processing},
	volume = {21},
	number = {2},
	doi = {10.1007/s11554-024-01443-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188539427&doi=10.1007%2fs11554-024-01443-7&partnerID=40&md5=ca9fbe778a84a1bc1e3fff45a34e3cbb},
	affiliations = {School of Computer Science and Engineering, Northeastern University, Shenyang, Liaoning, 110169, China; Shenyang Er Yi San Electronic Technology Co., Ltd, Shenyang, Liaoning, 110023, China},
	abstract = {Violent behavior detection (VioBD), as a special action recognition task, aims to detect violent behaviors in videos, such as mutual fighting and assault. Some progress has been made in the research of violence detection, but the existing methods have poor real-time performance and the algorithm performance is limited by the interference of complex backgrounds and the occlusion of dense crowds. To solve the above problems, we propose an end-to-end real-time violence detection framework based on 2D CNNs. First, we propose a lightweight skeletal image (SI) as the input modality, which can obtain the human body posture information and richer contextual information, and at the same time remove the background interference. As tested, at the same accuracy, the resolution of SI modality is only one-third of that of RGB modality, which greatly improves the real-time performance of model training and inference, and at the same resolution, SI modality has higher inaccuracy. Second, we also design a parallel prediction module (PPM), which can simultaneously obtain the single image detection results and the inter-frame motion information of the video, which can improve the real-time performance of the algorithm compared with the traditional “detect the image first, understand the video later" mode. In addition, we propose an auxiliary parameter generation module (APGM) with both efficiency and accuracy, APGM is a 2D CNNs-based video understanding module for weighting the spatial information of the video features, processing speed can reach 30–40 frames per second, and compared with models such as CNN-LSTM (Iqrar et al., Aamir: Cnn-lstm based smart real-time video surveillance system. In: 2022 14th International Conference on Mathematics, Actuarial, Science, Computer Science and Statistics (MACS), pages 1–5. IEEE, 2022) and Ludl et al. (Cristóbal: Simple yet efficient real-time pose-based action recognition. In: 2019 IEEE Intelligent Transportation Systems Conference (ITSC), pages 581–588. IEEE, 1999), the propagation effect speed can be increased by an average of 3∼20 frames per second per group of clips, which further improves the video motion detection efficiency and accuracy, greatly improving real-time performance. We conducted experiments on some challenging benchmarks, and RVBDN can maintain excellent speed and accuracy in long-term interactions, and are able to meet real-time requirements in methods for violence detection and spatio-temporal action detection. Finally, we update our proposed new dataset on violence detection images (violence image dataset). Dataset is available at https://github.com/ChinaZhangPeng/Violence-Image-Dataset © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	author_keywords = {Modified YOLO-Pose; Object detection; Real-time action recognition; Violent behavior detection},
	keywords = {Behavioral research; Face recognition; Gesture recognition; Image enhancement; Intelligent systems; Long short-term memory; Object recognition; Security systems; Action recognition; Behavior detection; Modified YOLO-pose; Objects detection; Real time performance; Real- time; Real-time action recognition; Violence detections; Violent behavior; Violent behavior detection; Object detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Plaza-Del-Arco2024159,
	author = {Plaza-Del-Arco, Flor Miriam},
	title = {Detecting offensive language by integrating multiple linguistic phenomena; [Detección del lenguaje ofensivo mediante la integración de diferentes fenómenos lingüísticos]},
	year = {2024},
	journal = {Procesamiento del Lenguaje Natural},
	volume = {72},
	pages = {159 – 164},
	doi = {10.26342/2024-72-13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203012314&doi=10.26342%2f2024-72-13&partnerID=40&md5=4523d7d1255672a9c9265fbbcfaec79d},
	affiliations = {Bocconi University, Milan, Italy},
	abstract = {This is a summary of the Ph.D. thesis conducted by Flor Miriam Plaza del Arco at the University of Jaén under the supervision of Ph.D. M. Teresa Martín Valdivia and Ph.D. L. Alfonso Ureña López. The thesis defense took place in Jaén on January 30, 2023, with the doctoral committee comprising Ph.D. Mariona Taulé Delor from the University of Barcelona, Ph.D. José Camacho Collados from the University of Cardiff, and Ph.D. Eugenio Martínez Cámara from the University of Granada. Notably, the thesis was awarded the distinction of Summa Cum Laude and received international recognition. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {hate speech; linguistic phenomena; multitask learning; Natural language processing; offensive language detection; Spanish corpora},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Arunachalam2024,
	author = {Arunachalam, V. and Maheswari, N.},
	title = {ENHANCED DETECTION OF HATE SPEECH IN DRAVIDIAN LANGUAGES IN SOCIAL MEDIA USING ENSEMBLE TRANSFORMERS},
	year = {2024},
	journal = {Interdisciplinary Journal of Information, Knowledge, and Management},
	volume = {19},
	doi = {10.28945/5403},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213982805&doi=10.28945%2f5403&partnerID=40&md5=1027e3630d3a7d98ca825267d4f3790e},
	affiliations = {School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India},
	abstract = {Aim/Purpose This study aims to propose an efficient implementation of identifying and detecting offensive and hate comments on social media platforms for Dravidian languages. Background There has been a notable increase in hate comments on social media platforms in recent years. Hate language and hate speech are expressions of conflicts that arise between different groups, both within and across civilizations. This toxic behavior has a detrimental impact on individuals, resulting in disagreements, arguments, political conflicts, and even mental health issues such as cyberbullying, depression, and anxiety. In recent years, research on offensive detection has expanded beyond English and Hindi languages to include other languages such as Urdu, Spanish, Arabic, and more. An ongoing trend in modern research involves gathering data from prominent social media platforms such as YouTube, Instagram, and Twitter to train models in proposed studies. Methodology The objective of this work is to identify and detect offensive or hateful comments on social media platforms dedicated explicitly to the Dravidian languages - Tamil, Kannada, and Malayalam. The dataset, HASOC-Offensive Language Identification track in Dravidian Code-Mix FIRE 2021, undergoes several proposed preprocessing procedures on the YouTube comments. Tokens were created to represent the attributes. The pre-trained models utilizing transformers were trained using tokenized data. The efficacy of different binary classifiers has been assessed and analyzed using the embedded vectors derived from the models. The mBert with the classifier model CATBOOST with GSCV achieved F1 scores for Tamil, Malayalam, and Kannada are 0.94, 0.98, and 0.82, respectively. Precision and recall values for Tamil, Malayalam, and Kannada are 0.94, 0.98, and 0.82, and 0.94, 0.98, and 0.83, respectively. Contribution This research produced an approach to improve the results and F1-score by performing an improved preprocessing method using stemming and stopword removal. The native and English-coded comment data used in this work were not discussed much in the previous works. Findings The findings of this study indicated that the preprocessing work combined both the native language data and the English-coded language. It describes the improved models and performance of the results in order to detect hate speech. Recommendations This study is expected to be valuable for social media platforms and other re-for Practitioners view sites to separate offensive comments from good and bad ones. This is also valuable for content creators and users in improving their ideas and content and also helps in preventing cyber harassment and bullying. Recommendations This study discussed the use of stemming and stopword removal and how it imfor Researchers proved the detection of hate comments for both native and codemix comments in social media. Impact on Society This work helps the users and community explore the positive side of the internet and allows content creators to share their ideas without undermining the benefits of online interactions. Future Research Future research will explore the uniqueness of the linguistics and slang of these three languages. Apart from these languages, future research will be conducted on North-Indian Indian languages like Bengali, Marathi, and Gujarati. © 2024 Informing Science Institute. All rights reserved.},
	author_keywords = {BERT; Code-mix; Dravidian languages; F1-Score; Hate comment; mBERT; Muril; NLP},
	keywords = {Economic analysis; Problem oriented languages; Speech enhancement; Speech recognition; BERT; Code-mix; Dravidian language; F1 scores; Hate comment; Malayalams; MBERT; Muril; Social media; Social media platforms; Economic and social effects},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Esen2024,
	author = {Esen, Fatih Sinan and Emrah Amrahov, Sahin},
	title = {TurkHSD: A Hate Speech Detection Model for Turkish Text Content},
	year = {2024},
	journal = {2024 Innovations in Intelligent Systems and Applications Conference, ASYU 2024},
	doi = {10.1109/ASYU62119.2024.10757058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213372359&doi=10.1109%2fASYU62119.2024.10757058&partnerID=40&md5=083aa960c4472f06d30b1af0d83d23d0},
	affiliations = {Department of Computer Engineering, Ankara University, Ankara, Turkey},
	abstract = {At a time when digital communication is rapidly developing, the spread of hate speech on social media platforms and websites poses a significant problem for social cohesion. In this study, we address the problem of detecting and reducing hate speech in Turkish text content. The study aims to propose a new model to solve the problem by using machine learning methods. We collected and labeled a substantial dataset of 12, 989 Turkish text entries from social media and various websites. This data was utilized to train and evaluate multiple machine learning models, including Naive Bayes, Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and XGBoost. The performances of the models were calculated with known metrics like accuracy, precision, recall, F1 score, and ROC-AUC score. Our findings indicate that Bernoulli Naive Bayes model outperformed other models in terms of accuracy and ROC-AUC score, making it the most effective model for detecting hate speech in Turkish text content. This paper details the methodology, dataset preparation, model training, evaluation, and the implications of deploying such models in real-world applications. Our contributions provide a significant step towards creating safer online environments for Turkish-speaking users by effectively identifying and curbing hate speech. © 2024 IEEE.},
	author_keywords = {discriminating language; hate speech; machine learning; offensive language},
	keywords = {Decision trees; Nearest neighbor search; Random forests; Speech recognition; Detection models; Digital communications; Discriminating language; Hate speech; Machine-learning; Offensive languages; Social media platforms; Speech detection; Text content; Turkish texts; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 Innovations in Intelligent Systems and Applications Conference, ASYU 2024; Conference date: 16 October 2024 through 18 October 2024; Conference code: 204562}
}

@ARTICLE{Dharani2025864,
	author = {Dharani, P. and Bagade, Nidhi and Nittala, Sripriya and Konkala, Sowmya and Sasidhar, B.},
	title = {Social Media Hate Speech Detection Using Machine Learning Algorithms: Comparative Study},
	year = {2025},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1273 LNEE},
	pages = {864 – 870},
	doi = {10.1007/978-981-97-8031-0_92},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206843391&doi=10.1007%2f978-981-97-8031-0_92&partnerID=40&md5=6a137ee6aefe70396be494286ced20a3},
	affiliations = {Department of CSE (AI & ML), G. Narayanamma Institute of Technology and Science (For Women), Hyderabad, India},
	abstract = {Cyberbullying on social media using hate speech in text is applying depreciatory dialect in message dispatches on online forums to abuse, defile, as well as ill-treat recipients. A report by the New Indian Express stated that 93% of Indian children were subordinated to cyberbullying out of which 45% were bullied by strangers and 48% were bullied by people known to them. The existing system uses feature extraction using count vectorizer with Support Vector Machine classifier to give an accuracy of 94.78%. The proposed system uses feature extraction using tokenization and padding with Artificial Neural Networks Classifier to achieve an accuracy of 95.85%. The system examines the text content of social media dispatches using Natural Language Processing through Artificial Neural Networks. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Artificial neural networks; Count vectorizer; Cyberbullying; Feature extraction; Natural language processing; Padding; Tokenization},
	keywords = {Contrastive Learning; Natural language processing systems; Phishing; Speech recognition; Support vector machines; Count vectorizer; Cyber bullying; Features extraction; Language processing; Natural language processing; Natural languages; Neural-networks; Padding; Tokenization; Vectorizer; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Data Science, Machine Learning and Applications, ICDSMLA 2023; Conference date: 15 December 2023 through 16 December 2023; Conference code: 321139}
}

@ARTICLE{Ramos2024,
	author = {Ramos, Gil and Batista, Fernando and Ribeiro, Ricardo and Fialho, Pedro and Moro, Sérgio and Fonseca, António and Guerra, Rita and Carvalho, Paula and Marques, Catarina and Silva, Cláudia},
	title = {A comprehensive review on automatic hate speech detection in the age of the transformer},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01361-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206238543&doi=10.1007%2fs13278-024-01361-3&partnerID=40&md5=7168599611608c30f8776aea95be3f4e},
	affiliations = {Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR, Lisbon, Portugal; Instituto Universitário de Lisboa (ISCTE-IUL), Lisbon, Portugal; INESC-ID, Lisbon, Portugal; University of Jordan, Amman, Jordan; ISCTE-Instituto Universitário de Lisboa and Center for Psychological Research and Social Intervention (CIS-ISCTE), Lisbon, Portugal; Universidade de Aveiro, Aveiro, Portugal; ISCTE-Instituto Universitário de Lisboa and Business Research Unit (BRU-ISCTE), Lisbon, Portugal; ITI-LARSyS and IST, Lisbon, Portugal},
	abstract = {The rapid proliferation of hate speech on social media poses significant challenges to maintaining a safe and inclusive digital environment. This paper presents a comprehensive review of automatic hate speech detection methods, with a particular focus on the evolution of approaches from traditional machine learning and deep learning models to the more advanced Transformer-based architectures. We systematically analyze over 100 studies, comparing the effectiveness, computational requirements, and applicability of various techniques, including Support Vector Machines, Long Short-Term Memory networks, Convolutional Neural Networks, and Transformer models like BERT and its multilingual variants. The review also explores the datasets, languages, and sources used for hate speech detection, noting the predominance of English-focused research while highlighting emerging efforts in low-resource languages and cross-lingual detection using multilingual Transformers. Additionally, we discuss the role of generative and multi-task learning models as promising avenues for future development. While Transformer-based models consistently achieve state-of-the-art performance, this review underscores the trade-offs between performance and computational cost, emphasizing the need for context-specific solutions. Key challenges such as algorithmic bias, data scarcity, and the need for more standardized benchmarks are also identified. This review provides crucial insights for advancing the field of hate speech detection and shaping future research directions. © The Author(s) 2024.},
	author_keywords = {Deep learning; Hate speech detection; Literature review; Machine learning; Transfer learning; Transformers},
	keywords = {Contrastive Learning; Convolutional neural networks; Deep reinforcement learning; Distribution transformers; Federated learning; Long short-term memory; Multi-task learning; Speech recognition; Support vector machines; Transfer learning; Deep learning; Digital environment; Hate speech detection; Learning models; Literature reviews; Machine-learning; Social media; Speech detection; Transfer learning; Transformer; Adversarial machine learning},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Pokkuluri2024386,
	author = {Pokkuluri, Kiran Sree and Smt. SSSN Usha Devi, N. and Khang, Alex},
	title = {Quantum-powered hate speech detection: Enhancing recurrent neural networks (RNNS) for safer online spaces},
	year = {2024},
	journal = {The Quantum Evolution: Application of AI and Robotics in the Future of Quantum Technology},
	pages = {386 – 400},
	doi = {10.1201/9781032642079-19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203115660&doi=10.1201%2f9781032642079-19&partnerID=40&md5=f0f12e28fe3f55c73f43c7b55dcb3cb3},
	affiliations = {Department of Computer Science and Engineering, Shri Vishnu Engineering College for Women, Bhimavaramm, Andhra Pradesh, India; Department of Computer Science and Engineering, University College of Engineering, UCEK, JNTUK, India; Department of AI and Data Science, Global Research Institute of Technology and Engineering, North Carolina, United States},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Saifullah2024,
	author = {Saifullah, Shoffan and Dreżewski, Rafał and Dwiyanto, Felix Andika and Aribowo, Agus Sasmito and Fauziah, Yuli and Cahyana, Nur Heri},
	title = {Automated Text Annotation Using a Semi-Supervised Approach with Meta Vectorizer and Machine Learning Algorithms for Hate Speech Detection},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {3},
	doi = {10.3390/app14031078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194577062&doi=10.3390%2fapp14031078&partnerID=40&md5=91b4da4a40e2cc172c22b44ba180a783},
	affiliations = {Faculty of Computer Science, AGH University of Krakow, Krakow, 30-059, Poland; Department of Informatics, Universitas Pembangunan Nasional Veteran Yogyakarta, Yogyakarta, 55283, Indonesia; Artificial Intelligence Research Group (AIRG), Informatics Department, Faculty of Industrial Technology, Universitas Ahmad Dahlan, Yogyakarta, 55166, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, 65145, Indonesia},
	abstract = {Text annotation is an essential element of the natural language processing approaches. The manual annotation process performed by humans has various drawbacks, such as subjectivity, slowness, fatigue, and possibly carelessness. In addition, annotators may annotate ambiguous data. Therefore, we have developed the concept of automated annotation to get the best annotations using several machine-learning approaches. The proposed approach is based on an ensemble algorithm of meta-learners and meta-vectorizer techniques. The approach employs a semi-supervised learning technique for automated annotation to detect hate speech. This involves leveraging various machine learning algorithms, including Support Vector Machine (SVM), Decision Tree (DT), K-Nearest Neighbors (KNN), and Naive Bayes (NB), in conjunction with Word2Vec and TF-IDF text extraction methods. The annotation process is performed using 13,169 Indonesian YouTube comments data. The proposed model used a Stemming approach using data from Sastrawi and new data of 2245 words. Semi-supervised learning uses 5%, 10%, and 20% of labeled data compared to performing labeling based on 80% of the datasets. In semi-supervised learning, the model learns from the labeled data, which provides explicit information, and the unlabeled data, which offers implicit insights. This hybrid approach enables the model to generalize and make informed predictions even when limited labeled data is available (based on self-learning). Ultimately, this enhances its ability to handle real-world scenarios with scarce annotated information. In addition, the proposed method uses a variety of thresholds for matching words labeled with hate speech ranging from 0.6, 0.7, 0.8, to 0.9. The experiments indicated that the DT-TF-IDF model has the best accuracy value of 97.1% with a scenario of 5%:80%:0.9. However, several other methods have accuracy above 90%, such as SVM (TF-IDF and Word2Vec) and KNN (Word2Vec), based on both text extraction methods in several test scenarios. © 2024 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {hate speech detection; machine learning; self-learning; semi-supervised learning; sentiment analysis; text mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mehmood20243077,
	author = {Mehmood, Faiza and Ghafoor, Hina and Asim, Muhammad Nabeel and Ghani, Muhammad Usman and Mahmood, Waqar and Dengel, Andreas},
	title = {Passion-Net: a robust precise and explainable predictor for hate speech detection in Roman Urdu text},
	year = {2024},
	journal = {Neural Computing and Applications},
	volume = {36},
	number = {6},
	pages = {3077 – 3100},
	doi = {10.1007/s00521-023-09169-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177752955&doi=10.1007%2fs00521-023-09169-6&partnerID=40&md5=1fd0fdbd5f133196a891d73ac6309da0},
	affiliations = {Al-Khawarizmi Institute of Computer Science (KICS), University of Engineering and Technology, Lahore, Pakistan; Department of Computer Science, University of Engineering and Technology (Faisalabad Campus), Lahore, Pakistan; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, 67663, Germany; Department of Computer Science, University of Engineering and Technology, Lahore, Pakistan; Department of Computer Science, Rheinland Pfälzische Technische Universität, Kaiserslautern, 67663, Germany},
	abstract = {With an aim to eliminate or reduce the spread of hate content across social media platforms, the development of artificial intelligence supported computational predictors is an active area of research. However, diversity of languages hinders development of generic predictors that can precisely identify hate content. Several language-specific hate speech detection predictors have been developed for most common languages including English, Chinese and German. Specifically, for Urdu language a few predictors have been developed and these predictors lack in predictive performance. The paper in hand presents a precise and explainable deep learning predictor which makes use of advanced language modelling strategies for the extraction of semantic and discriminative patterns. Extracted patterns are utilized to train an attention-based novel classifier that is competent in precisely identifying hate content. Over coarse-grained benchmark dataset, the proposed predictor significantly outperforms state-of-the-art predictor by 8.7% in terms of accuracy, precision and F1-score. Similarly, over fine-grained dataset, in comparison with state-of-the-art predictor, it achieves performance gain of 10.6%, 17.6%, 18.6% and 17.6% in terms of accuracy, precision, recall and F1-score. © 2023, The Author(s).},
	author_keywords = {Aggregation attention; Attention head; Deep learning; Hate speech detection; Interpretability; Language model; Roman Urdu},
	keywords = {Computational linguistics; Deep learning; Modeling languages; Speech recognition; Aggregation attention; Attention head; Deep learning; F1 scores; Hate speech detection; Interpretability; Language model; Roman urdu; Speech detection; State of the art; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bensalem2024,
	author = {Bensalem, Imene and Rosso, Paolo and Zitouni, Hanane},
	title = {Toxic language detection: A systematic review of Arabic datasets},
	year = {2024},
	journal = {Expert Systems},
	volume = {41},
	number = {8},
	doi = {10.1111/exsy.13551},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183853209&doi=10.1111%2fexsy.13551&partnerID=40&md5=e7abc79e1e62eed1a8335011f38ce01d},
	affiliations = {ESCF de Constantine, Constantine, Algeria; MISC Lab, Constantine 2 University, Constantine, Algeria; Universitat Politècnica de València, València, Spain; Constantine 2 University, Constantine, Algeria},
	abstract = {The detection of toxic language in the Arabic language has emerged as an active area of research in recent years, and reviewing the existing datasets employed for training the developed solutions has become a pressing need. This paper offers a comprehensive survey of Arabic datasets focused on online toxic language. We systematically gathered a total of 54 available datasets and their corresponding papers and conducted a thorough analysis, considering 18 criteria across four primary dimensions: availability details, content, annotation process, and reusability. This analysis enabled us to identify existing gaps and make recommendations for future research works. For the convenience of the research community, the list of the analysed datasets is maintained in a GitHub repository. © 2024 John Wiley & Sons Ltd.},
	author_keywords = {annotation; Arabic datasets; dataset accessibility; dataset reusability; hate speech; offensive language; toxic language},
	keywords = {Annotation; Arabic dataset; Arabic languages; Dataset accessibility; Dataset reusability; Hate speech; Language detection; Offensive languages; Systematic Review; Toxic language; Reusability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Kibriya2024,
	author = {Kibriya, Hareem and Siddiqa, Ayesha and Khan, Wazir Zada and Khan, Muhammad Khurram},
	title = {Towards safer online communities: Deep learning and explainable AI for hate speech detection and classification},
	year = {2024},
	journal = {Computers and Electrical Engineering},
	volume = {116},
	doi = {10.1016/j.compeleceng.2024.109153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186659253&doi=10.1016%2fj.compeleceng.2024.109153&partnerID=40&md5=97887a976a292f41a50b053f82ec1d40},
	affiliations = {Department of Computer Science, University of Wah, Wah Cantt., 47040, Pakistan; Center of Excellence in Information Assurance, King Saud University, Riyadh, 11451, Saudi Arabia},
	abstract = {The internet and social media facilitate widespread idea sharing but also contribute to cyber-crimes and harmful behaviors, notably the dissemination of abusive and hateful speech, which poses a significant threat to societal cohesion. Hence, prompt and accurate detection of such harmful content is crucial. To address this issue, our study introduces a fully automated end-to-end model for hate speech detection and classification using Natural Language Processing and Deep Learning techniques. The proposed architecture comprising embedding, Convolutional, bidirectional Recurrent Neural Network, and bidirectional Long Short Term Memory layers, achieved the highest accuracy of 98.5%. Additionally, we employ explainable AI techniques, such as SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), to gain insights into the performance of the proposed framework. This comprehensive approach meets the pressing demand for swift and precise detection and categorization of harmful online content. © 2024 Elsevier Ltd},
	author_keywords = {Deep learning; Explainable Artificial Intelligence; Hate speech; Hate speech detection; Machine learning; Social media; Toxic comments},
	keywords = {E-learning; Learning systems; Lime; Multilayer neural networks; Natural language processing systems; Recurrent neural networks; Social networking (online); Deep learning; Explainable artificial intelligence; Hate speech; Hate speech detection; Machine-learning; On-line communities; Social media; Speech classification; Speech detection; Toxic comment; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Mamun2024,
	author = {Mamun, Maliha Binte and Tsunakawa, Takashi and Nishida, Masafumi and Nishimura, Masafumi},
	title = {Hate Speech Detection by Using Rationales for Judging Sarcasm},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {11},
	doi = {10.3390/app14114898},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195994928&doi=10.3390%2fapp14114898&partnerID=40&md5=96e8a50c3e4d3dd9061c2d6f0aeea9b3},
	affiliations = {Graduate School of Science and Technology, Shizuoka University, 3-5-1 Johoku, Chuo-ku, Hamamatsu, 432-8011, Japan; Department of Smart Design, Faculty of Architecture and Design, Aichi Sangyo University, 12-5 Harayama, Oka-machi, Okazaki, 444-0005, Japan},
	abstract = {The growing number of social media users has impacted the rise in hate comments and posts. While extensive research in hate speech detection attempts to combat this phenomenon by developing new datasets and detection models, reconciling classification accuracy with broader decision-making metrics like plausibility and faithfulness remains challenging. As restrictions on social media tighten to stop the spread of hate and offensive content, users have adapted by finding new approaches, often camouflaged in the form of sarcasm. Therefore, dealing with new trends such as the increased use of emoticons (negative emoticons in positive sentences) and sarcastic comments is necessary. This paper introduces sarcasm-based rationale (emoticons or portions of text that indicate sarcasm) combined with hate/offensive rationale for better detection of hidden hate comments/posts. A dataset was created by labeling texts and selecting rationale based on sarcasm from the existing benchmark hate dataset, HateXplain. The newly formed dataset was then applied in the existing state-of-the-art model. The model’s F1-score increased by 0.01 when using sarcasm rationale with hate/offensive rationale in a newly formed attention proposed in the data’s preprocessing step. Also, with the new data, a significant improvement was observed in explainability metrics such as plausibility and faithfulness. © 2024 by the authors.},
	author_keywords = {hate speech; rationale; sarcasm},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Hashmi2025,
	author = {Hashmi, Ehtesham and Yayilgan, Sule Yildirim and Yamin, Muhammad Mudassar and Abomhara, Mohamed and Ullah, Mohib},
	title = {Self-supervised hate speech detection in Norwegian texts with lexical and semantic augmentations},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {264},
	doi = {10.1016/j.eswa.2024.125843},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210076395&doi=10.1016%2fj.eswa.2024.125843&partnerID=40&md5=07b69320884e3520040185b9b00b94c2},
	affiliations = {Dept. of Information Security and Communication Technology (IIK), Norwegian University of Science and Technology (NTNU), Teknologivegen 22, 2815, Innlandet, Gjøvik, Norway; Intelligent Systems and Analytics (ISA) Research Group, Department of Computer Science (IDI), Norwegian University of Science and Technology (NTNU), Teknologivegen 22, 2815, Innlandet, Gjøvik, Norway},
	abstract = {The proliferation of social media platforms has significantly contributed to the spread of hate speech, targeting individuals based on race, gender, impaired functioning, religion, or sexual orientation. Online hate speech not only provokes prejudice and violence in cyber-space, but it also has profound impacts in real-world communities, eroding social harmony and increasing the risk of physical harm. This necessitates the urgency for effective hate speech detection systems, especially in low-resource languages such as Norwegian, where limited data availability presents additional challenges. This study utilizes the Barlow Twins methodology, applying a self-supervised learning framework to initially develop robust language representations for Norwegian, a language that is typically underrepresented in NLP research. These learned representations are then utilized in a semi-supervised classification task to detect hate speech. Leveraging a combination of text augmentation techniques at both the word and sentence level, along with self-training strategies, our approach demonstrates the potential to efficiently learn meaningful representations with a minimal amount of annotated data. Experimental results show that the Nor-BERT model is well-suited for detecting hate speech within the limited Norwegian data available, consistently outperforming other models. Additionally, Nor-BERT surpassed all deep learning-based models in terms of F1-score. © 2024 The Authors},
	author_keywords = {Data augmentation; Hate speech; Natural language processing; Self-representation learning; Transformers},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Natural language processing systems; Semantics; Semi-supervised learning; Speech recognition; Data augmentation; Hate speech; Language processing; Natural language processing; Natural languages; Self-representation learning; Semantic augmentations; Social media platforms; Speech detection; Transformer; Self-supervised learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Dodda202515,
	author = {Dodda, Ratnam and Putta, Pooja Reddy and Shulamite, Elthuri Chelsi and Ashwini, Kalmuri},
	title = {Enhancing Hate Speech Detection: Evaluation of Classification Models and Techniques},
	year = {2025},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1273 LNEE},
	pages = {15 – 21},
	doi = {10.1007/978-981-97-8031-0_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206809004&doi=10.1007%2f978-981-97-8031-0_2&partnerID=40&md5=ca4a9be61acc2e21ff2da0d01ec4d9c2},
	affiliations = {Depatment of CSIT, CVR College of Engineering, Hyderabad, India},
	abstract = {This paper addresses the analysis of hate speech detection models, responding to their increasing presence on social media and the need for effective countermeasures. While various techniques exist for automated hate speech detection, aimed at classifying text into hate speech or non-hate speech and identifying related attributes, a significant performance gap persists between these categories. The inherent challenge lies in the scarcity of distinct hate speech features, relegating it to a minority within datasets. To mitigate this, we propose employing Decision Trees, K-nearest neighbors (KNN), and Random Forest classification models. Our evaluation encompasses these models’ performance on extensive hate speech datasets sourced from common texts. Leveraging Python libraries such as Word Cloud, Sklearn, Pandas, Seaborn, Numpy, Lazypredict, Confusion Matrix, and F1 Score, we assess the realtime predictive accuracy of the hate speech detection model. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Decision trees; Hate speech detection; K-nearest neighbors; Random forest; Social media; Text classification},
	keywords = {Classification (of information); Nearest neighbor search; Speech recognition; Classification models; Classification technique; Detection models; Hate speech detection; K-near neighbor; Nearest-neighbour; Random forests; Social media; Speech detection; Text classification; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Data Science, Machine Learning and Applications, ICDSMLA 2023; Conference date: 15 December 2023 through 16 December 2023; Conference code: 321139}
}

@ARTICLE{Ayetiran2024,
	author = {Ayetiran, Eniafe Festus and Özgöbek, Özlem},
	title = {An inter-modal attention-based deep learning framework using unified modality for multimodal fake news, hate speech and offensive language detection},
	year = {2024},
	journal = {Information Systems},
	volume = {123},
	doi = {10.1016/j.is.2024.102378},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188460535&doi=10.1016%2fj.is.2024.102378&partnerID=40&md5=af78f7f696a2e70cf71b64b448bf19ba},
	affiliations = {Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway; Department of Computer Science, Achievers University, Nigeria},
	abstract = {Fake news, hate speech and offensive language are related evil triplets currently affecting modern societies. Text modality for the computational detection of these phenomena has been widely used. In recent times, multimodal studies in this direction are attracting a lot of interests because of the potentials offered by other modalities in contributing to the detection of these menaces. However, a major problem in multimodal content understanding is how to effectively model the complementarity of the different modalities due to their diverse characteristics and features. From a multimodal point of view, the three tasks have been studied mainly using image and text modalities. Improving the effectiveness of the diverse multimodal approaches is still an open research topic. In addition to the traditional text and image modalities, we consider image–texts which are rarely used in previous studies but which contain useful information for enhancing the effectiveness of a prediction model. In order to ease multimodal content understanding and enhance prediction, we leverage recent advances in computer vision and deep learning for these tasks. First, we unify the modalities by creating a text representation of the images and image–texts, in addition to the main text. Secondly, we propose a multi-layer deep neural network with inter-modal attention mechanism to model the complementarity among these modalities. We conduct extensive experiments involving three standard datasets covering the three tasks. Experimental results show that detection of fake news, hate speech and offensive language can benefit from this approach. Furthermore, we conduct robust ablation experiments to show the effectiveness of our approach. Our model predominantly outperforms prior works across the datasets. © 2024 The Author(s)},
	author_keywords = {BiLSTM-CNN; Fake news; Hate speech; Inter-modal attention; Multimodal content understanding; Multimodal fusion; Offensive language; Unified modality},
	keywords = {Deep neural networks; Fake detection; Multilayer neural networks; Speech recognition; BiLSTM-CNN; Fake news; Hate speech; Image texts; Inter-modal attention; Multi-modal; Multi-modal fusion; Multimodal content understanding; Offensive languages; Unified modality; Image enhancement},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gómez-Adorno2024393,
	author = {Gómez-Adorno, Helena and Bel-Enguix, Gemma and Calvo, Hiram and Ojeda-Trueba, Sergio and Andersen, Scott Thomas and Vásquez, Juan and Alcántara, Tania and Soto, Miguel and Macias, Cesar},
	title = {Overview of HOMO-MEX at IberLEF 2024: Hate Speech Detection Towards the Mexican Spanish speaking LGBT+ Population; [Resumen de HOMO-MEX en IberLEF 2024: Detección de discursos de odio hacia la población LGBT+ hispanohablante mexicana]},
	year = {2024},
	journal = {Procesamiento del Lenguaje Natural},
	number = {73},
	pages = {393 – 405},
	doi = {10.26342/2024-73-30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206842225&doi=10.26342%2f2024-73-30&partnerID=40&md5=2c6cfac767dc4068b89ce18b74834360},
	affiliations = {Instituto de Investigaciones en Matemáticas Aplicadas y Sistemas, Universidad Nacional Autónoma de México, Mexico; Instituto de Ingeniería, Universidad Nacional Autónoma de México, Mexico; Universidad Nacional Autónoma de México, Mexico; University of Colorado Boulder, Department of Computer Science, United States; Instituto Politécnico Nacional, Centro de Investigación en Computación, Mexico; Facultat de Filologia i Comunicació, Universitat de Barcelona, Spain},
	abstract = {We present the HOMO-MEX shared task organized at IberLEF 2024, as part of the 40th. International Conference of the Spanish Society for Natural Language Processing (SEPLN 2024). The aim of this task is to promote the development of natural language processing systems capable of detecting and classifying LGBT+phobic content in Mexican-Spanish digital posts and song lyrics. HOMO-MEX 2024 is composed of three subtasks: Task 1 on LGBT+phobia detection on social media posts, Task 2 on fine-grained phobia identification, and Task 3 on LGBT+phobia detection on song lyrics. In this second edition of HOMO-MEX, 40 participants registered on our Codabench platform. Subtask 1 received 19 submissions, subtask 2 received 10 submissions, and Subtask 3 got 17 submissions. Finally, 11 teams presented papers describing their systems. Most systems used transformer-based approaches to tackle the task, while the best-performing teams included data augmentation and preprocessing techniques. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {hate speech; LGBT+phobia; machine learning; song lyrics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Chanda2024103,
	author = {Chanda, Supriya and Dhaka, Abhishek and Pal, Sukomal},
	title = {Towards Safer Online Spaces: Deep Learning for Hate Speech Detection in Code-Mixed Social Media Conversations},
	year = {2024},
	journal = {Companion Proceedings of the 16th ACM  Web Science Conference, Websci Companion 2024 - Reflecting on the Web, AI and Society},
	pages = {103 – 109},
	doi = {10.1145/3630744.3663610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197186946&doi=10.1145%2f3630744.3663610&partnerID=40&md5=e31beb1e11edc1b433a9860af4864f0b},
	affiliations = {Indian Institute of Technology (BHU) Varanasi, Uttar Pradesh, Varanasi, India; B. K. Birla Institute of Engineering and Technology, Rajasthan, Pilani, India},
	abstract = {In the midst of the widespread adoption of technology, particularly among younger generations, the increasing prevalence of hate speech online has become a pressing global concern. This research paper aims to address this urgent issue by conducting a thorough investigation into hate speech detection in Hindi-English code-mixed data. Existing research has largely approached hate speech recognition as a text classification problem, focusing on predicting the class of a message based solely on its textual content. Our task, however, delves into the classification of hateful content disseminated through tweets, comments, and replies on Twitter, taking into account the contextual intricacies inherent in social media communication. In this context, contextual nuances play a crucial role in understanding communication dynamics. By employing state-of-The-Art deep learning techniques tailored to the unique linguistic characteristics of each language, this research makes a significant contribution to the development of robust and culturally sensitive hate speech detection systems. Such systems are essential for creating safer online environments and promoting cross-cultural understanding. Warning: The content of this paper may contain offensive material, reader discretion is advised. © 2024 ACM.},
	author_keywords = {Code-Mixing; Hate Speech Identification; Hindi-English; mBERT; Sentence BERT},
	keywords = {Classification (of information); Codes (symbols); Deep learning; E-learning; Learning systems; Linguistics; Online systems; Social networking (online); Text processing; Code-mixing; Hate speech identification; Hindi-english; MBERT; Pressung; Sentence BERT; Social media; Speech detection; Speech identification; Younger generations; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 16th ACM  Web Science Conference, Websci Companion 2024; Conference date: 21 May 2024 through 24 May 2024; Conference code: 200275; All Open Access, Bronze Open Access}
}

@ARTICLE{Imbwaga2024447,
	author = {Imbwaga, Joan L. and Chittaragi, Nagatatna B. and Koolagudi, Shashidhar G.},
	title = {Automatic hate speech detection in audio using machine learning algorithms},
	year = {2024},
	journal = {International Journal of Speech Technology},
	volume = {27},
	number = {2},
	pages = {447 – 469},
	doi = {10.1007/s10772-024-10116-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197117989&doi=10.1007%2fs10772-024-10116-6&partnerID=40&md5=7bbc64f421c6849bf4b582d75021da3d},
	affiliations = {Computer Science and Engineering, National Institute of Technology Karnataka, Karnataka, Surathkal, 575025, India; Information Science and Engineering, Siddaganga Institute of Technology, Karnataka, Tumkur, 572103, India},
	abstract = {Even though every individual is entitled to freedom of speech, some limitations exist when this freedom is used to target and harm another individual or a group of people, as it translates to hate speech. In this study, the proposed research deals with detection of hate speech for English and Kiswahili languages from audio. The dataset used in this work was collected manually from YouTube videos and then converted to audio. Audio-based features namely spectral, temporal, prosodic and excitation source features were extracted and used to train various machine learning classifiers. Initial experiments were conducted for English language and later on for Kiswahili language. However, it is observed from literature that research activities on Kiswahili language is comparatively lesser. The scores calculated for accuracy, recall, precision, auc and f1 score in detecting hate speech, suggest that Random Forest classifier performed better for English language while the Extreme Gradient Boosting classifier performed better for Kiswahili language. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Audio classification; Hate speech; Kiswahili; Machine learning; Prosodic features; Spectral features; YouTube},
	keywords = {Audio acoustics; Learning algorithms; Speech recognition; Audio classification; English languages; Hate speech; Kiswahilus; Machine learning algorithms; Machine-learning; Prosodic features; Spectral feature; Speech detection; YouTube; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Rohith2024,
	author = {Rohith, Yalam Venkata Sai and Amanullah, M.},
	title = {Improving the Accuracy by Comparing the Gaussian Naive Bayes Algorithm and Logistic Regression for Predicting Hate Speech Recognition},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10723838},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212859522&doi=10.1109%2fICCCNT61001.2024.10723838&partnerID=40&md5=95738ff08bb1b4e1089d1f0ee21b4874},
	affiliations = {Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Tamilnadu, India; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Saveetha Univerity, Tamilnadu, India},
	abstract = {Comparing the Novel Gaussian Naive Bayes method with Logistic Regression for Hate Speech Prediction with the aim of increasing accuracy. Materials and Methods: This proposed Machine learning uses improved accuracy through Novel Gaussian Naive Bayes algorithm compared with Logistic Regression. This study mainly consists of two groups. There are a total of 20 samples with each set having a example size of 10. The example size calculation is done with a G-power pretest of 80 percent, threshold 0.05 % and CI - 95 %. Results: When compared to the present system,which has an accuracy of only 92 %, it was found that the proposed method obtained 95 % accuracy. There exists no significance between the Novel Gaussian Naive Bayes algorithm Model and the Logistic Regression Model grounded on a sample T-test with the two tailed significance value of p=0.000 (p<0.05). This suggests that the two algorithms vary in a way that is statistically significant. Conclusion: Improved prediction accuracy of hate speech is shown by the outcomes of the Logistic Regression method. Hate Speech can be predicted by the existing system but using the Logistic Regression (LR) algorithm shows better accuracy to predict Hate Speech. So, the LR algorithm is used to forecast Hate Speech. ©2024 IEEE.},
	author_keywords = {Hate Speech; Logistic Regression; Machine Learning; Novel Gaussian Naive Bayes; Prediction; Violence},
	keywords = {Logistic regression; Prediction models; Bayes method; Gaussians; Hate speech; Logistic regression algorithms; Logistics regressions; Machine-learning; Naive bayes; Naive-Bayes algorithm; Novel gaussian naive baye; Violence; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@CONFERENCE{Yasmin2024682,
	author = {Yasmin, Ghazaala and Chaurasia, Kuldeep and Mahto, Anil Kumar},
	title = {Aspect Based Offensive Speech Detection Exploring Audio Features Through NLP Model},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {682 – 687},
	doi = {10.1145/3675888.3676131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210858071&doi=10.1145%2f3675888.3676131&partnerID=40&md5=675d18effbed6edc05810457a280d8f8},
	affiliations = {Jaypee Institute of Information Technology, Noida, India; Bennett University, Greater Noida, India},
	abstract = {Emotion recognition system is a very common yet challenging area where research is still extending its exploration. The problem becomes more challenging when it comes to analyze the sentiments to be understandable by the autistic children from speech. This challenge has motivated us to implement a sentiment analysis system along with that the system will also detect the system will detect offensive content from the speech data. The analysis of sentiment by using the concept of Natural Language Processing is identifying and categorising emotions in speech data. The identification of speech that contains words which impacts a person or a group is known as offensive speech. The proposed task is focussed on identifying emotion in a person voice. After the identification of speech others task is on determining the nature of the content of the speech data. This has been achieved by computing the speech polarities. The category of the content is majorly categorising into positive, negative, or neutral. The primary focus of the propound research is on identifying inappropriate vocabulary as well sentiments majorly categories as stressful, happy, anger and disgust. The speech data we have taken is a monolingual audio speech data. The proposed method has adopted the concept of transformer in natural language processing approach for creating the data into vectors and uses deep neural network for categorizing offensive content from the speech data. The proposed work has extracted relevant speech-based audio features to find the emotion and applying deep neural network to train the speech data in order to find the abusive word has been detected by applying natural language processing approach. The model has been trained on well-known Natural language processing model such as Global Vectors for Word Representation (GloVe), Convolution Neural Network (CNN), Long Short-Term Memory (LSTM), Bidirectional Encoder Representations from Transformers (BERT) and RoBERTa. In order to make the proposed worked more robust, it has been trained standard benchmark data of audio speech along with that, it has been trained on sample data. Finally, the model has been compared with state of art work. Some statistical measure is also considered for better analysis of the proposed methodology. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Audio Feature; BERT; CNN; Emotion detection; feature extraction; LSTM; MFCC; Offensive speech; RMS; RoBERTa},
	keywords = {Benchmarking; Convolutional neural networks; Emotion Recognition; Image coding; Long short-term memory; Network security; Spatio-temporal data; Speech analysis; Steganography; Word processing; Audio features; Bidirectional encoder representation from transformer; Convolution neural network; Emotion detection; Features extraction; MFCC; Offensive speech; RMS; RoBERTa; Short term memory; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 16th International Conference on Contemporary Computing, IC3 2024; Conference date: 8 August 2024 through 10 August 2024; Conference code: 204100}
}

@ARTICLE{Gde Bagus Janardana Abasan20241371,
	author = {Gde Bagus Janardana Abasan, I. and Setiawan, Erwin Budi},
	title = {Empowering hate speech detection: leveraging linguistic richness and deep learning},
	year = {2024},
	journal = {Bulletin of Electrical Engineering and Informatics},
	volume = {13},
	number = {2},
	pages = {1371 – 1382},
	doi = {10.11591/eei.v13i2.6938},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185946779&doi=10.11591%2feei.v13i2.6938&partnerID=40&md5=7664d973f3d993737a606e2aa06ed9e6},
	affiliations = {Department of Informatics Engineering, School of Computing, Telkom University, Bandung, Indonesia},
	abstract = {Social media has become a vital part of most modern human personal life. Twitter is one of the social media that was formed from the development of communication technology. A lot of social media gives users the freedom to express themselves. This facility is misused by users, so hate speech is spread. Designing a system to detect hate speech intelligently is needed. This study uses the hybrid deep learning (HDL) and solo deep learning (SDL) approach with the convolutional neural networks (CNN) and bidirectional gated recurrent unit (Bi-GRU) algorithm. There are 4 models built, namely CNN, Bi-GRU, CNN+Bi-GRU, and Bi-GRU+CNN. Term frequency-inverse document frequency (TF-IDF) is used for feature extraction, which is to get linguistic features to be analyzed and studied. FastText is used to perform feature expansion to minimize mismatched vocabulary. Four scenarios are run. CNN with an accuracy of 87.63%, Bi-GRU produces an accuracy of 87.46%, CNN+Bi-GRU provides an accuracy of 87.47% and Bi-GRU+CNN provides an accuracy of 87.34%. The ability of this approach to understand the context is qualified. HDL outperforms SDL in terms of n-gram type, where HDL can understand sentences broken down by hybrid n-gram types, namely Unigram-Bigram-Trigram which is a complex n-gram hybrid. © 2024, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {FastText; Feature expansion; Hate speech detection; Hybrid deep learning; Natural language processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Di Bonaventura2024,
	author = {Di Bonaventura, Chiara and Siciliani, Lucia and Basile, Pierpaolo and Meroño-Peñuela, Albert and McGillivray, Barbara},
	title = {Is Explanation All You Need? An Expert Survey on LLM-generated Explanations for Abusive Language Detection},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214358362&partnerID=40&md5=5989ce82fb6d225cb6de5a4b031b300c},
	affiliations = {King's College London, London, United Kingdom; Imperial College London, London, United Kingdom; Department of Computer Science, University of Bari Aldo Moro, Italy},
	abstract = {Explainable abusive language detection has proven to help both users and content moderators, and recent research has focused on prompting LLMs to generate explanations for why a specific text is hateful. Yet, understanding the alignment of these generated explanations with human expectations and judgements is far from being solved. In this paper, we design a before-and-after study recruiting AI experts to evaluate the usefulness and trustworthiness of LLM-generated explanations for abusive language detection tasks, investigating multiple LLMs and learning strategies. Our experiments show that expectations in terms of usefulness and trustworthiness of LLM-generated explanations are not met, as their ratings decrease by 47.78% and 64.32%, respectively, after treatment. Further, our results suggest caution in using LLMs for explanation generation of abusive language detection due to (i) their cultural bias, and (ii) difficulty in reliably evaluating them with empirical metrics. In light of our results, we provide three recommendations to use LLMs responsibly for explainable abusive language detection. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Explanation Generation; Hate Speech Detection; Human Evaluation; Large Language Models},
	keywords = {Speech recognition; Before-and-after study; Expert survey; Explanation generation; Hate speech detection; Human evaluation; Language detection; Language model; Large language model; Recent researches; Speech detection; Economic and social effects},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 10th Italian Conference on Computational Linguistics, CLiC-it 2024; Conference date: 4 December 2024 through 6 December 2024; Conference code: 205363}
}

@ARTICLE{Kumar2024,
	author = {Kumar, Ashwini and Kumar, Santosh and Passi, Kalpdrum and Mahanti, Aniket},
	title = {A Hybrid Deep BiLSTM-CNN for Hate Speech Detection in Multi-social media},
	year = {2024},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {23},
	number = {8},
	doi = {10.1145/3657635},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201604448&doi=10.1145%2f3657635&partnerID=40&md5=194cd90759b40eaa6ccf05113d270356},
	affiliations = {Department of Computer Science and Engineering, Graphic Era Deemed to Be University, Uttarakhand, Dehradun, India; Department of Mathematics & Computer Science, Laurentian University, Sudbury, ON, Canada; School of Computer Science, University of Auckland, Auckland, Auckland, New Zealand},
	abstract = {Nowadays, means of communication among people have changed due to advancements in information technology and the rise of online multi-social media. Many people express their feelings, ideas, and emotions on social media sites such as Instagram, Twitter, Gab, Reddit, Facebook, and YouTube. However, people have misused social media to send hateful messages to specific individuals or groups to create chaos. For various governance authorities, manually identifying hate speech on various social media platforms is a difficult task to avoid such chaos. In this study, a hybrid deep-learning model, where bidirectional long short-term memory (BiLSTM) and convolutional neural network (CNN) are used to classify hate speech in textual data, is proposed. This model incorporates a GLOVE-based word embedding approach, dropout, L2 regularization, and global max pooling to get impressive results. Further, the proposed BiLSTM-CNN model has been evaluated on various datasets to achieve state-of-the-art performance that is superior to the traditional and existing machine learning methods in terms of accuracy, precision, recall, and F1-score.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Bi-LSTM; CNN; Hate speech; machine learning},
	keywords = {Adversarial machine learning; Long short-term memory; Speech recognition; Tweets; Bi-LSTM; Convolutional neural network; Facebook; Hate speech; Machine-learning; Short term memory; Social media; Social media platforms; Speech detection; YouTube; Convolutional neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Putra2024,
	author = {Putra, Cendra Devayana and Wang, Hei-Chia},
	title = {Semi-meta-supervised hate speech detection},
	year = {2024},
	journal = {Knowledge-Based Systems},
	volume = {287},
	doi = {10.1016/j.knosys.2024.111386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183956994&doi=10.1016%2fj.knosys.2024.111386&partnerID=40&md5=2b8146d142aa22a843c91ebec6212ae6},
	affiliations = {Institute of Information Management, National Cheng Kung University, Tainan, 701, Taiwan; Center for Innovative FinTech Business Models, National Cheng Kung University, Tainan, 701, Taiwan},
	abstract = {On social media, hate speech is a daily occurrence but has physical and psychological implications. Utilizing a deep learning strategy to combat hate speech is one method for preventing it. Deep learning techniques may require massive datasets to generate accurate models, but hate speech samples (such as misogyny and cyber samples) are frequently insufficient and diverse. We offer methods for leveraging these diverse datasets and enhancing deep learning models through knowledge sharing. We analyzed the existing Bidirectional Encoder Representations from Transformers (BERT) technique and built a BERT-3CNN method to generate a single-task classifier that optimally absorbs the target dataset's features. Second, we proposed a shared BERT layer to gain a general understanding of hate speech. Third, we proposed a method for adapting another dataset to the desired dataset. We conducted several quantitative experimental investigations on five datasets, including Hatebase, Supremacist, Cybertroll, TRAC, and TRAC 2020, and assessed the achieved performance using the accuracy and F1 metrics. The first experiment demonstrated that our BERT-3CNN model improved the average accuracy by 5% and the F1 score by 18%. The second experiment demonstrated that BERT-SP improved the average accuracy by 0.2% and the F1 score by 2%. TRAC, Supremacist, Hatebase, and Cybertroll all showed improvements in accuracy, with Semi BERT-SP enhancing accuracy by 6% and F1 score by 5%, while TRAC2020 showed 10% and 9% improvements. © 2024 Elsevier B.V.},
	author_keywords = {Hate speech; Semisupervised learning; Shared knowledge; Single-task learning},
	keywords = {Deep learning; Knowledge management; Learning systems; Speech recognition; F1 scores; Hate speech; Learning strategy; Learning techniques; Massive data sets; Semi-supervised learning; Shared knowledge; Single task learning; Social media; Speech detection; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Thapa20241854,
	author = {Thapa, Surendrabikram and Jafri, Farhan Ahmad and Rauniyar, Kritesh and Nasim, Mehwish and Naseem, Usman},
	title = {RUHate-MM: Identification of Hate Speech and Targets using Multimodal Data from Russia-Ukraine Crisis},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {1854 – 1863},
	doi = {10.1145/3589335.3651973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194483871&doi=10.1145%2f3589335.3651973&partnerID=40&md5=e285838a168ef646f7d439d4ebd066b8},
	affiliations = {Virginia Tech, Blacksburg, VA, United States; Jamia Millia Islamia, Delhi, New Delhi, India; Delhi Technological University, Delhi, New Delhi, India; University of Western Australia, Flinders University, Australia; Macquarie University, Sydney, NSW, Australia},
	abstract = {During the conflict between Ukraine and Russia, hate speech targeted toward specific groups was widespread on different social media platforms. With most social platforms allowing multimodal content, the use of multimodal content to express hate speech is widespread on the Internet. Although there has been considerable research in detecting hate speech within unimodal content, the investigation into multimodal content remains insufficient. The limited availability of annotated multimodal datasets further restricts our ability to explore new methods to interpret and identify hate speech and its targets. The availability of annotated datasets for hate speech detection during political events, such as invasions, are even limited. To fill this gap, we introduce a comprehensive multimodal dataset consisting of 20,675 posts related to the Russia-Ukraine crisis, which were manually annotated as either ‘Hate Speech’ or ‘No Hate Speech’. Additionally, we categorize the hate speech data into three targets: ‘Individual’, ‘Organization’, and ‘Community’. Our benchmarked evaluations show that there is still room for improvement in accurately identifying hate speech and its targets. We hope that the availability of this dataset and the evaluations performed on it will encourage the development of new methods for identifying hate speech and its targets during political events like invasions and wars. The dataset and resources are made available at https://github.com/Farhan-jafri/Russia-Ukraine. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Content Moderation; Hate Speech; Multimodal Data; Russia-Ukraine Crisis},
	keywords = {Speech recognition; Content moderation; Hate speech; Multi-modal; Multi-modal data; Multi-modal dataset; Political events; Russia-ukraine crisis; Social media platforms; Ukraine; Unimodal; HTTP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 33rd ACM Web Conference, WWW 2024; Conference date: 13 May 2024 through 17 May 2024; Conference code: 199461; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhou2024443,
	author = {Zhou, Sunrui},
	title = {Chinese cyber-violent Speech Detection and Analysis Based on Pre-trained Model},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {443 – 447},
	doi = {10.1145/3670105.3670179},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200944031&doi=10.1145%2f3670105.3670179&partnerID=40&md5=c0ca4e8847926927163954e3847f746d},
	affiliations = {Shanghai University, China},
	abstract = {Cyber-violent speech is prevalent on Chinese social platforms today, and traditional manual moderation by platform administrators is no longer effective in detecting and analyzing it. Therefore, the use of artificial intelligence technologies like natural language processing for automated detection on the Internet is an essential requirement to promptly prevent the spread of cyber-violent speech. Due to the covert and diverse nature of cyber-violent speech, existing models have shown unsatisfactory performance in detecting implicitly expressed violent speech. This paper proposes a violence speech detection method based on BERT and Hanyu Pinyin and emotion assistance, and its effectiveness and advancement are validated on multiple datasets. Subsequently, the experimental results are analyzed to summarize the characteristics of Chinese violent speech, facilitating further development in violence speech detection efforts in the future.  © 2024 ACM.},
	author_keywords = {BERT; Chinese cyber-violent speech; Emotion; Hanyu Pinyin},
	keywords = {Natural language processing systems; Artificial intelligence technologies; Automated detection; BERT; Chinese cybe-violent speech; Emotion; Hanyu pinyin; Language processing; Natural languages; Performance; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Computing, Networks and Internet of Things, CNIOT 2024; Conference date: 24 May 2024 through 26 May 2024; Conference code: 201391}
}

@CONFERENCE{Alves202455,
	author = {Alves, Thayná and Weitzel, Leila},
	title = {MULTIMODAL HATE SPEECH DETECTION: LEVERAGING TEXTUAL AND VISUAL INFORMATION (IN PORTUGUESE)},
	year = {2024},
	journal = {Proceedings of the International Conferences on Applied Computing and WWW/Internet 2024},
	pages = {55 – 62},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214112549&partnerID=40&md5=151ddbf25c8852ed62b70dc8c6d52035},
	affiliations = {Computer Science Department, Fluminense Federal University, Rio de Janeiro, Brazil},
	abstract = {The rapid growth of social media has amplified the dissemination of hate speech, posing a substantial threat to online communities. While traditional text-based approaches have limitations, e.g., they often fall short in capturing the rich contextual information conveyed through visual cues. To tackle this issue, the multimodal analysis offers potential improvements. This paper proposes a multimodal model that integrates textual and visual cues for hate speech detection specifically focusing on Brazilian Portuguese. By combining CNNs for facial expression analysis and BERT for text processing. Multimodal classification allows for a more comprehensive understanding of the context in which hate speech occurs. Visual cues, such as symbols or gestures in images, can be strong indicators of hate speech that textual analysis alone might miss. This research suggest that multimodal approaches can reduce this ambiguity by providing additional context through images or videos, making it easier to discern the true intent behind a post. While multimodal classification holds great promise, several challenges remain. One major issue is the computational complexity associated with processing and integrating multiple modalities, which can require substantial computational resources. © 2024 Proceedings of the International Conferences on Applied Computing and WWW/Internet 2024. All rights reserved.},
	author_keywords = {Hate Speech Detection; Late Fusion; Multimodal; Social Media},
	keywords = {Hate speech detection; Late fusion; Multi-modal; On-line communities; Rapid growth; Social media; Speech detection; Textual information; Visual cues; Visual information; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st International Conference on Applied Computing 2024, AC 2024 and 23rd International Conference on WWW/Internet 2024, ICWI 2024; Conference date: 26 October 2024 through 28 October 2024; Conference code: 204900}
}

@CONFERENCE{Sudharsan2025349,
	author = {Sudharsan, V. and Kumar, U. Nidhish and Evan, X. Moses and Jeya, J. Jospin},
	title = {Multi-task semantic level hate speech detection using transformer based model and ensemble classifiers},
	year = {2025},
	journal = {Computational Methods in Science and Technology - Proceedings of the 4th International Conference on Computational Methods in Science and Technology, ICCMST 2024},
	volume = {2},
	pages = {349 – 354},
	doi = {10.1201/9781003561651-50},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209185991&doi=10.1201%2f9781003561651-50&partnerID=40&md5=b290f6c889afd4822afb52662486d444},
	affiliations = {SRM Institute of Science and Technology, Ramapuram Campus, Chennai, India},
	abstract = {The sheer amount of social users has led to many people misusing these platforms to spread offensive content and hate speech. It’s not practical to manually track the number of posts, so it’s necessary to create an automated process to find out quickly. Large language models are learned about many documents and content embeddings are also used. To detect hateful words and suspicious content in tweets, a system based on the classical tracking algorithm is proposed, which only inputs character n-grams and hence all individual words. Interpreting hate speech to encompass multiple languages and documents eliminates cultural nuances in meaning; therefore, using language-independent embeddings to build models that capture the negative context speech in the literature. These performances suggest that this is an interesting level to evaluate the results of using more techniques (such as deep learning) or to consider additional resources. © 2025 the Author(s).},
	keywords = {Embeddings; Speech recognition; Tweets; Automated process; Embeddings; Ensemble-classifier; Language model; Multi tasks; Multiple languages; N-grams; Semantic levels; Speech detection; Tracking algorithm; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Computational Methods in Science and Technology, ICCMST 2024; Conference date: 2 May 2024 through 3 May 2024; Conference code: 321169}
}

@ARTICLE{Guo2024,
	author = {Guo, Xingyi and Adnan, Hamedi Mohd and Abidin, Muhammad Zaiamri Zainal},
	title = {Detecting Offensive Language on Malay Social Media: A Zero-Shot, Cross-Language Transfer Approach Using Dual-Branch mBERT},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {13},
	doi = {10.3390/app14135777},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198483317&doi=10.3390%2fapp14135777&partnerID=40&md5=3a7c7f825f945e0c184ba24de91bb4ca},
	affiliations = {Department of Media and Communication Studies, University of Malaya, Kuala Lumpur, 50603, Malaysia},
	abstract = {Social media serves as a platform for netizens to stay informed and express their opinions through the Internet. Currently, the social media discourse environment faces a significant security threat—offensive comments. A group of users posts comments that are provocative, discriminatory, and objectionable, intending to disrupt online discussions, provoke others, and incite intergroup conflict. These comments undermine citizens’ legitimate rights, disrupt social order, and may even lead to real-world violent incidents. However, current automatic detection of offensive language primarily focuses on a few high-resource languages, leaving low-resource languages, such as Malay, with insufficient annotated corpora for effective detection. To address this, we propose a zero-shot, cross-language unsupervised offensive language detection (OLD) method using a dual-branch mBERT transfer approach. Firstly, using the multi-language BERT (mBERT) model as the foundational language model, the first network branch automatically extracts features from both source and target domain data. Subsequently, Sinkhorn distance is employed to measure the discrepancy between the source and target language feature representations. By estimating the Sinkhorn distance between the labeled source language (e.g., English) and the unlabeled target language (e.g., Malay) feature representations, the method minimizes the Sinkhorn distance adversarially to provide more stable gradients, thereby extracting effective domain-shared features. Finally, offensive pivot words from the source and target language training sets are identified. These pivot words are then removed from the training data in a second network branch, which employs the same architecture. This process constructs an auxiliary OLD task. By concealing offensive pivot words in the training data, the model reduces overfitting and enhances robustness to the target language. In the end-to-end framework training, the combination of cross-lingual shared features and independent features culminates in unsupervised detection of offensive speech in the target language. The experimental results demonstrate that employing cross-language model transfer learning can achieve unsupervised detection of offensive content in low-resource languages. The number of labeled samples in the source language is positively correlated with transfer performance, and a greater similarity between the source and target languages leads to better transfer effects. The proposed method achieves the best performance in OLD on the Malay dataset, achieving an F1 score of 80.7%. It accurately identifies features of offensive speech, such as sarcasm, mockery, and implicit expressions, and showcases strong generalization and excellent stability across different target languages. © 2024 by the authors.},
	author_keywords = {cross-language model; mBERT; offensive language detection; transfer learning; unsupervised methods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Huang2025333,
	author = {Huang, Qingbao and Deng, Zehua and Chen, Shizhen and Chen, Yifei and Shuang, Feng},
	title = {Hate Speech Detection for the Power Domain},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15362 LNAI},
	pages = {333 – 345},
	doi = {10.1007/978-981-97-9440-9_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210069987&doi=10.1007%2f978-981-97-9440-9_26&partnerID=40&md5=9da1abbd184e41b215d9d4c1ae225c19},
	affiliations = {School of Electrical Engineering, Guangxi University, Guangxi, Nanning, China; School of Computer, Electronics and Information, Guangxi University, Guangxi, Nanning, China; Guangxi Key Laboratory of Intelligent Control and Maintenance of Power Equipment, Guangxi, Nanning, China},
	abstract = {The professional nature and confidentiality of the power domain hinder the public to accurately assess the authenticity of online electricity-related statements, fostering an environment conducive to the spread of electricity-related hate speech on social media. To address this challenge, we introduce a new hate speech detection task for the electric power domain. A dataset for electric power domain hate speech detection is constructed, consisting of 6000 electricity-related Weibo posts. We propose a prompt learning approach for hate speech detection in the electric power domain, which integrates power domain knowledge, such as work scenarios and terms. Subsequently, a prompt template is formulated to facilitate hate speech detection. Experimental results on the dataset indicate that the proposed prompt learning method surpasses the baseline model. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Hate Speech Detection; Pre-trained visual language model; Prompt Learning},
	keywords = {Detection tasks; Electric power; Hate speech detection; Learning approach; Powerdomains; Pre-trained visual language model; Prompt learning; Social media; Speech detection; Visual language model},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024; Conference date: 1 November 2024 through 3 November 2024; Conference code: 322629}
}

@ARTICLE{Mali2025,
	author = {Mali, Mohan K. and Pawar, Ranjeet R. and Shinde, Sandeep A. and Kale, Satish D. and Mulik, Sameer V. and Jagtap, Asmita A. and Tambewagh, Pratibha A. and Rajput, Punam U.},
	title = {Automatic detection of cyberbullying behaviour on social media using Stacked Bi-Gru attention with BERT model},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {262},
	doi = {10.1016/j.eswa.2024.125641},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208507505&doi=10.1016%2fj.eswa.2024.125641&partnerID=40&md5=89731db6fd4eda303d4ef366984a71ce},
	affiliations = {Bharati Vidyapeeth Institute of Technology, Navi Mumbai, India},
	abstract = {Cyberbullying behaviour has drawn more attention as social media usage has grown. Teen suicide has been related to cyberbullying, among other serious and harmful effects on a person's life. Using the appropriate natural language processing and machine learning techniques, it is possible to proactively identify bullying content to reduce and eventually eradicate cyberbullying. Accordingly, the article proposed an automated deep-learning model for detecting aggressive activity in cyberbullying. Initially, the data was extracted from the social media platform using Formspring, Instagram and MySpace datasets for perceiving cyberbullying behaviour, then the collected data are input for preprocessing. To remove the raw data, several preprocessing processes have been introduced. They consist of removing stop words, white spaces for punctuation, and changing the comments to lowercase. Lexical Density (LD) has been one of the metrics used to gauge language complexity generally. As a result, the study made use of the Feature Density (FD) to calculate how complicated certain natural language datasets are using the linguistically backed preprocessing model. After preprocessing, the data are input to the feature selection process which selects the pertinent features or attributes to include in predictive modelling and which to leave out. Since, the article proposed a Binary Chimp Optimization (BCO)-based Feature Selection (BCO-FSS) technique, which selects the subset of features for classification performance improvement. The selected features are exploited for cyberbullying behaviour detection. To identify the exploit of social media for cyberbullying text content, the article suggested Stacked Bidirectional Gated Recurrent Unit (SBiGRU) Attention for learning spatial location information and sequential semantic representations using a Bi-GRU. Additionally, the BERT model is employed as a base classifier to recognize and categorise aggressive behaviour in the textual content. The Matlab software is employed for simulation. For accuracy, precision, recall, and F1-Score, this experiment yielded a practically perfect outcome with values of 99.12%, 94.73%, 97.45%, and 93.91% respectively. © 2024},
	author_keywords = {Aggressive Behaviour; Automatic Detection; Binary Chimp Optimization; Cyberbullying; Feature Selection; Social Networks; Stacked Bidirectional Gated Recurrent Unit},
	keywords = {Computer software selection and evaluation; Deep learning; Economic and social effects; Input output programs; Natural language processing systems; Semantics; Aggressive behavior; Automatic Detection; Binary chimp optimization; Cyber bullying; Features selection; Natural languages; Optimisations; Social media; Social network; Stacked bidirectional gated recurrent unit; MATLAB},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mazari2024325,
	author = {Mazari, Ahmed Cherif and Boudoukhani, Nesrine and Djeffal, Abdelhamid},
	title = {BERT-based ensemble learning for multi-aspect hate speech detection},
	year = {2024},
	journal = {Cluster Computing},
	volume = {27},
	number = {1},
	pages = {325 – 339},
	doi = {10.1007/s10586-022-03956-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145503586&doi=10.1007%2fs10586-022-03956-x&partnerID=40&md5=35a10bdb97da9846c9b0841c5b0909ef},
	affiliations = {LSEA Laboratory, Mathematics and Computer Science Department, University of Médéa, Médéa, Algeria; EEDIS Laboratory, Computer Science Department, University of Sidi Bel Abbès, Sidi Bel Abbès, Algeria; LESIA Laboratory, Computer Science Department, University of Biskra, Biskra, Algeria},
	abstract = {The social media world nowadays is overwhelmed with unfiltered content ranging from cyberbullying and cyberstalking to hate speech. Therefore, identifying and cleaning up such toxic language presents a big challenge and an active area of research. This study is dedicated to multi-aspect hate speech detection based on classifying text in multi-labels including ‘identity hate’, ‘threat’, ‘insult’, ‘obscene’, ‘toxic’ and ‘severe toxic’. The proposed approach is based on the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model combined with Deep Learning (DL) models to compose several ensemble learning architectures. The DL models used are built by stacking Bidirectional Long-Short Term Memory (Bi-LSTM) and/or Bidirectional Gated Recurrent Unit (Bi-GRU) on GloVe and FastText word embeddings. Whereby, these models and BERT are trained individually on multi-label hateful dataset and used in combination for hate speech detection tasks on social media. Thus, we demonstrate that encoding texts by using recent word embedding techniques as FastText and GloVe alongside Bi-LSTM and Bi-GRU can create models that, when combined with BERT, can enhance the ROC-AUC score to 98.63%. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.},
	author_keywords = {BERT model; Deep learning; Ensemble learning; Language toxicity; Multi-aspect hate speech},
	keywords = {Embeddings; Signal encoding; Social networking (online); Speech recognition; Bidirectional encoder representation from transformer model; Deep learning; Ensemble learning; Language toxicity; Multi aspects; Multi-aspect hate speech; Multi-labels; Social media; Speech detection; Transformer modeling; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Gasmi2024355,
	author = {Gasmi, Salwa and Mezghani, Anis and Kherallah, Monji},
	title = {SMOTE for enhancing Tunisian Hate Speech detection on social media with machine learning},
	year = {2024},
	journal = {International Journal of Hybrid Intelligent Systems},
	volume = {20},
	number = {4},
	pages = {355 – 368},
	doi = {10.3233/HIS-240012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214653183&doi=10.3233%2fHIS-240012&partnerID=40&md5=576d2b4c3581645d65832a7f6ce27f4e},
	affiliations = {National School of Engineers, University of Gabes, Gabès, Tunisia; Advanced Technologies for Environment and Smart Cities, Faculty of Sciences, University of Sfax, Sfax, Tunisia; Higher Institute of Industrial Management, University of Sfax, Sfax, Tunisia},
	abstract = {In the last decade, the world has witnessed remarkable technological development, especially in artificial intelligence, which helps researchers find solutions to problems of concern to the individual and society, mainly, the huge propagation of hate speech with the increased use of social media platforms. In this study, we aim to enhance the detection of Arabic hate speech on social media by addressing challenges related to imbalanced datasets through data augmentation techniques. Several machine learning algorithms and the DziriBert, a pre-trained transformer model, are implemented on the Tunisian Hate Speech and Abusive Dataset (T-HSAB). The proposed approach achieves good results, improving the detection of hateful comments on Arabic social media using the Synthetic Minority Over-sampling Technique (SMOTE). Notably, the DziriBert model exhibits remarkable proficiency in detecting hate speech, achieving an accuracy of 82%. Random Forest (RF) and Linear SVC outperform the state of the art approaches, achieving the best result.  © 2024 - IOS Press. All rights reserved.},
	author_keywords = {DziriBert; machine learning; NLP; SMOTE; social media; Tunisian hate speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Imbwaga2024793,
	author = {Imbwaga, Joan L. and Chittaragi, Nagaratna B. and Koolagudi, Shashidhar G.},
	title = {Explainable hate speech detection using LIME},
	year = {2024},
	journal = {International Journal of Speech Technology},
	volume = {27},
	number = {3},
	pages = {793 – 815},
	doi = {10.1007/s10772-024-10135-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202689010&doi=10.1007%2fs10772-024-10135-3&partnerID=40&md5=c50ee3cad8f39a9668a5c3fd6595984c},
	affiliations = {Computer Science and Engineering, National Institute of Technology Karnataka, Karnataka, Surathkal, 575025, India; Information Science and Engineering, Siddaganga Institute of Technology, Karnataka, Tumkur, 572103, India},
	abstract = {Free speech is essential, but it can conflict with protecting marginalized groups from harm caused by hate speech. Social media platforms have become breeding grounds for this harmful content. While studies exist to detect hate speech, there are significant research gaps. First, most studies used text data instead of other modalities such as videos or audio. Second, most studies explored traditional machine learning algorithms. However, due to the increase in complexities of computational tasks, there is need to employ complex techniques and methodologies. Third, majority of the research studies have either been evaluated using very few evaluation metrics or not statistically evaluated at all. Lastly, due to the opaque, black-box nature of the complex classifiers, there is need to use explainability techniques. This research aims to address these gaps by detecting hate speech in English and Kiswahili languages using videos manually collected from YouTube. The videos were converted to text and used to train various classifiers. The performance of these classifiers was evaluated using various evaluation and statistical measurements. The experimental results suggest that the random forest classifier achieved the highest results for both languages across all evaluation measurements compared to all classifiers used. The results for English language were: accuracy 98%, AUC 96%, precision 99%, recall 97%, F1 98%, specificity 98% and MCC 96% while the results for Kiswahili language were: accuracy 90%, AUC 94%, precision 93%, recall 92%, F1 94%, specificity 87% and MCC 75%. These results suggest that the random forest classifier is robust, effective and efficient in detecting hate speech in any language. This also implies that the classifier is reliable in detecting hate speech and other related problems in social media. However, to understand the classifiers’ decision-making process, we used the Local Interpretable Model-agnostic Explanations (LIME) technique to explain the predictions achieved by the random forest classifier. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {BERT; Explainable AI (XAI); GPT-J-6B; Hate speech; Kiswahili; Local Interpretable Model-agnostic Explanations (LIME); Whisper AI},
	keywords = {Decision trees; Economic and social effects; Machine learning; Speech recognition; BERT; Explainable AI (XAI); Free speech; GPT-J-6b; Hate speech; Kiswahilus; Local interpretable model-agnostic explanation; Random forest classifier; Speech detection; Whisper AI; Random forests},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Faria2024,
	author = {Faria, Fatema Tuj Johora and Baniata, Laith H. and Kang, Sangwoo},
	title = {Investigating the Predominance of Large Language Models in Low-Resource Bangla Language over Transformer Models for Hate Speech Detection: A Comparative Analysis},
	year = {2024},
	journal = {Mathematics},
	volume = {12},
	number = {23},
	doi = {10.3390/math12233687},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211805581&doi=10.3390%2fmath12233687&partnerID=40&md5=1728482a29ba303f923eba762b23ddc4},
	affiliations = {Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, 1208, Bangladesh; School of Computing, Gachon University, Seongnam, 13120, South Korea},
	abstract = {The rise in abusive language on social media is a significant threat to mental health and social cohesion. For Bengali speakers, the need for effective detection is critical. However, current methods fall short in addressing the massive volume of content. Improved techniques are urgently needed to combat online hate speech in Bengali. Traditional machine learning techniques, while useful, often require large, linguistically diverse datasets to train models effectively. This paper addresses the urgent need for improved hate speech detection methods in Bengali, aiming to fill the existing research gap. Contextual understanding is crucial in differentiating between harmful speech and benign expressions. Large language models (LLMs) have shown state-of-the-art performance in various natural language tasks due to their extensive training on vast amounts of data. We explore the application of LLMs, specifically GPT-3.5 Turbo and Gemini 1.5 Pro, for Bengali hate speech detection using Zero-Shot and Few-Shot Learning approaches. Unlike conventional methods, Zero-Shot Learning identifies hate speech without task-specific training data, making it highly adaptable to new datasets and languages. Few-Shot Learning, on the other hand, requires minimal labeled examples, allowing for efficient model training with limited resources. Our experimental results show that LLMs outperform traditional approaches. In this study, we evaluate GPT-3.5 Turbo and Gemini 1.5 Pro on multiple datasets. To further enhance our study, we consider the distribution of comments in different datasets and the challenge of class imbalance, which can affect model performance. The BD-SHS dataset consists of 35,197 comments in the training set, 7542 in the validation set, and 7542 in the test set. The Bengali Hate Speech Dataset v1.0 and v2.0 include comments distributed across various hate categories: personal hate (629), political hate (1771), religious hate (502), geopolitical hate (1179), and gender abusive hate (316). The Bengali Hate Dataset comprises 7500 non-hate and 7500 hate comments. GPT-3.5 Turbo achieved impressive results with 97.33%, 98.42%, and 98.53% accuracy. In contrast, Gemini 1.5 Pro showed lower performance across all datasets. Specifically, GPT-3.5 Turbo excelled with significantly higher accuracy compared to Gemini 1.5 Pro. These outcomes highlight a 6.28% increase in accuracy compared to traditional methods, which achieved 92.25%. Our research contributes to the growing body of literature on LLM applications in natural language processing, particularly in the context of low-resource languages. © 2024 by the authors.},
	author_keywords = {Bengali language; few-shot learning; hate speech detection; large language models; low resource language; natural language processing; zero-shot learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Dhanya2024316,
	author = {Dhanya, L.K. and Balakrishnan, Kannan},
	title = {Integrating Hybrid Neural Networks and Domain-Specific Embeddings for Detecting Hate Content in Code Mixed Social Media Comments},
	year = {2024},
	journal = {Journal of Internet Services and Information Security},
	volume = {14},
	number = {3},
	pages = {316 – 329},
	doi = {10.58346/JISIS.2024.I3.019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204689734&doi=10.58346%2fJISIS.2024.I3.019&partnerID=40&md5=edb306a421eb6aa44c3614228226e471},
	affiliations = {Department of Computer Applications, Cochin University of Science and Technology, Kerala, Kochi, India; Mar Baselios College of Engineering and Technology, Kerala, Trivandrum, India},
	abstract = {Hate speech is any communication intended to irritate, intimidate, disrupt, or incite anger in an individual or a group, typically targeting characteristics such as religion, ethnicity, appearance, or sexual orientation. Inhabitants of multilingual communities often engage in conversations using multiple regional languages. This sort of textual communication is known as code-mixed data since it combines many languages. This research shows how to recognize and detect hate speech in code-mixed Malayalam-English (Manglish) material. We created a dataset of Manglish-written social media comments from platforms like YouTube and Facebook. Before delving into word embeddings, we developed a unique stopword list designed specifically for Manglish, which has never been done previously. This bespoke stopword list significantly enhanced our data preparation operations. Following that, we concentrated on evaluating several word embedding techniques. We then utilized Glove to develop a distinct domain-specific word embedding model (DSG)for Malayalam-English code-mixed data. This concept was crucial in increasing the overall efficiency of our model. In addition to the approaches described above, we conducted a comprehensive set of experiments using several classifiers such as logistic regression, SVM, and XGBoost, as well as deep learning models such as Convolutional Neural Network (CNN) and bidirectional Long-Short-Term Memory (BiLSTM). Following thorough experimental testing, we suggested a unique hybrid deep-learning model with domain-specific word embeddings. This technique was quite effective in managing our dataset, with an astonishing 96.4% accuracy in detecting hate speech in Manglish comments. © 2024, Innovative Information Science and Technology Research Group. All rights reserved.},
	author_keywords = {Code-mixed Data; Domain Specific Word Embedding; Hate Speech; Hybrid Deep Learning; Manglish; Stopwords},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Nandhini2024,
	author = {Nandhini, P.S. and Karunamoorthi, R. and Mariappan, P. and Revathi, S.},
	title = {Multilingual Offensive Language Detection In Social Media Content Using BERT-Base-Multilingual-Cased Model},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10726015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213065971&doi=10.1109%2fICCCNT61001.2024.10726015&partnerID=40&md5=8332ef2837eae1ca3f349640bbf4f5fa},
	affiliations = {Kongu Engineering College, Department of CSE, Erode, India; Velalar College of Engg.& Tech, Department of CSE, Erode, India; ErodeSengunthar Engg. College, Department of CSE, Erode, India},
	abstract = {The rise of social media and online communication has fostered global dialogue, transcending linguistic and geographic barriers. However, it has also ushered in the use of offensive language, posing challenges to safe digital spaces. Addressing this in a multilingual context is crucial for a more inclusive online environment. This paper tackles the classification of offensive and non-offensive comments, delving into the complexities of multilingual offensive language detection. Utilizing a joint-multilingual approach-based BERT model, comments are classified across various languages. Experiments on a dataset featuring English, Hindi, Telugu, Malayalam, Kannada, Greek, and Russian comments yield promising results: 92.47% of accuracy and a confidence score of 51.60%. © 2024 IEEE.},
	author_keywords = {BERT; joint multilingual method; languages; Offensive Detection},
	keywords = {Classification (of information); BERT; Joint multilingual method; Language; Language detection; Media communications; Media content; Offensive detection; Offensive languages; On-line communication; Social media; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@ARTICLE{Awal20241086,
	author = {Awal, Md Rabiul and Lee, Roy Ka-Wei and Tanwar, Eshaan and Garg, Tanmay and Chakraborty, Tanmoy},
	title = {Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {1},
	pages = {1086 – 1095},
	doi = {10.1109/TCSS.2023.3252401},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153346219&doi=10.1109%2fTCSS.2023.3252401&partnerID=40&md5=d0e66afd1f97c7eff0d17cbb929ddb0b},
	affiliations = {University of Saskatchewan, Department of Computer Science, Saskatoon, S7N 5A2, Canada; Singapore University of Technology and Design, Design and Artificial Intelligence, Tampines, 487372, Singapore; DTU-Delhi, College of Engineering, Delhi, 110042, India; IIIT-Delhi, Department of Computer Science and Engineering, Delhi, 110020, India; IIT Delhi, Department of Electrical Engineering, Delhi, 110016, India},
	abstract = {Hate speech in social media is a growing phenomenon, and detecting such toxic content has recently gained significant traction in the research community. Existing studies have explored fine-Tuning language models (LMs) to perform hate speech detection, and these solutions have yielded significant performance. However, most of these studies are limited to detecting hate speech only in English, neglecting the bulk of hateful content that is generated in other languages, particularly in low-resource languages. Developing a classifier that captures hate speech and nuances in a low-resource language with limited data is extremely challenging. To fill the research gap, we propose HateMAML, a model-Agnostic meta-learning (MAML)-based framework that effectively performs hate speech detection in low-resource languages. HateMAML utilizes a self-supervision strategy to overcome the limitation of data scarcity and produces better LM initialization for fast adaptation to an unseen target language (i.e., cross-lingual transfer) or other hate speech datasets (i.e., domain generalization). Extensive experiments are conducted on five datasets across eight different low-resource languages. The results show that HateMAML outperforms the state-of-The-Art baselines by more than 3% in the cross-domain multilingual transfer setting. We also conduct ablation studies to analyze the characteristics of HateMAML.  © 2014 IEEE.},
	author_keywords = {Cross-lingual transfer; hate speech detection; meta-learning},
	keywords = {Job analysis; Learning systems; Adaptation models; Cross-lingual; Cross-lingual transfer; Hate speech; Hate speech detection; Metalearning; Predictive models; Speech detection; Task analysis; Training data; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@ARTICLE{Arul Antran Vijay2024407,
	author = {Arul Antran Vijay, S. and Tanush, K. and Udhayarajan, M. and Jishnu, B. and Suwinkumar, T.},
	title = {Detecting Offensive Language in Tamil YouTube Comments},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {856 LNNS},
	pages = {407 – 420},
	doi = {10.1007/978-981-97-7571-2_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214421591&doi=10.1007%2f978-981-97-7571-2_31&partnerID=40&md5=c90f437f9227ff135fa6661e0b8c8e0c},
	affiliations = {Department of Computer Science and Engineering, Karpagam College of Engineering, Tamilnadu, Coimbatore, India},
	abstract = {Online content moderation faces significant challenges in identifying offensive language across diverse linguistic environments. This study compares the performance of five advanced BERT models mBERT, BERT Base, BERT Large, DistilBERT, and RoBERTa in detecting offensive language specifically in Tamil YouTube comments. Through meticulous evaluation using metrics like accuracy, precision, recall, and F1-score, we analyze the nuanced processing capabilities of these models tailored to address the complexities of the Tamil language. Among the models assessed, mBERT emerges as a computationally efficient option due to its multilingual efficacy, while RoBERTa demonstrates impressive accuracy with fine-tuning on a Tamil-specific corpus. BERT Base exhibits solid performance, albeit with higher computational demands, and BERT Large showcases enhanced accuracy at the cost of increased resource requirements. DistilBERT presents a memory-efficient alternative, maintaining reasonable performance with a smaller model size. Nonetheless, all models face challenges inherent in processing Tamil YouTube comments, such as code-mixing and informal language usage. This comparative analysis not only aids in selecting the most suitable BERT model for Tamil language content moderation but also sheds light on the broader landscape of offensive language detection in multilingual contexts. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {BERT models; Multilingual natural language processing; Offensive language detection},
	keywords = {Formal languages; Linguistics; Modeling languages; BERT model; Language detection; Language processing; Multilingual natural language processing; Natural languages; Offensive language detection; Offensive languages; Performance; Tamil language; YouTube; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Computing and Machine Learning, CML 2024; Conference date: 29 April 2024 through 30 April 2024; Conference code: 322069}
}

@ARTICLE{Patel2025,
	author = {Patel, Dharil and Pramanik, Pijush Kanti Dutta and Suryawanshi, Chaitanya and Pareek, Preksha},
	title = {Detecting toxic comments on social media: an extensive evaluation of machine learning techniques},
	year = {2025},
	journal = {Journal of Computational Social Science},
	volume = {8},
	number = {1},
	doi = {10.1007/s42001-024-00349-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213238166&doi=10.1007%2fs42001-024-00349-5&partnerID=40&md5=125978f1ab5092b117e5c07daf86d1bc},
	affiliations = {Department of Artificial Intelligence & Machine Learning, Symbiosis Institute of Technology, Maharashtra, Pune, India; School of Computer Applications and Technology, Galgotias University, Uttar Pradesh, Greater Noida, India; Department of Computer Engineering, Thakur College of Engineering and Technology, Maharashtra, Mumbai, India},
	abstract = {The prevalence of toxic comments on social networking sites poses a significant threat to the freedom of speech and the psychological well-being of online users. To address this challenge, researchers have turned to machine learning algorithms as a means of categorizing and identifying toxic contents. This study presents a comprehensive comparison of multiple machine learning techniques for predicting toxic posts on a social media platform. The Jigsaw toxic comment classification dataset was used to test the performance of nine different machine learning models. Various evaluation metrics, including accuracy, precision, recall, and F1-score, were employed to assess the models' effectiveness. Additionally, hyperparameter tuning was performed for each algorithm, and the outcomes were compared to determine the optimal technique, while examining the effects of hyperparameter variations. The results demonstrate that the naive Bayes classifier is the most accurate among the proposed models, achieving an accuracy of 97.30% and a run-time complexity of 0.06. The second-highest accuracy score of 97.31% was recorded for the XGBoost algorithm, with a run-time complexity of 41.06. The findings of this study have important implications for the development of efficient online hate speech identification systems. By leveraging the insights gained from this comparative analysis, researchers and practitioners can design more effective strategies for managing and mitigating the prevalence of toxic comments in online communities, ultimately fostering a safer and more inclusive digital environment. © The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Comparative analysis; Machine learning; Natural language processing; Social media; Text classification; Toxic comments},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Raut2024445,
	author = {Raut, Rohan and Spezzano, Francesca},
	title = {Enhancing hate speech detection with user characteristics},
	year = {2024},
	journal = {International Journal of Data Science and Analytics},
	volume = {18},
	number = {4},
	pages = {445 – 455},
	doi = {10.1007/s41060-023-00437-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168080250&doi=10.1007%2fs41060-023-00437-1&partnerID=40&md5=997ac7aa1033dc5742bc1d2408d3c7ae},
	affiliations = {Boise State University, Boise, ID, United States},
	abstract = {Social media provide users with a powerful platform to share their ideas. Using one’s right to expression to incite hate toward a particular group of people is inappropriate. However, hate speech is pervasive in our society. Spreading hate through online social networks like Facebook, Twitter, Tiktok, and Instagram is commonplace in today’s milieu. One such case is the unprecedented COVID-19 pandemic, which engendered anti-Asian hate. In the current literature, there is limited study on using user features in conjunction with textual features to detect hate speech. In this paper, we propose to combine tweet textual features with a variety of user features to improve the state-of-the-art hate speech detection techniques. The user feature we propose consists of demographic, behavioral-based, network-based, emotions, personality, readability, and writing style. To test our approach, we used four different English datasets gathered from Twitter and available in the public domain. Our results show that combining tweet textual features with the proposed user features improves hate speech detection up to +0.32 in F1 score and beats previously proposed approaches that use a limited number of user features. The analysis of the most important features confirms that hateful tweets or their authors express more negative emotions and use more swear words. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2023.},
	author_keywords = {Hate speech; Tweet text classification; User information and behavior},
	keywords = {Behavioral research; Classification (of information); COVID-19; Feature extraction; Speech recognition; Text processing; Hate speech; Social media; Speech detection; Text classification; Textual features; Tweet text classification; User behaviors; User characteristics; User feature; User information; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Fetahi2024190,
	author = {Fetahi, Endrit and Hamiti, Mentor and Susuri, Arsim and Ajdari, Jaumin and Zenuni, Xhemal},
	title = {AI-Based Hate Speech Detection in Albanian Social Media: New Dataset and Mobile Web Application Integration},
	year = {2024},
	journal = {International Journal of Interactive Mobile Technologies },
	volume = {18},
	number = {24},
	pages = {190 – 208},
	doi = {10.3991/ijim.v18i24.50851},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213401498&doi=10.3991%2fijim.v18i24.50851&partnerID=40&md5=555dbaed969988fcaf38170f899a1ea2},
	affiliations = {South East European University, Tetovo, North Macedonia; University of Prizren, Prizren, Kosovo},
	abstract = {This paper aims to advance AI-based hate speech (HS) detection in the Albanian language, which is resource-limited in natural language processing (NLP). Addressing the challenge of limited data, we developed a human-annotated dataset of over 11,000 comments, carefully curated from various Albanian social media platforms, containing a substantial number of HS instances. The dataset was annotated using a detailed two-layer taxonomy to capture the complex dimensions of HS. To ensure high-quality annotations, three expert annotators applied a majority voting system, achieving a substantial Fleiss’s kappa coefficient of 0.62, underscoring the reliability and consistency of the annotations. We conducted a comparative analysis of several machine learning (ML) algorithms, including support vector machine (SVM), Naïve Bayes (NB), XGBoost, and random forest (RF), paired with various text vectorisation techniques and pre-processing methods. In binary classification, the NB model with term frequencyinverse document frequency (TF-IDF) vectorization achieved the highest performance, with an F1 score of 0.80. For multiclass classification, XGBoost outperformed other models, achieving an F1 score of 0.77. Interestingly, our experiments revealed that pre-processing steps generally reduced model performance, suggesting that raw text inputs work better for the Albanian language. Through error analysis using local interpretable model-agnostic explanations (LIME), we identified key challenges, such as polysemy and irony, which contributed to misclassifications. To demonstrate the practical applicability of our work, we developed a user-friendly mobile web application based on the best-performing model, providing realtime HS detection with the potential for integration into social media platforms. © 2024 by the authors of this article.},
	author_keywords = {Albanian; hate speech (HS) detection; machine learning (ML); social media networks; web platform},
	keywords = {Data integration; Gluing; Natural language processing systems; Support vector machines; Taxonomies; Voting machines; Albanian languages; Albanians; Hate speech  detection; Machine learning; Machine-learning; Mobile web applications; Social media networks; Social media platforms; Speech detection; Web platform; Decision trees},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Trivedi2025171,
	author = {Trivedi, Shivani and Rastogi, Sugandh and Agrawal, Sneha and sharma, Ravish},
	title = {Empowering Hate Speech Detection: A Comparative Exploration of Deep Learning Models},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2267 CCIS},
	pages = {171 – 183},
	doi = {10.1007/978-3-031-75164-6_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210559176&doi=10.1007%2f978-3-031-75164-6_13&partnerID=40&md5=adc5cb4094e974ebbc629f1ca740467b},
	affiliations = {Department of Computer Science and Engineering, ABES Engineering College, Ghaziabad, India},
	abstract = {Hate Speech Detection, employing Natural Language Processing (NLP) and Machine Learning techniques, serves as a crucial tool for automatically identifying and flagging discriminatory language, hatred, or other protected characteristics within the vast landscape of social media. The escalating volume of social media posts, generated every second, has led to a surge in hateful and disrespectful comments. The imperative to automatically detect such content arises due to the time and resource intensity involved in creating high-quality human-labeled datasets. This study meticulously selects a dataset ensuring its inclusion of a substantial amount of hate speech instances across diverse languages, capturing the nuanced nature of online discourse. To enhance model performance, each model, including BERT, GPT, and LSTM, undergoes fine-tuning on this dataset, incorporating personalized adjustments based on hyperparameters and preprocessing strategies. The comparative analysis yields insightful findings on the effectiveness of BERT, GPT, and LSTM models in Hate Speech Detection. Notably, this research advances beyond the previous abstract, acknowledging the diverse linguistic landscape by utilizing data generated from social media in various languages. The study contributes valuable insights to intellectuals and researchers, emphasizing the deployment of state-of-the-art techniques in real-world applications across linguistic boundaries. This paper underscores the importance of a nuanced approach in model selection for different Hate Speech Detection tasks, recognizing the challenges posed by diverse languages. Moreover, it highlights the necessity of research-centric innovation in addressing the critical issue of hate speech across multilingual social media platforms. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Bidirectional encoder representations from transformers (BERT); Generative pre-trained transformer (GPT); long-short-term-memory (LSTM); machine learning; natural language processing (NLP)},
	keywords = {Adversarial machine learning; Contrastive Learning; Linguistics; Natural language processing systems; Spatio-temporal data; Speech enhancement; Speech recognition; Bidirectional encoder representation from transformer; Generative pre-trained transformer; Language processing; Long-short-term-memory; Machine-learning; Natural language processing; Natural languages; Short term memory; Social media; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Artificial Intelligence and Speech Technology, AIST 2023; Conference date: 26 December 2023 through 27 December 2023; Conference code: 323319}
}

@ARTICLE{Ying2025146,
	author = {Ying, Hao and Ou, Qiongrong and Fan, Chengjun and Mei, Lin and Zhang, Shuyu and Xu, Xu},
	title = {Domain Adaptation for Chinese Offensive Language Detection},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15362 LNAI},
	pages = {146 – 158},
	doi = {10.1007/978-981-97-9440-9_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210095038&doi=10.1007%2f978-981-97-9440-9_12&partnerID=40&md5=b7527e3f9a0e8b4d3bbcf17a01396960},
	affiliations = {State Key Laboratory of Photovoltaic Science and Technology, Institute for Electric Light Sources, School of Information Science and Technology, Fudan University, Shanghai, 200433, China; Administrative Center for the DTH Service in China, Beijing, 100866, China; Donghai Laboratory, Zhoushan, 316021, China},
	abstract = {Accurate detection of offensive language is crucial for maintaining harmony on social media platforms. However, the lack of well-annotated datasets makes it challenging to classify semantically Chinese offensive language using deep learning. To this end, we have studied how to transfer rich corpus knowledge from other languages to Chinese, exploring the impact of data from different cultural backgrounds on the detection of offensive language in Chinese under various conditions. We found that when enough Chinese corpus and labeling information are available, domain adaptation can prevent negative transfers caused by cultural differences while utilizing rich corpus knowledge to enhance detection performance. In a zero-shot learning environment, domain adaptation allows the effective transfer of corpus knowledge from specific languages to Chinese language detection tasks based on the model’s linguistic background, thereby enhancing the performance of monolingual models in cross-lingual tasks. Our research indicates that domain adaptation plays a positive role in cross-cultural transfer detection. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Domain Adaptation; Offensive Language Detection; Transfer Learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Domain Knowledge; Federated learning; Transfer learning; Annotated datasets; Chinese corpus; Condition; Cultural backgrounds; Domain adaptation; Language detection; Offensive language detection; Offensive languages; Social media platforms; Transfer learning; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024; Conference date: 1 November 2024 through 3 November 2024; Conference code: 322629}
}

@ARTICLE{Luu202456763,
	author = {Luu, Son T. and Van Nguyen, Kiet and Nguyen, Ngan Luu-Thuy},
	title = {An approach of data augmentation to improve the performance of BERTology models for Vietnamese hate speech detection},
	year = {2024},
	journal = {Multimedia Tools and Applications},
	volume = {83},
	number = {19},
	pages = {56763 – 56783},
	doi = {10.1007/s11042-023-16968-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179726891&doi=10.1007%2fs11042-023-16968-5&partnerID=40&md5=071210f1c22a423b8f93aa2d70b5d91f},
	affiliations = {Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {Hate speech detection on social media networks is the classification task that automatically detects harmful comments from users and prevents the appearance of those toxic comments on social sites. The profit of the hate speech detection task is preventing harassment and toxicity content on the social networks site to protect the users that join the social media networks. Many attempts to solve the problem of hate speech detection in Vietnamese social texts have been proposed and achieved optimal results. However, with the robust ability of BERTology, the advantage of popular text pre-processing methods is not as significant as traditional models. In this paper, we investigate the effect of text pre-processing methods to the BERTology models on the two Vietnamese hate speech detection datasets - the ViHSD and the UIT-ViCTSD. The results show that the popular text pre-processing methods are not efficient in the performance of the classification models. Besides, we propose a new approach for the EDA data augmentation that has more benefit for the BERTology models when training with the imbalance dataset. Moreover, we also implement the Focal loss for BERTology models to investigate the efficiency in imbalanced classification. From the empirical results, our proposed EDA method is good for both multiclass and binary classification, while the Focal loss shows its robustness for only the multiclass classification when working with imbalanced data. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.},
	author_keywords = {Bertology; Data augmentation; Hate speech detection; Imbalance data; Machine learning; Text classification; Text pre-processing},
	keywords = {Classification (of information); Data handling; Social networking (online); Speech recognition; Text processing; Bertology; Data augmentation; Hate speech detection; Imbalance datum; Machine-learning; Pre-processing; Speech detection; Text classification; Text pre-processing; Vietnamese; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Khanduja2024,
	author = {Khanduja, Namit and Kumar, Nishant and Chauhan, Arun},
	title = {Telugu language hate speech detection using deep learning transformer models: Corpus generation and evaluation},
	year = {2024},
	journal = {Systems and Soft Computing},
	volume = {6},
	doi = {10.1016/j.sasc.2024.200112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197068383&doi=10.1016%2fj.sasc.2024.200112&partnerID=40&md5=947688726da5ccef0211a7fedc59c7f5},
	affiliations = {Department of Computer Science & Engineering, Faculty of Engineering & Technology, Gurukula Kangri Deemed to be University, Uttarakhand, Haridwar, India; Department of Computer Science & Engineering, Graphic Era Deemed to be University, Uttarakhand, Dehradun, India},
	abstract = {In today's digital era, social media has become a new tool for communication and sharing information, with the availability of high-speed internet it tends to reach the masses much faster. Lack of regulations and ethics have made advancement in the proliferation of abusive language and hate speech has become a growing concern on social media platforms in the form of posts, replies, and comments towards individuals, groups, religions, and communities. However, the process of classification of hate speech manually on online platforms is cumbersome and impractical due to the excessive amount of data being generated. Therefore, it is crucial to automatically filter online content to identify and eliminate hate speech from social media. Widely spoken resource-rich languages like English have driven the research and achieved the desired result due to the accessibility of large corpora, annotated datasets, and tools. Resource-constrained languages are not able to achieve the benefits of advancement due to a lack of data corpus and annotated datasets. India has diverse languages that change with demographics and languages that have limited data availability and semantic differences. Telugu is one of the low-resource Dravidian languages spoken in the southern part of India. In this paper, we present a monolingual Telugu corpus consisting of tweets posted on Twitter annotated with hate and non-hate labels and experiments to provide a comparison of state-of-the-art fine-tuned deep learning models (mBERT, DistilBERT, IndicBERT, NLLB, Muril, RNN+LSTM, XLM-RoBERTa, and Indic-Bart). Through transfer learning and hyperparameter tuning, the models are compared for their effectiveness in classifying hate speech in Telugu text. The fine-tuned mBERT model outperformed all other fine-tuned models achieving an accuracy of 98.2. The authors also propose a deployment model for social media accounts. © 2024},
	author_keywords = {Deep learning; Hate speech; Low-resource languages; NLP; Offensive text; Transformers},
	keywords = {Large datasets; Learning systems; Long short-term memory; Social networking (online); Speech communication; Speech recognition; Annotated datasets; Deep learning; Digital era; Hate speech; Low resource languages; Offensive text; Social media; Speech detection; Transformer; Transformer modeling; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mu2024,
	author = {Mu, Yufei and Yang, Jin and Li, Tianrui and Li, Siyu and Liang, Weiheng},
	title = {HA-GCEN: Hyperedge-abundant graph convolutional enhanced network for hate speech detection},
	year = {2024},
	journal = {Knowledge-Based Systems},
	volume = {300},
	doi = {10.1016/j.knosys.2024.112166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196975365&doi=10.1016%2fj.knosys.2024.112166&partnerID=40&md5=bfcebeb304e439b826c9e67df914298b},
	affiliations = {School of Cyber Science and Engineering, Sichuan University, Chengdu, 610207, China; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, 611756, China},
	abstract = {The proliferation of online social networks (OSNs) has led to the rampant spread of hate speech. However, traditional detection methods often struggle to effectively detect various forms of hate speech with satisfactory performance, primarily because these methods typically rely on graph-based models that tend to focus on pairwise relationships, thus failing to fully exploit the contextual and user-specific information that could unveil more subtle forms of hate speech. However, establishing a complete graph inevitably introduces considerable computational overhead and redundant information. To overcome these limitations, this study introduces a hyperedge-abundant graph convolutional enhanced network (HA-GCEN) learning framework for hate speech detection (HSD) in OSNs. The proposed hypergraph construction method with a hypergraph convolutional enhanced network primarily consists of three content-, relation-, and semanteme-hyperedge components. These components were designed to enhance context sensitivity, to comprehensively improve the understanding of group relationships and detect latent hate speech. Furthermore, the HA-GCEN was carefully designed to extract high-level correlations from the constructed hypergraph through hypergraph convolutional layers. The efficiency of the proposed method was validated on two benchmark datasets, SemEval2019 task 5 and FUNC, achieving significant improvements over state-of-the-art methods with increases of 5.74% and 2.56% in the F1 score, 5.43% and 1.47% in precision, and 5.98% and 3.47% in recall, respectively. These results attest to HA-GCEN's advanced feature mining and learning capabilities, demonstrating its potential for more effective HSD within OSNs. © 2024 Elsevier B.V.},
	author_keywords = {Graph neural networks; Hate speech detection; Hypergraph; Online social networks},
	keywords = {Convolution; Graphic methods; Social networking (online); Speech recognition; Complete graphs; Detection methods; Graph neural networks; Graph-based models; Hate speech detection; Hyper graph; Hyperedges; Performance; Specific information; Speech detection; Graph neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kakati2024,
	author = {Kakati, Pallabi and Dandotiya, Devendra},
	title = {Automatic detection of hate speech in code-mixed Indian languages in twitter social media interaction using DConvBLSTM-MuRIL ensemble method},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01264-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194398122&doi=10.1007%2fs13278-024-01264-3&partnerID=40&md5=f28f1febafd32edc0470202c0a39a31b},
	affiliations = {Department of Electronics and Communication Engineering, Presidency University, Karnataka, Bangalore, 560064, India; Department of Mechanical Engineering, Presidency University, Karnataka, Bangalore, India; Innovation and Translational Research Hub (iTRH), Presidency University, Karnataka, Bangalore, 560064, India},
	abstract = {Social media platforms have gained immense popularity in recent years and are used for various activities such as marketing, news-sharing, and celebrating achievements. However, they are also notorious for spreading hateful and discriminatory content, which can cause harm to individuals and communities. Therefore, it is crucial to detect and remove such content from social media platforms as soon as possible. Although research related to the detection of hate speech and inflammatory content is increasing, studies focused on code-mixed Indian languages are limited. Hence, in this work, we have conducted a comprehensive study, where we have compared the effectiveness of various neural networks, and transformer-based techniques for the detection of hate and objectionable language in social media tweets in Hinglish, Tamil written in English, and Malayalam written in English, to propose the best-performing ensemble model, named as DConvBLSTM-MuRIL. To carry out our experiments, we have created our datasets for the three languages under study and compared the results with already existing datasets. Our proposed weighted ensemble framework outperformed the existing models, achieving better-weighted F1-scores and better accuracy for all the three languages under consideration. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024.},
	author_keywords = {DConvBLSTM; Ensemble; Hate speech detection; Multiclass classification; MuRIL},
	keywords = {Codes (symbols); Speech recognition; Automatic Detection; DConvBLSTM; Ensemble; Hate speech detection; Indian languages; Multi-class classification; MuRIL; Social media; Social media platforms; Speech detection; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Poorani2024,
	author = {Poorani, S. and Valantina, G. Mary},
	title = {Identification of hate speech from social media using GoogleNet classifier in comparison with KNN classifier},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212874400&doi=10.1109%2fICCCNT61001.2024.10724024&partnerID=40&md5=0201346d4de6460ed18b371d0503de5e},
	affiliations = {Dept of CSE Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Chennai, India},
	abstract = {The goal of this project is to use Innovation's ML classifiers to filter out hate speech on social media. The two most recommended and widely used methods for understanding real-time datasets are Google Net Classifier and K Nearest Neighbor. To predict hate speech on social media, we use Google Net & K-Nearest Neighbor with separate training and testing sets. On average, the test measures G power at about 85%. Google Net has a greater accuracy (91.9520%) This difference is significantly different when compared to the k closest neighbors (90.7700%) (p=0.001; p<0.05). Google Net is more accurate than K-Nearest Neighbor when tested side by side. © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; Hate Speech; K-Nearest Neighbor; Social Media},
	keywords = {Google+; Hate speech; K-near neighbor; Nearest-neighbour; Power; Real-time dataset; Social media; Testing sets; Training and testing; Training sets; k-nearest neighbors},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@CONFERENCE{Sheth2024626,
	author = {Sheth, Paras and Moraffah, Raha and Kumarage, Tharindu S. and Chadha, Aman and Liu, Huan},
	title = {Causality Guided Disentanglement for Cross-Platform Hate Speech Detection},
	year = {2024},
	journal = {WSDM 2024 - Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
	pages = {626 – 635},
	doi = {10.1145/3616855.3635771},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189049435&doi=10.1145%2f3616855.3635771&partnerID=40&md5=74b013c810a8df7de42ea2c3c01f7250},
	affiliations = {Arizona State University, Tempe, AZ, United States; Amazon. Inc, Sunnyvale, CA, United States},
	abstract = {espite their value in promoting open discourse, social media plat-forms are often exploited to spread harmful content. Current deep learning and natural language processing models used for detect-ing this harmful content rely on domain-specific terms affecting their ability to adapt to generalizable hate speech detection. This is because they tend to focus too narrowly on particular linguistic signals or the use of certain categories of words. Another signifi-cant challenge arises when platforms lack high-quality annotated data for training, leading to a need for cross-platform models that can adapt to different distribution shifts. Our research introduces a cross-platform hate speech detection model capable of being trained on one platform's data and generalizing to multiple unseen platforms. One way to achieve good generalizability across plat-forms is to disentangle the input representations into invariant and platform-dependent features. We also argue that learning causal relationships, which remain constant across diverse environments, can significantly aid in understanding invariant representations in hate speech. By disentangling input into platform-dependent fea-tures (useful for predicting hate targets) and platform-independent features (used to predict the presence of hate), we learn invariant representations resistant to distribution shifts. These features are then used to predict hate speech across unseen platforms. Our ex-tensive experiments across four platforms highlight our model's enhanced efficacy compared to existing state-of-The-Art methods in detecting generalized hate speech © 2024 ACM.},
	author_keywords = {causal representation learning; domain generalization; hate speech detection},
	keywords = {Forecasting; Natural language processing systems; Speech recognition; 'current; Causal representation learning; Cross-platform; Domain generalization; Generalisation; Hate speech detection; Invariant representation; Learning languages; Social media; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 17th ACM International Conference on Web Search and Data Mining, WSDM 2024; Conference date: 4 March 2024 through 8 March 2024; Conference code: 198776; All Open Access, Green Open Access}
}

@ARTICLE{Yadav2024,
	author = {Yadav, Ashok and Khan, Farrukh Aslam and Singh, Vrijendra},
	title = {A Multi-Architecture Approach for Offensive Language Identification Combining Classical Natural Language Processing and BERT-Variant Models},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {23},
	doi = {10.3390/app142311206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211815415&doi=10.3390%2fapp142311206&partnerID=40&md5=0873158e6b7c37d9aef7818243aaa7e9},
	affiliations = {Department of Information Technology, Indian Institute of Information Technology, Prayagraj, Allahabad, 211015, India; Center of Excellence in Information Assurance (CoEIA), King Saud University, Riyadh, 11653, Saudi Arabia},
	abstract = {Offensive content is a complex and multifaceted form of harmful material that targets individuals or groups. In recent years, offensive language (OL) has become increasingly harmful, as it incites violence and intolerance. The automatic identification of OL on social networks is essential to curtail the spread of harmful content. We address this problem by developing an architecture to effectively respond to and mitigate the impact of offensive content on society. In this paper, we use the Davidson dataset containing 24,783 samples of tweets and proposed three different architectures for detecting OL on social media platforms. Our proposed approach involves concatenation of features (TF-IDF, Word2Vec, sentiments, and FKRA/FRE) and a baseline machine learning model for the classification. We explore the effectiveness of different dimensions of GloVe embeddings in conjunction with deep learning models for classifying OL. We also propose an architecture that utilizes advanced transformer models such as BERT, ALBERT, and ELECTRA for pre-processing and encoding, with 1D CNN and neural network layers serving as the classification components. We achieve the highest precision, recall, and F1 score, i.e., 0.89, 0.90, and 0.90, respectively, for both the “bert encased preprocess/1 + small bert/L4H512A8/1 + neural network layers” model and the “bert encased preprocess/1 + electra small/2 + cnn” architecture. © 2024 by the authors.},
	author_keywords = {convolutional neural network (CNN); offensive language; random forest; social network; support vector machine; VADER},
	keywords = {Convolutional neural networks; Multilayer neural networks; Natural language processing systems; Support vector machines; Convolutional neural network; Language identification; Neural-networks; Offensive languages; Preprocess; Random forests; Social network; Support vectors machine; VADER; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Mnassri2024,
	author = {Mnassri, Khouloud and Farahbakhsh, Reza and Crespi, Noel},
	title = {Multilingual Hate Speech Detection: A Semi-Supervised Generative Adversarial Approach},
	year = {2024},
	journal = {Entropy},
	volume = {26},
	number = {4},
	doi = {10.3390/e26040344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191603360&doi=10.3390%2fe26040344&partnerID=40&md5=5255123bc99b84070b840a5ea5e06019},
	affiliations = {Samovar, Télécom SudParis, Institut Polytechnique de Paris, Palaiseau, 91120, France},
	abstract = {Social media platforms have surpassed cultural and linguistic boundaries, thus enabling online communication worldwide. However, the expanded use of various languages has intensified the challenge of online detection of hate speech content. Despite the release of multiple Natural Language Processing (NLP) solutions implementing cutting-edge machine learning techniques, the scarcity of data, especially labeled data, remains a considerable obstacle, which further requires the use of semisupervised approaches along with Generative Artificial Intelligence (Generative AI) techniques. This paper introduces an innovative approach, a multilingual semisupervised model combining Generative Adversarial Networks (GANs) and Pretrained Language Models (PLMs), more precisely mBERT and XLM-RoBERTa. Our approach proves its effectiveness in the detection of hate speech and offensive language in Indo-European languages (in English, German, and Hindi) when employing only 20% annotated data from the HASOC2019 dataset, thereby presenting significantly high performances in each of multilingual, zero-shot crosslingual, and monolingual training scenarios. Our study provides a robust mBERT-based semisupervised GAN model (SS-GAN-mBERT) that outperformed the XLM-RoBERTa-based model (SS-GAN-XLM) and reached an average F1 score boost of 9.23% and an accuracy increase of 5.75% over the baseline semisupervised mBERT model. © 2024 by the authors.},
	author_keywords = {GAN; hate speech; multilingual; PLMs; semisupervised; social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Maheswari2024187,
	author = {Maheswari, V. Uma and Priya, R.},
	title = {Novel Approach to Offensive Language Detection on Social Media: Tree CNN Integration with Adversarial Bi-LSTM},
	year = {2024},
	journal = {International Journal of Engineering Trends and Technology},
	volume = {72},
	number = {7},
	pages = {187 – 197},
	doi = {10.14445/22315381/IJETT-V72I7P120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199876097&doi=10.14445%2f22315381%2fIJETT-V72I7P120&partnerID=40&md5=10e787e2776436ad0b818350a698fbf5},
	affiliations = {Department of Computer Science, School of Computing Sciences, Vels Institute of Science, Technology & Advanced Studies (VISTAS), Chennai, India; Department of Computer Applications, School of Computing Sciences, Vels Institute of Science, Technology & Advanced Studies (VISTAS), Chennai, India},
	abstract = {Offensive language detection on social media platforms is a crucial task for maintaining a healthy online environment and ensuring user safety. Traditional methods often struggle to effectively capture the nuances and dynamic nature of offensive language in such diverse and rapidly evolving contexts. Our research presents a novel approach to offensive language detection on social media by integrating Tree Convolutional Neural Networks (CNN) with Adversarial Bidirectional Long Short-Term Memory (Bi-LSTM) networks. We address the challenges of imbalanced data and semantic understanding by employing the Synthetic Minority Over-sampling Technique (SMOTE) and Word2Vec for feature extraction. To enhance model interpretability and focus on relevant features, we incorporate attention mechanisms within both the Tree CNN and the Adversarial Bi-LSTM. We utilize two attention mechanisms: one for identifying repetitive patterns using an Entropy Pruning Method and another for error loss monitoring during training. This dual attention mechanism enables our model to effectively distinguish offensive from non-offensive text while also providing insights into model decisions. Experimental findings on benchmarking social media datasets show that our suggested methodology outperforms cutting-edge approaches in terms of accuracy and interpretation. Our study contributes to advancing offensive language detection techniques on social media platforms and provides a framework for developing more reliable and interpretable models for online content moderation. © 2024 Seventh Sense Research Group. All rights reserved.},
	author_keywords = {Adversarial Bi-LSTM; Attention mechanisms; Imbalanced data handling; Offensive language detection; SMOTE; Social media; Tree CNN; Word2Vec},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bora2024,
	author = {Bora, Sanjib and Baruah, Nomi and Baruah, Debajani and Barman, Swarnangka and Neog, Mandira},
	title = {Empowering Abusive Language Detection in Low-Resource Scenarios: A Dynamic LSTM-Based Abusive Content Detection with Attention Mechanism},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213044905&doi=10.1109%2fICCCNT61001.2024.10724214&partnerID=40&md5=07bd0c0cccbbf80408f32d5d65268837},
	affiliations = {Duiet, Dibrugarh University, Computer Science and Engineering, Dibrugarh, India},
	abstract = {In India, with its rich linguistic landscape, abusive social media remarks that attack individuals or communities based on protected attributes provide serious difficulty. Research in this area is hampered by the lack of digital resources for low-resource Indian languages like Assamese, which exacerbates this complexity. The goal of this research is to close this gap by creating a system that can accurately identify abusive remarks made in Assamese on social media. The experiment produced promising results by leveraging the highlighted capabilities of deep learning techniques, namely Long Short-Term Memory (LSTM) networks enhanced with attention mechanisms. The accuracy of the LSTM model was 71.97%; however, by incorporating attention processes, performance was dramatically increased to 75.22%. The results demonstrate how well attention mechanisms and deep learning techniques work together to enhance the detection of abusive comments in Assamese on web-based platforms. Particularly given the limitations of low-resource languages, this research provides important insights meant to foster a more safe online environment. © 2024 IEEE.},
	author_keywords = {Abusive comments; Assamese; Attention Mechanism; LSTM},
	keywords = {Federated learning; Abusive comment; Assamese; Attention mechanisms; Community-based; Content detection; Individual-based; Language detection; Learning techniques; Short term memory; Social media; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@CONFERENCE{Duong2024386,
	author = {Duong, Phuc H. and Nguyen, Truc T. and Nguyen, Hien T.},
	title = {Fusion Network for Multimodal Hate Speech Detection},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {386 – 390},
	doi = {10.1145/3654522.3654562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200497987&doi=10.1145%2f3654522.3654562&partnerID=40&md5=78f883cf2d1b93f424479da96964f885},
	affiliations = {Artificial Intelligence Laboratory, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Viet Nam; Center for Applied Information Technology, Ton Duc Thang University, Ho Chi Minh City, Viet Nam; Department of Economic Mathematics, Banking University of Ho Chi Minh City, Ho Chi Minh City, Viet Nam},
	abstract = {In an era where social network platforms are increasingly plagued by harmful content, effective detection methods are crucial for maintaining healthy online communities. In this paper, we introduce a multimodal approach to hate speech detection, leveraging a fusion network that integrates text and image analysis. We mainly use state-of-the-art pre-trained language models like DistilBERT, MPNet, and image processing models such as ResNet and EfficientNetV2. These models facilitate a nuanced understanding of both intra- and inter-modality content dynamics. Additionally, we compare the effectiveness of context-free word embedding models like GloVe and fastText with contextual language models. Extensive experiments on the MMHS150K dataset, a popular and specialized dataset for multimodal hate speech analysis, demonstrate competitive performance compared with existing multimodal hate speech detection methods. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Deep learning; Hate speech detection; Multimodal},
	keywords = {Computational linguistics; Deep learning; Image processing; Modal analysis; Deep learning; Detection methods; Hate speech detection; Language model; Multi-modal; Multi-modal approach; Network platforms; On-line communities; Speech detection; Text analysis; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 9th International Conference on Intelligent Information Technology, ICIIT 2024; Conference date: 23 February 2024 through 25 February 2024; Conference code: 201377}
}

@ARTICLE{Asiri2024,
	author = {Asiri, Afefa and Saleh, Mostafa},
	title = {SOD: A Corpus for Saudi Offensive Language Detection Classification},
	year = {2024},
	journal = {Computers},
	volume = {13},
	number = {8},
	doi = {10.3390/computers13080211},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202613944&doi=10.3390%2fcomputers13080211&partnerID=40&md5=7ecdbb77a64dd41b25d269ddbe95cdb7},
	affiliations = {Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia},
	abstract = {Social media platforms like X (formerly known as Twitter) are integral to modern communication, enabling the sharing of news, emotions, and ideas. However, they also facilitate the spread of harmful content, and manual moderation of these platforms is impractical. Automated moderation tools, predominantly developed for English, are insufficient for addressing online offensive language in Arabic, a language rich in dialects and informally used on social media. This gap underscores the need for dedicated, dialect-specific resources. This study introduces the Saudi Offensive Dialectal dataset (SOD), consisting of over 24,000 tweets annotated across three levels: offensive or non-offensive, with offensive tweets further categorized as general insults, hate speech, or sarcasm. A deeper analysis of hate speech identifies subtypes related to sports, religion, politics, race, and violence. A comprehensive descriptive analysis of the SOD is also provided to offer deeper insights into its composition. Using machine learning, traditional deep learning, and transformer-based deep learning models, particularly AraBERT, our research achieves a significant F1-Score of 87% in identifying offensive language. This score improves to 91% with data augmentation techniques addressing dataset imbalances. These results, which surpass many existing studies, demonstrate that a specialized dialectal dataset enhances detection efficacy compared to mixed-language datasets. © 2024 by the authors.},
	author_keywords = {Arabic language processing; computational linguistics; data annotation; data augmentation; deep learning; dialect analysis; hate speech detection; machine learning; natural language processing (NLP); offensive detection; Saudi dialect; text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Nandi202477733,
	author = {Nandi, Arpan and Sarkar, Kamal and Mallick, Arjun and De, Arkadeep},
	title = {Combining multiple pre-trained models for hate speech detection in Bengali, Marathi, and Hindi},
	year = {2024},
	journal = {Multimedia Tools and Applications},
	volume = {83},
	number = {32},
	pages = {77733 – 77757},
	doi = {10.1007/s11042-023-17934-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186256794&doi=10.1007%2fs11042-023-17934-x&partnerID=40&md5=7b0ec11a5404de09eb235816b46ef6ea},
	affiliations = {Department of Computer Science and Engineering, Jadavpur University, Raja S C Mallick Road, West Bengal, Kolkata, 700032, India},
	abstract = {With the increasing practice of using regional languages in social media platforms, hate speech detection in regional languages has received the attention of researchers. In India, hundreds of languages are spoken in various forms, which are dependent on their geography, culture, etc. Recently the number of active internet users has been rapidly increasing in India, and therefore social media has penetrated the common Indian population. Though the need for proper detection and timely removal of abusive or offensive texts has increased, well-organized and labeled data for Indian languages are scarce. Almost all the regional languages in India are low-resource languages. Hence, the objective of this study is to develop an approach that will learn from relatively small volumes of Indian language data and provide state-of-the-art results. A fusion of features extracted from a fined-tuned multilingual BERT (Bidirectional Encoder Representations from Transformers) and a fine-tuned Indic BERT has been proposed in this study. Since the BERT models that we have used for this work are pre-trained using a large volume of texts in multiple Indian languages, transfer learning solves the problem of low training data volume, and this makes the proposed model more generic. Three datasets for three different Indian languages namely, Bengali, Marathi, and Hindi have been considered in this study to evaluate the proposed approach. The proposed model achieved a weighted F1 score of 0.923, 0.815, and 0.924 for the Bengali, Hindi, and Marathi datasets respectively. In the Bengali and Marathi datasets, the obtained results are better than the existing best results. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Abusive comments; Bengali; Deep learning; Ensemble; Hate speech detection; Hindi; Indian languages; Marathi},
	keywords = {Deep learning; Large datasets; Social networking (online); Abusive comment; Bengalis; Deep learning; Ensemble; Hate speech detection; Hindi; Indian languages; Marathi; Social media platforms; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Sharma2024,
	author = {Sharma, Deepawali and Singh, Vivek Kumar and Gupta, Vedika},
	title = {TABHATE: A Target-based hate speech detection dataset in Hindi},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01355-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204499979&doi=10.1007%2fs13278-024-01355-1&partnerID=40&md5=c385ab981ce8a553120410457c1e4d46},
	affiliations = {Department of Computer Science, Banaras Hindu University, Varanasi, India; School of Computer Science Engineering and Technology (SCSET), Bennett University, Greater Noida, 201310, India; Department of Computer Science, University of Delhi, Delhi, 110007, India; Jindal Global Business School, O.P. Jindal Global University, Haryana, Sonipat, 131001, India},
	abstract = {Social media has become a platform for expressing opinions and emotions, but some people also use it to spread hate, targeting individuals, groups, communities, or countries. Therefore, there is a need to identify such content and take corrective action. During the last few years, several techniques have been developed to automatically detect and identify hate speech, offensive and abusive content from social media platforms. However, majority of the studies focused on hate speech detection in English language texts only. The non-availability of suitable datasets is a major reason for lack of research work in other languages. Hindi is one such widely spoken language where such datasets are not available. This work attempts to bridge this research gap by presenting a curated and annotated dataset for target-based hate speech (TABHATE) in the Hindi language. The suitability of the dataset is explored by applying some standard deep learning and transformer-based models for the task of hate speech detection. The experimental results obtained show that the dataset can be used for experimental work on hate speech detection of Hindi language texts. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024.},
	author_keywords = {Deep learning; Hate speech; Hate speech corpus; Hate speech dataset; Hindi language},
	keywords = {Community OR; Corrective actions; Deep learning; Hate speech; Hate speech corpus; Hate speech dataset; Hindi language; Social media; Speech corpora; Speech detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Miranda-Pina2024276,
	author = {Miranda-Pina, Grisel and Alejo, Roberto and Rendon-Lara, Erendira and Garcia, Vicente},
	title = {Detection of violent speech against women in Mexican tweets using an active learning approach},
	year = {2024},
	journal = {IEEE Latin America Transactions},
	volume = {22},
	number = {4},
	pages = {276 – 285},
	doi = {10.1109/TLA.2024.10473002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188243145&doi=10.1109%2fTLA.2024.10473002&partnerID=40&md5=b190b99694224124b9e6c9044228cb5d},
	affiliations = {Division of Postgraduate Studies and Research, National Institute of Technology of Mexico (TecNM) Campus Toluca, Metepec, Estado de Mexico, Mexico; Departamento de Ingeniería Eléctrica y Computación, Universidad Autonóma de Ciudad Juárez. Juarez, Chihuahua, Mexico},
	abstract = {In Latin American and Caribbean States the verbal violence against women on social networks, such as Twitter, is a serious threat that has been addressed through the implementation of social norms, public policies, and social movements. Nevertheless, a challenge is the effective and automatic real-time detection of violent tweets. In this sense, traditional machine learning algorithms have been proposed to tackle social issues where the training process is performed in a static manner. However, considering that Twitter is a dynamic environment where a vast of tweets are generated each second, it requires powerful machine learning algorithms that could exploit this pool of unlabeled data to be incorporated into the model through continuous updates. This paper explores an active learning method based on uncertainty sampling, which identifies the most confusing tweets to be labeled by an expert in real-time. This focused selection prioritizes which data can be used to train a multilayer perceptron that can achieve a better performance with fewer training samples. Experimental results show that including new samples yields promising results, increasing the AUC from 0.8712 to 0.8833.  © 2003-2012 IEEE.},
	author_keywords = {Active learning; MLP; Speech violence detection; Twitter, Mexican Spanish Language; Violence against women},
	keywords = {Learning algorithms; Machine learning; Speech recognition; Active Learning; Latin americans; Learning approach; Machine learning algorithms; MLP; Spanish language; Speech violence detection; Twitter, mexican spanish language; Violence against woman; Violence detections; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{da Silva2024,
	author = {da Silva, Félix Leonel V. and Cerri, Artur and Corrêa, Ulisses B. and de Freitas, Larissa A.},
	title = {The Impact of Data Augmentation on the Hate Speech Detection in Portuguese Language},
	year = {2024},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200502518&partnerID=40&md5=65f5e5175e8c0c5ca0a71515dfde62a3},
	affiliations = {CDTEC, Universidade Federal de Pelotas, 96010-610, Brazil},
	abstract = {Online communities allow users to establish a web presence, manage their identities, and stay connected with others. The internet has facilitated global outreach with just a click on the World Wide Web. However, the current landscape of online social media platforms are marred by various issues, with hate speech prominently taking center stage. Hate speech is characterized by hostile and malicious language driven by prejudice, targeting individuals or groups based on their innate, natural, or perceived characteristics. Detecting such speech is crucial for maintaining a safe online environment. This study examines the impact of dataset regularization techniques on the performance of BERTimbau-based models when applied to four Portuguese hate speech datasets: Fortuna et al. (2019), OFFCOMBR-2, ToLD-BR, and Hate-BR. Four Data Augmentation techniques are evaluated: Oversampling, Undersampling, Text Augmentation, and Synonym Replacement. Our experiments revealed that, apart from the Fortuna et al. (2019) dataset, the Data Augmentation techniques did not significantly enhance the performance of hate speech detection tasks. Copyright © 2024 by the authors.},
	keywords = {Speech recognition; 'current; Augmentation techniques; Data augmentation; On-line communities; Online social medias; Performance; Portuguese languages; Social media platforms; Speech detection; Web presence; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 37th International Florida Artificial Intelligence Research Society Conference, FLAIRS 2024; Conference date: 19 May 2024 through 21 May 2024; Conference code: 201354}
}

@ARTICLE{Mednini2024486,
	author = {Mednini, Latifa and Noubigh, Zouhaira and Turki, Mouna Damak},
	title = {Natural Language Processing for Detecting Brand Hate Speech},
	year = {2024},
	journal = {Journal of Telecommunications and the Digital Economy},
	volume = {12},
	number = {1},
	pages = {486 – 509},
	doi = {10.18080/jtde.v12n1.859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189340409&doi=10.18080%2fjtde.v12n1.859&partnerID=40&md5=b0278a9c94ceaa735c4ef411a5a9a559},
	affiliations = {Technology, Science, AI & Automation Laboratory, Paris, France; IHEC, Sfax, Tunisia},
	abstract = {Brand hate is a complex feeling that is not easy for companies to recognize. Mednini and Turki (2022) have confirmed that the hate can originate from genuine brand haters or an employee who works with competitors, to spread negative word-of-mouth in communities. That is why it is important to detect this emotion. This study aims to identify brand hate speech based on NLP techniques to detect consumer hate sentiment using a chatbot. We present a methodology for fine-tuning the GPT 2 language model for sentiment analysis through text classification. Experiments are conducted on datasets in three languages — Arabic, French, and English — within the context of consumer consumption. The model is retrained on labelled data to effectively identify brand hate sentiment. Furthermore, we evaluate our chatbot by conducting semi-structured interviews with diverse consumers. The experimental results demonstrate a significant improvement in sentiment analysis performance, highlighting increased accuracy when compared to other models and baseline approaches. We achieved an accuracy rate of 0.98 in the training set and 0.84 in the testing set, showcasing the utility of using GPT-2 in this context. This research contributes to the capability of managers to promptly identify brand hate speech, and proactively avert potential brand crises. © 2024 Telecommunications Association Inc.. All rights reserved.},
	author_keywords = {AI; Brand hate; GPT2; NLP; Sentiments analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Gandhi2024,
	author = {Gandhi, Ankita and Ahir, Param and Adhvaryu, Kinjal and Shah, Pooja and Lohiya, Ritika and Cambria, Erik and Poria, Soujanya and Hussain, Amir},
	title = {Hate speech detection: A comprehensive review of recent works},
	year = {2024},
	journal = {Expert Systems},
	volume = {41},
	number = {8},
	doi = {10.1111/exsy.13562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186472657&doi=10.1111%2fexsy.13562&partnerID=40&md5=da6c750919b15476d55fecf60531676f},
	affiliations = {School of Cyber Security and Digital Forensic, National Forensic Sciences University, Gujarat, Ganhinagar, India; Computer Engineering, Shankarsinh Vaghela Bapu Institute of Technology, Gujarat, Ganhinagar, India; School of Technology, Pandit Dindayal Energy University, Gujarat, Ganhinagar, India; Faculty of Engineering, Sciences and Technology, Adani University, Gujarat, Ganhinagar, India; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; Singapore University of Technology and Design, Singapore University of Technology and Design, Singapore, Singapore; Edinburgh Napier University, Edinburgh, United Kingdom},
	abstract = {There has been surge in the usage of Internet as well as social media platforms which has led to rise in online hate speech targeted on individual or group. In the recent years, hate speech has resulted in one of the challenging problems that can unfurl at a fast pace on digital platforms leading to various issues such as prejudice, violence and even genocide. Considering the acceptance of Artificial Intelligence (AI) and Natural Language Processing (NLP) techniques in varied application domains, it would be intriguing to consider these techniques for automated hate speech detection. In literature, there have been efforts to recognize and categorize hate speech using varied Machine Learning (ML) and Deep Learning (DL) techniques. Hence, considering the need and provocations for hate speech detection we aim to present a comprehensive review that discusses fundamental taxonomy as well as recent advances in the field of online hate speech identification. There is a significant amount of literature related to the initial phases of hate speech detection. The background section provides a detailed explanation of the previous research. The subsequent section that follows is dedicated to examining the recent literature published from the year 2020 onwards. The paper presents some of the hate speech datasets considered for hate speech detection. Furthermore, the paper discusses different data modalities, namely, textual hate speech detection, multi-modal hate speech detection and multilingual hate speech detection. Apart from systematic review on hate speech detection, the paper also implement several multi-label models to compare the performance of hate speech detection by employing classic ML technique namely, Logistic Regression and DL technique namely, Long Short-Term Memory (LSTM) and a multiclass multi-label architecture. In the implemented architecture, we have derived two new elements to quantify the hatefulness and intensity of hatred to improve the results for hate speech detection using Indonesian tweet dataset. Empirical Analysis of the model reveals that the implemented approach outperforms and is able to achieve improved results for the underlying dataset. © 2024 John Wiley & Sons Ltd.},
	author_keywords = {CNN; deep learning; hate speech detection; LSTM; multi-label; multi-lingual},
	keywords = {Natural language processing systems; Speech recognition; Deep learning; Digital platforms; Hate speech detection; Internet media; Learning techniques; Multi-labels; Multi-lingual; Natural languages; Social media platforms; Speech detection; Long short-term memory},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Singhal2025184,
	author = {Singhal, Mayank and Komal and Zeeshan, Mohammad and Saini, Ishika and Nagrath, Preeti},
	title = {Hate Speech Detection Using Glove and BERT},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2267 CCIS},
	pages = {184 – 194},
	doi = {10.1007/978-3-031-75164-6_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210580803&doi=10.1007%2f978-3-031-75164-6_14&partnerID=40&md5=fcfaf0651869fb38530e7ffeb59da4d9},
	affiliations = {Department of Computer Science Engineering, Bharati Vidyapeeth’s College of Engineering, New Delhi, India},
	abstract = {The increasing prevalence of hate speech, on platforms poses a threat to inclusive communication. In our research we have utilized word embeddings to acknowledge the challenge of identifying Hate speech. For enhancing the accuracy and contextual understanding of our hate speech detection models we have incorporated both BERT (Bidirectional Encoder Representations, from Transformers) and GloVe (Global Vectors for Word Representation) embeddings. By preprocessing input and training machine learning models using these embeddings we have developed a methodology that effectively recognizes hate speech. Our experiments demonstrate the effectiveness of combining GloVe and BERT in detecting instances of hate speech. This proposed approach not outperforms techniques but also captures the intricate context in which hate speech manifests. Through this study we contribute to endeavors aimed at mitigating the impact of Hate speech on platforms. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {CountVectorizer; Decision Tree; Hate speech; Lo gistic Regression; Machine Learning; Naive Bayes; Natural Language Processing; TF-IDF},
	keywords = {Adversarial machine learning; Contrastive Learning; Decision trees; Machine learning; Natural language processing systems; Speech enhancement; Speech recognition; Countvectorizer; Embeddings; Hate speech; Language processing; Lo gistic regression; Machine-learning; Naive bayes; Natural language processing; Natural languages; TF-IDF; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Artificial Intelligence and Speech Technology, AIST 2023; Conference date: 26 December 2023 through 27 December 2023; Conference code: 323319}
}

@ARTICLE{Abdellaoui2024,
	author = {Abdellaoui, Israe and Ibrahimi, Anass and El Bouni, Mohamed Amine and Mourhir, Asmaa and Driouech, Saad and Aghzal, Mohamed},
	title = {Investigating Offensive Language Detection in a Low-Resource Setting with a Robustness Perspective},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {12},
	doi = {10.3390/bdcc8120170},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213438142&doi=10.3390%2fbdcc8120170&partnerID=40&md5=d684438ca910e28aa4929cce689feeea},
	affiliations = {School of Science and Engineering, Al Akhawayn University, Ifrane, 53000, Morocco},
	abstract = {Moroccan Darija, a dialect of Arabic, presents unique challenges for natural language processing due to its lack of standardized orthographies, frequent code switching, and status as a low-resource language. In this work, we focus on detecting offensive language in Darija, addressing these complexities. We present three key contributions that advance the field. First, we introduce a human-labeled dataset of Darija text collected from social media platforms. Second, we explore and fine-tune various language models on the created dataset. This investigation identifies a Darija RoBERTa-based model as the most effective approach, with an accuracy of 90% and F1 score of 85%. Third, we evaluate the best model beyond accuracy by assessing properties such as correctness, robustness and fairness using metamorphic testing and adversarial attacks. The results highlight potential vulnerabilities in the model’s robustness, with the model being susceptible to attacks such as inserting dots (29.4% success rate), inserting spaces (24.5%), and modifying characters in words (18.3%). Fairness assessments show that while the model is generally fair, it still exhibits bias in specific cases, with a 7% success rate for attacks targeting entities typically subject to discrimination. The key finding is that relying solely on offline metrics such as the F1 score and accuracy in evaluating machine learning systems is insufficient. For low-resource languages, the recommendation is to focus on identifying and addressing domain-specific biases and enhancing pre-trained monolingual language models with diverse and noisier data to improve their robustness and generalization capabilities in diverse linguistic scenarios. © 2024 by the authors.},
	author_keywords = {adversarial data; Darija; fairness; metamorphic testing; offensive language detection; robustness},
	keywords = {Economic and social effects; Linguistics; Machine learning; Natural language processing systems; Adversarial data; Darija; Fairness; Language detection; Language model; Low resource languages; Metamorphic testing; Offensive language detection; Offensive languages; Robustness; Adversarial machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Miao20241493,
	author = {Miao, Zhenxiong and Chen, Xingshu and Wang, Haizhou and Tang, Rui and Yang, Zhou and Huang, Tiemai and Tang, Wenyi},
	title = {Detecting Offensive Language Based on Graph Attention Networks and Fusion Features},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {1},
	pages = {1493 – 1505},
	doi = {10.1109/TCSS.2023.3250502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149859874&doi=10.1109%2fTCSS.2023.3250502&partnerID=40&md5=3df39796e14e7e56bc250fc504ed86c6},
	affiliations = {Sichuan University, School of Cyber Science and Engineering, Chengdu, 610207, China; Sichuan University, School of Cyber Science and Engineering, The Cyber Science Research Institute, Chengdu, 610207, China; China Mobile (Chengdu) Information and Telecommunication Technology Company Ltd., Chengdu, 610065, China},
	abstract = {The pervasiveness of offensive language on social networks has caused adverse effects on society, such as abusive behavior online. It is urgent to detect offensive language and curb its spread. In the popular datasets, the distribution of users and tweets is imbalanced, which limits the generalization ability of the model. In addition, existing research shows that methods with community information extracted from the social graphs effectively improve the performance of offensive language detection. However, the existing models deal with social graphs independently, which seriously affects the effectiveness of detection models. In this article, we release a new dataset with users and social relationships. To encode community information, we construct the social graphs based on the user historical behavior information and social relationships. Moreover, we propose a model based on graph attention networks (GATs) and fusion features for offensive language detection (GF-OLD). Specifically, the community information is directly captured by the GAT module, and the text embeddings are taken from the last hidden layer of bidirectional encoder representation from transformer (BERT). Attention mechanisms and position encoding are used to fuse these features. Our method outperforms baselines with the F1-score of 89.94%. The results show that our model effectively learns the potential information of social graphs and text, and user historical behavior information is more suitable for user attribute in the social graphs. © 2014 IEEE.},
	author_keywords = {Deep learning; graph attention networks (GATs); offensive language detection; social networks},
	keywords = {Behavioral research; Deep learning; Encoding (symbols); Graphic methods; Online systems; Signal encoding; Social aspects; Social networking (online); Behavioral science; Bit-error rate; Deep learning; Features extraction; Graph attention network; Language detection; Offensive language detection; Offensive languages; Social network; Social networking (online); Task analysis; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{De Oliveira20241461,
	author = {De Oliveira, Aillkeen Bezerra and Baptista, Claudio De Souza and Firmino, Anderson Almeida and De Paiva, Anselmo Cardoso},
	title = {A Large Language Model Approach to Detect Hate Speech in Political Discourse Using Multiple Language Corpora},
	year = {2024},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {1461 – 1468},
	doi = {10.1145/3605098.3635964},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197679298&doi=10.1145%2f3605098.3635964&partnerID=40&md5=c7fa15190acdc4cda0c1801f9dd2e089},
	affiliations = {Federal University of Campina Grande, Paraíba, Campina Grande, Brazil; Federal University of Maranhao, Maranhão, São Luíz, Brazil},
	abstract = {In this era of unprecedented digital connectivity and interactions, the issue of hate speech has become a focal point in societal discussions. The rise of digital communication platforms has fundamentally transformed how hate speech spreads. Online social media and messaging apps have rapidly disseminated hate speech, exacerbated by the internet's anonymity. Computational technology has emerged as a valuable tool for identifying and mitigating hate speech on social media. In this work, we employed five distinct corpora representing the English, Italian, Filipino, German, and Turkish languages. We propose employing a Large Language Model (GPT-3) enhanced with Cross-Lingual Learning to improve hate speech detection in English and Italian. Our investigation employs a strategy, namely JL/CL+, which combines two strategies: Joint Learning (JL) and Cascade Learning (CL). Even using data with lexical disparities, our findings demonstrate substantial success, yielding an F1-score of 96.58% for English and 92.05% for Italian languages. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {cross-lingual learning; hate speech; large language model; machine learning; natural language processing},
	keywords = {Computational linguistics; Digital communication systems; Learning algorithms; Learning systems; Machine learning; Natural language processing systems; Speech communication; Speech recognition; Cross-lingual; Cross-lingual learning; Hate speech; Joint learning; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 39th Annual ACM Symposium on Applied Computing, SAC 2024; Conference date: 8 April 2024 through 12 April 2024; Conference code: 200614}
}

@ARTICLE{Al Maruf2024,
	author = {Al Maruf, Abdullah and Abidin, Ahmad Jainul and Haque, Md. Mahmudul and Jiyad, Zakaria Masud and Golder, Aditi and Alubady, Raaid and Aung, Zeyar},
	title = {Hate speech detection in the Bengali language: a comprehensive survey},
	year = {2024},
	journal = {Journal of Big Data},
	volume = {11},
	number = {1},
	doi = {10.1186/s40537-024-00956-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199283542&doi=10.1186%2fs40537-024-00956-z&partnerID=40&md5=9ef7482c0114ca641aa3f1f74e19d5eb},
	affiliations = {Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh; Department of Information and Communication Technology, Bangladesh University of Professionals, Dhaka, Bangladesh; Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh; Department of Information Technology, Engineering Technical College, Al-Ayen University, Thi-Qar, Iraq; Center for Secure Cyber-Physical Systems (C2PS) and Department of Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates},
	abstract = {The detection of hate speech (HS) in online platforms has become extremely important for maintaining a safe and inclusive environment. While significant progress has been made in English-language HS detection, methods for detecting HS in other languages, such as Bengali, have not been explored much like English. In this survey, we outlined the key challenges specific to HS detection in Bengali, including the scarcity of labeled datasets, linguistic nuances, and contextual variations. We also examined different approaches and methodologies employed by researchers to address these challenges, including classical machine learning techniques, ensemble approaches, and more recent deep learning advancements. Furthermore, we explored the performance metrics used for evaluation, including the accuracy, precision, recall, receiver operating characteristic (ROC) curve, area under the ROC curve (AUC), sensitivity, specificity, and F1 score, providing insights into the effectiveness of the proposed models. Additionally, we identified the limitations and future directions of research in Bengali HS detection, highlighting the need for larger annotated datasets, cross-lingual transfer learning techniques, and the incorporation of contextual information to improve the detection accuracy. This survey provides a comprehensive overview of the current state-of-the-art HS detection methods used in Bengali text and serves as a valuable resource for researchers and practitioners interested in understanding the advancements, challenges, and opportunities in addressing HS in the Bengali language, ultimately assisting in the creation of reliable and effective online platform detection systems. © The Author(s) 2024.},
	author_keywords = {Artificial intelligence; Bengali language; Deep learning; Hate speech; Machine learning; Natural language processing},
	keywords = {Deep learning; E-learning; Learning systems; Natural language processing systems; Online systems; Bengali language; Bengalis; Deep learning; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Online platforms; Speech detection; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Zsisku2024241,
	author = {Zsisku, Eszter and Zubiaga, Arkaitz and Dubossarsky, Haim},
	title = {Hate Speech Detection and Reclaimed Language: Mitigating False Positives and Compounded Discrimination},
	year = {2024},
	journal = {Proceedings of the 16th ACM Web Science Conference, WebSci 2024},
	pages = {241 – 249},
	doi = {10.1145/3614419.3644025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195116049&doi=10.1145%2f3614419.3644025&partnerID=40&md5=1e5a046b7725ae1b701538fdead18b73},
	affiliations = {Queen Mary University of London, United Kingdom; University of Cambridge, 3 The Alan Turing Institute, United Kingdom},
	abstract = {While minimising false negatives in hate speech classification remains an important goal in order to reduce discrimination and increase fairness for online communities, there is a growing need to produce models that are sensitive to nuanced language use. This is particularly true for terms that may be considered hateful in certain contexts, but not others. The LGBTQ+ community has long faced stigmatisation and hate, which continues to be the case online. There has been a rise in appreciation and understanding of this community's use of “mock impoliteness" and the reclaiming of language that has traditionally been used derogatorily against them. Reclaimed language in particular presents a challenge in the field of hate-speech detection. As a first-of-its-kind study looking into the impact of reclaimed language on hate speech detection models, we create a novel dataset, Reclaimed Hate Speech Dataset (RHSD), which enables investigation into the phenomenon. Through the use of a state-of-the-art hate speech detection model, we demonstrate that models may inadvertently discriminate against the LGBTQ+ community's reclaimed language use through misclassifying such content as hateful. As a result, there is a risk of compounding discrimination against this population through restricting their language use and self-expression. In response to this issue, we produce a fine-tuned hate-speech detection model which aims to minimise false positive classifications of reclaimed language. By creating and publishing the first dataset that focuses on reclaimed language and investigating its impact on hate speech detection models, our research highlights the importance of semantically aware approaches to hate-speech detection that are not overly reliant on individual words or phrases associated with hate. We thus establish a benchmark methodology for further investigation into reclaimed language, that promises to support marginalised groups, taking into account the intersectional nature of their discourse. NB: Readers should be advised that this paper contains use of and reference to racial, homophobic and transphobic slurs which they may find triggering. References to sentences containing such slurs are purely for illustration purposes and in no way reflect the author's attitudes or opinions. © 2024 Copyright held by the owner/author(s)},
	author_keywords = {Discrimination; Hate speech classification; LGBTQ+; Natural language processing; NLP; Reclaimed language; Semantic understanding},
	keywords = {Classification (of information); Computational linguistics; Semantics; Speech recognition; Discrimination; Hate speech classification; Language processing; LGBTQ+; Natural language processing; Natural languages; Reclaimed language; Semantics understanding; Speech classification; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 16th ACM Web Science Conference, WebSci 2024; Conference date: 21 May 2024 through 24 May 2024; Conference code: 199712}
}

@CONFERENCE{Shedge2024,
	author = {Shedge, Prachi and Kamalkar, Siddhi and Gupta, Deepa},
	title = {Hate Speech Detection in Marathi Tweets using Stacked Deep Learning models},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724157},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213024162&doi=10.1109%2fICCCNT61001.2024.10724157&partnerID=40&md5=1529dcdd599461b1de0c0c8991713cee},
	affiliations = {Amrita School of Computing, Amrita Vishwa Vidyapeetham, Department of Computer Science and Engineering, Bengaluru, India},
	abstract = {Digital platforms have revolutionized communication, but they have also led to an increase in hate speech, making it challenging to create welcoming online groups. The purpose of this study is to close this gap by using deep learning models to detect hate speech in Marathi, a regional language of India. The researchers use advanced word embeddings and DL models like Long Short-Term Memory and Bidirectional LSTM to demonstrate the efficacy of these methods. The study aims to build strong hate speech detection systems that can be extended to other low-resource languages, creating safer online spaces. The study emphasizes the importance of contextually and culturally appropriate data in enhancing model accuracy. In order to strengthen their models' training and validation and guarantee reliable performance in real-world applications, the researchers also intend to integrate real-world social media data. The study closes a significant gap in regional language processing by concentrating on Marathi and opens the door for more inclusive and thorough hate speech detection frameworks across linguistic landscapes. © 2024 IEEE.},
	author_keywords = {BERT; Bi-LSTM; Classification Report; Confusion Matrix; Deep Learning; GRU; LSTM; NLP; Word Embeddings},
	keywords = {Contrastive Learning; Deep learning; Speech recognition; Tweets; BERT; Bi-LSTM; Classification report; Confusion matrix; Deep learning; Embeddings; GRU; LSTM; Speech detection; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@ARTICLE{Zapatier2024151,
	author = {Zapatier, Luis and Morejón, María and Escobar, Silvana and Jima-González, Alexandra and Cuenca, Erick},
	title = {Hate Speech Detection in the 2022 Ecuador Strike Using the K-Nearest Neighbors Algorithm},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {775 LNNS},
	pages = {151 – 166},
	doi = {10.1007/978-3-031-69228-4_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214022019&doi=10.1007%2f978-3-031-69228-4_10&partnerID=40&md5=b9ea64c0bf73d4dcbba975b83976d754},
	affiliations = {Yachay Tech University, Urcuquí, Ecuador; Tecnológico de Monterrey, Monterrey, Mexico},
	abstract = {With the exponential growth of social media platforms, there has been a facilitated global message dissemination and diverse information exchange in real time. However, this communicative diversity can also nurture hate speech due to a myriad of opinions. This research focuses on detecting hate speech during the 2022 national strike in Ecuador, where derogatory remarks were directed against indigenous protesters on Twitter. By implementing a system in Python that employs the K-Nearest Neighbors (KNN) Algorithm in tandem with a dual-check method based on identifying words commonly associated with hate towards indigenous people, tweets are categorized into “hate speech” and “non-hate speech” classes. Utilizing this combined approach, the classification achieved an accuracy of 88.96%. The findings illuminate the dynamics of hate speech during significant events and underscore the imperative to analyze tweets to combat hate speech on social platforms, thereby fostering an inclusive and respectful online discourse. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hate Speech; K-Nearest Neighbors; Machine Learning; Strike; Twitter},
	keywords = {Nearest neighbor search; Social networking (online); Ecuador; Exponential growth; Hate speech; K-near neighbor; Machine-learning; Nearest-neighbor algorithms; Nearest-neighbour; Social media platforms; Speech detection; Strike; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Computer Science, Electronics and Industrial Engineering, CSEI 2023; Conference date: 6 November 2023 through 10 November 2023; Conference code: 324509}
}

@CONFERENCE{Hee20241063,
	author = {Hee, Ming Shan and Singh, Karandeep and Min, Charlotte Ng Si and Choo, Kenny Tsu Wei and Lee, Roy Ka-Wei},
	title = {Brinjal: A Web-Plugin for Collaborative Hate Speech Detection},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {1063 – 1066},
	doi = {10.1145/3589335.3651250},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194495529&doi=10.1145%2f3589335.3651250&partnerID=40&md5=64d1cd54db07302b3a6b8fb4768bb647},
	affiliations = {Singapore University of Technology and Design, Singapore; Singapore Polytechnic, Singapore},
	abstract = {The proliferation of hate speech (HS) has compromised the safety and trustworthiness of the internet, exacerbating social divides by promoting hatred and discrimination. Although recent studies have produced guidelines and developed advanced technologies for the automated detection of HS, their efficacy and adaptability in real-world applications remain unclear. Furthermore, existing guidelines on what constitutes HS might not reflect the perspectives and beliefs of individuals and communities. This paper introduces Brinjal, a multifaceted web plugin designed for the collaborative detection of HS. Brinjal enables individuals to identify instances of HS and engage in discussions to verify such content, thereby enhancing the collective understanding of HS. Additionally, Brinjal serves as a practical platform for deploying and evaluating advanced HS detection models, facilitating user interaction and performance assessment. Lastly, Brinjal includes an analytical tool for analyzing HS, offering insights based on the crowdsourced instances and discussions about HS across various websites. The video demonstration of Brinjal can be viewed here: https://youtu.be/_JxziIVWBO4 Disclaimer: This paper contains violent and discriminatory content that may be disturbing to some readers. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {collaborative platform; hate speech; human-computer interaction},
	keywords = {Human computer interaction; Speech recognition; Advanced technology; Automated detection; Brinjals; Collaborative detection; Collaborative platform; Hate speech; Plug-ins; Practical platforms; Real-world; Speech detection; HTTP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 33rd ACM Web Conference, WWW 2024; Conference date: 13 May 2024 through 17 May 2024; Conference code: 199461; All Open Access, Bronze Open Access}
}

@ARTICLE{Kebriaei20244359,
	author = {Kebriaei, Emad and Homayouni, Ali and Faraji, Roghayeh and Razavi, Armita and Shakery, Azadeh and Faili, Heshaam and Yaghoobzadeh, Yadollah},
	title = {Persian offensive language detection},
	year = {2024},
	journal = {Machine Learning},
	volume = {113},
	number = {7},
	pages = {4359 – 4379},
	doi = {10.1007/s10994-023-06370-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168598661&doi=10.1007%2fs10994-023-06370-5&partnerID=40&md5=e6e7d4134891eab562cfadbdd31bcc2e},
	affiliations = {School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran; School of Computer Science, Institute for Research in Fundamental Sciences (IPM), Tehran, Iran},
	abstract = {With the proliferation of social networks and their impact on human life, one of the rising problems in this environment is the rise in verbal and written insults and hatred. As one of the significant platforms for distributing text-based content, Twitter frequently publishes its users’ abusive remarks. Creating a model that requires a complete collection of offensive sentences is the initial stage in recognizing objectionable phrases. In addition, despite the abundance of resources in English and other languages, there are limited resources and studies on identifying hateful and offensive statements in Persian. In this study, we compiled a 38K-tweet dataset of Persian Hate and Offensive language using keyword-based data selection strategies. A Persian offensive lexicon and nine hatred target group lexicons were gathered through crowdsourcing for this purpose. The dataset was annotated manually so that at least two annotators investigated tweets. In addition, for the purpose of analyzing the effect of used lexicons on language model functionality, we employed two assessment criteria (FPED and pAUCED) to measure the dataset’s potential bias. Then, by configuring the dataset based on the results of the bias measurement, we mitigated the effect of words’ bias in tweets on language model performance. The results indicate that bias is significantly diminished, while less than a hundredth reduced the F1 score. © The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature 2023.},
	author_keywords = {Debiasing; Imbalanced data; Offensive language detection; Twitter},
	keywords = {Computational linguistics; De-biasing; Human lives; Imbalanced data; Keyword-based; Language detection; Language model; Offensive language detection; Offensive languages; Persians; Twitter; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shawkat2024253,
	author = {Shawkat, Nabil and Saquer, Jamil and Shatnawi, Hazim},
	title = {Evaluation of Different Machine Learning and Deep Learning Techniques for Hate Speech Detection},
	year = {2024},
	journal = {Proceedings of the 2024 ACM Southeast Conference, ACMSE 2024},
	pages = {253 – 258},
	doi = {10.1145/3603287.3651218},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192525932&doi=10.1145%2f3603287.3651218&partnerID=40&md5=d70a6a2dea7002d926669fe40dd33d43},
	affiliations = {Missouri State University, Springfield, MO, United States; The George Washington University, Washington, DC, United States},
	abstract = {Detecting online hate speech is important for creating safer online spaces. In this paper, we evaluate the performance of several machine learning (ML) and deep learning (DL) models in detecting hate speech on three different datasets. We evaluate the performance of the traditional ML algorithms Support Vector Machines (SVM), Naive Bayes, Decision Trees, Random Forests, and Logistic Regression. We also evaluate the performance of deep learning Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM), and the BERT pre-trained transformer model. Our experiments show that BERT outperformed all other models with F-1 scores of 90.6% on one dataset and 89.7% and 88.2% on the other two datasets. After that, CNN and LSTM outperformed the traditional ML algorithms with F1-scores over 80% on all three datasets. Among the traditional ML models, SVM performed best with the highest F1-score of 75.6%. © 2024 ACM.},
	author_keywords = {BERT; deep learning; hate speech; machine learning; text classification},
	keywords = {Classification (of information); Convolutional neural networks; Decision trees; Learning systems; Logistic regression; Speech recognition; Support vector regression; Text processing; Transfer learning; BERT; Convolutional neural network; Deep learning; F1 scores; Hate speech; Machine learning algorithms; Machine-learning; Performance; Support vectors machine; Text classification; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 ACM Southeast Conference, ACMSE 2024; Conference date: 18 April 2024 through 20 April 2024; Conference code: 199181}
}

@ARTICLE{Moreno-Sandoval2024,
	author = {Moreno-Sandoval, Luis Gabriel and Pomares-Quimbaya, Alexandra and Barbosa-Sierra, Sergio Andres and Pantoja-Rojas, Liliana Maria},
	title = {Detection of Hate Speech, Racism and Misogyny in Digital Social Networks: Colombian Case Study},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {9},
	doi = {10.3390/bdcc8090113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205060278&doi=10.3390%2fbdcc8090113&partnerID=40&md5=643dc31268e5cd286afed6dda2ce1021},
	affiliations = {Engineering Faculty, Pontificia Universidad Javeriana, Bogotá, 110231, Colombia; Engineering Faculty, Universidad Distrital Francisco José de Caldas, Bogotá, 111611, Colombia},
	abstract = {The growing popularity of social networking platforms worldwide has substantially increased the presence of offensive language on these platforms. To date, most of the systems developed to mitigate this challenge focus primarily on English content. However, this issue is a global concern, and therefore, other languages, such as Spanish, are involved. This article addresses the task of identifying hate speech, racism, and misogyny in Spanish within the Colombian context on social networks, and introduces a gold standard dataset specifically developed for this purpose. Indeed, the experiment compares the performance of TLM models from Deep Learning methods, such as BERT, Roberta, XLM, and BETO adjusted to the Colombian slang domain, then compares the best TLM model against a GPT, having a significant impact on achieving more accurate predictions in this task. Finally, this study provides a detailed understanding of the different components used in the system, including the architecture of the models and the selection of functions. The best results show that the BERT model achieves an accuracy of 83.6% for hate speech detection, while the GPT model achieves an accuracy of 90.8% for racism speech and 90.4% for misogyny detection. © 2024 by the authors.},
	author_keywords = {digital social networks; hate speech detection; large language models; sentiment analysis; social network analysis; subjectivity analysis; text classification},
	keywords = {Colombians; Digital social network; Hate speech detection; Language model; Large language model; Sentiment analysis; Social Network Analysis; Speech detection; Subjectivity analyze; Text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Frediani2025244,
	author = {Frediani, João Otávio Rodrigues Ferreira and Garcia, Gabriel Lino and Paiola, Pedro Henrique and Passos, Leandro Aparecido and Papa, João Paulo and Marana, Aparecido Nilceu},
	title = {Hate Speech Detection in Portuguese Using BERTimbau},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15368 LNCS},
	pages = {244 – 255},
	doi = {10.1007/978-3-031-76607-7_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210225301&doi=10.1007%2f978-3-031-76607-7_18&partnerID=40&md5=1ad5d76c491e810b6b948512e17cae4d},
	affiliations = {School of Sciences, São Paulo State University (UNESP), Bauru, Brazil},
	abstract = {Hate speech refers to language expressions that attack individuals or groups based on specific characteristics associated with their identities, causing lasting damage. Social networks have become a pertinent environment for hate speech proliferation since they allow anonymity and maintain a safe distance from aggressors and assaulted victims. With the amount of data published every minute, automatic identification of hate speech using machine learning gathered much attention from academic and industrial researchers. However, as with many natural language processing tasks, the efforts mainly focused on English, and languages like Portuguese remain less explored. Therefore, this paper aims to experiment with different techniques to deal with the challenges associated with low-resource languages in automatic hate speech detection. It evaluates whether knowledge transferred from offensive speech detection as a source task can be effective for hate detection and if the unbalanced data poses an obstacle for a Portuguese pre-trained BERT model, BERTimbau. Experimental results show that transferring learning between tasks does not improve performance and that using balanced data leads to better F1 scores and Cohen’s Kappa. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Hate Speech; Machine Learning; Natural Language Processing; Portuguese Language; Undersampling},
	keywords = {Natural language processing systems; Speech recognition; Group-based; Hate speech; Individual-based; Language processing; Machine-learning; Natural language processing; Natural languages; Portuguese languages; Speech detection; Under-sampling; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 27th Iberoamerican Congress on Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications, CIARP 2024; Conference date: 26 November 2024 through 29 November 2024; Conference code: 323079}
}

@CONFERENCE{Chen2024365,
	author = {Chen, Tong and Wang, Danny and Liang, Xurong and Risius, Marten and Demartini, Gianluca and Yin, Hongzhi},
	title = {Hate Speech Detection with Generalizable Target-aware Fairness},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {365 – 375},
	doi = {10.1145/3637528.3671821},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203684307&doi=10.1145%2f3637528.3671821&partnerID=40&md5=e8d0a21df46afeb43249cc17b23bceeb},
	affiliations = {The University of Queensland, Brisbane, Australia},
	abstract = {To counter the side effect brought by the proliferation of social media platforms, hate speech detection (HSD) plays a vital role in halting the dissemination of toxic online posts at an early stage. However, given the ubiquitous topical communities on social media, a trained HSD classifier can easily become biased towards specific targeted groups (e.g.,female andblack people), where a high rate of either false positive or false negative results can significantly impair public trust in the fairness of content moderation mechanisms, and eventually harm the diversity of online society. Although existing fairness-aware HSD methods can smooth out some discrepancies across targeted groups, they are mostly specific to a narrow selection of targets that are assumed to be known and fixed. This inevitably prevents those methods from generalizing to real-world use cases where new targeted groups constantly emerge (e.g., new forums created on Reddit) over time. To tackle the defects of existing HSD practices, we propose <u>Generalizable <u>target-aware <u>Fairness (GetFair), a new method for fairly classifying each post that contains diverse and even unseen targets during inference. To remove the HSD classifier's spurious dependence on target-related features, GetFair trains a series of filter functions in an adversarial pipeline, so as to deceive the discriminator that recovers the targeted group from filtered post embeddings. To maintain scalability and generalizability, we innovatively parameterize all filter functions via a hypernetwork. Taking a target's pretrained word embedding as input, the hypernetwork generates the weights used by each target-specific filter on-the-fly without storing dedicated filter parameters. In addition, a novel semantic gap alignment scheme is imposed on the generation process, such that the produced filter function for an unseen target is rectified by its semantic affinity with existing targets used for training. Finally, experiments are conducted on two benchmark HSD datasets, showing advantageous performance of GetFair on out-of-sample targets among baselines.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {data science for social good; debiased content moderation; hate speech detection; target-aware fairness},
	keywords = {Classification (of information); Economic and social effects; Hypertext systems; Social networking (online); Speech recognition; Wiener filtering; Data science for social good; Debiased content moderation; Embeddings; Filter function; Hate speech detection; Hypernetwork; Side effect; Social media platforms; Speech detection; Target-aware fairness; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2024; Conference date: 25 August 2024 through 29 August 2024; Conference code: 202030; All Open Access, Green Open Access}
}

@CONFERENCE{Nafea20244303,
	author = {Nafea, Youssef and Shehata, Shady and Talat, Zeerak and Aboeitta, Ahmed and Sharshar, Ahmed and Nakov, Preslav},
	title = {ARAOFFENSE: Detecting Offensive Speech Across Dialects in Arabic Media},
	year = {2024},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	pages = {4303 – 4307},
	doi = {10.21437/Interspeech.2024-2077},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214798242&doi=10.21437%2fInterspeech.2024-2077&partnerID=40&md5=b3add5eda6800a762437e01c11bf12f7},
	affiliations = {Mohamed Bin Zayed University of Artificial Intelligence, United Arab Emirates; Invertible AI, United Arab Emirates},
	abstract = {Natural language processing (NLP) has made efforts towards identifying toxicity and offensive content for the text and image modalities. Despite sharing similar concerns with text and images, such as increased access to online abuse using speech, speech offensiveness research trails behind. While NLP has primarily considered English language data, speech has emphasized under-represented languages such as Swahili and Wolof. In this work, we introduce ARAOFFENSE, a dataset of scripted media in Arabic dialects labelled for offensiveness. ARAOFFENSE contains 2146 instances, of which 475 are labelled as offensive, spanning 1.55 hours of audio. We assess the capabilities of speech models to detect offensive content and present a hard-to-beat multi-modal text and audio model which outperforms the baselines by 26+% in terms of the Matthews Correlation Coefficient. Our work thus presents the first benchmark for offensive speech detection in dialectical Arabic. © 2024 International Speech Communication Association. All rights reserved.},
	author_keywords = {computational paralinguistics; content moderation; offensive content},
	keywords = {Computational linguistics; Natural language processing systems; Translation (languages); Arabic dialects; Computational paralinguistic; Content moderation; English languages; Image modality; Language processing; Natural languages; Offensive content; Paralinguistic; Under-represented; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 25th Interspeech Conferece 2024; Conference date: 1 September 2024 through 5 September 2024; Conference code: 204983}
}

@ARTICLE{Hashmi20244535,
	author = {Hashmi, Ehtesham and Yayilgan, Sule Yildirim},
	title = {Multi-class hate speech detection in the Norwegian language using FAST-RNN and multilingual fine-tuned transformers},
	year = {2024},
	journal = {Complex and Intelligent Systems},
	volume = {10},
	number = {3},
	pages = {4535 – 4556},
	doi = {10.1007/s40747-024-01392-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188193309&doi=10.1007%2fs40747-024-01392-5&partnerID=40&md5=7fea2fc47e321857d8538505f569d87e},
	affiliations = {Department of Information Security and Communication Technology (IIK), Norwegian University of Science and Technology (NTNU), Teknologivegen 22, Innlandet, Gjøvik, 2815, Norway},
	abstract = {The growth of social networks has provided a platform for individuals with prejudiced views, allowing them to spread hate speech and target others based on their gender, ethnicity, religion, or sexual orientation. While positive interactions within diverse communities can considerably enhance confidence, it is critical to recognize that negative comments can hurt people’s reputations and well-being. This emergence emphasizes the need for more diligent monitoring and robust policies on these platforms to protect individuals from such discriminatory and harmful behavior. Hate speech is often characterized as an intentional act of aggression directed at a specific group, typically meant to harm or marginalize them based on certain aspects of their identity. Most of the research related to hate speech has been conducted in resource-aware languages like English, Spanish, and French. However, low-resource European languages, such as Irish, Norwegian, Portuguese, Polish, Slovak, and many South Asian, present challenges due to limited linguistic resources, making information extraction labor-intensive. In this study, we present deep neural networks with FastText word embeddings using regularization methods for multi-class hate speech detection in the Norwegian language, along with the implementation of multilingual transformer-based models with hyperparameter tuning and generative configuration. FastText outperformed other deep learning models when stacked with Bidirectional LSTM and GRU, resulting in the FAST-RNN model. In the concluding phase, we compare our results with the state-of-the-art and perform interpretability modeling using Local Interpretable Model-Agnostic Explanations to achieve a more comprehensive understanding of the model’s decision-making mechanisms. © The Author(s) 2024.},
	author_keywords = {Deep Learning; Hate speech; Interpretability modeling; Natural language processing; Norwegian language; Transformers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access}
}

@ARTICLE{Mao2025,
	author = {Mao, Junjie and Shi, Hanxiao and Li, Xiaojun},
	title = {Research on multimodal hate speech detection based on self-attention mechanism feature fusion},
	year = {2025},
	journal = {Journal of Supercomputing},
	volume = {81},
	number = {1},
	doi = {10.1007/s11227-024-06602-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207048422&doi=10.1007%2fs11227-024-06602-y&partnerID=40&md5=c195218712daace43acc0bf6080fa130},
	affiliations = {School of Management and E-Business, Zhejiang Gongshang University, Zhejiang, Hangzhou, 310018, China},
	abstract = {The widespread rise of multimedia social platforms has diversified the ways in which people communicate and the content they share. Hate speech, as a threat to societal harmony, has also shifted its manifestation from a singular textual to a multimodal one. Previously, most methods for detecting hate speech were limited to the text modality, making it difficult to identify and classify newly emerging multimodal hate speech that combines text and images. This paper proposes a novel multimodal hate speech detection model to respond to the above-mentioned needs for multimodal hate speech detection. The proposed joint model can use moving windows to extract multi-level visual features and extract text features based on the RoBERTa pretraining model and introduces a multi-head self-attention mechanism in the later fusion process for image and text feature fusion. This article also conducted experiments on the multimodal benchmark dataset hateful memes. The model achieved an accuracy of 0.8780, precision of 0.9135, F1-score of 0.8237, and AUCROC of 0.8532, defeating the SOTA multimodal hate speech recognition model. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Attention mechanism; Deep learning; Hateful speech detecting; Modal fusion; Multimodal data analysis},
	keywords = {Data fusion; Speech recognition; Attention mechanisms; Deep learning; Detection models; Features fusions; Hateful speech detecting; Modal fusion; Multi-modal; Multimodal data analysis; Speech detection; Text feature; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jarquín-Vásquez2024361,
	author = {Jarquín-Vásquez, Horacio and Escalante, Hugo Jair and Montes-y-Gómez, Manuel},
	title = {Enhancing abusive language detection: A domain-adapted approach leveraging BERT pre-training tasks},
	year = {2024},
	journal = {Pattern Recognition Letters},
	volume = {186},
	pages = {361 – 368},
	doi = {10.1016/j.patrec.2024.05.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195507531&doi=10.1016%2fj.patrec.2024.05.007&partnerID=40&md5=7ab5bb94471299c334576a73e293bd4e},
	affiliations = {Instituto Nacional de Astrofísica, Óptica y Electrónica (INAOE), Luis Enrique Erro #1, Sta María Tonanzintla, Puebla, San Andrés Cholula, 72840, Mexico},
	abstract = {The widespread adoption of deep learning approaches in natural language processing is largely attributed to their exceptional performance across diverse tasks. Notably, Transformer-based models, such as BERT, have gained popularity for their remarkable efficacy and their ease of adaptation (via fine-tuning) across various domains. Despite their success, fine-tuning these models for informal language, particularly instances involving offensive expressions, presents a major challenge due to limitations in vocabulary coverage and contextual information for such tasks. To address these challenges, we propose the domain adaptation of the BERT language model for the task of detecting abusive language. Our approach involves constraining the language model with the adaptation and paradigm shift of two default pre-trained tasks, the design of two datasets specifically engineered to support the adapted pre-training tasks, and the proposal of a dynamic weighting loss function. The evaluation of these adapted configurations on six datasets dedicated to abusive language detection reveals promising outcomes, with a significant enhancement observed compared to the base model. Furthermore, our proposed methods yield competitive results when compared to state-of-the-art approaches, establishing a robust and easily trainable model for the effective identification of abusive language. © 2024 Elsevier B.V.},
	author_keywords = {Abusive language; Attention mechanisms; Pretraining tasks; Transformer models},
	keywords = {Computational linguistics; Natural language processing systems; Abusive language; Attention mechanisms; Fine tuning; Language detection; Language model; Learning approach; Natural languages; Pre-training; Pretraining task; Transformer modeling; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bensoltane20242927,
	author = {Bensoltane, Rajae and Zaki, Taher},
	title = {Fine-grained hate speech detection in Arabic using transformer-based models},
	year = {2024},
	journal = {International Journal of Electrical and Computer Engineering},
	volume = {14},
	number = {3},
	pages = {2927 – 2936},
	doi = {10.11591/ijece.v14i3.pp2927-2936},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191361535&doi=10.11591%2fijece.v14i3.pp2927-2936&partnerID=40&md5=b17454f3cb6dcf7d6075cbf0cd19e226},
	affiliations = {Laboratory of Innovation in Mathematics and Intelligent Systems, Faculty of Applied Sciences, Ibn Zohr University, Agadir, Morocco},
	abstract = {With the proliferation of social media platforms, characterized by features such as anonymity, user-friendly access, and the facilitation of online community building and discourse, the matter of detecting and monitoring hate speech has emerged as an increasingly formidable challenge for society, individuals, and researchers. Despite the crucial importance of hate speech detection task, the majority of work in this field has been conducted in English, with insufficient focus on other languages, particularly Arabic. Furthermore, most existing studies on Arabic hate speech detection have addressed this task as a binary classification problem, which is unreliable. Therefore, the aim of this study is to provide an enhanced model for detecting fine-grained hate speech in Arabic. To this end, three transformer-based models were evaluated to generate contextualized word embeddings from input sequence. Additionally, these models were combined with a bidirectional gated recurrent unit (BiGRU) layer to further improve the extracted semantic and context features. The experiments were conducted on an Arabic reference dataset provided by the open-source Arabic corpora and processing tools (OSACT-5) shared task. A comparative analysis indicates the efficiency of the proposed model over the baseline and related work models by achieving a macro F1-score of 61.68%. © 2024 Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Arabic Bidirectional gated recurrent unit Fine-grained hate speech Natural language processing Transformer},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Chakraborty2024,
	author = {Chakraborty, Angana and Joardar, Subhankar and Sekh, Arif Ahmed},
	title = {Ensemble Classifier for Hindi Hostile Content Detection},
	year = {2024},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {23},
	number = {1},
	doi = {10.1145/3591353},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183755960&doi=10.1145%2f3591353&partnerID=40&md5=d245ce063bf82ebaf135d873eb8f9cc0},
	affiliations = {Haldia Institute of Technology, Haldia, India; School of Computer Science Engineering, Xim University, Bhubaneswar, India},
	abstract = {Detection of hostile content fromsocialmedia posts (Facebook, Twitter, etc.) is a demanding task in the field of Natural Language Processing. The increase of hostile content in different electronic media has opened up new challenges in language understanding. It becomes more difficult in regional languages. AI-based solutions are required to identify hostile content on a large scale. Although a satisfactory amount of research has been carried out in the English language, finding hostile content in regional languages is still under development due to the unavailability of suitable datasets and tools. In terms of the number of speakers, Hindi ranks third in the world and first on the Indian subcontinent. The objective of this article is to design a hostile content detection system in Hindi using coarse-grained (binary) classification and fine-grained (multi-class, multi-label) classification. We note that different baseline learning methods with different pre-trained language models perform differently. Using the Constraint 2021 Hindi Dataset, this research proposes a Bidirectional Encoder Representations from Transformers-(BERT) based contextual embedding technique with a concatenation of emoji2vec embeddings to classify social media posts in Hindi Devanagari script as hostile or non-hostile. Additionally, for the fine-grained tasks where hostile posts are sub-categorized as defamation, fake, hate, and offensive, we develop an ensemble classifier varying different learning methods and embedding models. With an F1-Score of 0.9721, it is found that our proposed Indic-BERT+emoji model outperforms the baseline model and other existing models for the coarse-grained task. We have also observed that our proposed ensemble method provides better results than the existing models and the baseline model for the fine-grained tasks with F1-Scores of 0.43, 0.82, 0.58, and 0.62 for the defamation, fake, hate, and offensive classes, respectively. © 2024 Association for Computing Machinery. All rights reserved.},
	author_keywords = {BERT; defamation; fake; hate; Hindi; Hostility detection; NLP; offensive; social media},
	keywords = {Classification (of information); Embeddings; Fake detection; Social networking (online); BERT; Defamation; Ensemble-classifier; Fake; Fine grained; Hate; Hindi; Hostility detection; Offensive; Social media; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Mazari2024,
	author = {Mazari, Ahmed Cherif and Benterkia, Asmaa and Takdenti, Zineb},
	title = {Advancing offensive language detection in Arabic social media: a BERT-based ensemble learning approach},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01347-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203552598&doi=10.1007%2fs13278-024-01347-1&partnerID=40&md5=30dbd1182fbd5d0acde6b9d00482aa75},
	affiliations = {LSEA Laboratory, Mathematics and Computer Science Department, University of Médéa, Médéa, Algeria; Mathematics and Computer Science Department, University of Médéa, Médéa, Algeria},
	abstract = {The growing ubiquity of online anonymity has significantly transformed the dynamics of participation and collaboration across digital platforms, especially through social media. While this veil of anonymity enables the free expression of personal opinions, it also leads to the spread of negative content, including offensive language. The detection and mitigation of such offensive language pose a considerable challenge and represent a dynamic research area. This paper introduces and evaluates a new ensemble learning approach designed for the Arabic offensive language detection task. The proposed approach combines three distinct models: the pretrained Bidirectional Encoder Representations from Transformers (BERT) model, BERT combined with Global Average and Global Max layers, and BERT augmented with pooled stacked Bidirectional Long Short-Term Memory (Bi-LSTMs). Outperforming the performance of the baseline OffensEval2020 winner in “SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media”, our model achieved a 90.97% F1-score on the original Arabic OffensEval2020 dataset and an enhanced 94.56% F1-score on the augmented dataset. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024.},
	author_keywords = {Arabic social media; BERT model; Bi-LSTM; Ensemble learning; OffensEval2020 dataset; Offensive language detection},
	keywords = {Adversarial machine learning; Social networking (online); Arabic social medium; Bi-LSTM; Bidirectional encoder representation from transformer model; Ensemble learning; Language detection; Offenseval2020 dataset; Offensive language detection; Offensive languages; Social media; Transformer modeling; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nicola20243447,
	author = {Nicola, Elena-Beatrice and Cercel, Dumitru-Clementin and Pop, Florin},
	title = {Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {3447 – 3456},
	doi = {10.1016/j.procs.2024.09.212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213350339&doi=10.1016%2fj.procs.2024.09.212&partnerID=40&md5=863c584a897f379be568cd54e98964bf},
	affiliations = {Faculty of Automatic Control and Computers, National University of Science and Technology POLITEHNICA, Bucharest, Romania; National Institute for Research and Development in Informatics (ICI), Bucharest, Romania; Academy of Romanian Scientists, Bucharest, Romania},
	abstract = {Offensive language detection is a crucial task in today's digital landscape, where online platforms grapple with maintaining a respectful and inclusive environment. However, building robust offensive language detection models requires large amounts of labeled data, which can be expensive and time-consuming to obtain. Semi-supervised learning offers a feasible solution by utilizing labeled and unlabeled data to create more accurate and robust models. In this paper, we explore a few different semi-supervised methods, as well as data augmentation techniques. Concretely, we implemented eight semi-supervised methods and ran experiments for them using only the available data in the RO-Offense dataset and applying five augmentation techniques before feeding the data to the models. Experimental results demonstrate that some of them benefit more from augmentations than others. © 2024 The Authors.},
	author_keywords = {1. Introduction; Data Augmentation; Offensive Language; Romanian Language; Semi-Supervised Learning},
	keywords = {Contrastive Learning; Data assimilation; Labeled data; Semi-supervised learning; 1.; Augmentation techniques; Data augmentation; Introduction; Language detection; Offensive languages; Online platforms; Romanian language; Semi-supervised learning; Semi-supervised method; Self-supervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems, KES 2024; Conference date: 11 November 2022 through 12 November 2022; Conference code: 150888; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Abdelsamie2024,
	author = {Abdelsamie, Mahmoud Mohamed and Azab, Shahira Shaaban and Hefny, Hesham A.},
	title = {A comprehensive review on Arabic offensive language and hate speech detection on social media: methods, challenges and solutions},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01258-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195132209&doi=10.1007%2fs13278-024-01258-1&partnerID=40&md5=88b71bb4b4a35681fee48355e8f0893e},
	affiliations = {FGSSR, Department of Computer Science, Cairo University, Cairo, Egypt},
	abstract = {In recent years, social media has witnessed an exponential growth in promoting healthy relationships and communication between family, friends, and acquaintances, but it isn’t without its flaws. It is clear that sometimes social media freedom can create an unattractive online environment. Hate speech and offensive language are frequently spread on social media platforms. Thus, they encompass different negative effects on our society. Therefore, detecting hate speech and offensive language has become the theme of one of the major research trends. Although the Arabic language occupies a distinct position among the languages on social media networks such as Twitter and Facebook, the ability to identify Arabic hate speech and offensive language is still developing due to the variety and complexity of Arabic dialects and forms. In this paper, we present an in-depth review focused on studies published between 2019 and September 2023 related to Arabic offensive language and hate speech detection. To conclude, we highlighted the most significant methods, Arabic datasets, taxonomy analysis, and challenges. Moreover, this review provides a foundation of knowledge that can help the researchers design and implement reliable and more accurate solutions. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024.},
	author_keywords = {Arabic dialects; Arabic hate speech; Arabic offensive language; Deep learning (DL); Machine learning (ML); Natural language processing (NLP); Social media; Taxonomy},
	keywords = {Deep learning; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Arabic dialects; Arabic hate speech; Arabic offensive language; Deep learning; Language processing; Machine learning; Machine-learning; Natural language processing; Natural languages; Offensive languages; Social media; Taxonomies},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Pookpanich2024,
	author = {Pookpanich, Peerat and Siriborvornratanakul, Thitirat},
	title = {Offensive language and hate speech detection using deep learning in football news live streaming chat on YouTube in Thailand},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-023-01183-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181245124&doi=10.1007%2fs13278-023-01183-9&partnerID=40&md5=448cfc1afd0b9c310f34ed8d8f844f63},
	affiliations = {Graduate School of Applied Statistics, National Institute of Development Administration, Bangkok, 10240, Thailand},
	abstract = {Today, hate speech is frequently seen on Thai social media platforms such as Facebook, Twitter, and even online video platforms such as YouTube. In live video broadcasts of football news, for example, some Thais expressed hate speech toward opposing football fans and players. This paper presented offensive language and hate speech detection for Thai in YouTube live streaming chat with transformer-based language models by using five BERT models, including BERT, XLM-RoBERTa, DistilBERT, WangchanBERTa, and TwHIN-BERT, which were trained with multilingual languages as well as Thai. In the data labeling process, a two-step data labeling procedure was developed. The first stage involved automated data labeling utilizing the WangchanBERTa model, and the second stage involved manual data labeling conducted by the researchers. We developed text classification models using 11 different positive and negative class ratio datasets to get the most efficient model. In terms of recall and F1 score, the results showed that XLM-RoBERTa performed the best. It yielded an average recall and F1 score of 0.9669 and 0.9530, respectively. However, neither of the five models has significantly different performance. When considering the purpose of the application, DistilBERT is most appropriate. Because of its similar performance to XLM-RoBERTa, it has smaller model sizes and works faster. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Deep learning; Offensive language detection; Text classification; Thai natural language processing},
	keywords = {Classification (of information); Deep learning; Social networking (online); Speech recognition; Text processing; Data labelling; Deep learning; Language detection; Language processing; Natural languages; Offensive language detection; Offensive languages; Text classification; Thai natural language processing; YouTube; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Nandi2024,
	author = {Nandi, Arpan and Sarkar, Kamal and Mallick, Arjun and De, Arkadeep},
	title = {A survey of hate speech detection in Indian languages},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01223-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188605233&doi=10.1007%2fs13278-024-01223-y&partnerID=40&md5=072d01a96c723b148b2e121a82d52f5b},
	affiliations = {Department of Computer Science and Engineering, Jadavpur University, Raja S C Mallick Road, West Bengal, Kolkata, 700032, India},
	abstract = {With the enormous increase in accessibility of high-speed internet, the number of social media users is increasing rapidly. Due to a lack of proper regulations and ethics, social media platforms are often contaminated by posts and comments containing abusive language and offensive remarks toward individuals, groups, races, religions, and communities. A single remark often triggers a huge chain of reactions with similar abusiveness, or even more. To prevent such occurrences, there is a need for automated systems that can detect abusive texts and hate speeches and remove them immediately. However, most existing research works are limited only to globally popular languages like English. Since India is a nation of many diverse languages and multiple religions, nowadays abusive posts and remarks in Indian languages (monolingual or code-mixed form) are not infrequent on social media platforms. Although resources such as hate speech lexicon and annotated datasets are limited for Indian languages, most research works on hate speech detection in such languages used traditional machine learning and deep learning methods for this task. However, multilingualism and code-mixing make hate speech detection in Indian languages more challenging. Given these facts, this paper mainly focuses on reviewing the latest impactful research works on hate speech detection in Indian languages. In this paper, we have analyzed and compared the latest research works on hate speech detection in Indian languages in terms of various aspects—datasets used, feature extraction and classification methods applied, and the results achieved. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024.},
	author_keywords = {Abusive comments; Code-mixed; Hate speech detection; Indian languages; Mixed languages},
	keywords = {Automation; Classification (of information); Codes (symbols); Feature extraction; Learning systems; Social networking (online); Speech recognition; Abusive comment; Automated systems; Code-mixed; Hate speech detection; High speed internet; Indian languages; Mixed language; Social media; Social media platforms; Speech detection; Deep learning},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Kia20242704,
	author = {Kia, Mahsa Abazari and Samiee, Dorsa},
	title = {From Monolingual to Multilingual: Enhancing Hate Speech Detection with Multi-channel Language Models},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {2704 – 2713},
	doi = {10.1016/j.procs.2024.09.401},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213404966&doi=10.1016%2fj.procs.2024.09.401&partnerID=40&md5=8935a94d16927aefea81f3e8ba0885ef},
	affiliations = {Northeastern University, London, United Kingdom; Royal Holloway University of London, United Kingdom},
	abstract = {The rise of social networking services (SNS) has reshaped communication dynamics in cyberspace, yet it has also exacerbated the proliferation of online hate speech due to the anonymity and fluidity these platforms offer. With manual hate speech detection by human annotators proving costly and time-intensive, the imperative for developing automated recognition algorithms is evident. Leveraging knowledge transfer through fine-tuning pre-trained language models has emerged as a promising strategy in natural language processing. Notably, Bidirectional Encoder Representations from Transformers (BERT) and HateBERT, a domain-specific variant, stand out for their ability to glean deep bidirectional representations from extensive corpora. This paper introduces a multichannel model integrating these two language models for multilingual hate speech detection. Furthermore, we explore the efficacy of augmenting input data through translation, ensuring compatibility with the English requirement of the HateBERT model. By evaluating our approach on three non-English datasets alongside an English dataset, we demonstrate achieving state-of-the-art or comparable performance, underscoring the effectiveness of our methodology in combating hate speech across linguistic barriers. © 2024 The Authors.},
	author_keywords = {BERT; Cross-lingual classification; Deep Learning; Hate speech detection; Social Networking Services; Transfer Learning},
	keywords = {Economic and social effects; Linguistics; Natural language processing systems; Speech enhancement; Speech recognition; Bidirectional encoder representation from transformer; Cross-lingual; Cross-lingual classification; Deep learning; Hate speech detection; Language model; Multi channel; Social networking services; Speech detection; Transfer learning; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems, KES 2024; Conference date: 11 November 2022 through 12 November 2022; Conference code: 150888; All Open Access, Gold Open Access}
}

@ARTICLE{Shilpashree2024,
	author = {Shilpashree, S. and Ashoka, D.V.},
	title = {F-DenseCNN: feature-based dense convolutional neural networks and swift text word embeddings for enhanced hate speech prediction},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-024-01345-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204902150&doi=10.1007%2fs13278-024-01345-3&partnerID=40&md5=96fb1b6e3a372254ddecf3a19986abea},
	affiliations = {School of Advanced Studies, Computer Science Department, S-Vyasa University, Global City Campus, Karnataka, Bengaluru, 560059, India; Department of Computer Science and Engineering, JSS Academy of Technical Education, Bengaluru, Visvesvaraya Technological University, Belagavi, Dr. Vishnuvardhana Road, Karnataka, Bengaluru, 560060, India; Department of Information Science and Engineering, JSS Academy of Technical Education, Bengaluru, Visvesvaraya Technological University, Belagavi, Dr. Vishnuvardhana Road, Karnataka, Bengaluru, 560060, India},
	abstract = {Hate speech on social media platforms poses a significant threat to individuals and society, necessitating robust automated detection systems. While existing approaches employ supervised machine learning with text mining elements, they often fall short in capturing the nuanced and evolving nature of hate speech, including subtle linguistic cues, implicit biases, and coded language. This study addresses these limitations by introducing two novel techniques: the feature-based dense convolutional neural network and the swift text word embedding technique. Our key contributions include the development of F-DenseCNN, a deep learning architecture designed to extract complex features from textual data, and the introduction of the swift text word embedding technique, offering efficient and context-aware word representations. Extensive experimentation and evaluation demonstrate that our proposed method significantly outperforms conventional approaches, achieving a 96.2% accuracy in hate speech detection. This substantial improvement in detection accuracy has important implications for content moderation systems, potentially enhancing their reliability and effectiveness in combating online hate speech. Our findings underscore the potential of advanced deep learning techniques in addressing the evolving challenges of hate speech detection on social media platforms. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024.},
	author_keywords = {Deep learning; Dense neural network; Feature extraction; Hate speech prediction; Word embeddings},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep neural networks; Network embeddings; Speech enhancement; Speech recognition; Convolutional neural network; Deep learning; Dense neural network; Embeddings; Feature-based; Features extraction; Hate speech prediction; Neural-networks; Text words; Word embedding; Convolutional neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bensoltane20241351,
	author = {Bensoltane, Rajae and Zaki, Taher},
	title = {Enhancing Arabic offensive language detection with BERT-BiGRU model},
	year = {2024},
	journal = {Bulletin of Electrical Engineering and Informatics},
	volume = {13},
	number = {2},
	pages = {1351 – 1361},
	doi = {10.11591/eei.v13i2.6530},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185943591&doi=10.11591%2feei.v13i2.6530&partnerID=40&md5=eb91dd3c74ca96a5b31326f806ab271a},
	affiliations = {Laboratory of Innovation in Mathematics and Intelligent Systems, Faculty of Applied Sciences, Agadir, Morocco},
	abstract = {With the advent of Web 2.0, various platforms and tools have been developed to allow internet users to express their opinions and thoughts on diverse topics and occurrences. Nevertheless, certain users misuse these platforms by sharing hateful and offensive speeches, which has a negative impact on the mental health of internet society. Thus, the detection of offensive language has become an active area of research in the field of natural language processing. Rapidly detecting offensive language on the internet and preventing it from spreading is of great practical significance in reducing cyberbullying and self-harm behaviors. Despite the crucial importance of this task, limited work has been done in this field for non-English languages such as Arabic. Therefore, in this paper, we aim to improve the results of Arabic offensive language detection without the need for laborious preprocessing or feature engineering work. To achieve this, we combine the bidirectional encoder representations from transformers (BERT) model model with a bidirectional gated recurrent unit (BiGRU) layer to further enhance the extracted context and semantic features. The experiments were conducted on the Arabic dataset provided by the SemEval 2020 Task 12. The evaluation results show the effectiveness of our model compared to the baseline and related work models by achieving a macro F1-score of 93.16%. © 2024, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Arabic; Bidirectional encoder representations from transformers; Bidirectional gated recurrent unit; Natural language processing; Offensive language detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Zhang202421779,
	author = {Zhang, Jiang and Wu, Qiong and Xu, Yiming and Cao, Cheng and Du, Zheng and Psounis, Konstantinos},
	title = {Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {19},
	pages = {21779 – 21787},
	doi = {10.1609/aaai.v38i19.30178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189642565&doi=10.1609%2faaai.v38i19.30178&partnerID=40&md5=505dc43018b9a4b3b659f0e99e15c46a},
	affiliations = {University of Southern California, Los Angeles, CA, United States; Amazon.com, Inc., Bellevue, WA, United States},
	abstract = {Toxic content detection is crucial for online services to remove inappropriate content that violates community standards. To automate the detection process, prior works have proposed varieties of machine learning (ML) approaches to train Language Models (LMs) for toxic content detection. However, both their accuracy and transferability across datasets are limited. Recently, Large Language Models (LLMs) have shown promise in toxic content detection due to their superior zero-shot and few-shot in-context learning ability as well as broad transferability on ML tasks. However, efficiently designing prompts for LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder their deployments in production. To address these challenges, in this work, we propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling LLMs for toxic content detection. Specifically, we design a novel prompting method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection performance and extract high-quality rationales. DToT can automatically select more fine-grained context to re-prompt LLMs when their responses lack confidence. Additionally, we use the rationales extracted via DToT to fine-tune student LMs. Our experimental results on various datasets demonstrate that DToT can improve the accuracy of LLMs by up to 4.6%. Furthermore, student LMs fine-tuned with rationales extracted via DToT outperform baselines on all datasets with up to 16.9% accuracy improvement, while being more than 60× smaller than conventional LLMs. Finally, we observe that student LMs fine-tuned with rationales exhibit better cross-dataset transferability. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Computational linguistics; Learning systems; Students; Zero-shot learning; Community standards; Content detection; Context learning; Detection process; In contexts; Language model; Learning abilities; Machine learning approaches; On-line service; On-machines; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 38th AAAI Conference on Artificial Intelligence, AAAI 2024; Conference date: 20 February 2024 through 27 February 2024; Conference code: 198370; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rahim20247091,
	author = {Rahim, Nur Umaira Abd and Mustapha, Norwati},
	title = {TRANSFORMER-BASED MODEL WITH CNN AND CAPSNETS TO IMPROVE MALAY HATE SPEECH DETECTION IN TWEETS},
	year = {2024},
	journal = {Journal of Theoretical and Applied Information Technology},
	volume = {102},
	number = {19},
	pages = {7091 – 7102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207448527&partnerID=40&md5=3a5c607b9bf8154e3dcdffe343e29dc7},
	affiliations = {Department of Computer Science, Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Malaysia},
	abstract = {With the rise of social media, the spread of hate speech poses a significant threat to online harmony, especially within the Malay-speaking community. Existing research mainly focuses on high-resource languages like English, leaving a gap in effective HSD for low-resource languages like Malay. Even with a study done in previous research on Malay HSD, there is some room for improvement, and the lack of diverse datasets may significantly affect the system’s overall performance and generalization. Thus, this study proposes a model that uses a transformer-based model named RoBERTa integrated with CNNs and Capsule Networks. RoBERTa is very effective in handling contextual information in bidirectional ways. Experimental results demonstrate that the proposed models, which are RoBERTa, outperform other models in a new dataset in terms of F1-score and accuracy, which are 84.54% and 84.45%, respectively and also outperform the existing dataset, which is 77.67% and 77.45%, respectively. By offering an extensive architecture, this research not only advances the technological area but also tackles social problems by enabling safer online environments for Malay speaker’s communities. Additionally, this research contributes a valuable new Malay Hate Speech dataset, enriching resources for low-resource languages. The results underscore the importance of dataset diversity and advanced NLP techniques in generalizing well across different datasets, making this model practical for real-world applications. Furthermore, this study highlights the global potential of these techniques for improving HSD in other low-resource languages. © Little Lion Scientific.},
	author_keywords = {BERT; Hate Speech Detection; Natural Language Processing; RoBERTa; Transformer; XLNet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yuan2025,
	author = {Yuan, Lanqin and Rizoiu, Marian-Andrei},
	title = {Generalizing Hate Speech Detection Using Multi-Task Learning: A Case Study of Political Public Figures},
	year = {2025},
	journal = {Computer Speech and Language},
	volume = {89},
	doi = {10.1016/j.csl.2024.101690},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199424863&doi=10.1016%2fj.csl.2024.101690&partnerID=40&md5=2adff80917872ac9ad29475b70418a3c},
	affiliations = {University of Technology Sydney, 15 Broadway, Ultimo NSW 2007, Sydney, 2007, Australia},
	abstract = {Automatic identification of hateful and abusive content is vital in combating the spread of harmful online content and its damaging effects. Most existing works evaluate models by examining the generalization error on train–test splits on hate speech datasets. These datasets often differ in their definitions and labeling criteria, leading to poor generalization performance when predicting across new domains and datasets. This work proposes a new Multi-task Learning (MTL) pipeline that trains simultaneously across multiple hate speech datasets to construct a more encompassing classification model. Using a dataset-level leave-one-out evaluation (designating a dataset for testing and jointly training on all others), we trial the MTL detection on new, previously unseen datasets. Our results consistently outperform a large sample of existing work. We show strong results when examining the generalization error in train–test splits and substantial improvements when predicting on previously unseen datasets. Furthermore, we assemble a novel dataset, dubbed PUBFIGS, focusing on the problematic speech of American Public Political Figures. We crowdsource-label using Amazon MTurk more than 20,000 tweets and machine-label problematic speech in all the 305,235 tweets in PUBFIGS. We find that the abusive and hate tweeting mainly originates from right-leaning figures and relates to six topics, including Islam, women, ethnicity, and immigrants. We show that MTL builds embeddings that can simultaneously separate abusive from hate speech, and identify its topics. © 2024 The Authors},
	author_keywords = {Abusive speech; Hate speech; Multi-task learning; Public political figures; Transfer learning},
	keywords = {Automation; Classification (of information); Learning systems; Linearization; Speech recognition; Abusive speech; Automatic identification; Case-studies; Generalization Error; Hate speech; Multitask learning; Public figure; Public political figure; Speech detection; Transfer learning; Statistical tests},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Grotti202465,
	author = {Grotti, Leonardo},
	title = {Italian Linguistic Features for Toxic Language Detection in Social Media},
	year = {2024},
	journal = {Italian Journal of Computational Linguistics},
	volume = {10},
	number = {1},
	pages = {65 – 94},
	doi = {10.4000/125no},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206209574&doi=10.4000%2f125no&partnerID=40&md5=1ea1b2f1535f63be1b57f1748ca47232},
	affiliations = {CLiPS Research Center, Faculty of Arts, Prinsstraat 13, Antwerp, B-2000, Belgium},
	abstract = {This study addresses the urgent issue of toxic language, prevalent on social media platforms, focusing on the detection of toxic comments on popular Italian Facebook pages. We build upon the framework suggested by the LiLaH project: a standardized framework for analyzing hateful content in multiple languages, including Dutch, English, French, Slovene, and Croatian. We start by examining the linguistic features of Italian toxic language on social media. Our analysis reveals that toxic comments in Italian tend to be longer and have fewer unique emojis compared to non-toxic comments, while both exhibit similar lexical diversity. To evaluate the impact of linguistic features on state-of-the-art models’ performance, we fine-tune three pre-trained language models (PoliBERT, UmBERTo, and bert-base-italian-xxl-uncased). Despite their significant correlation with comments’ toxicity, the inclusion of linguistic features worsens the best model’s performance. © 2024 Associazione Italiana di Linguistica Computazionale.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Hebert202422096,
	author = {Hebert, Liam and Sahu, Gaurav and Guo, Yuxuan and Sreenivas, Nanda Kishore and Golab, Lukasz and Cohen, Robin},
	title = {Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {20},
	pages = {22096 – 22104},
	doi = {10.1609/aaai.v38i20.30213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189638874&doi=10.1609%2faaai.v38i20.30213&partnerID=40&md5=df2d5bd276355eb4c438d1647637535d},
	affiliations = {University of Waterloo, Canada},
	abstract = {We present the Multi-Modal Discussion Transformer (mDT), a novel method for detecting hate speech on online social networks such as Reddit discussions. In contrast to traditional comment-only methods, our approach to labelling a comment as hate speech involves a holistic analysis of text and images grounded in the discussion context. This is done by leveraging graph transformers to capture the contextual relationships in the discussion surrounding a comment and grounding the interwoven fusion layers that combine text and image embeddings instead of processing modalities separately. To evaluate our work, we present a new dataset, HatefulDiscussions, comprising complete multi-modal discussions from multiple online communities on Reddit. We compare the performance of our model to baselines that only process individual comments and conduct extensive ablation studies. © 2024, Association for the Advancement of Artifcial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Contextual relationships; Fusion layers; Holistic analysis; Image embedding; Labelings; Multi-modal; Novel methods; On-line communities; Social media; Text images; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 38th AAAI Conference on Artificial Intelligence, AAAI 2024; Conference date: 20 February 2024 through 27 February 2024; Conference code: 198370; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mahajan2024,
	author = {Mahajan, Esshaan and Mahajan, Hemaank and Kumar, Sanjay},
	title = {EnsMulHateCyb: Multilingual hate speech and cyberbully detection in online social media},
	year = {2024},
	journal = {Expert Systems with Applications},
	volume = {236},
	doi = {10.1016/j.eswa.2023.121228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169504870&doi=10.1016%2fj.eswa.2023.121228&partnerID=40&md5=6479af34e864087232e4c79800a0f93d},
	affiliations = {University School of Information, Communication and Technology, Guru Gobind Singh Indraprastha University, Dwarka, New Delhi, India; Department of Applied Mathematics, Delhi Technological University, Main Bawana Road, New Delhi, 110042, India; Department of Computer Science and Engineering, Delhi Technological University, Main Bawana Road, New Delhi, 110042, India},
	abstract = {Nowadays, users across the globe interact with one another for information exchange, communication, and association on various online social media. However, some individuals exploit these venues for malicious practices like hate speech and cyberbully. In this paper, we present an improved multilingual hate speech and cyberbully detection model using bagging-stacking based hybrid ensemble deep learning techniques. The proposed model utilizes Bi-directional Long Short-Term Memory (BiLSTM), Bi-directional Gated Recurrent Unit (Bi-GRU), Convolutional Neural Network (CNN), and Long Short-Term Memory (LSTM) techniques to enhance the overall performance. We first preprocess the multilingual data streams followed by adoption of Global vectors for word Representation (GloVe) embeddings to convert words to a vector representation in parallel enabling the data streams for binary classification task. In order to construct an architecture for the detection of hate speech and cyberbully, we introduce a heterogeneous fusion of multiple effective models in a unique approach such that CNN-LSTM utilizes a stacking approach with stochastic gradient descent to achieve optimal weights, whereas all the base learners used bagging ensemble approach with cross-validation to reach optimal weights. The final output layer of the proposed ensemble deep learning architecture is achieved using a super learner approach on base learners. To show the efficacy of the proposed model, we conduct the simulation on a total of nine real-world social media datasets in different languages and compared the results with other contemporary hate speech and cyberbully detection methods. The collected findings show that the proposed model outperforms other models on considered datasets and shows an improvement of at least 4.44% in F1 scores. © 2023 Elsevier Ltd},
	author_keywords = {Bi-GRU; BiLSTM; Cyberbully detection; Ensemble deep learning; Hate speech detection; Multilingual data streams},
	keywords = {Brain; Computational linguistics; Computer simulation languages; Convolutional neural networks; Gradient methods; Learning systems; Memory architecture; Modeling languages; Network architecture; Optimization; Social networking (online); Speech communication; Speech recognition; Stochastic models; Stochastic systems; Syntactics; Bi-directional; Bi-directional gated recurrent unit; Bi-directional long short-term memory; Cyberbully; Cyberbully detection; Data stream; Ensemble deep learning; Hate speech detection; Multilingual data stream; Speech detection; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Chidambaram20247655,
	author = {Chidambaram, Vivek Alias Meenatchisundaram and Chandrasekaran, Karthik Painganadu},
	title = {F3DNN-Net: behaviours violence detection via fine-tuned fused feature based deep neural network from surveillance video},
	year = {2024},
	journal = {Signal, Image and Video Processing},
	volume = {18},
	number = {11},
	pages = {7655 – 7669},
	doi = {10.1007/s11760-024-03418-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202476070&doi=10.1007%2fs11760-024-03418-4&partnerID=40&md5=37013e5bc2aa866f18ce3373d0307fec},
	affiliations = {Department of Data Science and Business Systems, School of Computing, SRM Institute of Science and Technology, Tamilnadu, Kattankulathur, India},
	abstract = {Detecting violence in images has emerged as an important area of research and application as digital imaging and computer vision advance. Detecting and assessing violent content automatically in visual data holds great promise for enhancing public safety, security, and content moderation. Violent incidents are difficult to detect because of disruptions in optical flow, complications caused by camera aperture variations, and difficulties with illumination and feature tracking. In this work, a novel F3DNN-Net has been proposed for violence detection in images. The input videos from the surveillance camera are initially converted into frame sequences and pre-processed. The Yolov8 (You Only Look Once) algorithm is employed to detect objects within pre-processed frames. Simultaneously, the ego algorithm is applied to the pre-processed images for motion estimation, ensuring comprehensive coverage of information. Afterwards, the features are extracted using the fined feature extraction phase as independent component analysis (ICA), and the selected features are selected using the Dingo algorithm. Then, the fine-tuned fused (FF) features are implemented in the deep neural network (DNN) approach for the categorization of violent and non-violent cases. According to the findings, the proposed F3DNN-Net detects violence in images with an accuracy rate of 99.33%. The proposed DNN enhances an overall F1-score of 10.46%, 6.91%, and 4.44%, better than Alex Net, ResNet, and Dense Net. The proposed F3DNN-Net enhances the overall accuracy by 6%, 0.3%, and 29.33% better than Inception-Resnet-V2, CNN, LSTM, and ResNet50, respectively. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.},
	author_keywords = {Deep learning; Deep neural network; Independent component analysis; Violence detection; YOLOV8},
	keywords = {Deep neural networks; Image enhancement; Motion estimation; Network security; Deep learning; Digital imaging; Feature-based; Independent components analysis; Neural-networks; Research and application; Surveillance video; Violence detections; Visual data; YOLOV8; Optical flows},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhu2025249,
	author = {Zhu, Jian and Ruan, Yuping and Chang, Jingfei and Sun, Wenhui and Wan, Hui and Long, Jian and Luo, Cheng},
	title = {Deep Prompt Multi-task Network for Abuse Language Detection},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15301 LNCS},
	pages = {249 – 263},
	doi = {10.1007/978-3-031-78107-0_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211904146&doi=10.1007%2f978-3-031-78107-0_16&partnerID=40&md5=556d91d1948d913d7cabc780fea19778},
	affiliations = {Zhejiang Lab, Hangzhou, China},
	abstract = {The detection of abuse language remains a long-standing challenge with the extensive use of social networks. The detection task of abuse language suffers from limited accuracy. We argue that the existing detection methods utilize the fine-tuning technique of the pre-trained language models (PLMs) to handle downstream tasks. Hence, these methods fail to stimulate the general knowledge of the PLMs. To address the problem, we propose a novel Deep Prompt Multi-task Network (DPMN) for abuse language detection. Specifically, DPMN first attempts to design two forms of deep prompt tuning and light prompt tuning for the PLMs. The effects of different prompt lengths, tuning strategies, and prompt initialization methods on detecting abuse language are studied. In addition, we propose a Task Head based on Bi-LSTM and FFN, which can be used as a short text classifier. Eventually, DPMN utilizes multi-task learning to improve detection metrics further. The multi-task network has the function of transferring effective knowledge. The proposed DPMN is evaluated against eight typical methods on three public datasets: OLID, SOLID, and AbuseAnalyzer. The experimental results show that our DPMN outperforms the state-of-the-art methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Abuse Language Detection; Deep Prompt Tuning; Multi-task Network; Prompt-based Learning},
	keywords = {Classification (of information); Economic and social effects; Problem oriented languages; Social networking (online); Abuse language detection; Deep prompt tuning; Detection methods; Detection tasks; Language detection; Language model; Multi tasks; Multi-task network; Prompt-based learning; Task networks; Multi-task learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 27th International Conference on Pattern Recognition, ICPR 2024; Conference date: 1 December 2024 through 5 December 2024; Conference code: 323679}
}

@CONFERENCE{Lee20241667,
	author = {Lee, Kyuhan and Ram, Sudha},
	title = {Deep Learning for Hate Speech Detection: A Personality-based Approach},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {1667 – 1671},
	doi = {10.1145/3589335.3652502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194492717&doi=10.1145%2f3589335.3652502&partnerID=40&md5=5705e73a4f1f787aaea5938ce01807a0},
	affiliations = {Korea University Business School, Seoul, South Korea; University of Arizona, Tucson, AZ, United States},
	abstract = {A crucial element in the combat against hate speech is the development of efficient algorithms for automatically detecting hate speech. Previous research, however, has primarily neglected important insights from the field of psychology literature, particularly the relationship between personality and hate, resulting in suboptimal performance in hate speech detection. To this end, we propose a novel framework for detecting hate speech focusing on people’s personality factors reflected in their writing. Our framework has two components: (i) a knowledge distillation model for fully automating the process of personality inference from text and (ii) a personality-based deep learning model for hate speech detection. Our approach is unique in that it incorporates low-level personality factors, which have been largely neglected in prior literature, into automated hate speech detection and proposes novel deep learning components for fully exploiting the intricate relationship between personality and hate (i.e., intermediate personality factors). The evaluation shows that our model significantly outperforms state-of-the-art baselines. Our study paves the way for future research by incorporating personality aspects into the design of automated hate speech detection. In addition, it offers substantial assistance to online social platforms and governmental authorities facing challenges in effectively moderating hate speech. © 2024 Copyright is held by the owner/author(s).},
	author_keywords = {deep learning; hate speech detection; personality},
	keywords = {Deep learning; Speech recognition; Deep learning; Governmental authorities; Hate speech detection; Learning models; Personality; Speech detection; State of the art; Sub-optimal performance; Two-component; Distillation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 33rd ACM Web Conference, WWW 2024; Conference date: 13 May 2024 through 17 May 2024; Conference code: 199461; All Open Access, Hybrid Gold Open Access}
}@CONFERENCE{Hou2024800,
	author = {Hou, Boyuan and Xie, Xin and Zhang, Dongcheng and Zheng, Liyuan and Yan, Guojun},
	title = {Chinese Offensive Language Detection Algorithm based on Pre-trained Language model and Pointer Network Augmentation},
	year = {2024},
	journal = {2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2024},
	pages = {800 – 805},
	doi = {10.1109/AINIT61980.2024.10581762},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199136105&doi=10.1109%2fAINIT61980.2024.10581762&partnerID=40&md5=45a3726c731d5fa0d30cbd0310b63749},
	affiliations = {Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China},
	abstract = {The traditional offensive language detection methods suffer from issues such as inadequate understanding of semantic information and sensitivity to noise in text. To address these problems, this paper proposes a Chinese offensive language detection algorithm based on a pre-trained language model and augmented with a pointer network. Firstly, the algorithm incorporates task prompt information into the text using the prompt layer. Then, it feeds the integrated text with task prompt information into the pre-trained language model RoBERTa to extract deep semantic information and obtain a semantic vector. Subsequently, the generated semantic vector is inputted into the focus layer of the pointer network to obtain a focus vector that strongly relates to offensive language. Finally, by concatenating the semantic vector and focus vector, they are passed through a classification layer for text classification and determining whether it contains offensive language. Experimental results on the Chinese offensive language dataset COLD demonstrate that our proposed method outperforms mainstream methods significantly in terms of detection effectiveness. © 2024 IEEE.},
	author_keywords = {offensive language detection; Pointer network; Pre-trained language models},
	keywords = {Computational linguistics; Semantics; Signal detection; Text processing; Vectors; Detection algorithm; Language detection; Language model; Network augmentation; Offensive language detection; Offensive languages; Pointer network; Pre-trained language model; Semantic vectors; Semantics Information; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2024; Conference date: 29 May 2024 through 31 May 2024; Conference code: 200991}
}

@ARTICLE{Ahuja2024285,
	author = {Ahuja, Garvita and Vij, Sonakshi and Virmani, Deepali},
	title = {Advancements in Hate Speech Detection: A Comprehensive Analysis of NLP Models and Techniques},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1020 LNNS},
	pages = {285 – 293},
	doi = {10.1007/978-981-97-3588-4_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200668167&doi=10.1007%2f978-981-97-3588-4_24&partnerID=40&md5=a434f998e7917e86ec2d1cb165aea269},
	affiliations = {Vivekananda Institute of Professional Studies—Technical Campus, Delhi, India},
	abstract = {In today’s digitally connected world, the proliferation of hate speech and the amplifying of prejudices through online social networks are serious concerns. Expressions of hate, which target individuals or groups based on a range of qualities, pose major societal problems. In this study, we specifically focus on Twitter to identify hate speech in online social networks. We use a publicly available dataset on Hugging Face. We examine state-of-the-art techniques for identifying offensive speech, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Bidirectional Long Short-Term Memory networks (BiLSTMs), XGBoost, and Support Vector Machines (SVMs), in order to solve this. We use a dataset of 85 K tweets to study the designs, performances, and ethical concerns of these models. Our extensive research strives to mitigate the negative consequences of hateful speech on social media platforms. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Hate speech detection; Natural Language Processing; Online social networks},
	keywords = {Natural language processing systems; Recurrent neural networks; Speech recognition; Support vector machines; Comprehensive analysis; Group-based; Hate speech detection; Individual-based; Language processing; Natural language processing; Natural languages; Societal problems; Speech detection; State-of-the-art techniques; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Innovative Computing and Communications, ICICC 2024; Conference date: 16 February 2024 through 17 February 2024; Conference code: 316009}
}

@CONFERENCE{Zhang202412073,
	author = {Zhang, Min and He, Jianfeng and Ji, Taoran and Lu, Chang-Tien},
	title = {Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {12073 – 12086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204430017&partnerID=40&md5=fe704d4feabdb19f68538a92d767f66a},
	affiliations = {Virginia Tech, United States; Texas A&M University-Corpus Christi, United States},
	abstract = {The fairness and trustworthiness of Large Language Models (LLMs) are receiving increasing attention. Implicit hate speech, which employs indirect language to convey hateful intentions, occupies a significant portion of practice. However, the extent to which LLMs effectively address this issue remains insufficiently examined. This paper delves into the capability of LLMs to detect implicit hate speech (Classification Task) and express confidence in their responses (Calibration Task). Our evaluation meticulously considers various prompt patterns and mainstream uncertainty estimation methods. Our findings highlight that LLMs exhibit two extremes: (1) LLMs display excessive sensitivity towards groups or topics that may cause fairness issues, resulting in misclassifying benign statements as hate speech. (2) LLMs' confidence scores for each method excessively concentrate on a fixed range, remaining unchanged regardless of the dataset's complexity. Consequently, the calibration performance is heavily reliant on primary classification accuracy. These discoveries unveil new limitations of LLMs, underscoring the need for caution when optimizing models to ensure they do not veer towards extremes. This serves as a reminder to carefully consider sensitivity and confidence in the pursuit of model fairness. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Calibration tasks; Classification accuracy; Classification tasks; Confidence score; Estimation methods; Language model; Performance; Speech classification; Speech detection; Uncertainty estimation; Calibration},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202222}
}

@ARTICLE{Kalyan2024144,
	author = {Kalyan, Kakollu Pavan and Naveen, Valiveti and Vani, V. and Karthik, N.},
	title = {Offensive Language Detection on Telugu Language},
	year = {2024},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {717 IFIPAICT},
	pages = {144 – 155},
	doi = {10.1007/978-3-031-69982-5_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207651006&doi=10.1007%2f978-3-031-69982-5_11&partnerID=40&md5=2bd08154db5e37d3a3a65fb918658afc},
	affiliations = {Department of Computer Science and Engineering, National Institute of Technology Puducherry, Karaikal, India},
	abstract = {In the present world a lot of data is generated via twitter, Instagram, WhatsApp etc. in different languages. It is important and necessary task to detect the offensive language among those data to create healthy and good environment among people. And it is even highly challenging task to identify offensive language in low resource languages due to less availability of the classified datasets. This paper aims to detecting of offensive language on a low resource language Telugu. To identify solution for this problem different types of ML models and DL models are used. Based on accuracy of the different models we are going to choose a model. To split the data and train the data and to test the data we have been using stratified k fold cross validation which is an efficient way to split the data and to increase model’s ability to perform better. From basis of this experiments, we can have a model to detect offensive language in Telugu and it must be considered as a small step for future models to work on it. © IFIP International Federation for Information Processing 2024.},
	author_keywords = {Deep learning; High resource; Low resource; Machine learning; Offensive language; Smote; Stratified k fold cross validation},
	keywords = {Adversarial machine learning; Economic and social effects; Deep learning; High resource; K fold cross validations; Language detection; Low resource; Low resource languages; Machine-learning; Offensive languages; Smote; Stratified k fold cross validation; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th IFIP TC 12 International Conference on Computational Intelligence in Data Science, ICCIDS 2024; Conference date: 21 February 2024 through 23 February 2024; Conference code: 321159}
}

@CONFERENCE{Janardhan2024270,
	author = {Janardhan, G. and Saikiran, Bollu and Reddy, InugalaSwanith and Abhishek, Mogilicherla},
	title = {Twitter Hate Speech Detection using Machine Learning},
	year = {2024},
	journal = {Proceedings - 2024 4th International Conference on Pervasive Computing and Social Networking, ICPCSN 2024},
	pages = {270 – 278},
	doi = {10.1109/ICPCSN62568.2024.00051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201723507&doi=10.1109%2fICPCSN62568.2024.00051&partnerID=40&md5=8f4ddc700bf418780fbd166b2603cb4b},
	affiliations = {Vignan Institute of Technology and Science, Telangana State, Hyderabad, India; Vignan Institute of Technology and Science, Telangana State, Hyderabad, India},
	abstract = {There is an unprecedented rise in hate speech on social media sites like Twitter in recent times. This widespread problem affects users, leads to problems in the real world, and makes it hard to moderate material. This study aims to find good ways to find hate speech so that it doesn't have as much of an effect on online groups and other places. By using cutting-edge algorithms, the project takes a thorough method to finding hate speech. To make a strong and flexible hate speech recognition system, machine learning models and deep learning methods are used. To make sure accuracy and dependability, model performance is carefully checked using a variety of measures. Accuracy, precision, recall, and F1 score are the common measures used here to show how well the model can correctly spot cases of hate speech. a measure of its general selective power that shows how well it works at different levels. As the project comes to a close, the thorough review of hate speech recognition models has given us useful information. Even though progress has been made, problems still exist, especially when it comes to dealing with changing speaking trends on social media. The study shows how important it is to keepresearching and developing ways to find hate speech. This will helpmake content management better in the future, which will make the internet safer. A strong ensemble method called the stacking classifier is also used as part of the hate speech recognition model. It achieves an amazing 100% success. In addition, the Hybrid Approach, which used both LSTM and BiGRU models, showed an impressive 94% accuracy. A front end was built using the Flask framework to make testing easier for people. It has login features to make the Twitter Hate Speech Detection system safer and more trustworthy. This makes sure that users have a smooth and reliable way to rate how well the model finds and stops hate speech on Twitter. © 2024 IEEE.},
	author_keywords = {automatic detection; classification; Hate speech; natural language processing; social media; systematic review; twitter},
	keywords = {Adversarial machine learning; Automatic Detection; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Recognition models; Social media; Speech detection; Systematic Review; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Pervasive Computing and Social Networking, ICPCSN 2024; Conference date: 3 May 2024 through 4 May 2024; Conference code: 201477}
}

@ARTICLE{Abazari Kia202449,
	author = {Abazari Kia, Mahsa and Samiee, Dorsa and Pournajar, Nasrin},
	title = {A Generalizable Context-Aware Deep Learning Model for Abusive Language Detection},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15022 LNCS},
	pages = {49 – 63},
	doi = {10.1007/978-3-031-72350-6_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205308366&doi=10.1007%2f978-3-031-72350-6_4&partnerID=40&md5=6b904ad65423877e722387cdb942e526},
	affiliations = {Northeastern University London, London, United Kingdom; Royal Holloway University of London, Egham, United Kingdom; Isfahan University of Technology, Isfahan, Iran},
	abstract = {The proliferation of abusive language and hate speech in online content has become a pressing societal concern, necessitating effective detection methods. Recent years have witnessed a surge in datasets and computational methods for detecting abusive language, reflecting the growing interest in combating online abuse. Deep learning, in particular, has emerged as a powerful tool for addressing this pervasive issue. This paper presents a novel context-aware, attention-based Bidirectional Long Short-Term Memory (Bi-LSTM) model that relies exclusively on textual features. The model is designed for robust detection of abusive language. The proposed model integrates a domain-specific language model, HateBERT, with stacked Bi-LSTM and attention mechanism to enhance the processing capabilities of neural networks, enabling nuanced understanding of abusive language patterns. The versatility of the model is demonstrated through experiments on diverse abuse categories, showcasing its ability to effectively classify various types of abuse. The paper compares the model with existing state-of-the-art approaches and the findings underscore the potential of deep learning-based models in addressing the pervasive issue of online abusive behavior. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Abusive language; BERT; Contextual attention; long short-term memory (LSTM) networks; Social media analysis; Toxic comments},
	keywords = {Adversarial machine learning; Long short-term memory; Abusive language; BERT; Context-Aware; Contextual attention; Learning models; Long short-term memory  network; Memory network; Short term memory; Social media analysis; Toxic comment; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 33rd International Conference on Artificial Neural Networks, ICANN 2024; Conference date: 17 September 2024 through 20 September 2024; Conference code: 319199}
}

@ARTICLE{Awajan202477,
	author = {Awajan, Arafat A.},
	title = {Offensive Language Detection from Arabic Texts},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1018 LNNS},
	pages = {77 – 91},
	doi = {10.1007/978-3-031-62269-4_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199526710&doi=10.1007%2f978-3-031-62269-4_6&partnerID=40&md5=fad70027013725f7f89686357176b866},
	affiliations = {King Hussein School for Computing Sciences, Princess Sumaya University for Technology, Amman, Jordan},
	abstract = {Detecting offensive language (OL) in social media platforms has become an important task for researchers in natural language processing and understanding. Despite emerging research and efforts to address this problem in many languages, more efforts are still needed to improve the performance of OL detection in Arabic-language contexts. This work investigates the state of the art for both the English and Arabic languages, studies the research communities’ different proposed approaches, and compares their performances. We present new approaches to the use of word-embedding models, where each word has two representations: the first representation describes the target word’s context in offensive texts, while the second represents the context of the word in non-offensive texts. The primary results are promising, with a precision reaching an average of 65% of the detection of OL and around 71% for the identification of non-offensive language. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Arabic NLP; Conflictual language detection; Offensive language; Word embedding models},
	keywords = {Natural language processing systems; Arabic languages; Arabic NLP; Arabic texts; Conflictual language detection; Embeddings; Language detection; Offensive languages; Performance; Social media platforms; Word embedding model; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Science and Information Conference, SAI 2024; Conference date: 11 July 2024 through 12 July 2024; Conference code: 313889}
}

@BOOK{Pendzel202454,
	author = {Pendzel, Sagi and Wullach, Tomer and Adler, Amir and Minkov, Einat},
	title = {Generative AI for Hate Speech Detection: Evaluation and Findings},
	year = {2024},
	journal = {Regulating Hate Speech Created by Generative Ai},
	pages = {54 – 76},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199171514&partnerID=40&md5=27cd70af2bc822db0ace3404db3c896a},
	affiliations = {University of Haifa, Israel; OriginAI, United States; Braude College of Engineering, Israel; Massachusetts Institute of Technology, United Kingdom},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Paval2024,
	author = {Paval, K.S. and Radhakrishnan, Vishnu and Krishnan, K.M. and Lal, G Jyothish and Premjith, B.},
	title = {Multimodal Fusion for Abusive Speech Detection Using Liquid Neural Networks and Convolution Neural Network},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724438},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211105616&doi=10.1109%2fICCCNT61001.2024.10724438&partnerID=40&md5=e21429a406caea9c0531175208a719b2},
	affiliations = {Amrita Vishwa Vidyapeetham, Amrita School of Artificial Intelligence, Tamil Nadu, Coimbatore, India},
	abstract = {The recent surge in the use of social media has created vast spaces for viral content that attracts attention of large crowds. This has paved the way to the misuse of these platforms making them breading grounds for toxicity and harassment. Hence there is a need for effective abuse detection methods. In our research, we leverage the ADIMA dataset to investigate abuse detection methodologies, aiming to enhance the effectiveness of existing systems. We propose a multimodal, multilingual abuse detection system that includes three main aspects: the utilization of multimodal fusion techniques for abuse detection, the application of Liquid Neural Networks (LNN) in identifying abusive text content, the use of Convolutional Neural Networks (CNN) in identifying abusive audio utterances and the extension of multimodal fusion abuse detection to cross-lingual settings. This enabled our system to detect abuses in 10 Indian languages. Our approach takes the existing works a step further as it is able to accommodate multiple modalities and multiple languages. We use Convolutional Neural Networks to analyze sound patterns from melspectrograms and Liquid Neural Networks to process text information. To consolidate the strengths of both the representation, late fusion is applied to combine the results, resulting in an ensemble model which achieves an accuracy of 77.47%, and an AUC of 77.89% on the multilingual test set.  © 2024 IEEE.},
	author_keywords = {Abuse-Detection; Abusive Speech; Convolutional Neural Networks; Late Fusion; Liquid Neural Networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@CONFERENCE{Svetasheva20246898,
	author = {Svetasheva, Arina and Lee, Keeheon},
	title = {Harnessing Large Language Models for Effective and Efficient Hate Speech Detection},
	year = {2024},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	pages = {6898 – 6907},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199778233&partnerID=40&md5=e5baaa4a7dcc850a2878ea036139c5e3},
	affiliations = {Yonsei University, South Korea},
	abstract = {Hate speech presents a growing concern within online communities, posing threats to marginalized groups and undermining ethical norms. Although automatic hate speech detection (AHSD) methods have shown promise, there is still room for improvement. Recent advancements in Language Model Pretraining, exemplified by the introduction of ChatGPT-4, bring forth new possibilities for enhancing classification. In this study, we propose leveraging synthetic data generation to improve hate speech detection. Our findings demonstrate the effectiveness and efficiency of this approach in rapidly improving model performance, particularly in scenarios where obtaining sufficient amounts of hate speech data is challenging. Through our research, we establish that Large Language Models (LLMs) can proficiently serve as both data generators and annotators in the desired format, exhibiting performance comparable to, and even surpassing, that of humans. Moreover, we validate the applicability of LLMs in domains characterized by complex and highly abbreviated lexicons, such as the gaming industry. © 2024 IEEE Computer Society. All rights reserved.},
	author_keywords = {ChatGPT; Hate speech detection; Online toxicity; Synthetic datasets},
	keywords = {Computational linguistics; Large datasets; ChatGPT; Detection methods; Hate speech detection; Language model; On-line communities; Online toxicity; Pre-training; Speech detection; Synthetic data generations; Synthetic datasets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 57th Annual Hawaii International Conference on System Sciences, HICSS 2024; Conference date: 3 January 2024 through 6 January 2024; Conference code: 201047}
}

@ARTICLE{Matei2024317,
	author = {Matei, Vlad-Cristian and Tăiatu, Iulian-Marius and Smădu, Răzvan-Alexandru and Cercel, Dumitru-Clementin},
	title = {Enhancing Romanian Offensive Language Detection Through Knowledge Distillation, Multi-task Learning, and Data Augmentation},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14762 LNCS},
	pages = {317 – 332},
	doi = {10.1007/978-3-031-70239-6_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205363370&doi=10.1007%2f978-3-031-70239-6_22&partnerID=40&md5=7cf9cda2cc9c7c0bf9c2dae71fd520e0},
	affiliations = {Faculty of Automatic Control and Computers, National University of Science and Technology POLITEHNICA Bucharest, Bucharest, Romania},
	abstract = {This paper highlights the significance of natural language processing (NLP) within artificial intelligence, underscoring its pivotal role in comprehending and modeling human language. Recent advancements in NLP, particularly in conversational bots, have garnered substantial attention and adoption among developers. This paper explores advanced methodologies for attaining smaller and more efficient NLP models. Specifically, we employ three key approaches: (1) training a Transformer-based neural network to detect offensive language, (2) employing data augmentation and knowledge distillation techniques to increase performance, and (3) incorporating multi-task learning with knowledge distillation and teacher annealing using diverse datasets to enhance efficiency. The culmination of these methods has yielded demonstrably improved outcomes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Data Augmentation; Knowledge Distillation; Multi-Task Learning; Offensive Language},
	keywords = {Adversarial machine learning; Contrastive Learning; Modeling languages; Natural language processing systems; Data augmentation; Human language; Knowledge distillation; Language detection; Language processing; Multitask learning; Natural languages; Offensive languages; Processing model; Romanians; Multi-task learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 29th International Conference on Natural Language and Information Systems, NLDB 2024; Conference date: 25 June 2024 through 27 June 2024; Conference code: 319819}
}

@CONFERENCE{Maqbool2024321,
	author = {Maqbool, Fariha and Spahiu, Blerina and Maurino, Andrea},
	title = {Impact of Data Augmentation on Hate Speech Detection in Roman Urdu},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3741},
	pages = {321 – 330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202057651&partnerID=40&md5=8b3e91a3b5b9b93ca129714e3270d1a9},
	affiliations = {Dipartimento di Informatica, Sistemistica e Comunicazione, University of Milano-Bicocca, Viale Sarca 336, Milan, 20126, Italy},
	abstract = {The prevalence of hate speech leads to an increase in hate crimes, online violence, and serious harm to social safety, physical security, and cyberspace. To address this issue, several studies have been conducted on hate speech detection in European languages, whereas little attention has been paid to low-resource South Asian languages, making social media vulnerable for millions of users. Due to the scarcity of the datasets and the samples available, there is a need to apply some strategies to increase the data samples. In this paper, we improved the performance of the already fine-tuned m-Bert model by applying data augmentation techniques to one of the datasets on hate speech on tweets in Roman Urdu language. F1-score and accuracy matrix have been used to compare the results. We also experiment to determine the optimal percentage of augmented data to be included and the percentage of words augmented in each instance of data. The new RUHSOLD++ Dataset containing the augmented data has also been published publicly. The improvement in hate speech detection of the model proved that the performance of the models can be improved by applying data augmentation techniques to the dataset with a limited number of instances. © 2024 Copyright for this paper by its authors.},
	keywords = {Speech recognition; Augmentation techniques; Cyberspaces; Data augmentation; Data sample; European languages; Performance; Physical security; Social media; South Asian languages; Speech detection; Spatio-temporal data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 32nd Italian Symposium on Advanced Database Systems, SEBD 2024; Conference date: 23 June 2024 through 26 June 2024; Conference code: 201761}
}

@CONFERENCE{Hendrawan2024275,
	author = {Hendrawan, Rahmat and Hana, Karimah Mutisari and Kurniati, Angelina Prima},
	title = {Enhancing Indonesian Abusive Language Detection on Imbalanced News Comment Dataset Using Support Vector Machine with Oversampling},
	year = {2024},
	journal = {Proceeding - 2024 International Conference on Information Technology Research and Innovation, ICITRI 2024},
	pages = {275 – 280},
	doi = {10.1109/ICITRI62858.2024.10699029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207043316&doi=10.1109%2fICITRI62858.2024.10699029&partnerID=40&md5=d06291014129179bb446f18df516ce23},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {The growth of the internet facilitates ease of interaction and communication, including in the online news platforms with their comment sections. However, this phenomenon triggers the emergence of the online disinhibition effect, leading individuals to exhibit more aggressive behavior on the internet (toxic disinhibition). This has resulted in the prevalence of abusive language in online news comment sections, posing risks to the other readers and the subjects targeted by the abusive comments. In the context of abusive language detection, comments can be categorized into three classes, i.e., not abusive, abusive but not offensive, and abusive and offensive. Therefore, this study conducts a multiclass classification of Indonesian online news comments with those three categories. Experimental results indicate that SVM with word unigram TF-IDF serves as the best baseline classification model with a macro-average F1-score of 45.37%. We compared Easy Data Augmentation (EDA) and Synthetic Minority Oversampling Technique (SMOTE) to address the issue of extreme imbalance in the dataset. The results show that SMOTE outperforms EDA with a macro-average F1-score of 51.45% (an increase of 6.08% from baseline classification), while EDA achieves a macro-average F1-score of 49.83%. The random deletion (RD) operation was chosen for EDA, as other operations tended to decrease its performance. One drawback of EDA is the lack of a corpus for finding similar words. On the other hand, the classification results using SMOTE improve the generalization of the model more effectively. However, some issues persist, such as the abundance of Out of Vocabulary (OOV) occurrences leading to misclassification.  © 2024 IEEE.},
	author_keywords = {abusive language detection; news comment dataset; oversampling; support vector machine},
	keywords = {Economic and social effects; Abusive language detection; Data augmentation; Disinhibition; F1 scores; Language detection; News comment dataset; Online news; Over sampling; Support vectors machine; Synthetic minority over-sampling techniques; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Conference on Information Technology Research and Innovation, ICITRI 2024; Conference date: 5 September 2024 through 6 September 2024; Conference code: 203096}
}

@CONFERENCE{Prudhvish2024,
	author = {Prudhvish, N. and Nagarajan, G. and Bharath Kumar, U. and Vardhan B, Harsha and Tharun Kumar, L.},
	title = {DeTox: A WebApp for Toxic Comment Detection and Moderation},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204441946&doi=10.1109%2fTQCEBT59414.2024.10545229&partnerID=40&md5=6313b0383f12307c01c77a8806fdc74c},
	affiliations = {Kalasalingam Academy of Research and Education, School of Computer Science and Engineering, Krishnankoil, India},
	abstract = {The extensive adoption of internet platforms such as YouTube has transformed communication and information exchange, compelling people to share their opinions and participate in global conversations. Open communication can, however, also encourage the spread of offensive material, such as remarks that are derogatory or involve threats or hate speech. Such offensive remarks have the potential to damage users' mental health by fostering a hostile and unsafe environment that discourages meaningful relationships. We introduce DeTox, a web application that uses machine learning techniques to detect and eliminate harmful comments from YouTube videos in order to address this problem. For the purpose of classifying comments, DeTox uses ML and DL models, which guarantees precise identification of harmful content. The YouTube Data API is integrated by the system to retrieve comments from specific videos and eliminate any harmful remarks found. A detailed examination of the Toxic Comment Classification Challenge dataset, made available by Kaggle, was necessary for the development of DeTox. To find common patterns in hazardous language, preprocessing and examination of the data were done in order to examine the distribution of toxic and non-toxic remarks. FastAPI is a high-level Python web framework that makes web application development easier and is used by the DeTox online application. The application includes a user friendly interface for creating accounts, logging in, and selecting videos to moderate. The application also includes a user interface for reviewing toxic comments and choosing to remove or keep them. DeTox is a valuable tool for moderating comments on YouTube videos. The application utilizes a machine learning model to accurately identify toxic comments, and it provides a vi user-friendly interface for removing or keeping the comments. DeTox has the potential to make YouTube a more friendly and safe environment for users.  © 2024 IEEE.},
	author_keywords = {API; BERT; Machine Learning; Toxic comments; YOUTUBE},
	keywords = {Adversarial machine learning; Websites; API; BERT; Information exchanges; Machine-learning; Mental health; Open communication; Toxic comment; User friendly interface; WEB application; YouTube; Detoxification},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2024; Conference date: 22 March 2024 through 23 March 2024; Conference code: 202352}
}

@CONFERENCE{Ahn202410444,
	author = {Ahn, Hyeseon and Kim, Youngwook and Kim, Jungin and Han, Yo-Sub},
	title = {SHAREDCON: Implicit Hate Speech Detection using Shared Semantics},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {10444 – 10455},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205317633&partnerID=40&md5=f897509d05a12fb9f787034121fc2981},
	affiliations = {Yonsei University, Seoul, South Korea; KT, Seoul, South Korea},
	abstract = {The ever-growing presence of hate speech on social network services and other online platforms not only fuels online harassment but also presents a growing challenge for hate speech detection. As this task is akin to binary classification, one of the promising approaches for hate speech detection is the utilization of contrastive learning. Recent studies suggest that classifying hateful posts in just a binary manner may not adequately address the nuanced task of detecting implicit hate speech. This challenge is largely due to the subtle nature and context dependency of such pejorative remarks. Previous studies proposed a modified contrastive learning approach equipped with additional aids such as human-written implications or machine-generated augmented data for better implicit hate speech detection. While this approach can potentially enhance the overall performance by its additional data in general, it runs the risk of overfitting as well as heightened cost and time to obtain. These drawbacks serve as motivation for us to design a methodology that is not dependent on human-written or machine-generated augmented data for training. We propose a straightforward, yet effective, clustering-based contrastive learning approach that leverages the shared semantics among the data. © 2024 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Latent semantic analysis; Semantics; Speech recognition; Binary classification; Clusterings; Context dependency; Learning approach; Online platforms; Overfitting; Performance; Social network services; Speech detection; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Findings of the 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202475}
}

@ARTICLE{Tanyel2024829,
	author = {Tanyel, Toygar and Alkurdi, Besher and Ayvaz, Serkan},
	title = {Developing linguistic patterns to mitigate inherent human bias in offensive language detection},
	year = {2024},
	journal = {Turkish Journal of Electrical Engineering and Computer Sciences},
	volume = {32},
	number = {6},
	pages = {829 – 848},
	doi = {10.55730/1300-0632.4105},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210904135&doi=10.55730%2f1300-0632.4105&partnerID=40&md5=54ea7c88c35d9e71a9496c361953c660},
	affiliations = {Department of Computer Engineering, Yıldız Technical University, İstanbul, Turkey; Department of Biomedical Engineering, Istanbul Technical University, İstanbul, Turkey; Centre for Industrial Software, Maersk McKinney Moeller Institute, University of Southern Denmark, Sonderborg, Denmark},
	abstract = {With the proliferation of social media, there has been a sharp increase in offensive content, particularly targeting vulnerable groups, exacerbating social problems such as hatred, racism, and sexism. Detecting offensive language use is crucial to prevent offensive language from being widely shared on social media. However, the accurate detection of irony, implication, and various forms of hate speech on social media remains a challenge. Natural language-based deep learning models require extensive training with large, comprehensive, and labeled datasets. Unfortunately, creating such datasets manually is both costly and error-prone. Additionally, the presence of human-bias in offensive language datasets is a major concern for deep learning models. In this paper, we propose a linguistic data augmentation approach to reduce bias in labeling processes, which aims to mitigate the influence of human bias by leveraging the power of machines to improve the accuracy and fairness of labeling processes. This approach has the potential to improve offensive language classification tasks across multiple languages and reduce the prevalence of offensive content on social media. © TÜBİTAK.},
	author_keywords = {contextual models; data mining; data-augmentation; deep learning; linguistics; Offensive language},
	keywords = {Adversarial machine learning; Data mining; Deep learning; Federated learning; Labeled data; Linguistics; Contextual modeling; Data augmentation; Deep learning; Human bias; Labelings; Language detection; Learning models; Linguistic patterns; Offensive languages; Social media; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Roy20241,
	author = {Roy, Pradeep Kumar},
	title = {MMFFHS: Multi-Modal Feature Fusion for Hate Speech Detection on Social Media},
	year = {2024},
	journal = {IEEE Transactions on Big Data},
	pages = {1–12},
	doi = {10.1109/TBDATA.2024.3445372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201765813&doi=10.1109%2fTBDATA.2024.3445372&partnerID=40&md5=71e21f206243a176cc5c93788d9680c7},
	affiliations = {Indian Institute of Information Technology Surat, Gujarat, India},
	abstract = {Millions of users are active on social networking platforms like Facebook, YouTube, Twitter, and others to access information related to the news, entertainment, or sharing life events with peers. These platforms are intermediate channels for spreading rumors, posting hate speech, bullying, etc. Hate speech is one that frequently appears on social media platforms nowadays. Hate speech sometimes impairs readers&#x0027; mental and emotional health and societal order, even encouraging suicide. Therefore, timely detection is required to prevent the spread of hate speech posts on social media platforms. The researchers have reported some research works on textual hate speech detection. However, social media posts are not limited to text; images and text with images are also used in the posts, termed multimodal data. The text-based model is not sufficient to handle the multimodal data. Therefore, this study introduces a reliable architecture that utilizes deep learning and transfer learning capabilities to classify multimodal social media posts into hate and non-hate. The proposed model is compatible with text, images, and images with text-based social posts to categorize hate and non-hate social media posts. The feature-fusion-based MMFFHS proposed framework performed better than the existing models by achieving 70.26&#x0025; accuracy IEEE},
	author_keywords = {Blogs; Deep learning; Deep Learning; Feature extraction; Hate Speech; Hate speech; Multi-modal; Social Network; Social networking (online); Training; Transfer learning; Transfer Learning},
	keywords = {Active learning; Contrastive Learning; Deep learning; Features extraction; Hate speech; Multi-modal; Social network; Social networking (online); Social-networking; Transfer learning; Tweets},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Senthilkumar2024,
	author = {Senthilkumar, K. and Sathiyabama, S. and Ayyamuthukumar, D.},
	title = {Hate Speech Detection Using Enhanced Recurrent Neural Network Based on Elephant Herding Optimization on Social Media},
	year = {2024},
	journal = {2024 3rd International Conference on Electrical, Electronics, Information and Communication Technologies, ICEEICT 2024},
	doi = {10.1109/ICEEICT61591.2024.10718545},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208727494&doi=10.1109%2fICEEICT61591.2024.10718545&partnerID=40&md5=a6bc9ddc573df955a944a15d91e58e11},
	affiliations = {Thiruvalluvar Government Arts College, Department of Computer Science, Namakkal, Rasipuram, India; Department of Artificial Intelligence and Data Science, Muthayammal College of Engineering, Rasipuram, India},
	abstract = {In the past ten years, there has been a rise in nasty behaviors on social media due to the increased use of these platforms. One of the most offensive of these behaviors is hate speech, so users must safeguard themselves against it on social media. This research presents an approach to detect hate speech from social media using an optimized Elman recurrent neural network (ERNN) based on the hybrid local search algorithm (LSA) and elephant herding optimization (EHO) algorithm called LSAEHO. The LSA-EHO algorithm is used to LSA to obtain the optimal solution of EHO, enhance the convergence rate, and avoid the local optima problem of EHO. The LSA-EHO is used to find appropriate hyperparameters for ERNN to enhance the convergence rate and accuracy. The experimental results confirmed that the developed hate speech prediction-based optimized ERNN produced higher prediction accuracy and a faster convergence rate.  © 2024 IEEE.},
	author_keywords = {Convergence rate; Elephant herding optimization; Elman recurrent neural network; Hate speech detection; Hyperparameter optimization},
	keywords = {Recurrent neural networks; Speech recognition; Convergence rates; Elephant herding optimization; Elman's recurrent neural networks; Hate speech detection; Hyper-parameter optimizations; Local search algorithm; Network-based; Optimisations; Social media; Speech detection; Elman neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Electrical, Electronics, Information and Communication Technologies, ICEEICT 2024; Conference date: 24 July 2024 through 26 July 2024; Conference code: 203507}
}

@CONFERENCE{Ritika2024,
	author = {Ritika, Dharamkar and Pradnya, Dudhade and Yeboah, Jones and Nti, Isaac Kofi},
	title = {Predicting Cyberbullying Behavior in Social Media for Enhancing Online Safety},
	year = {2024},
	journal = {2024 IEEE 3rd International Conference on Computing and Machine Intelligence, ICMI 2024 - Proceedings},
	doi = {10.1109/ICMI60790.2024.10585879},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199478303&doi=10.1109%2fICMI60790.2024.10585879&partnerID=40&md5=ba9f947f14c41c1845f5cc6f2ad70038},
	affiliations = {School Of Information Technology, University Of Cincinnati, Cincinnati, United States},
	abstract = {Cyberbullying can have far-reaching and longlasting consequences, producing major emotional pain and potentially leading to serious mental health concerns such as despair and anxiety. Hence it is an escalating concern in the digital era, necessitating robust preventive strategies and early detection mechanisms. In our study, we conducted a comprehensive investigation into the potential of diverse machine learning (ML) algorithms for predicting cyberbullying behavior in social media posts. We systematically assessed six ML models: Support Vector Machines (SVM)(Accuracy 82%, F1 score 82), Multi-Layer Perceptron (MLP)( Accuracy 78%, F1 score 79), CatBoost(Accuracy 83%, F1 score 84), XGBoost(Accuracy 83%, F1 score 83), Logistic Regression (LR)( Accuracy 82.4%, F1 score 83), and naïve Bayes (NB)( Accuracy 76.3%, F1 score 75). The accuracy rates above 80% are generally accepted to be good if are accompanied by decent or high precision and recall values. Rigorous evaluations revealed discernible distinctions in their predictive capabilities. CatBoost and XGBoost demonstrated exceptional accuracy rates of 83% and impressive F1-scores from 84% to 85%, positioning them as front-runners. LR yielded noteworthy results, boasting an 82.4% accuracy rate and an 83% F1-score, ensuring consistent performance in cyberbullying prediction. SVM, MLP, and NB, although slightly trailing, provided credible results, showcasing their adaptability for specific application requirements. Each algorithm presents unique attributes, permitting customization to suit a variety of use cases. These findings hold significant implications, marking a new era in online safety. Machine learning algorithms have the potential to enhance content moderation systems by proactively identifying and addressing cyberbullying, fostering a safer digital environment. However, the choice of algorithm should align with precise objectives and operational needs, with CatBoost and XGBoost suited for comprehensive content moderation and SVM, MLP, LR, and NB suitable for applications necessitating tailored precision or recall optimization. As a future direction for the research, predicting cyberbullying on underrepresented groups or specific groups like LGBTQ+ can also be explored.  © 2024 IEEE.},
	author_keywords = {content moderation; Cyberbullying; machine learning; online safety; predictive modeling; social media},
	keywords = {Barium compounds; Computer crime; E-learning; Forecasting; Learning algorithms; Learning systems; Logistic regression; Social networking (online); Content moderation; Cyber bullying; F1 scores; Logistics regressions; Machine-learning; Multilayers perceptrons; Online safety; Predictive models; Social media; Support vectors machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd IEEE International Conference on Computing and Machine Intelligence, ICMI 2024; Conference date: 13 April 2024 through 14 April 2024; Conference code: 201027}
}

@ARTICLE{Gumelar2024880,
	author = {Gumelar, Agustinus Bimo and Yuniarno, Eko Mulyanto and Nugroho, Arif and Adi, Derry Pramono and Sugiarto, Indar and Purnomo, Mauridhi Hery},
	title = {An Improved Toxic Speech Detection on Multimodal Scam Confrontation Data Using LSTM-Based Deep Learning},
	year = {2024},
	journal = {International Journal of Intelligent Engineering and Systems},
	volume = {17},
	number = {6},
	pages = {880 – 904},
	doi = {10.22266/ijies2024.1231.67},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208104949&doi=10.22266%2fijies2024.1231.67&partnerID=40&md5=6ac48daa1b682daf500acef0227a2f7b},
	affiliations = {Department of Electrical Engineering, Faculty of Intelligent Electrical and Information Technology (ELECTICS), Institut Teknologi Sepuluh Nopember, Surabaya, 60111, Indonesia; Department of Computer Engineering, Faculty of Intelligent Electrical and Information Technology (ELECTICS), Institut Teknologi Sepuluh Nopember, Surabaya, 60111, Indonesia; Department of Electrical Engineering, Faculty of Engineering, Universitas Negeri Yogyakarta, Yogyakarta, 55281, Indonesia; Department of Electrical Engineering, Petra Christian University, Surabaya, 60236, Indonesia; University Center of Excellence on Artificial Intelligence for Healthcare and Society (UCE AIHeS), Surabaya, Indonesia},
	abstract = {Toxic speech has gained substantial attention, focusing on its detrimental effects and prevalence across online platforms. This phenomenon often exhibits discernible patterns in pronunciation analogous to emotions such as happiness or anger. It has been relatively underexplored in prior studies, which predominantly addressed offensive language, hate speech, and sarcasm without considering their emotional properties. Social media platforms have emerged as spaces where individuals share personal encounters with toxic speech that impacts on their well-being. To address this challenge, our study introduces a novel approach that combines speech and text data within a Long Short- Term Memory (LSTM) framework. Unlike existing methods that primarily focus on text analysis, our approach uniquely integrates both speech and text, thereby enhancing the model's ability to accurately detect toxic content. This multimodal data strategy is such an innovative step forward that it provides a more comprehensive solution to the problem of toxic speech detection. Our collected dataset comprises two-way conversations from online fraud reports and confrontations related to loan scams uploaded on YouTube, conducted in the Indonesian language. The absence of subtitles can emerge any ambiguity of homonyms, so it is required to transcribe the audio content to text. To do this, we used native speakers to make sure the transcription was correct in the Indonesian language of the toxic context. In addition, speech features, such as pitch, intensity, and speaking rate, were utilized alongside text features, including Bag-of-Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF). As a result, validation through F1-score measurement yielded 92.73% for text data and 89.09% for speech data. Our proposed approach provided a substantial improvement of approximately 12%-30% compared to the previous LSTM models. The performance comparison results confirmed that our proposed approach can enhance the accuracy of toxic speech detection. © (2024), (Intelligent Network and Systems Society). All rights reserved.},
	author_keywords = {Bag-of-words; Long short-term memory; Speech intensity; Speech pitch; Term frequency-inverse document frequency; Toxic speech detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dharani2024627,
	author = {Dharani, M. and Sathya, S.},
	title = {Deep Learning Algorithms with Adam Optimization for Detecting of Cyberbullying Comments},
	year = {2024},
	journal = {Nanotechnology Perceptions},
	volume = {20},
	number = {3},
	pages = {627 – 639},
	doi = {10.62441/nano-ntp.v20iS3.47},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198851192&doi=10.62441%2fnano-ntp.v20iS3.47&partnerID=40&md5=cd2c1d7d84ac77068008d8f63cf2a910},
	affiliations = {Department of Computer Science, Vels Institute of Science, Technolgy and Advanced Studies (VISTAS), Chennai, India; Department of Information Technology, Vels Institute of Science, Technolgy and Advanced Studies (VISTAS), Chennai, India},
	abstract = {The unavoidable utilization of web-based entertainment stages, like Facebook, Instagram, and X, has essentially intensified our electronic interconnectedness. Additionally, these stages are presently effectively available from any area at some random time. Nonetheless, the expanded prominence of virtual entertainment has additionally prompted cyberbullying. The peculiarity of cyberbullying has spread and has become perhaps of the most concerning issue confronting clients of virtual entertainment locales and produced critical unfriendly impacts on society and the casualty specifically. The utilization of oppressive and aggressive language has decisively extended in the virtual entertainment and systems administration time [16]. Youngsters are to a great extent liable for it. The greater parts of youngsters who utilize web-based entertainment for correspondence are survivors of cyberbullying. Affronts on person-to-person communication sites lead to unfavourable network connections. These remarks encourage a rude environment in web. Most of the instruments and calculations used to appreciate it and decrease it are idle. Tracking down fitting answers for recognize and diminish cyberbullying has become important to relieve its adverse consequences on society and the person in question. To characterize such remarks in a commonsense manner, the article expects to distinguish procedures to perceive tormenting in text by looking at and trying different things with different methodologies [27]. We recommended a compelling calculation to perceive unfriendly and badgering remarks, and we inspected these remarks to guarantee their legitimacy. In this paper, we were utilized three different profound learning calculations with Adam Enhancer. The existing methods like DNN, ANN, and RBFN are combined with Adam optimizer to detect the cyberbullying comments. The results show that by choosing the best features, the suggested RBFN with Adam Optimizer increases the accuracy of cyberbullying detection. © 2024, Collegium Basilea. All rights reserved.},
	author_keywords = {Adam optimization [2]; Artificial Neural Network (ANN); Cyberbullying; Deep Neural Network (DNN); Radial Basis Function Network (RBFN); Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tonneau20249020,
	author = {Tonneau, Manuel and de Castro, Pedro Vitor Quinta and Lasri, Karim and Farouq, Ibrahim and Subramanian, Lakshminarayanan and Orozco-Olvera, Victor and Fraiberger, Samuel P.},
	title = {NAIJAHATE: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {9020 – 9040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204420997&partnerID=40&md5=a67a32e85b3ff8ea190013dc95888eb2},
	affiliations = {The World Bank; University of Oxford, United Kingdom; New York University, United States; Universidade Federal de Goiás, Brazil; Ecole Normale Supérieure, France; Universiti Sultan Zainal Abidin, Malaysia; Massachusetts Institute of Technology, United States},
	abstract = {To address the global issue of online hate, hate speech detection (HSD) systems are typically developed on datasets from the United States, thereby failing to generalize to English dialects from the Majority World. Furthermore, HSD models are often evaluated on non-representative samples, raising concerns about overestimating model performance in real-world settings. In this work, we introduce NAIJAHATE, the first dataset annotated for HSD which contains a representative sample of Nigerian tweets. We demonstrate that HSD evaluated on biased datasets traditionally used in the literature consistently overestimates real-world performance by at least two-fold. We then propose NAIJAXLM-T, a pretrained model tailored to the Nigerian Twitter context, and establish the key role played by domain-adaptive pretraining and finetuning in maximizing HSD performance. Finally, owing to the modest performance of HSD systems in real-world conditions, we find that content moderators would need to review about ten thousand Nigerian tweets flagged as hateful daily to moderate 60% of all hateful content, highlighting the challenges of moderating hate speech at scale as social media usage continues to grow globally. Taken together, these results pave the way towards robust HSD systems and a better protection of social media users from hateful content in low-resource settings. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Online systems; Social networking (online); Speech recognition; Detection models; Detection system; Global issues; Modeling performance; Nigerians; Real world setting; Real-world performance; Representative sample; Social media; Speech detection; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202222}
}

@ARTICLE{Malik2024,
	author = {Malik, Jitendra Singh and Qiao, Hezhe and Pang, Guansong and van den Hengel, Anton},
	title = {Deep learning for hate speech detection: a comparative study},
	year = {2024},
	journal = {International Journal of Data Science and Analytics},
	doi = {10.1007/s41060-024-00650-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207004270&doi=10.1007%2fs41060-024-00650-6&partnerID=40&md5=7082dfa2b3c2e097e68c00613b3f84ab},
	affiliations = {School of Computer Science, University of Adelaide, Adelaide, SA, Australia; School of Computing and Information Systems, Singapore Management University, Singapore, Singapore},
	abstract = {Automated hate speech detection is an important tool in combating the spread of hate speech, particularly in social media. Numerous methods have been developed for the task, including a recent proliferation of deep-learning based approaches. A variety of datasets have also been developed, exemplifying various manifestations of the hate-speech detection problem. We present here a large-scale empirical comparison of deep and shallow hate-speech detection methods, mediated through the three most commonly used datasets. Our goal is to illuminate progress in the area, and identify strengths and weaknesses in the current state-of-the-art. We particularly focus our analysis on measures of practical performance, including detection effectiveness, computational efficiency, capability in using pre-trained models, and domain generalization. In doing so we aim to provide guidance as to the use of hate-speech detection in practice, quantify the state-of-the-art, and identify future research directions. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {Deep learning; Hate speech detection; Machine learning; Natural language processing; Transformers},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Natural language processing systems; Speech recognition; Comparatives studies; Deep learning; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Speech detection; State of the art; Transformer},
	type = {Review},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Jha2024241,
	author = {Jha, Arpana and Jaiswal, Arunima and Singh, Anshika and Swain, Sampurnna and Aggarwal, Eshika},
	title = {Comparative Analysis of Machine-Learning and Deep Learning Algorithms Using Manta Ray Foraging Optimization for the Detection of Hate Speech},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1085 LNNS},
	pages = {241 – 252},
	doi = {10.1007/978-981-97-6726-7_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209227556&doi=10.1007%2f978-981-97-6726-7_19&partnerID=40&md5=e4306320813f52b5cd851b8064771483},
	affiliations = {Department of Computer Science and Engineering, Indira Gandhi Delhi Technical University for Women, Kashmere Gate, Delhi, 110006, India},
	abstract = {User safety and societal well-being are two key concerns given the rising hate speech on online platforms. This study aims to tackle hate speech detection (HSD) using the Davidson’s dataset; a popular benchmark in this field. Count vectorization is used to preprocess textual data thereby enabling extraction of meaningful features. Various machine learning (ML) and deep learning (DL) architectures such as Support Vector Classifier (SVC), Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM), and Attention-based LSTM models are tested for performance. In addition, in this study a novel metaheuristic swarm-based optimization algorithm, Manta Ray Foraging Optimization (MRFO), has been used for enhanced feature selection to increase the detection accuracy of hate speech. The findings of the study have shown that MRFO in conjunction with attention-based approach produces an impressive performance. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Att-LSTM; Count vectorization; GRU; HSD; LSTM; Manta ray foraging optimization (MRFO); SVC},
	keywords = {Adaptive boosting; Adversarial machine learning; Benchmarking; Contrastive Learning; Feature Selection; Image segmentation; Speech enhancement; Att-long short-term memory; Count vectorization; GRU; Hate speech detection; Manta ray foraging optimization; Optimisations; Short term memory; Speech detection; Support vector classifiers; Vectorization; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th Doctoral Symposium on Computational Intelligence, DoSCI 2024; Conference date: 10 May 2024 through 10 May 2024; Conference code: 320959}
}

@CONFERENCE{Chu2024392,
	author = {Chu, Thiago Mei and Weitzel, Leila and Quaresma, Paulo},
	title = {Comparative Analysis of Hate Speech Detection Models on Brazilian Portuguese Data: Modified BERT vs. BERT vs. Standard Machine Learning Algorithms},
	year = {2024},
	journal = {Proceedings of the 13th International Conference on Data Science, Technology and Applications, DATA 2024},
	pages = {392 – 400},
	doi = {10.5220/0012770600003756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203089352&doi=10.5220%2f0012770600003756&partnerID=40&md5=62f607a4f7e52090d7156466713ce59d},
	affiliations = {Departament of Computer Science, Fluminense Federal University, Rio das Ostras, Brazil; Department of Informatics, University of Évora, Évora, Portugal},
	abstract = {The Internet became the platform for debates and expression of personal opinions on various subjects. Social media have assumed an important role as a tool for interaction and communication between people. To understand this phenomenon, it is indispensable to detect and assess what characterizes hate speech and how harmful it can be to society. In this paper we present a comprehensive evaluation of Portuguese-BR hate speech identification based on BERT model and ML models as baseline. The BERT model achieves higher scores compared to the machine learning algorithms, indicating better overall performance in distinguishing between classes. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {BERT; Hate Speech Detection; Machine Learning; Transformer},
	keywords = {Contrastive Learning; Speech recognition; BERT; Comparative analyzes; Detection models; Hate speech detection; Machine learning algorithms; Machine-learning; Social media; Speech detection; Standard machines; Transformer; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 13th International Conference on Data Science, Technology and Applications, DATA 2024; Conference date: 9 July 2024 through 11 July 2024; Conference code: 201842}
}

@CONFERENCE{Cabada2024,
	author = {Cabada, Ramón Zatarain and Barrón Estrada, María Lucía and Camacho Sapien, Ramón Alberto and Bátiz Beltrán, Víctor Manuel and López, Néstor Leyva and Sotelo Rivas, Manuel Alberto},
	title = {ITC at DIMEMEX: When hate goes Viral: Detection of Hate Speech in Mexican Memes Using Transformers},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204406367&partnerID=40&md5=ee6d42d39a9bcb4b0506fd5ab3c1a1a6},
	affiliations = {Tecnológico Nacional de México Campus Culiacán, Sinaloa, Culiacán, Mexico},
	abstract = {This article presents the work done in the task of detecting abusive content in memes through the use of images and text, in the DIMEMEX contest as part of IberLEF 2024. Like any violent event, memes with hate speech that circulate through the network generate a negative impact on society, affecting not only the people directly involved in their creation or spreading, but also vulnerable groups and the health of the social fabric in general. Precisely, our participation focused on making use of the dataset provided by the organizers to perform the task of detecting hate speech (or "toxicity") in memes using visual-textual information. To solve the contest task an approach focused on the use of OCR and Transformers was used. Our proposal was based on BETO model and obtained, for subtask 1, an f1-score value of 0.48, ranking fourth place in the final phase. We conclude that this task is very complicated, but we consider that our results and others are promising. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Hate Speech; LLM; Machine Learning; NLP; Sentiment Analysis; Transformers},
	keywords = {Adversarial machine learning; Deep learning; Economic and social effects; Speech analysis; Deep learning; Hate speech; LLM; Machine-learning; Sentiment analysis; Subtask; Textual information; Transformer; Viral detection; Vulnerable groups; Distribution transformers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@CONFERENCE{Ilhan2024,
	author = {Ilhan, Syed Shahidh and Sivakumar, Soubraylu and Nagaraj, J. and Ramesh, S. and Sreeram, N. and Rajalakshmi, Ratnavel},
	title = {Hate Speech Detection And Classification Using NLP},
	year = {2024},
	journal = {2nd IEEE International Conference on Advances in Information Technology, ICAIT 2024 - Proceedings},
	doi = {10.1109/ICAIT61638.2024.10690655},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208826408&doi=10.1109%2fICAIT61638.2024.10690655&partnerID=40&md5=1e68491d7b65e1316ec2c9d65d76723e},
	affiliations = {School of Computing, SRM Institute of Science and Technology, Kattankulathur, Chennai, India; Madanapalle Institute of Technology& Science, Andhra Pradesh, Madanapalle, India; Koneru Lakshmaiah Education Foundation Vaddeswaram, Andhra Pradesh, Guntur, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India},
	abstract = {Detected hate speech instances are appropriately classified, rebuilding the intricate landscape of disparaging language in an increasingly digitized society. We present an exhaustive analysis of the techniques, gravitating towards their efficiency, precision, and capability to adapt to the evolving dynamics of language manifestation online. The study uncovers fascinating insights into the relative strengths, weaknesses, limitations, and potential areas of improvement of Bi-LSTM and the Bi-LSTM with GRU in the realm of hate speech detection and classification. The results of Bi-LSTM with GRU has obtained an accuracy of 95% with an improvement of 1% over Bi-LSTM model. Serving as a cornerstone in the burgeoning NLP research, our findings provide promising direction and robust groundwork for future improvements and attempts in the continuous drive towards safer, more respectful digital communication platforms. © 2024 IEEE.},
	author_keywords = {Bidirectional Long Short-Term Memory; Gated Recurrent Unit; Hate Speech; Tweets; Twitter},
	keywords = {Classification (of information); Continuous speech recognition; Economic and social effects; Long short-term memory; Social networking (online); Speech enhancement; Bidirectional long short-term memory; Classifieds; Future improvements; Gated recurrent unit; Hate speech; Relative strength; Short term memory; Speech classification; Speech detection; Strength potential; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Advances in Information Technology, ICAIT 2024; Conference date: 24 July 2024 through 27 July 2024; Conference code: 203115}
}

@CONFERENCE{García-Hidalgo2024,
	author = {García-Hidalgo, Mario and García-Rodríguez, Mario and Payno, Jorge and Salerno, María Fernanda and Segura-Bedmar, Isabel},
	title = {DIMEMEX-2024: CyT at DIMEMEX: Leveraging Data Augmentation for the Detection of Hate Speech in Memes},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204372100&partnerID=40&md5=546264fb1baca1ccaa9f22116b1052dc},
	affiliations = {Universidad Carlos III de Madrid (UC3M), Madrid, Leganés, 28911, Spain},
	abstract = {The DIMEMEX 2024 competition proposes the development of multimodal computational models to detect abusive memes in Mexican Spanish, focusing on hate speech, offensive language, and vulgar content. This paper presents our approach to the two subtasks defined by the competition: a three-way classification distinguishing hate speech, inappropriate content, and neutral content, and a finer-grained classification that categorizes hate speech into specific types such as classism, sexism, and racism. Our methodology uses dataset expansion techniques, enriching the dataset by sourcing new memes and employing data augmentation methods to tackle class imbalances and increase the overall volume of data. We gathered memes from diverse sources, with a focus on underrepresented classes, resulting in a more balanced dataset. To further enhance the dataset, we leveraged state-of-the-art multimodal models such as Google Gemini 1.5 Pro for text extraction and Meta’s LLAMA 3 for text augmentation. This augmentation strategy increased the dataset size, providing a more robust training set. For the categorization of the memes, initially we used the BETO model for text representation and Vision Transformers (ViTs) for image features. We then experimented with multimodal models, such as CLIP, Multi-CLIP, and SIGLIP, to map features into a common feature space, fusing them and performing the classification with a MLP. © 2024 Copyright for this paper by its authors.},
	keywords = {Classification (of information); Computational linguistics; Feature extraction; Speech recognition; Augmentation methods; Balanced datasets; Class imbalance; Computational modelling; Data augmentation; Fine grained; Multi-modal; Multimodal models; Offensive languages; Subtask; Text mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@CONFERENCE{Hernández-González2024,
	author = {Hernández-González, Anibal and Madera-Quintana, Julio and Simón-Cuevas, Alfredo},
	title = {UC-CUJAE at HOMO-MEX 2024: Detecting Hate Speech Against the LGTB+ Community using Transformers on Imbalanced Datasets},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204368648&partnerID=40&md5=e86156290a6b0dafe043896476815198},
	affiliations = {University of Camagüey, Circunvalación Norte km 5 1/2, Camagüey, Cuba; Universidad Tecnológica de La Habana José Antonio Echeverría, La Habana, Marianao, Cuba},
	abstract = {The pervasive hate manifestations in social communication spaces and culture pose a significant challenge for contemporary societies. The sheer volume of daily information exacerbates the difficulty of detecting aggressive content targeting specific groups. The LGBTQ+ community is disproportionately affected by this problem. In order to promote a more positive and inclusive environment for the LGBTQ+ community, the Homo-Mex 2024 shared task proposes the development of automated learning systems capable of tackling various subtasks to create safer and healthier online spaces for the LGBTQ+ community. This paper proposes using transformer-based techniques to present solutions to the three problems posed at the event: multi-class, multi-label classification, and binary classification. The results show that the proposed procedure effectively addresses the undertaken tasks, with the binary classification yielding particularly noteworthy outcomes. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Data Augmentation; Hate Speech Detection; Imbalanced Classification; LGBT-Phobia; Transformers},
	keywords = {Adversarial machine learning; Classification (of information); Contrastive Learning; Speech recognition; Binary classification; Communication spaces; Data augmentation; Hate speech detection; Imbalanced classification; Imbalanced dataset; LGBT-phobia; Social communications; Speech detection; Transformer; Distribution transformers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@ARTICLE{de Oliveira2024144,
	author = {de Oliveira, Aillkeen Bezerra and de Souza Baptista, Cláudio and Firmino, Anderson Almeida and de Paiva, Anselmo Cardoso},
	title = {A Hate Speech Detection Approach Using Transfer Learning with Multiple Idioms},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {518 LNBIP},
	pages = {144 – 160},
	doi = {10.1007/978-3-031-64748-2_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200750255&doi=10.1007%2f978-3-031-64748-2_7&partnerID=40&md5=2fc3c2458fd5e31b8757d6faeae76773},
	affiliations = {Federal University of Campina Grande, Rua Aprigio Veloso, 882 - Universitário, Paraiba, Campina Grande, Brazil; Federal University of Maranhão, Av. dos Portugueses, 1966 - Vila Bacanga, Maranhão, São Luís, Brazil},
	abstract = {Nowadays, there is a growing connection among individuals promoted by the Internet, which provides opportunities for expressing their viewpoints through social media platforms. However, this expanded freedom of expression has been susceptible to the propagation of hate speech, a phenomenon that can precipitate unlawful conduct and potentially engender detrimental psychological ramifications. In response, computational technology has emerged as a valuable tool for identifying and mitigating hate speech on social media. In this chapter, we used five datasets to detect hate speech related to politics on social media. These datasets encompass the English, Italian, Filipino, German, and Turkish languages. In pursuit of hate speech detection, our study advocates adopting a Pre-Trained Language Model (PTLM) with Cross-Lingual Learning (CLL). We tried to detect hate speech in two languages (English and Italian) using English BERT and Italian BERT. We used Zero-Shot (ZST), Joint Learning (JL), Cascade Learning (CL), JL/CL, and CL/JL+ approaches. These techniques demonstrated efficacy in detecting hate speech. We obtained 94.8% in the F-score metric using English BERT and 93% using Italian BERT. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Cross-lingual learning; Hate speech detection; Machine learning; Pre-trained language model},
	keywords = {Computational linguistics; Learning systems; Speech recognition; Zero-shot learning; Cross-lingual; Cross-lingual learning; Detection approach; Hate speech detection; Joint learning; Language model; Machine-learning; Pre-trained language model; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 25th International Conference on Enterprise Information Systems, ICEIS 2023; Conference date: 24 April 2023 through 26 April 2023; Conference code: 315949}
}

@CONFERENCE{Riyadi2024,
	author = {Riyadi, Slamet and Andriyani, Annisa Divayu and Masyhur, Ahmad Musthafa},
	title = {Improving Hate Speech Detection Accuracy Using Hybrid CNN-RNN and Random Oversampling Techniques},
	year = {2024},
	journal = {2024 IEEE Symposium on Industrial Electronics and Applications, ISIEA 2024},
	doi = {10.1109/ISIEA61920.2024.10607232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201294456&doi=10.1109%2fISIEA61920.2024.10607232&partnerID=40&md5=8481598d64269c90219173936680659a},
	affiliations = {Universitas Muhammadiyah Yogyakarta, Department of Information Technology, Yogyakarta, Indonesia},
	abstract = {Detecting hate speech is crucial for addressing online toxicity and fostering a secure digital environment. This study aims to enhance the efficiency of hybrid CNN-RNN models, commonly used for this task, by improving accuracy. By integrating oversampling techniques with the model, the research aims to better categorize instances of hate speech, particularly in imbalanced datasets. The dataset used in this study is the Indonesian Tweet Hate Speech dataset. Following established protocols, including data pre-processing, training, and testing, significant improvements in accuracy are observed. The hybrid CNN-RNN achieves 0.827 accuracy, 0.797 precision, 0.759 recall, and 0.883 F1 score with imbalanced data. The model performs even better with balanced data, reaching 0.908 accuracy, 0.943 precision, 0.894 recall, and 0.914 F1 score. Notably, the proposed model outperforms the standard hybrid CNN-RNN on imbalanced datasets, with an accuracy of 0.752, precision of 0.797, recall of 0.559, and F1 score of 0.657. Techniques like dropout and early termination mitigate overfitting in complex models and large datasets. This research contributes to hate speech detection methods, underscoring the hybrid CNN-RNN's efficacy in handling imbalanced data, while future studies could explore additional methodologies for further enhancements.  © 2024 IEEE.},
	author_keywords = {balancing dataset; hate speech; hybrid CNN-RNN; oversampling; Twitter},
	keywords = {Data assimilation; Balancing dataset; Detection accuracy; F1 scores; Hate speech; Hybrid CNN-RNN; Imbalanced data; Imbalanced dataset; Over sampling; Oversampling technique; Speech detection; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 IEEE Symposium on Industrial Electronics and Applications, ISIEA 2024; Conference date: 6 July 2024 through 7 July 2024; Conference code: 201502}
}

@CONFERENCE{Damián2024,
	author = {Damián, Sergio and Vázquez, David and Felipe-Riverón, Edgardo and Yáñez-Márquez, Cornelio},
	title = {DSVS at HOMO-MEX24: Multi-Class and Multi-Label Hate Speech Detection using Transformer-Based Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204359024&partnerID=40&md5=3cdd14770a9a24ce6cd290ef19e1e910},
	affiliations = {Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico},
	abstract = {The present work describes the participation of the DSVS team in the HOMO-MEX shared task at IberLEF 2024 on detecting hate speech in online messages and music lyrics targeting the LGBTQ+ community, written in Mexican Spanish. The study addressed all three proposed tracks: Track 1 involves identifying LGBTQ+ categories (multiclass); Track 2 focuses on fine-grained hate speech detection (multi-labeled); and Track 3 involves homophobic lyrics detection (binary task). Through an exploration of the datasets, we employ various BERT-based models. Our team’s best submission secured the 4th position for Track 1, the 3rd position for Track 2, and the 9th position for Track 3. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Hate Speech Detection; Large Language Models; LGBTQ+ phobia; Natural Language Processing; Transformers},
	keywords = {Distribution transformers; Human computer interaction; Natural language processing systems; Speech recognition; Class labels; Hate speech detection; Language model; Language processing; Large language model; LGBTQ+ phobia; Natural language processing; Natural languages; Speech detection; Transformer; Homodyne detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@CONFERENCE{Ghaly2024166,
	author = {Ghaly, Rehab and Elkorany, Abeer and Ezzat, Cherry A.},
	title = {Hate Speech Detection in Arabic Text: Survey},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {244},
	pages = {166 – 177},
	doi = {10.1016/j.procs.2024.10.222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211234284&doi=10.1016%2fj.procs.2024.10.222&partnerID=40&md5=2b92ce9ffbdc011276ece03b6bbab8a1},
	affiliations = {Faculty of Computers and Artificial Intelligence, Cairo University, Cairo, 12613, Egypt},
	abstract = {In light of the continuous expansion of social media content, users have the freedom to express themselves without any boundaries or restrictions over the content. Unfortunately, this has increased the spread of hateful speech among users, which in turn has led to an increase in crimes, murders, and even acts of terrorism. Differentiating hate speech from other offensive language poses a significant challenge, requiring deep linguistic analysis. The task is further complicated by the scarcity of Arabic data resources, which significantly limits the availability of relevant information and the Arabic morphology's richness. This study seeks to conduct a comprehensive review of the current state of research on hate speech-related issues and automatic hate speech detection in Arabic text on social media platforms. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Arabic Text Analytics; Hate speech; NLP; Social Media Platforms},
	keywords = {Arabic text analytic; Arabic texts; Hate speech; Linguistic analysis; Media content; Offensive languages; Social media; Social media platforms; Speech detection; Text analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th International Conference on AI in Computational Linguistics, ACLing 2024; Conference date: 21 September 2024 through 22 September 2024; Conference code: 204464; All Open Access, Gold Open Access}
}

@ARTICLE{Aziz2024186,
	author = {Aziz, Noor Azeera Abdul and Zainal, Anazida and Al-Rimy, Bander Ali Saleh and Ghaleb, Fuad Abdulgaleel Abdoh},
	title = {Comparative Performance of Multi-level Pre-trained Embeddings on CNN, LSTM and CNN-LSTM for Hate Speech and Offensive Language Detection},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1078 LNNS},
	pages = {186 – 195},
	doi = {10.1007/978-3-031-66965-1_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200997691&doi=10.1007%2f978-3-031-66965-1_19&partnerID=40&md5=6e5740a9241343e4654f4660b50595c6},
	affiliations = {Department of Internet Engineering and Computer Science, Lee Kong Chian Faculty of Engineering and Science, Universiti Tunku Abdul Rahman, Selangor, Bandar Sungai Long, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor, Johor Bahru, Malaysia; School of Computing, University of Portsmouth, Buckingham Building, Lion Terrace, Portsmouth, PO1 3HE, United Kingdom; College of Computing and Digital Technology, Birmingham City University, Birmingham, B4 7XG, United Kingdom},
	abstract = {With growing concerns over hate speech, social media platforms provide policies for monitoring hate content. Nowadays, platforms like Twitter and Facebook rely on humans and machines as content moderators. As for machine moderators, many studies proposed hate speech detection using machine learning approaches. This study investigated which pre-trained text embedding (Word2Vec, GloVe, FastText, Elmo, and BERT) is the best for each tokenization level (word, subword, and character) and which neural network architecture (CNN, LSTM, and CNN-LSTM) is the best as an encoding method for hate speech and offensive language detection. The character-level GloVe with CNN-LSTM performed best among all tested methods. GloVe (character level) scored 93% for F1-score and 92% for accuracy. At the word level, BERT word embedding with CNN-LSTM had the best classification scores of 90% F1-score and 91% accuracy. At the subword level, CNN-LSTM and CNN fared best with BERT word embeddings, which had 86% for both accuracy and F1-score. The performance findings show that pre-trained embeddings at different tokenization levels capture diverse information. Moreover, with an average of 85% for F1-score and 86% for accuracy, CNN-LSTM yielded the best score for almost all text embedding regardless of the tokenization level compared to CNN and LSTM. These results show that CNN-LSTM complements each other to capture sequential and local patterns in the input text. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hate speech detection; neural network; text classification; text embedding},
	keywords = {Classification (of information); Long short-term memory; Network architecture; Social networking (online); Speech recognition; Text processing; Embeddings; F1 scores; Hate speech detection; Language detection; Neural-networks; Offensive languages; Speech detection; Text classification; Text embedding; Tokenization; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th International Conference on Soft Computing and Data Mining, SCDM 2024; Conference date: 21 August 2024 through 22 August 2024; Conference code: 316409}
}

@CONFERENCE{Kaundal2024,
	author = {Kaundal, Vineet and Chauhan, Naveen},
	title = {High-Performance Hate Speech Detection with Hybrid Attention},
	year = {2024},
	journal = {International Conference on Integrated Circuits, Communication, and Computing Systems, ICIC3S 2024 - Proceedings},
	doi = {10.1109/ICIC3S61846.2024.10603323},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201179664&doi=10.1109%2fICIC3S61846.2024.10603323&partnerID=40&md5=204db6dd0121cc6fab27b2ad0346611d},
	affiliations = {Computer Science And Engineering, National Institute of Technology, Himachal Pradesh, Hamirpur, 177005, India},
	abstract = {Online hate speech is a serious threat that endangers people and communities, impacting inclusivity. In this paper, we aim to design a novel deep learning system that performs more effectively in identifying hate speech. Our approach uti lizes hierarchical attention to capture cues for hate speech in sentences, multi-head attention to capture some pattern, and a BiLSTM to understand the context. We have also applied specific preprocessing techniques to address the issue of typos and collocation of words into colloquial language commonly found in hate speech. Moreover, we fine-tuned the model's hyperparameters to perfection to improve performance, custom made for our dataset on hate speech. The accuracy was a huge 93% under test conditions for a specific type of dataset, almost matching performance with a huge discrepancy from the baseline of the usual BiLSTM. We have demonstrated that our approach, incorporating customized preprocessing and attention processes, provides a practical way of mitigating the damages from hate speech online. This research will further assist in making online platforms more friendly, inclusive, and safe. © 2024 IEEE.},
	author_keywords = {Bi-LSTM; Deep learning; Hate speech; Hierarchical Attention; LSTM; Multi Head Attention; NLP; Offensive language; Twitter},
	keywords = {Learning systems; Long short-term memory; Speech recognition; Bi-LSTM; Deep learning; Hate speech; Hierarchical attention; LSTM; Multi head attention; Offensive languages; Performance; Speech detection; Twitter; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Conference on Integrated Circuits, Communication, and Computing Systems, ICIC3S 2024; Conference date: 8 June 2024 through 9 June 2024; Conference code: 201437}
}

@CONFERENCE{Chakarverti2024,
	author = {Chakarverti, Mohini and Goswami, Anurag and Yadav, Ashima},
	title = {Comparative Evaluation of Pre-Trained Models for Hate Speech Detection on Social Media},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10723959},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212843764&doi=10.1109%2fICCCNT61001.2024.10723959&partnerID=40&md5=9bebb17483d1467d34ceb78e284ab7c1},
	affiliations = {SCSET, Bennett University, Greater Noida, India},
	abstract = {The growing spread of hate speech across social networking is getting harder to use that demands ever further sophistication in measurement tools. This paper sought to do the same by understanding if currently available pre-trained transformer models can be effective hate speech identifiers while measuring their performance on critical metrics . In particular, the study aimed to do the same for the best available transformer-based transformers – ALBERT, BART, BERT, DistilBERT, and RoBERTa – through a comparison of their F1 Score, F1.5 Score, recall, accuracy, and precision. This made it much easier to understand the model’s strengths and weaknesses. It is RoBERTa that emerges as the top performer with an accuracy of 0.8912 (89%) . At the same time, it is easy to see that this model can become a game-changing tool for identifying hate speech using existing infrastructure. Additionally, one can also better understand the tradeoffs this model makes between precision and recall. It makes it easier to understand how these models operate when deployed. In the end, this paper shows how it is possible to further the current discussion around AI for good by presenting a relatively unbiased view of current achievement to create safer-online-spaces. As such, this paper also aims to influence how future hate speech detection projects are developed and deployments are managed. ©2024 IEEE.},
	author_keywords = {Hate Speech; Multilingual Models; Natural Language Processing (NLP); Transformer Models},
	keywords = {Distribution transformers; Natural language processing systems; Speech recognition; 'current; Comparative evaluations; Hate speech; Language processing; Multilingual model; Natural language processing; Natural languages; Social media; Speech detection; Transformer modeling},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@BOOK{Mishra202475,
	author = {Mishra, Anand Kumar and Raghuvanshi, C.S. and Soni, Hemant Kumar and Goswami, Pragya},
	title = {Analytics of Text and Social Media for Challenges of Hateful and Offensive Speech Detection},
	year = {2024},
	journal = {Text and Social Media Analytics for Fake News and Hate Speech Detection},
	pages = {75 – 91},
	doi = {10.1201/9781003409519-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202140385&doi=10.1201%2f9781003409519-4&partnerID=40&md5=52908d977f4f0d061bbd61166530fc96},
	affiliations = {Rama University, Uttar Pradesh, Kanpur, India; Faculty of Engineering and Technology Rama University, Kanpur, India; Amity University, Madhya Pradesh, Gwalior, India; Amity University, Madhya Pradesh, Gwalior, India},
	abstract = {The increasing popularity of social media platforms has resulted in a rapid increase in the spread of fake news and hate speech, which can have negative impacts on society. Identifying and preventing the spread of such content has become an important and crucial task for researchers and practitioners. This chapter aims to present an overview of text and social media analytics techniques for detecting fake and unreal news and hate speech. Section 4.1 of the chapter consists of the basics of fake news and hate speech, with definitions and examples. Section 4.2 includes text and social media analytics techniques, including natural language processing, sentiment analysis, and network analysis. Section 4.3 provides case studies of fake news and hate speech detection, focusing on the effectiveness of various approaches. Section 4.4 discusses the difficulties of detecting fake news and hate speech, the absence of a standard definition, and the constantly evolving nature of the problem. Section 4.5 explores future research fields in this area, including the use of machine learning techniques and the involvement of multiple modalities. In a nutshell, this chapter gives a comprehensive overview of the state-of-the-art in text and social media analytics for fake news and hate speech detection. It will be of interest to researchers, practitioners, and policymakers concerned with the spread of harmful content on social media platforms. © 2024 CRC Press.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Quan2024,
	author = {Quan, Le Minh and Son, Bui Hong and Van Thin, Dang},
	title = {CANTeam at HOMO-MEX 2024: Hate Speech Detection Towards the Mexican Spanish Speaking LGBT+ Population with Large Language Model},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204367044&partnerID=40&md5=6a9418798e911eccc956088e4b605c1c},
	affiliations = {University of Information Technology-VNUHCM, Quarter 6, Linh Trung Ward, Thu Duc District, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {This paper outlines our system for the three sub-tasks in the HOMO-MEX (Hate speech detection towards the Mexican Spanish speaking LGBT+ population) shared task at IberLEF 2024. To tackle this challenge, we developed a different approach based on fine-tuning Large Language Models with the LoRA technique for Task 1 (Multi-class Hate speech detection), Task 2 (Multi-label Fine-grained hate speech detection) and Task 3 (Binary classification Homophobic lyrics detection). LoRA (Low-Rank Adaptation) is a technique for parameter efficiently fine-tuning large language models. It significantly reduces training time and memory usage by using smaller, trainable matrices instead of modifying the entire model. This enables us to run Llama-2 on less powerful hardware. For all three tasks, we propose a fine-tuning system of the Llama-2 model by Meta AI. Our work ranked 2nd on Task 1, 1st on Task 2 and 8th on Task 3. Achieving 0.8775, 0.9730 and 0.4875 with F1 scores, respectively, for each task. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Fine-tuning LLM; HOMO-MEX 2024; IberLEF 2024; Large Language Model; Llama 2; LoRA; Prompting Engineering},
	keywords = {Classification (of information); Homodyne detection; Population statistics; Fine tuning; Fine-tuning LLM; HOMO-MEX 2024; IberLEF 2024; Language model; Large language model; Llama 2; Low-rank adaptation; Prompting engineering; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@ARTICLE{Hashmi2024121507,
	author = {Hashmi, Ehtesham and Yildirim Yayilgan, Sule and Hameed, Ibrahim A. and Mudassar Yamin, Muhammad and Ullah, Mohib and Abomhara, Mohamed},
	title = {Enhancing Multilingual Hate Speech Detection: From Language-Specific Insights to Cross-Linguistic Integration},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {121507 – 121537},
	doi = {10.1109/ACCESS.2024.3452987},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203525883&doi=10.1109%2fACCESS.2024.3452987&partnerID=40&md5=c91420a214124b1abf97ec77308af7ef},
	affiliations = {Norwegian University of Science and Technology (NTNU), Department of ICT and Natural Sciences (IIR), Møre og Romsdal, Ålesund, 6009, Norway; Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Gjovik, 2815, Norway},
	abstract = {The rise of social media has enabled individuals with biased perspectives to spread hate speech, directing it toward individuals based on characteristics such as race, gender, religion, or sexual orientation. Constructive interactions in varied communities can greatly enhance self-esteem, yet it is vital to consider that adverse comments may affect individuals' social standing and emotional health. The crucial task of detecting and addressing this type of content is imperative for reducing its negative effects on communities and individuals alike. The rising occurrence highlights the urgency for enhanced methods and robust regulations on digital platforms to protect humans from such prejudicial and damaging conduct. Hate speech typically appears as a deliberate hostile action aimed at a particular group, often with the intent to demean or isolate them based on various facets of their identity. Research on hate speech predominantly targets resource-aware languages like English, German, and Chinese. Conversely, resource-limited languages, including European languages such as Italian, Spanish, and Portuguese, alongside Asian languages like Roman Urdu, Korean, and Indonesian, present obstacles. These challenges arise from a lack of linguistic resources, making the extraction of information a more strenuous task. This study is focused on the detection and improvement of multilingual hate speech detection across 13 different languages. To conduct a thorough analysis, we carried out a series of experiments that ranged from classical machine learning techniques and mainstream deep learning approaches to recent transformer-based methods. Through hyperparameter tuning, optimization techniques, and generative configurations, we achieved robust and generalized performance capable of effectively identifying hate speech across various dialects. Specifically, we achieved a notable enhancement in detection performance, with precision and recall metrics exceeding baseline models by up to 10% across several lesser-studied languages. Additionally, our work extends the capabilities of explainable AI within this context, offering deeper insights into model decisions, which is crucial for regulatory and ethical considerations in AI deployment. Our study presents substantial performance improvements across various datasets and languages through meticulous comparisons. For example, our model significantly outperformed existing benchmarks: it achieved F1-scores of 0.90 in German (GermEval-2018), up from the baseline score of 0.72, and 0.93 in German (GermEval-2021), a substantial increase from 0.58. Additionally, it scored 0.95 in Roman Urdu HS, surpassing the previous peak of 0.91. Furthermore, for mixed-language datasets such as Italian and English (AMI 2018), our accuracy rose dramatically from 0.59 to 0.96. These outcomes emphasize the robustness and versatility of our model, establishing a new standard for hate speech detection systems across diverse linguistic settings. © 2024 The Authors.},
	author_keywords = {deep learning; explainable AI; Hate speech; machine learning; natural language processing; transformers; word embedding},
	keywords = {Benchmarking; Contrastive Learning; Deep learning; Economic and social effects; Energy security; Natural language processing systems; Speech enhancement; Deep learning; Embeddings; Explainable AI; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Transformer; Word embedding; Adversarial machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Bawachkar2024423,
	author = {Bawachkar, Abhishek and Pande, Siddhant and Selokar, Ankita and Mangoankar, Nikhita and Karande, Aarti},
	title = {Comparative Analysis of Various Machine-Learning and Deep Learning Model for Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1085 LNNS},
	pages = {423 – 435},
	doi = {10.1007/978-981-97-6726-7_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209183349&doi=10.1007%2f978-981-97-6726-7_34&partnerID=40&md5=1afc32697e42f2276ae0bc9176eb5b74},
	affiliations = {Sardar Patel Institute of Technology, Mumbai, India},
	abstract = {Toxic or hate comments, texts, phrases are most common on social media, as internet is freely available in today’s world, everyone have an access to it and can throw shades on anyone across the world without bearing any real-world consequences. Sitting in front of a computer screen and spreading toxic comments to people is very easy in the current world, but this situation has a very dark side which leads to cyber bullying followed by depression and increase in suicide rates, even tech giants are facing huge issues regarding online toxicity. Right now there is no foolproof or solid method to tackle these types of comments, but still with the help of AI and machine learning, stopping cyberbullying is somewhat possible. Our main aim is to create a solution which is more accurate and detect toxic and hateful texts, words, phrases, etc. Multiple machine-learning models are used on the same data set choosing the best performing machine-learning algorithm by comparing their precision, accuracy and other parameters and providing a robust solution which can be integrated with web, application or with any other technology. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Deep learning; Ensemble techniques; Hate speech detection; Machine-learning algorithms},
	keywords = {Contrastive Learning; Deep learning; Federated learning; Speech recognition; Analysis of various; Comparative analyzes; Cyber bullying; Deep learning; Ensemble techniques; Hate speech detection; Learning models; Machine learning algorithms; Machine-learning; Speech detection; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th Doctoral Symposium on Computational Intelligence, DoSCI 2024; Conference date: 10 May 2024 through 10 May 2024; Conference code: 320959}
}

@ARTICLE{Pradhan2024369,
	author = {Pradhan, Sriansh Raj and Yadav, Suman and Yang, Tiansheng and Wang, Lu and Rathore, Bharati and Tripathy, Hrudaya Kumar},
	title = {Hate and Offensive Speech Detection Using Machine Learning},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1085 LNNS},
	pages = {369 – 377},
	doi = {10.1007/978-981-97-6726-7_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209172062&doi=10.1007%2f978-981-97-6726-7_29&partnerID=40&md5=214257e0e5b3071166c8cc3002e5badd},
	affiliations = {Kalinga Institute of Industrial Technology, Deemed to be University, Bhubaneswar, India; ECE Department, Bharati Vidyapeeth’s College of Engineering, Delhi, India; University of South Wales, Llantwit Rd, Pontypridd, CF37 1DL, United Kingdom; Xi’an Jiaotong-Liverpool University, Wuzhong District, Suzhou, 215000, China},
	abstract = {The widespread occurrence of offensive and hateful texts on digital platforms, especially online media sites like Twitter, has sparked worries about user security and the welfare of the community. In order to recognize and reduce the impact of such harmful content, this article explains about a hateful and offensive language detection system using ML algorithms. Also the difficulties of identifying hateful and offensive content in a large volume of content produced by users are also discussed. This study uses a decision tree classifier as the main model and thoroughly compares and contrasts KNN, Naive Bayes (NB), and Random Forest (RF) classifying techniques to determine the best. Using labeled datasets from social media platforms for training and validation, the models are put through extensive testing to determine recall, accuracy, and precision. After analysis, we found that decision tree classifier is the best model. Due to its advanced features and classification methods, it produces the best accuracy rates, out of all other models. Referring this study, various better filtering solutions can be developed, which can help to make the Internet usage safer due to powerful ML algorithms that will help to prevent hate speech online. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Decision tree classifier; Hate and offensive speech; KNN classification; ML techniques; Predictions},
	keywords = {Adversarial machine learning; Decision trees; Random forests; Speech recognition; Tweets; Decision tree classifiers; Digital platforms; Hate and offensive speech; KNN classification; Language detection; Machine-learning; ML technique; Offensive languages; Online medium; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th Doctoral Symposium on Computational Intelligence, DoSCI 2024; Conference date: 10 May 2024 through 10 May 2024; Conference code: 320959}
}

@CONFERENCE{Pen2024332,
	author = {Pen, Haibo and Teo, Nicole and Wang, Zhaoxia},
	title = {Comparative Analysis of Hate Speech Detection: Traditional vs. Deep Learning Approaches},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Conference on Artificial Intelligence, CAI 2024},
	pages = {332 – 337},
	doi = {10.1109/CAI59869.2024.00070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201189868&doi=10.1109%2fCAI59869.2024.00070&partnerID=40&md5=0f29c271f83fd90a97157d0e4d6e4c85},
	affiliations = {Tianjin University, Key Laboratory of Smart Grid of Ministry of Education, Tianjin, 300072, China; Singapore Management University, School of Computing and Information Systems, Singapore},
	abstract = {Detecting hate speech on social media poses a significant challenge, especially in distinguishing it from offensive language, as learning-based models often struggle due to nuanced differences between them, which leads to frequent misclassifications of hate speech instances, with most research focusing on refining hate speech detection methods. Thus, this paper seeks to know if traditional learning-based methods should still be used, considering the perceived advantages of deep learning in this domain. This is done by investigating advancements in hate speech detection. It involves the utilization of deep learning-based models for detailed hate speech detection tasks and compares the results with those obtained from traditional learning-based baseline models through multidimensional aspect analysis. By considering various aspects to gain a comprehensive understanding, we can discern the strengths and weaknesses in current state-of-the-art techniques. Our research findings reveal the performance of traditional learning-based hate speech detection outperforms that of deep learning-based methods. While acknowledging the potential demonstrated by deep learning methodologies, this study emphasizes the significance of traditional machine learning approaches in effectively addressing hate speech detection tasks. It advocates for a balanced perspective, highlighting that dismissing the capabilities of traditional methods in favor of emerging deep learning-based techniques may not consistently yield the most effective results. © 2024 IEEE.},
	author_keywords = {Deep learning; Hate speech detection; Multidimensional aspect analysis; Performance comparison; Traditional learning-based methods},
	keywords = {Learning systems; Speech recognition; Deep learning; Detection tasks; Hate speech detection; Learning Based Models; Learning-based methods; Multidimensional aspect analyse; Performance comparison; Speech detection; Traditional learning; Traditional learning-based method; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE Conference on Artificial Intelligence, CAI 2024; Conference date: 25 June 2024 through 27 June 2024; Conference code: 201446}
}

@CONFERENCE{Usman2024370,
	author = {Usman and Quadri, S.M.K.},
	title = {Hate Speech Detection on Social Media using Machine Learning and Deep Learning: A review},
	year = {2024},
	journal = {15th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2024},
	volume = {1},
	pages = {370 – 376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208805674&partnerID=40&md5=28f696a1da7e4de8cc454f09d618c0ae},
	affiliations = {Jamia Millia Islamia, New Delhi, India},
	abstract = {Online toxic narratives may cause disputes and hurt virtual communities. Social networking sites are used in modern culture to share ideas and feelings. However, it occasionally can result in hate speech. Hate speech is offensive targeting someone or a group of people because of one or more of their origins, races, genders, religions, impairments, or other traits. It is a serious problem since it can have terrible results. In this paper, we have systematically investigated the various research works based on machine learning and deep learning techniques for text-based offensive speech classification. This research also offers empirical facts on the inherent features of hateful speech and assists in identifying future research. © Grenze Scientific Society, 2024.},
	author_keywords = {Deep learning; Hate speech; Machine learning; Offensive speech},
	keywords = {Contrastive Learning; Deep reinforcement learning; Deep learning; Hate speech; Learning techniques; Machine-learning; Offensive speech; On-machines; Social media; Social-networking; Speech detection; Virtual community; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2024; Conference date: 21 June 2024 through 22 June 2024; Conference code: 203500}
}

@CONFERENCE{Reghunathan2024,
	author = {Reghunathan, Arun and Singh, Saummya and Gunavathi, R. and Johnson, Amala},
	title = {Advanced Approaches for Hate Speech Detection: A Machine and Deep Learning Investigation},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545188},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204489011&doi=10.1109%2fTQCEBT59414.2024.10545188&partnerID=40&md5=a933df9e38c3107705aeec06e4f0f29c},
	affiliations = {Christ (Deemed to Be University), School of Science, Lavasa, India},
	abstract = {The prevalence of online social media platforms has led to an alarming rise in the frequency of cyberbullying and hate speech. This study uses a variety of machine-learning approaches and deep- learning algorithms to identify hate speech. The goal is to create a thorough and successful method for locating and categorizing hate speech on online networks. Our suggested approach intends to deliver a comprehensive solution to address the urgent problem of cyberbullying and hate speech in the digital sphere by leveraging the strength of these cutting-edge techniques. We work to make social media users' online experiences safer and more welcoming by identifying and addressing such harmful online actions. Through rigorous experimentation, we evaluate the efficacy of these methodologies, ultimately revealing that the Bidirectional Gated Recurrent Unit (Bi-GRU) outperforms the other employed techniques. The Bi-GRU model demonstrates superior hate speech detection capabilities, substantiated by robust performance metrics. This research contributes to the field by providing empirical evidence that deep learning models, such as Bi-GRU, can significantly advance hate speech detection accuracy. The findings underscore the potential of leveraging advanced neural architectures in the pursuit of fostering a more inclusive and respectful digital space.  © 2024 IEEE.},
	author_keywords = {Bi-GRU; classification; deep learning; Hate speech; machine learning; NLP; RNN},
	keywords = {Contrastive Learning; Deep learning; Speech recognition; Bidirectional gated recurrent unit; Cyber bullying; Deep learning; Hate speech; Machine learning approaches; Machine-learning; Online social medias; RNN; Social media platforms; Speech detection; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2024; Conference date: 22 March 2024 through 23 March 2024; Conference code: 202352}
}

@CONFERENCE{Raturi2024,
	author = {Raturi, Vandana and Kandpal, Ojasvi and Rawat, Daksh and Bhakuni, Vihan Singh and Manwal, Manika},
	title = {Offensive Speech Detection using Deep Learning},
	year = {2024},
	journal = {2024 1st International Conference on Advanced Computing and Emerging Technologies, ACET 2024},
	doi = {10.1109/ACET61898.2024.10730430},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210096474&doi=10.1109%2fACET61898.2024.10730430&partnerID=40&md5=f9281e1fceea227fee81fba62877614e},
	affiliations = {Graphic Era Hill University, Computer Science and Engineering, Dehradun, India; Graphic Era Hill University, Computer Science and Engineering, Uttarakhand, Dehradun, India; R/S Graphic Era Deemed to Be University, Uttarakhand, Dehradun, India},
	abstract = {As social media and the internet have grown in popularity, people now have access to a variety of forums for openly expressing their ideas and opinions on a wide range of topics. However, this freedom of expression is exploited to inspire hatred against specific persons or groups of individuals owing to disparities in gender, race, or religion, among other considerations. To address this growing problem on social networking sites, recent research have used breakthroughs in machine learning algorithms and feature engineering approaches to automate the identification of hate speech posts across a range of datasets. Advances in machine intelligence have piqued the interest of academics seeking and applying solutions to the problem of hate speech. Currently, hate speech is identified using a decision tree algorithm and text data.  © 2024 IEEE.},
	author_keywords = {Decision Tree; Deep Learning; Feature Engineering; HS; No Hate or Offensive; Offensive Speech},
	keywords = {Contrastive Learning; Decision trees; Deep learning; Feature engineerings; HS; Machine learning algorithms; No hate or offensive; Offensive speech; Recent researches; Social media; Social-networking; Speech detection; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Advanced Computing and Emerging Technologies, ACET 2024; Conference date: 23 August 2024 through 24 August 2024; Conference code: 203764}
}

@CONFERENCE{Rawat2024,
	author = {Rawat, Anchal and Kumar, Santosh and Samant, Surender Singh},
	title = {Hate Speech Detection using Machine Learning Techniques},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724896},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211175596&doi=10.1109%2fICCCNT61001.2024.10724896&partnerID=40&md5=22acde00a85bc39fdc33d532095bfb64},
	affiliations = {Graphic Era Deemed to be University, Department of Computer Science and Engineering, Dehradun, India},
	abstract = {The widespread transmission of dangerous online information is one notable concern raised by the rise in internet usage among people from a variety of cultural and educational backgrounds. The main difficulty is identifying hate speech and derogatory language in the context of automatically detecting harmful text material. This research endeavor presents a meticulous and exhaustive comparative examination of Machine Learning (ML) algorithms tailored for the identification of hate speech. Its primary objective is to reveal an optimal algorithmic amalgamation characterized by simplicity, ease of implementation, efficiency, and the capacity to deliver robust detection performance. In this study, we conducted a comparative analysis of three ML techniques - Decision Tree (DT), Gradient Boosting (GB) and Random Forest (RF), and - to categorize tweets on Twitter into two distinct categories: those containing hate speech and those devoid of by applying the term frequency-inverse document frequency (TF-IDF) technique. The RF model yielded the most promising results, a commendable accuracy rate of 82% and a recall rate of 84% were achieved. © 2024 IEEE.},
	author_keywords = {Decision Tree; Gradient Boosting; Hate Speech Detection; Machine Learning; Random Forest},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@ARTICLE{Mittal2024545,
	author = {Mittal, D. and Singh, Harmeet and Rani, Sita},
	title = {Exploring Explainable Artificial Intelligence Techniques for Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1038 LNNS},
	pages = {545 – 554},
	doi = {10.1007/978-981-97-4149-6_37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206098485&doi=10.1007%2f978-981-97-4149-6_37&partnerID=40&md5=0b13d7880ee5b402a4be8394dfe468fb},
	affiliations = {Department of Computer Science and Application, CT University, Ferozepur Rd, Punjab, Sidhwan Khurd, 142024, India; Department of Computer Science and Engineering, Guru Nanak Dev Engineering College, Ludhiana, 141006, India},
	abstract = {Hate speech detection on social media platforms is critical to maintain online safety but poses significant challenges. Traditional machine learning models often fail to capture the nuanced linguistic patterns of hate speech. While deep learning models like LSTM neural networks can effectively model the semantic and syntactic complexity, their lack of interpretability is problematic. This research proposes integrating explainable AI (XAI) techniques like LIME, LRP, Ktrain, and SHAP to enhance deep learning hate speech models’ interpretability. Our key innovation is demonstrating that SHAP provides superior model interpretation, with a score of 0.89, by highlighting discriminatory words aligned with human judgment. The findings show combining deep learning and XAI can advance hate speech detection through interpretable high-performance models. By using SHAP to uncover potential model biases, we can refine systems to be more transparent and fair. This research contributes interpretable hate speech detection advancing online safety and sets the stage for studying model transferability across diverse settings. Overall, our innovative application of XAI to deep learning hate speech detection promotes the development of fair, accountable AI systems to counter online hate. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Deep learning models; Explainable AI (XAI); Hate speech detection; Interpretability; Ktrain; Layer-Wise Relevance Propagation (LRP); Local Interpretable Model-agnostic Explanations (LIME); SHapley Additive exPlanations (SHAP)},
	keywords = {Contrastive Learning; Deep learning; Deep reinforcement learning; Economic and social effects; Semantics; Speech recognition; Deep learning model; Explainable AI (XAI); Hate speech detection; Interpretability; Ktrain; Layer-wise; Layer-wise relevance propagation; Learning models; Local interpretable model-agnostic explanation; Shapley; Shapley additive explanation; Speech detection; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Innovative Computing and Communication, ICICC 2024; Conference date: 16 February 2024 through 17 February 2024; Conference code: 316239}
}

@ARTICLE{Shahid20241,
	author = {Shahid, Muhammad and Umair, Muhammad and Iqbal, Muhammad Amjad and Rashid, Muhammad and Akram, Sheeraz and Zubair, Muhammad},
	title = {Leveraging deep learning for toxic comment detection in cursive languages},
	year = {2024},
	journal = {PeerJ Computer Science},
	volume = {10},
	pages = {1 – 33},
	doi = {10.7717/peerj-cs.2486},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212764075&doi=10.7717%2fpeerj-cs.2486&partnerID=40&md5=4ac27dc4d9a08cf831c728be4978ed65},
	affiliations = {Faculty of Information Technology and Computer Science, University of Central Punjab, Lahore, Pakistan; Department of Computer Science, National University of Technology, Islamabad, Pakistan; Information Systems Department, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia; Faculty of Computer Science and Information Technology, The Superior University, Lahore, Pakistan; Intelligent Data Visual Computing Research (IDVCR), The Superior University, Lahore, Pakistan},
	abstract = {Social media platforms enable individuals to publicly express opinions, support, and criticism. Influencers can launch campaigns to promote ideas. Most people can now share their views and feelings through visual or textual comments, which can range from appreciation to hate speech, potentially inciting societal violence and hatred. Detecting these noxious comments and thoughts is critical to protecting our communities from their negative social, psychological, and political impact. Although Urdu (a low-resource language) is one of the most popular Asian languages around the globe, a standard tool does not exist to detect toxic comments posted in this language. Tokenization and then categorizing cursive text is challenging due to its complex nature, especially when dealing with toxic comments, which are often ungrammatical and very brief. This study proposes a novel model to identify salient features in Urdu sentences. It uses transformers to identify and flag toxic comments using deep learning binary classification of the text. Statistically, the proposed fine-tuned model outperforms the existing ones by achieving a precision of 88.38%. Among the models evaluated, bidirectional encoder representations from transformers (BERT) demonstrated superior performance with an accuracy 85.45%, precision 85.71%, recall 85.45%, F1 score 85.41%, and a Cohen Kappa 70.83% on the full feature set. Conversely, GPT-2 was identified as the lowest-performing model. The outcomes of this research represent a noteworthy advancement in the broader endeavor to improve and optimize content moderation mechanisms across diverse languages and platforms. © 2024 Bhatti et al.},
	author_keywords = {Classification; Corpus; Cursive languages; Deep learning; Toxic comments},
	keywords = {Adversarial machine learning; Deep learning; Asian languages; Corpus; Cursive language; Deep learning; Low resource languages; Political impact; Social media platforms; Social psychological impact; Standard tools; Toxic comment; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fayas Ahamed2024,
	author = {Fayas Ahamed, F. and Prasanth, M. and Sundaresh, Atul Saju and Manoj Krishna, D. and Sindhu, S.},
	title = {Multimodal Hate Speech Detection With Explanability Using LIME},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211158858&doi=10.1109%2fICCCNT61001.2024.10724886&partnerID=40&md5=4cc775d8adbca511c150569452238a40},
	affiliations = {Nss College of Engineering, Computer Science and Engineering, Kerala, Palakkad, India},
	abstract = {Social media platforms link users from all over the world and enable opinion exchange on subjects including politics, finances and social issues. Policies governing objectionable material such as hate speech, that could potentially cause users psychological harm are difficult to reliably implement. Social media platform creators typically rely on human moderators to look into and assess potentially harmful content. Artificial intelligence (AI)-based decision support methods have attracted a lot of attention recently in regard to the identification of hate speech. For instance, AI-based models can be used to identify a variety of undesirable speech communication concepts, such as racism, hate speech and inflammatory language. This paper aims to develop an Explainable AI model for the automatic detection of hate speech in online content, providing transparency and interpretability in the decision-making process. Our initiative addresses the critical issue of hate speech in social media platforms through a multi-modal approach, encompassing both text and image analysis. Building a robust machine learning model that can precisely identify hate speech in diverse content types is one of our key objectives. To foster openness and trust, we employ sophisticated explainability approaches that provide a comprehensive explanation of the reasoning underlying the model's predictions for both text and image inputs. This ensures that users have a clear understanding of how the model makes decisions, enhancing transparency in our detection system. By making the internet a safer and friendlier environment for everyone, our multi-modal approach enhances the overall effectiveness of combating hate speech across different content formats. © 2024 IEEE.},
	author_keywords = {Ensemble Model; Explainable AI; Hate speech; Hateful Memes; Multi-Modal; Social media; Text classification},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@CONFERENCE{Sasidaran2024,
	author = {Sasidaran, Keerthana and Geetha, J.},
	title = {Multimodal Hate Speech Detection using Fine-Tuned Llama 2 Model},
	year = {2024},
	journal = {International Conference on Intelligent Algorithms for Computational Intelligence Systems, IACIS 2024},
	doi = {10.1109/IACIS61494.2024.10722018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208795803&doi=10.1109%2fIACIS61494.2024.10722018&partnerID=40&md5=cee6932a18cc2f646758022410c09513},
	affiliations = {Ramaiah Institute of Technology, Department of Computer Science and Engineering, Bangalore, India},
	abstract = {Hate speech detection is crucial for secure online environments, especially with recent policy changes on social media. This study enhances the Llama 2 model by fine-tuning it with a comprehensive Twitter dataset to improve hate speech detection accuracy. The system's frontend allows users to upload or record audio, upload videos, or provide YouTube URLs, with processing managed by the Google Speech Recognition API and the Whisper library. The backend integrates advanced speech recognition and video processing technologies. The refined Llama 2 model achieved an F1 score of 0.94, with accuracy, precision, and recall metrics surpassing other state-of-the-art models. These results demonstrate the model's high effectiveness and reliability in hate speech detection. This research highlights the potential of transformer-based models in enhancing online safety and inclusivity. Future work will focus on expanding the dataset, improving model generalization, supporting additional languages, and enhancing system scalability to better handle evolving hate speech forms.  © 2024 IEEE.},
	author_keywords = {fine-tuning; hate speech; llama 2; multimedia processing; speech recognition},
	keywords = {Economic and social effects; Speech enhancement; Speech recognition; Tweets; Video signal processing; Detection accuracy; Fine tuning; Hate speech; Llama 2; Multi-modal; Multimedia processing; Online environments; Policy changes; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Conference on Intelligent Algorithms for Computational Intelligence Systems, IACIS 2024; Conference date: 23 August 2024 through 24 August 2024; Conference code: 203642}
}

@ARTICLE{Revathi202431,
	author = {Revathi, S. and Muthu Priya, V. and Akila, R. and Ismail, Fathima},
	title = {Hate Speech Detection Using Deep Learning Algorithms},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1052 LNNS},
	pages = {31 – 39},
	doi = {10.1007/978-3-031-64776-5_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200695219&doi=10.1007%2f978-3-031-64776-5_4&partnerID=40&md5=ad34ea6a09c59f2fdd9e776c9b76899b},
	affiliations = {B.S A Crescent Institute of Science and Technology, Tamil Nadu, Chennai, India},
	abstract = {The surge in hate speech on social media, notably platforms like Twitter, is a mounting concern due to its potential harm to individuals and entire communities, fostering toxicity, discrimination, and violence. Primarily targeting protected categories such as gender, religion, and disability, hate speech also extends to characteristics like sexual orientation and political affiliation. Mitigating this issue requires robust measures, and the proposed methodology offers a multifaceted approach. The methodology uses natural language processing (NLP) techniques like sentiment analysis, and topic modelling to discern potentially harmful content. Advanced deep learning algorithms such as Random Forest, Long-Short Term Memory (LSTM), and Recurrent Neural Network (RNN), are then employed for hate speech classification and filtration. The resultant web application framework provides social media companies with a proactive tool to monitor and eliminate hate speech. The methodology uses NLP techniques and machine learning algorithms such as Random Forest (accuracy: 0.79%), deep learning algorithms like LSTM (accuracy: 0.68%), and RNN (accuracy: 1.0%), collectively offering a promising solution. Beyond technical interventions, it is crucial to promote awareness and education about the harmful effects of hate speech. Working and coordinating with community leaders, advocacy groups, and educators, social media platforms can provide resources and training on respectful communication, diversity, and inclusion. Transparent communication with users about hate speech policies and enforcement actions further fosters a culture of respect online. Overall, the proposed methodology, coupled with educational efforts, aims to create a safer, more inclusive online community. By synergizing technical solutions and fostering awareness, it aims to mitigate the adverse impacts of hate speech, promoting a positive and respectful online environment for all users. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hate Speech; Natural Language Processing; Sentiment Analysis; Social Media Platforms},
	keywords = {Computational linguistics; Learning algorithms; Long short-term memory; Modeling languages; Social networking (online); Speech communication; Speech recognition; Hate speech; Language processing; Language processing techniques; Natural language processing; Natural languages; Random forests; Sentiment analysis; Social media; Social media platforms; Speech detection; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 23rd International Conference on Intelligent Systems Design and Applications, ISDA 2023; Conference date: 11 December 2023 through 13 December 2023; Conference code: 315609}
}

@ARTICLE{Gupta2024717,
	author = {Gupta, Pradeep and Gupta, Sonam and Goel, Lipika and Yadav, Vikash and Singh, Divya},
	title = {Hate Speech Detection: Recent Advancements and Emerging Technologies},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1043 LNNS},
	pages = {717 – 731},
	doi = {10.1007/978-981-97-4228-8_46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208912102&doi=10.1007%2f978-981-97-4228-8_46&partnerID=40&md5=dbfa1eaf81c58788343d405826df3a2e},
	affiliations = {Ajay Kumar Garg Engineering College, Ghaziabad, India; Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India; Department of Technical Education, Government Polytechnic Bighapur Unnao, Uttar Pradesh, Bighapur, India},
	abstract = {Hate speech is a developing subject of research due to its effects on people and the community on the Internet. This paper reviews discrimination analysis research, emphasizing recent developments and new technologies. Hate speech analysis uses several approaches, methods, data, and metrics. It also analyzes problems regarding technology use. The rise of digital the channels that quickly circulate information that damages society made hate speech research studies important. Discrimination research advances and new technologies are examined in this literature. The research covers NLP, machine learning, and social sciences. This review covers discrimination research methods, datasets, measurements, and problems. The paper discusses speech discrimination using advanced deep learning techniques including RNNs, CNNs, and transformers. The investigation addresses discrimination tool ethics, biases, and limitations. It impacts future research and Internet hate speech for prevention purposes. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {CNN; Hate speech; NLP; RNN; Social media},
	keywords = {Contrastive Learning; Deep learning; Speech recognition; Analysis problems; Discrimination analysis; Emerging technologies; Hate speech; Research studies; RNN; Social media; Speech detection; Speech research; Technology use; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Innovative Computing and Communication, ICICC 2024; Conference date: 16 February 2024 through 17 February 2024; Conference code: 316239}
}

@CONFERENCE{Hakim2024374,
	author = {Hakim, Atalla Naufal and Sibaroni, Yuliant and Prasetyowati, Sri Suryani},
	title = {Detection of Hate-Speech Text on Indonesian Twitter Social Media Using IndoBERTweet-BiLSTM-CNN},
	year = {2024},
	journal = {2024 12th International Conference on Information and Communication Technology, ICoICT 2024},
	pages = {374 – 381},
	doi = {10.1109/ICoICT61617.2024.10698615},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207415731&doi=10.1109%2fICoICT61617.2024.10698615&partnerID=40&md5=c46889aaa28f92cc3c5d49f118e01cfe},
	affiliations = {School of Computing, Telkom University, Bandung, Indonesia},
	abstract = {Social media Twitter has become the second place in people's lives to express themselves. Social media users can comment on whatever they want, and it is not uncommon to find comments that contain hate-speech. If it is not stopped, hate-speech can spread quickly, therefore it is necessary to detect hate-speech. In this research, the detection of hate-speech was carried out using IndoBERTweet, which is a development of the BERT model that has been previously trained using data from Indonesian language Twitter, so it is suitable for classifying Indonesian language texts. BiLSTM and CNN are deep-learning methods that can be used for text classification. This research aims to detect hate-speech texts using these three methods and then combining them. To carry out optimization, experiments were carried out on batch size and learning rate values. With a batch size of 8 and a learning rate of 0.001, the best accuracy is 85.45%, and the F1-Score is 85.06%. © 2024 IEEE.},
	author_keywords = {BiLSTM; CNN; hate-speech; IndoBERTweet; Text Classification},
	keywords = {Batch sizes; BiLSTM; Hate-speech; Indobertweet; Indonesian languages; Learning methods; Learning rates; Optimisations; Social media; Text classification; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th International Conference on Information and Communication Technology, ICoICT 2024; Conference date: 7 August 2024 through 8 August 2024; Conference code: 203195}
}

@ARTICLE{Ponnambalam2024149,
	author = {Ponnambalam, Satheesh Kumar and Desai, Darshana},
	title = {Sentiment Analysis and Offensive Language Identification in Code-Mixed Tamil-English Languages Using Transformer-Based Models},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2092 CCIS},
	pages = {149 – 167},
	doi = {10.1007/978-3-031-64070-4_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202181684&doi=10.1007%2f978-3-031-64070-4_9&partnerID=40&md5=41666ebd8ac2d45c78fa29b3db98d6bc},
	affiliations = {SSBM, Geneva, Switzerland; Indira College of Engineering and Management, SPPU, Pune, India},
	abstract = {In multilingual countries like India, code-mixed text is common on social platforms. Current NLP tools, primarily trained on monolingual corpora, struggle with downstream tasks in code-mixed languages. Researchers have tried various methods for Sentiment Analysis (SA) and Offensive Language Identification (OLI) in code-mixed Dravidian languages, but none have combined semantic information from the last three hidden layers of multilingual Transformer models (XLM-RoBERTa-Base, MuRIL and DistilmBERT) with a Genetic Algorithm (GA) based ensembling technique and Multi-Task Learning (MTL) framework. This study proposes such an approach for classifying sentiments and offensive language in code-mixed Tamil using the DravidianLangTech-EACL2022 dataset. Results show that using semantic information from multilingual Transformer models improves performance and GA-based ensembling outperforms standard average ensembling. The best model (Genetic ensembling of XLM-R0BERTa-Base, MuRIL and DistilmBERT with cross entropy loss, AdamW optimizer, learning rate of 1e-5 and dropout of 0.4) achieved a weighted F1-score of 58.00% for Sentiment Analysis and 74.00% for Offensive Language Identification in Tamil-English Code-Mixed dataset. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Code-Mixed; DistilmBERT; Genetic Algorithm Ensemble; Multi-Task Learning; MuRIL; Offensive Language Identification; Sentiment Analysis; Standard Average Ensemble; Transformers; XLM-RoBERTa},
	keywords = {Economic and social effects; Multi-task learning; Code-mixed; Distilmbert; Genetic algorithm ensemble; Language identification; Multitask learning; MuRIL; Offensive language identification; Offensive languages; Sentiment analysis; Standard average ensemble; Transformer; XLM-RoBERTa; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Advanced Network Technologies and Intelligent Computing, ANTIC 2023; Conference date: 20 December 2023 through 22 December 2023; Conference code: 316879}
}

@CONFERENCE{Charfi2024478,
	author = {Charfi, Anis and Atalla, Andria and Akasheh, Raghda and Bessghaier, Mabrouka and Zaghouani, Wajdi},
	title = {A Web-Based Hate Speech Detection System for Dialectal Arabic},
	year = {2024},
	journal = {Proceedings of the 13th International Conference on Data Science, Technology and Applications, DATA 2024},
	pages = {478 – 485},
	doi = {10.5220/0012812000003756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203061803&doi=10.5220%2f0012812000003756&partnerID=40&md5=cc9708f4130ed3c147ae8934105f7c38},
	affiliations = {Carnegie Mellon University in Qatar, Education City, Doha, Qatar; Carnegie Mellon University in Qatar, Education City, Doha, Qatar},
	abstract = {A significant issue in today’s global society is hate speech, which is defined as any kind of expression that attempts to degrade an individual or a society based on attributes such as race, color, nationality, gender, or religion (Schmidt and Wiegand, 2017). In this paper, we present a Web-based hate speech detection system that focuses on the Arabic language and supports its various dialects. The system is designed to detect hate speech within a given sentence or within a file containing multiple sentences. Behind the scenes, our system makes use of the AraBERT model trained on our ADHAR hate speech corpus, which we developed in previous work. The output of our system discerns the presence of hate speech within the provided sentence by categorizing it into one of two categories:”Hate” or”Not hate”. Our system also detects different categories of hate speech such as race-based hate speech and religion-based hate speech. We experimented with various machine learning models, and our system achieved the highest accuracy, along with an F1-score of 0.94, when using AraBERT. Furthermore, we have extended the functionality of our tool to support inputting a file in CSV format and to visualize the output as polarization pie charts, enabling the analysis of large datasets. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Annotation; Arabic Corpus; Arabic Language; Dialectal Arabic; Hate Speech; Natural Language Processing},
	keywords = {Adversarial machine learning; Natural language processing systems; Speech recognition; Websites; Annotation; Arabic corpus; Arabic languages; Dialectal arabics; Hate speech; Language processing; Natural language processing; Natural languages; Speech detection; Web based; Large datasets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 13th International Conference on Data Science, Technology and Applications, DATA 2024; Conference date: 9 July 2024 through 11 July 2024; Conference code: 201842}
}

@CONFERENCE{Pachinger202411990,
	author = {Pachinger, Pia and Goldzycher, Janis and Planitzer, Anna Maria and Kusa, Wojciech and Hanbury, Allan and Neidhardt, Julia},
	title = {AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {11990 – 12001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205302065&partnerID=40&md5=4a163769a3265f4828609d106addc014},
	affiliations = {TU Wien, Austria; University of Zurich, Switzerland; University of Vienna, Austria},
	abstract = {Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian German dialect, comprising 4,562 user comments. In addition to binary offensiveness classification, we identify spans within each comment constituting vulgar language or representing targets of offensive statements. We evaluate fine-tuned language models as well as large language models in a zero- and few-shot fashion. The results indicate that while fine-tuned models excel in detecting linguistic peculiarities such as vulgar dialect, large language models demonstrate superior performance in detecting offensiveness in AustroTox. We publish the data and code. © 2024 Association for Computational Linguistics.},
	keywords = {Classification (of information); Modeling languages; Excel; Interpretability; Language detection; Language model; Offensive languages; Performance; Toxicity detection; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Findings of the 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202475}
}

@ARTICLE{Asante2024189,
	author = {Asante, Andrew and Hajek, Petr},
	title = {Detecting Antisocial Behavior on Social Media During COVID-19 Lockdown},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1170 LNNS},
	pages = {189 – 200},
	doi = {10.1007/978-3-031-73344-4_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207540394&doi=10.1007%2f978-3-031-73344-4_15&partnerID=40&md5=f3ad8337318ef4d4bc1b63aaa43bd140},
	affiliations = {Science and Research Centre, Faculty of Economics and Administration, University of Pardubice, Studentska 84, Pardubice, 53210, Czech Republic},
	abstract = {The widespread availability of the internet has rendered the engagement with social media an integral component of contemporary society. Platforms such as Facebook, Twitter/X, YouTube, among others, are designed to facilitate extensive, efficient, and sustained user participation, offering both anonymity and opportunities for positive engagement. However, these platforms have also become arenas for antisocial behaviors, including disregard for others’ rights, lack of empathy, trolling, and aggression, leading to significant negative psychological impacts on affected individuals. These impacts range from anxiety and emotional trauma to depression, psychological disorders, self-isolation, diminished self-esteem, and even suicidal thoughts. This study focuses on antisocial behavior (ASB) manifested in tweets from Ghana during the 21-day COVID-19 lockdown. We develop a gold-standard annotated ASB corpus from collected and pre-processed data. We then assess the performance of different baseline classifiers against three transformer models-BERT, RoBERTa, and ELECTRA-in a binary classification task designed to detect ASB. Each model demonstrated varying degrees of success; however, the RoBERTa model, upon fine-tuning, exhibited superior performance, achieving an accuracy rate of 95.59% and an F1 score of 94.99%, thereby outperforming the other models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Antisocial behavior; Large language model; Social media; Transformer},
	keywords = {Social behavior; Social psychology; Antisocial behavior; Facebook; Integral components; Language model; Large language model; Performance; Social media; Transformer; User participation; YouTube; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Novel and Intelligent Digital Systems, NiDS 2024; Conference date: 25 September 2024 through 27 September 2024; Conference code: 321459}
}

@ARTICLE{Aklouche20241031,
	author = {Aklouche, Billel and Bazine, Yousra and Ghalia-Bououchma, Zoumrouda},
	title = {Offensive Language and Hate Speech Detection Using Transformers and Ensemble Learning Approaches},
	year = {2024},
	journal = {Computacion y Sistemas},
	volume = {28},
	number = {3},
	pages = {1031 – 1039},
	doi = {10.13053/CyS-28-3-4724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210927600&doi=10.13053%2fCyS-28-3-4724&partnerID=40&md5=383b1db1c8810caebe3815a6f146528b},
	affiliations = {University of Constantine 2, Abdelhamid Mehri, LIRE Laboratory, Algeria; University of Constantine 2, Abdelhamid Mehri, TLSI Department, Algeria},
	abstract = {Social networks play a vital role in facilitating communication and information sharing. However, these platforms are also witnessing a growing prevalence of hate content, which can pose a major threat to individuals and entire communities. In this paper, we propose a new method that addresses the problem of offensive language and hate speech detection using seven transformer models, including BERT, and six ensemble learning strategies (Majority Voting, Averaging, Highest-sum, Stacking, Boosting and Bagging). Specifically, a fine-tuning process is run for each pre-trained model on hate speech detection downstream task. Subsequently, various ensemble learning techniques are applied by combining the predictions of individual models in order to improve overall performance. Extensive experiments have been conducted on the publicly available Davidson-dataset to assess the performance of our proposed method. Evaluation demonstrates promising results in terms of various evaluation metrics, outperforming competitive state-of-the-art baselines. © 2024 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {ensemble learning; fine-tuning; Hate speech detection; offensive language; social media; transformers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rastogi2024147,
	author = {Rastogi, Aryan and Kumar, Arjit and Dwivedi, Daarshik and Singh, Abhishek Pratap and Saberwal, Suruchi and Alam, Mehboob},
	title = {Hate Speech Detection on Twitter: A Comparative Evaluation of Different Machine Learning Techniques},
	year = {2024},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1191 LNEE},
	pages = {147 – 159},
	doi = {10.1007/978-981-97-2508-3_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205340875&doi=10.1007%2f978-981-97-2508-3_11&partnerID=40&md5=83d1ba692768e990a7387359e93e50af},
	affiliations = {Department of Computer Science, JSS Academy of Technical Education, Uttar Pradesh, Noida, India},
	abstract = {The necessity for robust and fast detection techniques has become critical as social media hate speech has grown. This study investigates ways to identify hate speech comments present on Twitter using language processing methods. In this work, we suggest a cutting-edge method for effectively identify hate speech in tweets that combines linguistic elements and machine learning techniques. Using a sizable dataset of annotated tweets, we test our model, and we get good F1-score and accuracy. The findings of this study present the possibilities of using techniques for processing natural language to identify hateful speech on Twitter and can assist in direct the creation of efficient regulations and interventions to lessen the negative consequences of hate speech on social media sites. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Hateful speech; Machine learning; Tweets; Twitter},
	keywords = {Adversarial machine learning; Contrastive Learning; Comparative evaluations; Fast detections; Hateful speech; Language processing; Machine learning techniques; Machine-learning; Processing method; Robust detection; Social media; Speech detection; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Artificial-Business Analytics, Quantum and Machine Learning: Trends, Perspectives, and Prospects, Com-IT-Con 2023; Conference date: 14 July 2023 through 15 July 2023; Conference code: 319829}
}

@CONFERENCE{Gangarde2024,
	author = {Gangarde, Rupali and Ghosh, Moubani and Thacker, Ravi},
	title = {Enhancing Online Safety: Automated Hate Speech Detection on Instagram with BERT-powered Model and Real-time Moderation},
	year = {2024},
	journal = {Proceedings of InC4 2024 - 2024 IEEE International Conference on Contemporary Computing and Communications},
	doi = {10.1109/InC460750.2024.10649076},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203791136&doi=10.1109%2fInC460750.2024.10649076&partnerID=40&md5=85e885a93d601a0bca7b6d2a0e63f961},
	affiliations = {Symbiosis Institute of Technology, Department of CSE, Pune, India},
	abstract = {This paper introduces an innovative hate speech detection model tailored for Instagram, utilizing the powerful Bidirectional Encoder Representations from Transformers (BERT) model. Through a meticulous integration of BERT with an elaborate data collection strategy and refined methodology, the study seeks to enhance precision and recall, mitigating false positives and negatives, thereby fostering a safer and more inclusive online environment on Instagram. Addressing the existing research gap, the model distinguishes itself by incorporating real-world context and addressing nuanced language nuances often missed by current hate speech detection models. The HateXplain dataset is employed for training and validation, complemented by a web scraping strategy for collecting real-time Instagram comments via the 'Insc' extension. The BERT model undergoes fine-tuning to adapt to Instagram-specific language patterns. The comprehensive methodology spans data selection, training, and integration with Instagram, classification, evaluation, and real-time deployment. The anticipated contributions and findings include the model's superiority in accuracy and performance metrics, such as precision, recall, and F1-score, and its effectiveness in detecting diverse forms of hate speech while maintaining robustness. Comparative analysis showcases the advantages of BERT over LSTM models in terms of accuracy and contextual understanding. The paper suggests future directions, urging exploration of multilingual support, user profile integration for enhanced context, and experimentation with multi-modal hate speech detection incorporating images and videos. In summary, this paper offers a promising avenue for combating hate speech on Instagram, striving to contribute to the creation of a safer and more inclusive online community.  © 2024 IEEE.},
	author_keywords = {BERT; HateXplain; LSTM; NLP Introduction (Heading 1); RNN},
	keywords = {Speech enhancement; Bidirectional encoder representation from transformer; Detection models; Hatexplain; Introduction (Heading 1); LSTM; NLP introduction (heading 1); Real- time; RNN; Speech detection; Transformer modeling; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Contemporary Computing and Communications, InC4 2024; Conference date: 15 March 2024 through 16 March 2024; Conference code: 202291}
}

@ARTICLE{L. Imbwaga2024289,
	author = {L. Imbwaga, Joan and B. Chittaragi, Nagaratna and G. Koolagudi, Shashidhar},
	title = {Hate Speech Detection in Audio Using SHAP - An Explainable AI},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2091 CCIS},
	pages = {289 – 304},
	doi = {10.1007/978-3-031-64064-3_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202215551&doi=10.1007%2f978-3-031-64064-3_21&partnerID=40&md5=01d34a93b4c740277becefbd552498b0},
	affiliations = {National Institute of Technology, Karnataka, India; Siddaganga Institute of Technology, Tumkur, Karnataka, India},
	abstract = {Hate speech detection is a process of recognition of communication media such as text, audio, and/or video, if it contains hatred and/or encourages violence towards a person or a community of people. This is usually based on prejudice against ’protected characteristics’ such as their ethnicity, gender, sexual orientation, religion, age and so on. Complex and sophisticated classifiers based hate speech detection systems are available in the literature. However, the characteristics exhibited by explainable artificial intelligence techniques demonstrated versatile capabilities. This potential is due to the complex classifiers presenting themselves as black-box in nature hence limiting the social acceptability and usability of the developed systems. In this study, video datasets for English and Kiswahili languages were manually collected from YouTube, converted to audio, and used to detect hate speech. Ensemble based classification algorithms have been used for implementation of hate speech detection system. Random Forest classifier recorded an accuracy of 95.8% for English language while for Kiswahili language, Extreme Gradient Boosting classifier achieved an accuracy of 91.8%. To explain the results achieved by these classifiers, in terms of how specific audio-based features contributed to the overall detection of hate speech, SHapley Additive exPlanations technique (SHAP) is used. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hate Speech; Kiswahili; MFCCs; Prosodic; SHAP; XAI},
	keywords = {Adaptive boosting; Classification (of information); Economic and social effects; Audio videos; Communication media; Detection system; Hate speech; Kiswahilus; MFCC; Prosodics; SHAP; Speech detection; XAI; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 3rd International Conference on Advanced Network Technologies and Intelligent Computing, ANTIC 2023; Conference date: 20 December 2023 through 22 December 2023; Conference code: 316879}
}

@CONFERENCE{Ren2024,
	author = {Ren, Hang and Yang, Jin and Ni, Shengqiao and Yang, Qin and Zhang, Jing and Qun, Nuo},
	title = {A Method for Tibetan Offensive Language Detection Based on Prompt Learning and Information Theory},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10651369},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204984146&doi=10.1109%2fIJCNN60899.2024.10651369&partnerID=40&md5=18ac2fa33e3adefea4d74724271c3d42},
	affiliations = {Tibet University, School of Information Science and Technology, Lhasa, 850000, China; Collaborative Innovation Center for Tibet Informatization by MOE and Tibet Autonomous Region, Lhasa, 850000, China; Sichuan University, School of Cyber Science and Engineering, Chengdu, 610065, China; Sichuan University, School of Mechanical Engineering, Chengdu, 610065, China},
	abstract = {Offensive language on social media is a serious social problem, which affects people's mental health and social harmony. However, there is a lack of effective detection methods for Tibetan offensive language, which makes the supervision and management of Tibetan social media platforms challenging. To effectively detect Tibetan offensive language, this paper proposes a method based on prompt learning and information theory, which has the following three characteristics: (1) It uses prompt learning technique to transform the text classification problem into a masked language modeling problem, and uses multi-label words based on external knowledge as the output of the verbalizer function, thus improving the model's transferability and semantic expression; (2) It uses weighted cross-entropy loss and batch-averaged Kullback-Leibler divergence loss to balance the loss of different categories, and constrains the model output distribution under different dropout to be consistent, thus solving the overfitting problem and enhancing robustness; (3) It uses prior distribution to adjust the model output logits, making the model output closer to the true label distribution, increasing mutual information, compensating for the loss caused by class imbalance and magnitude mismatch, thus solving the class imbalance problem in the dataset. This paper uses current best mainstream model XLM-RoBerta (CINO) as the baseline, and conducts experiments on the newly collected dataset TOLD (Tibetan Offensive Language Dataset), which shows that this paper's method can significantly improve the performance and generalization ability of Tibetan offensive language detection model, achieving 82.2% and 79.9% in accuracy and F1 score respectively, which are 3.5% and 2.5% higher than the baseline. This paper provides an effective offensive language detection tool for Tibetan social media platforms, which helps to maintain the order and security of cyberspace. © 2024 IEEE.},
	author_keywords = {Information theory; Prompt learning; Tibetan offensive language detection},
	keywords = {Economic and social effects; Problem solving; Language detection; Mental health; Model outputs; Offensive languages; Prompt learning; Social media; Social media platforms; Social problems; Tibetan offensive language detection; Tibetans; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Joint Conference on Neural Networks, IJCNN 2024; Conference date: 30 June 2024 through 5 July 2024; Conference code: 202527}
}

@CONFERENCE{Garg2024,
	author = {Garg, Bhavika and Bhardwaj, Aditya and Jain, Tarun},
	title = {Detection of Hate Speech and Offensive Language Using Machine Learning and Deep Learning for Multi-Class Tweets},
	year = {2024},
	journal = {2024 IEEE International Conference on Smart Power Control and Renewable Energy, ICSPCRE 2024},
	doi = {10.1109/ICSPCRE62303.2024.10675191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212060118&doi=10.1109%2fICSPCRE62303.2024.10675191&partnerID=40&md5=85c0b6e9679f6d1bff49da728f26eb00},
	affiliations = {Manipal University Jaipur, Department of Computer Science and Engineering, Jaipur, India; School of Computer Science Engineering and Technology (SCSET), Bennett University, Greater Noida, India},
	abstract = {Nowadays, every single person is indulged in social media, and because of its hidden characteristics, people are free to express their views and thoughts and expressing their views freely is their right. Expressing their thoughts and views on dynamic news puts a positive impact in economy, as it shows how people relate to each other. Yet, there are times when individuals throw toxic comments or accusing them on the grounds of caste, religion, gender identity, ethnicity etc. is a harassment of the given freedom. Due to this, hate and offensive language has become the serious issue, in modern society, which leads to damaging the people's peace, their human rights as well as creating an inequality in society. In this research paper, the dataset has been taken from the Kaggle source, sentiment analysis will be done on the detection of hate speech and offensive language, and the classification will be done on the following three labels: Hate Speech, Offensive Language and Neither. © 2024 IEEE.},
	author_keywords = {Feature Extraction; Hate Speech; Machine Learning; Natural Language Processing; Offensive Language; Sentiment Analysis},
	keywords = {Deep learning; Tweets; Features extraction; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Offensive languages; ON dynamics; Sentiment analysis; Social media; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st IEEE International Conference on Smart Power Control and Renewable Energy, ICSPCRE 2024; Conference date: 19 July 2024 through 21 July 2024; Conference code: 204377}
}

@ARTICLE{Alsekait2024811,
	author = {Alsekait, Deema Mohammed and Shdefat, Ahmed Younes and AlArnaout, Zakwan and Mohamed, Nermin Rafiq and Fathi, Hanaa and AbdElminaam, Diaa Salama},
	title = {Semantic Safeguards: Harnessing BERT and Advanced Deep Learning Models Outperforming in the Detection of Hate Speech on Social Networks},
	year = {2024},
	journal = {Applied Mathematics and Information Sciences},
	volume = {18},
	number = {4},
	pages = {811 – 825},
	doi = {10.18576/amis/180413},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202760274&doi=10.18576%2famis%2f180413&partnerID=40&md5=a608cf32462ebae43ce195c41f9d5b64},
	affiliations = {Department of Computer Science and Information Technology, Applied College, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia; College of Engineering and Technology, American University of the Middle East, Egaila, 54200, Kuwait; Department of Educational Fundamentals, Faculty of Physical Education, Sadat City University, Sadat City, 32958, Egypt; Applied Science Research Center, Applied Science Private University, Amman, Jordan; Information Systems Department, Faculty of Computers and Artificial Intelligence, Benha University, Benha, Egypt; Data Science Department, Faculty of Computer Science, Misr International University, Cairo, Egypt; MEU Research Unit, Middle East University, Amman, Jordan},
	abstract = {This paper presents an innovative approach for hate speech detection on social media platforms utilizing optimized deep learning algorithms. Capitalizing on the strengths of four machine learning algorithms (Decision Trees, Support Vector Machines, Naive Bayes, and K-Nearest Neighbors), two deep learning algorithms (Bidirectional Long Short-Term Memory and Recurrent Neural Networks), and a transformer model (Bidirectional Encoder Representations from Transformers, BERT), this research aims to classify text as hate speech efficiently. By implementing feature extraction techniques—TF-IDF for machine learning models and embedding layers for deep learning and transformer models—we leverage two datasets comprising English tweets from Twitter and Facebook. The results indicate a superior performance of the BERT model, achieving an impressive 95% accuracy on the HSOL dataset and 67% on the HASOC dataset, thus significantly advancing the hate speech detection methodology. This paper’s methods and findings enhance the existing body of knowledge and provide a reliable model for improving online social interaction safety. The novelty of our work lies in the comprehensive preprocessing and the application of BERT in this context, marking a significant scientific contribution with practical implications for creating a more inclusive online community. © 2024 NSP Natural Sciences Publishing Cor.},
	author_keywords = {Bidirectional Encoder Representations from Transformers (BERT); Deep Learning; Emotion and Speech Analysis; Hate Speech; Social Media Text Analysis; Transformer Models; Transformer Neural Networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wu2024,
	author = {Wu, Xiaodong and Wu, Hao and He, Pei},
	title = {Leveraging Domain-Specific Word Embedding and Hate Concepts in Hate Speech Detection},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10650500},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205018882&doi=10.1109%2fIJCNN60899.2024.10650500&partnerID=40&md5=0faab5b248d5ccaba55f870b599fd7ee},
	affiliations = {Guangzhou University, School of Computer Science and Cyber Engineering, Guangzhou, China},
	abstract = {Malicious spreading of hate speech on social media hinders the construction of a harmonious online environment, so efficient automatic hate detection become crucial. However, due to the short text form in which most hate speech exists, the semantic features of these texts are relatively sparse, making it difficult for models to learn enough knowledge for classification. Additionally, an increasing number of hate speech tends to use abbreviated and misspelled hate words to evade detection, making it challenging for many hate speech detection methods to capture hidden hate intents. In this paper, we propose a hate speech detection model based on multi-source feature fusion. The model not only takes into account hate concepts and semantic structure information in the target sentence, but also recognizes abbreviated and misspelled hate words by introducing domain-specific word embedding.Ultimately, it dynamically fuses multisource feature through the attention mechanism to enrich the expressive ability of feature vector and realize the effective detection of complex hate speech. We conduct detailed comparison and ablation experiments, and the results prove the effectiveness of our proposed model. © 2024 IEEE.},
	author_keywords = {deep learning; hate speech; machine learning; text classification},
	keywords = {Contrastive Learning; Deep learning; Embeddings; Semantics; Speech recognition; Deep learning; Domain specific; Embeddings; Hate speech; Machine-learning; Multi-Sources; Online environments; Social media; Speech detection; Text classification; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Joint Conference on Neural Networks, IJCNN 2024; Conference date: 30 June 2024 through 5 July 2024; Conference code: 202527}
}

@CONFERENCE{Jayapriya20242421,
	author = {Jayapriya, P. and Kishore Vel, I.V. and Kishore, P. and Logesh Krishna, M.R. and Naveen Raja, S.},
	title = {Hate Speech Detection Using Support Vector Machine (SVM)},
	year = {2024},
	journal = {10th International Conference on Advanced Computing and Communication Systems, ICACCS 2024},
	pages = {2421 – 2424},
	doi = {10.1109/ICACCS60874.2024.10716982},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208611063&doi=10.1109%2fICACCS60874.2024.10716982&partnerID=40&md5=341d0b45d8cb76864d51ff2d868bc0b5},
	affiliations = {Sri Eshwar College of Engineering, Department of Cse, Coimbatore, India},
	abstract = {The burgeoning prevalence of hate speech in the digital era necessitates effective detection methods. This research paper offers a thorough investigation and comparative assessment of hate speech detecting techniques, aiming to support and also contribute to the development of precise and robust detection systems. We delve into a spectrum of methodologies with a focus on discerning hate speech within textual data. The study confronts the intricate challenges inherent in accurately classifying hate speech, including the complexities of contextual comprehension, linguistic subtleties, and the ever-evolving nature of hate speech lexicons. Our research assesses the efficacy of diverse Hate Speech Detection (HSD) models across varied datasets, elucidating the merits and shortcomings of each approach. Furthermore, we address ethical quandaries and potential biases that may surface in the deployment of hate speech detection systems, underscoring the imperative for equitable and transparent system design. This inquiry offers invaluable insights for researchers, practitioners, and policymakers committed to countering the proliferation of hate speech in online spaces. © 2024 IEEE.},
	author_keywords = {feature extraction; Hate Speech; SVM; Text identification},
	keywords = {Speech recognition; Support vector machines; Comparative assessment; Detection methods; Detection system; Digital era; Features extraction; Hate speech; Research papers; Speech detection; Support vectors machine; Text identification; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 10th International Conference on Advanced Computing and Communication Systems, ICACCS 2024; Conference date: 14 March 2024 through 15 March 2024; Conference code: 203503}
}

@CONFERENCE{Madhukar2024,
	author = {Madhukar, Ayush and Madhukar, Aparnay and Anubhav and Ishan and Nagpal, Sushama},
	title = {An Ensemble Based Approach to Detect Hate Speech},
	year = {2024},
	journal = {2024 IEEE Region 10 Symposium, TENSYMP 2024},
	doi = {10.1109/TENSYMP61132.2024.10752152},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211920158&doi=10.1109%2fTENSYMP61132.2024.10752152&partnerID=40&md5=a0b210787961c8fef91acc408a706aff},
	affiliations = {Netaji Subhas University of Technology, Computer Science and Engg, Delhi, New Delhi, Dwarka, India},
	abstract = {In recent times, we see numerous hate speech incidents related to different domains like: gender, caste, religion, etc. The sudden outburst of users over the online forums has aggravated this issue. Given the relentless stream of content posted on online sites, the task of manually filtering hateful posts is a difficult task. Furthermore, in ML models there exist problems of generalization. In order to tackle this problem, we have proposed an ensemble model based on CNN+LSTM - a deep learning technique and RoBERTa - transformer based model. We have trained our model on three popular datasets namely HASOC, Davidson and HatEval and also on the combination of these three to get more generalized results. The outcome of the research indicates that the presented ensemble model gives better accuracy and F1 score on the combined data set as compared to the individual method.  © 2024 IEEE.},
	author_keywords = {BERT; Deep Neural Network; Hate speech; Roberta; Transfer learning; Word embeddings},
	keywords = {Adversarial machine learning; Deep neural networks; Network embeddings; BERT; Different domains; Embeddings; Ensemble models; Hate speech; Neural-networks; Online forums; Robertum; Transfer learning; Word embedding; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 IEEE Region 10 Symposium, TENSYMP 2024; Conference date: 27 September 2024 through 29 September 2024; Conference code: 204286}
}

@ARTICLE{Kousar2024106631,
	author = {Kousar, Abida and Ahmad, Jameel and Ijaz, Khalid and Yousef, Amr and Ahmed Shaikh, Zaffar and Khosa, Ikramullah and Chavali, Durga and Anjum, Mohd},
	title = {MLHS-CGCapNet: A Lightweight Model for Multilingual Hate Speech Detection},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {106631 – 106644},
	doi = {10.1109/ACCESS.2024.3434664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200260907&doi=10.1109%2fACCESS.2024.3434664&partnerID=40&md5=4fd44ff2e58561b6b821b8a9969eb6f4},
	affiliations = {University of Management and Technology, School of Systems and Technology, Department of Artificial Intelligence, Lahore, 54770, Pakistan; University of Management and Technology, School of Systems and Technology, Department of Computer Science, Lahore, 54770, Pakistan; University of Business and Technology, Electrical Engineering Department, Jeddah, 23435, Saudi Arabia; Alexandria University, Engineering Mathematics Department, Alexandria, 21544, Egypt; Benazir Bhutto Shaheed University Lyari, Department of Computer Science and Information Technology, Karachi, 75660, Pakistan; School of Engineering Ecole Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland; COMSATS University Islamabad, Department of Electrical and Computer Engineering, Lahore Campus, Lahore, 54000, Pakistan; Trinity Information Services, Trinity Health, Livonia, 48152, MI, United States; Aligarh Muslim University, Department of Computer Engineering, Aligarh, 202002, India},
	abstract = {The rapid advancement of computer technology and the widespread adoption of online social media platforms have inadvertently provided fertile ground for individuals with antisocial inclinations to thrive, ushering in a range of security concerns, including the proliferation of fake profiles, hate speech, social bots, and the spread of unfounded rumors. Among these issues, a prominent concern is the prevalence of hate speech within online social networks (OSNs). However, the relevance of numerous studies on hate speech detection has been limited, as they primarily focus on a single language, often English. In response, our research embarks on an exhaustive exploration of multilingual hate speech across 12 distinct languages, offering a novel approach by adapting hate speech detection resources across linguistic boundaries. This study presents the development of a robust, lightweight and multilingual hate speech detection model, known as MLHS-CGCapNet, which combines convolutional and bidirectional gated recurrent units with a capsule network. With commendable accuracy, recall and f-score values of 0.89, 0.80, and 0.84, respectively, our proposed model exhibits strong performance, even when handling an imbalanced dataset. Notably, during the training and validation phases, the suggested model showcases exceptional effectiveness, achieving accuracy values of 0.93 and 0.90, respectively, particularly in the challenging context of imbalanced data. In comparison to both baseline and state-of-the-art techniques, our model offers superior performance.  © 2024 The Authors.},
	author_keywords = {BiGRU; capsule network; deep learning; Hate speech detection; social networks},
	keywords = {Blogs; Deep learning; Feature extraction; Social sciences computing; Speech recognition; Accuracy; BiGRU; Capsule network; Context models; Deep learning; Features extraction; Hate speech; Hate speech detection; Social network; Social networking (online); Speech detection; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Casula202411240,
	author = {Casula, Camilla and Leonardelli, Elisa and Tonelli, Sara},
	title = {Don't Augment, Rewrite? Assessing Abusive Language Detection with Synthetic Data},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {11240 – 11247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205311086&partnerID=40&md5=96e0f91b82f68b3e427089b13883feaf},
	affiliations = {Fondazione Bruno Kessler, Italy; University of Trento, Italy},
	abstract = {Research on abusive language detection and content moderation is crucial to combat online harm. However, current limitations set by regulatory bodies and social media platforms can make it difficult to share collected data. We address this challenge by exploring the possibility to replace existing datasets in English for abusive language detection with synthetic data obtained by rewriting original texts with an instruction-based generative model. We show that such data can be effectively used to train a classifier whose performance is in line, and sometimes better, than a classifier trained on original data. Training with synthetic data also seems to improve robustness in a cross-dataset setting. A manual inspection of the generated data confirms that rewriting makes it impossible to retrieve the original texts online. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Data assimilation; Current limitation; Generative model; Language content; Language detection; Manual inspection; Performance; Regulatory bodies; Social media platforms; Synthetic data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Findings of the 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202475}
}

@ARTICLE{Jarquin-Vasquez2024,
	author = {Jarquin-Vasquez, Horacio and Escalante, Hugo Jair and Montes-Y-Gomez, Manuel and Gonzalez, Fabio A.},
	title = {GHA: a Gated Hierarchical Attention Mechanism for the Detection of Abusive Language in Social Media},
	year = {2024},
	journal = {IEEE Transactions on Affective Computing},
	doi = {10.1109/TAFFC.2024.3483010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207734497&doi=10.1109%2fTAFFC.2024.3483010&partnerID=40&md5=7498870699a7d1ca0d5226a4873a1124},
	abstract = {The use of attention mechanisms in deep learning solutions has become popular within natural language processing tasks. The use of these mechanisms allows managing the relevance of the elements of a sequence in accordance with their context, however, this relevance has been observed independently between the pairs of elements of a sequence (self-attention) or between the application domain of a sequence (contextual attention), leading to the loss of relevant information and limiting the representation of the sequences. To tackle these particular issues, we propose a dual attention mechanism, which trades off the previous limitations, by considering the internal and contextual relationships between the elements of the sequence. Additionally, we propose the extension of the dual attention mechanism into a multi-layer perspective, through the weighted fusion of the different encoding layers of deep architectures. As the interpretation of abusive language is highly contextdependent, its identification is an ideal task to evaluate the proposed attention mechanism. Accordingly, we considered six standard collections for the abusive language identification task. The obtained results are encouraging; the proposed hierarchical attention mechanism outperformed the current self-attention and contextual attention mechanisms coupled with recurrent neural networks and Transformers, as well as, state-of-the-art approaches in detecting abusive language.  © 2010-2012 IEEE.},
	author_keywords = {Abusive Language Detection; Attention Mechanisms; Deep Learning; Neural Language Models},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ramadhan2024142,
	author = {Ramadhan, Reza Wahyu and Shiddiqi, Ary Mazharuddin},
	title = {A Deep Feature Extraction for Hate Speech Detection using Fine-Tuned Naive Bayes},
	year = {2024},
	journal = {ICSINTESA 2024 - 2024 4th International Conference of Science and Information Technology in Smart Administration: The Collaboration of Smart Technology and Good Governance for Sustainable Development Goals},
	pages = {142 – 147},
	doi = {10.1109/ICSINTESA62455.2024.10748002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211573771&doi=10.1109%2fICSINTESA62455.2024.10748002&partnerID=40&md5=299001075598316e390be175b4c418f5},
	affiliations = {Teknologi Sepuluh Nopember, Department of Informatics Institut, Surabaya, Indonesia},
	abstract = {Hate speech on social media platforms like Twitter is a significant problem that can negatively affect individuals and communities, disrupting a healthy online environment. To address this problem, our study introduces a new method for detecting hate speech in Bahasa, combining Deep Feature Extraction (DFE) with a Fine-tuned Naive Bayes (FTNB) approach. This method uses an Artificial Neural Network (ANN) to learn and extract complex patterns and semantic relationships from the text. These extracted features are then processed using a FTNB model to enhance decision-making. Integrating deep learning for feature extraction with the probabilistic approach of Naive Bayes (NB) significantly improves the model's accuracy and precision in identifying hate speech. © 2024 IEEE.},
	author_keywords = {artificial neural network; deep feature extraction; deep learning; hate speech detection; naive bayes classifier},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep reinforcement learning; Semantics; Tweets; Deep feature extraction; Deep learning; Features extraction; Hate speech detection; Naive bayes; Naive Bayes classifiers; Neural-networks; Online environments; Social media platforms; Speech detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference of Science and Information Technology in Smart Administration, ICSINTESA 2024; Conference date: 12 July 2024; Conference code: 204233}
}

@CONFERENCE{Yadav2024,
	author = {Yadav, Ashima and Mittal, Aanchal and Jain, Navya},
	title = {Cross-linguistic hate speech detection with transformer architectures: A comparative analysis},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212848845&doi=10.1109%2fICCCNT61001.2024.10724011&partnerID=40&md5=1e31a914cb4ce52791ac369f1c799197},
	affiliations = {Department of Computer Science Engineering, Bennett University, India},
	abstract = {The proliferation of online platforms has led to an increase in user-generated content containing offensive language, including hate speech. Previous research on hate speech detection has primarily focused on monolingual datasets and traditional machine learning approaches. With the advent of transformer models, significant advancements have been made in natural language processing (NLP), enabling more effective multilingual hate speech detection. To mitigate this issue and foster positive online communities, detecting hate speech is crucial. This paper focuses on multilingual hate speech detection using a dataset comprising French, English, and Hindi languages. The dataset used in this study was carefully curated to include a balanced representation of these languages. The paper utilizes advanced transformer models such as BERT, RoBERTa, DistilBERT, and XLNet to identify instances of hate speech. Our experimental results indicate that transformer models achieve impressive performance in hate speech detection, with XLNet showing the best results: an accuracy of 93.46%, F1 score of 93.12%, sensitivity of 91.56%, negative predicted value (NPV) of 92.34%, and precision of 94.74%. We hope this study will aid researchers in the field of hate speech detection by highlighting the most effective transformer models. ©2024 IEEE.},
	author_keywords = {BERT; Deep Learning; Fake news; Hate Speech; Machine Learning},
	keywords = {Adversarial machine learning; Deep learning; Speech recognition; BERT; Comparative analyzes; Deep learning; Fake news; Hate speech; Machine-learning; Online platforms; Speech detection; Transformer modeling; User-generated; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024; Conference date: 24 June 2024 through 28 June 2024; Conference code: 203877}
}

@ARTICLE{Preetham202481,
	author = {Preetham, K. and Arun Arumugham, D. and Yogesh Kumar, M. and Shameedha Begum, B.},
	title = {Abusive Speech Detection and Politeness Transfer},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13102 LNCS},
	pages = {81 – 90},
	doi = {10.1007/978-3-031-12700-7_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200688547&doi=10.1007%2f978-3-031-12700-7_9&partnerID=40&md5=75e2afd643966b2bff4a16f747e2fef9},
	affiliations = {Department of Computer Science and Engineering, National Institute of Technology, Tiruchirappalli, Tiruchirappalli, India},
	abstract = {In the recent times of lockdown, the usage of all kinds of online platforms like Twitter, Facebook, YouTube and Reddit have increased by quite an extent. In addition to using these platforms for creating and sharing positive and inspiring content, a lot of hate and anger comments also seem to be prevalent in them. These problems are tackled by first detecting these forms of hate speech in textual data, then imparting “politeness” to the hateful comments while preserving the meaning conveyed. For the first phase of abusive speech detection, Baseline models like Logistic Regression, Naive Bayes, SVM, Random Forest and Decision Tree were trained and analyzed. Next, state-of-the-art models like LSTMs, Bi-LSTMs and Transformers were trained for classification of text. Word vectorization models like BOW and TF-IDF and also GloVe embeddings were used and evaluated on the models. It was found that Logistic Regression (with BOW), SVM (with TFIDF) and LSTMs were better performing than others in their categories. A hybrid model of the best performing classifiers was finally used. The next phase of politeness transfer to the abusive text was explored using BERT’s language model and its bidirectional property of understanding context to reduce the average toxicity of input sentences. © Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; BOW; Decoder; Embedding; Encoder; GloVe; LSTM; Masked Language Modelling; NLP; RNN; TF-IDF; Transformer},
	keywords = {Computational linguistics; Decision trees; Logistic regression; Long short-term memory; Modeling languages; Natural language processing systems; Signal encoding; Social networking (online); Speech recognition; Support vector machines; Syntactics; Text processing; BERT; BOW; Decoder; Embeddings; Encoder; Glove; Language model; LSTM; Masked language modeling; RNN; TF-IDF; Transformer; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th International Conference on Pattern Recognition and Machine Intelligence, PReMI 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 316049}
}

@ARTICLE{Gasmi2024174,
	author = {Gasmi, Salwa and Mezghani, Anis and Kherallah, Monji},
	title = {Arabic Hate Speech Detection on Social Media Using Machine Learning},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1048 LNNS},
	pages = {174 – 183},
	doi = {10.1007/978-3-031-64650-8_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200764671&doi=10.1007%2f978-3-031-64650-8_17&partnerID=40&md5=dc25e949058d48d08f56c7390438ead8},
	affiliations = {Faculty of Sciences, University of Gafsa, Gafsa, Tunisia; Higher Institute of Industrial Management, University of Sfax, Sfax, Tunisia; Faculty of Sciences, University of Sfax, Sfax, Tunisia; Advanced Technologies for Environment and Smart Cities (ATES Unit), University of Sfax, Sfax, Tunisia},
	abstract = {With the spread of online hate speech, in the recent decade, that threatens the safety of human beings and assaults their protected characteristics, there is an important interest in hate speech detection on social media as a real-world problem. Our work aims to detect automatically, the hateful comments using Logistic regression (LR) and Linear Support Vector Classification (Linear SVC) as machine learning algorithms with Term Frequency – Inverse Document Frequency (TF-IDF) and Bi-directional Long Short Term Memory (BI-LSTM) as a deep learning model with word embedding, implementing them on the Arabic and Tunisian Dataset named Tunisian Hate Speech and Abusive Dataset (T-HSAB), trying to exhibit the impact of NLP techniques on Arabic text classification. Linear SVC outperforms the other models with an accuracy equal to 99.75% © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Arabic hate speech; linear SVC; NLP; social media},
	keywords = {Classification (of information); Computational linguistics; Learning algorithms; Learning systems; Logistic regression; Natural language processing systems; Social networking (online); Speech recognition; Support vector machines; Text processing; Arabic hate speech; Human being; Linear SVC; Logistics regressions; Machine learning algorithms; Machine-learning; Real-world problem; Social media; Speech detection; Support vector classification; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 23rd International Conference on Intelligent Systems Design and Applications, ISDA 2023; Conference date: 11 December 2023 through 13 December 2023; Conference code: 315609}
}

@CONFERENCE{Da Rocha Junqueira2024,
	author = {Da Rocha Junqueira, Júlia and Lopes, Émerson P. and Da S. M. Junior, Claudio Luis and Silva, Félix Leonel V. and Carvalho, Eduarda Abreu and Freitas, Larissa and Brisolara, Ulisses},
	title = {Sabiá in Action: An Investigation of its Abilities in Aspect-Based Sentiment Analysis, Hate Speech Detection, Irony Detection, and Question-Answering},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10650878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205022078&doi=10.1109%2fIJCNN60899.2024.10650878&partnerID=40&md5=724f85f947238be59b096162d71d8c84},
	affiliations = {Federal University of Pelotas (UFPel), Technological Development Center (CDTec), Pelotas, Brazil},
	abstract = {This research investigates the efficacy of the versatile Sabiá-7B model, employed to decipher the complexities of Portuguese language across various tasks. Leveraging state-of-the-art architecture, the model extends LLaMA-7B pre-training to represent the Portuguese language better. This study focuses on evaluating Sabiá-7B's performance in Aspect-Based Sentiment Analysis (ABSA), Hate Speech Detection (HS), Irony Detection (ID), and Question-Answering (QA) tasks using a few-shot approach. Employing the few-shot method and prompt engineering throughout task executions, our research revealed that Sabiá-7B exhibits notable proficiency, mainly when provided with ample examples during few-shot extraction. However, particular challenges emerged, especially in QA tasks, where the model displayed limitations in generating precise answers compared to expected exact responses. This limitation resulted in the inclusion of extraneous words, potentially classified as irrelevant, impeding the accurate identification of an exact match. Our investigation sheds light on the strengths and potential limitations of Sabiá-7B in various NLP domains. As AI capabilities continue to advance, understanding these intricacies becomes essential for practical applications and the field's ongoing development. © 2024 IEEE.},
	keywords = {Engineering research; Speech analysis; Classifieds; Performance; Portuguese languages; Pre-training; Question Answering; Question Answering Task; Sentiment analysis; Speech detection; State of the art; Task executions; Economic and social effects},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Joint Conference on Neural Networks, IJCNN 2024; Conference date: 30 June 2024 through 5 July 2024; Conference code: 202527}
}

@BOOK{Chanda2024225,
	author = {Chanda, Supriya and Pal, Sukomal},
	title = {Hate Content Identification in Code-mixed Social Media Data},
	year = {2024},
	journal = {Text and Social Media Analytics for Fake News and Hate Speech Detection},
	pages = {225 – 247},
	doi = {10.1201/9781003409519-13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202111510&doi=10.1201%2f9781003409519-13&partnerID=40&md5=24e96f7b487b3d08b545e60fea90c216},
	affiliations = {IIT BHU, Varanasi, India; IIT BHU, Varanasi, India},
	abstract = {Social media has witnessed a tremendous boom over the past few years, which has in turn generated vast quantities of user-generated content. Users share their opinions, expressions, and emotions openly on social networking sites. Sometimes, these unabated expressions of feelings and thoughts transcend the limit of decency and lead to swearing, bullying, and character assassination. Harsh and derogatory words are directed toward individuals or groups. Often these acts are termed hate speech. As more and more people gain easy access to the Internet, social media gets flooded with such expressions, comments, and opinions in many diverse languages. It becomes increasingly difficult to police (monitor) such hate speech, especially the posts of multilingual people, which are frequently code-mixed or made up of numerous languages. In order to mitigate the spread of offensive content on social media platforms, the initial step is to detect and identify such textual content. Manually identifying hate speech or bullying in code-mixed languages, if not impossible, is a time-consuming and arduous task. Automating this task involves substantial complications and challenges due to the variety and volume of the data. In a multi-lingual code-mixed environment with multiple languages and scripts, the task becomes even more difficult. This chapter begins with different initiatives and approaches related to the identification of offensive content and hate speech in the English language and then we study their applications on code-mixed data. We evaluate the limitations found in the current state-of-the-art techniques, which demonstrate proficiency in handling text data written in a single language and script. Subsequently, we delve into the challenges associated with processing multi-lingual content. We list down different sources of code-mixed datasets and challenges faced during the processing of the data of multilingual content. We attempt to delineate the timeline with respect to the development of models on hate speech recognition for code-mixed data (with all their advantages, data pre-processing techniques, and limitations), Starting with machine learning (ML) and deep learning (DL) approaches, additional textual representation techniques are increasingly added. We then move on to the multilingual pre-trained models (for example, mBERT, XLMR, MuRIL) for text classification. To corroborate our discussion, we consider a specific dataset (ICHCL 2021, 2022) as a case study for analyzing and identifying hate content from code-mixed online datasets, which are conversational in nature. In addition to considering only single-stand-alone sentences where a sentence holds the context by itself, cases, where previous conversations and the chronology of messages are also taken into account, are discussed. In the end, we discuss the shortcomings of the existing techniques and provide directions for future work. © 2024 CRC Press.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nascimento2024,
	author = {Nascimento, Francimaria R. S. and Cavalcanti, George D. C. and Costa-Abreu, Marjory Da},
	title = {Gender bias detection on hate speech classification: an analysis at feature-level},
	year = {2024},
	journal = {Neural Computing and Applications},
	doi = {10.1007/s00521-024-10841-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212443489&doi=10.1007%2fs00521-024-10841-8&partnerID=40&md5=20ee7a8adfa9de0ad382ff803f0c43da},
	affiliations = {Centro de Informática (CIn), Universidade Federal de Pernambuco (UFPE), Av. Jornalista Anibal Fernandes s/n, Pernambuco, Recife, 50740-600, Brazil; Department of Computing, Sheffield Hallam University, Sheffield, United Kingdom},
	abstract = {Hate speech is a growing problem on social media due to the larger volume of content being shared. Recent works demonstrated the usefulness of distinct machine learning algorithms combined with natural language processing techniques to detect hateful content. However, when not constructed with the necessary care, learning models can magnify discriminatory behaviour and lead the model to incorrectly associate comments with specific identity terms (e.g., woman, black, and gay) with a particular class, such as hate speech. Moreover, some specific characteristics should be considered in the test set when evaluating the presence of bias, considering that the test set can follow the same biased distribution of the training set and compromise the results obtained by the bias metrics. This work argues that considering the potential bias in hate speech detection is needed and focuses on developing an intelligent system to address these limitations. Firstly, we proposed a comprehensive, unbiased dataset to unintended gender bias evaluation. Secondly, we propose a framework to help analyse bias from feature extraction techniques. Then, we evaluate several state-of-the-art feature extraction techniques, specifically focusing on the bias towards identity terms. We consider six feature extraction techniques, including TF, TF-IDF, FastText, GloVe, BERT, and RoBERTa, and six classifiers, LR, DT, SVM, XGB, MLP, and RF. The experimental study across hate speech datasets and a range of classification and unintended bias metrics demonstrates that the choice of the feature extraction technique can impact the bias on predictions, and its effectiveness can depend on the dataset analysed. For instance, combining TF and TF-IDF with DT and MLP resulted in higher bias, while BERT and RoBERTa showed lower bias with the same classifier for the HE and WH datasets. The proposed dataset and source code will be publicly available when the paper is published. © The Author(s) 2024.},
	author_keywords = {Feature extraction; Hate speech detection; Machine learning techniques; Social media; Unbiased dataset; Unintended gender bias},
	keywords = {Adversarial machine learning; Intelligent systems; Natural language processing systems; Speech analysis; Feature extraction techniques; Features extraction; Gender bias; Hate speech detection; Machine learning techniques; Social media; Speech detection; Test sets; Unbiased dataset; Unintended gender bias; Contrastive Learning},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nabila2024346,
	author = {Nabila, Putri and Setiawan, Erwin Budi},
	title = {Adam and AdamW Optimization Algorithm Application on BERT Model for Hate Speech Detection on Twitter},
	year = {2024},
	journal = {2024 International Conference on Data Science and Its Applications, ICoDSA 2024},
	pages = {346 – 351},
	doi = {10.1109/ICoDSA62899.2024.10651619},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204306239&doi=10.1109%2fICoDSA62899.2024.10651619&partnerID=40&md5=013e5d91a818702f2927eef0cc6bf731},
	affiliations = {School of Computing, Telkom University, Bandung, Indonesia},
	abstract = {Twitter is one of the social media platforms used to channel user's opinions and it is common for users to misuse this feature to express hate speech. Hate speech, intentional or unintentional, can trigger conflicts, especially on social media platforms with a large user base like Twitter, where hate speech can easily spread and reach its targets. Therefore, a system is needed to detect hate speech to prevent its spread and handle it. In this study, hyperparameter fine-tuning is performed on a pretrained BERT Model classify data containing hate speech with the collected data from Twitter. Adam Optimizer and AdamW Optimizer are used on the constructed BERT model, and their accuracies will be compared to determine which one yields the best result. This research found that the fine tuning the right parameter for each optimizer can result in a significantly higher accuracy compared to the model with default parameter setting. For the task of identifying hate speech in data, BERT model optimized by AdamW optimizer can reach an accuracy of 90.08% by setting the initial learning rate to 1e-5 and initial weight decay to 1e-3, an increase of 40.03% from the baseline. While BERT model optimized with Adam reaches 90.03% in accuracy by setting the initial learning rate to 1e-5 and using its default initial weight decay, an increase of 40.38% from the baseline.  © 2024 IEEE.},
	author_keywords = {Adam; AdamW; BERT; Hate Speech; Optimizer; Twitter},
	keywords = {Social networking (online); Adam; Adamw; BERT; Fine tuning; Hate speech; Initial weights; Learning rates; Optimizers; Social media platforms; Weight decay; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th International Conference on Data Science and Its Applications, ICoDSA 2024; Conference date: 10 July 2024 through 11 July 2024; Conference code: 202354}
}

@CONFERENCE{Kikkisetti2024,
	author = {Kikkisetti, Dhanush and Mustafa, Raza and Melillo, Wendy and Corizzo, Roberto and Boukouvalas, Zois and Gill, Jeff and Japkowicz, Nathalie},
	title = {Coded Term Discovery for Online Hate Speech Detection},
	year = {2024},
	journal = {2024 IEEE 11th International Conference on Data Science and Advanced Analytics, DSAA 2024},
	doi = {10.1109/DSAA61799.2024.10722816},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209407836&doi=10.1109%2fDSAA61799.2024.10722816&partnerID=40&md5=1cd61c5b796405629b4a8a53bf20ead7},
	affiliations = {American University, United States; Loyola University New Orleans, United States},
	abstract = {Online hate speech proliferation has created a difficult problem for social media platforms. A particular challenge relates to the use of coded language by groups interested in both creating a sense of belonging for its users and evading detection. Coded language evolves quickly and its use varies over time. This paper proposes a methodology for detecting emerging coded hate-laden terminology. The methodology is tested in the context of online antisemitic discourse. The approach considers posts scraped from social media platforms, often used by extremist users. The posts are scraped using seed expressions related to previously known discourse of hatred towards Jews. The method begins by identifying the expressions most representative of each post and calculating their frequency in the whole corpus. It filters out grammatically incoherent expressions as well as previously encountered ones so as to focus on emergent well-formed terminology. This is followed by an assessment of semantic similarity to known antisemitic terminology using a fine-tuned large language model, and subsequent filtering out of the expressions that are too distant from known expressions of hatred. Emergent antisemitic expressions containing terms clearly relating to Jewish topics are then removed to return only coded expressions of hatred. © 2024 IEEE.},
	author_keywords = {antisemitism; coded terminology; hate speech},
	keywords = {Social networking (online); Speech recognition; Terminology; Antisemitism; Coded terminology; Hate speech; Language model; Semantic similarity; Sense of belonging; Social media platforms; Speech detection; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th IEEE International Conference on Data Science and Advanced Analytics, DSAA 2024; Conference date: 6 October 2024 through 10 October 2024; Conference code: 203643}
}

@ARTICLE{Siddiqui2024143177,
	author = {Siddiqui, Jawaid Ahmed and Yuhaniz, Siti Sophiayati and Shaikh, Ghulam Mujtaba and Soomro, Safdar Ali and Mahar, Zafar Ali},
	title = {Fine-Grained Multilingual Hate Speech Detection Using Explainable AI and Transformers},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {143177 – 143192},
	doi = {10.1109/ACCESS.2024.3470901},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205881382&doi=10.1109%2fACCESS.2024.3470901&partnerID=40&md5=c2fb31732085a864b941e9c70fe2f635},
	affiliations = {Universiti Teknologi Malaysia, Razak Faculty of Technology and Informatics (RFTI), Kuala Lumpur, 54100, Malaysia; Sukkur IBA University, Department of Computer Science, Sindh, Sukkur, 65200, Pakistan},
	abstract = {The detection of hate speech on online platforms is essential for maintaining safe and inclusive digital environments. Although significant progress has been made in binary classification for hate speech detection, challenges persist in multilingual and fine-grained classification. This study presents a comprehensive model for hate speech detection across English, Urdu, and Sindhi, utilizing advanced deep learning models like Bidirectional Encoder Representations from Transformers (BERT) and its multilingual variants. Additionally, the research employs Explainable Artificial Intelligence (XAI) techniques, such as Local Interpretable Model-Agnostic Explanations (LIME), to gain insights into model performance. This work curated a multilingual hate speech detection dataset and a robust fine-grained hate speech detection model. The dataset includes non-hate and hate speech classes. Furthermore, the hate speech class is categorized into five fine-grained categories, including Disability, Gender, Nationality, Race, and Religion. The experimental findings of this study showed 91% F-score in binary class classification and 86% weighted F-score in fine-grained hate speech detection for multilingual datasets using XLM-RoBERTa technique. Notably, the Religion class achieved the highest F-score of 92%. It is believed that this study contributes to reducing the spread of hate speech (written in Either Urdu, English, or Sindhi) on various social media platforms.  © 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.},
	author_keywords = {Deep learning; explainable AI; hate speech; large language model; low-resource language},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Digital environment; Explainable AI; Fine grained; Hate speech; Language model; Large language model; Low resource languages; Online platforms; Speech detection; Distribution transformers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Pham2024106,
	author = {Pham, Thi-Ngoc-Diem and Phan, Ba-Dai-Phuc and Tran, Thanh-Dien},
	title = {Child Abuse Behaviors Identification from Surveillance Videos},
	year = {2024},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {87},
	pages = {106 – 118},
	doi = {10.1007/978-3-031-70011-8_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205115880&doi=10.1007%2f978-3-031-70011-8_10&partnerID=40&md5=38b40649a469419b29a7dcc8169b06ea},
	affiliations = {Can Tho University, Can Tho, Viet Nam},
	abstract = {Child abuse is a grave and pervasive social problem with profound consequences for both individual victims and society as a whole. Proper detection is important not only in recognizing child abuse but also in applying appropriate penalties for those who perform violence on children. In this paper, YOLOv5 and YOLOv8 are used to build models detecting whether there is any child violence performed in surveillance videos. The child abuse behaviors examined in this study were pinching, kicking, slapping, and choking. Experimental results on the dataset of 12666 images related to these four behaviors and extracted from videos showed that the model built by YOLOv8 is better than the other. It obtained the IoU measure of 80.9% and the F1-score measure of 97%. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {child abuse behavior; deep learning; object detection; surveillance video; YOLO},
	keywords = {Deep learning; Object recognition; Behavior identifications; Child abuse; Child abuse behavior; Deep learning; F1 scores; Objects detection; Social problems; Surveillance video; YOLO; Object detection},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Riyadi2024159660,
	author = {Riyadi, Slamet and Divayu Andriyani, Annisa and Noraini Sulaiman, Siti},
	title = {Improving Hate Speech Detection Using Double-Layers Hybrid CNN-RNN Model on Imbalanced Dataset},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {159660 – 159668},
	doi = {10.1109/ACCESS.2024.3487433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209134904&doi=10.1109%2fACCESS.2024.3487433&partnerID=40&md5=000fd7c0ed4f6df694652599b4e2dd55},
	affiliations = {Universitas Muhammadiyah Yogyakarta, Faculty of Engineering, Department of Information Technology, Yogyakarta, 55183, Indonesia; Universiti Teknologi MARA Cawangan Pulau Pinang, Center of Electrical Engineering, College of Engineering, Permatang Pauh, Penang, 13500, Malaysia},
	abstract = {Hate speech detection is crucial in curbing online toxicity and fostering a safer digital environment. Previous research has proposed the use of a hybrid CNN-RNN model for this purpose. This study aims to improve the performance of the hybrid CNN-RNN method by using a double-layer approach to address imbalanced datasets. The novelty lies in using double layers of hybrid CNN-RNN to enhance hate speech detection accuracy. This research also employed an oversampling technique alongside the double-layer model. The process included preprocessing, feature extraction, training tuning, testing, and performance evaluation. The results demonstrated that the double-layer hybrid CNN-RNN model achieved an accuracy of 0.827, a precision of 0.797, a recall of 0.759, and an F1 score of 0.883, with imbalanced data. Meanwhile, balanced data yielded a higher accuracy of 0.908, a precision of 0.943, a recall of 0.894, and an F1 score of 0.914. Moreover, the proposed model outperformed the hybrid CNN-RNN with an imbalanced dataset, generating an accuracy of 0.752, a precision of 0.797, a recall of 0.559, and an F1 score of 0.657. Dropout and early stopping techniques addressed overfitting in complex models and large datasets. This research has advanced hate speech detection methodologies by demonstrating the effectiveness of a double-layer hybrid CNN-RNN model, especially for imbalanced data. It underscores the importance of addressing imbalanced datasets for improved model accuracy. Future work could explore alternative data augmentation techniques or compare the proposed model with other architectures.  © 2013 IEEE.},
	author_keywords = {Deep learning; hate speech; hybrid CNN-RNN; oversample; sentiment analysis},
	keywords = {Deep learning; Double layers; F1 scores; Hate speech; Hybrid CNN-RNN; Imbalanced data; Imbalanced dataset; Oversample; Sentiment analysis; Speech detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nguyen20241,
	author = {Nguyen, Anh Thi-Hoang and Nguyen, Dung Ha and Nguyen, Nguyet Thi and Ho, Khanh Thanh-Duy and Nguyen, Kiet Van},
	title = {Automatic Textual Normalization for Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1049 LNNS},
	pages = {1 – 12},
	doi = {10.1007/978-3-031-64779-6_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200653456&doi=10.1007%2f978-3-031-64779-6_1&partnerID=40&md5=4495b15a739a9fe4f9c138e24966f9b8},
	affiliations = {Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {Social media data is a valuable resource for research, yet it contains a wide range of non-standard words (NSW). These irregularities hinder the effective operation of NLP tools. Current state-of-the-art methods for the Vietnamese language address this issue as a problem of lexical normalization, involving the creation of manual rules or the implementation of multi-staged deep learning frameworks, which necessitate extensive efforts to craft intricate rules. In contrast, our approach is straightforward, employing solely a sequence-to-sequence (Seq2Seq) model. In this research, we provide a dataset for textual normalization, comprising 2,181 human-annotated comments with an inter-annotator agreement of 0.9014. By leveraging the Seq2Seq model for textual normalization, our results reveal that the accuracy achieved falls slightly short of 70%. Nevertheless, textual normalization enhances the accuracy of the Hate Speech Detection (HSD) task by approximately 2%, demonstrating its potential to improve the performance of complex NLP tasks. Our dataset is accessible for research purposes (Github: https://github.com/AnhHoang0529/Small-LexNormViHSD). © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hate speech detection; Lexical normalization; Seq2Seq; Social media},
	keywords = {Computational linguistics; Deep learning; Social networking (online); Speech recognition; 'current; Hate speech detection; Lexical normalization; NLP tools; Normalisation; Seq2seq; Social media; Social media datum; Speech detection; State-of-the-art methods; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 23rd International Conference on Intelligent Systems Design and Applications, ISDA 2023; Conference date: 11 December 2023 through 13 December 2023; Conference code: 315609}
}

@CONFERENCE{Negi2024,
	author = {Negi, Deepti and Manchanda, Mahesh and Kala, Aditi and Harbola, Aditya},
	title = {Exploring Machine Learning Methods for Hate Speech Detection on Social Media},
	year = {2024},
	journal = {2nd IEEE International Conference on Advances in Information Technology, ICAIT 2024 - Proceedings},
	doi = {10.1109/ICAIT61638.2024.10690691},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208826041&doi=10.1109%2fICAIT61638.2024.10690691&partnerID=40&md5=32cb6a64e289da4f3094b02d2e54e2db},
	affiliations = {School of Computing, Graphic Era Hill University, Dehradun, India; Graphic Era Hill University, Dehradun, India},
	abstract = {As social media usage continues to expand daily, so too does the spread of hate speech. To swiftly remove inflammatory content, every social media platform needs to implement a dependable algorithm for identifying hate speech. Challenges in this task include understanding language nuances, varying definitions of hate speech, and insufficient data for training and assessing these systems. To tackle the issue of detecting hate speech, various approaches can be employed, such as machine learning, deep learning, and others, which we will explore below. © 2024 IEEE.},
	author_keywords = {detection; Hate speech; inflammatory information; language nuance; machine learning methods; recognition; reliable hate speech identification algorithm; spreading},
	keywords = {Detection; Hate speech; Identification algorithms; Inflammatory information; Language nuance; Machine learning methods; Recognition; Reliable hate speech identification algorithm; Speech identification; Spreading; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Advances in Information Technology, ICAIT 2024; Conference date: 24 July 2024 through 27 July 2024; Conference code: 203115}
}

@CONFERENCE{Wang2024,
	author = {Wang, Yeshan and Markov, Ilia},
	title = {CLTL at DIMEMEX Shared Task: Fine-Grained Detection of Hate Speech in Memes},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204390400&partnerID=40&md5=c9d721624a6012abdc616183d24744ed},
	affiliations = {Computational Linguistics & Text Mining Lab (CLTL), Vrije Universiteit Amsterdam, Amsterdam, 1081 HV, Netherlands},
	abstract = {We present the CLTL system developed for the DIMEMEX Shared Task on detecting fine-grained types of hate speech in Mexican Spanish memes. The competition consisted of two tasks. Task 1 involved classifying memes into hate speech, inappropriate, or harmless categories, while Task 2 required further classification of hateful memes into classism, sexism, racism, or other types. We explored the effectiveness of combining state-of-the-art language models with the Swin Transformer-based visual model to create a multimodal system using the Multilayer Perceptron fusion module for classification. Our experiments demonstrated that the XLM-T model combined with Swin Transformer V2 achieved the highest results, with an F1 score of 57.88 for Task 1 and 43.65 for Task 2, ranking 1st in both tasks in the competition. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Hateful Memes Detection; Mexican Spanish; Multimodal Hate Speech Detection},
	keywords = {Classification (of information); Economic and social effects; Visual languages; Fine grained; Hateful meme detection; Language model; Mexican spanish; Multi-modal; Multimodal hate speech detection; Multimodal system; Speech detection; State of the art; Visual model; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@CONFERENCE{Nguyen20245948,
	author = {Nguyen, Luan Thanh},
	title = {VIHATET5: Enhancing Hate Speech Detection in Vietnamese With a Unified Text-to-Text Transformer Model},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {5948 – 5961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205308109&partnerID=40&md5=ca7cd89249498c62db17cdd88c841622},
	affiliations = {Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {Recent advancements in hate speech detection (HSD) in Vietnamese have made significant progress, primarily attributed to the emergence of transformer-based pre-trained language models, particularly those built on the BERT architecture. However, the necessity for specialized fine-tuned models has resulted in the complexity and fragmentation of developing a multitasking HSD system. Moreover, most current methodologies focus on fine-tuning general pre-trained models, primarily trained on formal textual datasets like Wikipedia, which may not accurately capture human behavior on online platforms. In this research, we introduce VIHATET5, a T5-based model pre-trained on our proposed large-scale domain-specific dataset named VOZ-HSD. By harnessing the power of a text-to-text architecture, VIHATET5 can tackle multiple tasks using a unified model and obtain state-of-the-art performance on all benchmark HSD datasets in Vietnamese. The experiments also underscore the significance of label distribution in pretraining data on model efficacy. We provide our experimental materials for research purposes, including the VOZ-HSD dataset, pre-trained checkpoint, the unified HSD-multitask VIHATET5 model, and related source code on GitHub publicly. © 2024 Association for Computational Linguistics.},
	keywords = {Large datasets; Speech enhancement; Speech recognition; 'current; Detection system; Fine tuning; Human behaviors; Language model; Online platforms; Speech detection; Transformer modeling; Vietnamese; Wikipedia; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Findings of the 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202475}
}

@ARTICLE{Singh2024277,
	author = {Singh, Divya and Gupta, Sonam and Gupta, Pradeep},
	title = {Detection of Hate Speech Using Ensemble Models},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1021 LNNS},
	pages = {277 – 289},
	doi = {10.1007/978-981-97-3591-4_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206379398&doi=10.1007%2f978-981-97-3591-4_23&partnerID=40&md5=532f1517f660270b985c0c8316adebcf},
	affiliations = {Department of Computer Science and Engineering, Ajay Kumar Garg Engineering College, Ghaziabad, India},
	abstract = {This study examined cyberbullying on social media sites such as Twitter, with the aim of analyzing these messages before they impact the victims. To achieve this, a global database of 20,010 tweets was used with six different learning machines: LR, RFC, ADB, GNB, SVM, and DTC. The results showed that RFC had the highest F1 (0.90), Precision (0.96), Accuracy (0.91) and highest Re (0.89). These findings raise awareness of the benefits of increasingly popular social media and information sharing. However, it also causes some problems in the spread of hate speech. Researchers are working on using engineering techniques and machine learning algorithms to detect HS in many documents. However, there is currently no research that measures and compares the results of the public information process. This study provides an effective way to detect hate speech on Twitter by using a combination of learning and machine learning techniques. Create a curated database of tweets tagged as hateful, offensive, or neutral to provide a more accurate picture of online discourse. The accuracy of this model is then compared to specific studies to provide a basis for comparison. The results showed that the fused learning method was more effective than the traditional learning method, and RFC showed the highest accuracy in discrimination detection. The research also examines the combination of word embeddings such as Word2Vec and GloVe to improve the performance of the model. Embeddings help improve the model's ability to discern discrimination in online communication. As social media sites continue to serve as vehicles for hate speech and popular information, it is important to develop tools to detect the nature of such speech. With this study, an important step has been taken to achieve this goal. These findings could play an important role in further research to combat hate speech and promote effective online communication. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Cyberbullying; Ensemble; Hate speech; Machine learning},
	keywords = {Contrastive Learning; Embeddings; Federated learning; Social networking (online); Tweets; Cyber bullying; Embeddings; Ensemble; Ensemble models; Global database; Hate speech; Learning methods; Machine-learning; On-line communication; Social media; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Innovative Computing and Communication, ICICC 2024; Conference date: 16 February 2024 through 17 February 2024; Conference code: 316239}
}

@ARTICLE{Golcarenarenji2024,
	author = {Golcarenarenji, Gelayol and Khusainov, Rinat and Gegov, Alexander and Martinez-Alpiste, Ignacio},
	title = {Detecting Violent Behaviour on Edge Using Convolutional Neural Networks},
	year = {2024},
	journal = {International IEEE Conference  proceedings, IS},
	number = {2024},
	doi = {10.1109/IS61756.2024.10705272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208445358&doi=10.1109%2fIS61756.2024.10705272&partnerID=40&md5=771c466357ddd3085eade0bc66f5e2f4},
	affiliations = {School of Computing, University of Portmouth, United Kingdom; Focalise Ltd., R&d Department},
	abstract = {A new portable solution is proposed based on Convolutional Neural Networks (CNN) to increase the speed and accuracy of detecting violence behaviour on edge devices. This solution has numerous applications in public safety. A combination of surveillance using CCTV cameras and Unmanned Aerial Vehicles (UAVs) is used to demonstrate the real-world surveillance use cases to monitor abnormal behaviors in public. The proposed solution delivers 95.01% accuracy while taking 13.2ms for inference on GeForce GTX 1660 Ti GPU and reaching 38 frames per second throughput on Jetson AGX Orin measured on a combination of Drone-action and chu-surveillance-violence-detection datasets. The results show the strong practical application potential of the proposed solution in terms of real-time performance, visual quality, and high accuracy.  © 2024 IEEE.},
	author_keywords = {CCTV Cameras; Edge Computing; UAVs; Violent Behaviour; YOLOV5},
	keywords = {Aircraft accidents; Aircraft detection; Crime; Edge computing; Unmanned aerial vehicles (UAV); Abnormal behavior; Aerial vehicle; CCTV camera; Convolutional neural network; Edge computing; Public safety; Real-world; Unmanned aerial vehicle; Violent behavior; YOLOV5; Convolutional neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th IEEE International Conference on Intelligent Systems, IS 2024; Conference date: 29 August 2024 through 31 August 2024; Conference code: 203263}
}

@ARTICLE{Liu2024186,
	author = {Liu, Ge and Yang, Xiaona and Shi, Xiayang and Li, Yinlin},
	title = {Unsupervised offensive speech detection for multimedia based on multilingual BERT},
	year = {2024},
	journal = {International Journal of Sensor Networks},
	volume = {46},
	number = {3},
	pages = {186 – 196},
	doi = {10.1504/IJSNET.2024.142516},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209228438&doi=10.1504%2fIJSNET.2024.142516&partnerID=40&md5=edcfc004fef44c9fee3df933f650202c},
	affiliations = {Xuchang Vocational and Technical College, Henan, 461000, China; Software College, Zhengzhou University of Light Industry, Henan, 450000, China; Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China},
	abstract = {There is a significant amount of offensive speech in multimedia, which seriously negatively impacts social stability. With the proliferation of sensor-equipped devices contributing to social media data, detecting offensive speech within this vast dataset has emerged as a critical challenge. However, most existing methods have focused only on a few high-resource languages. This paper proposes a cross-lingual aggressive transfer learning method based on bidirectional encoder representations from transformers (BERT) for automatically detecting offensive speech in low-resource languages. Initially, we utilise the multilingual BERT model to learn the characteristics of aggressive speech from a high-resource language dataset to establish an initial model. Subsequently, based on the linguistic similarity between languages, this model is transferred to low-resource languages. Experimental results demonstrate that our method achieves higher detection accuracy in multiple languages including English, Danish, Arabic, Turkish, and Greek, particularly excelling in low-resource languages. © 2024 Inderscience Enterprises Ltd.},
	author_keywords = {natural language processing; offensive speech detection; social media},
	keywords = {Critical challenges; Cross-lingual; Language processing; Low resource languages; Natural language processing; Natural languages; Offensive speech detection; Social media; Social stability; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{AlSukhni2024,
	author = {AlSukhni, Emad and AlAzzam, Iyad and Hanandeh, Sereen},
	title = {Offensive Language Detection of Arabic Tweets Using Deep Learning Algorithm},
	year = {2024},
	journal = {2024 15th International Conference on Information and Communication Systems, ICICS 2024},
	doi = {10.1109/ICICS63486.2024.10638282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203683688&doi=10.1109%2fICICS63486.2024.10638282&partnerID=40&md5=0a5e8ddadaf04ab4e2d890770d235748},
	affiliations = {Information Systems dept., Yarmouk University, Irbid, Jordan},
	abstract = {Offensive language has become a common occurrence in Arabic social media. Toxic textual content can be prohibited more easily with the use of automatic offensive language identification technologies. In this study, a deep learning approach was used to detect offensive Arabic language. Three models were used: RNN with LSTM, RNN with BLSTM, and the SVM learning algorithm. A dataset of 7000 tweets with two attributes from the Egyptian dialect was used. After data preprocessing, a 6-fold cross-validation was used to train and test the data. The evaluation of the three models showed the suitability of the RNN models (with an accuracy of 95.6%) over the SVM. ©2024 IEEE.},
	author_keywords = {Deep learning; long short-term memory; offensive language detection; Recurrent neural network; Support Vector Machine},
	keywords = {Adversarial machine learning; Contrastive Learning; Long short-term memory; Support vector machines; Deep learning; Language detection; Neural-networks; Offensive language detection; Offensive languages; Short term memory; Social media; Support vectors machine; Textual content; Three models; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Information and Communication Systems, ICICS 2024; Conference date: 13 August 2024 through 15 August 2024; Conference code: 202057}
}

@CONFERENCE{Ivan2024464,
	author = {Ivan, Shahriar and Ahmed, Tasnim and Ahmed, Sabbir and Kabir, Md. Hasanul},
	title = {A Vision-Language Multimodal Framework for Detecting Hate Speech in Memes},
	year = {2024},
	journal = {Canadian Conference on Electrical and Computer Engineering},
	pages = {464 – 468},
	doi = {10.1109/CCECE59415.2024.10667078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204948866&doi=10.1109%2fCCECE59415.2024.10667078&partnerID=40&md5=3f81b2d89951460f65b365cbcf968ed3},
	affiliations = {Islamic University of Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; Queen's University, School of Computing, ON, Canada},
	abstract = {Memes, widely used in social media, serve both entertainment and communication purposes but can also contain offensive elements. Due to the vastness of internet content, automated techniques are necessary for categorizing and preventing the spread of offensive memes. This research explores the field of hateful meme identification, highlighting current limitations and the potential of combining vision and language models to utilize information from both image and text modalities. The proposed framework utilizes an 'Image Captioning block' to extract meaningful textual description from the input meme image, and subsequently a 'Fusion and Classification block' for combining the features from image modality and text modality as well as generating classification results separately from three transformers-based language models, and finally obtains a decision from an ensemble of the three predictions in the 'Decision block'. We evaluate our proposed framework on the Hateful Memes Challenge Dataset, obtaining an accuracy of 72.2% and an AUROC score of 0.7708. In addition, we provide a comprehensive analysis regarding the characteristics of the memes that may introduce difficulty in accurately classifying them, which in turn provides valuable insight to future researchers by explaining how certain kinds of memes are misclassified by the models.  © 2024 IEEE.},
	author_keywords = {Automated content moderation; Hateful memes; Image captioning; Image-text fusion; Text transformers},
	keywords = {Classification (of information); Image classification; Image coding; Image fusion; Modeling languages; Speech recognition; Automated content moderation; Hateful meme; Image captioning; Image texts; Image-text fusion; Internet content; Language model; Multimodal frameworks; Social media; Text transformer; Visual languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 Annual IEEE Canadian Conference on Electrical and Computer Engineering, CCECE 2024; Conference date: 6 August 2024 through 9 August 2024; Conference code: 202653}
}

@CONFERENCE{Bolatbek202494,
	author = {Bolatbek, Milana and Sagynay, Moldir and Mussiraliyeva, Shynar and Baisylbayeva, Kymbat and Yeltay, Zhastay},
	title = {Kazakh Language Dataset for Hate Speech Detection on Social Media Text},
	year = {2024},
	journal = {2024 IEEE 9th International Conference on Computational Intelligence and Applications, ICCIA 2024},
	pages = {94 – 98},
	doi = {10.1109/ICCIA62557.2024.10719327},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208420513&doi=10.1109%2fICCIA62557.2024.10719327&partnerID=40&md5=e30f096ebaab7229272ce20d7a083a7f},
	affiliations = {Al-Farabi Kazakh National University, Department of Information Systems, Almaty, Kazakhstan},
	abstract = {The article presents an urgent problem of the spread of destructive messages in the modern information society, aggravated by the rapid development of the Internet and social networks. The main attention is paid to the characterization of destructive messages, which include racism, national extremism, bullying and extremist content that can damage interpersonal relationships, self-esteem and the mental state of people. A significant increase in the number of such messages has been highlighted due to the anonymity and accessibility of Internet platforms, which leads to increased aggression and problems in online communication. The use of various methods, such as machine learning algorithms, keyword analysis, allows to effectively detect and combat destructive messages in various environments, including the Internet. This not only helps to prevent negative impacts on people, but also helps to maintain the moral and ethical standards of society. In this paper classes of destructive messages such as bullying, racism, national extremism and violent extremism are considered, emphasizing the need for an integrated approach to combating these phenomena to ensure the safety of the information space. © 2024 IEEE.},
	author_keywords = {bullying; destructive messages; Kazakh language; national extremism; racism; violent extremism},
	keywords = {Bullying; Destructive message; Information society; Kazakh language; National extremism; Racism; Social media; Speech detection; Urgent problems; Violent extremism; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th IEEE International Conference on Computational Intelligence and Applications, ICCIA 2024; Conference date: 9 August 2024 through 11 August 2024; Conference code: 203532}
}

@ARTICLE{Damo2024211,
	author = {Damo, Greta and Ocampo, Nicolás Benjamín and Cabrio, Elena and Villata, Serena},
	title = {Unveiling the Hate: Generating Faithful and Plausible Explanations for Implicit and Subtle Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14762 LNCS},
	pages = {211 – 225},
	doi = {10.1007/978-3-031-70239-6_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205394033&doi=10.1007%2f978-3-031-70239-6_15&partnerID=40&md5=0dc1b057b3355b1eb8586e9801b56c9a},
	affiliations = {Université Côte d’Azur, CNRS, Inria, I3S, Sophia Antipolis, France},
	abstract = {In today’s digital age, the huge amount of abusive content and hate speech on social media platforms presents a significant challenge. Natural Language Processing (NLP) methods have focused on detecting explicit forms of hate speech, often overlooking more nuanced and implicit instances. To address this gap, our paper aims to enhance the detection and understanding of implicit and subtle hate speech. More precisely, we propose a comprehensive approach combining prompt construction, free-text generation, few-shot learning, and fine-tuning to generate explanations for hate speech classification, with the goal of providing more context for content moderators to unveil the actual nature of a message on social media. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Generating Explanations; Hate Speech Detection; Implicit Hate Speech; Subtle Hate Speech},
	keywords = {Digital age; Generating explanation; Hate speech detection; Implicit hate speech; Language processing; Natural languages; Processing method; Social media platforms; Speech detection; Subtle hate speech; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 29th International Conference on Natural Language and Information Systems, NLDB 2024; Conference date: 25 June 2024 through 27 June 2024; Conference code: 319819}
}

@CONFERENCE{Maqbool2024,
	author = {Maqbool, Fariha and Fersini, Elisabetta},
	title = {Multimodal Hate Speech Detection in Memes from Mexico using BLIP},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204360739&partnerID=40&md5=2ed419dd5ac9bb582e2700fcd0ba0381},
	affiliations = {Dipartimento di informatica, sistemistica e comunicazione, University of Milano-Bicocca, Viale Sarca 336, Milan, 20126, Italy},
	abstract = {The proliferation of online platforms has introduced a novel challenge in identifying inappropriate and hateful content in digital discourse. This paper describes our approach to detect such content on social media platforms, for Task 1 of DIMEMEX challenge in IberLEF 2024 [1]. We employed vision-language based pre-trained model BLIP to extract the combined image text embeddings. Subsequently, a Gradient Boosting Classifier was employed for sample classification. Our findings highlight the potential for further enhancements in multi-modal analysis and classification frameworks. © 2024 Copyright for this paper by its authors.},
	author_keywords = {BLIP; Hate Speech; Inappropriate Content},
	keywords = {BLIP; Combined images; Hate speech; Image texts; Inappropriate content; Me-xico; Multi-modal; Online platforms; Social media platforms; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Iberian Languages Evaluation Forum, IberLEF 2024; Conference date: 24 September 2024; Conference code: 202334}
}

@CONFERENCE{Vasudevan2024,
	author = {Vasudevan, Nandu and Sachin Kumar, S.},
	title = {Offensive Language Identification in Dravidian Codemixed Dataset},
	year = {2024},
	journal = {2024 4th International Conference on Intelligent Technologies, CONIT 2024},
	doi = {10.1109/CONIT61985.2024.10626672},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202742803&doi=10.1109%2fCONIT61985.2024.10626672&partnerID=40&md5=49f849c6a735797b0e81474e0ae42a88},
	affiliations = {Center for Computational Engineering and Networking, Amrita Vishwa Vidyapeetham, Coimbatore, 641112, India},
	abstract = {This research uses an English-Malayalam dataset taken from YouTube comments to investigate improper language detection in multilingual settings. To capture the subtleties of language usage - such as code-mixing - that are common in the under-resourced Dravidian language family, we use autoencoders and ensemble techniques using BERT models as features. We use LIME in addition to improve interpretability. A lazy classifier that uses a variety of classifiers also helps to determine which classifier is the most efficient. Supervised learning methods are enhanced by unsupervised k-means clustering. Our results surpass standards and demonstrate the effectiveness of our method in offensive language identification. The field's understanding is advanced by this confluence of methodologies. © 2024 IEEE.},
	author_keywords = {Auto encoder; Bert; K-means clustering; Lstm; Offensive language detection},
	keywords = {Classification (of information); Self-supervised learning; Semi-supervised learning; Unsupervised learning; Auto encoders; Bert; K-means++ clustering; Language detection; Language identification; Lstm; Malayalams; Offensive language detection; Offensive languages; Research use; K-means clustering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Intelligent Technologies, CONIT 2024; Conference date: 21 June 2024 through 23 June 2024; Conference code: 201883}
}

@CONFERENCE{Sekkate2024,
	author = {Sekkate, Sara and Chebbi, Safa and Adib, Abdellah and Jebara, Sofia Ben},
	title = {A deep learning framework for offensive speech detection},
	year = {2024},
	journal = {ISIVC 2024 - Proceedings: 12th IEEE International Symposium on Signal, Image, Video, and Communications},
	doi = {10.1109/ISIVC61350.2024.10577928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198916494&doi=10.1109%2fISIVC61350.2024.10577928&partnerID=40&md5=208184d13b7904ebc65734b5fe309c66},
	affiliations = {Hassan Ii University of Casablanca, Lmcsa Lab, Team Data Science & Artificial Intelligence, Morocco; University of Carthage, Cosim Lab. Higher School of Communications of Tunis, Tunisia},
	abstract = {Offensive speech covers many different ways someone may harm another such as humiliation, criticism, yelling, or verbal abuse. Such behavior results in negative consequences with possible dangerous impacts like biasing people's thoughts, spreading racism, discrimination and even physical violence among citizens. While offensive speech takes place online and offline and in all forms of social interaction, our work contributes at filtering the alarming diffusion of such behaviors in televisiondebate programs by proposing a speech-based offensive behavior detection system. To do so, we investigated the use of the Vera Am Mittag (VAM) corpus which is a collection of recordings taken from a German TV talk show. From these, a mixture of Mel Frequency Cepstral Coefficients (MFCC) and Stationary Wavelet Transform (SWT) based features was extracted and several feature selection techniques were applied for capturing the most relevant features. Finally, both of K-Nearest Neighbors (KNN) and deep learning Convolutional Neural Networks (CNNs) were employed for classification. Results highlight that the best performance is associated with CNNs whith feature selection, reaching a classification accuracy of 97.21 %.  © 2024 IEEE.},
	author_keywords = {deep learning; feature extraction; feature selection; machine learning; MFCC; Offensive speech; SWT},
	keywords = {Feature Selection; Nearest neighbor search; Speech recognition; Wavelet transforms; Convolutional neural network; Deep learning; Features extraction; Features selection; Learning frameworks; Machine-learning; Mel frequency cepstral co-efficient; Mel-frequency cepstral coefficients; Offensive speech; Stationary wavelet transforms; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th IEEE International Symposium on Signal, Image, Video, and Communications, ISIVC 2024; Conference date: 21 May 2024 through 23 May 2024; Conference code: 200840}
}

@CONFERENCE{Han2024,
	author = {Han, Baixuan and Peng, Yueping and Hao, Hexiang and Yin, Wenji and Liu, Wenchao},
	title = {Violent behavior detection algorithm in aerial images based on YOLOv9},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13403},
	doi = {10.1117/12.3051697},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210877184&doi=10.1117%2f12.3051697&partnerID=40&md5=d3f5b1bc1d2ba96fa5f7ff247f71d9e8},
	affiliations = {School of Information Engineering, Engineering University of PAP, Xi’an, 710086, China},
	abstract = {Aiming at the shortage of accuracy and feature extraction ability of aerial image behavior detection algorithm, we designed an improved YOLOv9 fight behavior detection algorithm. WE use drones to take aerial photos and build datasets of violent behavior, and we add Multidimensional Collaborative Attention (MCA) to the object detection header to improve the detection accuracy, and introduce maximum feature pooling to strengthen the ability of network feature extraction for self-built datasets. For unevenly distributed data sets, Focaler-loss function is used. The results show that compared with the original network, the detection accuracy is improved from 90.6% to 92.9%, and the FPS reaches 56 frames per second, which meets the requirement of high precision real-time detection. © 2024 SPIE ·},
	author_keywords = {Artificial Intelligence; Drone aerial photography dataset; Feature extraction; Violent behavior detection; YOLOv9 algorithm},
	keywords = {Aerial photography; Aircraft detection; Image enhancement; Aerial images; Behavior detection; Detection accuracy; Detection algorithm; Drone aerial photography dataset; Features extraction; Image-based; Violent behavior; Violent behavior detection; YOLOv9 algorithm; Drones},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Conference on Algorithms, High Performance Computing, and Artificial Intelligence, AHPCAI 2024; Conference date: 14 August 2024 through 16 August 2024; Conference code: 204186}
}

@CONFERENCE{Kim202416177,
	author = {Kim, Jaehoon and Jin, Seungwan and Park, Sohyun and Park, Someen and Han, Kyungsik},
	title = {Label-aware Hard Negative Sampling Strategies with Momentum Contrastive Learning for Implicit Hate Speech Detection},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {16177 – 16188},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205317854&partnerID=40&md5=e96ebe31221e145de496c9d7f33aa9c7},
	affiliations = {Department of Artificial Intelligence, Hanyang University, Seoul, South Korea; Department of Data Science, Hanyang University, Seoul, South Korea},
	abstract = {Detecting implicit hate speech that is not directly hateful remains a challenge. Recent research has attempted to detect implicit hate speech by applying contrastive learning to pre-trained language models such as BERT and RoBERTa, but the proposed models still do not have a significant advantage over cross-entropy loss-based learning. We found that contrastive learning based on randomly sampled batch data does not encourage the model to learn hard negative samples. In this work, we propose Label-aware Hard Negative sampling strategies (LAHN) that encourage the model to learn detailed features from hard negative samples, instead of naive negative samples in random batch, using momentum-integrated contrastive learning. LAHN outperforms the existing models for implicit hate speech detection both in- and cross-datasets. The code is available at https://github.com/Hanyang-HCC-Lab/LAHN. © 2024 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Speech recognition; Batch data; Cross entropy; Entropy loss; Language model; Learn+; Negative samples; Recent researches; Sampling strategies; Speech detection; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Findings of the 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024; Conference date: 11 August 2024 through 16 August 2024; Conference code: 202475}
}

@CONFERENCE{Hoang20246460,
	author = {Hoang, Nhat M. and Do, Xuan Long and Do, Duc Anh and Vu, Duc Anh and Tuan, Luu Anh},
	title = {ToXCL: A Unified Framework for Toxic Speech Detection and Explanation},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {6460 – 6472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199560183&partnerID=40&md5=529bef3baad212faf7da268737f88614},
	affiliations = {Nanyang Technological University, Singapore; National University of Singapore, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore},
	abstract = {The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce TOXCL1, a unified framework for the detection and explanation of implicit toxic speech. Our model consists of three modules: a (i) Target Group Generator to generate the targeted demographic group(s) of a given post; an (ii) Encoder-Decoder Model in which the encoder focuses on detecting implicit toxic speech and is boosted by a (iii) Teacher Classifier via knowledge distillation, and the decoder generates the necessary explanation. TOXCL achieves new state-of-the-art effectiveness, and outperforms baselines significantly. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Decoding; Distillation; Population statistics; Speech recognition; Demographic groups; Detection tasks; Encoder-decoder; Error propagation; Speech detection; State of the art; Target group; Teachers'; Text generations; Unified framework; Signal encoding},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024; Conference date: 16 June 2024 through 21 June 2024; Conference code: 200463}
}

@ARTICLE{Ramos2024101374,
	author = {Ramos, Gil and Batista, Fernando and Ribeiro, Ricardo and Fialho, Pedro and Moro, Sérgio and Fonseca, António and Guerra, Rita and Carvalho, Paula and Marques, Catarina and Silva, Cláudia},
	title = {Leveraging Transfer Learning for Hate Speech Detection in Portuguese Social Media Posts},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {101374 – 101389},
	doi = {10.1109/ACCESS.2024.3430848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199862643&doi=10.1109%2fACCESS.2024.3430848&partnerID=40&md5=58ba8a94b1b24ef1b0835d7fa74e649f},
	affiliations = {Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR, Lisbon, 1649-026, Portugal; Instituto Universitário de Lisboa (ISCTE-IUL), Lisbon, 1649-026, Portugal; INESC-ID, Lisbon, 1000-029, Portugal; The University of Jordan, Amman, 11941, Jordan; ISCTE—Instituto Universitário de Lisboa, Center for Psychological Research and Social Intervention (CIS-ISCTE), Lisbon, 1000-029, Portugal; ISCTE—Instituto Universitário de Lisboa and Business Research Unit (BRU-ISCTE), Lisbon, 1649-026, Portugal; Interactive Technologies Institute, Laboratory of Robotics and Engineering Systems (ITI-LARSyS), Lisbon, 1900-319, Portugal; Instituto Superior Tcnico (IST), Lisbon, 1049-001, Portugal},
	abstract = {The rapid rise of social media has brought about new ways of digital communication, along with a worrying increase in online hate speech (HS), which, in turn, has led researchers to develop several Natural Language Processing methods for its detection. Although significant strides have been made in automating HS detection, research focusing on the European Portuguese language remains scarce (as it happens in several under-resourced languages). To address this gap, we explore the efficacy of various transfer learning models, which have been shown in the literature to have better performance for this task than other Deep Learning models. We employ BERT-like models pre-trained on Portuguese text, such as BERTimbau and mDeBERTa, as well as GPT, Gemini and Mistral generative models, for the detection of HS within Portuguese online discourse. Our study relies on two annotated corpora of YouTube comments and tweets, both annotated as HS and non-HS. Our findings show that the best model for the YouTube corpus was a variant of BERTimbau retrained with European Portuguese tweets and fine-tuned for the HS task, with an F-score of 87.1% for the positive class, outperforming the baseline models by more than 20% and with a 1.8% increase compared with base BERTimbau. The best model for the Twitter corpus was GPT-3.5, with an F-score of 50.2% for the positive class. We also assess the impact of using in-domain and mixed-domain training sets, as well as the impact of providing context in generative model prompts on their performance. © 2024 The Authors.},
	author_keywords = {generative models; Hate speech; text classification; transfer learning; transformer models},
	keywords = {Classification (of information); Deep learning; Digital communication systems; Learning algorithms; Natural language processing systems; Social networking (online); Speech communication; Speech recognition; Text processing; Transfer learning; Generative model; Hate speech; Learning models; Performance; Social media; Speech detection; Text classification; Transfer learning; Transformer modeling; YouTube; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}@CONFERENCE{Premjith202449,
	author = {Premjith, B. and Chakravarthi, Bharathi Raja and Kumaresan, Prasanna Kumar and Rajiakodi, Saranya and Karnati, Sai Prashanth and Mangamuru, Sai Rishith Reddy and Janakiram, Chandu},
	title = {Findings of the Shared Task on Hate and Offensive Language Detection in Telugu Codemixed Text (HOLD-Telugu)@DravidianLangTech 2024},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {49 – 55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189863095&partnerID=40&md5=8565b1da1e63bc43df8c009f480018fc},
	affiliations = {Amrita School of Artificial Intelligence, Amrita Vishwa Vidyapeetham, Coimbatore, India; School of Computer Science, University of Galway, Ireland; Data Science Institute, University of Galway, Ireland; Central University of Tamil Nadu, India},
	abstract = {This paper examines the submissions of various participating teams to the task on Hate and Offensive Language Detection in Telugu Codemixed Text (HOLD-Telugu) organized as part of DravidianLangTech 2024. In order to identify the contents containing harmful information in Telugu codemixed social media text, the shared task pushes researchers and academicians to build models. The dataset for the task was created by gathering YouTube comments and annotated manually. A total of 23 teams participated and submitted their results to the shared task. The rank list was created by assessing the submitted results using the macro F1-score. © 2024 Association for Computational Linguistics.},
	keywords = {F1 scores; Language detection; Offensive languages; Participating teams; Rank lists; Social media; YouTube},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Tanev202485,
	author = {Tanev, Hristo},
	title = {JRC at ClimateActivism 2024: Lexicon-based Detection of Hate Speech},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {85 – 88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190271090&partnerID=40&md5=1d763616323a72826a8dfab57380b74f},
	affiliations = {European Commission, Joint Research Centre, via Enrico Fermi 2749, Ispra, 21020, Italy},
	abstract = {In this paper we describe the participation of the JRC team in the Sub-task A: "Hate Speech Detection" in the Shared task Stance and Hate Event Detection in Tweets Related to Climate Activism at the CASE 2024 workshop. Our system is purely lexicon (keyword) based and does not use any statistical classifier. The system ranked 18 out of 22 participants with F1 of 0.83, only one point below a system, based on LLM. Our system also obtained one of the highest achieved precision scores among all participating algorithms. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Events detection; Keyword-based; Lexicon-based; Speech detection; Statistical classifier; Subtask; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Qachfar2024199,
	author = {Qachfar, Fatima Zahra and Tuck, Bryan E. and Verma, Rakesh M.},
	title = {DetectiveReDASers at HSD-2Lang 2024: A New Pooling Strategy with Cross-lingual Augmentation and Ensembling for Hate Speech Detection in Low-resource Languages},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {199 – 204},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190254232&partnerID=40&md5=0031ed3c5e95f91b27de0dbb66ef249f},
	affiliations = {University of Houston, Houston, TX, United States},
	abstract = {This paper addresses hate speech detection in Turkish and Arabic tweets, contributing to the HSD-2Lang Shared Task. We propose a specialized pooling strategy within a soft-voting ensemble framework to improve classification in Turkish and Arabic language models. Our approach also includes expanding the training sets through cross-lingual translation, introducing a broader spectrum of hate speech examples. Our method attains F1-Macro scores of 0.6964 for Turkish (Subtask A) and 0.7123 for Arabic (Subtask B). While achieving these results, we also consider the computational overhead, striking a balance between the effectiveness of our unique pooling strategy, data augmentation, and soft-voting ensemble. This approach advances the practical application of language models in low-resource languages for hate speech detection. © 2024 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Arabic languages; Cross-lingual; Language model; Low resource languages; Soft voting; Speech detection; Subtask; Training sets; Turkish language; Turkishs; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Sai2024119,
	author = {Sai, Chava Srinivasa and Kumar, Rangoori Vinay and Saumya, Sunil and Biradar, Shankar},
	title = {IIITDWD_SVC@DravidianLangTech-2024: Breaking Language Barriers; Hate Speech Detection in Telugu-English Code-Mixed Text},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {119 – 123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189863891&partnerID=40&md5=ecfe2f4c7c23c7ef9044b2e7d976a534},
	affiliations = {Department of Data Science and Intelligent Systems, Indian Institute of Information Technology, Karnatka, Dharwad, India},
	abstract = {Social media platforms have become increasingly popular and are utilized for a wide range of purposes, including product promotion, news sharing, accomplishment sharing, and much more. However, it is also employed for defamatory speech, intimidation, and the propagation of untruths about particular groups of people. Further, hateful and offensive posts spread quickly and often have a negative impact on people; it is important to identify and remove them from social media platforms as soon as possible. Over the past few years, research on hate speech detection and offensive content has grown in popularity. One of the many difficulties in identifying hate speech on social media platforms is the use of code-mixed language. The majority of people who use social media typically share their messages in languages with mixed codes, like Telugu–English. To encourage research in this direction, the organizers of DravidianLangTech@EACL-2024 conducted a shared task to identify hateful content in Telugu-English code-mixed text. Our team participated in this shared task, employing three different models: Xlm-Roberta, BERT, and Hate-BERT. In particular, our BERT-based model secured the 14th rank in the competition with a macro F1 score of 0.65. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Social networking (online); Breakings; F1 scores; Language barriers; Social media; Social media platforms; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Yagci2024195,
	author = {Yagci, Utku Ugur and Kolcak, Ahmet Emirhan and Iscan, Egemen},
	title = {ReBERT at HSD-2Lang 2024: Fine-Tuning BERT with AdamW for Hate Speech Detection in Arabic and Turkish},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {195 – 198},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190311192&partnerID=40&md5=e459965380ffd3ace2f4bc2adee35abb},
	affiliations = {Middle East Technical University, Turkey; Istanbul Technical University, Turkey; King's Business School, United Kingdom},
	abstract = {This research tackles the issue of detecting hate speech in Arabic and Turkish languages by utilizing pre-trained BERT models, namely TurkishBERTweet and Arabertv02-twitter. These models are enhanced through a comprehensive hyperparameter search to improve their performance. Our classifiers excelled in the HSD-2Lang 2024 contest, with the Turkish model placing second in Subtask A and the Arabic model first in Subtask B on the private leaderboard. Both models also ranked first on the public dataset. These results demonstrate the efficacy and adaptability of our approach in addressing the evolving challenges of hate speech detection in multilingual contexts. © 2024 Association for Computational Linguistics.},
	keywords = {Arabic languages; Fine tuning; Hyper-parameter; Multilingual context; Performance; Public dataset; Speech detection; Subtask; Turkish language; Turkishs; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Krylova-Grek2024224,
	author = {Krylova-Grek, Yuliya and Burov, Oleksandr},
	title = {A content analysis software system for efficient monitoring and detection of hate speech in online media},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3679},
	pages = {224 – 233},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192731330&partnerID=40&md5=e4444116af64cfb289e70e5116cd40f1},
	affiliations = {National University of “Kyiv-Mohyla Academy”, 2 Hryhoriya Skovorody Str., Kyiv, 04655, Ukraine; Uppsala University, Gamla torget 3, Uppsala, 753 20, Sweden; Institute for Digitalisation of Education, 9 M. Berlinskoho Str., Kyiv, 04060, Ukraine; University of Vienna, 5 Liebiggasse, Vienna, 1010, Austria},
	abstract = {This paper presents the results of interdisciplinary project that is a combination of computer program and psycholinguistic approach to media study. In the research we presented the programs that can be used for monitoring and analysis of media content to identify hate speech at its early stage. The aims of research were the following: 1) develop content analysis program for monitoring Russian media outlets; 2) apply the psycholinguistic approach for identifying hidden and manipulative hate speech. In the research there were used two types of content-analysis: quantitative and qualitative. Quantitative content analysis was conducted with computer program that was developed to select publication that could have contained hate speech. For qualitative content analysis the psycholinguistic method of text analysis was used. The method applies for identification methods and tolls that journalists use to incriminate hidden and manipulative hate speech. It is hypothesized that programs of content-analysis help to optimize work and makes it less time-consuming and more effective for analyst, journalists and other specialists who involved into media study. Methods. Quantitative content analysis, psycholinguistic method of qualitative content-analysis. Quantitative content analysis was developed with Python programming language. The publications were selected according to the key words, periods of search (month) and the name of outlet. The list of key words includes words that are used in media for discrimination, dehumanization, and marginalization of objects of hate. Implementation such a program helped to reduce time of monitoring of media outlets. The qualitative content-analysis was conducted with the authors' psycholinguistic method of text analysis that can be applied for analyzing media texts. The programs of content analysis were applied within the project “Hate Speech in Online Media Publicizing Events in Crimea”. The results were published in a data analysis report on spreading the hate speech in the Russian language media communicating the armed Ukraine - Russia conflict and events related to it in Crimea on a regular base (December 2020 - May 2021). The research showed that the content analysis programs used in the project are useful tools for systematizing and processing data in humanities research and can be used by a wide range of specialist who have deal with collection and processing of information (media, communication, human rights and so on). © 2024 Copyright for this paper by its authors.},
	author_keywords = {content-analysis; hate speech; media; text},
	keywords = {Data handling; Analysis softwares; Content analysis; Hate speech; Key words; Media outlets; Medium; Online medium; Quantitative content analysis; Text; Text analysis; Linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 11th Workshop on Cloud Technologies in Education, CTE 2023; Conference date: 22 December 2023; Conference code: 199320}
}

@CONFERENCE{Das20246370,
	author = {Das, Mithun and Pandey, Saurabh Kumar and Mukherjee, Animesh},
	title = {Evaluating ChatGPT Against Functionality Tests for Hate Speech Detection},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {6370 – 6380},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195993947&partnerID=40&md5=62b181482a7a699c9fc00cb145b56b22},
	affiliations = {Indian Institute of Technology, West Bengal, Kharagpur, 721302, India},
	abstract = {Large language models like ChatGPT have recently shown a great promise in performing several tasks, including hate speech detection. However, it is crucial to comprehend the limitations of these models to build robust hate speech detection systems. To bridge this gap, our study aims to evaluate the strengths and weaknesses of the ChatGPT model in detecting hate speech at a granular level across 11 languages. Our evaluation employs a series of functionality tests that reveals various intricate failures of the model which the aggregate metrics like macro F1 or accuracy are not able to unfold. In addition, we investigate the influence of complex emotions, such as the use of emojis in hate speech, on the performance of the ChatGPT model. Our analysis highlights the shortcomings of the generative models in detecting certain types of hate speech and highlighting the need for further research and improvements in the workings of these models. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {ChatGPT; functionality tests; hate speech; social media},
	keywords = {Aggregates; Social networking (online); ChatGPT; Complex emotions; Detection system; Functionality tests; Granular levels; Hate speech; Language model; Performance; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@CONFERENCE{Shahiki Tash2024184,
	author = {Shahiki Tash, M. and Ahani, Z. and Zamir, M.T. and Kolesnikova, O. and Sidorov, G.},
	title = {Lidoma@LT-EDI 2024:Tamil Hate Speech Detection in Migration Discourse},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {184 – 189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189856435&partnerID=40&md5=b61f5be772dbae3a35012e41366e180e},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico},
	abstract = {The exponential rise in social media users has revolutionized information accessibility and exchange. While these platforms serve various purposes, they also harbor negative elements, including hate speech and offensive behavior. Detecting hate speech in diverse languages has garnered significant attention in Natural Language Processing (NLP). This paper delves into hate speech detection in Tamil, particularly related to migration and refuge, contributing to the Caste/migration hate speech detection shared task. Employing a Convolutional Neural Network (CNN), our model achieved an F1 score of 0.76 in identifying hate speech and signaling potential in the domain despite encountering complexities. We provide an overview of related research, methodology, and insights into the competition’s diverse performances, showcasing the landscape of hate speech detection nuances in the Tamil language. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Convolutional neural networks; Natural language processing systems; Convolutional neural network; Exponentials; F1 scores; Information accessibility; Information exchanges; Language processing; Natural languages; Research methodologies; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@ARTICLE{Daouadi2024681,
	author = {Daouadi, Kheir Eddine and Boualleg, Yaakoub and Guehairia, Oussama},
	title = {Comparing Pre-Trained Language Model for Arabic Hate Speech Detection},
	year = {2024},
	journal = {Computacion y Sistemas},
	volume = {28},
	number = {2},
	pages = {681 – 693},
	doi = {10.13053/CyS-28-2-4130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197733765&doi=10.13053%2fCyS-28-2-4130&partnerID=40&md5=933a9a01b7dd7f89b6aca9bdc46cf5ff},
	affiliations = {Echahid Cheikh Larbi Tebessi University, Laboratory of Vision and Artificial Intelligence, Algeria; Mohamed Khider University of Biskra, Faculty of Sciences and Technology, Algeria},
	abstract = {Today, the classification of hate speech in Arabic tweets has garnered significant attention from scholars worldwide. Although numerous classification approaches proposed in response to this interest, two primary challenges persist are reliance on handcrafted features and limited performance rates. This paper addresses the task of identifying Arabic hate speech on Twitter, aiming to deepen insights into the efficacy of novel machine-learning techniques. Specifically, we compare the performance of traditional machine learning-based approaches with state-of-the-art pre-trained language models based on Transfer Learning, as well as deep learning models. Our experiments, conducted on a benchmark dataset using a standard evaluation scenario, reveal several key findings. Firstly, multidialectal pre-trained language models demonstrate superior performance compared to monolingual and multilingual variants. Secondly, fine-tuning the pre-trained large language models significantly enhances the accuracy of hate speech classification in Arabic tweets. Our primary contribution lies in achieving promising results for the corresponding task through the application of multidialectal pre-trained language models trained on Twitter data. © 2024 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {AraBERT; Arabic hate speech detection; fine-tuning; transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ganguly2024125,
	author = {Ganguly, Amrita and Emran, Al Nahian Bin and Puspo, Sadiya Sayara Chowdhury and Raihan, Md Nishat and Goswami, Dhiman and Zampieri, Marcos},
	title = {MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate Speech and Target Detection Using Transformer Ensembles},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {125 – 131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190263073&partnerID=40&md5=90905305ddb745e325a15a3792e53b5e},
	affiliations = {George Mason University, United States},
	abstract = {The automatic identification of offensive language such as hate speech is important to keep discussions civil in online communities. Identifying hate speech in multimodal content is a particularly challenging task because offensiveness can be manifested in either words or images or a juxtaposition of the two. This paper presents the MasonPerplexity submission for the Shared Task on Multimodal Hate Speech Event Detection at CASE 2024 at EACL 2024. The task is divided into two sub-tasks: subtask A focuses on the identification of hate speech and sub-task B focuses on the identification of targets in text-embedded images during political events. We use an XLM-roBERTa-large model for sub-task A and an ensemble approach combining XLM-roBERTa-base, BERTweet-large, and BERT-base for sub-task B. Our approach obtained 0.8347 F1-score in sub-task A and 0.6741 F1-score in sub-task B ranking 3rd on both sub-tasks. © 2024 Association for Computational Linguistics.},
	keywords = {Automation; Computational linguistics; Automatic identification; Events detection; F1 scores; Multi-modal; Offensive languages; On-line communities; Speech detection; Speech events; Subtask; Targets detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Tabassum2024167,
	author = {Tabassum, Nafisa and Khan, Mosabbir Hossain and Ahsan, Shawly and Hossain, Jawad and Hoque, Mohammed Moshiul},
	title = {Sandalphon@DravidianLangTech-EACL2024: Hate and Offensive Language Detection in Telugu Code-mixed Text using Transliteration-Augmentation},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {167 – 172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189854781&partnerID=40&md5=532048e981f47209d26acee7f7ac66c8},
	affiliations = {Department of Computer Science and Engineering, Chittagong University of Engineering and Technology, Bangladesh},
	abstract = {Hate and offensive language in online platforms pose significant challenges, necessitating automatic detection methods. Particularly in the case of codemixed text, which is very common in social media, the complexity of this problem increases due to the cultural nuances of different languages. DravidianLangTechEACL2024 organized a shared task on detecting hate and offensive language for Telugu. To complete this task, this study investigates the effectiveness of transliteration-augmented datasets for Telugu code-mixed text. In this work, we compare the performance of various machine learning (ML), deep learning (DL), and transformer-based models on both original and augmented datasets. Experimental findings demonstrate the superiority of transformer models, particularly Telugu-BERT, achieving the highest f1-score of 0.77 on the augmented dataset, ranking the 1st position in the leader-board. The study highlights the potential of transliteration-augmented datasets in improving model performance and suggests further exploration of diverse transliteration options to address real-world scenarios. © 2024 Association for Computational Linguistics.},
	keywords = {Codes (symbols); Learning systems; Automatic detection method; Language detection; Machine-learning; Modeling performance; Offensive languages; Online platforms; Performance; Real-world scenario; Social media; Transformer modeling; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Shin2024270,
	author = {Shin, Mingi and Chin, Hyojin and Song, Hyeonho and Choi, Yubin and Choi, Junghoi and Cha, Meeyoung},
	title = {Context-Aware Offensive Language Detection in Human-Chatbot Conversations},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Big Data and Smart Computing, BigComp 2024},
	pages = {270 – 277},
	doi = {10.1109/BigComp60711.2024.00049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191517963&doi=10.1109%2fBigComp60711.2024.00049&partnerID=40&md5=8dca4cd05f64e10c5c05848465f07ab3},
	affiliations = {Kaist, Daejeon, South Korea; Institute for Basic Science (IBS), Daejeon, South Korea; Simsimi Inc., Seoul, South Korea; Ibs, Kaist, Daejeon, South Korea},
	abstract = {Dialogs generated by chatbots may contain unethical and offensive language that can negatively affect users, the service, and society. Existing methods for automatically detecting offensive language are not effective for chat data, which is short and multi-turn and hence requires understanding the subtle context behind the language. We introduce a new offensive language dataset from real human-chatbot conversations with context-aware annotations that can identify the kinds of language that are offensive only in a certain context. We propose a neural network model CALIOPER (Context-Aware modeL for Identifying Offensive language using Pre-trained Encoder and Retrieval), which uses a context-aware encoder and attention mechanism to incorporate previous messages and retrieve relevant information for detecting implicit offensiveness. Experimental results show that the model performs well on multi-turn dialog data, par-ticularly for context-dependent offensive language. This work contributes to making a safer chatbot ecosystem by advancing techniques to detect offensive language in multi-turn dialog data. (Disclaimer: This work contains profanity due to the study topic, which we replace with ∗ marks.)  © 2024 IEEE.},
	author_keywords = {Chatbot; Conversation; Offensive Speech},
	keywords = {Signal encoding; Attention mechanisms; Chatbots; Context-Aware; Context-aware models; Conversation; Language detection; Multi-turn; Neural network model; Offensive languages; Offensive speech; Neural network models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 IEEE International Conference on Big Data and Smart Computing, BigComp 2024; Conference date: 18 February 2024 through 21 February 2024; Conference code: 198771}
}

@CONFERENCE{Zheng20242691,
	author = {Zheng, Jiangrui and Liu, Xueqing and Yang, Guanqun and Haque, Mirazul and Qian, Xing and Rathnasuriya, Ravishka and Yang, Wei and Budhrani, Girish},
	title = {HateModerate: Testing Hate Speech Detectors against Content Moderation Policies},
	year = {2024},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	pages = {2691 – 2710},
	doi = {10.18653/v1/2024.findings-naacl.172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197900343&doi=10.18653%2fv1%2f2024.findings-naacl.172&partnerID=40&md5=1cf4777d288b6d57688c32ec3db703c2},
	affiliations = {Stevens Institute of Technology, United States; University of Texas, Dallas, United States; JP Morgan AI Research, United States},
	abstract = {To protect users from massive hateful content, existing works studied automated hate speech detection. Despite the existing efforts, one question remains: Do automated hate speech detectors conform to social media content policies? A platform's content policies are a checklist of content moderated by the social media platform. Because content moderation rules are often uniquely defined, existing hate speech datasets cannot directly answer this question. This work seeks to answer this question by creating HateModerate, a dataset for testing the behaviors of automated content moderators against content policies. First, we engage 28 annotators and GPT in a six-step annotation process, resulting in a list of hateful and non-hateful test suites matching each of Facebook's 41 hate speech policies. Second, we test the performance of state-of-the-art hate speech detectors against HateModerate, revealing substantial failures these models have in their conformity to the policies. Third, using HateModerate, we augment the training data of a top-downloaded hate detector on HuggingFace. We observe significant improvement in the models' conformity to content policies while having comparable scores on the original test data. Our dataset and code can be found on https://github.com/stevens-textmining/HateModerate. © 2024 Association for Computational Linguistics.},
	keywords = {Automation; Computational linguistics; Social networking (online); Speech recognition; Facebook; Matchings; Media content; Performance; Social media; Social media platforms; Speech detection; State of the art; Test data; Training data; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 Findings of the Association for Computational Linguistics: NAACL 2024; Conference date: 16 June 2024 through 21 June 2024; Conference code: 200405}
}

@CONFERENCE{Hangya20248307,
	author = {Hangya, Viktor and Fraser, Alexander},
	title = {How to Solve Few-Shot Abusive Content Detection Using the Data We Actually Have},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {8307 – 8322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195906662&partnerID=40&md5=298d8c83dc480e4e6a582ea8a08cdd31},
	affiliations = {Center for Information and Language Processing, LMU Munich, Munich Center for Machine Learning, Germany},
	abstract = {Due to the broad range of social media platforms, the requirements of abusive language detection systems are varied and ever-changing. Already a large set of annotated corpora with different properties and label sets were created, such as hate or misogyny detection, but the form and targets of abusive speech are constantly evolving. Since, the annotation of new corpora is expensive, in this work we leverage datasets we already have, covering a wide range of tasks related to abusive language detection. Our goal is to build models cheaply for a new target label set and/or language, using only a few training examples of the target domain. We propose a two-step approach: first we train our model in a multitask fashion. We then carry out few-shot adaptation to the target requirements. Our experiments show that using already existing datasets and only a few-shots of the target task the performance of models improve both monolingually and across languages. Our analysis also shows that our models acquire a general understanding of abusive language, since they improve the prediction of labels which are present only in the target dataset and can benefit from knowledge about labels which are not directly used for the target task. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {abusive content detection; few-shot training; transfer learning},
	keywords = {Abusive content detection; Content detection; Detection system; Few-shot training; Label sets; Language detection; Property; Social media platforms; Target labels; Transfer learning; Transfer learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@CONFERENCE{Islam2024963,
	author = {Islam, Md. Hasibul and Farzana, Kaniz and Khalil, Ibrahim and Ara, Shaneen and Shazid, Md.Ruhul Amin and Kabir Mehedi, Md Humaion},
	title = {Unmasking Toxicity: A Comprehensive Analysis of Hate Speech Detection in Banglish},
	year = {2024},
	journal = {Proceedings - 6th International Conference on Electrical Engineering and Information and Communication Technology, ICEEICT 2024},
	pages = {963 – 968},
	doi = {10.1109/ICEEICT62016.2024.10534362},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195237469&doi=10.1109%2fICEEICT62016.2024.10534362&partnerID=40&md5=fc00b7a94bed03f311b7490cf21b652b},
	affiliations = {Bangladesh University of Business and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; Brac University, Department of Computer Science and Engineering, Dhaka, Bangladesh},
	abstract = {As the digital landscape expands, the rise of online hate speech presents a pressing challenge, necessitating sophis-ticated tools for effective detection and mitigation. This project focuses on the intricate linguistic landscape of Banglish a hybrid language amalgamating Bengali and English striving to develop robust models tailored to its unique characteristics. The dataset, comprising 5000 Banglish comments categorized into various hate speech types, serves as the foundation for model exploration. Our approach spans a wide variety of models, including traditional machine learning (SVM, Logistic Regression,random forest), advanced deep learning architectures and innovative hybrid models (CNN+BiLSTM). Approaches for feature extraction such word embedding, TF-IDF, and Bag-of-Words and sentiment analysis scores are adapted to the nuances of Banglish. Ethical considerations guide our development, addressing algorithmic bias and user rights. The experimental results provide a nuanced understanding of model performance, in- cluding accuracy (90%), precision, recall, and F1 score. Insights derived from these analyses contribute to the ongoing refinement of hate speech detection methodologies, advancing the field of computational linguistics and ethical artificial intelligence. © 2024 IEEE.},
	author_keywords = {Banglish; computational linguistics; content moderation; deep learning; ethical AI; hate speech detection; multilingualism},
	keywords = {Computational linguistics; Deep learning; Ethical technology; Forestry; Learning systems; Logistic regression; Speech recognition; Support vector machines; Banglish; Comprehensive analysis; Content moderation; Deep learning; Ethical AI; Hate speech detection; Hybrid languages; Multilingualism; Pressung; Speech detection; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th International Conference on Electrical Engineering and Information and Communication Technology, ICEEICT 2024; Conference date: 2 May 2024 through 4 May 2024; Conference code: 199753}
}

@BOOK{Tiwari202493,
	author = {Tiwari, Ravi Shekhar},
	title = {Hate speech detection using LSTM and explanation by LIME (local interpretable model-agnostic explanations)},
	year = {2024},
	journal = {Computational Intelligence Methods for Sentiment Analysis in Natural Language Processing Applications},
	pages = {93 – 110},
	doi = {10.1016/B978-0-443-22009-8.00005-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191118592&doi=10.1016%2fB978-0-443-22009-8.00005-7&partnerID=40&md5=6d5e0d8a280005ef9fb5af62215a024c},
	affiliations = {École Centrale School of Engineering, Computer Science and Engineering, Mahindra University, Telangana, Hyderabad, India},
	abstract = {Nowadays, Social Media has a very high impact on everyone’s lives. Social media platforms such as Twitter, Facebook, and Instagram are open platforms where people can express their feelings, thoughts, and emotions. This can lead to a variety of opinions—can collide and lead to verbal conflicts. Therefore, it’s necessary to make social media sites safe by identifying and eliminating hate speech. Any statement that disparages an individual or a group based on a trait such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or another attribute is referred to as hate speeches. Several countries or group of countries such as India, USA, France, Canada, European Unions, and several others have created code of conduct to ensure that social media platforms must regulate any kind of hateful speech, which can disturb the normal functioning of our society and mitigate the risk of any unrest by using social media as a platform. In recent years, we have several examples where fake as well as hate speech on social media has created chaos in real life. Therefore, there is a strict need for an automated methodology to automatically detect and remove hate speech, which can lead to the disturbance in our society. The automated methodology should also be able to provide the clear reason why the specific sentence or the word was detected as hate speech. In this chapter, we will implement a Deep Learning algorithm, that is, Long Short Term Memory to identify hate speech from Twitter speech data, we will be using preprocessing techniques such as Bag of Words, Term Frequency–Inverse Document Frequency, and Glove word embedding by implementing Tensorflow data Pipeline. After training these models, we will compare these models, and based on the metric, we will select all the trained models and implement XAI Explainable Artificial Intelligence known as Local Interpretable Model–Agnostic Explanation to unravel the selected model to understand why the black-box model is associating the datapoint with the specific class. We will discuss theoretical as well as the implementation with the help of python Tensorflow in depth. © 2024 Elsevier Inc. All rights reserved.},
	author_keywords = {bag of words; glove; Hate speech detection; LIME; LSTM; TF-IDF; XAI},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Yu20243456,
	author = {Yu, Seunguk and Choi, Juhwan and Kim, Youngbin},
	title = {Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks},
	year = {2024},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	pages = {3456 – 3467},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197910430&partnerID=40&md5=0eeac8728bacbe762dad4ac5fa3ccdda},
	affiliations = {Chung-Ang University, Seoul, South Korea},
	abstract = {Offensive language detection is an important task for filtering out abusive expressions and improving online user experiences. However, malicious users often attempt to avoid filtering systems through the involvement of textual noises. In this paper, we propose these evasions as user-intended adversarial attacks that insert special symbols or leverage the distinctive features of the Korean language. Furthermore, we introduce simple yet effective pooling strategies in a layer-wise manner to defend against the proposed attacks, focusing on the preceding layers not just the last layer to capture both offensiveness and token embeddings. We demonstrate that these pooling strategies are more robust to performance degradation even when the attack rate is increased, without directly training of such patterns. Notably, we found that models pre-trained on clean texts could achieve a comparable performance in detecting attacked offensive language, to models pre-trained on noisy texts by employing these pooling strategies. © 2024 Association for Computational Linguistics.},
	keywords = {Embeddings; Filtering systems; Korean language; Language detection; Layer-wise; Offensive languages; Online users; Simple++; Special symbols; Users' experiences},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 Findings of the Association for Computational Linguistics: NAACL 2024; Conference date: 16 June 2024 through 21 June 2024; Conference code: 200405}
}

@CONFERENCE{Siddiqui2024,
	author = {Siddiqui, Jawaid Ahmed and Yuhaniz, Siti Sophiayati and Memon, Zulfiqar Ali},
	title = {A Comparative Study of Automatic Hate Speech Detection Using Machine Learning},
	year = {2024},
	journal = {2024 IEEE 1st Karachi Section Humanitarian Technology Conference, Khi-HTC 2024},
	doi = {10.1109/KHI-HTC60760.2024.10482049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190650329&doi=10.1109%2fKHI-HTC60760.2024.10482049&partnerID=40&md5=a48546382d9ca008c09ebe2ae9fef6b1},
	affiliations = {University Technology Malaysia (UTM), Razak Faculty of Technology and Informatics, Kuala Lumpur, Malaysia; National University of Computer and Emerging Sciences (NUCES-FAST), Computer Science Department, Karachi, Pakistan},
	abstract = {There is no denying that social media's ubiquitous use and the knowledge it seamlessly disseminates have improved humanity. But despite its many benefits, this growth has also given rise to urgent worries, including the spread of hate speech. Modern research have embraced a variety of feature engineering techniques and machine learning algorithms as a remedy to this increasing difficulty inside the world of social media platforms. These initiatives aim to automatically identify hate speech across several datasets, offering a promising way to lessen this pervasive problem. As far as we are aware that no research has directly compared different feature engineering methods with different machine learning algorithms to determine which method produces the best results on a representative public dataset. This article's goal is to evaluate how well three different feature engineering approaches work with eight different machine learning algorithms using an open source free publicly available datasets that include 03 different classes. The results of the experiment revealed that the combination of bigram features and the (SVM) support vector machine algorithm performed the best overall, with an amazing accuracy rate of '79%'. Our research consequences touch on actual situations, making it a landmark study that potentially laid the foundation for future efforts aimed at automatically identifying hate speech. Further, the results of these comparisons will serve as state-of-the-art approaches against which further studies of automated text classification can be measured. © 2024 IEEE.},
	author_keywords = {hates speech; machine learning; natural language processing; online social networks; Text classification},
	keywords = {Classification (of information); E-learning; Learning algorithms; Learning systems; Natural language processing systems; Speech recognition; Support vector machines; Text processing; Comparatives studies; Feature engineerings; Hate speech; Language processing; Machine learning algorithms; Machine-learning; Natural language processing; Natural languages; Speech detection; Text classification; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st IEEE Karachi Section Humanitarian Technology Conference, Khi-HTC 2024; Conference date: 8 January 2024 through 9 January 2024; Conference code: 198557}
}

@ARTICLE{Pan20242849,
	author = {Pan, Ronghao and García-Díaz, José Antonio and Valencia-García, Rafael},
	title = {Comparing Fine-Tuning, Zero and Few-Shot Strategies with Large Language Models in Hate Speech Detection in English},
	year = {2024},
	journal = {CMES - Computer Modeling in Engineering and Sciences},
	volume = {140},
	number = {3},
	pages = {2849 – 2868},
	doi = {10.32604/cmes.2024.049631},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198660022&doi=10.32604%2fcmes.2024.049631&partnerID=40&md5=f13a62c503ad45fbce821fc6687424d0},
	affiliations = {Departamento de Informática y Sistemas, Universidad de Murcia, Campus de Espinardo, Murcia, 30100, Spain},
	abstract = {Large Language Models (LLMs) are increasingly demonstrating their ability to understand natural language and solve complex tasks, especially through text generation.One of the relevant capabilities is contextual learning,which involves the ability to receive instructions in natural language or task demonstrations to generate expected outputs for test instances without the need for additional training or gradient updates. In recent years, the popularity of social networking has provided a medium through which some users can engage in offensive and harmful online behavior. In this study, we investigate the ability of different LLMs, ranging from zero-shot and few-shot learning to fine-tuning. Our experiments show that LLMs can identify sexist and hateful online texts using zero-shot and few-shot approaches through information retrieval. Furthermore, it is found that the encoder-decodermodel called Zephyr achieves the best results with the fine-tuning approach, scoring 86.811% on the Explainable Detection of Online Sexism (EDOS) test-set and 57.453% on the Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (HatEval) test-set. Finally, it is confirmed that the evaluated models perform well in hate text detection, as they beat the best result in the HatEval task leaderboard. The error analysis shows that contextual learning had difficulty distinguishing between types of hate speech and figurative language.However, the fine-tuned approach tends to produce many false positives. © 2024 Tech Science Press. All rights reserved.},
	author_keywords = {few-shot; fine-tuning; Hate speech detection; natural language processing; zero-shot},
	keywords = {Computational linguistics; Natural language processing systems; Zero-shot learning; Contextual learning; Few-shot; Fine tuning; Hate speech detection; Language model; Language processing; Natural language processing; Natural languages; Speech detection; Zero-shot; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Zamir2024101,
	author = {Zamir, Muhammad Tayyab and Tash, Moein Shahiki and Ahani, Zahra and Gelbukh, Alexander and Sidorov, Girigori},
	title = {Lidoma@DravidianLangTech 2024: Identifying Hate Speech in Telugu Code-Mixed: A BERT Multilingual},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {101 – 106},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189854545&partnerID=40&md5=05d5f7af1c6e7c02aee403ac035746fa},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico},
	abstract = {Over the past few years, research on hate speech and offensive content identification on social media has been ongoing. Since most people in the world are not native English speakers, unapproved messages are typically sent in code-mixed language. We accomplished collaborative work to identify the language of code-mixed text on social media in order to address the difficulties associated with it in the Telugu language scenario. Specifically, we participated in the shared task on the provided dataset by the DravidianLangTech Organizer for the purpose of identifying hate and non-hate content. The assignment is to classify each sentence in the provided text into two predetermined groups: hate or non-hate. We developed a model in Python and selected a BERT multilingual to do the given task. Using a train-development data set, we developed a model, which we then tested on test data sets. An average macro F1 score metric was used to measure the model’s performance. For the task, the model reported an average macro F1 of 0.6151. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Python; Statistical tests; A-train; Collaborative Work; Content identifications; Data set; F1 scores; Performance; Social media; Test data; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@BOOK{Sharma2024207,
	author = {Sharma, Deepawali and Gupta, Vedika and Singh, Vivek Kumar},
	title = {Abusive comment detection in Tamil using deep learning},
	year = {2024},
	journal = {Computational Intelligence Methods for Sentiment Analysis in Natural Language Processing Applications},
	pages = {207 – 226},
	doi = {10.1016/B978-0-443-22009-8.00001-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191110984&doi=10.1016%2fB978-0-443-22009-8.00001-X&partnerID=40&md5=37625b36d4b115846114cd334b7e6a0d},
	affiliations = {Department of Computer Science, Banaras Hindu University, Uttar Pradesh, Varanasi, India; Jindal Global Business School, O.P. Jindal Global University, Haryana, Sonipat, India},
	abstract = {During the recent years, online social media have expanded in volume and coverage and have become a significant source of information for different groups of people. The comments posted on social media can be emotion-laden and hence can create an impact on mental health of an individual or a group of individuals. One such category of posts includes comments that are abusive or hateful in nature. The comments that spread hate and are abusive in nature usually target certain individuals or some specific communities. It is, therefore, very important to know about them and perhaps be able to detect such content in time. While there exist methods for automated detection of hate speech from posts in English language, there is relatively less research done on other low-resource languages, such as Tamil. This chapter presents an overview of research on detecting hate speech in low-resource languages and explores application of various deep learning models for the task. The abusive comments are classified in different categories: Homophobia, Xenophobia, Transphobic, Misandry, Misogyny, Counter-speech, and Hope speech, from Tamil and Tamil–English code-mixed language. Those comments that are not in the Tamil language are categorized as “Not-Tamil.” The following deep learning models: recurrent neural network, long-short term memory (LSTM), and bidirectional LSTM, are applied to the task. Experimental results are presented along with an analysis of the quality of results. © 2024 Elsevier Inc. All rights reserved.},
	author_keywords = {Abusive; Bi-LSTM; deep learning; GloVe embedding; low-resource language; LSTM; RNN},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Kanta202491,
	author = {Kanta, Selam Abitte and Sidorov, Grigori and Gelbukh, Alexander},
	title = {Selam@DravidianLangTech 2024:Identifying Hate Speech and Offensive Language},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {91 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189859326&partnerID=40&md5=0350424c73a92e081824a6a08faf2e65},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico},
	abstract = {Social media has transformed into a powerful tool for sharing information while upholding the principle of free expression. However, this open platform has given rise to significant issues like hate speech, cyberbullying, aggression, and offensive language, negatively impacting societal well-being. These problems can even lead to severe consequences such as suicidal thoughts, affecting the mental health of the victims. Our primary goal is to develop an automated system for the rapid detection of offensive content on social media, facilitating timely interventions and moderation. This research employs various machine learning classifiers, utilizing character N-gram TF-IDF features. Additionally, we introduce SVM, RL, and Convolutional Neural Network (CNN) models specifically designed for hate speech detection. SVM utilizes character N-gram TF-IDF features, while CNN employs word embedding features. Through extensive experiments, we achieved optimal results, with a weighted F1-score of 0.77 in identifying hate speech and offensive language. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Convolutional neural networks; Learning systems; Neural network models; Social networking (online); Speech recognition; Automated systems; Convolutional neural network; Cyber bullying; Mental health; N-grams; Offensive languages; Open platforms; Sharing information; Social media; Well being; Automation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@ARTICLE{Cao202495165,
	author = {Cao, Tao and Guo, Hengchang and Bai, Shuchen and Li, Bingbing and Liu, Na},
	title = {A Parallel Dual-Channel Chinese Offensive Language Detection Method Combining BERT and CTM Topic Information},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {95165 – 95184},
	doi = {10.1109/ACCESS.2024.3414431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196074167&doi=10.1109%2fACCESS.2024.3414431&partnerID=40&md5=3815b86917180d2bd74558f16e1352f1},
	affiliations = {Shanghai M&g Stationery Inc., Shanghai, 201406, China; Guangzhou Baimaode Medical Equipment Co., Ltd., Guangzhou, 511457, China; Dalian Polytechnic University, School of Information Science and Engineering, Dalian, 116034, China},
	abstract = {With the development of intelligent technology, the application of detection models in various fields becomes more and more important. In this study, a novel detection model (BCOLD) is developed, which is not only suitable for language detection, but also can be widely used in fields such as medical text and image identification.The BCOLD model first utilizes BERT-generated word vectors to capture contextual details, and then combines them with CTM-generated topic vectors to understand the core themes of the text. This fusion strategy enhances the model's detection capability and understanding of the deeper meaning of the text. The fused vectors are fed into DPCNN and TextCNN models in parallel to capture complex semantic structures and local features, and the feature representation is further optimized by the Multi-Head Attention mechanism. The experimental results show that the BCOLD model performs well in language detection, provides an efficient and accurate solution for automatic detection and classification, and exhibits a wide range of application prospects.  © 2013 IEEE.},
	author_keywords = {Attention model; BERT; Chinese text classification; CTM; dual-channel model},
	keywords = {Biological systems; Character recognition; Modeling languages; Semantics; Social networking (online); Vectors; Accuracy; Attention model; Bert; Biological system modeling; Channel modelling; Chinese text; Chinese text classifification; Ctm; Dual channel; Dual-channel model; Features extraction; Social networking (online); Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Gupta2024823,
	author = {Gupta, Palak and Jain, Nikhilesh and Bhat, Aruna},
	title = {Hate Speech Detection using CoT and Post-hoc Explanation through Instruction-based Fine Tuning in Large Language Models},
	year = {2024},
	journal = {Proceedings of the 3rd International Conference on Applied Artificial Intelligence and Computing, ICAAIC 2024},
	pages = {823 – 829},
	doi = {10.1109/ICAAIC60222.2024.10575336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198699467&doi=10.1109%2fICAAIC60222.2024.10575336&partnerID=40&md5=bb0f7cccbedbf41d8b565fe084075b39},
	affiliations = {Delhi Technological University, Department of Computer Science and Engineering, Delhi, India},
	abstract = {In recent times, both social media platforms and researchers have been working to identify hateful language using large language models. However, none of these efforts have focused on using instruction-based fine-tuning with explanations and additional context information in the detection process. This research study has conducted experiments with LaMini and Google Flan-T5 models to analyze the impact of CoT prompts and explanations in zero shot and few shot settings to enhance model interpretability. The analysis reveals that on average including target information in pipeline significantly improves model performance. There is also a considerable effect of adding the explanations into the pipeline, boosting accuracy. The research findings highlight the importance of context and structured prompts in improving model accuracy, highlighting the need for responsible development and deployment of hate speech detection systems in online environments. © 2024 IEEE.},
	author_keywords = {Contextual Information; Google Flan-T5; Hate Speech Detection; Lamini Model; Large Language Models; Prompts},
	keywords = {Computational linguistics; Online systems; Speech recognition; Contextual information; Fine tuning; Google flan-t5; Google+; Hate speech detection; Lamini model; Language model; Large language model; Prompt; Speech detection; Pipelines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Applied Artificial Intelligence and Computing, ICAAIC 2024; Conference date: 5 June 2024 through 7 June 2024; Conference code: 200775}
}

@CONFERENCE{Allan2024211,
	author = {Allan, Shaun H. and Sivakumar, Samyuktaa and Rohan, R. and Jayaguptha, Nikilesh and Thenmozhi, Durairaj},
	title = {Quartet@LT-EDI 2024: A Support Vector Machine Approach For Caste and Migration Hate Speech Detection},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {211 – 215},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189861198&partnerID=40&md5=ee471737a87e2caf27993eb2a2eb30f7},
	affiliations = {Sri Sivasubramaniya Nadar College of Engineering, India},
	abstract = {Hate speech refers to the offensive remarks against a community or individual based on inherent characteristics. Hate speech against a community based on their caste and native are unfortunately prevalent in the society. Especially with social media platforms being a very popular tool for communication and sharing ideas, people post hate speech against caste or migrants on social medias. The Shared Task LT–EDI 2024: Caste and Migration Hate Speech Detection was created with the objective to create an automatic classification system that detects and classifies hate speech posted on social media targeting a community belonging to a particular caste and migrants. Datasets in Tamil language were provided along with the shared task. We experimented with several traditional models such as Naive Bayes, Support Vector Machine (SVM), Logistic Regression, Random Forest Classifier and Decision Tree Classifier out of which Support Vector Machine yielded the best results placing us 8th in the rank list released by the organizers. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Decision trees; Logistic regression; Social networking (online); Speech communication; Speech recognition; Automatic classification systems; Community OR; Community-based; Individual-based; Inherent characteristics; Social media; Social media platforms; Speech detection; Support vectors machine; Tamil language; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@ARTICLE{Ibrahim202459474,
	author = {Ibrahim, Yasmine M. and Essameldin, Reem and Saad, Saad M.},
	title = {Social Media Forensics: An Adaptive Cyberbullying-Related Hate Speech Detection Approach Based on Neural Networks With Uncertainty},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {59474 – 59484},
	doi = {10.1109/ACCESS.2024.3393295},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191334782&doi=10.1109%2fACCESS.2024.3393295&partnerID=40&md5=e24461da576b767a5b4fab10ec333ffc},
	affiliations = {Institute of Graduate Studies and Research, Alexandria University, Department of Information Technology, Alexandria, 21526, Egypt; The Egyptian E-Learning University (EELU), Faculty of Computers and Information Technology, Giza, 12611, Egypt; Alexandria University, Faculty of Computers and Data Science, Alexandria, 21554, Egypt; Pharos University in Alexandria, Faculty of Computer Sciences and Artificial Intelligence, Department of Artificial Intelligence, Alexandria, 21648, Egypt},
	abstract = {Cyberbullying is a social media network issue, a global crisis affecting the victims and society. Automatically identifying cyberbullying on social media has become extremely hard because of the complicated nature and intricate language employed within these platforms. The brevity and informal nature of text often results in ambiguous or unclear expressions, making it challenging to accurately interpret the intended meaning. Identifying cyberbullying becomes even more complex when faced with uncertain or contextually vague content. Presently, numerous approaches are available for cyberbullying detection, However, they continue to grapple with the challenge of distinguishing between various forms of cyberbullying-related hate speech due to its ambiguous and vague nature, and they also fall short in terms of accuracy. This paper proposes a novel approach to fine-grained cyberbullying classification by integrating Neutrosophic Logic within the Multi-Layer Perceptron (MLP) model. The proposed model enhances cyberbullying types by mitigating the challenges posed by the ambiguity and overlapping boundaries between distinct categories of cyberbullying. The incorporation of Neutrosophic Logic aims to address the uncertainty, ambiguity, and indeterminacy within classification decisions, offering a more comprehensive and flexible approach for handling complex classification scenarios. The model, leveraging the one-against-one strategy in MLP classification, captures complex relationships between various types of cyberbullying, due to the overlaps and ambiguous instances within cyberbullying types. The testing phase of this model emphasizes the significance of Neutrosophic Logic, employing class probabilities from multiple one-against-one classifiers to provide a comprehensive insight into classification outcomes. The results of the proposed model demonstrate the performance enhancement of incorporating Neutrosophic Logic for fine-grained cyberbullying classification tasks.  © 2013 IEEE.},
	author_keywords = {Cyberbullying; hate speech detection; multiclass classification, neutrosophic sets; one-against-one; social media forensics},
	keywords = {Complex networks; Computer crime; Digital forensics; Learning systems; Social networking (online); Speech recognition; Uncertainty analysis; Cyber bullying; Hate speech; Hate speech detection; Machine-learning; Multi-class classification; Neutrosophic sets; One-against-one; Social media; Social medium forensic; Speech detection; Support vectors machine; Task analysis; Uncertainty; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Saha2024439,
	author = {Saha, Sagor Kumar and Mim, Afrina Akter and Akter, Sanzida and Hosen, Md. Mehraz and Shihab, Arman Habib and Mehedi, Md Humaion Kabir},
	title = {BengaliHateCB: A Hybrid Deep Learning Model to Identify Bengali Hate Speech Detection from Online Platform},
	year = {2024},
	journal = {Proceedings - 6th International Conference on Electrical Engineering and Information and Communication Technology, ICEEICT 2024},
	pages = {439 – 444},
	doi = {10.1109/ICEEICT62016.2024.10534319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195237773&doi=10.1109%2fICEEICT62016.2024.10534319&partnerID=40&md5=28e6b75883136aac715796ecf0abad40},
	affiliations = {Bangladesh University of Business and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; Brac University, Department of Computer Science and Engineering, Dhaka, Bangladesh},
	abstract = {Online issues including hate speech, abusive communications, and harassment have been exacerbated by the rising number of Internet users. People in Bangladesh often face online harassment and threats expressed in Bengali on various social media platforms. Also, there has not been nearly enough investigation into the possibility of Offensive language in Bengali literature. Although finding realistic ways to reduce hate speech in Bengali texts is urgently needed, there is a notable lack of study in the area of Bengali abusive speech detection, despite the widespread detrimental impacts of abusive text on people's well-being. The results of this research provide a method for spotting bad hateful comments in Bengali online profiles. This research provides a methodology to identify potentially manipulative hate speech in Bengali social media postings. The BERT architecture is used to gather characteristics of Bengali texts. The next step in hate speech classification is to use a Convolutional Neural Network (CNN) model including a softMax activation function. We propose a new model, BERT-CNN, that combines both models. On the Bengali Hate Speech from Social Platforms (BD-SHS) dataset, the BERT-CNN model outperformed most baseline architectures, with accuracy, precision, recall, and F1-scores of 95.67%, 93.55%,92.67%, and 94.44%, respectively. According to our research, the method we suggested for spotting hate speech in Bengali writings posted on social networking sites works well, which can lessen online hate comments and foster a more civilized online community. © 2024 IEEE.},
	author_keywords = {bidirectional encoder representations from transformers; convolutional neural network; hate speech; Natural language processing; social platform},
	keywords = {Convolution; Convolutional neural networks; Deep learning; Natural language processing systems; Network architecture; Network coding; Neural network models; Social networking (online); Bengalis; Bidirectional encoder representation from transformer; Convolutional neural network; Hate speech; Language processing; Natural language processing; Natural languages; Neural network model; Social platform; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th International Conference on Electrical Engineering and Information and Communication Technology, ICEEICT 2024; Conference date: 2 May 2024 through 4 May 2024; Conference code: 199753}
}

@ARTICLE{Charfi2024,
	author = {Charfi, Anis and Besghaier, Mabrouka and Akasheh, Raghda and Atalla, Andria and Zaghouani, Wajdi},
	title = {Hate speech detection with ADHAR: a multi-dialectal hate speech corpus in Arabic},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1391472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195699845&doi=10.3389%2ffrai.2024.1391472&partnerID=40&md5=052c6ad493fcd8ac827642e4d8023490},
	affiliations = {Information Systems Department, Carnegie Mellon University, Doha, Qatar; College of Humanities and Social Sciences, Hamad Bin Khalifa University, Doha, Qatar},
	abstract = {Hate speech detection in Arabic poses a complex challenge due to the dialectal diversity across the Arab world. Most existing hate speech datasets for Arabic cover only one dialect or one hate speech category. They also lack balance across dialects, topics, and hate/non-hate classes. In this paper, we address this gap by presenting ADHAR—a comprehensive multi-dialect, multi-category hate speech corpus for Arabic. ADHAR contains 70,369 words and spans four language variants: Modern Standard Arabic (MSA), Egyptian, Levantine, Gulf and Maghrebi. It covers four key hate speech categories: nationality, religion, ethnicity, and race. A major contribution is that ADHAR is carefully curated to maintain balance across dialects, categories, and hate/non-hate classes to enable unbiased dataset evaluation. We describe the systematic data collection methodology, followed by a rigorous annotation process involving multiple annotators per dialect. Extensive qualitative and quantitative analyses demonstrate the quality and usefulness of ADHAR. Our experiments with various classical and deep learning models demonstrate that our dataset enables the development of robust hate speech classifiers for Arabic, achieving accuracy and F1-scores of up to 90% for hate speech detection and up to 92% for category detection. When trained with Arabert, we achieved an accuracy and F1-score of 94% for hate speech detection, as well as 95% for the category detection. Copyright © 2024 Charfi, Besghaier, Akasheh, Atalla and Zaghouani.},
	author_keywords = {Arabic corpora; Arabic language; dataset annotation; dialectal Arabic; hate speech; natural language processing},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Uludoğan2024205,
	author = {Uludoğan, Gökçe and Yüksel, Atıf Emre and Tunçer, Ümit Can and Işık, Burak and Korkmaz, Yasemin and Akar, Didar and Özgür, Arzucan},
	title = {Detecting Hate Speech in Turkish Print Media: A Corpus and A Hybrid Approach with Target-oriented Linguistic Knowledge},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {205 – 214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190239137&partnerID=40&md5=fc2b204589bb7f325887db21a0ee5348},
	affiliations = {Department of Computer Engineering, Bogazici University, Istanbul, 34342, Turkey; Department of Linguistics, Bogazici University, Istanbul, 34342, Turkey; Hrant Dink Foundatio, Istanbul, 34373, Turkey},
	abstract = {The use of hate speech targeting ethnicity, nationalities, religious identities, and specific groups has been on the rise in the news media. However, most existing automatic hate speech detection models focus on identifying hate speech, often neglecting the target group-specific language that is common in news articles. To address this problem, we first compile a hate speech dataset, TurkishHatePrintCorpus, derived from Turkish news articles and annotate it specifically for the language related to the targeted group. We then introduce the HateTargetBERT model, which integrates the target-centric linguistic features extracted in this study into the BERT model, and demonstrate its effectiveness in detecting hate speech while allowing the model's classification decision to be explained. We have made the dataset and source code publicly available at https://github.com/boun-tabi/HateTargetBERT-TR. Warning: This paper contains hate speech and offensive terms directed towards specific groups. © 2024 Association for Computational Linguistics.},
	keywords = {Linguistics; Speech recognition; Detection models; Hybrid approach; Linguistic knowledge; News articles; News media; Print media; Speech detection; Target group; Target oriented; Turkishs; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Najafi2024185,
	author = {Najafi, Ali and Varol, Onur},
	title = {VRLLab at HSD-2Lang 2024: Turkish Hate Speech Detection Online with TurkishBERTweet},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {185 – 189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190299201&partnerID=40&md5=055d296af2fbc9cc9fa5a8da04a6c888},
	affiliations = {Faculty of Engineering and Natural Sciences, Sabanci University, Turkey; Center of Excellence in Data Analytics, Sabanci University, Turkey},
	abstract = {Social media platforms like Twitter - recently rebranded as X - produce nearly half a billion tweets daily and host a significant number of users that can be affected by content that is not properly moderated. In this work, we present an approach that ranked third at the HSD-2Lang 2024 competition's subtask-A, along with additional methodology developed for this task and evaluation of different approaches. We utilize three different models, and the best-performing approach uses the publicly available TurkishBERTweet model with low-rank adaptation (LoRA) for fine-tuning. We also experiment with another publicly available model and a novel methodology to ensemble different hand-crafted features and outcomes of different models. Finally, we report the experimental results, competition scores, and discussion to improve this effort further. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Detection online; Fine tuning; Novel methodology; Social media platforms; Speech detection; Subtask; Turkishs; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Singh20247204,
	author = {Singh, Akshay and Thakur, Rahul},
	title = {Generalizable Multilingual Hate Speech Detection on Low Resource Indian Languages using Fair Selection in Federated Learning},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {7204 – 7214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198214325&partnerID=40&md5=d24646d0b68175e9425c928c9f865ba0},
	affiliations = {Indian Institute of Technology, Roorkee, India},
	abstract = {Social media, originally meant for peaceful communication, now faces issues with hate speech. Detecting hate speech from social media in Indian languages with linguistic diversity and cultural nuances presents a complex and challenging task. Furthermore, traditional methods involve sharing of users’ sensitive data with a server for model training making it undesirable and involving potential risk to their privacy remained under-studied. In this paper, we combined various low-resource language datasets and propose MultiFED, a federated approach that performs effectively to detect hate speech. MultiFED utilizes continuous adaptation and fine-tuning to aid generalization using subsets of multilingual data overcoming the limitations of data scarcity. Extensive experiments are conducted on 13 Indic datasets across five different pre-trained models. The results show that MultiFED outperforms the state-of-the-art baselines by 8% (approx.) in terms of Accuracy and by 12% (approx.) in terms of F-Score. © 2024 Association for Computational Linguistics.},
	keywords = {Linguistics; Social networking (online); Speech communication; Speech recognition; Fine tuning; Generalisation; Indian languages; Linguistic diversity; Low resource languages; Model training; Potential risks; Sensitive datas; Social media; Speech detection; Sensitive data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024; Conference date: 16 June 2024 through 21 June 2024; Conference code: 200463}
}

@CONFERENCE{Singhal2024249,
	author = {Singhal, Kriti and Bedi, Jatin},
	title = {Transformers@LT-EDI-EACL2024: Caste and Migration Hate Speech Detection in Tamil Using Ensembling on Transformers},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {249 – 253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189858963&partnerID=40&md5=c52d40e0297ef3580d4a980bbbff70c7},
	affiliations = {Computer Science and Engineering Department, Thapar Institute of Engineering and Technology, India},
	abstract = {In recent years, there has been a persistent focus on developing systems that can automatically identify the hate speech content circulating on diverse social media platforms. This paper describes the team "Transformers" submission to the Caste and Migration Hate Speech Detection in Tamil shared task by LT-EDI 2024 workshop at EACL 2024. We used an ensemble approach in the shared task, combining various transformer-based pre-trained models using majority voting. The best macro average F1-score achieved was 0.82. We secured the 1st rank in the Caste and Migration Hate Speech in Tamil shared task. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Ensemble approaches; F1 scores; Social media platforms; Speech content; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@ARTICLE{Shi202485,
	author = {Shi, Xiaohou and Liu, Jiahao and Song, Yaqi},
	title = {BERT and LLM-Based Multivariate Hate Speech Detection on Twitter: Comparative Analysis and Superior Performance},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2058 CCIS},
	pages = {85 – 97},
	doi = {10.1007/978-981-97-1277-9_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190436047&doi=10.1007%2f978-981-97-1277-9_7&partnerID=40&md5=f4c2fbb33c3d525c19669dddb3cb6f7d},
	affiliations = {China Telecom Corporation Limited Research Institute, Beijing, China; Johns-Hopkins University, Baltimore, 21218, MD, United States},
	abstract = {The detection of toxic and hate speech in online social media is becoming increasingly necessary due to its prevalence and the potentially harmful consequences it can cause. Previous research has demonstrated the vital role that machine learning and natural language processing models have in identifying inappropriate language. In this study, the aim is to assess the viability of BERT for accurately predicting multivariate classifications related to hate speech on Twitter. The analysis will be conducted using the Twitter hate speech dataset. BERT has demonstrated exceptional performance in numerous areas of NLP, making it a potentially superior alternative to traditional machine learning approaches. Experiments were performed on the same dataset using 1-layer BERT, 2-layers BERT, and logistic regression models for both training and prediction purposes. The results demonstrate that the 2-layer BERT produces an accuracy of 85%. Additionally, we incorporated transfer learning techniques by leveraging a Large Language model GPT-3 and data augmentation strategies to further enhance model performance. This experiment reached a higher accuracy of 88%. As this is a multivariate classification problem with an asymmetrical dataset, we anticipate BERT and GPT-3 will achieve greater accuracy for the binary classification problem of identifying hate speech. These findings enhance the comprehension of hate speech detection in online material and the implications of various modeling approaches. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {BERT; data augmentation; Fine-tuning; GPT-3; Hate Speech Detection; Large Language modeling; Nature Language Process; Social media; Transfer learning},
	keywords = {Classification (of information); Computational linguistics; Learning algorithms; Learning systems; Logistic regression; Modeling languages; Social networking (online); Speech recognition; Transfer learning; BERT; Data augmentation; Fine tuning; GPT-3; Hate speech detection; Language model; Large language modeling; Nature language process; Social media; Speech detection; Transfer learning; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st International Artificial Intelligence Conference, IAIC 2023; Conference date: 25 November 2023 through 27 November 2023; Conference code: 310589}
}

@ARTICLE{Altinel202486252,
	author = {Altinel, Ayse Berna and Baydogmus, Gozde Karatas and Sahin, Sema and Gurbuz, Mustafa Zahid},
	title = {So-haTRed: A Novel Hybrid System for Turkish Hate Speech Detection in Social Media With Ensemble Deep Learning Improved by BERT and Clustered-Graph Networks},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {86252 – 86270},
	doi = {10.1109/ACCESS.2024.3415350},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196480581&doi=10.1109%2fACCESS.2024.3415350&partnerID=40&md5=2cfd4bc53d0c83ef31f0a23a51dc9cf0},
	affiliations = {Marmara University, Faculty of Technology, Department of Computer Engineering, Istanbul, Maltepe, 34854, Turkey; Doǧuş University, Department of Computer Engineering, Istanbul, 34775, Turkey},
	abstract = {Hate speech on online platforms, characterized by discriminatory language targeting individuals or groups, poses significant harm and necessitates robust detection methods for digital safety. Recognizing the ease with which individuals can engage in such speech online, our study delved into detecting Turkish hate speech using deep learning algorithms and natural language processing techniques. We developed innovative methodologies, including a k-means+textGCN classifier with BERT, which marked the first such attempt in the literature, and explored multiple vector representation techniques such as Term Frequency, Word2Vec, Doc2Vec, and GloVe. Additionally, we investigated various learning algorithms and natural language processing techniques, conducting thorough evaluations on three distinct Turkish hate speech datasets. Notably, our newly presented algorithm exhibited superior performance, achieving an impressive F1-score of 87.81% on the 9K dataset, showcasing advancements in hate speech detection and contributing to a safer online environment.  © 2013 IEEE.},
	author_keywords = {Graph convolutional network; hate speech detection; machine learning; natural language processing; toxic speech; Turkish social media},
	keywords = {Convolution; Deep learning; Graph neural networks; Hybrid systems; Learning algorithms; Learning systems; Natural language processing systems; Social networking (online); Classification algorithm; Convolutional networks; Convolutional neural network; Cultural difference; Deep learning; Graph convolutional network; Graph neural networks; Hate speech; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Social media; Social networking (online); Speech detection; Toxic speech; Turkish social medium; Turkishs; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Reddy2024233,
	author = {Reddy, A. Ankitha and Thomas, Ann Maria and Moorthi, Pranav and Bharathi, B.},
	title = {SSN-Nova@LT-EDI 2024: POS Tagging, Boosting Techniques and Voting Classifiers for Caste And Migration Hate Speech Detection},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {233 – 237},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189864156&partnerID=40&md5=b10be0ce3b9e06d0f163bc15de53653e},
	affiliations = {Department of CSE, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, India},
	abstract = {This paper presents our submission for the shared task on Caste and Migration Hate Speech Detection: LT-EDI@EACL 20241. This text classification task aims to foster the creation of models capable of identifying hate speech related to caste and migration. The dataset comprises social media comments, and the goal is to categorize them into negative and positive sentiments. Our approach explores back-translation for data augmentation to address sparse datasets in low-resource Dravidian languages. While Part-of-Speech (POS) tagging is valuable in natural language processing, our work highlights its ineffectiveness in Dravidian languages, with model performance drastically reducing from 0.73 to 0.67 on application. In analyzing boosting and ensemble methods, the voting classifier with traditional models outperforms others and the boosting techniques, underscoring the efficacy of simpler models on low-resource data despite augmentation. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Speech recognition; Syntactics; Text processing; Back translations; Classification tasks; Data augmentation; Natural languages; Part of speech tagging; Parts-of-speech tagging; Social media; Speech detection; Text classification; Voting classifiers; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@CONFERENCE{Yang202416973,
	author = {Yang, Chuanpeng and Zhu, Fuqing and Liu, Yaxin and Han, Jizhong and Hu, Songlin},
	title = {Uncertainty-Aware Cross-Modal Alignment for Hate Speech Detection},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {16973 – 16983},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195998189&partnerID=40&md5=793cb5e79fda3c8284619a92718f6220},
	affiliations = {Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China},
	abstract = {Hate speech detection has become an urgent task with the emergence of huge multimodal harmful content (e.g., memes) on social media platforms. Previous studies mainly focus on complex feature extraction and fusion to learn discriminative information from memes. However, these methods ignore two key points: 1) the misalignment of image and text in memes caused by the modality gap, and 2) the uncertainty between modalities caused by the contribution degree of each modality to hate sentiment. To this end, this paper proposes an uncertainty-aware cross-modal alignment (UCA) framework for modeling the misalignment and uncertainty in multimodal hate speech detection. Specifically, we first utilize the cross-modal feature encoder to capture image and text feature representations in memes. Then, a cross-modal alignment module is applied to reduce semantic gaps between modalities by aligning the feature representations. Next, a cross-modal fusion module is designed to learn semantic interactions between modalities to capture cross-modal correlations, providing complementary features for memes. Finally, a cross-modal uncertainty learning module is proposed, which evaluates the divergence between unimodal feature distributions to to balance unimodal and cross-modal fusion features. Extensive experiments on five publicly available datasets show that the proposed UCA produces a competitive performance compared with the existing multimodal hate speech detection methods. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {cross-modal alignment; hate speech detection; uncertainty-aware},
	keywords = {Semantics; Speech recognition; Uncertainty analysis; Cross-modal; Cross-modal alignment; Feature representation; Hate speech detection; Learn+; Multi-modal; Speech detection; Uncertainty; Uncertainty-aware; Unimodal; Alignment},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@ARTICLE{Ibrahim2024819,
	author = {Ibrahim, Muhammad Amien and Faisal and Sulistiya, Zefanya Delvin and Winarto, Tora Sangputra Yopie},
	title = {Prompt-Based Data Augmentation with Large Language Models for Indonesian Gender-Based Hate Speech Detection},
	year = {2024},
	journal = {Journal of Computer Science},
	volume = {20},
	number = {8},
	pages = {819 – 826},
	doi = {10.3844/jcssp.2024.819.826},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195291858&doi=10.3844%2fjcssp.2024.819.826&partnerID=40&md5=2823dff6b129629b6543c6ed996d0efd},
	affiliations = {Department of Computer Science, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Department of Mathematics, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia},
	abstract = {The increasing amount of content on social media content makes the use of automatic moderation crucial for preserving a healthy online community and reducing the spread of offensive and abusive content, such as hate speech based on gender. Developing automated social media moderation using machine learning demands a large and balanced dataset. However, difficulties such as data scarcity and class imbalance have hindered the development of gender-based hate speech detection on Indonesian Twitter communities. Creating and annotating a new dataset would be time-consuming and costly. One practical alternative is to use data augmentation methods to help address the minority class imbalance in datasets. This study investigates how prompt-based data augmentation may be used with a large language model to provide organic tweet samples for gender-based hate speech detection. Furthermore, the study investigates the preservation of labels in augmented Twitter samples. In comparison to the benchmark back translation approach, the results show that prompt-based data augmentation using a large language model may generate new and organic Twitter samples while keeping labels preserved and avoiding memorization. In conventional machine learning models, prompt-based data augmentation with a large language model shows competitive performance compared to back translation in terms of accuracy metrics. According to these results, using prompting for data augmentation on large language models is an alternative strategy that can provide new, less memorization tweet samples that maintain label integrity while achieving competitive accuracy results. © 2024 Muhammad Amien Ibrahim, Faisal, Zefanya Delvin Sulistiya and Tora Sangputra Yopie Winarto. This open-access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.},
	author_keywords = {Data Augmentation; Hate Speech Detection; Large Language Models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dutta2024,
	author = {Dutta, Surajit and Neog, Mandira and Baruah, Nomi},
	title = {Assamese Toxic Comment Detection On Social Media Using Machine Learning Methods},
	year = {2024},
	journal = {2nd International Conference on Emerging Trends in Information Technology and Engineering, ic-ETITE 2024},
	doi = {10.1109/ic-ETITE58242.2024.10493331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192548722&doi=10.1109%2fic-ETITE58242.2024.10493331&partnerID=40&md5=6dc8888ac86c9bc1f0f07d492f5782f0},
	affiliations = {Dibrugarh University, Department of Computer Science & Engineering, Dibrugarh, India},
	abstract = {Social media users across society are negatively impacted by toxic contents. For a strong social environment and safe language models, a toxic comment detection system is designed to protect users from harmful content in Social Media.Toxic Comment Detection in Assamese Languages is one of the most challenging Natural Language Processing (NLP) tasks since Indian languages like Assamese are ambiguous in nature and rich in morphology. Despite dearth of e-resources of Assamese language, 19,550 comments are collected manually from popular social media platforms and examined considering Naive Bayes(NB), Support Vector Machine(SVM), Logistic Regression(LR) and Random Forest(RF) with count vector, count vector+TF-IDF and n-gram representation. The experimental findings show that SVM with count vector + TF-IDF has outperformed all the proposed machine learning models with a remarkable accuracy and F1-score of 94%.  © 2024 IEEE.},
	author_keywords = {Assamese; LR; NB; RF; SVM; Toxic},
	keywords = {Learning systems; Natural language processing systems; Random forests; Social networking (online); Support vector regression; Vectors; Assamese; Logistics regressions; Machine learning methods; Naive bayes; Random forests; Safe languages; Social environment; Social media; Support vectors machine; Toxic; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Emerging Trends in Information Technology and Engineering, ic-ETITE 2024; Conference date: 22 February 2024 through 23 February 2024; Conference code: 198961}
}

@ARTICLE{Maity20245714,
	author = {Maity, Krishanu and Poornash, A.S. and Bhattacharya, Shaubhik and Phosit, Salisa and Kongsamlit, Sawarod and Saha, Sriparna and Pasupa, Kitsuchart},
	title = {HateThaiSent: Sentiment-Aided Hate Speech Detection in Thai Language},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {5},
	pages = {5714 – 5727},
	doi = {10.1109/TCSS.2024.3376958},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190173814&doi=10.1109%2fTCSS.2024.3376958&partnerID=40&md5=a07f73936cdfce6f4e9d1a3e33ec5f91},
	affiliations = {Indian Institute of Technology Patna, Department of Computer Science and Engineering, Patna, 801103, India; King Mongkut's Institute of Technology Ladkrabang, School of Information Technology, Bangkok, 10520, Thailand},
	abstract = {Social media platforms are a double-edged sword: on the one hand, they enable the dissemination of information; but on the other hand, they also provide an avenue for spreading online abuse and harassment, such as hate speech. While significant research efforts are being devoted to detecting online hate speech in the English language, little attention has been paid to the Thai language. In this study, we created a benchmark dataset, called HateThaiSent, which labels each post with both hate speech and sentiment information. To detect hate speech, we created a multitask model that uses a dual-channel deep learning approach based on FastText and BERT embeddings, with an added capsule network. One channel utilizes pretrained FastText embeddings while the other uses embeddings from the BERT language model. We aimed to answer two research questions: (Q1) Does incorporating sentiment information improves the performance of hate speech detection (HD) in the Thai language? (Q2) What is the comparative effectiveness of two different approaches for sentiment-Aware HD in the Thai language: feature engineering versus multitasking? Our proposed approach outperformed other baselines and state-of-The-Art models on the HateThaiSent dataset, with overall accuracy/macro-F1 values of 89.67%/89.79%, and 80.92%/80.97% for hate speech and sentiment detection tasks, respectively. We concluded that multitasking is more effective than feature engineering in enhancing the performance of the main task (HD). © 2014 IEEE.},
	author_keywords = {Capsule networks; hate speech detection (HD); multitask (MT); sentiment},
	keywords = {Deep learning; Embeddings; Feature extraction; Job analysis; Multitasking; Speech recognition; Annotation; Capsule network; Features extraction; Hate speech; Hate speech detection; Multitask; Sentiment; Social networking (online); Speech detection; Task analysis; COVID-19},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Tverdokhlib2024339,
	author = {Tverdokhlib, Oleksiy and Vysotska, Victoria and Pukach, Petro and Vovk, Myroslava},
	title = {Information Technology for Identifying Hate Speech in Online Communication Based on Machine Learning},
	year = {2024},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {195},
	pages = {339 – 369},
	doi = {10.1007/978-3-031-54012-7_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191506697&doi=10.1007%2f978-3-031-54012-7_15&partnerID=40&md5=a8805497e42e5ff9da3fc174bdd6f5bb},
	affiliations = {Lviv Polytechnic National University, 12 Bandera Str., Lviv, 79013, Ukraine; Osnabrück University, 1 Friedrich-Janssen-Str., Osnabrück, 49076, Germany},
	abstract = {Proposed in this paper information technology for identifying hate speech in online communication via machine learning methods is realized through the next steps: collecting data from reliable sources and forming datasets, data preprocessing (noise removal, text normalization, stop words removal, tokenization), labeling and data marking (hate, offensive or no hate), extracting significant linguistic features (using Bag-of-Words, TF-IDF, Word2Vec, GloVe, BERT), machine learning method choice, model realization, study and training of the model, estimation of classifier model accuracy. The basis of the considered model is implementation of the data cleaning, dataset partitioning, model training, fasttext using and prognostication. Machine learning method is selected taking into account its suitability for the tasks of text classification into categories of hate and hate speech and the previous efficiency evaluations. Different classifiers from the set of options as KNN (K-Nearest Neighbors), Naive Bayes, Decision Tree, Logistic Regression and Random Forest are estimated. According to metrics Accuracy KNN classifier achieves the accuracy of hate identification 0.832, Naive Bayes 0.315, Decision Tree 0.878, Logistic Regression 0.904 and Random Forest 0.879. According to metrics ROC AUC (Receiver Operating Characteristic Area Under the Curve) KNN classifier achieves performance of hate identification 0.82, Naive Bayes 0.61, Decision Tree 0.80, Logistic Regression 0.92 and Random Forest 0.89. Overall, random forest and logistic regression stand out as the most effective classifiers due to their high values of ROC AUC for all classes and general AUC. Decision Tree and KNN also demonstrate sufficient performance, whereas Naive Bayes lags behind other classifiers in terms of discriminative power and overall classification performance. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Decision Tree; Hate classification; Hate identification; K-Nearest Neighbors; KNN; Logistic Regression; Machine learning; Naive Bayes; NLP; Random Forest; Twitter},
	keywords = {Classification (of information); E-learning; Information retrieval; Learning systems; Linguistics; Logistic regression; Machine learning; Motion compensation; Nearest neighbor search; Random forests; Speech communication; Text processing; Hate classification; Hate identification; K-near neighbor; Logistics regressions; Machine-learning; Naive bayes; Nearest-neighbour; Random forests; Twitter; Decision trees},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Jin20247867,
	author = {Jin, Yiping and Wanner, Leo and Shvets, Alexander},
	title = {GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech Detection?},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {7867 – 7885},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195901200&partnerID=40&md5=05a7f756c139bdddab53b27b526b779b},
	affiliations = {NLP Group, Pompeu Fabra University, Barcelona, Spain; Catalan Institute for Research and Advanced Studies, United States},
	abstract = {Online hate detection suffers from biases incurred in data sampling, annotation, and model pre-training. Therefore, measuring the averaged performance over all examples in held-out test data is inadequate. Instead, we must identify specific model weaknesses and be informed when it is more likely to fail. A recent proposal in this direction is HateCheck, a suite for testing fine-grained model functionalities on synthesized data generated using templates of the kind “You are just a [slur] to me.” However, despite enabling more detailed diagnostic insights, the HateCheck test cases are often generic and have simplistic sentence structures that do not match the real-world data. To address this limitation, we propose GPT-HateCheck, a framework to generate more diverse and realistic functional tests from scratch by instructing large language models (LLMs). We employ an additional natural language inference (NLI) model to verify the generations. Crowd-sourced annotation demonstrates that the generated test cases are of high quality. Using the new functional tests, we can uncover model weaknesses that would be overlooked using the original HateCheck dataset. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Data Synthesization; Hate Speech Detection; Large Language Models},
	keywords = {Computational linguistics; Speech recognition; Data sampling; Data synthesization; Functional test; Hate speech detection; Language model; Large language model; Pre-training; Speech detection; Synthesization; Test case; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@CONFERENCE{Maity2024709,
	author = {Maity, Amit and More, Rishi and Patil, Abhijit and Oza, Jay and Kambli, Gitesh},
	title = {Toxic Comment Detection Using Bidirectional Sequence Classifiers},
	year = {2024},
	journal = {2nd International Conference on Intelligent Data Communication Technologies and Internet of Things, IDCIoT 2024},
	pages = {709 – 716},
	doi = {10.1109/IDCIoT59759.2024.10467922},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190142305&doi=10.1109%2fIDCIoT59759.2024.10467922&partnerID=40&md5=f1cfdab5ed032ba31e42558b835d8d39},
	affiliations = {K.J. Somaiya Institute of Technology, Computer Engineering, India},
	abstract = {With the rising surge of online toxicity, automating the identification of abusive language becomes crucial for improving online discourse. This study proposes a deep learning system that efficiently uses multiple labels to classify harmful comments using bi-directional Long Short-Term Memory (LSTM) networks. By leveraging contextual information, the bi-LSTM model achieves state-of-the-art performance in classifying subtle forms of toxicity such as threats, insults, identity hate, and obscenity. The model achieves above 95% accuracy on benchmark datasets with rigorous data processing, optimized neural architecture, and the utilization of FastText embeddings to handle words that are not in the vocabulary. This technique can automatically filter different levels of toxicity, promoting positive online interactions when integrated into online platforms. The proposed study outlines an end-to-end pipeline incorporating recent NLP advancements and deep contextualized language models to address contemporary challenges in AI-enabled content moderation.  © 2024 IEEE.},
	author_keywords = {bidirectional classifier; long short-term memory; natural language processing; sequence modeling; toxic comment detection},
	keywords = {Brain; Classification (of information); Data handling; Learning systems; Modeling languages; Natural language processing systems; Toxicity; Bi-directional; Bidirectional classifier; Contextual information; Language processing; Memory network; Multiple labels; Natural language processing; Natural languages; Sequence models; Toxic comment detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things, IDCIoT 2024; Conference date: 4 January 2024 through 6 January 2024; Conference code: 198326; All Open Access, Green Open Access}
}

@CONFERENCE{Shaik2024134,
	author = {Shaik, Zuhair Hasan and Kasu, Sai Kartheek Reddy and Saumya, Sunil and Biradar, Shankar},
	title = {IIITDWD-zk@DravidianLangTech-2024: Leveraging the Power of Language Models for Hate Speech Detection in Telugu-English Code-Mixed Text},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {134 – 139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189863475&partnerID=40&md5=710c73207ecaebac0ae37b2fe5317f83},
	affiliations = {Department of Data Science and Intelligent Systems, Indian Institute of Information Technology Dharwad, Karnatka, Dharwad, India},
	abstract = {Hateful online content is a growing concern, especially for young people. While social media platforms aim to connect us, they can also become breeding grounds for negativity and harmful language. This study tackles this issue by proposing a novel framework called HOLD-Z, specifically designed to detect hate and offensive comments in Telugu-English code-mixed social media content. HOLD-Z leverages a combination of approaches, including three powerful models: LSTM architecture, Zypher, and openchat_3.5. The study highlights the effectiveness of prompt engineering and Quantized Low-Rank Adaptation (QLoRA) in boosting performance. Notably, HOLD-Z secured the 9th place in the prestigious HOLD-Telugu DravidianLangTech@EACL-2024 shared task, showcasing its potential for tackling the complexities of hate and offensive comment classification. © 2024 Association for Computational Linguistics.},
	keywords = {Codes (symbols); Computational linguistics; Long short-term memory; Social networking (online); Breeding grounds; Language model; Media content; Online content; Performance; Power; Social media; Social media platforms; Speech detection; Young peoples; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@ARTICLE{Sathishkumar2024209,
	author = {Sathishkumar, R. and Govindarajan, M. and Deepankumar, R.},
	title = {Hate Speech Detection in Social Media Using Ensemble Method in Classifiers},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {915},
	pages = {209 – 222},
	doi = {10.1007/978-981-97-0700-3_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193581856&doi=10.1007%2f978-981-97-0700-3_16&partnerID=40&md5=1e0115918ef6f6552454dc8d5fd094a0},
	affiliations = {Manakula Vinayagar Institute of Technology, Puducherry, India; Annamalai University, Tamilnadu, Chidambaram, India},
	abstract = {Artificial intelligence has reached a stage where machines possess the capability to engage in tasks that traditionally demanded human intelligence. The integral component of this advancement lies in “machine learning,” where algorithms are trained to generate predictions or make decisions by analyzing data. In hate speech identification using machine learning, a number of methods are used to automatically find text that uses vocabulary that is considered to be derogatory, discriminatory, or motivated by hatred. Supervised learning techniques like neural networks, decision trees, and SVMs need a labelled dataset comprising samples of hate speech and non-hate speech. Unsupervised techniques, such k-means clustering, use word frequency and other variables to group comparable text data. CNNs and RNNs are examples of deep learning systems that learn complex word associations and spot trends indicating hate speech. Text data is subjected to the utilization of N-grams, word embeddings, and sentiment analysis in order to derive distinctive attributes. Accurate detection is improved by ensemble methods that combine predictions from various models. Identifying hate speech, avoiding bias in data and algorithms, and the necessity for large and diverse datasets are among the difficulties. Ultimately, machine learning-based hate speech identification is an essential tool for preventing hate speech online and fostering an inclusive and secure online environment for all users. So we did research on detecting hate speech using various algorithms. The TF-IDF representation prioritises textual terms, whereas the ensemble method uses classifier diversity to capture distinctive patterns. Results from experiments show the strategy's effectiveness, with a 90% average accuracy rate for detecting hate speech. By successfully utilizing AI's capacity to fight hate speech, this research helps the development of a diverse and secure online environment. The suggested approach works well for automatically identifying hate speech, making the internet a safer and more welcoming place for all users. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Decision Tree Classifier; Hate Speech; Machine learning; Naive Bayes; Random Forest Classifier; SGD; SVM},
	keywords = {Decision trees; Deep learning; Large datasets; Learning systems; Sentiment analysis; Social networking (online); Speech recognition; Support vector machines; Decision tree classifiers; Ensemble methods; Hate speech; Machine-learning; Naive bayes; Random forest classifier; SGD; Speech identification; SVM; Text data; K-means clustering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Mobile Radio Communications and 5G Networks, MRCN 2023; Conference date: 25 August 2023 through 26 August 2023; Conference code: 312019}
}

@CONFERENCE{Du Toit2024,
	author = {Du Toit, Johannes Louis and Kotze, Eduan},
	title = {The Automatic Detection of Abusive Language in Dota 2 Chat Messages},
	year = {2024},
	journal = {International Conference on Artificial Intelligence, Computer, Data Sciences, and Applications, ACDSA 2024},
	doi = {10.1109/ACDSA59508.2024.10467500},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189931123&doi=10.1109%2fACDSA59508.2024.10467500&partnerID=40&md5=70cb7d3a326a38abe966221aaa27cfb0},
	affiliations = {University of the Free State, Department of Computer Science and Informatics, Bloemfontein, South Africa},
	abstract = {This study addresses the pervasive issue of abusive language in online video game communication channels, focusing on Dota 2 chat messages. The aim was to employ diverse traditional machine learning algorithms and advanced deep learning architectures to identify and classify toxic and abusive language effectively. Leveraging TF-IDF, GloVe word embeddings, and self-trained embeddings, the research compared various classical machine learning models such as Naïve Bayes, Logistic Regression, and Support Vector Machine with convolutional and recurrent neural network models. The results revealed a consistent trend where deep learning models, particularly those employing GRUs and LSTMs, outperformed classical machine learning models. Experiments also demonstrated that self-trained embeddings generally outperformed GloVe embeddings in the domain of online video game chat messages. © 2024 IEEE.},
	author_keywords = {abusive language classification; deep learning; embeddings; GloVe; machine learning; neural networks},
	keywords = {Convolutional neural networks; Embeddings; Human computer interaction; Recurrent neural networks; Abusive language classification; Automatic Detection; Deep learning; Embeddings; Glove; Machine learning models; Machine-learning; Neural-networks; Online video; Video-games; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2024 International Conference on Artificial Intelligence, Computer, Data Sciences, and Applications, ACDSA 2024; Conference date: 1 February 2024 through 2 February 2024; Conference code: 198277}
}

@CONFERENCE{Rajiakodi2024145,
	author = {Rajiakodi, Saranya and Chakravarthi, Bharathi Raja and Ponnusamy, Rahul and Kumaresan, Prasanna Kumar and Thangasamy, Sathiyaraj and Sivagnanam, Bhuvaneswari and Rajkumar, Charmathi},
	title = {Overview of Shared Task on Caste and Migration Hate Speech Detection},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {145 – 151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189864167&partnerID=40&md5=5787efa5f6f4e9f3290ed2910693d51a},
	affiliations = {Central University of Tamil Nadu, India; School of Computer Science, University of Galway, Ireland; Data Science Institute, University of Galway, Ireland; Department of Tamil, Sri Krishna Adithya College of Arts and Science, Tamil Nadu, India; The American College, Tamil Nadu, Madurai, India},
	abstract = {We present an overview of the first shared task on "Caste and Migration Hate Speech Detection." The shared task is organized as part of LT-EDI@EACL 2024. The system must delineate between binary outcomes, ascertaining whether the text is categorized as a caste/migration hate speech or not. The dataset presented in this shared task is in Tamil, which is one of the under-resource languages. There are a total of 51 teams participated in this task. Among them, 15 teams submitted their research results for the task. To the best of our knowledge, this is the first time the shared task has been conducted on textual hate speech detection concerning caste and migration. In this study, we have conducted a systematic analysis and detailed presentation of all the contributions of the participants as well as the statistics of the dataset, which is the social media comments in Tamil language to detect hate speech. It also further goes into the details of a comprehensive analysis of the participants’ methodology and their findings. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Comprehensive analysis; Research results; Social media; Speech detection; Systematic analysis; Tamil language; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@CONFERENCE{Som2024,
	author = {Som, Prithvi and Mishra, Rupali and Das, Simran and Singh, Rohit Kumar and Rakesh, Deepak Kumar and Behera, Bichitrananda and Kumar, Rakesh Ranjan},
	title = {Evaluating Machine Learning Models for Hate Speech Detection in ODIA Language},
	year = {2024},
	journal = {2024 1st International Conference on Cognitive, Green and Ubiquitous Computing, IC-CGU 2024},
	doi = {10.1109/IC-CGU58078.2024.10530821},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195212359&doi=10.1109%2fIC-CGU58078.2024.10530821&partnerID=40&md5=f951a8d07fd9806710f58cdf43eb99ad},
	affiliations = {C. V Raman Global University, Department Of CSE, Bhubaneswar, India},
	abstract = {Low-resource language research can strengthen local communities by providing them with a platform on the international scene. ODIA can be considered as one of the low-resource languages as it is confined only to the region of Odisha. This study delves into the identification of hate speech for the ODIA language on social media platforms through the utilization of machine learning algorithms. In this study we deploy and evaluate different machine learning modals for hate speech detection in ODIA language. Our study employs TF-IDF for Feature extraction and the different well known classification alogrithm i.e SVM, Logistic Regression, Random Forest, Gradient Boosting and Adaboost. The results demonstrate that TF-IDF features, particularly when combined with SVM, exhibit a high level of accuracy (0.838) in detecting hate speech within ODIA datasets. The findings of the study addresses the automatic identification of hate speech in ODIA language can be extracted to other low-resource languages.  © 2024 IEEE.},
	author_keywords = {Feature extraction; Low-resource language; Machine learning models; ODIA},
	keywords = {Adaptive boosting; Extraction; Learning systems; Logistic regression; Random forests; Speech recognition; Support vector machines; Features extraction; Local community; Low resource languages; Machine learning algorithms; Machine learning models; Machine-learning; ODIA; Social media platforms; Speech detection; SVM-Logistic regression; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Cognitive, Green and Ubiquitous Computing, IC-CGU 2024; Conference date: 1 March 2024 through 2 March 2024; Conference code: 199647}
}

@CONFERENCE{Neog20242297,
	author = {Neog, Mandira and Baruah, Nomi},
	title = {A hybrid deep learning approach for Assamese toxic comment detection in social media},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {235},
	pages = {2297 – 2306},
	doi = {10.1016/j.procs.2024.04.218},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196426768&doi=10.1016%2fj.procs.2024.04.218&partnerID=40&md5=86271ddbe1386dd69e30e542f43ce691},
	affiliations = {Dibrugarh University, Dibrugarh, 786004, India},
	abstract = {The presence of toxic comments on online platforms creates significant barriers to encouraging positive conversation and user involvement. The present research introduces a novel hybrid deep learning methodology that combines Bidirectional long-short-term memory (BiLSTM) and Convolutional Neural Network (CNN) architectures to improve toxic comment identification. The major goal is to improve accuracy and efficiency in detecting Assamese toxic content, particularly on social media sites. Due to insufficient existing datasets, information is manually gathered from a wide range of public domains, allowing for a thorough evaluation of the performance of the hybrid method. We used two alternative activation functions in our experiments: sigmoid and softmax. The sigmoid activation obtained 88.43% accuracy, while the softmax activation outperformed with 90.51% accuracy. We have also made an effort to use our suggested Approach in Bengali and Hindi, two additional Indian languages. Due to their comparable Subject-Object-Verb (SOV) linguistic structure to Assamese, we chose these languages, and the results have been fairly encouraging. The findings from the research are extremely significant since they highlight that the hybrid deep learning approach is a promising option for effectively identifying toxic comments on social media networks. © 2024 Elsevier B.V.. All rights reserved.},
	author_keywords = {Assamese; Hybrid deep learning; social media; toxic comment},
	keywords = {Convolutional neural networks; Deep learning; Learning systems; Linguistics; Social networking (online); Assamese; Convolutional neural network; Hybrid deep learning; Learning approach; Neural network architecture; Online platforms; Sigmoids; Social media; Toxic comment; User involvement; Chemical activation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd International Conference on Machine Learning and Data Engineering, ICMLDE 2023; Conference date: 23 November 2023 through 24 November 2023; Conference code: 199981; All Open Access, Gold Open Access}
}

@CONFERENCE{Dehghan202454,
	author = {Dehghan, Somaiyeh and Yanikoglu, Berrin},
	title = {Evaluating ChatGPT's Ability to Detect Hate Speech in Turkish Tweets},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {54 – 59},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190236964&partnerID=40&md5=18210f98e8d945211668934d9b7e457c},
	affiliations = {Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, 34956, Turkey; Center of Excellence in Data Analytics (VERIM), Sabanci University, Istanbul, 34956, Turkey},
	abstract = {ChatGPT, developed by OpenAI, has made a significant impact on the world, mainly on how people interact with technology. In this study, we evaluate ChatGPT's ability to detect hate speech in Turkish tweets and measure its strength using zero- and few-shot paradigms and compare the results to the supervised fine-tuning BERT model. On evaluations with the SIU2023-NST dataset, ChatGPT achieved 65.81% accuracy in detecting hate speech for the few-shot setting, while BERT with supervised fine-tuning achieved 82.22% accuracy. This results supports previous findings that show that, despite its much smaller size, BERT is more suitable for natural language classifications tasks such as hate speech detection. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Speech recognition; Classification tasks; Fine tuning; Natural languages; Speech detection; Turkishs; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Markantonatou202415861,
	author = {Markantonatou, Stella and Stamou, Vivian and Christodoulou, Christina and Apostolopoulou, Georgia and Balas, Antonis and Ioannakis, George},
	title = {The Corpus AIKIA: using ranking annotation for Offensive Language Detection in Modern Greek},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {15861 – 15871},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195976848&partnerID=40&md5=a0ff8a3ce7bddfeac736377c4b0534fd},
	affiliations = {Institute for Language and Speech Processing, National Centre for Scientific Research “Demokritos”, Athens, Greece, Artemidos 6 & Epidavrou, Maroussi, 151 25, Greece; Archimedes, Athena R.C., Panepistimioupolis, Ilissia, Athens, GR-16122, Greece; Department of Informatics and Telecommunications, NKUA, Informatics & Telecommunications, Agia Paraskevi, 15310, Greece},
	abstract = {We introduce a new corpus, named AIKIA, for Offensive Language Detection (OLD) in Modern Greek (EL). EL is a less-resourced language regarding OLD. AIKIA offers free access to annotated data leveraged from EL Twitter and fiction texts using the lexicon of offensive terms, ERIS, that originates from HurtLex. AIKIA has been annotated for offensive values with the Best Worst Scaling (BWS) method, which is designed to avoid problems of categorical and scalar annotation methods. BWS assigns continuous offensive scores in the form of floating point numbers instead of binary arithmetical or categorical values. AIKIA's performance in OLD was tested by fine-tuning a variety of pre-trained language models in a binary classification task. Experimentation with a number of thresholds showed that the best mapping of the continuous values to binary labels should occur at the range [0.5-0.6] of BWS values and that the pre-trained models on EL data achieved the highest Macro-F1 scores. Greek-Media-BERT outperformed all models with a threshold of 0.6 by obtaining a Macro-F1 score of 0.92. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Modern Greek; offensive language detection; ranking annotation},
	keywords = {Annotation methods; Best-worst scaling; F1 scores; Free access; Language detection; Modern greek; Offensive language detection; Offensive languages; Ranking annotation; Scaling method; Digital arithmetic},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@BOOK{Gupta2024189,
	author = {Gupta, Pradeep and Gupta, Sonam},
	title = {Hate speech detection using machine learning models},
	year = {2024},
	journal = {Computational Intelligence in the Industry 4.0},
	pages = {189 – 218},
	doi = {10.1201/9781003479031-11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194519814&doi=10.1201%2f9781003479031-11&partnerID=40&md5=0fb377b183f8a9d183a5e493b41d793d},
	affiliations = {Ajay Kumar Garg Engineering College, Ghaziabad, India; Ajay Kumar Garg Engineering College, Ghaziabad, India},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Santhiya20241506,
	author = {Santhiya, S. and Uma, S. and Abinaya, N. and Jayadharshini, P. and Priyanka, S. and Dharshini, M.N.},
	title = {A Comparative Exploration in Text Classification for Hate Speech and Offensive Language Detection Using BERT-Based and GloVe Embeddings},
	year = {2024},
	journal = {2024 2nd International Conference on Disruptive Technologies, ICDT 2024},
	pages = {1506 – 1509},
	doi = {10.1109/ICDT61202.2024.10489019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191263599&doi=10.1109%2fICDT61202.2024.10489019&partnerID=40&md5=fdbbf8c2b2db1b29d1a6be99167abe5a},
	affiliations = {Kongu Engineering College, Department of Artificial Intelligence, Erode, India; Vivekananda College of Engineering for Women, Department of Computer Science and Engineering, Trichengode, India},
	abstract = {On social media platforms, hate speech and provocative language have significantly increased over the past few years, generating major concerns about their effects on both individuals and society. The proposed work analyzes four models, namely BERT Tokenizer(Bidirectional Encoder Representations from Transformers), BERT-CNN(Convolutional Neural Network), and BERT-RNN(Recurrent Neural Network), and a 1D CNN model with GloVe embeddings, to identify hate speech and offensive language. The aim of the proposed research is to examine the accuracy and other evaluation criteria of these models' performance in identifying hate speech and offensive language. A labeled Kaggle dataset with instances of offensive and hateful words is used for training and testing. To rectify the issue of class imbalance, oversampling techniques are utilized to equalize the class distribution within the dataset. The BERT Tokenizer model utilizes the BERT tokenizer for text tokenization and encoding to classify hate speech and offensive language. BERTCNN model incorporates a CNN layer, while the BERT-RNN model employs an LSTM layer. 1D CNN with GloVe embeddings model uses a 1D CNN layer with pre-trained GloVe word embeddings for classification. The models are trained, validated, and tested using appropriate train-validation-test splits. The 1D CNN with GloVe embeddings model, which obtains the 96.91% as highest accuracy of the four models, is demonstrated to be effective by the experimental findings. An in-depth analysis of recall, precision, and F1-score for every classification enables an improved understanding of the model's performance.  © 2024 IEEE.},
	author_keywords = {BERT Tokenizer; BERT-RNN; BERTCNN; GloVe embeddings; Hate speech; Offensive language},
	keywords = {Classification (of information); Convolutional neural networks; Long short-term memory; Signal encoding; Speech recognition; Statistical tests; Text processing; BERT tokenizer; BERT-RNN; BERTCNN; Embeddings; Glove embedding; Hate speech; Modeling performance; Offensive languages; Text classification; Tokenizer; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Disruptive Technologies, ICDT 2024; Conference date: 15 March 2024 through 16 March 2024; Conference code: 198772}
}

@CONFERENCE{Nithya2024,
	author = {Nithya, M. and Packiam, R.S Lysa and Murugappan, S. Abirami},
	title = {Detection of Offensive Language in Code-Mixed Text on Social Media},
	year = {2024},
	journal = {2024 3rd International Conference on Artificial Intelligence for Internet of Things, AIIoT 2024},
	doi = {10.1109/AIIoT58432.2024.10574567},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198522908&doi=10.1109%2fAIIoT58432.2024.10574567&partnerID=40&md5=e88260ec784041ca6378b6794f7285e2},
	affiliations = {Anna University, Dept of Information Science and Technologically Engineering Guindy, Chennai, India; Anna University, Dept of Information Science and Technology, College of Engineering Guindy, Chennai, India},
	abstract = {In today's digitally interconnected landscape, people have started expressing their thoughts and views on social media platforms. Expressing such freedom of thought occurs not only in English but also in a combination of native and English languages. Such a combination is called a code-mixed language. Expression of thoughts has positive as well as negative impacts, such as a decrease in privacy, cyberbullying, isolation, polarization, comparison, envy, and so on, posing significant challenges for maintaining a positive online environment. One of the negative outcomes can be the use of language that is offensive or disrespectful. We developed a novel framework to indicate the proliferation of offensive language. For this framework, we introduce a code-mixed corpus (Tamil, English, and Tamil-English text) for the detection of the offensive text within the comments. This work is introduced to scrutinize the systemic relationships among comments, users, and their interactions, thus enabling precise detection of offensive language patterns. Unlike traditional models, this framework considers not only the content of individual comments but also the intricate interconnections within the comments. Addressing this issueis essential not just for the well-being of users but can also give a few other advantages on social media platforms. A pre-trained transformer-based model approach is proposed for the classification of offensive language in code-mixed text. This proposed method attained an F 1-score with an overall accuracy of 67.07 \%.  © 2024 IEEE.},
	author_keywords = {Code-Mixed Text; Offensive Language; Social Media; Transformer},
	keywords = {Pattern recognition; Text processing; Code-mixed text; Cyber bullying; English languages; Language patterns; Native language; Offensive languages; Online environments; Social media; Social media platforms; Transformer; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Artificial Intelligence For Internet of Things, AIIoT 2024; Conference date: 3 May 2024 through 4 May 2024; Conference code: 200762}
}

@ARTICLE{Abdrakhmanov2024575,
	author = {Abdrakhmanov, Rustam and Kenesbayev, Serik Muktarovich and Berkimbayev, Kamalbek and Toikenov, Gumyrbek and Abdrashova, Elmira and Alchinbayeva, Oichagul and Ydyrys, Aizhan},
	title = {Offensive Language Detection on Social Media using Machine Learning},
	year = {2024},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {15},
	number = {5},
	pages = {575 – 582},
	doi = {10.14569/IJACSA.2024.0150557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197153260&doi=10.14569%2fIJACSA.2024.0150557&partnerID=40&md5=f26eb3b163ba37f351f8c1608676ba9c},
	affiliations = {International University of Tourism and Hospitality, Turkistan, Kazakhstan; Kazakh National Women’s Teacher Training University, Almaty, Kazakhstan; Khoja Akhmet Yassawi International Kazakh-Turkish University, Turkistan, Kazakhstan; M. Auezov South Kazakhstan University, Shymkent, Kazakhstan; International Information Technology University, Almaty, Kazakhstan},
	abstract = {This research paper addresses the critical issue of cyberbullying detection within the realm of social networks, employing a comprehensive examination of various machine learning and deep learning techniques. The study investigates the performance of these methodologies through rigorous evaluation using standard metrics, including Accuracy, Precision, Recall, F-measure, and AUC-ROC. The findings highlight the notable efficacy of deep learning models, particularly the Bidirectional Long Short-Term Memory (BiLSTM) architecture, in consistently outperforming alternative methods across diverse classification tasks. Confusion matrices and graphical representations further elucidate model performance, emphasizing the BiLSTM-based model's remarkable capacity to discern and classify cyberbullying instances accurately. These results underscore the significance of advanced neural network structures in capturing the complexities of online hate speech and offensive content. This research contributes valuable insights toward fostering safer and more inclusive online communities by facilitating early identification and mitigation of cyberbullying. Future investigations may explore hybrid approaches, additional feature integration, or realtime detection systems to further refine and advance the state-of-the-art in addressing this critical societal concern. © (2024), (Science and Information Organization). All Rights Reserved.},
	author_keywords = {CNN; deep learning; hate speech; LSTM; Machine learning; RNN},
	keywords = {Computer crime; Learning systems; Social networking (online); Cyber bullying; Deep learning; Hate speech; Language detection; LSTM; Machine-learning; Offensive languages; Research papers; RNN; Social media; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Ibrahim2024243,
	author = {Ibrahim, Yasmine M. and Essameldin, Reem and Darwish, Saad M.},
	title = {An Adaptive Hate Speech Detection Approach Using Neutrosophic Neural Networks for Social Media Forensics},
	year = {2024},
	journal = {Computers, Materials and Continua},
	volume = {79},
	number = {1},
	pages = {243 – 262},
	doi = {10.32604/cmc.2024.047840},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191708666&doi=10.32604%2fcmc.2024.047840&partnerID=40&md5=620b3c7fdc6c07bef4ee0fc77e6f05c0},
	affiliations = {Department of Information Technology, Institute of Graduate Studies and Research, Alexandria University, Alexandria, 21526, Egypt; Faculty of Computers and Information Technology, Egyptian E-Learning University (EELU), Giza, 12611, Egypt; Faculty of Computers and Data Science, Alexandria University, Alexandria, 21554, Egypt},
	abstract = {Detecting hate speech automatically in social media forensics has emerged as a highly challenging task due to the complex nature of language used in such platforms. Currently, several methods exist for classifying hate speech, but they still suffer from ambiguity when differentiating between hateful and offensive content and they also lack accuracy. The work suggested in this paper uses a combination of the Whale Optimization Algorithm (WOA) and Particle Swarm Optimization (PSO) to adjust the weights of two Multi-Layer Perceptron (MLPs) for neutrosophic sets classification. During the training process of the MLP, the WOA is employed to explore and determine the optimal set of weights. The PSO algorithm adjusts the weights to optimize the performance of the MLP as fine-tuning. Additionally, in this approach, two separate MLP models are employed. One MLP is dedicated to predicting degrees of truth membership, while the other MLP focuses on predicting degrees of false membership. The difference between these memberships quantifies uncertainty, indicating the degree of indeterminacy in predictions. The experimental results indicate the superior performance of our model compared to previous work when evaluated on the Davidson dataset. © 2024 Tech Science Press. All rights reserved.},
	author_keywords = {Hate speech detection; neutrosophic sets; social media forensics; whale optimization},
	keywords = {Forecasting; Particle swarm optimization (PSO); Social networking (online); Hate speech detection; Multilayers perceptrons; Neutrosophic sets; Optimisations; Optimization algorithms; Performance; Social media; Social medium forensic; Speech detection; Whale optimization; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Ullah202485,
	author = {Ullah, Fida and Zamir, Muhammad Tayyab and Arif, Muhammad and Ahmad, M. and Felipe-Riveron, E. and Gelbukh, A.},
	title = {Fida @DravidianLangTech 2024: A Novel Approach to Hate Speech Detection Using Distilbert-base-multilingual-cased},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {85 – 90},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189856488&partnerID=40&md5=97bbff71749f4b13687813b4cbfe1466},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico},
	abstract = {In the contemporary digital landscape, social media has emerged as a prominent means of communication and information dissemination, offering a rapid outreach to a broad audience compared to traditional communication methods. Unfortunately, the escalating prevalence of abusive language and hate speech on these platforms has become a pressing issue. Detecting and addressing such content on the Internet has garnered considerable attention due to the significant impact it has on individuals. The advent of deep learning has facilitated the use of pre-trained deep neural network models for text classification tasks. While these models demonstrate high performance, some exhibit a substantial number of parameters. In the DravidianLangTech@EACL 2024 task, we opted for the Distilbert-base-multilingual-cased model, an enhancement of the BERT model that effectively reduces the number of parameters without compromising performance. This model was selected based on its exceptional results in the task. Our system achieved a commendable macro F1 score of 0.6369, securing the 18th position among the 27 participating teams. © 2024 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Deep neural networks; Neural network models; Text processing; Classification tasks; Communication method; F1 scores; Neural network model; Participating teams; Performance; Pressung; Social media; Speech detection; Text classification; Information dissemination},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Păis202467,
	author = {Păis, Vasile},
	title = {RACAI at ClimateActivism 2024: Improving Detection of Hate Speech by Extending LLM Predictions with Handcrafted Features},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {67 – 72},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190298800&partnerID=40&md5=e6d9f61eac377ea0cd78e25abb3e7cf9},
	affiliations = {Research Institute for Artificial Intelligence "Mihai Drăgănescu", Romanian Academy, Bucharest, Romania},
	abstract = {This paper describes the system that participated in the Climate Activism Stance and Hate Event Detection shared task organized at The 7th Workshop on Challenges and Applications of Automated Extraction of Sociopolitical Events from Text (CASE 2024). The system tackles the important task of hate speech detection by combining large language model predictions with manually designed features, while trying to explain where the LLM approach fails to predict the correct results. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Feature extraction; Speech recognition; Automated extraction; Events detection; Language model; Model prediction; Speech detection; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Singhal2024190,
	author = {Singhal, Kriti and Bedi, Jatin},
	title = {Transformers at HSD-2Lang 2024: Hate Speech Detection in Arabic and Turkish Tweets Using BERT Based Architectures},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {190 – 194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190298920&partnerID=40&md5=8825ec54ad1736ef77296175ffb29355},
	affiliations = {Computer Science and Engineering Department, Thapar Institute of Engineering and Technology, India},
	abstract = {Over the past years, researchers across the globe have made significant efforts to develop systems capable of identifying the presence of hate speech in different languages. This paper describes the team Transformers' submission to the subtasks: Hate Speech Detection in Turkish across Various Contexts and Hate Speech Detection with Limited Data in Arabic, organized by HSD-2Lang in conjunction with CASE at EACL 2024. A BERT based architecture was employed in both the subtasks. We achieved an F1 score of 0.63258 using XLM RoBERTa and 0.48101 using mBERT, hence securing the 6th rank and the 5th rank in the first and the second subtask, respectively. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; F1 scores; Limited data; Speech detection; Subtask; Turkishs; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Joshi2024,
	author = {Joshi, Prasad and Pathak, Varsha},
	title = {Development of Code-Mixed Marathi-English Dataset for Hate Speech Detection},
	year = {2024},
	journal = {2024 International Conference on Emerging Smart Computing and Informatics, ESCI 2024},
	doi = {10.1109/ESCI59607.2024.10497428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191739845&doi=10.1109%2fESCI59607.2024.10497428&partnerID=40&md5=17208d23a015472aff842f432312b14b},
	affiliations = {JET's Zulal Bhilajirao Patil College, Dhule(M.S.), K B C North Maharashtra University Jalgaon (M.S.), Jalgaon, India},
	abstract = {In India, people commonly use a mix of English and their regional languages on social media, resulting in a substantial amount of code-mixed content. As of the present date, there is only a limited number of hate speech code-mixed datasets available for Indian languages, including Hindi-English, Bengali-Hindi, Malayalam-English, and Tamil-English. However, there are no resources or datasets available for Marathi-English code-mixed data with hate speech labels. This paper introduces a novel gold standard corpus for sentiment analysis of code-mixed text in Marathi-English, annotated by voluntary annotators. The gold standard corpus achieved an impressive Krippendorff's alpha score of above 0.9 for the dataset. Utilizing this new corpus, the paper establishes a benchmark for sentiment analysis in Marathi-English code-mixed texts.  © 2024 IEEE.},
	author_keywords = {code-mixed; dataset; hate; machine learning; Marathi; sentiment},
	keywords = {Machine learning; Code-mixed; Dataset; Gold standards; Hate; Machine-learning; Marathi; Sentiment; Sentiment analysis; Social media; Speech detection; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th IEEE International Conference on Emerging Smart Computing and Informatics, ESCI 2024; Conference date: 5 March 2024 through 7 March 2024; Conference code: 198933}
}

@CONFERENCE{Ahani2024107,
	author = {Ahani, Z. and Shahiki Tash, M. and Zamir, M.T. and Gelbukh, I. and Gelbukh, A.},
	title = {Zavira@DravidianLangTech 2024:Telugu hate speech detection using LSTM},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {107 – 112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189860177&partnerID=40&md5=8451b82efff8ab0aaa7649a85ab26ba0},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico},
	abstract = {Hate speech is communication, often oral or written, that incites, stigmatizes, or incites violence or prejudice against individuals or groups based on characteristics such as race, religion, ethnicity, gender, sexual orientation, or other protected characteristics. This usually involves expressions of hostility, contempt, or prejudice and can have harmful social consequences. Among the broader social landscape, an important problem and challenge facing the medical community is related to the impact of people’s verbal expression. These words have a significant and immediate effect on human behavior and psyche. Repeating such phrases can even lead to depression and social isolation. In an attempt to identify and classify these Telugu text samples in the social media domain, our research LSTM and the findings of this experiment are summarized in this paper, in which out of 27 participants, we obtained 8th place with an F1 score of 0.68. © 2024 Association for Computational Linguistics.},
	keywords = {Behavioral research; Economic and social effects; Speech communication; Speech recognition; Community IS; Group-based; Human behaviors; Individual-based; Medical community; Problems and challenges; Sexual orientations; Social consequences; Social landscapes; Speech detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Dehghan202411745,
	author = {Dehghan, Somaiyeh and Yanikoglu, Berrin},
	title = {Multi-domain Hate Speech Detection Using Dual Contrastive Learning and Paralinguistic Features},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {11745 – 11755},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195912073&partnerID=40&md5=1cf4b2a576dac2acf9ed5397a734d6fc},
	affiliations = {Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, 34956, Turkey; Center of Excellence in Data Analytics (VERIM), Sabanci University, Istanbul, 34956, Turkey},
	abstract = {Social networks have become venues where people can share and spread hate speech, especially when the platforms allow users to remain anonymous. Hate speech can have significant social and cultural effects, especially when it targets specific groups of people in terms of religion, race, ethnicity, culture or a specific social situation such as immigrants and refugees. In this study, we propose a hate speech detection model, BERTurk-DualCL, using a mixed objective with contrastive learning loss that is combined with the traditional cross-entropy loss used for classification. In addition, we study the effects of paralinguistic features, namely emojis and hashtags, on the performance of our model. We trained and evaluated our model on tweets in four different topics with heated discussions from two separate datasets, ranging from discussions about migrants to the Israel-Palestine conflict. Our multi-domain model outperforms comparable results in literature and the average results of four domain-specific models, achieving a macro-F1 score of 81.04% and 58.89% on two- and five-class tasks respectively. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Contrastive Learning; Hate Speech Detection; Turkish Language},
	keywords = {Linguistics; Social aspects; Contrastive learning; Cross entropy; Cultural effects; Detection models; Entropy loss; Hate speech detection; Multi-domains; Paralinguistic; Speech detection; Turkish language; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@CONFERENCE{Monish2024,
	author = {Monish, M.N. and Sooda, Kavitha},
	title = {Ensemble Approaches for Offensive Language Detection in Kannada},
	year = {2024},
	journal = {2024 3rd International Conference for Innovation in Technology, INOCON 2024},
	doi = {10.1109/INOCON60754.2024.10511853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193625045&doi=10.1109%2fINOCON60754.2024.10511853&partnerID=40&md5=96c60fab47d0555e68a2772c8d496ded},
	affiliations = {B.M.S. College of Engineering, Dept. of Computer Science & Engineering, Bengaluru, India},
	abstract = {In the realm of natural language processing, sentiment analysis remains a focal point due to its pivotal role in discerning and analyzing public sentiments. While past research has been dedicated to enhancing the performance of sentiment analysis models, this study delves into the potential benefits of ensemble techniques, with a special emphasis on Genetic Algorithm (GA) optimization, The main thrust of this research was to investigate whether merging multiple models and subsequently optimizing their weights via GA could elevate performance. Evaluations were thoughtfully conducted, focusing on the weighted precision, recall, and F1-scores of individual models. Additionally, the study compared the ensemble methods, both with and without GA optimization, The ensemble method, even without the GA optimization, secured an impressive F1-score of 0.73. Upon integrating the GA optimization, there was a gentle improvement in the ensemble's performance, achieving an F1-score of 0.75, In summing up, this study manifests a palpable enhancement in sentiment analysis outcomes when shifting from standalone models to a GA-optimized ensemble mechanism. The results, epitomized by an F1-score peaking at 0.75, underline the intrinsic merits of harnessing GA for weight optimization in ensemble constructs. © 2024 IEEE.},
	author_keywords = {Data Augmentation; Ensemble Modeling; Genetic Algorithm; MBERT; MPNet; Natural Language Processing; XLM-Roberta},
	keywords = {Modeling languages; Sentiment analysis; Data augmentation; Ensemble models; F1 scores; Genetic-algorithm optimizations; Language processing; MBERT; MPNet; Natural language processing; Natural languages; XLM-robertum; Genetic algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 3rd International Conference for Innovation in Technology, INOCON 2024; Conference date: 1 March 2024 through 3 March 2024; Conference code: 199351}
}

@ARTICLE{Maity2024317,
	author = {Maity, Krishanu and Balaji, Gokulapriyan and Saha, Sriparna},
	title = {Towards Analyzing the Efficacy of Multi-task Learning in Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14452 LNCS},
	pages = {317 – 328},
	doi = {10.1007/978-981-99-8076-5_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190366158&doi=10.1007%2f978-981-99-8076-5_23&partnerID=40&md5=e0faf63b0df4b3f0af512875a1a2a433},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, 801103, India; Indian Institute of Information and Technology, Design and Manufacturing, Chennai, Kancheepuram, India},
	abstract = { Secretary-General António Guterres launched the United Nations Strategy and Plan of Action on Hate Speech in 2019, recognizing the alarming trend of increasing hate speech worldwide. Despite extensive research, benchmark datasets for hate speech detection remain limited in volume and vary in domain and annotation. In this paper, the following research objectives are deliberated (a) performance comparisons between multi-task models against single-task models; (b) performance study of different multi-task models (fully shared, shared-private) for hate speech detection, considering individual dataset as a separate task; (c) what is the effect of using different combinations of available existing datasets in the performance of multi-task settings? A total of six datasets that contain offensive and hate speech on the accounts of race, sex, and religion are considered for the above study. Our analysis suggests that a proper combination of datasets in a multi-task setting can overcome data scarcity and develop a unified framework. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Data scarcity; Hate Speech; Multi-Task; Single Task},
	keywords = {Learning systems; Benchmark datasets; Data scarcity; Hate speech; Multi tasks; Multi-task model; Multitask learning; Plans of actions; Single task; Speech detection; United Nations; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th International Conference on Neural Information Processing, ICONIP 2023; Conference date: 20 November 2023 through 23 November 2023; Conference code: 304439}
}

@CONFERENCE{Bade2024240,
	author = {Bade, Girma Yohannis and Kolesnikova, Olga and Sidorov, Grigori and Oropeza, José Luis},
	title = {Social Media Hate and Offensive Speech Detection Using Machine Learning Method},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {240 – 244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189859519&partnerID=40&md5=c1863ca8caceffa21c745cab6f6ad050},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico},
	abstract = {Even though the improper use of social media is increasing nowadays, there is also technology that brings solutions. Here, improperness is posting hate and offensive speech that might harm an individual or group. Hate speech refers to an insult toward an individual or group based on their identities. Spreading it on social media platforms is a serious problem for society. The solution, on the other hand, is the availability of natural language processing(NLP) technology that is capable to detect and handle such problems. This paper presents the detection of social media’s hate and offensive speech in the code-mixed Telugu language. For this, the task and golden standard dataset were provided for us by the shared task organizer (DravidianLangTech@EACL 2024)1. To this end, we have employed the TF-IDF technique for numeric feature extraction and used a random forest algorithm for modeling hate speech detection. Finally, the developed model was evaluated on the test dataset and achieved 0.492 macro-F1. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Forestry; Learning algorithms; Natural language processing systems; Social networking (online); Speech recognition; Statistical tests; Group-based; Individual-based; Language processing; Machine learning methods; Natural languages; Processing technologies; Social media; Social media platforms; Speech detection; TF-IDF technique; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Almohaimeed2024142,
	author = {Almohaimeed, Saad and Almohaimeed, Saleh and Boloni, Ladislau},
	title = {Transfer Learning and Lexicon-Based Approaches for Implicit Hate Speech Detection: A Comparative Study of Human and GPT-4 Annotation},
	year = {2024},
	journal = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
	pages = {142 – 147},
	doi = {10.1109/ICSC59802.2024.00028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192236912&doi=10.1109%2fICSC59802.2024.00028&partnerID=40&md5=5704b51c214e576930aa5797f3449980},
	affiliations = {University of Central Florida, Dept. of Computer Science, Orlando, United States},
	abstract = {Detecting harmful speech is the subject of significant research effort both in the academia and industry. While good progress was made on detecting explicit hate speech, detecting implicit hate remains difficult as it requires a deep understanding of the allusions of the text and the social context in which it was uttered. In this paper we study the effectiveness of several approaches to implicit hate speech detection, including lexicon-based approaches, transfer learning, and the use of up-to-date large language models, such as GPT-4. By combining lexicon-based approach with the targeted topics, we performed transfer learning experiments using knowledge from seven public harmful speech datasets. Various combinations of the proposed approaches showed an improvement of 0.6-2.3% in the F1Macro score compared to the baselines. We observed that while GPT-4 annotations show a good agreement with human labels, there is often a conflict when interpreting sarcasm, text shortening based on context, and speech that targets individuals. Warning: due to the nature of the research subject, this paper contains explicit and potentially offensive language.  © 2024 IEEE.},
	author_keywords = {abusive language; GPT-4 annotation; hate speech; implicit hate; lexicon-based; transfer learning},
	keywords = {Learning systems; Speech recognition; Abusive language; Comparatives studies; GPT-4 annotation; Hate speech; Implicit hate; Lexicon-based; Research efforts; Social context; Speech detection; Transfer learning; Transfer learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 18th IEEE International Conference on Semantic Computing, ICSC 2024; Conference date: 5 February 2024 through 7 February 2024; Conference code: 198360}
}

@CONFERENCE{Pokrywka2024196,
	author = {Pokrywka, Jakub and Jassem, Krzysztof},
	title = {kubapok@LT-EDI 2024: Evaluating Transformer Models for Hate Speech Detection in Tamil},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {196 – 199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189858945&partnerID=40&md5=f755056fefb3436c4c24bb67bf6c034e},
	affiliations = {Adam Mickiewicz University, Faculty of Mathematics and Computer Science, Poland},
	abstract = {We describe the second-place submission for the shared task organized at the Fourth Workshop on Language Technology for Equality, Diversity, and Inclusion (LT-EDI-2024). The task focuses on detecting caste/migration hate speech in Tamil. The included texts involve the Tamil language in both Tamil script and transliterated into Latin script, with some texts also in English. Considering different scripts, we examined the performance of 12 transformer language models on the dev set. Our analysis revealed that for the whole dataset, the model google/muril-large-cased performs the best. We used an ensemble of several models for the final challenge submission, achieving 0.81 for the test dataset. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large datasets; Speech recognition; Google+; Language model; Language technology; Performance; Speech detection; Tamil language; Transformer modeling; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@CONFERENCE{Maronikolakis20241,
	author = {Maronikolakis, Antonis and Köksal, Abdullatif and Schütze, Hinrich},
	title = {Sociocultural knowledge is needed for selection of shots in hate speech detection tasks},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {1 – 13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189857855&partnerID=40&md5=384b608828316a4bab09c7ec2d9d0c13},
	affiliations = {Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning, Germany},
	abstract = {We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for Brazil, Germany, India and Kenya, to aid model development and interpretability. First, we demonstrate how HATELEXICON can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target group names. Further, we propose a culturally-informed method to aid shot selection for training in low-resource settings. In few-shot learning, shot selection is of paramount importance to model performance and we need to ensure we make the most of available data. We work with HASOC German and Hindi data for training and the Multilingual HateCheck (MHC) benchmark for evaluation. We show that selecting shots based on our lexicon leads to models performing better than models trained on shots sampled randomly. Thus, when given only a few training examples, using HATELEXICON to select shots containing more sociocultural information leads to better few-shot performance. With these two use-cases we show how our HATELEXICON can be used for more effective hate speech detection. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Detection tasks; Interpretability; Low-resource settings; Model development; Model prediction; Modeling performance; Performance; Speech detection; Target group; Training example; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@CONFERENCE{El-Sayed2024105,
	author = {El-Sayed, Ahmed and Nasr, Omar},
	title = {AAST-NLP at ClimateActivism 2024: Ensemble-Based Climate Activism Stance and Hate Speech Detection: Leveraging Pretrained Language Models},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {105 – 110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190240319&partnerID=40&md5=c90b6d0734f1ed90f9592771773bd613},
	affiliations = {Arab Academy for Science and Technology, Egypt},
	abstract = {Climate activism has emerged as a powerful force in addressing the urgent challenges posed by climate change. Individuals and organizations passionate about environmental issues use platforms like Twitter to mobilize support, share information, and advocate for policy changes. Unfortunately, amidst the passionate discussions, there has been an unfortunate rise in the prevalence of hate speech on the platform. Some users resort to personal attacks and divisive language, undermining the constructive efforts of climate activists. In this paper, we describe our approaches for three subtasks of ClimateActivism at CASE 2024. For all the three subtasks, we utilize pretrained language models enhanced by ensemble learning. Regarding the second subtask, dedicated to target detection, we experimented with incorporating Named Entity Recognition in the pipeline. Additionally, our models secure the second, third and fifth ranks in the three subtasks respectively. © 2024 Association for Computational Linguistics.},
	keywords = {Climate models; Computational linguistics; Speech recognition; Ensemble learning; Environmental issues; Language model; Named entity recognition; Policy changes; Speech detection; Subtask; Targets detection; Climate change},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Rishi20241171,
	author = {Rishi, Priti and Abhishek, K.S. and Rity Nivedha, Y.},
	title = {Hate Speech Detection in Tweets using Support Vector Machine},
	year = {2024},
	journal = {Proceedings - International Conference on Computing, Power, and Communication Technologies, IC2PCT 2024},
	pages = {1171 – 1175},
	doi = {10.1109/IC2PCT60090.2024.10486593},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191162945&doi=10.1109%2fIC2PCT60090.2024.10486593&partnerID=40&md5=2f60d75e99f54be121c98bde28b03aaf},
	affiliations = {Srm Institute of Science and Technology, Department of Electronics & Communication Engineering, Chennai, Vadapalani, India; B. Tech (Electronics and Communication Engineering with Specialization in Data Science), Srm Institute of Science and Technology, Chennai, Vadapalani, India},
	abstract = {The proliferation of hate speech has grown to be a significant social worry because of social media's explosive growth. This work aims to explain a new approach that blends Sentiment Analysis and Support Vector Machine (SVM) techniques. The objective is to build a robust and precise system that can identify hate speech instantly and promote a safer online community. Many trials are conducted in order to assess the system's performance using metrics like accuracy, precision, recall, and F1-score. Modern hate speech identification technologies are used in comparison assessments to verify the superiority of the suggested method. It was found that using Sentiment Analysis and SVM together outperforms standard approaches, reaching comparatively large accuracy rates in detecting hate speech. In addition, this work investigates the ethical implications and future reach of algorithms that detect hate speech.  © 2024 IEEE.},
	author_keywords = {Intrusion Detection System; Natural Language Processing (NLP); Natural Language Toolkit; Sentiment Reasoner (VADER); Support Vector Machine (SVM); Term Frequency -Inverse Document Frequency (TF-IDF); Valence Aware Dictionary},
	keywords = {Intrusion detection; Inverse problems; Sentiment analysis; Social networking (online); Speech recognition; Intrusion Detection Systems; Language processing; Natural language processing; Natural language toolkit; Natural languages; Reasoners; Sentiment reasoner (VADER); Support vector machine; Support vectors machine; Term frequency -inverse document frequency; Term frequencyinverse document frequency (TF-IDF); Valence aware dictionary; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th IEEE  International Conference on Computing, Power, and Communication Technologies, IC2PCT 2024; Conference date: 9 February 2024 through 10 February 2024; Conference code: 198737}
}

@CONFERENCE{Krak202416,
	author = {Krak, Iurii and Zalutska, Olha and Molchanova, Maryna and Mazurets, Olexander and Bahrii, Ruslan and Sobko, Olena and Barmak, Olexander},
	title = {Abusive Speech Detection Method for Ukrainian Language Used Recurrent Neural Network},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3688},
	pages = {16 – 28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195144402&partnerID=40&md5=95ccb96b818d1a3a6496ef8c72198135},
	affiliations = {Taras Shevchenko National University of Kyiv, Ukraine; Glushkov Institute of Cybernetics of NAS of Ukraine, Kyiv, Ukraine; Khmelnytskyi National University, 11, Institutes str., Khmelnytskyi, 29016, Ukraine},
	abstract = {The paper is devoted to the creation and approbation of a method for determining the level of social acceptability of textual Ukrainian-language content, which will be able to determine the level of detection of offensive speech for the Ukrainian language using a recurrent neural network based on the entered textual information. The method of detecting offensive speech involves the use of a combined approach based on the use of a dictionary of offensive words and a neural network approach to determine the sentiment tone of the message. The proposed method will allow to assess the level of social acceptability of Ukrainian-language Internet content for automated moderation of Internet content. Further research can be focused on applied use, which can be a useful tool for assessing the level of social acceptability of digital text content published on social networks and for preventing the spread of harmful or offensive information. It can also help improve the quality of communication and increase the level of social interaction in general. © 2024 Copyright for this paper by its authors.},
	author_keywords = {RNN; sentiment analysis; sentiment classification; social acceptance},
	keywords = {Recurrent neural networks; Speech recognition; Detection methods; Internet content; Language content; Levels of detections; RNN; Sentiment analysis; Sentiment classification; Social acceptability; Social acceptance; Speech detection; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 8th International Conference on Computational Linguistics and Intelligent Systems. Volume III: Intelligent Systems Workshop, ISW-CoLInS 2024; Conference date: 12 April 2024 through 13 April 2024; Conference code: 199764}
}

@ARTICLE{Mut Altın202462,
	author = {Mut Altın, Lütfiye Seda and Saggion, Horacio},
	title = {Review of Offensive Language Detection on Social Media: Current Trends and Opportunities},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {960},
	pages = {62 – 76},
	doi = {10.1007/978-3-031-56728-5_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193578313&doi=10.1007%2f978-3-031-56728-5_6&partnerID=40&md5=7588c220d5c4b4069118aa77e07d6d5f},
	affiliations = {Department of Information and Communication Technologies, Pompeu Fabra University, C/Tànger, 122, Barcelona, 08018, Spain},
	abstract = {Offensive language is defined as derogatory or obscene language that has various forms such as hate speech or cyberbullying. Automated detection of offensive language gains traction due to the high and growing scale of social media user input. In this paper, we provide an overview of the field including background and recent research with a focus on natural language processing. We present a synopsis on the ambiguity in definition and categorization of offensive language, application areas of an automated system, shared tasks organized in this field, dataset creation, model evolution in time through machine learning and deep learning algorithms. Finally challenges and gaps in research are discussed. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Natural Language Processing; Offensive Language; Social Media},
	keywords = {Automation; Deep learning; Natural language processing systems; Social networking (online); 'current; Automated detection; Cyber bullying; Language detection; Language processing; Natural language processing; Natural languages; Offensive languages; Social media; User input; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Emerging Trends and Applications in Artificial Intelligence, ICETAI 2023; Conference date: 8 September 2023 through 9 September 2023; Conference code: 311999}
}

@ARTICLE{Tembe2024359,
	author = {Tembe, Lucia Americo and Anand Kumar, M.},
	title = {Hate Speech Detection Using Audio in Portuguese Language},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2046 CCIS},
	pages = {359 – 367},
	doi = {10.1007/978-3-031-58495-4_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192366721&doi=10.1007%2f978-3-031-58495-4_26&partnerID=40&md5=c70f32d623dda53a7590b622e1fd03b1},
	affiliations = {Department of Information Technology, National Institute of Technology Karnataka, Surathkal, India},
	abstract = {This study focuses on hate speech in Portuguese language using audio and introduces a novel methodology that integrates audio-to-text and self-image technologies to effectively tackle this problem. We utilize Machine Learning and Deep Learning models to differentiate between hate speech and normal speech. The research utilized a total of 200 datasets, which were categorized into hate speech and normal speech. These datasets were collected by me personally for this project. Four distinct models are presented in the analysis: LSTM, SVM, CNN, and Random Forest. The findings highlight the superior performance of the CNN model when applied to spectrogram data, achieving an accuracy rate of 90%. Conversely, the Random Forest model outperforms others when dealing with text data, achieving an impressive accuracy rate of 73.1%. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {CNN; Deep Learning; LSTM; Machine Learning; Random Forest; SVM},
	keywords = {Forestry; Learning systems; Long short-term memory; Speech recognition; Accuracy rate; Deep learning; Image technology; LSTM; Machine-learning; Novel methodology; Portuguese languages; Random forests; Speech detection; SVM; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Speech and Language Technologies for Low-Resource Languages, SPELLL 2023; Conference date: 6 December 2023 through 8 December 2023; Conference code: 311549}
}

@CONFERENCE{Rodriguez-Garcia202489,
	author = {Rodriguez-Garcia, Raquel and Centeno, Roberto},
	title = {HAMiSoN-MTL at ClimateActivism 2024: Detection of Hate Speech, Targets, and Stance using Multi-task Learning},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {89 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190276965&partnerID=40&md5=0e352221bc879d560926cbd91d4cdee5},
	affiliations = {NLP & IR Group, UNED, Spain},
	abstract = {The automatic identification of hate speech constitutes an important task, playing a relevant role towards inclusivity. In these terms, the shared task on Climate Activism Stance and Hate Event Detection at CASE 2024 proposes the analysis of Twitter messages related to climate change activism for three subtasks. Sub-tasks A and C aim at detecting hate speech and establishing the stance of the tweet, respectively, while subtask B seeks to determine the target of the hate speech. In this paper, we describe our approach to the given subtasks. Our systems leverage transformer-based multi-task learning. Additionally, since the dataset contains a low number of tweets, we have studied the effect of adding external data to increase the learning of the model. With our approach we achieve the fourth position on subtask C on the final leaderboard, with minimal difference from the first position, showcasing the strength of multi-task learning. © 2024 Association for Computational Linguistics.},
	keywords = {Automation; Computational linguistics; Learning systems; Speech recognition; Automatic identification; Events detection; Multitask learning; Speech targets; Subtask; Climate change},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Nasir2024,
	author = {Nasir, Sarah and Seerat, Ayesha and Wasim, Muhammad},
	title = {Hate Speech Detection in Roman Urdu using Machine Learning Techniques},
	year = {2024},
	journal = {2024 5th International Conference on Advancements in Computational Sciences, ICACS 2024},
	doi = {10.1109/ICACS60934.2024.10473250},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190269084&doi=10.1109%2fICACS60934.2024.10473250&partnerID=40&md5=1fec8ca7f654e6971a82561d7d604c75},
	affiliations = {University of Management and Technology, Dept. of Computer Science, Sialkot Campus, Lahore, Pakistan},
	abstract = {In recent years, the spread of hate speech on social media has been a major source of discomfort. Hate speech may be extremely harmful, resulting in violence, discrimination, and even genocide. The problem is particularly acute in the case of the Roman Urdu language, where the use of hate speech is widespread. To address this issue, there's a growing demand for effective methods to identify hate speech on social media. While many researchers have focused on European languages, few have worked on South Asian languages, such as Roman Urdu, which are widely used in the subcontinent. In this study, we contribute by developing a methodology to detect hate speech in Roman Urdu at two levels. First, we classify the social media content into neutral and hostile categories. Secondly, we classify the hostile content as offensive and hate speech. We use a benchmark corpus (HS-RU-20) to evaluate the proposed methodology and the two-level classification. Furthermore, we analyze the word and character level features along with six supervised learning models (logistic regression, multinomial bias, KNN, random forest, SVM, and convolutional neural network (CNN)). The results show that logistic regression performed better in terms of accuracy, at 81% on neutral-hostile, and outperformed offensive-hate speech classification with an accuracy of 87%. © 2024 IEEE.},
	author_keywords = {cnn; cyberbullying; hate speech detection; machine learning; roman urdu},
	keywords = {Convolutional neural networks; Learning systems; Random forests; Social networking (online); Speech recognition; Support vector regression; Cnn; Cyber bullying; Growing demand; Hate speech detection; Logistics regressions; Machine learning techniques; Machine-learning; Roman urdu; Social media; Speech detection; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th International Conference on Advancements in Computational Sciences, ICACS 2024; Conference date: 19 February 2024 through 20 February 2024; Conference code: 198356}
}

@ARTICLE{Paraschiv202485,
	author = {Paraschiv, Andrei and Cojocaru, Andreea and Dascalu, Mihai},
	title = {Automated Offensive Comment Detection for the Romanian Language},
	year = {2024},
	journal = {Learning and Analytics in Intelligent Systems},
	volume = {36},
	pages = {85 – 110},
	doi = {10.1007/978-3-031-53957-2_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191305991&doi=10.1007%2f978-3-031-53957-2_5&partnerID=40&md5=54437d55db5f0694d01ab9de63352796},
	affiliations = {National University of Science and Technology POLITEHNICA Bucharest, 313 Splaiul Independetei, Bucharest, Romania},
	abstract = {Offensive language can lead to uncomfortable situations, psychological harm, and, in particular cases, even violence. Social networks and websites struggle to reduce the prevalence of these messages by using an automated detector. One goal of Human-computer interaction (HCI) sciences is to provide respectful, safe, and user-friendly systems. This extends to any form of computer-mediated social interaction. This chapter contributes to this objective by proposing a Romanian language dataset for offensive message detection. We manually annotated 4,052 comments on a Romanian local news website into one of the following classes: non-offensive, targeted insults, racist, homophobic, and sexist. In addition, we establish a baseline of five automated classifiers, out of which the model based on RoBERT and two layers of CNN achieves the highest performance with a weighted F1-score of 74.74%. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hate-speech; Natural language processing; Offensive language; Romanian language; Romanian offensive dataset},
	keywords = {Automation; Human computer interaction; Natural language processing systems; Automated detectors; Hate-speech; Language processing; Natural language processing; Natural languages; Offensive languages; Romanian language; Romanian offensive dataset; Romanians; User friendly; Websites},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Putra2024239,
	author = {Putra, Cendra Devayana and Wang, Hei-Chia},
	title = {Advanced BERT-CNN for Hate Speech Detection},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {234},
	pages = {239 – 246},
	doi = {10.1016/j.procs.2024.02.170},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193202285&doi=10.1016%2fj.procs.2024.02.170&partnerID=40&md5=72806a9230535ae08847bc73e44cd222},
	affiliations = {Institute of Information Management, National Cheng Kung University, Tainan City, Taiwan; Center for Innovative FinTech Business Models, National Cheng Kung University, Tainan City, Taiwan},
	abstract = {Hate Speech already been phenomenal expansion over the past decade. The paper proposed a new model that combines advanced CNN and Bidirectional Encoder Representations from Transformers (BERT) context embedding to predict hate speech in social media. This research trained contextual embedding on the datasets and used the learned information to identify objectionable language and hate speech in text. The paper evaluated supervised machine learning classifiers for bigoted and offensive content on Twitter using two datasets and found that advanced CNN context embeddings produced superior results. This research generated optimistic outcomes, which achieves 73% F1-score for Davidson dataset and 56% F1-score for TRAC-1 dataset. © 2023 The Authors. Published by Elsevier B.V.},
	author_keywords = {BERT; Context Embedding; Convolution Layer; Hate Speech Detection},
	keywords = {Classification (of information); Social networking (online); Speech recognition; Supervised learning; Bidirectional encoder representation from transformer; Context embedding; Convolution layer; Embeddings; F1 scores; Hate speech detection; Learning classifiers; Social media; Speech detection; Supervised machine learning; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th Information Systems International Conference, ISICO 2023; Conference date: 26 July 2023 through 28 July 2023; Conference code: 199175}
}

@ARTICLE{Farjana2024861,
	author = {Farjana, Mayeesha and Chowdhury, Barisha and Rahman, Farhana and Makin, Zuairia Raisa Bintay and Rahman, Sumaiya and Srizon, Azmain Yakin},
	title = {Gender-Abusive Language Detection in Bengali Using Machine Learning Algorithms},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {867 LNNS},
	pages = {861 – 875},
	doi = {10.1007/978-981-99-8937-9_57},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190360580&doi=10.1007%2f978-981-99-8937-9_57&partnerID=40&md5=cc947ea991502837af1c2480b32dc172},
	affiliations = {Rajshahi University of Engineering and Technology, Rajshahi, 6204, Bangladesh},
	abstract = {The issue of gender-based abuse is a prevalent concern in today’s society. As technology and social media platforms have become increasingly ubiquitous, these platforms have also become a breeding ground for abusive language and harassment, particularly toward women. In this study, we utilized machine learning techniques—logistic regression, decision tree, random forest, K-nearest neighbors, support vector machine, and Naïve Bayes—to classify abusive text based on gender. The considered dataset in this research comprised comments and posts from various social media platforms, which were preprocessed before being subjected to classification. Experimental analysis revealed that support vector machine demonstrated superior performance in terms of precision, recall, accuracy, sensitivity, and specificity indicating its potential effectiveness in identifying and filtering out gender-based abuse from social media platforms. The findings of this study suggest that machine learning techniques can play a critical role in combating gender-based abuse and harassment online. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Bengali gender-abusive dataset; Classification; Machine learning; Naïve Bayes; Support vector machine},
	keywords = {Classification (of information); Classifiers; Decision trees; Learning algorithms; Learning systems; Logistic regression; Nearest neighbor search; Social networking (online); Bengali gender-abusive dataset; Bengalis; Breeding grounds; Language detection; Machine learning algorithms; Machine learning techniques; Machine-learning; Naive bayes; Social media platforms; Support vectors machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Big Data, IoT and Machine Learning, BIM 2023; Conference date: 6 September 2023 through 8 September 2023; Conference code: 310379}
}

@CONFERENCE{Muthuthanthri2024155,
	author = {Muthuthanthri, Meuru and Smith, Roy Ian},
	title = {Hate Speech Detection for Transliterated English and Sinhala Code-Mixed Data},
	year = {2024},
	journal = {ICARC 2024 - 4th International Conference on Advanced Research in Computing: Smart and Innovative Trends in Next Generation Computing Technologies},
	pages = {155 – 160},
	doi = {10.1109/ICARC61713.2024.10499768},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192184280&doi=10.1109%2fICARC61713.2024.10499768&partnerID=40&md5=80be3c47ad33fdb2f37872d5403b256c},
	affiliations = {Icbt Campus, Cardiff Metropolitan University, Cardiff, United Kingdom; University of Moratuwa, Computer Science Engineering, Moratuwa, Sri Lanka},
	abstract = {The rise of online hate speech has highlighted the need for sophisticated detection methods, particularly in settings with linguistic diversity. This study focuses on 'Transliterated English and Sinhala code-mixed data' from Facebook, carefully annotated to maintain dataset accuracy. The data underwent preprocessing and feature extraction, with techniques like Term Frequency (TF) - Inverse Document Frequency (IDF) and fastText Word Embeddings applied to grasp the complexities of the mixed-code language. Various models were evaluated, ranging from conventional ones like Logistic Regression and Support Vector Machine (SVM) to advanced architectures like Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) with Long Short-Term Memory (LSTM). The study also incorporated gradient-boosting frameworks and transformer-based models like BERT and GPT2. The effectiveness of these models was rigorously assessed using metrics like accuracy, precision, recall, F1-score, confusion matrices, and Receiver Operating Characteristic area under curve value (ROC AUC) values. BERT stood out, achieving 82% accuracy and a 90% ROC AUC value, proving highly effective for this detection task. It paves the way for future research in diverse linguistic settings and online environments.  © 2024 IEEE.},
	author_keywords = {code-mixed; hate speech detection; NLP; Singlish; transliteration},
	keywords = {Convolutional neural networks; Linguistics; Long short-term memory; Natural language processing systems; Speech recognition; Support vector machines; Text processing; Code-mixed; Detection methods; Facebook; Hate speech detection; Linguistic diversity; Mixed data; Receiver operating characteristics; Singlish; Speech detection; Transliteration; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Advanced Research in Computing, ICARC 2024; Conference date: 21 February 2024 through 24 February 2024; Conference code: 199063}
}

@CONFERENCE{Wang202473,
	author = {Wang, Yeshan and Markov, Ilia},
	title = {CLTL@Multimodal Hate Speech Event Detection 2024: The Winning Approach to Detecting Multimodal Hate Speech and Its Targets},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {73 – 78},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190299361&partnerID=40&md5=e35814218b702b4fa1ec4032c4c27d50},
	affiliations = {CLTL, Vrije Universiteit Amsterdam, Amsterdam, Netherlands},
	abstract = {In the context of the proliferation of multimodal hate speech related to the Russia-Ukraine conflict, we introduce a unified multimodal fusion system for detecting hate speech and its targets in text-embedded images. Our approach leverages the Twitter-based RoBERTa and Swin Transformer V2 models to encode textual and visual modalities, and employs the Multilayer Perceptron (MLP) fusion mechanism for classification. Our system achieved macro F1 scores of 87.27% for hate speech detection and 80.05% for hate speech target detection in the Multimodal Hate Speech Event Detection Challenge 2024, securing the 1st rank in both subtasks. We open-source the trained models at https://huggingface.co/Yestin-Wang. © 2024 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Embedded images; Events detection; Fusion mechanism; Fusion systems; Multi-modal; Multi-modal fusion; Multilayers perceptrons; Speech events; Ukraine; Visual modalities; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@ARTICLE{Revanth Reddy2024236,
	author = {Revanth Reddy, Pingala and Munawwar, K.V. and Nandhini, K.},
	title = {Telugu-English Abusive Comment Detection Using XLMRoBERTa and mBERT},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2046 CCIS},
	pages = {236 – 245},
	doi = {10.1007/978-3-031-58495-4_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192360443&doi=10.1007%2f978-3-031-58495-4_17&partnerID=40&md5=551f5b4312590b9a6c0863235803317b},
	affiliations = {Central University of Tamil Nadu, Tamil Nadu, Thiruvarur, 610005, India},
	abstract = {The proliferation of social media platforms has enabled users to express their thoughts and opinions freely, but it has also given rise to the rampant spread of abusive and offensive content. The detection and moderation of such abusive comments have become crucial for maintaining a healthy online environment. Detecting abusive comments in multilingual settings is a challenging task due to the presence of diverse languages, writing scripts, and code-mixing. This paper presents a comprehensive approach for abusive comment detection in the Telugu-English language pair, fine-tuning the state-of-the-art models for native Telugu script, Telugu sentences written in English script, and code-mixing or a combination of Telugu and English script. We leverage the power of two state-of-the-art pre-trained language models, XLMRoBERTa and mBERT, to effectively tackle this task. Our results demonstrate the efficacy of XLMRoBERTa and mBERT models in addressing these challenges in the detection of abusive language in the multilingual context in terms of accuracy, precision, recall, and F1 score. The fine-tuned mBERT gave an Accuracy of 66.21% and fine-tuned XLMRoBERTa gave an Accuracy of 70.51%. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Abusive Comment Detection; Code-Mixed Data; mBERT; Telugu-English Data; XLMRoBERTa},
	keywords = {Codes (symbols); Abusive comment detection; Code-mixed data; Code-mixing; MBERT; Mixed data; Online environments; Social media platforms; State of the art; Telugu-english data; XLMRoBERTa; Mixing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Speech and Language Technologies for Low-Resource Languages, SPELLL 2023; Conference date: 6 December 2023 through 8 December 2023; Conference code: 311549}
}

@CONFERENCE{Uludoğan2024229,
	author = {Uludoğan, Gökçe and Dehghan, Somaiyeh and Arın, Inanç and Erol, Elif and Yanikoglu, Berrin and Özgür, Arzucan},
	title = {Overview of the Hate Speech Detection in Turkish and Arabic Tweets (HSD-2Lang) Shared Task at CASE 2024},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {229 – 233},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190283733&partnerID=40&md5=9490747e896eaade67448d1cbed7d078},
	affiliations = {Department of Computer Engineering, Bogazici University, 34342, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, 34956, Turkey; Center of Excellence in Data Analytics (VERIM), Sabanci University, Istanbul, 34956, Turkey; Hrant Dink Foundation, Istanbul, 34373, Turkey},
	abstract = {This paper offers an overview of the Hate Speech Detection in Turkish and Arabic Tweets (HSD-2Lang) Shared Task at CASE workshop that was held jointly with EACL 2024. The task was divided into two subtasks: Subtask A, targeting hate speech detection in various Turkish contexts, and Subtask B, addressing hate speech detection in Arabic with limited data. The shared task attracted significant attention with 33 teams that registered and 10 teams that participated in at least one task. In this paper, we provide the details of the tasks and the approaches adopted by the participant along with an analysis of the results obtained from this shared task. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Limited data; Speech detection; Subtask; Turkishs; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@CONFERENCE{Bourgeade20248438,
	author = {Bourgeade, Tom and Li, Zongmin and Benamara, Farah and Moriceau, Véronique and Su, Jian and Sun, Aixin},
	title = {Humans Need Context, What About Machines? Investigating Conversational Context in Abusive Language Detection},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {8438 – 8452},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195904580&partnerID=40&md5=737be9bcc03c34223b032db7791997da},
	affiliations = {University of Turin, Italy; IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; CNRS@CREATE Ltd., Singapore; IPAL, CNRS-NUS-A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore},
	abstract = {A crucial aspect in abusive language on social media platforms (toxicity, hate speech, harmful stereotypes, etc.) is its inherent contextual nature. In this paper, we focus on the role of conversational context in abusive language detection, one of the most “direct” forms of context in this domain, as given by the conversation threads (e.g., directly preceding message, original post). The incorporation of surrounding messages has proven vital for the accurate human annotation of harmful content. However, many prior works have either ignored this aspect, collecting and processing messages in isolation, or have obtained inconsistent results when attempting to embed such contextual information into traditional classification methods. The reasons behind these findings have not yet been properly addressed. To this end, we propose an analysis of the impact of conversational context in abusive language detection, through: (1) an analysis of prior works and the limitations of the most common concatenation-based approach, which we attempt to address with two alternative architectures; (2) an evaluation of these methods on existing datasets in English, and a new dataset of French tweets annotated for hate speech and stereotypes; and (3) a qualitative analysis showcasing the necessity for context-awareness in ALD, but also its difficulties. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Abusive language detection; Context-aware classification; Conversational context},
	keywords = {Abusive language detection; Context-Aware; Context-aware classification; Contextual information; Conversational context; Direct forms; Human annotations; Human needs; Language detection; Social media platforms; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@CONFERENCE{Pannerselvam202435,
	author = {Pannerselvam, Kathiravan and Rajiakodi, Saranya and Thavareesan, Sajeetha and Thangasamy, Sathiyaraj and Ponnusamy, Kishore Kumar},
	title = {SetFit: A Robust Approach for Offensive Content Detection in Tamil-English Code-Mixed Conversations Using Sentence Transfer Fine-tuning},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {35 – 42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189858118&partnerID=40&md5=16dd2f53764f64e8bcab343a373dc86c},
	affiliations = {Department of Computer Science, Central University of Tamil Nadu, India; Eastern University, Sri Lanka; Sri Krishna Adithya College of Arts and Science, India; Digital University of Kerala, India},
	abstract = {Code-mixed languages are increasingly prevalent on social media and online platforms, presenting significant challenges in offensive content detection for natural language processing (NLP) systems. Our study explores how effectively the Sentence Transfer Fine-tuning (SetFit) method, combined with logistic regression, detects offensive content in a Tamil-English code-mixed dataset. We compare our model’s performance with five other NLP models: Multilingual BERT (mBERT), LSTM, BERT, IndicBERT, and Language-agnostic BERT Sentence Embeddings (LaBSE). Our model, SetFit, outperforms these models in accuracy, achieving an impressive 89.72%, significantly higher than other models. These results suggest the sentence transformer model’s substantial potential for detecting offensive content in code-mixed languages. Our study provides valuable insights into the sentence transformer model’s ability to identify various types of offensive material in Tamil-English online conversations, paving the way for more advanced NLP systems tailored to code-mixed languages. © 2024 Association for Computational Linguistics.},
	author_keywords = {Code-mixed languages; Hate speech; Natural language processing; Offensive detection; SetFit; Tamil-English dataset},
	keywords = {Computational linguistics; Logistic regression; Long short-term memory; Online systems; Social networking (online); Code-mixed language; Content detection; Fine tuning; Hate speech; Language processing; Natural language processing; Natural languages; Offensive detection; Sentence transfer fine-tuning; Tamil-english dataset; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Song20244760,
	author = {Song, Hyeonho and Hong, Jisu and Jung, Chani and Chin, Hyojin and Shin, Mingi and Choi, Junghoi and Choi, Yubin and Cha, Meeyoung},
	title = {Detecting Offensive Language in an Open Chatbot Platform},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {4760 – 4771},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195898602&partnerID=40&md5=0bcb9c2237a82627b654d9d28b83bf9a},
	affiliations = {KAIST School of Computing, Daejeon, South Korea; Seoul National University, Seoul, South Korea; Institute for Basic Science, Daejeon, South Korea; SimSimi Inc., Seoul, South Korea},
	abstract = {While detecting offensive language in online spaces remains an important societal issue, there is still a significant gap in existing research and practial datasets specific to chatbots. Furthermore, many of the current efforts by service providers to automatically filter offensive language are vulnerable to users' deliberate text manipulation tactics, such as misspelling words. In this study, we analyze offensive language patterns in real logs of 6,254,261 chat utterance pairs from the commercial chat service Simsimi, which cover a variety of conversation topics. Based on the observed patterns, we introduce a novel offensive language detection method-a contrastive learning model that embeds chat content with a random masking strategy. We show that this model outperforms existing models in detecting offensive language in open-domain chat conversations while also demonstrating robustness against users' deliberate text manipulation tactics when using offensive language. We release our curated chatbot dataset to foster research on offensive language detection in open-domain conversations and share lessons learned from mitigating offensive language on a live platform. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Chatbot; Contrastive learning; Offensive language detection; Open-domain conversations},
	keywords = {'current; Chatbots; Contrastive learning; Language detection; Offensive language detection; Offensive languages; Open-domain conversation; Service provider; Societal issues; Text manipulation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@ARTICLE{Madhavi20241164,
	author = {Madhavi, M. and Agal, Sanjay and Odedra, Niyati Dhirubhai and Chowdhary, Harish and Ruprah, Taranpreet Singh and Vuyyuru, Veera Ankalu and Baker El-Ebiary, Yousef A.},
	title = {Elevating Offensive Language Detection: CNN-GRU and BERT for Enhanced Hate Speech Identification},
	year = {2024},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {15},
	number = {5},
	pages = {1164 – 1172},
	doi = {10.14569/IJACSA.2024.01505118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197807181&doi=10.14569%2fIJACSA.2024.01505118&partnerID=40&md5=6e41e6811c90edfd6e63e7b5b22c991a},
	affiliations = {Department of CSE, Velagapudi Ramakrishna Siddhartha Engineering College, Andhra Pradesh, Vijayawada, India; Department of Computer Science & Engineering, Parul Institute of Engineering and Technology (PIET), P.O.Limda, Ta.Waghodia, Dist, Gujarat, Vadodara, 391760, India; Department of Computer Engineering, Dr V R Godhania College of Engineering & Technology, Gujarat, India; Rashtriya Raksha University, Gujarat, Gandhinagar, India; Rajarambapu Institute of Technology, Sakharale, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Andhra Pradesh, Vaddeswaram, India; Faculty of Informatics and Computing, UniSZA University, Malaysia},
	abstract = {Upholding a secure and accepting digital environment is severely hindered by hate speech and inappropriate information on the internet. A novel approach that combines Convolutional Neural Network with GRU and BERT from Transformers proposed for enhancing the identification of offensive content, particularly hate speech. The method utilizes the strengths of both CNN-GRU and BERT models to capture complex linguistic patterns and contextual information present in hate speech. The proposed model first utilizes CNN-GRU to extract local and sequential features from textual data, allowing for effective representation learning of offensive language. Subsequently, BERT, advanced transformer-based model, is employed to capture contextualized representations of the text, thereby enhancing the understanding of detailed linguistic nuances and cultural contexts associated with hate speech. Fine tuning BERT model using hugging face transformer. To execute tests using datasets for hate speech identification that are made accessible to the public and show how well the method works to identify inappropriate content. By assisting with the continuing efforts to prevent the dissemination of hate speech and undesirable language online, the proposed framework promotes a more diverse and secure digital environment. The proposed method is implemented using python. The method achieves 98% competitive performance compared to existing approaches LSTM and RNN, CNN, LSTM and GBAT, showcasing its potential for real-world applications in combating online hate speech. Furthermore, it provides insights into the interpretability of the model’s predictions, highlighting key linguistic and contextual factors influencing offensive language detection. The study contributes to advancing hate speech detection by integrating CNN-GRU and BERT models, giving a robust solution for enhancing offensive content identification in online platforms. © (2024), (Science and Information Organization). All rights reserved.},
	author_keywords = {Bidirectional encoder representations from transformers; convolutional neural network; Gated Recurrent Unit; hate speech; hugging face transformer},
	keywords = {Convolutional neural networks; Linguistics; Long short-term memory; Speech recognition; Bidirectional encoder representation from transformer; Convolutional neural network; Digital environment; Gated recurrent unit; Hate speech; Hugging face transformer; Language detection; Linguistic patterns; Offensive languages; Speech identification; Convolution},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Tyagi2024449,
	author = {Tyagi, Vishu and Jain, Sourabh},
	title = {Methods and Datasets for Detecting Hate Speech in Textual Content},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {958 LNNS},
	pages = {449 – 455},
	doi = {10.1007/978-981-97-1961-7_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195599715&doi=10.1007%2f978-981-97-1961-7_29&partnerID=40&md5=db77fb9d6d21f0431d3ef8affdc9cbc6},
	affiliations = {Indian Institute of Information Technology, Haryana, Sonepat, India; Graphic Era Deemed to Be University, Uttarakhand, Dehradun, India},
	abstract = {Online discussions with harmful content can lead to group conflicts or abuse of online communities. Hate speech is complex, offensive, or harmful content targeting people or crowds. This paper detects textual hate speech, emphasizes the key datasets, text features, and machine learning models used, and systematically examines the deep learning technologies. This paper proposes a model for hate speech detection based on deep learning architecture. The proposed LSTM-CNN model to enhance the performance on benchmark datasets. This paper provides insights into the generic pipeline of automatic hate speech detection, including dataset collection, feature engineering, and model training. We compared the performance of our model with classical methods. It is prominent from the outcome that our proposed model performed with an accuracy of 93.1%. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	keywords = {Feature extraction; Learning systems; Long short-term memory; Social networking (online); Speech recognition; Feature learning; Group conflicts; Learning technology; Machine learning models; On-line communities; Online discussions; Performance; Speech detection; Text feature; Textual content; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Advanced Computing and Intelligent Technologies, ICACIT 2023; Conference date: 8 December 2023 through 9 December 2023; Conference code: 312909}
}

@ARTICLE{Alhazmi2024,
	author = {Alhazmi, Ali and Mahmud, Rohana and Idris, Norisma and Abo, Mohamed Elhag Mohamed and Eke, Christopher},
	title = {A systematic literature review of hate speech identification on Arabic Twitter data: research challenges and future directions},
	year = {2024},
	journal = {PeerJ Computer Science},
	volume = {10},
	doi = {10.7717/peerj-cs.1966},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190401290&doi=10.7717%2fpeerj-cs.1966&partnerID=40&md5=4557064f7dc078479104b8c85604953b},
	affiliations = {Faculty of Computer Science and Information Technology, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Information Technology and Security, Jazan University, Jazan, Saudi Arabia; Department of Computer Science, The Future University, Khartoum, Sudan; Department of Computer Science, Faculty of Computing, Federal University of Lafia, Nasarawa State, Lafia, Nigeria},
	abstract = {The automatic speech identification in Arabic tweets has generated substantial attention among academics in the fields of text mining and natural language processing (NLP). The quantity of studies done on this subject has experienced significant growth. This study aims to provide an overview of this field by conducting a systematic review of literature that focuses on automatic hate speech identification, particularly in the Arabic language. The goal is to examine the research trends in Arabic hate speech identification and offer guidance to researchers by highlighting the most significant studies published between 2018 and 2023. This systematic study addresses five specific research questions concerning the types of the Arabic language used, hate speech categories, classification techniques, feature engineering techniques, performance metrics, validation methods, existing challenges faced by researchers, and potential future research directions. Through a comprehensive search across nine academic databases, 24 studies that met the predefined inclusion criteria and quality assessment were identified. The review findings revealed the existence of many Arabic linguistic varieties used in hate speech on Twitter, with modern standard Arabic (MSA) being the most prominent. In identification techniques, machine learning categories are the most used technique for Arabic hate speech identification. The result also shows different feature engineering techniques used and indicates that N-gram and CBOW are the most used techniques. F1-score, precision, recall, and accuracy were also identified as the most used performance metric. The review also shows that the most used validation method is the train/test split method. Therefore, the findings of this study can serve as valuable guidance for researchers in enhancing the efficacy of their models in future investigations. Besides, algorithm development, policy rule regulation, community management, and legal and ethical consideration are other real-world applications that can be reaped from this research. Copyright 2024 Alhazmi et al.},
	author_keywords = {Arabic tweets; Automatic identification; Classification techniques; Hate speech; Natural language processing; SLR},
	keywords = {Automation; Classification (of information); Laws and legislation; Linguistics; Philosophical aspects; Social networking (online); Speech recognition; Arabic languages; Arabic tweet; Automatic identification; Classification technique; Hate speech; Language processing; Natural language processing; Natural languages; SLR; Speech identification; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Lu202415566,
	author = {Lu, Junyu and Xu, Bo and Zhang, Xiaokun and Liu, Kaiyuan and Zhang, Dongyu and Yang, Liang and Lin, Hongfei},
	title = {Take its Essence, Discard its Dross! Debiasing for Toxic Language Detection via Counterfactual Causal Effect},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {15566 – 15578},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195901237&partnerID=40&md5=fec7122f07ff7b63672ad139080ba7ee},
	affiliations = {School of Computer Science and Technology, Dalian University of Technology, China; School of Foreign Chinese, Dalian University of Technology, China},
	abstract = {Current methods of toxic language detection (TLD) typically rely on specific tokens to conduct decisions, which makes them suffer from lexical bias, leading to inferior performance and generalization. Lexical bias has both “useful” and “misleading” impacts on understanding toxicity. Unfortunately, instead of distinguishing between these impacts, current debiasing methods typically eliminate them indiscriminately, resulting in a degradation in the detection accuracy of the model. To this end, we propose a Counterfactual Causal Debiasing Framework (CCDF) to mitigate lexical bias in TLD. It preserves the “useful impact” of lexical bias and eliminates the “misleading impact”. Specifically, we first represent the total effect of the original sentence and biased tokens on decisions from a causal view. We then conduct counterfactual inference to exclude the direct causal effect of lexical bias from the total effect. Empirical evaluations demonstrate that the debiased TLD model incorporating CCDF achieves state-of-the-art performance in both accuracy and fairness compared to competitive baselines applied on several vanilla models. The generalization capability of our model outperforms current debiased models for out-of-distribution data. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Causal Inference; Lexical Bias; Toxic Language Detection},
	keywords = {'current; Causal inferences; Counterfactuals; De-biasing; Generalisation; Language detection; Lexical bias; Performance; Total effect; Toxic language detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Joint 30th International Conference on Computational Linguistics and 14th International Conference on Language Resources and Evaluation, LREC-COLING 2024; Conference date: 20 May 2024 through 25 May 2024; Conference code: 199620}
}

@BOOK{Saroja2024251,
	author = {Saroja, S. and Haseena, S.},
	title = {A metaheuristic harmony search optimization–based approach for hateful and offensive speech detection in social media},
	year = {2024},
	journal = {Computational Intelligence Methods for Sentiment Analysis in Natural Language Processing Applications},
	pages = {251 – 264},
	doi = {10.1016/B978-0-443-22009-8.00009-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191125587&doi=10.1016%2fB978-0-443-22009-8.00009-4&partnerID=40&md5=0eb4ad77e28aa69d80ab75716d125891},
	affiliations = {Department of Computer Applications, National Institute of Technology, Tamil Nadu, Trichy, India; Department of Information Technology, Mepco Schlenk Engineering College, Tamil Nadu, Sivakasi, India},
	abstract = {The exponential increase in Internet users brought up undesirable cyber concerns, such as cyberbullying, hate speech, and many others. Direct communication has increased between individuals with different cultural and psychological backgrounds as a result of the rapid rise of social networks and microblogging websites, leading to an increase in “cyber” conflicts between these individuals. Hate speech seems to be an offensive type of interaction process that propagates a hate ideology by utilizing misconceptions. The hate speech primarily targets several categories that are protected, such as gender, religion, color, and disability. Sometimes unintentional crimes, murders, and terrorism will occur as a result of hate speech as someone or a group of individuals become disheartened. In order to prevent the spread of hate speech, it is crucial to keep an eye on user posts. The number of tweets sent and received on Twitter, however, is over 600 every second and over 500 million each day. With so much incoming traffic, manually filtering out any information is almost impossible. In this chapter, a metaheuristic-based automatic hate speech detection system was developed for better outcomes in this novel and significant topic. The metaheuristic that has only lately been invented is the harmony search algorithm. It imitates how a musician would act to create a perfect harmony. Due to its simplicity of implementation compared with other metaheuristics, it has been utilized to tackle a wide range of optimization issues in real-world settings. During a search, it might strike a balance between exploration and exploitation.We propose a classification technique based on attention-based LSTM that distinguishes between offensive languages and hate speech.The proposed model outperformed the current models and achieved the best precision, recall, and F1-score values. © 2024 Elsevier Inc. All rights reserved.},
	author_keywords = {deep learning; Hate speech detection; metaheuristics; optimization; twitter},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Raturi2024446,
	author = {Raturi, Ayush and Joshi, Kireet and Anupriya and Jain, Paras and Gupta, Vishan Kumar and Meena, Jaishree},
	title = {Hate Speech Detection System using Machine Learning Algorithms},
	year = {2024},
	journal = {Proceedings - 2nd International Conference on Advancement in Computation and Computer Technologies, InCACCT 2024},
	pages = {446 – 451},
	doi = {10.1109/InCACCT61598.2024.10551015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196663696&doi=10.1109%2fInCACCT61598.2024.10551015&partnerID=40&md5=eb8418fe0644ca3848946758378b786a},
	affiliations = {Graphic Era Deemed to be University, Department of CSE, Dehradun, India; Graphic Era Hill University, School of Computing, Dehradun, India; VIT Bhopal University, School of Computing Science and Engineering, Madhya Pradesh, Sehore, India; Amity University Punjab, Amity School of Engineering and Technology, Mohali, India; Amity School Punjab, Amity School of Biological Sciences, Mohali, India},
	abstract = {Hateful comments and speeches on social media platforms have emerged as a significant and disturbing issue in recent times. With the rapid modernization of the internet, the proliferation of such content has also increased swiftly. Addressing this problem requires substantial efforts within the sector, particularly in the development of hate speech detection techniques. One effective approach involves the utilization of efficient machine learning models. This paper proposes a model dedicated to the detection of hate speech. The chosen dataset undergoes thorough preprocessing and cleaning, enhancing the quality of the text. Further exploration of the cleaned text aims to provide a more comprehensive understanding. Key features are extracted from the dataset to facilitate model training, incorporating lemmatization, stemming, and the removal of stop words to eliminate unnecessary data. The model is built using CountVectorizer, and various machine learning algorithms are employed to assess performance and gain insights for model improvement. By implementing effective preprocessing techniques and optimizing hyperparameters, our model has demonstrated superior performance, achieving an accuracy of 96%. © 2024 IEEE.},
	author_keywords = {CountVectorizer; evaluation metric; Natural language processing; Sentiment Analysis; Word2vec},
	keywords = {Learning algorithms; Learning systems; Machine learning; Speech recognition; Countvectorizer; Evaluation metrics; Language processing; Machine learning algorithms; Natural language processing; Natural languages; Performance; Sentiment analysis; Speech detection; Word2vec; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Advancement in Computation and Computer Technologies, InCACCT 2024; Conference date: 2 May 2024 through 3 May 2024; Conference code: 200156}
}

@ARTICLE{Jobair2024845,
	author = {Jobair, Md. and Das, Dhrubajyoti and Islam, Nimmy Binte and Dhar, Munna},
	title = {Bengali Hate Speech Detection with BERT and Deep Learning Models},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {867 LNNS},
	pages = {845 – 859},
	doi = {10.1007/978-981-99-8937-9_56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190362651&doi=10.1007%2f978-981-99-8937-9_56&partnerID=40&md5=9106c653ce113dc949b036594c465d32},
	affiliations = {Dept of Computer Science and Engineering, Premier University, Chattogram, 4000, Bangladesh},
	abstract = {An increasing amount of harmful effects have been linked to prolonged exposure to abusive language on numerous social media sites. If we want to keep the internet safe and peaceful, we must do something about the epidemic of harsh language. Although studies on the topic of identifying hostile speech have been conducted, the vast majority have only covered the English language. Recent instances in Bangladesh, however, have led to the emergence of inflammatory speech in a variety of languages. Therefore, it is crucial to address this type of harmful material. Unfortunately, Bangla hate speech detection on social media sites such as Facebook and YouTube has been hampered by a lack of available public Bangla datasets. Although some datasets are available online, they are sparse, poorly sequenced, and lack necessary data types. As a means of filling this void, we have compiled a new dataset consisting of 8600 user comments from Facebook and YouTube, which we have divided into the following five categories: sports, religion, politics, entertainment, and others. Following that, we used five distinct models to perform a massive study of abusive language in Bengali. After testing a number of different models, we found that the BERT model had the highest accuracy of 80%. The availability of this dataset greatly aids our contribution to the study of identifying hate speech in Bengali. The same models have also been run on an existing dataset of 30,000 records, where we achieved an accuracy of 97%. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Bengali hate speech detection; Custom CNN; Deep learning methods; RNN; Transformer},
	keywords = {Deep learning; Learning systems; Social networking (online); Bengali hate speech detection; Bengalis; Custom CNN; Deep learning method; Facebook; Learning methods; RNN; Social media; Speech detection; Transformer; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Big Data, IoT and Machine Learning, BIM 2023; Conference date: 6 September 2023 through 8 September 2023; Conference code: 310379}
}

@ARTICLE{Bajaj2024284,
	author = {Bajaj, Peehu and Shimpi, Avanish and Kumar, Satish and Jadhav, Priya and Bongale, Arunkumar},
	title = {Developing an Efficient Toxic Comment Detector Using Machine Learning Techniques},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2053 CCIS},
	pages = {284 – 297},
	doi = {10.1007/978-3-031-56700-1_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190299776&doi=10.1007%2f978-3-031-56700-1_23&partnerID=40&md5=0bf908b0f0a0bab5738dfdcdf31c8e1c},
	affiliations = {Symbiosis International University, Pune, India; Symbiosis Centre for Applied Artificial Intelligence, Symbiosis International (Deemed University), Maharashtra State, Lavale, Pune, India},
	abstract = {Social media has changed the way people communicate, but it has also become a breeding ground for dangerous content. Natural Language Processing (NLP) is used in this study to classify unstructured data into dangerous and benign categories, providing insights about internet toxicity. The NLP approach used in the study gives light on the challenges and opportunities of toxicity identification. The researchers uncovered patterns and trends indicative of dangerous content by analysing massive amounts of text data, allowing them to construct powerful classification systems. The paper discusses the advantages and disadvantages of toxicity detection. Automated systems can swiftly scan enormous amounts of content, but they may misclassify some material, thereby leading to censorship or harassment. The online toxicity detection provide valuable guidance for stakeholders seeking to address this issue. By understanding the strengths and limitations of NLP-based approaches, informed decisions can be made about implementing effective toxicity detection strategies, ensuring a safer and more inclusive digital environment. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {AI; Machine Learning; Toxic comment detector},
	keywords = {Automation; Classification (of information); Learning algorithms; Natural language processing systems; Text processing; Toxicity; Breeding grounds; Language processing; Machine learning techniques; Machine-learning; Natural languages; Processing approach; Social media; Toxic comment detector; Toxicity detection; Unstructured data; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 13th International Advanced Computing Conference, IACC 2023; Conference date: 15 December 2023 through 16 December 2023; Conference code: 310219}
}

@CONFERENCE{Tanvir Rahman2024212,
	author = {Tanvir Rahman, Md. and Raihan, Abu Bakkar Siddique and Rahman, Tanzim and Ahsan, Shawly and Hossain, Jawad and Das, Avishek and Hoque, Mohammed Moshiul},
	title = {Binary_Beasts@DravidianLangTech-EACL 2024: Multimodal Abusive Language Detection in Tamil based on Integrated Approach of Machine Learning and Deep Learning Techniques},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {212 – 217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189856469&partnerID=40&md5=7eea805f632c216dc86bdd49605b3e5e},
	affiliations = {Department of Computer Science and Engineering, Chittagong University of Engineering & Technology, Chattogram, 4349, Bangladesh},
	abstract = {Detecting abusive language on social media is a challenging task that needs to be solved effectively. This research addresses the formidable challenge of detecting abusive language in Tamil through a comprehensive multimodal approach, incorporating textual, acoustic, and visual inputs. This study utilized ConvLSTM, 3D-CNN, and a hybrid 3D-CNN with BiLSTM to extract video features. Several models, such as BiLSTM, LR, and CNN, are explored for processing audio data, whereas for textual content, MNB, LR, and LSTM methods are explored. To further enhance overall performance, this work introduced a weighted late fusion model amalgamating predictions from all modalities. The fusion model was then applied to make predictions on the test dataset. The ConvLSTM+BiLSTM+MNB model yielded the highest macro F1 score of 71.43%. Our methodology allowed us to achieve 1st rank for multimodal abusive language detection in the shared task. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Convolutional neural networks; Data handling; Learning systems; Statistical tests; Visual languages; Audio data; Fusion model; Integrated approach; Language detection; Learning techniques; Machine-learning; Multi-modal; Multi-modal approach; Social media; Video features; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@CONFERENCE{Farsi2024193,
	author = {Farsi, Salman and Eusha, Asrarul Hoque and Hossain, Jawad and Ahsan, Shawly and Das, Avishek and Hoque, Mohammed Moshiul},
	title = {CUET_Binary_Hackers@DravidianLangTech EACL2024: Hate and Offensive Language Detection in Telugu Code-Mixed Text Using Sentence Similarity BERT},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {193 – 199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189858008&partnerID=40&md5=23f8a0b3a9e191191b0668e27820b697},
	affiliations = {Department of Computer Science and Engineering, Chittagong University of Engineering & Technology, Chattogram, 4349, Bangladesh},
	abstract = {With the continuous evolution of technology and widespread internet access, various social media platforms have gained immense popularity, attracting a vast number of active users globally. However, this surge in online activity has also led to a concerning trend by driving many individuals to resort to posting hateful and offensive comments or posts, publicly targeting groups or individuals. In response to these challenges, we participated in this shared task. Our approach involved proposing a fine-tuning-based pre-trained transformer model to effectively discern whether a given text contains offensive content that propagates hatred. We conducted comprehensive experiments, exploring various machine learning (LR, SVM, and Ensemble), deep learning (CNN, BiLSTM, CNN+BiLSTM), and transformer-based models (Indic-SBERT, m-BERT, MuRIL, Distil-BERT, XLM-R), adhering to a meticulous fine-tuning methodology. Among the models evaluated, our fine-tuned L3Cube-Indic-Sentence-SimilarityBERT or Indic-SBERT model demonstrated superior performance, achieving a macro-average F1-score of 0.7013. This notable result positioned us at the 6th place in the task. The implementation details of the task will be found in the GitHub repository. © 2024 Association for Computational Linguistics.},
	keywords = {Bismuth compounds; Personal computing; Support vector machines; Evolution of technology; Fine tuning; Internet access; Language detection; Number of active users; Offensive languages; Online activities; Sentence similarity; Social media platforms; Transformer modeling; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@ARTICLE{Singh2024110,
	author = {Singh, Divya and Gupta, Sonam and Baghel, Rekha},
	title = {Hate Speech Detection Using Machine Learning and Deep Learning Techniques},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2128 CCIS},
	pages = {110 – 124},
	doi = {10.1007/978-3-031-62217-5_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197216577&doi=10.1007%2f978-3-031-62217-5_10&partnerID=40&md5=15d3154dc353a4fc8cda68a4c6897f10},
	affiliations = {Ajay Kumar Garg Engineering College, Ghaziabad, India},
	abstract = {This paper delves into the pressing issue of hate speech in the digital era, which undermines inclusive online conversations. It investigates various methods for detecting hate speech, utilizing both conventional machine learning techniques and state-of-the-art deep learning architectures. The study focuses on deep learning models such as Convolutional Neural Networks, Recurrent Neural Networks, and Transformers, assessing their effectiveness in identifying textual patterns. Additionally, the practicality of machine learning algorithms, including ensemble methods, is examined. To ensure fairness, class inequality and ethical considerations are thoroughly taken into account when evaluating the efficiency of hate speech detection systems. Furthermore, the report addresses emerging challenges like context-dependent hate speech and evolving linguistic patterns. It places great importance on the ongoing necessity for research efforts and moral obligations to combat hate speech on online platforms. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {convolutional neural network; deep learning; hate speech; machine learning; recurrent neural network; transformers},
	keywords = {Convolution; Convolutional neural networks; Deep neural networks; Learning algorithms; Learning systems; Speech recognition; Conventional machines; Convolutional neural network; Deep learning; Digital era; Hate speech; Learning techniques; Machine-learning; Pressung; Speech detection; Transformer; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Machine Learning, Image Processing, Network Security, and Data Sciences, MIND 2023; Conference date: 21 December 2023 through 22 December 2023; Conference code: 313539}
}

@CONFERENCE{Kaya2024111,
	author = {Kaya, Ahmet Kagan and Ozcelik, Oguzhan and Toraman, Cagri},
	title = {ARC-NLP at ClimateActivism 2024: Stance and Hate Speech Detection by Generative and Encoder Models Optimized with Tweet-Specific Elements},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {111 – 117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190246489&partnerID=40&md5=8c1170e054b5806f557607f1780f7573},
	affiliations = {ASELSAN, Ankara, Turkey},
	abstract = {Social media users often express hate speech towards specific targets and may either support or refuse activist movements. The automated detection of hate speech, which involves identifying both targets and stances, plays a critical role in event identification to mitigate its negative effects. In this paper, we present our methods for three subtasks of the Climate Activism Stance and Hate Event Detection Shared Task at CASE 2024. For each subtask (i) hate speech identification (ii) targets of hate speech identification (iii) stance detection, we experiment with optimized Transformer-based architectures that focus on tweet-specific features such as hashtags, URLs, and emojis. Furthermore, we investigate generative large language models, such as Llama2, using specific prompts for the first two subtasks. Our experiments demonstrate better performance of our models compared to baseline models in each subtask. Our solutions also achieve third, fourth, and first places respectively in the subtasks. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Automated detection; Event identification; Events detection; Hashtags; Language model; Performance; Social media; Speech detection; Speech identification; Subtask; Signal encoding},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@ARTICLE{Aljawazeri20241,
	author = {Aljawazeri, Jinan Ali and Jasim, Mahdi Nsaif},
	title = {Addressing Challenges in Hate Speech Detection Using BERT-Based Models: A Review},
	year = {2024},
	journal = {Iraqi Journal for Computer Science and Mathematics},
	volume = {5},
	number = {2},
	pages = {1 – 20},
	doi = {10.52866/ijcsm.2024.05.02.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191663288&doi=10.52866%2fijcsm.2024.05.02.001&partnerID=40&md5=4507b274f73b072fa8fb4366fa63cdfd},
	affiliations = {Department of Software, University of Babylon, Hillah, 51001, Iraq; Department of Business Informatics, University of Information Technology and Communications, Baghdad, 10001, Iraq},
	abstract = {The rapid growth of social media platforms has led to an increase in hate speech. This has prompted the development of effective detection mechanisms that aim to mitigate the potential hazards and threats it poses to society. BERT (Bidirectional Encoder Representations from Transformers) has produced cutting-edge results in this field. This review paper aims to identify and analyze the whole process of using the BERT model to tackle the challenges associated with the hate speech detection problem. This academic discussion will begin by addressing the training datasets and the preprocessing methods involved. Subsequently, the use of the BERT model will be explored, followed by an examination of the contributions made to address the issues encountered. Finally, we will discuss the evaluation phase. The use of BERT included the application of two primary approaches. In the feature-based approach, BERT accepts textual input and generates its corresponding representation as output. The resulting output is then used as input for any classification model. The second approach involves the process of fine-tuning BERT using labeled datasets and then employing it directly for classification purposes. The controversial issues and open challenges that appeared at each stage were discussed. The results indicate that in both approaches, BERT has shown its efficacy relative to other models under contention. However, there is a need for greater attention and advancement to effectively solve the existing issues and constraints in the future. © 2024 College of Education, Al-Iraqia University. All rights reserved.},
	author_keywords = {BERT; Feature-Based; Fine-Tuning; Hate Speech Detection},
	keywords = {Speech recognition; Bidirectional encoder representation from transformer; Detection mechanism; Feature-based; Fine tuning; Hate speech detection; Potential hazards; Rapid growth; Social media platforms; Speech detection; Transformer modeling; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Alam2024238,
	author = {Alam, Md Ashraful and Taher, Hasan Mesbaul Ali and Hossain, Jawad and Ahsan, Shawly and Hoque, Mohammed Moshiul},
	title = {CUET_NLP_Manning@LT-EDI 2024: Transformer-based Approach on Caste and Migration Hate Speech Detection},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {238 – 243},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189864768&partnerID=40&md5=9b8275f72776d836a21575404c10c34b},
	affiliations = {Department of Computer Science and Engineering, Chittagong University of Engineering & Technology, Chattogram, 4349, Bangladesh},
	abstract = {The widespread use of online communication has caused a significant increase in the spread of hate speech on social media. However, there are also hate crimes based on caste and migration status. Despite several nations efforts to bring equality among their citizens, numerous crimes occur just based on caste. Migration-based hostility happens both in India and in developed countries. A shared task was arranged to address this issue in a low-resourced language such as Tamil. This paper aims to improve the detection of hate speech and hostility based on caste and migration status on social media. To achieve this, this work investigated several Machine Learning (ML), Deep Learning (DL), and transformer-based models, including M-BERT, XLM-R, and Tamil BERT. Experimental results revealed the highest macro f1-score of 0.80 using the M-BERT model, which enabled us to rank 3rd on the shared task. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Deep learning; Learning systems; Social networking (online); Speech communication; Speech recognition; Developed countries; Machine-learning; On-line communication; Social media; Speech detection; Crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@CONFERENCE{Barkhordar2024215,
	author = {Barkhordar, Ehsan and Topçu, Işık S. and Hürriyetoğlu, Ali},
	title = {Team Curie at HSD-2Lang 2024: Hate Speech Detection in Turkish and Arabic Tweets using BERT-based models},
	year = {2024},
	journal = {CASE 2024 - 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {215 – 220},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190289452&partnerID=40&md5=66b2adb30e439f46c2e2df16e9fbbe05},
	affiliations = {Koç University, İstanbul, Turkey; Wageningen Food Safety Research (WFSR), Wageningen, Netherlands},
	abstract = {This study focuses on hate speech detection in Turkish and Arabic tweets using advanced BERT-based models. Performance metrics demonstrate the models' effectiveness, with the Turkish variant achieving a 71.8% F1 score and the Arabic model a 76.9% F1 score, ranking them fourth and third, respectively, in a competitive leaderboard. Performance enhancements were realized through targeted preprocessing, including emoji translation and user mention exclusion, and thoughtful data balancing approaches. Future directions include refining model accuracy and broadening language support. Our reproducible approach and detailed findings are accessible on GitHub. © 2024 Association for Computational Linguistics.},
	keywords = {F1 scores; Modeling accuracy; Performance enhancements; Performance metrices; Speech detection; Turkishs; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2024; Conference date: 22 March 2024; Conference code: 198162}
}

@ARTICLE{Mnassri2024,
	author = {Mnassri, Khouloud and Farahbakhsh, Reza and Chalehchaleh, Razieh and Rajapaksha, Praboda and Jafari, Amir Reza and Li, Guanlin and Crespi, Noel},
	title = {A survey on multi-lingual offensive language detection},
	year = {2024},
	journal = {PeerJ Computer Science},
	volume = {10},
	doi = {10.7717/peerj-cs.1934},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190380615&doi=10.7717%2fpeerj-cs.1934&partnerID=40&md5=f4f328dffd25fbe793d7436e2ebaeec1},
	affiliations = {Samovar, Telecom SudParis, Institut Polytechnique de Paris, Palaiseau, France},
	abstract = {The prevalence of offensive content on online communication and social media platforms is growing more and more common, which makes its detection difficult, especially in multilingual settings. The term “Offensive Language” encompasses a wide range of expressions, including various forms of hate speech and aggressive content. Therefore, exploring multilingual offensive content, that goes beyond a single language, focus and represents more linguistic diversities and cultural factors. By exploring multilingual offensive content, we can broaden our understanding and effectively combat the widespread global impact of offensive language. This survey examines the existing state of multilingual offensive language detection, including a comprehensive analysis on previous multilingual approaches, and existing datasets, as well as provides resources in the field. We also explore the related community challenges on this task, which include technical, cultural, and linguistic ones, as well as their limitations. Furthermore, in this survey we propose several potential future directions toward more efficient solutions for multilingual offensive language detection, enabling safer digital communication environment worldwide. © 2024 Zeng and Asif},
	author_keywords = {Hate speech; Literature review; Multilingualism; Offensive language; Social media},
	keywords = {Digital communication systems; Social networking (online); Communication media; Hate speech; Language detection; Linguistic diversity; Literature reviews; Multilingualism; Offensive languages; On-line communication; Social media; Social media platforms; Linguistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}@BOOK{Wieczorkowski2024242,
	author = {Wieczorkowski, Jędrzej and Suwińska, Aleksandra},
	title = {Automatic Hate Speech Detection Methods as a Tool Supporting a Sustainable Society and Economy},
	year = {2024},
	journal = {Adoption of Emerging Information and Communication Technology for Sustainability},
	pages = {242 – 264},
	doi = {10.1201/9781003316572-16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183249554&doi=10.1201%2f9781003316572-16&partnerID=40&md5=3b315bec224a693754200853b875bec1},
	affiliations = {Institute of Information Systems and Digital Economy, Collegium of Economic Analysis, SGH Warsaw School of Economics, Poland},
	abstract = {Hate speech is a problem that has become especially visible with the development of the Internet, including social media. Leaving it unresolved results in social and economic consequences, hence the attempts to limit this phenomenon. One of the activities supporting such processes may be automatic hate speech detection using text mining methods to block aggressive statements. The aim of the chapter is to demonstrate and confirm the thesis about the effectiveness of text mining in the automatic detection of hate speech on the Internet. Moreover, the purpose is to compare different methods in terms of their effectiveness. The following text mining methods were compared: artificial neural network, naive Bayes classifier and support vector machine. Considerations do not allow for the full automation of the process of eliminating hate speech, but it can significantly accelerate the moderation of the content on the Internet. The use of the proposed model in practice may bring several social (e.g. reduction of discrimination of minorities, social unrest) and economic (e.g. reduction of disturbances in the labor market and free movement of capital) benefits. © 2024 Ewa Ziemba and Jarosław Wątróbski.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Adaikkan20238775,
	author = {Adaikkan, Kalaivani and Thenmozhi, Durairaj},
	title = {Detecting offensive language using Chaotic Ant Lion optimization-based Ghost net in social media},
	year = {2023},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {45},
	number = {5},
	pages = {8775 – 8788},
	doi = {10.3233/JIFS-232217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176585023&doi=10.3233%2fJIFS-232217&partnerID=40&md5=7cba1296fa6feeec346182a3f8c3f81d},
	affiliations = {Department of Computer Science Engineering, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Kalavakkam, India},
	abstract = {Social media has become one of the most popular medium of communication and the post may be predominantly unstructured, informal, and frequently misspelled. It has become increasingly common for users to use abusive language in their comments. Detecting offensive language on social media platforms and the presence of such language on the Internet has become a major challenge for modern society. To overcome this challenge, Offensive Language Classification based on the Chaotic Antlion optimization algorithm has been proposed. Initially, the dataset is pre-processed using NLP languages for removing irrelevant data. Consequently, statistical, synthetic, and lexicon features are extracted using various feature extraction techniques. A Chaotic Antlion Optimization Algorithm is used to select the most relevant features during the feature selection phase. After selecting the features, a Ghost network classifies the input data into four classes namely offensive, non-offensive, swear, and offensive but not offensive. The proposed method was evaluated based on a number of variables, including precision, accuracy, specificity, recall, and F-measure. The best classification accuracy is achieved by the suggested method, which is 99.27% for the SOLID dataset and 98.99% for the OLID dataset. The suggested method outperforms the DCNN, Simple Logistics, and CNN methods in terms of overall accuracy by 4.99%, 8.72%, and 10.4%, respectively.  © 2023-IOS Press. All rights reserved.},
	author_keywords = {Chaotic Antlion optimization algorithm; DCNN; detecting offensive language; Ghost network; SOLID dataset},
	keywords = {Feature Selection; Optimization; Social networking (online); Chaotic antlion optimization algorithm; Chaotics; DCNN; Detecting offensive language; Ghost network; Offensive languages; Optimisations; Optimization algorithms; Social media; SOLID dataset; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mnassri2024192,
	author = {Mnassri, Khouloud and Farahbakhsh, Reza and Crespi, Noel},
	title = {Multilingual Hate Speech Detection Using Semi-supervised Generative Adversarial Network},
	year = {2024},
	journal = {Studies in Computational Intelligence},
	volume = {1144 SCI},
	pages = {192 – 204},
	doi = {10.1007/978-3-031-53503-1_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187722999&doi=10.1007%2f978-3-031-53503-1_16&partnerID=40&md5=599b3e8d2f2d0866f86bc9e75b674185},
	affiliations = {Samovar, Telecom SudParis, Institut Polytechnique de Paris, Palaiseau, 91120, France},
	abstract = {Online communication has overcome linguistic and cultural barriers, enabling global connection through social media platforms. However, linguistic variety introduced more challenges in tasks such as the detection of hate speech content. Although multiple NLP solutions were proposed using advanced machine learning techniques, data annotation scarcity is still a serious problem urging the need for employing semi-supervised approaches. This paper proposes an innovative solution—a multilingual Semi-Supervised model based on Generative Adversarial Networks (GAN) and mBERT models, namely SS-GAN-mBERT. We managed to detect hate speech in Indo-European languages (in English, German, and Hindi) using only 20% labeled data from the HASOC2019 dataset. Our approach excelled in multilingual, zero-shot cross-lingual, and monolingual paradigms, achieving, on average, a 9.23% F1 score boost and 5.75% accuracy increase over baseline mBERT model. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {GAN; Hate Speech; mBERT; multilingual; offensive language; semi-supervised; social media},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 12th International Conference on Complex Networks and their Applications, COMPLEX NETWORKS 2023; Conference date: 28 November 2023 through 30 November 2023; Conference code: 308339}
}

@ARTICLE{Boucherit2024639,
	author = {Boucherit, Oussama and Abainia, Kheireddine},
	title = {Offensive Language Detection in Under-Resourced Algerian Dialectal Arabic Language},
	year = {2024},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1053 LNEE},
	pages = {639 – 647},
	doi = {10.1007/978-981-99-3481-2_49},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180156807&doi=10.1007%2f978-981-99-3481-2_49&partnerID=40&md5=7112e6f04e1be8fd8c07b0a1ae356199},
	affiliations = {PIMIS Laboratory, Department of Electronics and Telecommunications, Université 8 Mai 1945, Guelma, 24000, Algeria},
	abstract = {This paper addresses the problem of detecting the offensive and abusive content in Facebook comments, where we focus on the Algerian dialectal Arabic which is one of the under-resourced languages. The latter has a variety of dialects mixed with different languages (i.e., Berber, French, and English). In addition, we deal with texts written in both Arabic and Roman scripts (i.e., Arabizi). Due to the scarcity of works on the same language, we have built a new corpus regrouping more than 8.7 k texts manually annotated as normal, abusive, and offensive. We have conducted a series of experiments using the state-of-the-art classifiers of text categorization, namely: BiLSTM, CNN, FastText, SVM, and NB. The results showed acceptable performances, but the problem requires further investigation on linguistic features to increase the identification accuracy. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Abusive language; Algerian dialectal Arabic; Facebook; Offensive language; Social media},
	keywords = {Linguistics; Support vector machines; Text processing; Abusive language; Algerian dialectal arabic; Arabic languages; Dialectal arabics; Facebook; Language detection; Offensive languages; Social media; Under-resourced; Under-resourced languages; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Big Data, Machine Learning, and Applications, BigDML 2021; Conference date: 19 December 2021 through 20 December 2021; Conference code: 305219; All Open Access, Green Open Access}
}

@ARTICLE{Neog2024485,
	author = {Neog, Mandira and Baruah, Nomi},
	title = {A Deep Learning Framework for Assamese Toxic Comment Detection: Leveraging LSTM and BiLSTM Models with Attention Mechanism},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {892},
	pages = {485 – 497},
	doi = {10.1007/978-981-99-9521-9_37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187684716&doi=10.1007%2f978-981-99-9521-9_37&partnerID=40&md5=af28778a0cd99e4ccf436857e9a4b573},
	affiliations = {Dibrugarh University, Assam, Dibrugarh, India},
	abstract = {As social media platforms grow in popularity, this research piece discusses the significance of creating a secure and positive online environment. The major goal is to protect users by detecting objectionable language in Assamese social media comments. The ultimate goal is to create a very effective mechanism for detecting toxic comments in Assamese, supporting a safe online environment. To address the lack of available datasets, a well-curated dataset was manually assembled for the experiment. Deep learning models such as LSTM and bidirectional LSTM (BiLSTM) were used to capture the contextual intricacies of user-generated comments. Notably, the BiLSTM model beats the LSTM model by including an attention mechanism, attaining a promising accuracy rate of 86.9% in successfully identifying toxic comments. Using the capabilities of the LSTM and BiLSTM models, a more robust and efficient approach for recognizing toxic phrases in Assamese is developed, aligned with the goal of building a secure, respectful, and toxic-free online environment. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Assamese; Attention mechanism; BiLSTM; LSTM; Toxic},
	keywords = {Long short-term memory; Assamese; Attention mechanisms; Bidirectional LSTM; Effective mechanisms; Learning frameworks; LSTM; Online environments; Social media; Social media platforms; Toxic; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Advances in Data-driven Computing and Intelligent Systems, ADCIS 2023; Conference date: 21 September 2023 through 23 September 2023; Conference code: 308729}
}

@ARTICLE{Şahinuç20231591,
	author = {Şahinuç, Furkan and Yilmaz, Eyup Halit and Toraman, Cagri and Koç, Aykut},
	title = {The effect of gender bias on hate speech detection},
	year = {2023},
	journal = {Signal, Image and Video Processing},
	volume = {17},
	number = {4},
	pages = {1591 – 1597},
	doi = {10.1007/s11760-022-02368-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139678600&doi=10.1007%2fs11760-022-02368-z&partnerID=40&md5=71c80cb315d7c6dd255fd344636c2aab},
	affiliations = {Aselsan Research Center, Ankara, 06200, Turkey; Department of Electrical and Electronics Engineering, Bilkent University, Ankara, 06800, Turkey; The National Magnetic Resonance Research Center, Bilkent University, Ankara, 06800, Turkey},
	abstract = {Hate speech against individuals or communities with different backgrounds is a major problem in online social networks. The domain of hate speech has spread to various topics, including race, religion, and gender. Although there are many efforts for hate speech detection in different domains and languages, the effects of gender identity are not solely examined in hate speech detection. Moreover, hate speech detection is mostly studied for particular languages, specifically English, but not low-resource languages, such as Turkish. We examine gender identity-based hate speech detection for both English and Turkish tweets. We compare the performances of state-of-the-art models using 20 k tweets per language. We observe that transformer-based language models outperform bag-of-words and deep learning models, while the conventional bag-of-words model has surprising performances, possibly due to offensive or hate-related keywords. Furthermore, we analyze the effect of debiased embeddings for hate speech detection. We find that the performance can be improved by removing the gender-related bias in neural embeddings since gender-biased words can have offensive or hateful implications. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Debiased embedding; Deep learning; Gender identity; Hate speech; Language model},
	keywords = {Computational linguistics; Deep learning; Information retrieval; Social networking (online); Speech recognition; Debiased embedding; Deep learning; Embeddings; Gender bias; Gender identity; Hate speech; Language model; Performance; Speech detection; Turkishs; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Alrashidi2023,
	author = {Alrashidi, Bedour and Jamal, Amani and Alkhathlan, Ali},
	title = {Abusive Content Detection in Arabic Tweets Using Multi-Task Learning and Transformer-Based Models},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {10},
	doi = {10.3390/app13105825},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160868323&doi=10.3390%2fapp13105825&partnerID=40&md5=009961bab2a18c0ceb6e1bb5044b07c7},
	affiliations = {Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Department of Information and Computer Science, College of Computer Science and Engineering, University of Ha’il, Ha’il, 55436, Saudi Arabia},
	abstract = {Different social media platforms have become increasingly popular in the Arab world in recent years. The increasing use of social media, however, has also led to the emergence of a new challenge in the form of abusive content, including hate speech, offensive language, and abusive language. Existing research work focuses on automatic abusive content detection as a binary classification problem. In addition, the existing research work on the automatic detection task surrounding abusive Arabic content fails to tackle the dialect-specific phenomenon. Consequently, this has led to two important issues in the automatic abusive Arabic content detection task. In this study, we used a multi-aspect annotation schema to tackle the automatic abusive content detection problem in Arabic countries, based on the multi-class classification task and the dialectal Arabic (DA)-specific phenomenon. More precisely, the multi-aspect annotation schema includes five attributes: directness, hostility, target, group, and annotator. We specifically developed a framework to automatically detecting abusive content on Twitter using natural language processing (NLP) techniques. The developed framework used different models of machine learning (ML), deep learning (DL), and pretrained Arabic language models (LMs) using the multi-aspect annotation dataset. In addition, to investigate the impact of the other approaches, such as multi-task learning (MTL), we developed four MTL models built on top of a pretrained DA language model (called MARBERT) and trained on the multi-aspect annotation dataset. Our MTL models and pretrained Arabic LMs enhanced the performance compared to the existing DL model mentioned in the literature. © 2023 by the authors.},
	author_keywords = {abusive content; dialectal Arabic (DA); DL; multitask learning; NLP},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{García-Díaz2023,
	author = {García-Díaz, José Antonio and Pan, Ronghao and Valencia-García, Rafael},
	title = {Leveraging Zero and Few-Shot Learning for Enhanced Model Generality in Hate Speech Detection in Spanish and English},
	year = {2023},
	journal = {Mathematics},
	volume = {11},
	number = {24},
	doi = {10.3390/math11245004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180457484&doi=10.3390%2fmath11245004&partnerID=40&md5=f7737b9cd60f7bd73e2d0f6ad37e58eb},
	affiliations = {Facultad de Informática, Universidad de Murcia, Campus de Espinardo, Murcia, 30100, Spain},
	abstract = {Supervised training has traditionally been the cornerstone of hate speech detection models, but it often falls short when faced with unseen scenarios. Zero and few-shot learning offers an interesting alternative to traditional supervised approaches. In this paper, we explore the advantages of zero and few-shot learning over supervised training, with a particular focus on hate speech detection datasets covering different domains and levels of complexity. We evaluate the generalization capabilities of generative models such as T5, BLOOM, and Llama-2. These models have shown promise in text generation and have demonstrated the ability to learn from limited labeled data. Moreover, by evaluating their performance on both Spanish and English datasets, we gain insight into their cross-lingual applicability and versatility, thus contributing to a broader understanding of generative models in natural language processing. Our results highlight the potential of generative models to bridge the gap between data scarcity and model performance across languages and domains. © 2023 by the authors.},
	author_keywords = {few-shot learning; fine-tuning; hate speech detection; large language models; natural language processing; zero-shot learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Ludwig20241974,
	author = {Ludwig, Florian and Pinto, Ana Alves and Dolos, Klara and Zesch, Torsten},
	title = {Unraveling the Dynamics of Semi-Supervised Hate Speech Detection: The Impact of Unlabeled Data Characteristics and Pseudo-Labeling Strategies},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2024},
	pages = {1974 – 1986},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188731313&partnerID=40&md5=2282d699e09c67f53689ab6764ec96fb},
	affiliations = {ZITiS, Zamdorfer Str. 88, München, 81677, Germany; FernUniversität in Hagen, Universitätsstraße 47, Hagen, 58097, Germany},
	abstract = {Despite advances in machine learning based hate speech detection, the need for larges amounts of labeled training data for state-of-the-art approaches remains a challenge for their application. Semi-supervised learning addresses this problem by leveraging unlabeled data and thus reducing the amount of annotated data required. Underlying this approach is the assumption that labeled and unlabeled data follow similar distributions. This assumption however may not always hold, with consequences for real world applications. We address this problem by investigating the dynamics of pseudo-labeling, a commonly employed form of semi-supervised learning, in the context of hate speech detection. Concretely we analysed the influence of data characteristics and of two strategies for selecting pseudo-labeled samples: threshold- and ratio-based. The results show that the influence of data characteristics on the pseudo-labeling performances depends on other factors, such as pseudo-label selection strategies or model biases. Furthermore, the effectiveness of pseudo-labeling in classification performance is determined by the interaction between the number, hate ratio and accuracy of the selected pseudo-labels. Analysis of the results suggests an advantage of the threshold-based approach when labeled and unlabeled data arise from the same domain, whilst the ratio-based approach may be recommended in the opposite situation. © 2024 Association for Computational Linguistics.},
	keywords = {Learning algorithms; Supervised learning; Data characteristics; Labeled and unlabeled data; Labeling strategy; Labelings; Large amounts; Machine-learning; Semi-supervised; Semi-supervised learning; Speech detection; Unlabeled data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 18th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2024 - Findings of EACL 2024; Conference date: 17 March 2024 through 22 March 2024; Conference code: 198141}
}

@ARTICLE{Kaminska2023521,
	author = {Kaminska, Olha and Cornelis, Chris and Hoste, Veronique},
	title = {Fuzzy rough nearest neighbour methods for detecting emotions, hate speech and irony},
	year = {2023},
	journal = {Information Sciences},
	volume = {625},
	pages = {521 – 535},
	doi = {10.1016/j.ins.2023.01.054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146143437&doi=10.1016%2fj.ins.2023.01.054&partnerID=40&md5=f31cc5950bd078b1f3d291c0d5373a53},
	affiliations = {Computational Web Intelligence, Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium; LT3 Language and Translation Technology Team, Ghent University, Ghent, Belgium},
	abstract = {Due to the ever-expanding volumes of information available on social media, the need for reliable and efficient automated text understanding mechanisms becomes evident. Unfortunately, most current approaches rely on black-box solutions rooted in deep learning technologies. In order to provide a more transparent and interpretable framework for extracting intrinsic text characteristics like emotions, hate speech and irony, we propose to integrate fuzzy rough set techniques and text embeddings. We apply our methods to different classification problems originating from Semantic Evaluation (SemEval) competitions, and demonstrate that their accuracy is on par with leading deep learning solutions. © 2023 Elsevier Inc.},
	author_keywords = {Emotion detection; Fuzzy rough sets; Natural language processing; Text embeddings},
	keywords = {Deep learning; Emotion Recognition; Rough set theory; Semantics; 'current; Embeddings; Emotion detection; Fuzzy-rough sets; Language processing; Natural language processing; Natural languages; Nearest neighbours method; Social media; Text embedding; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access}
}

@ARTICLE{Chen2023,
	author = {Chen, Jing and Ma, Kun and Ji, Ke and Chen, Zhenxiang},
	title = {TM-HOL: Topic memory model for detection of hate speech and offensive language},
	year = {2023},
	journal = {Concurrency and Computation: Practice and Experience},
	volume = {35},
	number = {14},
	doi = {10.1002/cpe.6754},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120630293&doi=10.1002%2fcpe.6754&partnerID=40&md5=4f694f1d71da163019e9cc1b4f78e0fd},
	affiliations = {College of Information Science and Engineering, University of Jinan, Jinan, China; Shandong Provincial Key Laboratory of Network Based Intelligent Computing, University of Jinan, Jinan, China},
	abstract = {In the era of the explosion of digital content of large-scale self-media, user-friendly social platforms such as Twitter and Facebook, provide opportunities for people to express their ideas and opinions freely. Due to lack of restrictions, hateful speech and its exposure can have profound psychological impacts on society. Current social networking platform is over-reliant on the manual check, and it is labor-intensive and time-consuming. Although there are many machines learning methods for the detection of hate speech, short text with character limit on social platforms is more challenging for the detection of hate speech and offensive language. To address the problem of data sparsity, we have proposed a topic memory model for hate speech and offensive language detection (abbreviated as TM-HOL). Potential topics are generated with our encoder and decoder to enrich short text features. Two memory matrices correspond to the topic words and the text, and the hate feature matrix is used to learn the syntactic features. It is demonstrated that our proposed method is effective on three datasets, performing better weighted-F1. © 2021 John Wiley & Sons, Ltd.},
	author_keywords = {Big data processing; hate speech; offensive language; text classification; topic model},
	keywords = {Big data; Data handling; Learning systems; Matrix algebra; Social networking (online); Speech recognition; Text processing; Big data processing; Digital contents; Hate speech; Large-scales; Memory modeling; Offensive languages; Short texts; Text classification; Topic Modeling; User friendly; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Subramanian2023110,
	author = {Subramanian, Malliga and Easwaramoorthy Sathiskumar, Veerappampalayam and Deepalakshmi, G. and Cho, Jaehyuk and Manikandan, G.},
	title = {A survey on hate speech detection and sentiment analysis using machine learning and deep learning models},
	year = {2023},
	journal = {Alexandria Engineering Journal},
	volume = {80},
	pages = {110 – 121},
	doi = {10.1016/j.aej.2023.08.038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170256806&doi=10.1016%2fj.aej.2023.08.038&partnerID=40&md5=bd515b2562dc222ad367e14fc865b35c},
	affiliations = {Department of Computer Science and Engineering, Kongu Engineering College, Perundurai, Erode, India; Department of Software Engineering, Jeonbuk National University, Jeongu-si, South Korea; School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India},
	abstract = {In today's digital era, the rise of hate speech has emerged as a critical concern, driven by the rapid information-sharing capabilities of social media platforms and online communities. As the internet expands, the proliferation of harmful content, including hate speech, presents considerable obstacles in ensuring a secure and inclusive online environment. In response to this challenge, researchers have embraced machine learning and deep learning methods to create automated systems that can effectively detect hate speech and conduct sentiment analysis, offering potential solutions to address this pressing issue. This survey article provides a comprehensive overview of recent advancements in hate speech detection and sentiment analysis using machine learning and deep learning models. We present an in-depth analysis of various methodologies and datasets employed in this domain. Additionally, we explore the unique challenges faced by these models in accurately identifying and classifying hate speech and sentiment in online text. Finally, we outline areas where more study is needed and suggest potential new avenues for exploration in the field of hate speech identification and sentiment analysis. Using the results of this survey, we hope to encourage the development of more effective machine learning and deep learning-based solutions to curb hate speech and promote a more inclusive online environment. © 2023 THE AUTHORS},
	author_keywords = {Deep learning; Hate speech detection; Inclusive online; Machine learning; Sentiment analysis},
	keywords = {Automation; Deep learning; E-learning; Learning systems; Social networking (online); Speech recognition; Deep learning; Digital era; Hate speech detection; Inclusive online; Information sharing; Learning models; Machine-learning; Online environments; Sentiment analysis; Speech detection; Sentiment analysis},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access}
}

@ARTICLE{Zampieri20231416,
	author = {Zampieri, Marcos and Rosenthal, Sara and Nakov, Preslav and Dmonte, Alphaeus and Ranasinghe, Tharindu},
	title = {OffensEval 2023: Offensive language identification in the age of Large Language Models},
	year = {2023},
	journal = {Natural Language Engineering},
	volume = {29},
	number = {6},
	pages = {1416 – 1435},
	doi = {10.1017/S1351324923000517},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179763014&doi=10.1017%2fS1351324923000517&partnerID=40&md5=0a9f3ce716cf166f5ede914adf91e1b7},
	affiliations = {George Mason University, Fairfax, VA, United States; IBM Research, Yorktown Heights, NY, United States; Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Aston University, Birmingham, United Kingdom},
	abstract = {The OffensEval shared tasks organized as part of SemEval-2019-2020 were very popular, attracting over 1300 participating teams. The two editions of the shared task helped advance the state of the art in offensive language identification by providing the community with benchmark datasets in Arabic, Danish, English, Greek, and Turkish. The datasets were annotated using the OLID hierarchical taxonomy, which since then has become the de facto standard in general offensive language identification research and was widely used beyond OffensEval. We present a survey of OffensEval and related competitions, and we discuss the main lessons learned. We further evaluate the performance of Large Language Models (LLMs), which have recently revolutionalized the field of Natural Language Processing. We use zero-shot prompting with six popular LLMs and zero-shot learning with two task-specific fine-tuned BERT models, and we compare the results against those of the top-performing teams at the OffensEval competitions. Our results show that while some LMMs such as Flan-T5 achieve competitive performance, in general LLMs lag behind the best OffensEval systems. © The Author(s), 2023. Published by Cambridge University Press.},
	author_keywords = {Machine learning; Text classification},
	keywords = {Classification (of information); Computational linguistics; Learning algorithms; Text processing; Zero-shot learning; Benchmark datasets; Hierarchical taxonomy; Language identification; Language model; Machine-learning; Offensive languages; Participating teams; State of the art; Text classification; Turkishs; Natural language processing systems},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Lammerts2023834,
	author = {Lammerts, Philippe and Lippmann, Philip and Hsu, Yen-Chia and Casati, Fabio and Yang, Jie},
	title = {How do you feel? Measuring User-Perceived Value for Rejecting Machine Decisions in Hate Speech Detection},
	year = {2023},
	journal = {AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {834 – 844},
	doi = {10.1145/3600211.3604655},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173608009&doi=10.1145%2f3600211.3604655&partnerID=40&md5=e551cb72c87e46342c6413fec2ad3633},
	affiliations = {Delft University of Technology, Delft, Netherlands; University of Amsterdam, Amsterdam, Netherlands; ServiceNow, Santa Clara, CA, United States},
	abstract = {Hate speech moderation remains a challenging task for social media platforms. Human-AI collaborative systems offer the potential to combine the strengths of humans' reliability and the scalability of machine learning to tackle this issue effectively. While methods for task handover in human-AI collaboration exist that consider the costs of incorrect predictions, insufficient attention has been paid to accurately estimating these costs. In this work, we propose a value-sensitive rejection mechanism that automatically rejects machine decisions for human moderation based on users' value perceptions regarding machine decisions. We conduct a crowdsourced survey study with 160 participants to evaluate their perception of correct and incorrect machine decisions in the domain of hate speech detection, as well as occurrences where the system rejects making a prediction. Here, we introduce Magnitude Estimation, an unbounded scale, as the preferred method for measuring user (dis)agreement with machine decisions. Our results show that Magnitude Estimation can provide a reliable measurement of participants' perception of machine decisions. By integrating user-perceived value into human-AI collaboration, we further show that it can guide us in 1) determining when to accept or reject machine decisions to obtain the optimal total value a model can deliver and 2) selecting better classification models as compared to the more widely used target of model accuracy.  © 2023 Owner/Author.},
	author_keywords = {crowdsourcing; hate speech; human-in-the-loop; machine confidence; rejection; value-sensitive machine learning},
	keywords = {Machine learning; Speech recognition; Hate speech; Human-in-the-loop; Machine confidence; Machine decisions; Machine-learning; Magnitude estimation; Perceived value; Rejection; Speech detection; Value-sensitive machine learning; Crowdsourcing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 AAAI / ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2023; Conference date: 8 August 2023 through 10 August 2023; Conference code: 192626; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ayenew2024149,
	author = {Ayenew, Abirham and Chauhan, Uttam},
	title = {Amharic Language Hate Speech Detection Using Machine Learning},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {896},
	pages = {149 – 163},
	doi = {10.1007/978-981-99-9811-1_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188662503&doi=10.1007%2f978-981-99-9811-1_12&partnerID=40&md5=5a8ffef7fda5bde45aca0401bbbae7da},
	affiliations = {Computer Engineering, Vishwakarma Government Engineering College, Gujarat, Ahmedabad, India},
	abstract = {The extensive availability of social media platforms, as well as the adaptability of the Internet, has made it easier for users to participate in violent communication. The anonymity provided by online platforms makes them appealing to individuals engaging in hate speech to conceal their criminal activities. This poses a significant challenge in many countries, especially Ethiopia. As social media platforms continue to multiply and the volume of social media data grows exponentially, the identification of hate speech presents a formidable challenge. This challenge exacerbates conflicts between diverse ethnic groups and contributes to the dissemination of misinformation within communities. Despite the fact that there is a lot of research on hate speech identification, much of it is for high-resource languages, and there is still a lot of work to be done for low-resource languages. These pique our interest. As a response to these issues, this study uses machine learning methods to create an Amharic hate speech detection model. In this research, we prepared a new Amharic hate speech dataset from Facebook, labeled manually as hate and free based on standard guidelines and pre-processed, and labeled into two classes, and the data is augmented to balance the class category. We applied word2Vec embedding and TF-IDF feature selection techniques to train Random Forest, and Naïve Bayes machine learning models. To evaluate the models, we adopted an (80, 10, 10) train, validate, and test split. We utilized precision, recall, and F1-score as a means to compare the performance of these models. By combining the Naïve Bayes algorithm with Word2Vec and TF-IDF techniques, the best performance was achieved, resulting in an accuracy of 91.59%. The model achieves a promising result with a unique feature selection and appropriate pre-processing techniques. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Amharic hate speech detection; Amharic posts and comments; Machine learning},
	keywords = {Feature extraction; Speech recognition; Amharic hate speech detection; Amharic post and comment; Criminal activities; Ethiopia; Features selection; Machine-learning; Online platforms; Performance; Social media platforms; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Recent Developments in Cyber Security, ReDCySec 2023; Conference date: 16 June 2023 through 17 June 2023; Conference code: 309229}
}

@ARTICLE{Shibly202419,
	author = {Shibly, F.H.A. and Sharma, Uzzal and Naleer, H.M.M.},
	title = {An Efficient Method for Detecting Hate Speech in Tamil Tweets Using an Ensemble Approach},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {731 LNNS},
	pages = {19 – 26},
	doi = {10.1007/978-981-99-4071-4_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177093856&doi=10.1007%2f978-981-99-4071-4_2&partnerID=40&md5=6389fd72dbf54325ea0feb13fd65c8da},
	affiliations = {South Eastern University of Sri Lanka, Oluvil, Sri Lanka; Assam Don Bosco University, Guwahati, India; Associate Professor, Department of Computer Science, Birangana Sati Sadhani Rajyik Viswavidyalaya, Assam, Golaghat, India; Department of Computer Science, Faculty of Applied Sciences, South Eastern University of Sri Lanka, Oluvil, Sri Lanka},
	abstract = {People have converged on a worldwide level because of advancements in communication technologies. They are critical in ensuring freedom of speech by allowing individuals to openly express their thoughts, behaviors, and opinions. Although this presents an excellent chance for racism, trolling, and exposure to a flood of nasty online content. As a result, social media’s exponential rise in hate speech is profoundly affecting society. In this study, we used machine learning and deep learning algorithms to identify hate speech, and we compared their performance to create an ensemble model. Researchers gathered and integrated two distinct datasets of hateful tweets in Tamil that were produced by Bharathi Raja Chakravarthi et al. Tweets in this dataset fall into two categories: non offensive and offensive. This dataset contains 10,129 tweets. In addition, the researchers used six selected machine and deep learning algorithms for this study namely. Support Vector Machine (SVM), Logistic Regression (LR), Naïve Bayes (NB), Bidirectional LSTM, Multi-layer Perceptron (MLP) and Multilingual BERT. When it comes to detecting hate speech, SVM (82%) and LR (82%) have the best Accuracy. Furthermore, researchers developed two ensemble algorithms to construct a most efficient model. First ensemble model was created by combining SVM, LR and NB and the second ensemble was developed using SVM and LR. Four algorithms including the two ensemble models were obtained same accuracy. Therefore, the researchers compared the F1 score and found that the ensemble model 02 outperformed other classifiers. The results of this study are significant because they can be used as a benchmark for future research on Tamil language hate speech using various machine learning algorithms to detect hate speech more effectively and accurately. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.},
	author_keywords = {Algorithms; Deep learning; Detection and ensemble model; Hate speech; Machine learning},
	keywords = {Logistic regression; Long short-term memory; Speech recognition; Deep learning; Detection models; Ensemble approaches; Ensemble models; Hate speech; Logistics regressions; Machine logistics; Machine-learning; Naive bayes; Support vectors machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th International Conference on Innovative Computing and Communication, ICICC 2023; Conference date: 17 February 2023 through 18 February 2023; Conference code: 298729}
}

@ARTICLE{Nagar2023,
	author = {Nagar, Seema and Barbhuiya, Ferdous Ahmed and Dey, Kuntal},
	title = {Towards more robust hate speech detection: using social context and user data},
	year = {2023},
	journal = {Social Network Analysis and Mining},
	volume = {13},
	number = {1},
	doi = {10.1007/s13278-023-01051-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149931652&doi=10.1007%2fs13278-023-01051-6&partnerID=40&md5=31223112f63cdfe73007d40422a578be},
	affiliations = {Computer Science and Engineering, Indian Institute of Information Technology Guwahati, Assam, Bongora, Guwahati, 781015, India},
	abstract = {In this paper, we present a novel approach to detecting hate speech on Twitter. Our method incorporates textual, social context and language features of the author to better capture the nuances of hate speech and improve detection accuracy. We formalize the idea that an individual’s hateful content is influenced by their social circle and propose a framework that combines text content with social context to detect hate speech. Our framework uses a Variational Graph Auto-encoder to jointly learn the unified features of authors using a social network, language features, and profile information. Additionally, to accommodate emerging and future language models, our framework is designed to be flexible and can incorporate any text encoder as a plug-in to obtain the textual features of the content. We evaluate our method on two diverse Twitter datasets and show that it outperforms existing state-of-the-art methods by a significant margin. Our results suggest that considering social context is a promising direction for improving hate speech detection on Twitter. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Graph convolutional network; Hate speech detection; Social context},
	keywords = {Computational linguistics; Graph neural networks; Signal encoding; Social networking (online); User profile; Context data; Context features; Convolutional networks; Detection accuracy; Graph convolutional network; Hate speech detection; Language features; Social context; Speech detection; User data; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{Kumar2024,
	author = {Kumar, Ashwini and Kumar, Santosh},
	title = {NDDSM: Novel Deep Decision-Support Model for Hate Speech Detection},
	year = {2024},
	journal = {SN Computer Science},
	volume = {5},
	number = {1},
	doi = {10.1007/s42979-023-02382-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182435521&doi=10.1007%2fs42979-023-02382-z&partnerID=40&md5=16d60ac37c8ee0b5b7fd869c3e0f9b5a},
	affiliations = {Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, India},
	abstract = {The pervasiveness of social media in people's lives is indisputable, the issue where it has become a necessary part of daily practices. However, unrestricted access to social media allows anonymous individuals to spread meaningless or even hostile information, defeating communication's purpose. Social media’s positive and negative impact on society or individuals becomes more pronounced as its usage increases. As the harmful effect of unmonitored ‘hate speech’ becomes increasingly apparent, detecting such content has become a crucial concern in social media. In a recent study, machine-learning models have been developed to identify hate speech across multiple languages. As a result, the use of Bidirectional long short-term memory (Bi-LSTM) and convolutional neural network (CNN) for feature extraction in evaluating and identifying hate speech has risen. However, LSTM and CNN hyperparameters are typically selected based on expert opinion and prior research, making it difficult for the model to generalize since its creators need to know the optimal values for its parameters. To address this issue, we propose a novel deep decision support model which uses the sparrow search algorithm (SSA) to optimize the Bi-LSTM and CNN model hyperparameters for detecting hate speech. We employed the SSA for the decision support system to identify the best hyperparameters for the model architecture to improve its interpretability and accuracy. The benchmark datasets have been used to evaluate the model's performance, and the results indicate that our proposed model outperforms conventional hate speech detection systems. © 2023, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Decision support system; Hate speech; Social media; Sparrow Search Algorithm},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Shanmugavadivel2024206,
	author = {Shanmugavadivel, Kogilavani and Subramanian, Malliga and Aiswarya, M. and Aruna, T. and Jeevaananth, S.},
	title = {KEC AI DSNLP@LT-EDI-2024:Caste and Migration Hate Speech Detection using Machine Learning Techniques},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {206 – 210},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189853456&partnerID=40&md5=e2a3e829b94350d4913c531d3aaaf7e5},
	affiliations = {Department of AI, Kongu Engineering College, Perundurai, Erode, India},
	abstract = {Commonly used language defines “hate speech” as objectionable statements that may jeopardize societal harmony by singling out a group or a person based on fundamental traits (including gender, caste, or religion). Using machine learning techniques, our research focuses on identifying hate speech in social media comments. Using a variety of machine learning methods, we created machine learning models to detect hate speech. An approximate Macro F1 of 0.60 was attained by the created models. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Machine learning; Speech recognition; Machine learning methods; Machine learning models; Machine learning techniques; Research focus; Social media; Speech detection; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@ARTICLE{Hermida202312833,
	author = {Hermida, Paulo Cezar de Q. and Santos, Eulanda M. dos},
	title = {Detecting hate speech in memes: a review},
	year = {2023},
	journal = {Artificial Intelligence Review},
	volume = {56},
	number = {11},
	pages = {12833 – 12851},
	doi = {10.1007/s10462-023-10459-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150619409&doi=10.1007%2fs10462-023-10459-7&partnerID=40&md5=6c8daccf55f2e7dd3fa9cbdf637ca1ae},
	affiliations = {Institute of Computing, Federal University of Amazonas, 6200, Gen. Rodrigo Octávio, Amazonas, Manaus, 69080-900, Brazil},
	abstract = {Methods that detect hate speech in memes have become vital in our connected society, especially in the context of many social media companies. Memes are a quick way to transfer ideas, events, or other content from the real world to the digital one. Massively created, they reproduce like viruses and aim to get people’s attention. They are powerful tools, that, when used to spread hate speech, are able to have global reach. Meme has a broad definition and different formats, such as short videos, GIFS, challenges, among others. In this paper, we follow the classical format of an image with superimposed text. In this context, the hateful meme detection task is extremely challenging, especially due to memes’ multimodal nature, i.e., they have two different sources: image and text. Consequently, when dealing with memes, a classification model needs to tackle both components in order to classify them as hateful or not-hateful. This work contributes to the effort to solve this task. We list the most recent research, synthesize and discuss the approaches proposed in the current literature by providing a critical analysis of these methods, highlighting their strengths and points to improve. We also introduce a taxonomy to allow grouping similar approaches. Our conclusion indicates that, despite the few studies currently available and the few public datasets specially designed for this topic, there is an evolution in the methodologies used, which is reflected in the evolution of the results attained. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Hate speech detection; Hateful meme detection; Multimodal machine learning; Multimodal transformers},
	keywords = {Machine learning; Speech recognition; Hate speech detection; Hateful meme detection; Machine-learning; Media companies; Multi-modal; Multimodal machine learning; Multimodal transformer; Social media; Speech detection; Viruses},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Singh20238177,
	author = {Singh, Pardeep and Singh, Nitin Kumar and Monika and Chand, Satish},
	title = {MBERT-GRU multilingual deep learning framework for hate speech detection in social media},
	year = {2023},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {44},
	number = {5},
	pages = {8177 – 8192},
	doi = {10.3233/JIFS-222057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166394530&doi=10.3233%2fJIFS-222057&partnerID=40&md5=29ea3c87c7934a7c5786ec923d5ce462},
	affiliations = {School of Computer and Systems Sciences, Jawaharlal Nehru University, New Delhi, India},
	abstract = {One major issue plaguing online social media is hate speech, a complex phenomenon whose identification and target categorization have been studied by the natural language processing community. In recent years, notable studies have been made towards hate speech detection using various mechanisms varying from traditional machine learning to complex deep neural network models. However, these studies mainly focus on high-resource English language. The multilingual societies such as the Indian subcontinent: English, Hindi and Hindi-English code-mixed languages are widespread and convenient for the users. The research works studying hate speech detection in these languages are still very limited. To fill this gap, we propose an mBERT-GRU framework comprising of multilingual BERT embedding and bidirectional GRU layers to learn the cumulative features for hate speech detection and its target categorization. We evaluated our work on three datasets HASOC-2019, HS and HEOT to prove the competitive performance. Our results show that the proposed framework outperformed monolingual and state-of-the-art methods on English, Hindi and Hindi-English code-mixed datasets with Macro-F1 measure values of 0.87, 0.83 and 0.77, respectively.  © 2023 - IOS Press. All rights reserved.},
	author_keywords = {Deep learning; GRU; hate speech detection; multilingual BERT; social media; text analysis},
	keywords = {Codes (symbols); Complex networks; Learning algorithms; Learning systems; Natural language processing systems; Neural network models; Social networking (online); Speech recognition; Deep learning; GRU; Hate speech detection; Learning frameworks; Multilingual BERT; Online social medias; Social media; Speech detection; Target categorization; Text analysis; Deep neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{De la Peña Sarracén2023,
	author = {De la Peña Sarracén, Gretel Liz and Rosso, Paolo},
	title = {Systematic keyword and bias analyses in hate speech detection},
	year = {2023},
	journal = {Information Processing and Management},
	volume = {60},
	number = {5},
	doi = {10.1016/j.ipm.2023.103433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162134103&doi=10.1016%2fj.ipm.2023.103433&partnerID=40&md5=245134ce4cb28b49d3730059088b8973},
	affiliations = {Universitat Politècnica de València, Camino de Vera, s/n, Valencia, 46022, Spain},
	abstract = {Hate speech detection refers broadly to the automatic identification of language that may be considered discriminatory against certain groups of people. The goal is to help online platforms to identify and remove harmful content. Humans are usually capable of detecting hatred in critical cases, such as when the hatred is non-explicit, but how do computer models address this situation? In this work, we aim to contribute to the understanding of ethical issues related to hate speech by analysing two transformer-based models trained to detect hate speech. Our study focuses on analysing the relationship between these models and a set of hateful keywords extracted from the three well-known datasets. For the extraction of the keywords, we propose a metric that takes into account the division among classes to favour the most common words in hateful contexts. In our experiments, we first compared the overlap between the extracted keywords with the words to which the models pay the most attention in decision-making. On the other hand, we investigate the bias of the models towards the extracted keywords. For the bias analysis, we characterize and use two metrics and evaluate two strategies to try to mitigate the bias. Surprisingly, we show that over 50% of the salient words of the models are not hateful and that there is a higher number of hateful words among the extracted keywords. However, we show that the models appear to be biased towards the extracted keywords. Experimental results suggest that fitting models with hateful texts that do not contain any of the keywords can reduce bias and improve the performance of the models. © 2023 The Author(s)},
	author_keywords = {Bias analysis; Bias mitigation; Hate speech detection; Keyword extraction},
	keywords = {Automation; Behavioral research; Decision making; Speech recognition; Automatic identification; Bias analyse; Bias mitigation; Computer models; Critical case; Ethical issues; Hate speech detection; Keywords extraction; Online platforms; Speech detection; Extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Khan202437418,
	author = {Khan, Atif and Ahmed, Abrar and Jan, Salman and Bilal, Muhammad and Zuhairi, Megat F.},
	title = {Abusive Language Detection in Urdu Text: Leveraging Deep Learning and Attention Mechanism},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {37418 – 37431},
	doi = {10.1109/ACCESS.2024.3370232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186973344&doi=10.1109%2fACCESS.2024.3370232&partnerID=40&md5=1cc152b98fc1ce9a7ae387fda022cd41},
	affiliations = {Islamia College Peshawar, Department of Computer Science, Peshawar, 25120, Pakistan; Universiti Kuala Lumpur, Malaysian Institute of Information Technology, Kuala Lumpur, 50250, Malaysia; Bacha Khan University Charsadda, Department of Computer Science, Peshawar, 24540, Pakistan},
	abstract = {The widespread use of the Internet and the tremendous growth of social media have enabled people to connect with each other worldwide. Individuals are free to express themselves online, sharing their photos, videos, and text messages globally. However, such freedom sometimes leads to misuse, as some individuals exploit this platform by posting hateful and abusive comments on forums. The proliferation of abusive language on social media negatively impacts individuals and groups, leading to emotional distress and affecting mental health. It is crucial to automatically detect and filter such abusive content in order to effectively tackle this challenging issue. Detecting abusive language in text messages is challenging due to intentional word concealment and contextual complexity. To counter abusive speech on social media, we need to explore the potential of machine learning (ML) and deep learning (DL) models, particularly those equipped with attention mechanisms. In this study, we utilized popular ML and DL models integrated with attention mechanism to detect abusive language in Urdu text. Our methodology involved employing Count Vectorizer and Term Frequency-Inverse Document Frequency (TF/IDF) to extract n-grams at the word level: Unigrams (Uni), Bigrams (Bi), Trigrams (Tri), and their combination (Uni + Bi + Tri). Initially, we evaluated four traditional ML models - Logistic Regression (LR), Gaussian Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest (RF) - on both proposed and established datasets. The results highlighted that RF model outperformed other conventional models in terms of accuracy, precision, recall, and F1-measure on both datasets. In our implementation of deep learning models, we employed various models integrated with custom fastText and Word2Vec embeddings, each equipped with an attention layer, except for the Convolutional Neural Network (CNN). Our findings indicated that the Bidirectional Long Short-Term Memory (Bi-LSTM) + attention model, utilizing custom Word2Vec embeddings, exhibited improved performance in detecting abusive language on both datasets.  © 2013 IEEE.},
	author_keywords = {Abusive language; Bi-GRU; Bi-LSTM; deep learning models; fastText; GRU; LSTM; NLP; TF/IDF; Urdu; Word2Vec},
	keywords = {Brain; Dynamic random access storage; Feature extraction; Modeling languages; Regression analysis; Social networking (online); Support vector machines; Text processing; Abusive language; Bigram-GRU; Bigram-LSTM; Bigrams; Context models; Deep learning; Deep learning model; Fasttext; Features extraction; GRU; Hate speech; Learning models; Logistics regressions; LSTM; Natural languages; Support vectors machine; Term frequencyinverse document frequency (TF-IDF); Transformer; Urdu; Word2vec; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@ARTICLE{Ahmad2024,
	author = {Ahmad, Ashraf and Azzeh, Mohammad and Alnagi, Eman and Abu Al-Haija, Qasem and Halabi, Dana and Aref, Abdullah and AbuHour, Yousef},
	title = {Hate speech detection in the Arabic language: corpus design, construction, and evaluation},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1345445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186629503&doi=10.3389%2ffrai.2024.1345445&partnerID=40&md5=11b3fd383dbb79df2333c58ef4ef9869},
	affiliations = {Department of Computer Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan; Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan; Department of Cybersecurity, Faculty of Computer and Information Technology, Jordan University of Science and Technology, Irbid, Jordan; SAE Institute, Luminus Technical University College (LTUC), Amman, Jordan; Department of Basic Sciences, Princess Sumaya University for Technology (PSUT), Amman, Jordan},
	abstract = {Hate Speech Detection in Arabic presents a multifaceted challenge due to the broad and diverse linguistic terrain. With its multiple dialects and rich cultural subtleties, Arabic requires particular measures to address hate speech online successfully. To address this issue, academics and developers have used natural language processing (NLP) methods and machine learning algorithms adapted to the complexities of Arabic text. However, many proposed methods were hampered by a lack of a comprehensive dataset/corpus of Arabic hate speech. In this research, we propose a novel multi-class public Arabic dataset comprised of 403,688 annotated tweets categorized as extremely positive, positive, neutral, or negative based on the presence of hate speech. Using our developed dataset, we additionally characterize the performance of multiple machine learning models for Hate speech identification in Arabic Jordanian dialect tweets. Specifically, the Word2Vec, TF-IDF, and AraBert text representation models have been applied to produce word vectors. With the help of these models, we can provide classification models with vectors representing text. After that, seven machine learning classifiers have been evaluated: Support Vector Machine (SVM), Logistic Regression (LR), Naive Bays (NB), Random Forest (RF), AdaBoost (Ada), XGBoost (XGB), and CatBoost (CatB). In light of this, the experimental evaluation revealed that, in this challenging and unstructured setting, our gathered and annotated datasets were rather efficient and generated encouraging assessment outcomes. This will enable academics to delve further into this crucial field of study. Copyright © 2024 Ahmad, Azzeh, Alnagi, Abu Al-Haija, Halabi, Aref and AbuHour.},
	author_keywords = {Arabic hate speech; Arabic hate speech corpus; Arabic hate speech detection; machine learning; natural language processing (NLP)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ranasinghe202313,
	author = {Ranasinghe, Tharindu and Ghosh, Koyel and Pal, Aditya Shankar and Senapati, Apurbalal and Dmonte, Alphaeus Eric and Zampieri, Marcos and Modha, Sandip and Satapara, Shrey},
	title = {Overview of the HASOC Subtracks at FIRE 2023: Hate Speech and Offensive Content Identification in Assamese, Bengali, Bodo, Gujarati and Sinhala},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {13 – 15},
	doi = {10.1145/3632754.3633278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180218799&doi=10.1145%2f3632754.3633278&partnerID=40&md5=3fd0ef1c18b05ffd2aaeb9499a9cb7c1},
	affiliations = {Aston University, Birmingham, United Kingdom; Central Institute of Technology, Assam, Kokrajhar, India; Indian Statistical Institute, Kolkata, India; Central Institute of Technology, India; George Mason University, Fairfax, VA, United States; LDRP-ITR, Gandhinagar, India; Indian Institute of Technology, Hyderabad, India},
	abstract = {The evaluation of content moderation systems requires reliable benchmark data. This task becomes particularly formidable for low-resource languages, where obtaining or curating such data poses significant challenges. Addressing this issue, HASOC 2023 organised various shared tasks focused on identifying offensive content in low-resource languages. This paper reports on tasks for hate speech detection in several Indo-Aryan languages - Assamese, Bengali, Gujarati, and Sinhala as well as a Sino-Tibetan language, Bodo, for which limited linguistic resources currently exist. The shared task involved the compilation of multiple datasets. In total, nearly 200 runs were submitted by more than 30 teams, which are presented and analysed in this report.  © 2023 Owner/Author.},
	author_keywords = {Assamese; Bengali; Bodo; Gujarati; Hate speech; Multilingual Datasets; Sinhala; Social media; Under-resourced languages},
	keywords = {Fires; Information retrieval; Speech recognition; Assamese; Bengalis; Bodo; Gujarati; Hate speech; Low resource languages; Multilingual dataset; Sinhalum; Social media; Under-resourced languages; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 15th Annual Meeting of the Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 197196}
}

@ARTICLE{Yuan20231081,
	author = {Yuan, Lanqin and Wang, Tianyu and Ferraro, Gabriela and Suominen, Hanna and Rizoiu, Marian-Andrei},
	title = {Transfer learning for hate speech detection in social media},
	year = {2023},
	journal = {Journal of Computational Social Science},
	volume = {6},
	number = {2},
	pages = {1081 – 1101},
	doi = {10.1007/s42001-023-00224-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174225695&doi=10.1007%2fs42001-023-00224-9&partnerID=40&md5=545bcbaff523f11a1df77a4e8fa8e5d6},
	affiliations = {University of Technology Sydney, Sydney, NSW, Australia; The Australian National University, Canberra, ACT, Australia; University of Turku (UTU), Southwest Finland, Turku, Finland},
	abstract = {Today, the internet is an integral part of our daily lives, enabling people to be more connected than ever before. However, this greater connectivity and access to information increase exposure to harmful content, such as cyber-bullying and cyber-hatred. Models based on machine learning and natural language offer a way to make online platforms safer by identifying hate speech in web text autonomously. However, the main difficulty is annotating a sufficiently large number of examples to train these models. This paper uses a transfer learning technique to leverage two independent datasets jointly and builds a single representation of hate speech. We build an interpretable two-dimensional visualization tool of the constructed hate speech representation—dubbed the Map of Hate—in which multiple datasets can be projected and comparatively analyzed. The hateful content is annotated differently across the two datasets (racist and sexist in one dataset, hateful and offensive in another). However, the common representation successfully projects the harmless class of both datasets into the same space and can be used to uncover labeling errors (false positives). We also show that the joint representation boosts prediction performances when only a limited amount of supervision is available. These methods and insights hold the potential for safer social media and reduce the need to expose human moderators and annotators to distressing online messaging. © 2023, The Author(s).},
	author_keywords = {Domain adaptation; Hate speech; Offensive speech; Transfer learning; Twitter; Visualization},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Sharif202427225,
	author = {Sharif, Waqas and Abdullah, Saima and Iftikhar, Saman and Al-Madani, Daniah and Mumtaz, Shahzad},
	title = {Enhancing Hate Speech Detection in the Digital Age: A Novel Model Fusion Approach Leveraging a Comprehensive Dataset},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {27225 – 27236},
	doi = {10.1109/ACCESS.2024.3367281},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186104352&doi=10.1109%2fACCESS.2024.3367281&partnerID=40&md5=41e839098be973e2f15f7b7bd7e7c9ff},
	affiliations = {Arab Open University, Faculty of Computer Studies, Riyadh, 11681, Saudi Arabia; The Islamia University of Bahawalpur, Faculty of Computing, Bahawalpur, 6300, Pakistan; University of Aberdeen, School of Natural and Computing Sciences, Aberdeen, AB24 3FX, United Kingdom},
	abstract = {In the era of digital communication, social media platforms have experienced exponential growth, becoming primary channels for information exchange. However, this surge has also amplified the rapid spread of hate speech, prompting extensive research efforts for effective mitigation. These efforts have prominently featured advanced natural language processing techniques, particularly emphasizing deep learning methods that have shown promising outcomes. This article presents a novel approach to address this pressing issue, combining a comprehensive dataset of 18 sources. It includes 0.45 million comments sourced from various digital platforms spanning different time frames. There were two models utilized to address the diversity in the data and leverage distinct strengths found within deep learning frameworks: CNN and BiLSTM with an attention mechanism. These models were tailored to handle specific subsets of the data, allowing for a more targeted approach. The unique outputs from both models were then fused into a unified model. This methodology outperformed recent models, showcasing enhanced generalization capabilities even when tested on the largest and most diverse dataset. Our model achieved an impressive accuracy of 89%, while maintaining a high precision of 0.88 and recall of 0.91.  © 2013 IEEE.},
	author_keywords = {BiLSTM; CNN; deep learning; Hate speech detection; model fusion; natural language processing},
	keywords = {Blogs; Data structures; Deep neural networks; Digital communication systems; Job analysis; Social networking (online); Speech recognition; BiLSTM; Context models; Convolutional neural network; Deep learning; Detection algorithm; Hate speech; Hate speech detection; Language processing; Model fusion; Natural language processing; Natural languages; Social networking (online); Speech detection; Task analysis; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Pamungkas202385,
	author = {Pamungkas, Endang Wahyu and Purworini, Dian and Priyawati, Diah and Chasana, Rona Rizkhy Bunga},
	title = {Exploring the Impact of Lexicon-based Knowledge Transfer for Hate Speech Detection in Indonesia Code-Mixed Languages},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {85 – 90},
	doi = {10.1145/3639233.3639247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187554833&doi=10.1145%2f3639233.3639247&partnerID=40&md5=13f3205b9445f410b44399ae3707579b},
	affiliations = {Informatics Engineering Department, Universitas Muhammadiyah Surakarta, Indonesia and Social Informatics Research Center, Universitas Muhammadiyah Surakarta, Indonesia; Communication Science Department, Universitas Muhammadiyah Surakarta, Indonesia and Social Informatics Research Center, Universitas Muhammadiyah Surakarta, Indonesia; Informatics Engineering Department, Universitas Muhammadiyah Surakarta, Indonesia},
	abstract = {In this study, our objective is to examine the influence of external knowledge from a lexicon on knowledge transfer for mitigating the language shift issue in the detection of hate speech in code-mixed languages. To accomplish this, we constructed a lexicon based on findings from previous studies. Subsequently, we implemented several machine learning models with various scenarios to assess the impact of the lexicon. The experimental results demonstrate that incorporating lexicon features leads to improved performance in detecting hate speech within code-mixed languages. Particularly, utilizing a lexicon that encompasses both implicit and explicit lexicons yields the most favorable outcomes in this investigation. This research provides valuable insights into understanding the detection of hate speech in code-mixed Indonesian languages and contributes to the advancement of more robust systems aimed at fostering a safer and more inclusive online environment. By leveraging the lexicon and exploring the interplay between implicit and explicit elements in hate speech, this study enhances our understanding of addressing hate speech challenges in Indonesia code-mixed languages and paves the way for developing more effective detection mechanisms. © 2023 ACM.},
	author_keywords = {code-mixed languages; hate speech detection; knowledge transfer; lexicon},
	keywords = {Codes (symbols); Knowledge management; Online systems; Code-mixed language; External knowledge; Hate speech detection; Indonesia; Knowledge transfer; Lexicon; Lexicon-based; Machine learning models; Performance; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Natural Language Processing and Information Retrieval, NLPIR 2023; Conference date: 15 December 2023 through 17 December 2023; Conference code: 197810}
}

@ARTICLE{Kaur2024104,
	author = {Kaur, Simrat and Singh, Sarbjeet and Kaushal, Sakshi},
	title = {Deep learning-based approaches for abusive content detection and classification for multi-class online user-generated data},
	year = {2024},
	journal = {International Journal of Cognitive Computing in Engineering},
	volume = {5},
	pages = {104 – 122},
	doi = {10.1016/j.ijcce.2024.02.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185832720&doi=10.1016%2fj.ijcce.2024.02.002&partnerID=40&md5=2a303f6b249814b0a9cee141b344e710},
	affiliations = {University Institute of Engineering and Technology, Panjab University, Chandigarh, 160014, India},
	abstract = {With the rapid growth of social media culture, the use of offensive or hateful language has surged, which necessitates the development of effective abusive language detection models for online platforms. This paper focuses on developing a multi-class classification model to identify different types of offensive language. The input data is taken in the form of labeled tweets and is classified into offensive language detection, offensive language categorization, and offensive language target identification. The data undergoes pre-processing, which removes NaN value and punctuation, as well as performs tokenization followed by the generation of a word cloud to assess data quality. Further, the tf-idf technique is used for the selection of features. In the case of classifiers, multiple deep learning techniques, namely, bidirectional gated recurrent unit, multi-dense long short-term memory, bidirectional long short-term memory, gated recurrent unit, and long short-term memory, are applied where it has been found that all the models, except long short-term memory, achieved a high accuracy of 99.9 % for offensive language target identification. Bidirectional LSTM and multi-dense LSTM obtained the lowest loss and RMSE values of 0.01 and 0.1, respectively. This research provides valuable insights and contributes to the development of effective abusive language detection methods to promote a safe and respectful online environment. The insights gained can aid platform administrators in efficiently moderating content and taking appropriate actions against offensive language. © 2024},
	author_keywords = {Abusive language; Deep learning models; Gated recurrent unit; Long short term memory; Offensive language; Offensive language categorization; Target identification},
	keywords = {Brain; Classification (of information); Data handling; Learning systems; Abusive language; Deep learning model; Gated recurrent unit; Language detection; Learning models; Learning-based approach; Offensive language categorization; Offensive languages; Target's identifications; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{Sreelakshmi202420064,
	author = {Sreelakshmi, K. and Premjith, B. and Chakravarthi, Bharathi Raja and Soman, K.P.},
	title = {Detection of Hate Speech and Offensive Language CodeMix Text in Dravidian Languages Using Cost-Sensitive Learning Approach},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {20064 – 20090},
	doi = {10.1109/ACCESS.2024.3358811},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184812864&doi=10.1109%2fACCESS.2024.3358811&partnerID=40&md5=890a55f7710e1c46ff5f156db9b254c6},
	affiliations = {Amrita Vishwa Vidyapeetham, Amrita School of Artificial Intelligence, Coimbatore, 641112, India; University of Galway, School of Computer Science, Galway, H91 TK33, Ireland},
	abstract = {Recently, the emergence of social media has opened the way for online harassment in the form of hate speech and offensive language. An automated approach is needed to detect hate and offensive content from social media, which is indispensable. This task is challenging in the case of social media posts or comments in low-resourced CodeMix languages. This paper investigates the efficacy of various multilingual transformer-based embedding models with machine learning classifiers for detecting hate speech and offensive language (HOS) content in social media posts in CodeMix Dravidian languages that belong to the low-resource language group. Experiments were conducted on six sets of openly available datasets in Kannada-English, Malayalam-English and Tamil-English languages. The objective is to identify a single pre-trained embedding model that commonly works well for HOS tasks in the above mentioned languages. For this, a comprehensive study of various multilingual transformer embedding models, such as BERT, DistilBERT, LaBSE, MuRIL, XLM, IndicBERT, and FNET for HOS detection was conducted. Our experiments revealed that MuRIL pre-trained embedding performed consistently well for all six datasets using Support Vector Machine (SVM) with Radial Basis Function (RBF) kernel. In a set of experiments conducted on six datasets, the highest accuracy results for each dataset are as follows: DravidianLangTech 2021 achieved 96% accuracy for Malayalam, 72% accuracy for Tamil, and 66% accuracy for Kannada. For HASOC 2021 Tamil, the accuracy reached 76%, and for HASOC 2021 Malayalam, it reached 68%. Additionally, HASOC 2020 demonstrated an accuracy of 92% for Malayalam. Moreover, we performed an in-depth error analysis and a comparative study, presenting a tabulated summary of our work compared to other top-performing studies. In addition, we employed a cost-sensitive learning approach to address the class imbalance problem in the dataset, in which minority classes get higher classification weights than the majority classes. The weights were initialized and fine-tuned to obtain the best balance between all the classes. The results showed that incorporating the cost-sensitive learning strategy avoided class bias in the trained model. In addition to the aforementioned points, a significant contribution of our research presented in this paper is introducing a novel annotated test set for Malayalam-English CodeMix. This new dataset serves as an extension to our existing data, known as the Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC) 2021 Malayalam-English dataset. © 2013 IEEE.},
	author_keywords = {bidirectional encoder representations from transformers; CodeMix; hate speech; IndicBERT; language-agnostic BERT sentence embedding; machine learning; multilingual representations for Indian languages; Natural language processing; offensive language},
	keywords = {Classification (of information); Cost benefit analysis; Encoding (symbols); Natural language processing systems; Radial basis function networks; Signal encoding; Social networking (online); Speech recognition; Support vector machines; Bidirectional control; Bidirectional encoder representation from transformer; Codemix; Embeddings; Encodings; Features extraction; Hate speech; Indian languages; IndicBERT; Language processing; Language-agnostic BERT sentence embedding; Machine-learning; Multilingual representation for indian language; Natural language processing; Natural languages; Offensive languages; Social networking (online); Task analysis; Transformer; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Mukherjee2023278,
	author = {Mukherjee, Swapnanil and Das, Sujit},
	title = {Application of Transformer-Based Language Models to Detect Hate Speech in Social Media},
	year = {2023},
	journal = {Journal of Computational and Cognitive Engineering},
	volume = {2},
	number = {4},
	pages = {278 – 286},
	doi = {10.47852/bonviewJCCE2022010102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188126546&doi=10.47852%2fbonviewJCCE2022010102&partnerID=40&md5=bfb93390e03bf3f748e9d0fa056d29ed},
	affiliations = {Department of Computer Science, Ashoka University, India; Department of Computer Science and Engineering, National Institute of Technology Warangal, India},
	abstract = {Detecting and removing hateful speech in various online social media is a challenging task. Researchers tried to solve this problem by using both classical and deep learning methods, which are found to have limitations in terms of the requirement of extensive hand-crafted features, model architecture design, and pretrained embeddings, that are not very proficient in capturing semantic relations between words. Therefore, in this paper, we tackle the problem using Transformer-based pretrained language models which are specially designed to produce contextual embeddings of text sequences. We have evaluated two such models—RoBERTa and XLNet—using four publicly available datasets from different social media platforms and compared them to the existing baselines. Our investigation shows that the Transformer-based models either surpass or match all of the existing baseline scores by significant margins obtained by previously used models such as 1-dimensional convolutional neural network (1D-CNN) and long short-term memory (LSTM). The Transformer-based models proved to be more robust by achieving native performance when trained and tested on two different datasets. Our investigation also revealed that variations in the characteristics of the data produce significantly different results with the same model. From the experimental observations, we are able to establish that Transformer-based language models exhibit superior performance than their conventional counterparts at a fraction of the computation cost and minimal need for complex model engineering. © The Author(s) 2021.},
	author_keywords = {fine-tuning; hate speech; natural language processing; RoBERTa; social media; transformer; XLNet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Song2023,
	author = {Song, Rui and Giunchiglia, Fausto and Li, Yingji and Shi, Lida and Xu, Hao},
	title = {Measuring and mitigating language model biases in abusive language detection},
	year = {2023},
	journal = {Information Processing and Management},
	volume = {60},
	number = {3},
	doi = {10.1016/j.ipm.2023.103277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147538507&doi=10.1016%2fj.ipm.2023.103277&partnerID=40&md5=03513ac9872e0acf65ae77d648c1c240},
	affiliations = {School of Artificial Intelligence, Jilin University, Changchun, 130012, China; College of Computer Science and Technology, Jilin University, Changchun, 130012, China; Department of Information Engineering and Computer Science, University of Trento, Italy; Chongqing Research Institute, Jilin University, Chongqing, 401123, China},
	abstract = {Warning: This paper contains abusive samples that may cause discomfort to readers. Abusive language on social media reinforces prejudice against an individual or a specific group of people, which greatly hampers freedom of expression. With the rise of large-scale pre-trained language models, classification based on pre-trained language models has gradually become a paradigm for automatic abusive language detection. However, the effect of stereotypes inherent in language models on the detection of abusive language remains unknown, although this may further reinforce biases against the minorities. To this end, in this paper, we use multiple metrics to measure the presence of bias in language models and analyze the impact of these inherent biases in automatic abusive language detection. On the basis of this quantitative analysis, we propose two different debiasing strategies, token debiasing and sentence debiasing, which are jointly applied to reduce the bias of language models in abusive language detection without degrading the classification performance. Specifically, for the token debiasing strategy, we reduce the discrimination of the language model against protected attribute terms of a certain group by random probability estimation. For the sentence debiasing strategy, we replace protected attribute terms and augment the original text by counterfactual augmentation to obtain debiased samples, and use the consistency regularization between the original data and the augmented samples to eliminate the bias at the sentence level of the language model. The experimental results confirm that our method can not only reduce the bias of the language model in the abusive language detection task, but also effectively improve the performance of abusive language detection. © 2023 Elsevier Ltd},
	author_keywords = {Abusive language detection; Debias; Language model},
	keywords = {Abusive language detection; De-biasing; Debias; Language analysis; Language detection; Language model; Large-scales; Model bias; Model classification; Social media; Computational linguistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Montesinos-Cánovas202315,
	author = {Montesinos-Cánovas, Esteban and García-Sánchez, Francisco and García-Díaz, José Antonio and Alcaraz-Mármol, Gema and Valencia-García, Rafael},
	title = {Spanish hate-speech detection in football; [Detección de odio en fútbol en español]},
	year = {2023},
	journal = {Procesamiento del Lenguaje Natural},
	number = {71},
	pages = {15 – 27},
	doi = {10.26342/2023-71-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175057125&doi=10.26342%2f2023-71-1&partnerID=40&md5=eeee2e5dc18cbcb69b77837f0f03d320},
	affiliations = {Departamento de Informática y Sistemas, Facultad de Informática, Universidad de Murcia, Spain; Departamento de Filología Moderna, Universidad de Castilla-La Mancha, Spain},
	abstract = {In the last few years, Natural Language Processing (NLP) tools have been successfully applied to a number of different tasks, including author profiling, negation detection or hate speech detection, to name but a few. For the identification of hate speech from text, pre-trained language models can be leveraged to build high-performing classifiers using a transfer learning approach. In this work, we train and evaluate state-of-the-art pre-trained classifiers based on Transformers. The explored models are fine-tuned using a hate speech corpus in Spanish that has been compiled as part of this research. The corpus contains a total of 7,483 football-related tweets that have been manually annotated under four categories: aggressive, racist, misogynist, and safe. A multi-label approach is used, allowing the same tweet to be labeled with more than one class. The best results, with a macro F1-score of 88.713%, have been obtained by a combination of the models using Knowledge Integration. ©2023 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {Hate speech detection; Interpretability; Large Language Models; Linguistic features},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Mohamed20236381,
	author = {Mohamed, Mohamed S. and Elzayady, Hossam and Badran, Khaled M. and Salama, Gouda I.},
	title = {An efficient approach for data-imbalanced hate speech detection in Arabic social media},
	year = {2023},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {45},
	number = {4},
	pages = {6381 – 6390},
	doi = {10.3233/JIFS-231151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173859107&doi=10.3233%2fJIFS-231151&partnerID=40&md5=74928c29f37c4e0275f00d8e7bda7379},
	affiliations = {Department of Computer Engineering and Artificial Intelligence, Military Technical College, Egypt},
	abstract = {The use of hateful language in public debates and forums is becoming more common. However, this might result in antagonism and conflicts among individuals, which is undesirable in an online environment. Countries, businesses, and educational institutions are exerting their greatest efforts to develop effective solutions to manage this issue. In addition, recognizing such content is difficult, particularly in Arabic, due to a variety of challenges and constraints. Long-tailed data distribution is often one of the most significant issues in actual Arabic hate speech datasets. Pre-trained models, such as bidirectional encoder representations from transformers (BERT) and generative pre-trained transformers (GPT), have become more popular in numerous natural language processing (NLP) applications in recent years. We conduct extensive experiments to address data imbalance issues by utilizing oversampling methods and a focal loss function in addition to traditional loss functions. Quasi-recurrent neural networks (QRNN) are employed to fine-tune the cutting-edge transformer-based models, MARBERTv2, MARBERTv1, and ARBERT. In this context, we suggest a new approach using ensemble learning that incorporates best-performing models for both original and oversampled datasets. Experiments proved that our proposed approach achieves superior performance compared to the most advanced methods described in the literature.  © 2023 - IOS Press. All rights reserved.},
	author_keywords = {Arabic hate speech; ensemble learning; oversampling method; Text classification; transformers},
	keywords = {Classification (of information); Learning algorithms; Natural language processing systems; Recurrent neural networks; Social networking (online); Speech recognition; Text processing; Arabic hate speech; Ensemble learning; Loss functions; Over sampling; Oversampling method; Public debate; Social media; Speech detection; Text classification; Transformer; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Chopra2023,
	author = {Chopra, Abhishek and Sharma, Deepak Kumar and Jha, Aashna and Ghosh, Uttam},
	title = {A Framework for Online Hate Speech Detection on Code-mixed Hindi-English Text and Hindi Text in Devanagari},
	year = {2023},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {22},
	number = {5},
	doi = {10.1145/3568673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162092055&doi=10.1145%2f3568673&partnerID=40&md5=d8a449357016ad28de4f71b93fce34a7},
	affiliations = {Department of Information Technology, Netaji Subash University of Technology, New Delhi, Delhi, 110078, India; Department of Information Technology, Indira Gandhi Delhi Technical University for Women, New Delhi, Delhi, 110078, India; Department of Electronics and Communications Engineering, Netaji Subash University of Technology, New Delhi, Delhi, 110078, India; Department of Computer Science and Data Science, Meharry School of Applied Computational Sciences, Nashville, 37240, TN, United States},
	abstract = {Social Media has been growing and has provided the world with a platform to opine, debate, display, and discuss like never before. It has a major influence in research areas that analyze human behavior and social groups, and the phenomenon of social interactions is even being used in areas such as Internet of Things. This constant stream of data connecting individuals and organizations across the globe has had a tremendous impact on the functioning of society and even has the power to sway elections. Despite having numerous benefits, social media has certain issues such as the prevalence of fake news, which has also led to the rise of the hate speech phenomenon. Due to lax security throughout these social media platforms, these issues continue to exist without any repercussions. This leads to cyberbullying, defamation, and presents grave security concerns. Even though some work has been done independently on native scripts, hate speech detection, and code-mixed data, there exists a lack of academic work and research in the area of detecting hate speech in transliterated code-mixed data and in-text containing native language scripts. Research in this field is inhibited greatly due to the multiple variations in grammar and spelling and in general a lack of availability of annotated datasets, especially when it comes to native languages. This article comes up with a method to automate hate speech detection in code-mixed and native language text. The article presents an architecture containing a Tabnet classifier-based model trained on features extracted using MuRIL from transliterated code-mixed textual data. The article also shows that the same model works well on features extracted from text in Devanagari despite being trained on transliterated data.  © 2023 Association for Computing Machinery.},
	author_keywords = {code-mixing; Cyber security; cyber security systems; hate speech detection; Hindi text classification; natural language processing; TabNet},
	keywords = {Behavioral research; Classification (of information); Codes (symbols); Cybersecurity; Data mining; Fake detection; Natural language processing systems; Online systems; Speech recognition; Text processing; Code-mixing; Cybe security system; Cyber security; Hate speech detection; Hindi text classification; Language processing; Natural language processing; Natural languages; Speech detection; Tabnet; Text classification; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Kumar2024617,
	author = {Kumar, Ashwini and Kumar, Santosh},
	title = {Optimized Deep Neural Networks Using Sparrow Search Algorithms for Hate Speech Detection},
	year = {2024},
	journal = {International Journal of Computing and Digital Systems},
	volume = {15},
	number = {1},
	pages = {617 – 626},
	doi = {10.12785/ijcds/150145},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186570588&doi=10.12785%2fijcds%2f150145&partnerID=40&md5=c449860da584c4e4dd3c9b7b86bd0430},
	affiliations = {Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, India},
	abstract = {Deep learning has widespread use in various domains, including computer vision, audio processing, and natural language processing. The hyperparameters of deep learning algorithms have a significant impact on the performance of these algorithms. However, it can be challenging to calculate the hyperparameters of complicated machine learning models like deep neural networks due to the nature of the models. This research suggested a strategy for hyperparameter optimization utilizing the Long Short-Term Memory with Sparrow Search Algorithm (LSTM-SSA) model. The model that has been presented uses a deep neural network, which can recognize and classify instances of hate speech as either hate speech or neither. Experiments are conducted to validate the suggested technique in both straightforward and intricate network environments. The LSTM-SSA model is validated using a dataset consisting of hate speech, and an experimental investigation into the model’s sensitivity, accuracy, and specificity is carried out. The outcomes of the experiments demonstrated that the suggested model might be improved upon, as it had an accuracy of 0.936. © 2024 University of Bahrain. All rights reserved.},
	author_keywords = {Hate speech; LSTM; NLP; social media; Sparrow Search Algorithm},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Khan20245210,
	author = {Khan, Anas Ali and Iqbal, M. Hammad and Nisar, Shibli and Ahmad, Awais and Iqbal, Waseem},
	title = {Offensive Language Detection for Low Resource Language Using Deep Sequence Model},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {4},
	pages = {5210 – 5218},
	doi = {10.1109/TCSS.2023.3280952},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162852722&doi=10.1109%2fTCSS.2023.3280952&partnerID=40&md5=ca2a719a3d613803ab371364244b079a},
	affiliations = {National University of Sciences and Technology (NUST), Department of Information Security, Islamabad, 44000, Pakistan; Imam Mohammed Ibn Saud Islamic University, College of Computer and Information Sciences, Information Systems Department, Riyadh, 11586, Saudi Arabia},
	abstract = {Social media platforms are heavily used by people to express their views in their native languages. Besides positive views, people often use abusive or offensive language to express their anger or frustration. Resource-rich languages have offensive language detection systems which automatically monitor and block offensive content, however, they are very rare for low-resourced languages. This is because of the nonavailability of datasets for local languages. This article proposes a model which automatically detects offensive language for a very low-resource language, i.e., Pashto. The Roman Pashto dataset is created by picking 60 thousand comments from different social media and labeling them manually. The proposed model is trained and tested using three different feature extraction approaches, i.e., bag-of-words (BoW), term frequency-inverse document frequency (TF-IDF), and sequence integer encoding. Four traditional classifiers and a deep sequence model are used to train on this task. Experimental result shows that the random forest classifier works best and give 94.07 % testing accuracy on a combination of unigrams, bigrams, and trigrams. The same classifier gives maximum accuracy of 93.90 % with TF-IDF. However, the overall highest testing accuracy of 97.21% is achieved by using bidirectional long short-term memory (BLSTM). The corpus created in this work is made available for the researcher working in this domain. © 2014 IEEE.},
	author_keywords = {Bag-of-words (BoW); deep neural networks (DNNs); long short-term memory (LSTM); offensive language; Pashto; term frequency-inverse document frequency (TF-IDF)},
	keywords = {Brain; Deep neural networks; Extraction; Feature extraction; Learning systems; Social networking (online); Text processing; Video on demand; Bag of words; Bag-of-word; Cyber bullying; Deep neural network; Features extraction; Long short-term memory; Machine-learning; Offensive languages; Pashto; Term frequency-inverse document frequency; Term frequencyinverse document frequency (TF-IDF); Text categorization; Video; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Firmino2024,
	author = {Firmino, Anderson Almeida and de Souza Baptista, Cláudio and de Paiva, Anselmo Cardoso},
	title = {Improving hate speech detection using Cross-Lingual Learning},
	year = {2024},
	journal = {Expert Systems with Applications},
	volume = {235},
	doi = {10.1016/j.eswa.2023.121115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168546171&doi=10.1016%2fj.eswa.2023.121115&partnerID=40&md5=7457cec625d24e5da165318e7b1c144d},
	affiliations = {Federal University of Campina Grande, Rua Aprigio Veloso, 882 - Universitário, Paraiba, Campina Grande, Brazil; Federal University of Maranhão, Av. dos Portugueses, 1966 - Vila Bacanga, Maranhão, São Luís, Brazil},
	abstract = {The growth of social media worldwide has brought social benefits and challenges. One problem we highlight is the proliferation of hate speech on social media. We propose a novel method for detecting hate speech in texts using Cross-Lingual Learning. Our approach uses transfer learning from Pre-Trained Language Models (PTLM) with large corpora available to solve problems in languages with fewer resources for the specific task. The proposed methodology comprises four stages: corpora acquisition, the PTLM definition, training strategies, and evaluation. We carried out experiments using Pre-Trained Language Models in English, Italian, and Portuguese (BERT and XLM-R) to verify which best suited the proposed method. We used corpora in English (WH) and Italian (Evalita 2018) as the source language and the OffComBr-2 corpus in Portuguese (the target language). The results of the experiments showed that the proposed methodology is promising: for the OffComBr-2 corpus, the best state-of-the-art result was obtained (F1-measure = 92%). © 2023 Elsevier Ltd},
	author_keywords = {Cross-Lingual Learning; Deep learning; Hate speech detection; Natural language processing; Social media},
	keywords = {Deep learning; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Transfer learning; Cross-lingual; Cross-lingual learning; Deep learning; Hate speech detection; Language model; Language processing; Natural language processing; Natural languages; Social media; Speech detection; Computational linguistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{Al Ghozali2023600,
	author = {Al Ghozali, Isnen Hadi and Pirman, Arif and Indra, Indra},
	title = {Comparison of SVM and Naïve Bayes Algorithms with InNER Enriched to Predict Hate Speech},
	year = {2023},
	journal = {El-Cezeri Journal of Science and Engineering},
	volume = {10},
	number = {3},
	pages = {600 – 611},
	doi = {10.31202/ecjse.1325078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174893854&doi=10.31202%2fecjse.1325078&partnerID=40&md5=bfb0b976440800548c33ccd9cdd44bf0},
	affiliations = {Fakultas Teknologi Informasi, Universitas Budi Luhur, Jakarta, Indonesia},
	abstract = {Hate speech is one of the negative sides of social media abuse. Hate speech can be classified into insults, defamation, unpleasant acts, provoking, inciting, and spreading fake news (hoax). The purpose of this study is to compare the SVM and Naïve Bayes methods with feature extraction in the form of Indonesian NER (InNER) for detecting hate speech. To obtain the best model, this study applies five steps: a) data collection; b) data preprocessing; c) feature engineering; d) model development; and e) evaluating and comparing models. In this study, we have collected 7100 tweets as an initial dataset. After manual annotation, this study produced 1681 tweets: 548 insult tweets, 288 blasphemy tweets, 272 provocative tweets, and 573 neutral tweets. This study use two Python libraries that accommodate NER in Indonesian, namely the NLTK library and the Polyglot library. Based on the results of the evaluation of the proposed model, model 5, which develops the SVM algorithm with the NLTK library, is the best model proposed. This model shows an accuracy score of 92.88% with a precision of 0.93, a recall of 0.93, and an F-1 score of 0.92. © 2023, TUBITAK. All rights reserved.},
	author_keywords = {Hate Speech; Naïve Bayes; NER; SVM},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Arya202422359,
	author = {Arya, Greeshma and Hasan, Mohammad Kamrul and Bagwari, Ashish and Safie, Nurhizam and Islam, Shayla and Ahmed, Fatima Rayan Awad and De, Aaishani and Khan, Muhammad Attique and Ghazal, Taher M.},
	title = {Multimodal Hate Speech Detection in Memes Using Contrastive Language-Image Pre-Training},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {22359 – 22375},
	doi = {10.1109/ACCESS.2024.3361322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184319075&doi=10.1109%2fACCESS.2024.3361322&partnerID=40&md5=d838fbe148ae3a3a9721bd3ea586a3a1},
	affiliations = {Indira Gandhi Delhi Technical University for Women, Department of Electronics and Communication Engineering, New Delhi, 110006, India; Universiti Kebangsaan Malaysia (UKM), Faculty of Information Science and Technology, Selangor, Bangi, 43600, Malaysia; Uttarakhand Technical University, Department of Electronics and Communication Engineering, Dehradun, 248007, India; Institute of Computer Science and Digital Innovation, UCSI University Malaysia, Kuala Lumpur, 56000, Malaysia; Prince Sattam Bin Abdulaziz University, College of Computer Engineering and Science, Computer Science Department, Al-Kharj, 16273, Saudi Arabia; HITEC University, Department of Computer Science, Taxila, 47080, Pakistan; Lebanese American University, Department of CS and Mathematics, Beirut, 1102 2801, Lebanon; Khalifa University, Centre for Cyber Physical Systems, Computer Science Department, Abu Dhabi, United Arab Emirates; Universiti Kebangsaan Malaysia (UKM), Center for Cyber Security, Faculty of Information Science and Technology, Selangor, Bangi, 43600, Malaysia; Applied Science Private University, Applied Science Research Center, Amman, 11937, Jordan},
	abstract = {In contemporary society, the proliferation of online hateful messages has emerged as a pressing concern, inflicting deleterious consequences on both societal fabric and individual well-being. The automatic detection of such malevolent content online using models designed to recognize it, holds promise in mitigating its harmful impact. However, the advent of 'Hateful Memes' poses fresh challenges to the detection paradigm, particularly within the realm of deep learning models. These memes, constituting of a textual element associated with an image are individually innocuous but their combination causes a detrimental effect. Consequently, entities responsible for disseminating information via web browsers are compelled to institute mechanisms that regulate and automatically filter out such injurious content. Effectively identifying hateful memes demands algorithms and models endowed with robust vision and language fusion capabilities, capable of reasoning across diverse modalities. This research introduces a novel approach by leveraging the multimodal Contrastive Language-Image Pre-Training (CLIP) model, fine-tuned through the incorporation of prompt engineering. This innovative methodology achieves a commendable accuracy of 87.42%. Comprehensive metrics such as loss, AUROC, and f1 score are also meticulously computed, corroborating the efficacy of the proposed strategy. Our findings suggest that this approach presents an efficient means to regulate the dissemination of hate speech in the form of viral meme content across social networking platforms, thereby contributing to a safer online environment. © 2013 IEEE.},
	author_keywords = {CLIP; contrastive learning; cosine similarity matrix; facebook hateful meme dataset; InfoNCE contrastive loss; multimodal; prompt engineering; zero-shot prediction},
	keywords = {Biological systems; Deep learning; Information dissemination; Modeling languages; User profile; Web browsers; Zero-shot learning; Biological system modeling; Context models; Contrastive language-image pre-training; Contrastive learning; Cosine similarity; Cosine similarity matrix; Facebook; Facebook hateful meme dataset; Features extraction; Hate speech; InfoNCE contrastive loss; Multi-modal; Pre-training; Predictive models; Prompt engineering; Similarity matrix; Task analysis; Zero-shot prediction; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Al-Hussaeni2023,
	author = {Al-Hussaeni, Khalil and Sameer, Mohamed and Karamitsos, Ioannis},
	title = {The Impact of Data Pre-Processing on Hate Speech Detection in a Mix of English and Hindi–English (Code-Mixed) Tweets},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {19},
	doi = {10.3390/app131911104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174182233&doi=10.3390%2fapp131911104&partnerID=40&md5=c0a73f4b66d93a4d68d7085339a5b61a},
	affiliations = {Computing Sciences, Rochester Institute of Technology, Dubai, 341055, United Arab Emirates; Graduate Programs and Research, Rochester Institute of Technology, Dubai, 341055, United Arab Emirates},
	abstract = {Due to the increasing reliance on social network platforms in recent years, hate speech has risen significantly among online users. Government and social media platforms face the challenging responsibility of controlling, detecting, and removing massively growing hateful content as early as possible to prevent future criminal acts, such as cyberviolence and real-life hate crimes. Twitter is used globally by people from various backgrounds and nationalities; it contains tweets posted in different languages, including code-mixed language, such as Hindi–English. Due to the informal format of tweets with variations in spelling and grammar, hate speech detection is especially challenging in code-mixed text. In this paper, we tackle the critical issue of hate speech detection on social media, with a focus on a mix of English and Hindi–English (code-mixed) text messages on Twitter. More specifically, we aim to evaluate the impact of data pre-processing on hate speech detection. Our method first performs 10-step data cleansing; then, it builds a detection method based on two architectures, namely a convolutional neural network (CNN) and a combination of CNN and long short-term Memory (LSTM) algorithms. We tune the hyperparameters of the proposed model architectures and conduct extensive experimental analysis on real-life tweets to evaluate the performance of the models in terms of accuracy, efficiency, and scalability. Moreover, we compare our method with a closely related hate speech detection method from the literature. The experimental results suggest that our method results in an improved accuracy and a significantly improved runtime. Among our best-performing models, CNN-LSTM improved accuracy by nearly 2% and decreased the runtime by almost half. © 2023 by the authors.},
	author_keywords = {code-mixed; hate speech; multilingual; neural networks; speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Bilal2023,
	author = {Bilal, Muhammad and Khan, Atif and Jan, Salman and Musa, Shahrulniza and Ali, Shaukat},
	title = {Roman Urdu Hate Speech Detection Using Transformer-Based Model for Cyber Security Applications},
	year = {2023},
	journal = {Sensors},
	volume = {23},
	number = {8},
	doi = {10.3390/s23083909},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153939788&doi=10.3390%2fs23083909&partnerID=40&md5=76c04d5744e58f852deed905e817b508},
	affiliations = {Department of Computer Science, Islamia College Peshawar, Peshawar, 25130, Pakistan; Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, 50250, Malaysia; Department of Computer Science, Bacha Khan University Charsadda, Charsadda, 24420, Pakistan},
	abstract = {Social media applications, such as Twitter and Facebook, allow users to communicate and share their thoughts, status updates, opinions, photographs, and videos around the globe. Unfortunately, some people utilize these platforms to disseminate hate speech and abusive language. The growth of hate speech may result in hate crimes, cyber violence, and substantial harm to cyberspace, physical security, and social safety. As a result, hate speech detection is a critical issue for both cyberspace and physical society, necessitating the development of a robust application capable of detecting and combating it in real-time. Hate speech detection is a context-dependent problem that requires context-aware mechanisms for resolution. In this study, we employed a transformer-based model for Roman Urdu hate speech classification due to its ability to capture the text context. In addition, we developed the first Roman Urdu pre-trained BERT model, which we named BERT-RU. For this purpose, we exploited the capabilities of BERT by training it from scratch on the largest Roman Urdu dataset consisting of 173,714 text messages. Traditional and deep learning models were used as baseline models, including LSTM, BiLSTM, BiLSTM + Attention Layer, and CNN. We also investigated the concept of transfer learning by using pre-trained BERT embeddings in conjunction with deep learning models. The performance of each model was evaluated in terms of accuracy, precision, recall, and F-measure. The generalization of each model was evaluated on a cross-domain dataset. The experimental results revealed that the transformer-based model, when directly applied to the classification task of the Roman Urdu hate speech, outperformed traditional machine learning, deep learning models, and pre-trained transformer-based models in terms of accuracy, precision, recall, and F-measure, with scores of 96.70%, 97.25%, 96.74%, and 97.89%, respectively. In addition, the transformer-based model exhibited superior generalization on a cross-domain dataset. © 2023 by the authors.},
	author_keywords = {BERT; BiLSTM; CNN; cyber security; deep learning; hate speech; LSTM; natural language processing (NLP); Roman Urdu; social media; transformer models},
	keywords = {Awareness; Computer Security; Hate; Humans; Language; Speech; Cybersecurity; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Text processing; BERT; BiLSTM; Cyber security; Deep learning; Hate speech; Language processing; LSTM; Natural language processing; Natural languages; Roman urdu; Social media; Transformer modeling; awareness; computer security; hate; human; language; speech; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Gold Open Access}
}

@ARTICLE{Madhu2023,
	author = {Madhu, Hiren and Satapara, Shrey and Modha, Sandip and Mandl, Thomas and Majumder, Prasenjit},
	title = {Detecting offensive speech in conversational code-mixed dialogue on social media: A contextual dataset and benchmark experiments},
	year = {2023},
	journal = {Expert Systems with Applications},
	volume = {215},
	doi = {10.1016/j.eswa.2022.119342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145576108&doi=10.1016%2fj.eswa.2022.119342&partnerID=40&md5=abea29bea8c803920b9ef89a1d139dc7},
	affiliations = {Indian Institute of Science, Bangalore, India; DAIICT, Gujarat, Gandhinagar, India; LDRP-ITR, Gujarat, Gandhinagar, India; University of Hildesheim, Hildesheim, Germany; TCG CREST, Kolkata, India; Indian Institute of Technology, Hyderabad, India},
	abstract = {The spread of Hate Speech on online platforms is a severe issue for societies and requires the identification of offensive content by platforms. Research has modeled Hate Speech recognition as a text classification problem that predicts the class of a message based on the text of the message only. However, context plays a huge role in communication. In particular, for short messages, the text of the preceding tweets can completely change the interpretation of a message within a discourse. This work extends previous efforts to classify Hate Speech by considering the current and previous tweets jointly. In particular, we introduce a clearly defined way of extracting context. We present the development of the first dataset for conversational-based Hate Speech classification with an approach for collecting context from long conversations for code-mixed Hindi (ICHCL dataset). Overall, our benchmark experiments show that the inclusion of context can improve classification performance over a baseline. Furthermore, we develop a novel processing pipeline for processing the context. The best-performing pipeline uses a fine-tuned SentBERT paired with an LSTM as a classifier. This pipeline achieves a macro F1 score of 0.892 on the ICHCL test dataset. Another KNN, SentBERT, and ABC weighting-based pipeline yields an F1 Macro of 0.807, which gives the best results among traditional classifiers. So even a KNN model gives better results with an optimized BERT than a vanilla BERT model. © 2022 Elsevier Ltd},
	author_keywords = {Benchmark; Conversational Analysis; Evaluation; Hate Speech; Natural Language Processing; Transformer},
	keywords = {Benchmarking; Character recognition; Classification (of information); Codes (symbols); Long short-term memory; Natural language processing systems; Pipeline processing systems; Social networking (online); Speech recognition; Statistical tests; Text processing; Benchmark; Benchmark experiments; Conversational analysis; Evaluation; Hate speech; Language processing; Natural language processing; Natural languages; Social media; Transformer; Pipelines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36}
}

@CONFERENCE{Shanmugavadivel2024146,
	author = {Shanmugavadivel, Kogilavani and Sowbarnigaa, K.S. and Sakthi, Mehal M.S. and Subhadevi, K. and Subramanian, Malliga},
	title = {MIT-KEC-NLP@DravidianLangTech-EACL 2024: Offensive Content Detection in Kannada and Kannada-English Mixed Text Using Deep Learning Techniques},
	year = {2024},
	journal = {DravidianLangTech 2024 - 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, Proceedings of the Workshop},
	pages = {146 – 150},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189854369&partnerID=40&md5=62be4a1a6c5752053749579e0cccf9aa},
	affiliations = {Department of AI, Kongu Engineering College, Perundurai, Erode, India},
	abstract = {This study presents a strong methodology for detecting offensive content in multilingual text, with a focus on Kannada and Kannada-English mixed comments. The first step in data pre-processing is to work with a dataset containing Kannada comments, which is backed by Google Translate for Kannada-English translation. Following tokenization and sequence labeling, BIO tags are assigned to indicate the existence and bounds of objectionable spans within the text. On annotated data, a Bidirectional LSTM neural network model is trained and BiLSTM model’s macro F1 score is 61.0 in recognizing objectionable content. Data preparation, model architecture definition, and iterative training with Kannada and Kannada-English text are all part of the training process. In a fresh dataset, the trained model accurately predicts offensive spans, emphasizing comments in the aforementioned languages. Predictions that have been recorded and include offensive span indices are organized into a database. © 2024 Association for Computational Linguistics.},
	author_keywords = {(B stands for Beginning I for Inside O for Outside)BIO Tagging; Bidirectional Long Short-Term Memory(BiLSTM); Deep Learning; Natural Language Processing(NLP); Offensive Content Detection},
	keywords = {Computational linguistics; Data handling; Iterative methods; Learning algorithms; Learning systems; Natural language processing systems; Neural network models; Translation (languages); (B stand for beginning I for inside O for outside)BIO tagging; Bidirectional long short-term memory; Content detection; Deep learning; Language processing; Learning techniques; Multilingual texts; Natural language processing; Natural languages; Offensive content detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, DravidianLangTech 2024; Conference date: 22 March 2024; Conference code: 198166}
}

@ARTICLE{Agarwal2023,
	author = {Agarwal, Shivang and Sonawane, Ankur and Chowdary, C. Ravindranath},
	title = {Accelerating automatic hate speech detection using parallelized ensemble learning models},
	year = {2023},
	journal = {Expert Systems with Applications},
	volume = {230},
	doi = {10.1016/j.eswa.2023.120564},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161706382&doi=10.1016%2fj.eswa.2023.120564&partnerID=40&md5=d5fa7c30a70ba2b33c2b343df67505d0},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology (BHU) Varanasi, 221005, India},
	abstract = {With increasing number of social media users and online engagement, it is essential to study hate speech propagation on social media platforms (SMPs). Automatic hate speech detection on social media is of utmost importance as hate speech can create discomfort among users and potentially generate a strong reaction in society. Ensemble learning algorithms are helpful in addressing sentiment-based classification due to their fault tolerance and efficiency. However, a simple, scalable, and robust framework is required to deal with large-scale data efficiently and accurately. Therefore, we propose parallelization to the standard ensemble learning algorithms to speed up the automatic hate speech detection on SMPs. In this study, we parallelize bagging, A-stacking, and random sub-space algorithms and test their serial and parallel versions on the standard high-dimensional datasets for hate speech detection. The experiments are performed using six datasets that address hate speech propagation during events like the COVID-19 pandemic, the US presidential election (2020), and the farmers’ protest in India (2021). Our parallel models observe a significant speedup with high efficiency, claiming that the proposed models are suitable for the considered application. Also, one of the main motivations of this study is to highlight the importance of generalization by testing the models under the cross-dataset environment. We observed that the accuracy is not affected while parallelizing the algorithms compared with serial algorithms executing on a single machine. © 2023 Elsevier Ltd},
	author_keywords = {Ensemble learning; Hate speech detection; Social media},
	keywords = {COVID-19; Learning algorithms; Learning systems; Social networking (online); Speech recognition; Statistical tests; Ensemble learning; Ensemble learning algorithm; Hate speech detection; Large scale data; Learning models; Sentiment-based classification; Simple++; Social media; Social media platforms; Speech detection; Efficiency},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Naskar2024447,
	author = {Naskar, Akash and Harchandani, Rohan and Thomas, K.T.},
	title = {Detection of toxic comments over the internet using deep learning methods},
	year = {2024},
	journal = {Artificial Intelligence, Blockchain, Computing and Security - Proceedings of the International Conference on Artificial Intelligence, Blockchain, Computing and Security, ICABCS 2023},
	volume = {1},
	pages = {447 – 454},
	doi = {10.1201/9781003393580-68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186737356&doi=10.1201%2f9781003393580-68&partnerID=40&md5=4db74d0de19fa6fdc5e8a687f66a6f41},
	affiliations = {Department of Data Science, Department of Data Science CHRIST (Deemed to be University) Pune, Lavasa, CHRIST (Deemed to be University) Pune, Maharashtra, Lavasa, India},
	abstract = {People now share their ideas on a wide range of topics on social media, which has become an integral part of contemporary culture. The majority of people are increasingly turning to social media as a necessity, and there are numerous incidents of social media addiction that have been reported. Socialmedia channels. Socialmedia platforms have established their worth over time by bringing individuals from different backgrounds together, but they have also shown harmful side effects that could have serious consequences. One such unfavourable result is how extremely poisonous many discussions on social media are. Online abuse, hate speech, and occasionally outrage culture are now all considered to be toxic. In this study, we leverage the Transformers’ Bidirectional Encoder Representations to build an efficient model to detect and classify toxicity in user-generated content on social media. The Kaggle dataset with labelled toxic comments, was used to refine the BERT pre-trained model. Other Deep learning models, including Bidirectional LSTM, Bidirectional-LSTM with attention, and a few other models, were also tested to see which performed best in this classification task. We further evaluate the proposed models utilising dataset obtained from Twitter in order to find harmful content (tweets) using relevant hashtags. The findings showed how well the suggested methodology classified and analysed toxic comments. © 2024 The Author(s).},
	author_keywords = {BERT; BERT; BidirectionalLSTM; finetuning; hate speech; language model; neural networks; pretraining; sentiment analysis; social media; toxic; toxic comment; twitter},
	keywords = {Learning systems; Long short-term memory; Social networking (online); BERT; Bidirectionallstm; Finetuning; Hate speech; Language model; Neural-networks; Pre-training; Sentiment analysis; Social media; Toxic; Toxic comment; Twitter; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Artificial Intelligence, Blockchain, Computing and Security, ICABCS 2023; Conference date: 24 February 2023 through 25 February 2023; Conference code: 307409}
}

@CONFERENCE{Sangeetham2024254,
	author = {Sangeetham, Saisandeep and Vinay, Shreyamanisha C. and Rajan, Kavin G. and Abishna, A. and Bharathi, B.},
	title = {Algorithm Alliance@LT-EDI-2024: Caste and Migration Hate Speech Detection},
	year = {2024},
	journal = {LT-EDI 2024 - 4th Workshop on Language Technology for Equality, Diversity, Inclusion, Proceedings of the Workshop},
	pages = {254 – 258},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189853441&partnerID=40&md5=91b985716c293ed97d3717bd2a2fbfcf},
	affiliations = {Department of Computer Science and Engineering, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, India},
	abstract = {Caste and Migration speech refers to the use of language that distinguishes the offense, violence, and distress on their social, caste, and migration status. Here, caste hate speech targets the imbalance of an individual’s social status and focuses mainly on the degradation of their caste group. While the migration hate speech imposes the differences in nationality, culture, and individual status. These speeches are meant to affront the social status of these people. To detect this hate in the speech, our task on Caste and Migration Hate Speech Detection has been created which classifies human speech into genuine or stimulate categories. For this task, we used multiple classification models such as the train test split model to split the dataset into train and test data, Logistic regression, Support Vector Machine, MLP (Multilayer Perceptron) classifier, Random Forest classifier, KNN classifier, and Decision tree classification. Among these models, The SVM gave the highest macro average F1 score of 0.77 and the average accuracy for these models is around 0.75. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Decision trees; Logistic regression; Speech recognition; Statistical tests; Classification models; Human speech; Logistics regressions; Multilayers perceptrons; Multiple Classification; Regression support vector machines; Social status; Speech detection; Speech targets; Test data; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th Workshop on Language Technology for Equality, Diversity, Inclusion, LT-EDI 2024; Conference date: 21 March 2024; Conference code: 198170}
}

@ARTICLE{Fieri20231,
	author = {Fieri, Brillian and Suhartono, Derwin},
	title = {Offensive Language Detection Using Soft Voting Ensemble Model},
	year = {2023},
	journal = {Mendel},
	volume = {29},
	number = {1},
	pages = {1 – 6},
	doi = {10.13164/mendel.2023.1.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163137347&doi=10.13164%2fmendel.2023.1.001&partnerID=40&md5=d573227d5838a9ce5159f64599bec6d5},
	affiliations = {Computer Science Department, BINUS Graduate Program – Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia},
	abstract = {Offensive language is one of the problems that have become increasingly severe along with the rise of the internet and social media usage. This language can be used to attack a person or specific groups. Automatic moderation, such as the usage of machine learning, can help detect and filter this particular language for someone who needs it. This study focuses on improving the performance of the soft voting classifier to detect offensive language by experimenting with the combinations of the soft voting estimators. The model was applied to a Twitter dataset that was augmented using several augmentation techniques. The features were extracted using Term Frequency-Inverse Document Frequency, sentiment analysis, and GloVe embedding. In this study, there were two types of soft voting models: machine learning-based, with the estimators of Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, and AdaBoost as the best combination, and deep learning-based, with the best estimator combination of Convolutional Neural Network, Bidirectional Long Short-Term Memory, and Bidirectional Gated Recurrent Unit. The results of this study show that the soft voting classifier was better in performance compared to classic machine learning and deep learning models on both original and augmented datasets. © 2023, Brno University of Technology. All rights reserved.},
	author_keywords = {Ensemble Model; Offensive Language; Text Classification; Voting Classifier},
	keywords = {Adaptive boosting; Classification (of information); Convolutional neural networks; Decision trees; Learning systems; Logistic regression; Recurrent neural networks; Social networking (online); Ensemble models; Internet media; Language detection; Machine-learning; Offensive languages; Performance; Social media; Soft voting; Text classification; Voting classifiers; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Kasampalis2024374,
	author = {Kasampalis, Apostolos and Chatzakou, Despoina and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
	title = {Bias Detection and Mitigation in Textual Data: A Study on Fake News and Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14610 LNCS},
	pages = {374 – 383},
	doi = {10.1007/978-3-031-56063-7_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189286295&doi=10.1007%2f978-3-031-56063-7_29&partnerID=40&md5=fa6c363f4b9c81c59c3722ded404b51c},
	affiliations = {Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece},
	abstract = {Addressing bias in NLP-based solutions is crucial to promoting fairness, avoiding discrimination, building trust, upholding ethical standards, and ultimately improving their performance and reliability. On the topic of bias detection and mitigation in textual data, this work examines the effect of different bias detection models along with standard debiasing methods on the effectiveness of fake news and hate speech detection tasks. Extensive discussion of the results draws useful conclusions, highlighting the inherent difficulties in effectively managing bias.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Bias; Fake news detection; Hate speech detection; NLP},
	keywords = {Fake detection; Speech recognition; Bias; De-biasing; Detection models; Detection tasks; Ethical standards; Fake news detection; Hate speech detection; Performance and reliabilities; Speech detection; Textual data; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 46th European Conference on Information Retrieval, ECIR 2024; Conference date: 24 March 2024 through 28 March 2024; Conference code: 309699}
}

@ARTICLE{Husain2023,
	author = {Husain, Fatemah},
	title = {A Novel Knowledge-augmented Model Customization Approach for Arabic Offensive Language Detection},
	year = {2023},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {22},
	number = {12},
	doi = {10.1145/3634702},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181478888&doi=10.1145%2f3634702&partnerID=40&md5=27d2ebdcc5bc08ae771f2a1e2f2a4693},
	affiliations = {Information Science Department, College of Life Sciences, Sabah AlSalem University City (Alshadadiya), Kuwait University, P.O. Box 5969, Safat, 13060, Kuwait},
	abstract = {Multiple attempts to develop systems for detecting online Arabic offensive language have been explored in previous studies. However, most of these attempts do not consider the variation of Arabic dialects, cultures, and offensive phrases. In contrast, this study aims to extract knowledge from multiple offensive language datasets to build a cross-dialect and culture knowledge-based repository. This knowledge-based repository is utilized to develop novel system architecture based on customizing the AraBERT model in a unique method to preserve dialectal knowledge and offensive cultural knowledge within the contextual word embedding of BERT architecture. Performance evaluation procedures consist of statistical evaluation metrics and a behavioral checklist. Results report more effective predictions by the customized model than the uncustomized one, particularly for offensive text. The customization process allows the model to gain more knowledge of informal text in general, and a better understanding of dialectal Arabic. © 2023 Copyright held by the owner/author(s)},
	author_keywords = {collocations; knowledge-based; Natural Language Processing; neural networks; offensive Language detection},
	keywords = {Knowledge based systems; Natural language processing systems; Neural networks; Online systems; Collocation; Customisation; Knowledge based; Language detection; Language processing; Natural language processing; Natural languages; Neural-networks; Offensive language detection; Offensive languages; Network architecture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Saeed2023,
	author = {Saeed, Ramsha and Afzal, Hammad and Rauf, Sadaf Abdul and Iltaf, Naima},
	title = {Detection of Offensive Language and ITS Severity for Low Resource Language},
	year = {2023},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {22},
	number = {6},
	doi = {10.1145/3580476},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164245888&doi=10.1145%2f3580476&partnerID=40&md5=1841037d66a36f068fb15f65022182c1},
	affiliations = {National University of Sciences and Technology (NUST), H-12, Islamabad, 46000, Pakistan; Department of Computer Science, Fatima Jinnah Women University (FJWU), Old Presidency, The Mall, Kachari Chowk, Rawalpindi, 46000, Pakistan},
	abstract = {Continuous proliferation of hate speech in different languages on social media has drawn significant attention from researchers in the past decade. Detecting hate speech is indispensable irrespective of the scale of use of language, as it inflicts huge harm on society. This work presents a first resource for classifying the severity of hate speech in addition to classifying offensive and hate speech content. Current research mostly limits hate speech classification to its primary categories, such as racism, sexism, and hatred of religions. However, hate speech targeted at different protected characteristics also manifests in different forms and intensities. It is important to understand varying severity levels of hate speech so that the most harmful cases of hate speech may be identified and dealt with earlier than the less harmful ones. In this work, we focus on detecting offensive speech, hate speech, and multiple levels of hate speech in the Urdu language. We investigate three primary target categories of hate speech: religion, racism, and national origin. We further divide these categories into levels based on the severity of hate conveyed. The severity levels are referred to as symbolization, insult, and attribution. A corpus comprising more than 20,000 tweets against the corresponding hate speech categories and severity levels is collected and annotated. A comprehensive experimentation scheme is applied using traditional as well as deep learning-based models to examine their impact on hate speech detection. The highest macro-averaged F-score yielded for detecting offensive speech is 86% while the highest F-scores for detecting hate speech with respect to ethnicity, national origin, and religious affiliation are 80%, 81%, and 72%, respectively. This shows that results are very encouraging and would provide a lead towards further investigation in this domain.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Additional Key Words and PhrasesHate speech; BERT; convolutional neural network; long short-term memory; Urdu NLP},
	keywords = {Convolutional neural networks; Deep learning; Additional key word and phraseshate speech; BERT; Convolutional neural network; F-score; Key words; Low resource languages; Offensive languages; Social media; Speech content; Urdu NLP; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Tarafder202447,
	author = {Tarafder, Tuhin and Vashisth, Harsh Kumar and Arora, Mamta},
	title = {Automated Tool for Toxic Comments Identification on Live Streaming YouTube},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {832},
	pages = {47 – 56},
	doi = {10.1007/978-981-99-8129-8_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187785572&doi=10.1007%2f978-981-99-8129-8_5&partnerID=40&md5=bbc2743f20e781dc415ac98d1ef05ad3},
	affiliations = {Manav Rachna University, Haryana, Faridabad, India},
	abstract = {The necessity for content moderation on social media websites is increasing every day. The reason behind this is the anonymity of an individual which is provided by the internet and that they can exercise on any streaming website like YouTube. This project aids the creators/moderators in maintaining and stabilizing the toxicity of comments on their channel/page. A moderator has the authority to delete/hide any inappropriate comment posted by any user. During the pandemic of Covid-19, a significant, large user base immigrated to social media websites particularly streaming websites like YouTube. This surge in users resulted in an increased need for moderators. Any user can post any hateful/toxic or obscene comment that moderators can miss due to the huge volume of comments. Using NLP (Natural Language Processing), a model can be implemented directly onto any live-streaming chat session which can identify any toxic/obscene or threat comment and can flag them under the respective category. This model is real time and formulated using NLP techniques that are used in order to achieve the task. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Deep learning; NLP; Text classification},
	keywords = {Classification (of information); Deep learning; Media streaming; Moderators; Natural language processing systems; Text processing; Websites; Automated tools; Deep learning; Language processing; Large users; Live streaming; Natural language processing; Natural languages; Social media websites; Text classification; YouTube; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Machine Intelligence for Research and Innovations, MAiTRI 2023; Conference date: 1 September 2023 through 3 September 2023; Conference code: 306789}
}

@ARTICLE{Zhou20231247,
	author = {Zhou, Linda and Caines, Andrew and Pete, Ildiko and Hutchings, Alice},
	title = {Automated hate speech detection and span extraction in underground hacking and extremist forums},
	year = {2023},
	journal = {Natural Language Engineering},
	volume = {29},
	number = {5},
	pages = {1247 – 1274},
	doi = {10.1017/S1351324922000262},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171525146&doi=10.1017%2fS1351324922000262&partnerID=40&md5=8517ee5221792046a05f21e41ace64da},
	affiliations = {Department of Computer Science and Technology, University of Cambridge, Cambridge, CB2 1TN, United Kingdom},
	abstract = {Hate speech is any kind of communication that attacks a person or a group based on their characteristics, such as gender, religion and race. Due to the availability of online platforms where people can express their (hateful) opinions, the amount of hate speech is steadily increasing that often leads to offline hate crimes. This paper focuses on understanding and detecting hate speech in underground hacking and extremist forums where cybercriminals and extremists, respectively, communicate with each other, and some of them are associated with criminal activity. Moreover, due to the lengthy posts, it would be beneficial to identify the specific span of text containing hateful content in order to assist site moderators with the removal of hate speech. This paper describes a hate speech dataset composed of posts extracted from HackForums, an online hacking forum, and Stormfront and Incels.co, two extremist forums. We combined our dataset with a Twitter hate speech dataset to train a multi-platform classifier. Our evaluation shows that a classifier trained on multiple sources of data does not always improve the performance compared to a mono-platform classifier. Finally, this is the first work on extracting hate speech spans from longer texts. The paper fine-Tunes BERT (Bidirectional Encoder Representations from Transformers) and adopts two approaches-span prediction and sequence labelling. Both approaches successfully extract hateful spans and achieve an F1-score of at least 69%.  © The Author(s), 2022. Published by Cambridge University Press.},
	author_keywords = {Corpus annotation; Span extraction; Text classification},
	keywords = {Classification (of information); Personal computing; Speech communication; Speech recognition; Text processing; Corpus annotations; Criminal activities; Cybercriminals; Group-based; Multi-platform; Offline; Online platforms; Span extraction; Speech detection; Text classification; Extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Chhabra20231203,
	author = {Chhabra, Anusha and Vishwakarma, Dinesh Kumar},
	title = {A literature survey on multimodal and multilingual automatic hate speech identification},
	year = {2023},
	journal = {Multimedia Systems},
	volume = {29},
	number = {3},
	pages = {1203 – 1230},
	doi = {10.1007/s00530-023-01051-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146551286&doi=10.1007%2fs00530-023-01051-8&partnerID=40&md5=87a14bdc480ca35402485a05b48a0c2e},
	affiliations = {Biometric Research Laboratory, Department of Information Technology, Delhi Technological University, Delhi, 110042, India},
	abstract = {Social media is a more common and powerful platform for communication to share views about any topic or article, which consequently leads to unstructured toxic, and hateful conversations. Curbing hate speeches has emerged as a critical challenge globally. In this regard, Social media platforms are using modern statistical tools of AI technologies to process and eliminate toxic data to minimize hate crimes globally. Demanding the dire need, machine and deep learning-based techniques are getting more attention in analyzing these kinds of data. This survey presents a comprehensive analysis of hate speech definitions along with the motivation for detection and standard textual analysis methods that play a crucial role in identifying hate speech. State-of-the-art hate speech identification methods are also discussed, highlighting handcrafted feature-based and deep learning-based algorithms by considering multimodal and multilingual inputs and stating the pros and cons of each. Survey also presents popular benchmark datasets of hate speech/offensive language detection specifying their challenges, the methods for achieving top classification scores, and dataset characteristics such as the number of samples, modalities, language(s), number of classes, etc. Additionally, performance metrics are described, and classification scores of popular hate speech methods are mentioned. The conclusion and future research directions are presented at the end of the survey. Compared with earlier surveys, this paper gives a better presentation of multimodal and multilingual hate speech detection through well-organized comparisons, challenges, and the latest evaluation techniques, along with their best performances. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Deep learning; Hate speech; Machine learning; Multilingual; Multimodal; Online social media},
	keywords = {Benchmarking; Deep learning; E-learning; Learning systems; Social networking (online); Speech recognition; Statistical mechanics; Critical challenges; Deep learning; Hate speech; Literature survey; Machine-learning; Multi-modal; Multilingual; Online social medias; Social media; Speech identification; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32}
}

@CONFERENCE{Masud2024826,
	author = {Masud, Sarah and Khan, Mohammad Aflah and Goyal, Vikram and Akhtar, Md Shad and Chakraborty, Tanmoy},
	title = {Probing Critical Learning Dynamics of PLMs for Hate Speech Detection},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2024},
	pages = {826 – 845},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188711224&partnerID=40&md5=bb97949aebcad0bc0fb762408def8770},
	affiliations = {IIIT Delhi, India; IIT Delhi, India},
	abstract = {Despite the widespread adoption, there is a lack of research into how various critical aspects of pretrained language models (PLMs) affect their performance in hate speech detection. Through five research questions, our findings and recommendations lay the groundwork for empirically investigating different aspects of PLMs’ use in hate speech detection. We deep dive into comparing different pretrained models, evaluating their seed robustness, finetuning settings, and the impact of pretraining data collection time. Our analysis reveals early peaks for downstream tasks during pretraining, the limited benefit of employing a more recent pretraining corpus, and the significance of specific layers during finetuning. We further call into question the use of domain-specific models and highlight the need for dynamic datasets for benchmarking hate speech detection. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Collection time; Data collection; Deep dives; Down-stream; Language model; Model use; Performance; Pre-training; Research questions; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 18th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2024 - Findings of EACL 2024; Conference date: 17 March 2024 through 22 March 2024; Conference code: 198141}
}

@ARTICLE{Chhabra2023,
	author = {Chhabra, Anusha and Vishwakarma, Dinesh Kumar},
	title = {Multimodal hate speech detection via multi-scale visual kernels and knowledge distillation architecture},
	year = {2023},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {126},
	doi = {10.1016/j.engappai.2023.106991},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168409098&doi=10.1016%2fj.engappai.2023.106991&partnerID=40&md5=6104265f111364626593bca75bfa0a5b},
	affiliations = {Biometric Research Laboratory, Department of Information Technology, Delhi Technological University, Delhi, 110042, India},
	abstract = {People increasingly use social media platforms to express themselves by posting visuals and texts. As a result, hate content is on the rise, necessitating practical visual caption analysis. Thus, the relationship between image and caption modalities is crucial in visual caption analysis. Contrarily, most methods combine features from the image and caption modalities using deep learning architectures with millions of parameters already trained without integrating a specialized attention module, resulting in less desirable outcomes. This paper suggests a novel multi-modal architecture for identifying hateful memetic information in response to the above observation. The proposed architecture contains a novel “multi-scale kernel attentive visual” (MSKAV) module that uses an efficient multi-branch structure to extract discriminative visual features. Additionally, MSKAV utilizes an adaptive receptive field using multi-scale kernels. MSKAV also incorporates a multi-directional visual attention module to highlight spatial regions of importance. The proposed model also contains a novel “knowledge distillation-based attentional caption” (KDAC) module. It uses a transformer-based self-attentive block to extract discriminative features from meme captions. Thorough experimentation on multi-modal hate speech benchmarks MultiOff, Hateful Memes, and MMHS150K datasets achieved accuracy scores of 0.6250, 0.8750, and 0.8078, respectively. It also reaches impressive AUC scores of 0.6557, 0.8363, and 0.7665 on the three datasets, respectively, beating SOTA multi-modal hate speech identification models. © 2023 Elsevier Ltd},
	author_keywords = {Adaptive receptive field; Deep learning; Hate content; Machine learning; Multimodal},
	keywords = {Architecture; Behavioral research; Deep learning; Learning systems; Speech recognition; Adaptive receptive field; Deep learning; Hate content; Learning architectures; Machine-learning; Multi-modal; Multi-scales; Receptive fields; Social media platforms; Speech detection; Distillation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Zampieri2023613,
	author = {Zampieri, Marcos and Ranasinghe, Tharindu and Sarkar, Diptanu and Ororbia, Alex},
	title = {Offensive language identification with multi-task learning},
	year = {2023},
	journal = {Journal of Intelligent Information Systems},
	volume = {60},
	number = {3},
	pages = {613 – 630},
	doi = {10.1007/s10844-023-00787-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153726798&doi=10.1007%2fs10844-023-00787-z&partnerID=40&md5=b0052df28f8d633944888fff1f191db2},
	affiliations = {George Mason University, Fairfax, VA, United States; Aston University, Birmingham, United Kingdom; Rochester Institute of Technology, Rochester, NY, United States},
	abstract = {The widespread presence of offensive content is a major issue in social media. This has motivated the development of computational models to identify such content in posts or conversations. Most of these models, however, treat offensive language identification as an isolated task. Very recently, a few datasets have been annotated with post-level offensiveness and related phenomena, such as offensive tokens, humor, engaging content, etc., creating the opportunity of modeling related tasks jointly which will help improve the explainability of offensive language detection systems and potentially aid human moderators. This study proposes a novel multi-task learning (MTL) architecture that can predict: (1) offensiveness at both post and token levels in English; and (2) offensiveness and related subjective tasks such as humor, engaging content, and gender bias identification in multilingual settings. Our results show that the proposed multi-task learning architecture outperforms current state-of-the-art methods trained to identify offense at the post level. We further demonstrate that MTL outperforms single-task learning (STL) across different tasks and language combinations. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Deep learning; Multi-task learning; Offensive language identification; Transformers},
	keywords = {Deep learning; Learning algorithms; Learning systems; Linearization; Natural language processing systems; Computational modelling; Deep learning; Language detection; Language identification; Learning architectures; Multitask learning; Offensive language identification; Offensive languages; Social media; Transformer; Modeling languages},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Xu2023,
	author = {Xu, Meijia and Liu, Shuxian},
	title = {RB_BG_MHA: A RoBERTa-Based Model with Bi-GRU and Multi-Head Attention for Chinese Offensive Language Detection in Social Media},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {19},
	doi = {10.3390/app131911000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174176773&doi=10.3390%2fapp131911000&partnerID=40&md5=41d46d3a7757843465158fc3920d8b58},
	affiliations = {College of Information Science and Engineering, Xinjiang University, Urumqi, 830046, China},
	abstract = {Offensive language in social media affects the social experience of individuals and groups and hurts social harmony and moral values. Therefore, in recent years, the problem of offensive language detection has attracted the attention of many researchers. However, the primary research currently focuses on detecting English offensive language, while few studies on the Chinese language exist. In this paper, we propose an innovative approach to detect Chinese offensive language. First, unlike previous approaches, we utilized both RoBERTa’s sentence-level and word-level embedding, combining the sentence embedding and word embedding of RoBERTa’s model, bidirectional GRU, and multi-head self-attention mechanism. This feature fusion allows the model to consider sentence-level and word-level semantic information at the same time so as to capture the semantic information of Chinese text more comprehensively. Second, by concatenating the output results of multi-head attention with RoBERTa’s sentence embedding, we achieved an efficient fusion of local and global information and improved the representation ability of the model. The experiments showed that the proposed model achieved 82.931% accuracy and 82.842% F1-score in Chinese offensive language detection tasks, delivering high performance and broad application potential. © 2023 by the authors.},
	author_keywords = {Bi-GRU; NLP; offensive language detection; RoBERTa},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Zhou2023266,
	author = {Zhou, Wei and Min, Xuanlin and Zhao, Yiheng and Pang, Yiran and Yi, Jun},
	title = {A Multi-Scale Spatio-Temporal Network for Violence Behavior Detection},
	year = {2023},
	journal = {IEEE Transactions on Biometrics, Behavior, and Identity Science},
	volume = {5},
	number = {2},
	pages = {266 – 276},
	doi = {10.1109/TBIOM.2022.3233399},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147202982&doi=10.1109%2fTBIOM.2022.3233399&partnerID=40&md5=959fafa9070bbb9a6b5c8fa1355666f7},
	affiliations = {Chongqing University of Science and Technology, School of Intelligent Technology and Engineering, Chongqing, 401331, China; Florida Atlantic University, Department of Electrical Engineering and Computer Science, Boca Raton, 33431, FL, United States},
	abstract = {Violence behavior detection has played an important role in computer vision, its widely used in unmanned security monitoring systems, Internet video filtration, etc. However, automatically detecting violence behavior from surveillance cameras has long been a challenging issue due to the real-time and detection accuracy. In this brief, a novel multi-scale spatio-temporal network termed as MSTN is proposed to detect violence behavior from video stream. To begin with, the spatio-temporal feature extraction module (STM) is developed to extract the key features between foreground and background of the original video. Then, temporal pooling and cross channel pooling are designed to obtain short frame rate and long frame rate from STM, respectively. Furthermore, short-time building (STB) branch and long-time building (LTB) branch are presented to extract the violence features from different spatio-temporal scales, where STB module is used to capture the spatial feature and LTB module is used to extract useful temporal feature for video recognition. Finally, a Trans module is presented to fuse the features of STB and LTB through lateral connection operation, where LTB feature is compressed into STB to improve the accuracy. Experimental results show the effectiveness and superiority of the proposed method on computational efficiency and detection accuracy.  © 2019 IEEE.},
	author_keywords = {convolutional neuronal network; deep learning; spatio-temporal; Violent behavior detection},
	keywords = {Access control; Behavioral research; Computational efficiency; Data mining; Deep learning; Extraction; Network security; Neural networks; Neurons; Real time systems; Security systems; Behavior detection; Behavioral science; Biometric (access control); Convolutional neuronal network; Deep learning; Features extraction; Kernel; Neuronal networks; Spatio-temporal; Violent behavior; Violent behavior detection; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Muzakir2023545,
	author = {Muzakir, Ari and Adi, Kusworo and Kusumaningrum, Retno},
	title = {Advancements in Semantic Expansion Techniques for Short Text Classification and Hate Speech Detection},
	year = {2023},
	journal = {Ingenierie des Systemes d'Information},
	volume = {28},
	number = {3},
	pages = {545 – 556},
	doi = {10.18280/isi.280302},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168009856&doi=10.18280%2fisi.280302&partnerID=40&md5=4c48417820c6bbbab76d0d33f3f9e44b},
	affiliations = {Doctoral Program of Information System, School of Postgraduated Studies, Diponegoro University, Semarang, 5024, Indonesia; Faculty of Science and Technology, Universitas Bina Darma, Palembang, 30264, Indonesia; Department of Physics, Faculty of Science and Mathematics, Diponegoro University, Semarang, 50275, Indonesia; Department of Informatics, Faculty of Science and Mathematics, Diponegoro University, Semarang, 50275, Indonesia},
	abstract = {Traditional text classification methodologies, which primarily rely on document context and word frequency, often fall short in handling the linguistic complexities of the Indonesian language, such as colloquialism and informal language usage. This study presents a comprehensive semantic expansion-based framework to address these challenges in detecting hate speech within Indonesian social media commentary. Our framework leverages trusted knowledge bases, WordNet and Kateglo, to alleviate ambiguity in short texts. The BERT word insertion model is employed for semantic similarity calculation, followed by the application of a CNN deep learning model for hate speech classification. This approach effectively enhances semantic understanding and accurately classifies hate speech. The study also highlights future trajectories in semantic expansion for short text classification, encouraging further research to implement the proposed framework as an automated detection system. © 2023 International Information and Engineering Technology Association. All rights reserved.},
	author_keywords = {Indonesia hate speech detection; semantic expansion; semantic similarity; short text expansion; text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Omran2023,
	author = {Omran, Esraa and Al Tararwah, Estabraq and Al Qundus, Jamal},
	title = {A comparative analysis of machine learning algorithms for hate speech detection in social media},
	year = {2023},
	journal = {Online Journal of Communication and Media Technologies},
	volume = {13},
	number = {4},
	doi = {10.30935/ojcmt/13603},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178898356&doi=10.30935%2fojcmt%2f13603&partnerID=40&md5=48399c7889ddf67dab3239fcbcab9568},
	affiliations = {Center for Applied Mathematics and Bioinformatics, Department of Computer Science, Gulf University for Science and Technology, Kuwait City, Kuwait; Gulf University for Science and Technology, Kuwait City, Kuwait; Faculty of Information Technology, Middle East University, Amman, Jordan},
	abstract = {A detecting and mitigating hate speech in social media, particularly on platforms like Twitter, is a crucial task with significant societal impact. This research study presents a comprehensive comparative analysis of machine learning algorithms for hate speech detection, with the primary goal of identifying an optimal algorithmic combination that is simple, easy to implement, efficient, and yields high detection performance. Through meticulous pre-processing and rigorous evaluation, the study explores various algorithms to determine their suitability for hate speech detection. The focus is finding a combination that balances simplicity, ease of implementation, computational efficiency, and strong performance metrics. The findings reveal that the combination of naïve Bayes and decision tree algorithms achieves a high accuracy of 0.887 and an F1-score of 0.885, demonstrating its effectiveness in hate speech detection. This research contributes to identifying a reliable algorithmic combination that meets the criteria of simplicity, ease of implementation, quick processing, and strong performance, providing valuable guidance for researchers and practitioners in hate speech detection in social media. By elucidating the strengths and limitations of various algorithmic combinations, this research enhances the understanding of hate speech detection. It paves the way for developing robust solutions, creating a safer, more inclusive digital environment. © 2023 by authors;.},
	author_keywords = {machine learning; s: hate speech detection; social media analysis; text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@ARTICLE{Ammar Aouchiche2023,
	author = {Ammar Aouchiche, Imane Rebeh and Boumahdi, Fatima and Madani, Amina and Remmide, Mohamed Abdelkarim},
	title = {Hate Speech Prediction on Social Media},
	year = {2023},
	journal = {SN Computer Science},
	volume = {4},
	number = {3},
	doi = {10.1007/s42979-023-01668-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148515826&doi=10.1007%2fs42979-023-01668-6&partnerID=40&md5=f3a5944c846625ddfe444e485e6652f7},
	affiliations = {LRDSI Laboratory, Blida 1 University, Blida, Algeria},
	abstract = {In order to stop hate speech spreaders on social media, researchers started developing machine learning systems that automatically detect hate speech. In this paper we present our proposed approach to detect hate speech on twitter. We develop two different models, the first one with a traditional approach using random forest model and the second one with the autoencoder as a deep learning model combinate with random forest model. The proposed models reached accuracies of 94% and 63% for Kaggle (https://www.kaggle.com/) and Pan (https://pan.webis.de/) dataset respectively. © 2023, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Autoencoder; Deep learning; Hate speech; Machine learning; Natural language processing; Random forest},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Imaduddin20231107,
	author = {Imaduddin, Helmi and Kusumaningtias, Lucky Anggari and A'la, Fiddin Yusfida},
	title = {Application of LSTM and GloVe Word Embedding for Hate Speech Detection in Indonesian Twitter Data},
	year = {2023},
	journal = {Ingenierie des Systemes d'Information},
	volume = {28},
	number = {4},
	pages = {1107 – 1112},
	doi = {10.18280/isi.280430},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171873412&doi=10.18280%2fisi.280430&partnerID=40&md5=43a001413fe3be1e6e4bf933d866d5ea},
	affiliations = {Department of Informatics, Universitas Muhammadiyah Surakarta, Surakarta, 57169, Indonesia; Department of Informatics Engineering, Universitas Sebelas Maret, Surakarta, 57124, Indonesia},
	abstract = {Hate speech, characterized by intentional expressions of dissatisfaction, is a prevalent phenomenon on social media platforms, including Twitter. Its continual occurrence can foster divisions, misunderstandings, and even acts of violence between individuals and groups, particularly due to the resulting prejudice. This study investigates the occurrence of hate speech within Indonesian content on Twitter, employing a deep learning approach to detect and analyze such expressions. The Long Short-Term Memory (LSTM) method, coupled with the GloVe word embedding technique, is utilized on a dataset comprising 13,169 Indonesian tweets flagged for hate speech. Four distinct model architectures were developed through the integration of LSTM and GloVe. The findings reveal model 1 to exhibit superior performance, achieving a precision of 89%, a recall of 99%, an F-1 score of 94%, and an overall accuracy of 94.24%. It is suggested that future research explore the potential deployment of this model in web or mobile platforms for real-time analysis, thereby enhancing the capacity for immediate hate speech detection and mitigation. © 2023 International Information and Engineering Technology Association. All rights reserved.},
	author_keywords = {deep learning; GloVe; hate speech; Long Short-Term Memory (LSTM); Natural Language Processing (NLP); twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Mubarak20231436,
	author = {Mubarak, Hamdy and Hassan, Sabit and Chowdhury, Shammur Absar},
	title = {Emojis as anchors to detect Arabic offensive language and hate speech},
	year = {2023},
	journal = {Natural Language Engineering},
	volume = {29},
	number = {6},
	pages = {1436 – 1457},
	doi = {10.1017/S1351324923000402},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171780713&doi=10.1017%2fS1351324923000402&partnerID=40&md5=69a369037e2d306ae36e4492de638ef1},
	affiliations = {Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar; School of Computing and Information, University of Pittsburgh, Pittsburgh, PA, United States},
	abstract = {We introduce a generic, language-independent method to collect a large percentage of offensive and hate tweets regardless of their topics or genres. We harness the extralinguistic information embedded in the emojis to collect a large number of offensive tweets. We apply the proposed method on Arabic tweets and compare it with English tweets - analyzing key cultural differences. We observed a constant usage of these emojis to represent offensiveness throughout different timespans on Twitter. We manually annotate and publicly release the largest Arabic dataset for offensive, fine-grained hate speech, vulgar, and violence content. Furthermore, we benchmark the dataset for detecting offensiveness and hate speech using different transformer architectures and perform in-depth linguistic analysis. We evaluate our models on external datasets - a Twitter dataset collected using a completely different method, and a multi-platform dataset containing comments from Twitter, YouTube, and Facebook, for assessing generalization capability. Competitive results on these datasets suggest that the data collected using our method capture universal characteristics of offensive language. Our findings also highlight the common words used in offensive communications, common targets for hate speech, specific patterns in violence tweets, and pinpoint common classification errors that can be attributed to limitations of NLP models. We observe that even state-of-the-art transformer models may fail to take into account culture, background, and context or understand nuances present in real-world data such as sarcasm.  © 2023 The Author(s).},
	author_keywords = {Emojis; Hate speech; Offensive language; Social media analysis; Text classification},
	keywords = {Linguistics; Social networking (online); Text processing; Cultural difference; Emojis; Fine grained; Hate speech; Language independents; Linguistic analysis; Multi-platform; Offensive languages; Social media analysis; Text classification; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Dwivedy202336279,
	author = {Dwivedy, Vishwajeet and Roy, Pradeep Kumar},
	title = {Deep feature fusion for hate speech detection: a transfer learning approach},
	year = {2023},
	journal = {Multimedia Tools and Applications},
	volume = {82},
	number = {23},
	pages = {36279 – 36301},
	doi = {10.1007/s11042-023-14850-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150161587&doi=10.1007%2fs11042-023-14850-y&partnerID=40&md5=a133722c02cac3990f16efc9b28d062a},
	affiliations = {Indian Institute of Information Technology, Gujarat, Surat, India},
	abstract = {Social platforms are receiving many posts from the hate speech category. These social posts affect societal order and impact the reader’s mental and emotional state, sometimes even leading to suicide. Hence, detecting hate speech posts from social media at the right time plays a crucial role in restraining the spread of hate speech. This paper presents a multimodal architecture consisting of a concatenated transfer learning model and LSTM based model to classify social media posts into hate speech and non-hate speech. The proposed model simultaneously considers text and images to understand their context and intent to predict hate in the post. The image and text features were fused to create a multimodal architecture to predict hate or non-hate speech from social media posts. Separate models for the text and image were also investigated and found the fusion of image and text information provided promising prediction outcomes by outperforming the base model. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Deep learning; Feature fusion; Hate speech; Machine learning; Multimodal; Social network},
	keywords = {Feature extraction; Learning systems; Long short-term memory; Network architecture; Social networking (online); Speech recognition; Deep learning; Features fusions; Hate speech; Machine-learning; Multi-modal; Multimodal architectures; Social media; Social network; Speech detection; Transfer learning; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Jia202316238,
	author = {Jia, Yuanzhe and Wu, Weixuan and Cao, Feiqi and Han, Soyeon Caren},
	title = {In-Game Toxic Language Detection: Shared Task and Attention Residuals},
	year = {2023},
	journal = {Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023},
	volume = {37},
	pages = {16238 – 16239},
	doi = {10.1609/aaai.v37i13.26979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168239333&doi=10.1609%2faaai.v37i13.26979&partnerID=40&md5=3e34002323fc50510879b377b7f72828},
	affiliations = {School of Computer Science, University of Sydney, Australia},
	abstract = {In-game toxic language becomes the hot potato in the gaming industry and community. There have been several online game toxicity analysis frameworks and models proposed. However, it is still challenging to detect toxicity due to the nature of in-game chat, which has an extremely short length. In this paper, we describe how the in-game toxic language shared task has been established using real-world in-game chat data. In addition, we propose and introduce the model/framework for toxic language token tagging (slot filling) from the in-game chat. The data and code will be released. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Artificial intelligence; Social networking (online); Analysis frameworks; Analysis models; Hot-potato; Language detection; Modelling framework; On-line games; Real-world; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493; All Open Access, Gold Open Access}
}

@ARTICLE{Hayaty20231928,
	author = {Hayaty, Mardhiya and Laksito, Arif Dwi and Adi, Sumarni},
	title = {Hate speech detection on Indonesian text using word embedding method-global vector},
	year = {2023},
	journal = {IAES International Journal of Artificial Intelligence},
	volume = {12},
	number = {4},
	pages = {1928 – 1937},
	doi = {10.11591/ijai.v12.i4.pp1928-1937},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167346723&doi=10.11591%2fijai.v12.i4.pp1928-1937&partnerID=40&md5=46049758b49211db7bc4d0fd6a53fca6},
	affiliations = {Department of Informatics, Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia; Deparment of Computer Science, Graduate School of Systems Design, Tokyo Metropolitan University, Tokyo, Japan; Department in Faculty of Computer Science, Universitas Amikom Yogyakarta, Indonesia},
	abstract = {Hate speech is defined as communication directed toward a specific individual or group that involves hatred or anger and a language with solid arguments leading to someone's opinion can cause social conflict. It has a lot of potential for individuals to communicate their thoughts on an online platform because the number of Internet users globally, including in Indonesia, is continually rising. This study aims to observe the impact of pre-trained global vector (GloVe) word embedding on accuracy in the classification of hate speech and non-hate speech. The use of pre-trained GloVe (Indonesian text) and single and multi-layer long short-term memory (LSTM) classifiers has performance that is resistant to overfitting compared to pre-trainable embedding for hate-speech detection. The accuracy value is 81.5% on a single layer and 80.9% on a double-layer LSTM. The following job is to provide pre-trained with formal and non-formal language corpus; pre-processing to overcome non-formal words is very challenging. © 2023, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Abusive; Glove; Hate speech; Long short-term memory; Word embedding},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Alsamman202336,
	author = {Alsamman, Ahmad and Schmitz, Andreas and Wimmer, Maria A.},
	title = {Towards an Organically Growing Hate Speech Dataset in Hate Speech Detection Systems in a Smart Mobility Application},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {36 – 43},
	doi = {10.1145/3598469.3598473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167872825&doi=10.1145%2f3598469.3598473&partnerID=40&md5=bbbd2a4625bd36d85b57c1fa9cbfc7a4},
	affiliations = {Research Group E-Government, University of Koblenz, Koblenz, Germany},
	abstract = {The automatic detection of hate speech online poses several challenges. A top challenge is that hate speech changes its targets and its format periodically. While the lack of available training data is a general issue in many natural language processing applications, the forementioned challenge amplifies the problem especially when taking into consideration the challenge of producing well labelled datasets. Based on the concepts of quarantining hate speech and integrating a linguistics expert in a smart mobility service provided in an administrative district in Germany, this paper proposes an approach that targets improving the training dataset quantitively and qualitatively in a running smart mobility app, the SWIA app. This proactive approach provides a long-term solution for hate speech detection models that rely on labelled datasets for training. The paper also discusses technical and practical challenges unanswered by this approach. © 2023 ACM.},
	author_keywords = {Co-Creation; Datasets; German Languages; Hate Speech Classification; Quarantining; Smart Mobility},
	keywords = {Classification (of information); Natural language processing systems; Co-creation; Dataset; Detection system; German language; Hate speech classification; Labeled dataset; Quarantining; Smart mobility; Speech classification; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 24th Annual International Conference on Digital Government Research - Together in the Unstable World: Digital Government and Solidarity, DGO 2023; Conference date: 11 July 2023 through 14 July 2023; Conference code: 190597; All Open Access, Bronze Open Access}
}

@ARTICLE{Fan20242730,
	author = {Fan, Xiaochao and Liu, Jiapeng and Liu, Junjie and Tuerxun, Palidan and Deng, Wenjun and Li, Weijie},
	title = {Identifying Hate Speech Through Syntax Dependency Graph Convolution and Sentiment Knowledge Transfer},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {2730 – 2741},
	doi = {10.1109/ACCESS.2023.3347591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181580273&doi=10.1109%2fACCESS.2023.3347591&partnerID=40&md5=c1eeb53be1412eb20da6c0f82b3f8a34},
	affiliations = {Xinjiang Normal University, School of Computer Science and Technology, Ürümqi, 830000, China; Xinjiang University, School of Software, Ürümqi, 830000, China},
	abstract = {In recent years, hate speech spread on the Internet has seriously affected society's harmony, stability, and development. A way to quickly identify hate speech from the vast amount of data on the Internet is urgent. In this paper, different from previous traditional methods, we explore a novel scenario of constructing a syntax dependency graph for each instance based on the syntactical information retrieved from an external tool. We propose a model called the Dependency Graph Convolutional and Sentiment Knowledge Transfer (DGCSKT) network. DGCSKT utilizes syntactic dependency graphs and dependency graph convolutional operations to enhance the model's ability to perceive contextual information. Additionally, we introduce sentiment resources that are data-homogeneous as an auxiliary task at the bottom level of the model to share effective sentiment features and improve recognition performance. Then, we propose the Dynamic Normalized Weighting (DNW) method to weight the training information of different tasks and thus improve the model's generalization ability. Compared to the current state-of-the-art methods, our proposed approach improves the Macro-F1 by 3.88% and 0.54% in OLID and HateEval respectively.  © 2013 IEEE.},
	author_keywords = {dependency graph convolution; dynamic normalized weighting; Hate speech detection; multi-task optimization},
	keywords = {Feature extraction; Job analysis; Knowledge management; Speech recognition; Syntactics; Context models; Dependency graph convolution; Dependency graphs; Dynamic normalized weighting; Features extraction; Hate speech; Hate speech detection; Multi tasks; Multi-task optimization; Optimisations; Speech detection; Task analysis; Convolution},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Aldreabi2023644,
	author = {Aldreabi, Esraa and Blackburn, Jeremy},
	title = {Enhancing Automated Hate Speech Detection: Addressing Islamophobia and Freedom of Speech in Online Discussions},
	year = {2023},
	journal = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023},
	pages = {644 – 651},
	doi = {10.1145/3625007.3627487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190627818&doi=10.1145%2f3625007.3627487&partnerID=40&md5=b77e7ad52c6496ff1646283b18e9ada3},
	affiliations = {Department of Computer Science, Binghamton University, Binghamton, NY, United States},
	abstract = {This paper emphasizes the necessity of a precise definition of Islamophobia within the realm of social media platforms. The current broad understanding often leads to misclassification and poses challenges to the principles of freedom of speech. Differentiating between Islamophobia and legitimate criticism presents a complex task for automated hate speech detection models, particularly in the presence of offensive language and emotionally charged tones. Furthermore, the paper highlights the inadvertent discriminatory consequences that can arise from misusing Islamophobia detection models against atheists, feminists, ex-Muslims, and others, underscoring the importance of safeguarding their rights. Our study introduces a refined definition and employs advanced deep learning models. It demonstrates a reduction in the number of Islamophobic comments in the dataset while maintaining the accurate identification of genuine instances of Islamophobia. This distinction is made without compromising discussions related to religion and criticism. The results show promise in improving the precision of Islamophobia identification, all while upholding principles of free expression and open dialogue. © 2023 Owner/Author(s).},
	author_keywords = {deep learning; freedom of speech; islamophobia; social media; topics},
	keywords = {Social networking (online); Speech recognition; Deep learning; Detection models; Freedom of speech; Islamophobia; Online discussions; Precise definition; Social media; Social media platforms; Speech detection; Topic; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023; Conference date: 6 November 2023 through 9 November 2023; Conference code: 198206; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gupta20233923,
	author = {Gupta, Shrey and Priyadarshi, Pratyush and Gupta, Manish},
	title = {Hateful Comment Detection and Hate Target-Type Prediction for Video Comments},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3923 – 3927},
	doi = {10.1145/3583780.3615260},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178166260&doi=10.1145%2f3583780.3615260&partnerID=40&md5=1977462c6dc308fc7a0ecb674b2e6baa},
	affiliations = {IIIT-Hyderabad, India; IIIT-Hyderabad, Microsoft, India},
	abstract = {With the widespread increase in hateful content on the web, hate detection has become more crucial than ever. Although vast literature exists on hate detection from text, images and videos, interestingly, there has been no previous work on hateful comment detection (HCD) from video pages. HCD is critical for comment moderation and for flagging controversial videos. Comments are often short, contextual and convoluted making the problem challenging. Toward solving this problem, we contribute a dataset, HateComments, consisting of 2071 comments for 401 videos obtained from two popular video sharing platforms. We investigate two related tasks: binary HCD and 4-class multi-label hate target-type prediction (HTP). We systematically explore the importance of various forms of context for effective HCD. Our initial experiments show that our best method which leverages rich video context (description, transcript and visual input) provides HCD accuracy of ∼78.6% and an ROC AUC score of ∼0.61 for HTP. Code and data is here. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Contextual comments; Hate Detection; Target Type Detection},
	keywords = {Contextual comment; Detection accuracy; Hate detection; Multi-labels; Sharing platforms; Target type; Target type detection; Text images; Type predictions; Video sharing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023; Conference date: 21 October 2023 through 25 October 2023; Conference code: 193792}
}

@ARTICLE{Yun2023641,
	author = {Yun, Sanggeon and Kang, Seungshik and Kim, Hyeokman},
	title = {BERT-Based Logits Ensemble Model for Gender Bias and Hate Speech Detection},
	year = {2023},
	journal = {Journal of Information Processing Systems},
	volume = {19},
	number = {5},
	pages = {641 – 651},
	doi = {10.3745/JIPS.04.0287},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176295117&doi=10.3745%2fJIPS.04.0287&partnerID=40&md5=a5e8746d577c10a43395c1e31f548517},
	affiliations = {Dept. of Computer Science, Kookmin University, Seoul, South Korea; Dept. of Computer Science, University of California, Irvine, CA, United States},
	abstract = {Malicious hate speech and gender bias comments are common in online communities, causing social problems in our society. Gender bias and hate speech detection has been investigated. However, it is difficult because there are diverse ways to express them in words. To solve this problem, we attempted to detect malicious comments in a Korean hate speech dataset constructed in 2020. We explored bidirectional encoder representations from transformers (BERT)-based deep learning models utilizing hyperparameter tuning, data sampling, and logits ensembles with a label distribution. We evaluated our model in Kaggle competitions for gender bias, general bias, and hate speech detection. For gender bias detection, an F1-score of 0.7711 was achieved using an ensemble of the Soongsil-BERT and KcELECTRA models. The general bias task included the gender bias task, and the ensemble model achieved the best F1-score of 0.7166. Copyright© 2023 KIPS},
	author_keywords = {BERT Embedding Model; Gender Bias; Hate Speech Detection; Logistics Ensemble},
	keywords = {Speech recognition; Bidirectional encoder representation from transformer embedding model; Embeddings; Ensemble models; F1 scores; Gender bias; Hate speech detection; Logistic ensemble; On-line communities; Social problems; Speech detection; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kar2023,
	author = {Kar, Purbani and Debbarma, Swapan},
	title = {Sentimental analysis & Hate speech detection on English and German text collected from social media platforms using optimal feature extraction and hybrid diagonal gated recurrent neural network},
	year = {2023},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {126},
	doi = {10.1016/j.engappai.2023.107143},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172296152&doi=10.1016%2fj.engappai.2023.107143&partnerID=40&md5=0c20202dd9b80409e335dc5dd13fec39},
	affiliations = {NIT Agartala, Tripura, India},
	abstract = {Social networking platforms allow users to ask questions, exchange information, opinions, ideas, and promote companies. Social media's massive user-generated text is useful for study, translation, and analysis. Due of their quick spread and detrimental impact, offensive remarks, hate speech, and harassment must be discovered and deleted immediately. In non-English main language environments, code-mixed text makes hate speech detection difficult. Hate speech's thematic emphasis and target-oriented orientation are typically ignored in binary categorization methods. These methods also fail in code-mixing multilingual contexts. In this study, we propose an optimal feature extraction and hybrid diagonal gated recurrent neural network (FE-DGRNN) for hate speech detection and sentiment analysis on code-mixed texts in multiple languages. Our FE-DGRNN technique consists of three processes: preprocessing, improved seagull optimization (ISO) for feature extraction, and hybrid diagonal gated recurrent neural network (Hyb-DGRNN) for hate speech detection and sentiment analysis. We evaluate the performance of our proposed technique using the HASOC 2019 dataset, focusing on English and German. The results demonstrate high accuracy of 95%, 96%, and 92% for English tasks, with Precision and F-measure of 94%, 96%, and 91%. For German tasks, the accuracy is 92% and 93%, with Precision and F-measure of 90% and 91%. © 2023},
	author_keywords = {Classification; Detection; Feature extraction; Hate speech; Pre processing},
	keywords = {Classification (of information); Extraction; Optimal systems; Recurrent neural networks; Sentiment analysis; Social networking (online); Speech recognition; Detection; F measure; Features extraction; Hate speech; Pre-processing; Sentiment analysis; Social media; Social media platforms; Social-networking; Speech detection; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Goswami2024331,
	author = {Goswami, Abhishek and Rawat, Ayushi and Tongaria, Shubham and Jhingran, Sushant},
	title = {Detection of hate speech in multi-modal social post},
	year = {2024},
	journal = {Artificial Intelligence, Blockchain, Computing and Security - Proceedings of the International Conference on Artificial Intelligence, Blockchain, Computing and Security, ICABCS 2023},
	volume = {1},
	pages = {331 – 336},
	doi = {10.1201/9781003393580-50},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186648906&doi=10.1201%2f9781003393580-50&partnerID=40&md5=e157dfd82033163c610b5bd3e5e231db},
	affiliations = {Sharda University, Greater Noida, India},
	abstract = {It has been observed in the past few years, multi- modal problems have been capable of attaining the interest of a large number of people. The core challenges faced in such problems are its representation, alignment, fusion, co-learning, and translation. The focus of this paper is on the analysis of multimodal memes for hate speech. On the evaluation of the dataset, we found out that the common statistics factors which were hateful initially became benign simply by unfolding the picture of thememe. Correspondingly, a bulk of the multi-modal baselines gives hate speech more options. In order to deal with such issues, we discover the visiblemodality through the use of item detection and image captioning fashions to realize the “real caption” after which we integrate it with multi-modal illustration to carry out binary classification. The method challenges the benign textual content co-founders present in the dataset to enhance the enactment. The second method that we use to test is to enhance the prediction with sentiment evaluation. It includes a unimodal sentiment to complement the features. Also we carry out in depth evaluation of the above methods stated, supplying compelling motives in want of the methodologies used. © 2024 The Author(s).},
	keywords = {Binary classification; Co-learning; Depth evaluations; Image captioning; Multi-modal; Multimodal problems; Number of peoples; Textual content; Unfoldings; Unimodal},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Artificial Intelligence, Blockchain, Computing and Security, ICABCS 2023; Conference date: 24 February 2023 through 25 February 2023; Conference code: 307409}
}

@ARTICLE{Jung2023507,
	author = {Jung, Chang Won},
	title = {Role of Informal Social Control in Predicting Racist Hate Speech on Online Platforms: Collective Efficacy and the Theory of Planned Behavior},
	year = {2023},
	journal = {Cyberpsychology, Behavior, and Social Networking},
	volume = {26},
	number = {7},
	pages = {507 – 518},
	doi = {10.1089/cyber.2022.0107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165520874&doi=10.1089%2fcyber.2022.0107&partnerID=40&md5=537bf890094339ce0d3aa894ba1150b7},
	affiliations = {College of Social Sciences, School of Media & Communication, Dankook University, Yongin-si, South Korea},
	abstract = {Drawing on the theory of planned behavior (TPB), the present study examined the relative importance of informal social control and social cohesion/trust in the behavioral intention to post online race-related hate speech. A conceptual framework of a mediation model was validated on data from 809 survey respondents, and age, gender, Internet usage, and the number of posts representing racist hate speech on online platforms in a 1-year period were controlled for as demographic data. Twenty-six measurement items were designed to measure the four TPB constructs of attitude, subjective norm, perceived behavioral control (PBC), and behavioral intention, as well as the two action-oriented variables of social cohesion/trust and informal social control. Partial least-squares structural equation modeling analysis was conducted to test a series of research hypotheses, and the findings were as follows: (a) informal social control partially mediated the relationships between behavioral intention to post online race-related hate speech and both attitude and subjective norm; (b) informal social control fully mediated the influence of PBC on behavioral intention; and (c) social cohesion/trust did not significantly mediate any of the relationships between behavioral intention and attitude, subjective norm, or PBC. The results indicate that the willingness to intervene in informal social control plays an important role in preventing unwelcome online activity.  © 2023, Mary Ann Liebert, Inc., publishers.},
	author_keywords = {collective efficacy; informal social control; online race-related hate speech; social cohesion/trust; theory of planned behavior},
	keywords = {Collective Efficacy; Hate; Humans; Intention; Psychological Theory; Social Control, Informal; Speech; Surveys and Questionnaires; Theory of Planned Behavior; adult; article; collective efficacy; conceptual framework; demographics; drawing; drug efficacy; female; gender; human; human experiment; internet use; major clinical study; male; partial least squares regression; race; social cohesion; speech; structural equation modeling; Theory of Planned Behavior; trust; behavior; hate; psychological theory; questionnaire; social control; speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2023,
	author = {Liu, Lin and Xu, Duo and Zhao, Pengfei and Zeng, Daniel Dajun and Hu, Paul Jen-Hwa and Zhang, Qingpeng and Luo, Yin and Cao, Zhidong},
	title = {A cross-lingual transfer learning method for online COVID-19-related hate speech detection},
	year = {2023},
	journal = {Expert Systems with Applications},
	volume = {234},
	doi = {10.1016/j.eswa.2023.121031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166967683&doi=10.1016%2fj.eswa.2023.121031&partnerID=40&md5=098fad7ffd449a05081dcec247547058},
	affiliations = {Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 101408, China; School of Mathematical Sciences, Beihang University, Beijing, 100191, China; School of Data Science, City University of Hong Kong, Hong Kong; David Eccles School of Business, the University of Utah, UT, United States},
	abstract = {During the COVID-19 pandemic, online social media platforms such as Twitter facilitate the exchange of information among people. However, the prevalence of “infodemic” such as online hate speech has exacerbated social rifts, discrimination, prejudice and even hate crimes. Timely and effective detection of the hate speech will help create a healthy public opinion environment. Most of the current COVID-19-related hate speech research focuses on a single language, such as English. In this paper, we introduce a cross-lingual transfer learning method, aiming to contribute to hate speech detection in low-resource languages. We propose a deep learning based model to classify hate speech with a pre-trained language model for multilingual text embedding. Data augmentation and cross-lingual contrastive learning are then utilized to further improve the performance of cross-lingual knowledge transfer. To evaluate our method, we collected three publicly available annotated COVID-19-related hate speech datasets on Twitter, i.e., two in English and one in German. Furthermore, a Chinese dataset based on Weibo is constructed to expand multilingual data. The experimental results across three languages illustrate the effectiveness of our method for cross-lingual hate speech detection. Test F1-scores of our method for English, Chinese, German as transfer target languages can reach up to 0.728, 0.799 and 0.612 respectively, which are on average better than other baselines. © 2023 Elsevier Ltd},
	author_keywords = {COVID-19; Cross-lingual; Deep learning; Hate speech detection; Natural language processing},
	keywords = {Deep learning; E-learning; Knowledge management; Learning systems; Natural language processing systems; Social aspects; Social networking (online); Speech recognition; Cross-lingual; Deep learning; Hate speech detection; Language processing; Natural language processing; Natural languages; Online social medias; Social media platforms; Speech detection; Transfer learning methods; COVID-19},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Saha20232041,
	author = {Saha, Punyajoy and Sheth, Divyanshu and Kedia, Kushal and Mathew, Binny and Mukherjee, Animesh},
	title = {Rationale-Guided Few-Shot Classification to Detect Abusive Language},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {372},
	pages = {2041 – 2048},
	doi = {10.3233/FAIA230497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175821347&doi=10.3233%2fFAIA230497&partnerID=40&md5=e5ec215811a5279b493d236c8148485c},
	affiliations = {Indian Institute of Technology, Kharagpur, India},
	abstract = {Abusive language is a concerning problem in online social media. Past research on detecting abusive language covers different platforms, languages, demographies, etc. However, models trained using these datasets do not perform well in cross-domain evaluation settings. To overcome this, a common strategy is to use a few samples from the target domain to train models to get better performance in that domain (cross-domain few-shot training). However, this might cause the models to overfit the artefacts of those samples. A compelling solution could be to guide the models toward rationales, i.e., spans of text that justify the text's label. This method has been found to improve model performance in the in-domain setting across various NLP tasks. In this paper, we propose RGFS (Rationale-Guided Few-Shot Classification) for abusive language detection. We first build a multitask learning setup to jointly learn rationales, targets, and labels, and find a significant improvement of 6% macro F1 on the rationale detection task over training solely rationale classifiers. We introduce two rationale-integrated BERT-based architectures (the RGFS models) and evaluate our systems over five different abusive language datasets, finding that in the few-shot classification setting, RGFS-based models outperform baseline models by about 7% in macro F1 scores and perform competitively to models finetuned on other source domains. Furthermore, RGFS-based models outperform LIME/SHAP-based approaches in terms of plausibility and are close in performance in terms of faithfulness. Disclaimer: This paper contains material that many will find offensive or hateful. However, this cannot be avoided owing to the nature of the work. © 2023 The Authors.},
	keywords = {Learning systems; Lime; Petroleum reservoir evaluation; Social networking (online); Common strategy; Cross-domain; Cross-domain evaluations; Modeling performance; Online social medias; Performance; Shot classification; Target domain; Text labels; Train model; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 26th European Conference on Artificial Intelligence, ECAI 2023; Conference date: 30 September 2023 through 4 October 2023; Conference code: 193052; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bel-Enguix2023361,
	author = {Bel-Enguix, Gemma and Gómez-Adorno, Helena and Sierra, Gerardo and Vásquez, Juan and Andersen, Scott Thomas and Ojeda-Trueba, Sergio},
	title = {Overview of HOMO-MEX at Iberlef 2023: Hate speech detection in Online Messages directed Towards the MEXican Spanish speaking LGBTQ+ population; [Resumen de HOMO-MEX en Iberlef 2023: Detección de discuros de odio en mensajes online dirigidos hacia la población LGBTQ+ hablante de español mexicano]},
	year = {2023},
	journal = {Procesamiento del Lenguaje Natural},
	number = {71},
	pages = {361 – 370},
	doi = {10.26342/2023-71-28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175096059&doi=10.26342%2f2023-71-28&partnerID=40&md5=c2761a72dc8dd422052c73ff5f68511b},
	affiliations = {Instituto de Ingeniería, (UNAM), Mexico; Insituto de Investigaciones en Matemáticas Aplicadas y Sistemas, (UNAM), Mexico; UNAM, Mexico; Facultat de Filologia i Comunicació, (UB), Spain},
	abstract = {The detection of hate speech and stereotypes in online platforms has gained significant attention in the field of Natural Language Processing (NLP). Among various forms of discrimination, LGBTQ+ phobia is prevalent on social media, particularly on platforms like Twitter. The objective of the HOMO-MEX task is to encourage the development of NLP systems that can detect and classify LGBTQ+ phobic content in Spanish tweets, regardless of whether it is expressed aggressively or subtly. The task aims to address the lack of dedicated resources for LGBTQ+ phobia detection in Spanish Twitter and encourages participants to employ multi-label classification approaches. © 2023 Sociedad Espanola para el Procesamiento del Lenguaje Natural. All rights reserved.},
	author_keywords = {hate speech; LGBTQ+ phobia; machine learning; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{Bonetti2023,
	author = {Bonetti, Andrea and Martínez-Sober, Marcelino and Torres, Julio C. and Vega, Jose M. and Pellerin, Sebastien and Vila-Francés, Joan},
	title = {Comparison between Machine Learning and Deep Learning Approaches for the Detection of Toxic Comments on Social Networks},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {10},
	doi = {10.3390/app13106038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160834689&doi=10.3390%2fapp13106038&partnerID=40&md5=3e115e74fa63a83b4d78ce4aa5a2aaa6},
	affiliations = {Intelligent Data Analysis Laboratory (IDAL), Department of Electronic Engineering, ETSE (Engineering School), Universitat de València (UV), Av. Universitat, sn, Burjassot, 46100, Spain; Allot Communications Spain SLU, C. José Echegaray, 8, Las Rozas de Madrid, 28232, Spain},
	abstract = {The way we communicate has been revolutionised by the widespread use of social networks. Any kind of online message can reach anyone in the world almost instantly. The speed with which information spreads is undoubtedly the strength of social networks, but at the same time, any user of these platforms can see how toxic messages spread in parallel with likes, comments and ratings about any person or entity. In such cases, the victim feels even more helpless and defenceless as a result of the rapid spread. For this reason, we have implemented an automatic detector of toxic messages on social media. This allows us to stop toxicity in its tracks and protect victims. In particular, the aim of the survey is to demonstrate how traditional Machine Learning methods of Natural Language Processing (NLP) work on equal terms with Deep Learning methods represented by a Transformer architecture and characterised by a higher computational cost. In particular, the paper describes the results obtained by testing different supervised Machine Learning classifiers (Logistic Regression, Random Forest and Support Vector Machine) combined with two topic-modelling techniques of NLP, (Latent Semantic Analysis and Latent Dirichlet Allocation). A pre-trained Transformer named BERTweet was also tested. All models performed well in this task, so much so that values close to or above 90% were achieved in terms of the F1 score evaluation metric. The best result achieved by Transformer BERTweet, 91.40%, was therefore not impressive in this context, as the performance gains are too small compared to the computational overhead. © 2023 by the authors.},
	author_keywords = {deep learning; machine learning; natural language processing; sentiment analysis; topic modelling; transformers},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access}
}

@ARTICLE{Toshevska2024222,
	author = {Toshevska, Martina and Kalajdziski, Slobodan and Gievska, Sonja},
	title = {Graph Neural Networks for Antisocial Behavior Detection on Twitter},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {1991 CCIS},
	pages = {222 – 236},
	doi = {10.1007/978-3-031-54321-0_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187695462&doi=10.1007%2f978-3-031-54321-0_15&partnerID=40&md5=01c51d21e7ad6dd96323cbd11762ceef},
	affiliations = {Faculty of Computer Science and Engineering, Ss Cyril and Methodiuos University, Skopje, North Macedonia},
	abstract = {Social media resurgence of antisocial behavior has exerted a downward spiral on stereotypical beliefs, and hateful comments towards individuals and social groups, as well as false or distorted news. The advances in graph neural networks employed on massive quantities of graph-structured data raise high hopes for the future of mediating communication on social media platforms. An approach based on graph convolutional data was employed to better capture the dependencies between the heterogeneous types of data. Utilizing past and present experiences on the topic, we proposed and evaluated a graph-based approach for antisocial behavior detection, with general applicability that is both language- and context-independent. In this research, we carried out an experimental validation of our graph-based approach on several PAN datasets provided as part of their shared tasks, that enable the discussion of the results obtained by the proposed solution. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {fake news detection; GAT; graph representation; Graph Transformer; GraphSAGE; hate speech detection; heterogeneous graph; irony detection; node classification},
	keywords = {Fake detection; Graph structures; Graphic methods; Social networking (online); Speech recognition; Fake news detection; GAT; Graph representation; Graph transformer; GraphSAGE; Hate speech detection; Heterogeneous graph; Irony detection; Node classification; Speech detection; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on ICT Innovations, ICT Innovations 2023; Conference date: 24 September 2023 through 26 September 2023; Conference code: 308769}
}

@CONFERENCE{Shrestha2023624,
	author = {Shrestha, Amendra and Kaati, Lisa and Akrami, Nazar and Linden, Kevin and Moshfegh, Arvin},
	title = {Harmful Communication: Detection of Toxic Language and Threats on Swedish},
	year = {2023},
	journal = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023},
	pages = {624 – 630},
	doi = {10.1145/3625007.3627597},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190627665&doi=10.1145%2f3625007.3627597&partnerID=40&md5=600cbbcb45179e2b548b7da803841433},
	affiliations = {Stockholm University, Stockholm, Sweden; Mind Intelligence Lab, Uppsala, Sweden; Uppsala University, Uppsala, Sweden},
	abstract = {Harmful communication, such as toxic language and threats directed toward individuals or groups, is a common problem on most social media platforms and online spaces. While several approaches exist for detecting toxic language and threats in English, few attempts have detected such communication in Swedish. Thus, we used transfer learning and BERT to train two machine learning models: one that detects toxic language and one that detects threats in Swedish. We also examined the intersection between toxicity and threat. The models are trained on data from several different sources, with authentic social media posts and data translated from English. Our models perform well on test data with an F1-score above 0.94 for detecting toxic language and 0.86 for detecting threats. However, the models' performance decreases significantly when they are applied to new unseen social media data. Examining the intersection between toxic language and threats, we found that 20% of the threats on social media are not toxic, which means that they would not be detected using only methods for detecting toxic language. Our finding highlights the difficulties with harmful language and the need to use different methods to detect different kinds of harmful language. © 2023 Owner/Author(s).},
	keywords = {Learning systems; Transfer learning; F1 scores; Machine learning models; Modeling performance; Social media; Social media datum; Social media platforms; Swedishs; Test data; Transfer learning; Two machines; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023; Conference date: 6 November 2023 through 9 November 2023; Conference code: 198206; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jan2024127,
	author = {Jan, Zahoor and Shah, Babar and Khan, Mohsin and Nasir, Mansoor and Tahir, Faryal},
	title = {Violent Behavior Detection in Surveillance Videos Using MoSIFT and SVM},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {839},
	pages = {127 – 134},
	doi = {10.1007/978-981-99-8324-7_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189498145&doi=10.1007%2f978-981-99-8324-7_12&partnerID=40&md5=867ed70af36db6984504a31fb204e024},
	affiliations = {DIP Lab, Department of Computer Science, Islamia College Peshawar, Peshawar, Pakistan; College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates},
	abstract = {Most of the recent research in action recognition is mainly focused on recognizing activities of human like clapping, jogging, running, etc. Detection of the violent behavior has been relatively less studied. The applications of violent behavior detection are huge and it can be used in surveillance videos, prisons, university campuses, international borders and anywhere where the cameras provide sufficient line of sight for a sensitive region. In this paper for finding violent behavior in surveillance videos, we used the popular Bag-of-visual-words framework. The feature descriptor that we used is MoSIFT and STIP that provide the feature vector for Bag-of-visual-words to detect violence using Support Vector Machine classifier. The linear classifier provides labels of both violent and non-violent scenes along with description of the video. The experimental evaluation is done with two different datasets while the model is implemented on Raspberry Pi. Experiment results suggest that we can achieve more than 90% accuracy with the MoSIFT descriptor. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {MoSIFT; Raspberry Pi; Surveillance videos; Violence detection},
	keywords = {Security systems; Action recognition; Bag-of-visual-words; Behavior detection; Human like; MoSIFT; Raspberry pi; Recent researches; Surveillance video; Violence detections; Violent behavior; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 17th International Conference on Information Technology and Applications, ICITA 2023; Conference date: 20 October 2022 through 22 October 2022; Conference code: 309789}
}

@ARTICLE{Zhang202413773,
	author = {Zhang, Yaosheng and Zhong, Tiegang and Yi, Tingjun and Li, Haoming},
	title = {Domain-Enhanced Prompt Learning for Chinese Implicit Hate Speech Detection},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {13773 – 13782},
	doi = {10.1109/ACCESS.2024.3351804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182348043&doi=10.1109%2fACCESS.2024.3351804&partnerID=40&md5=8831c83318b21c1a7de33b1e1fee2a60},
	affiliations = {Liaoning Technical University, School of Electronic and Information Engineering, Huludao, 125105, China; Henan University of Animal Husbandry and Economy, School of Information Engineering, Zhengzhou, 450000, China},
	abstract = {Hate Speech Detection, aims to identify the widespread presence of harmful speech on social networks, is a long-standing research field. Despite its significance, previous efforts almost focused on English, leading to a notable scarcity of datasets for Hate Speech Detection in Chinese. Even more, two emerging forms of hate speech under stringent regulatory environments: 1) domain specificity, manifesting itself as nuanced and harder-to-detect proprietary aggressive rhetoric within various domains; and 2) implicitness, characterized by indirect, abstract and ambiguous cold language. This evolution presents additional complexities for Multi-domain Implicit Hate Speech Detection in Chinese. To fill this gap, we construct a 20,000-large implicit hate speech detection dataset containing nine domains. Furthermore, this research introduce a Domain-enhanced Prompt Learning (DePL) approach, tailored to navigate the complexities of multi-domain and data-limited scenarios. This methodology innovatively combines domain feature fusion to effectively encode domain-specific features in hate speech with the latest advances in prompt learning, effectively tackling the dual challenges of domain diversity and data scarcity. Experimental results demonstrate that the DePL method achieves state-of-the-art (SOTA) results on our benchmark dataset in both few-shot and full-scale scenarios.  © 2013 IEEE.},
	author_keywords = {domain feature; few-shot; Hate speech detection; prompt learning},
	keywords = {Air navigation; Job analysis; Semantics; Speech recognition; Domain feature; Features extraction; Few-shot; Few-shot learning; Hate speech; Hate speech detection; Prompt learning; Speech detection; Support vectors machine; Task analysis; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Khezzar2023,
	author = {Khezzar, Ramzi and Moursi, Abdelrahman and Al Aghbari, Zaher},
	title = {arHateDetector: detection of hate speech from standard and dialectal Arabic Tweets},
	year = {2023},
	journal = {Discover Internet of Things},
	volume = {3},
	number = {1},
	doi = {10.1007/s43926-023-00030-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181480888&doi=10.1007%2fs43926-023-00030-9&partnerID=40&md5=a59496d4a678b4603ba3df332b94c3e9},
	affiliations = {Department of Computer Science, University of Sharjah, Street, Sharjah, United Arab Emirates},
	abstract = {Hate speech has become a phenomenon on social media platforms, such as Twitter. These websites and apps that were initially designed to facilitate our expression of free speech, are sometimes being used to spread hate towards each other. In the Arab region, Twitter is a very popular social media platform and thus the number of tweets that contain hate speech is increasing rapidly. Many tweets are written either in standard, dialectal Arabic, or mix. Existing work on Arabic hate speech are targeted towards either standard or single dialectal text, but not both. To fight hate speech more efficiently, in this paper, we conducted extensive experiments to investigate Arabic hate speech in tweets. Therefore, we propose a framework, called arHateDetector, that detects hate speech in the Arabic text of tweets. The proposed arHateDetector supports both standard and several dialectal Arabic. A large Arabic hate speech dataset, called arHateDataset, was compiled from several Arabic standard and dialectal tweets. The tweets are preprocessed to remove the unwanted content. We investigated the use of recent machine learning and deep learning models such as AraBERT to detect hate speech. All classification models used in the investigation are trained with the compiled dataset. Our experiments shows that AraBERT outperformed the other models producing the best performance across seven different datasets including the compiled arHateDataset with an accuracy of 93%. CNN and LinearSVC produced 88% and 89% respectively. © The Author(s) 2023.},
	author_keywords = {Arabic; Deep learning; Hate speech; Machine learning; Twitter},
	keywords = {Classification (of information); Deep learning; Learning systems; Social networking (online); Speech recognition; Arabic; Arabic texts; Deep learning; Dialectal arabics; Free speech; Hate speech; Machine-learning; Social media platforms; Standard arabics; Twitter; Large datasets},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@ARTICLE{Garg2024179,
	author = {Garg, Nitik and Vikram, Piyush Kumar and Rajora, Nidant and Goel, Anurag},
	title = {Ensemble Deep Model for Hate Speech Detection},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {896},
	pages = {179 – 190},
	doi = {10.1007/978-981-99-9811-1_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188747299&doi=10.1007%2f978-981-99-9811-1_14&partnerID=40&md5=b40c40320c37fb5c2cc51f1ed6d0777a},
	affiliations = {Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India},
	abstract = {Over the last decade, online platforms such as Meta and Twitter have experienced a significant increase in data due to a surge in users. Unfortunately, this growth led to an increase in hate speech content on social media platforms. The detection of hate speech is critical for various applications, including sentiment analysis and abusive content identification. Deep learning models have become increasingly popular for detecting hate speech online. This study employed three deep learning models, namely Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (Bi-LSTM), and Robustly BeRT pre-training approach (RoBeRTa) model for hate speech detection. Additionally, we proposed an integrated model that combined CNN, Bi-LSTM, and RoBeRTa and evaluated the models using a dataset of hate speech extracted from Twitter. The integrated model produced better results than the other models evaluated. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Bidirectional long short-term memory (Bi-LSTM); Convolutional neural network (CNN); Hate speech detection; Robustly BeRT pre-training approach (RoBeRTa)},
	keywords = {Brain; Convolution; Convolutional neural networks; Learning systems; Sentiment analysis; Social networking (online); Speech recognition; Bidirectional long short-term memory; Convolutional neural network; Hate speech detection; Integrated modeling; Learning models; Online platforms; Pre-training; Robustly BeRT pre-training approach; Speech detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Recent Developments in Cyber Security, ReDCySec 2023; Conference date: 16 June 2023 through 17 June 2023; Conference code: 309229}
}

@ARTICLE{Ataei20232787,
	author = {Ataei, Taha Shangipour and Darvishi, Kamyar and Javdan, Soroush and Pourdabiri, Amin and Minaei-Bidgoli, Behrouz and Pilehvar, Mohammad Taher},
	title = {Pars-OFF: A Benchmark for Offensive Language Detection on Farsi Social Media},
	year = {2023},
	journal = {IEEE Transactions on Affective Computing},
	volume = {14},
	number = {4},
	pages = {2787 – 2795},
	doi = {10.1109/TAFFC.2022.3219229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141586149&doi=10.1109%2fTAFFC.2022.3219229&partnerID=40&md5=1b961d14f0fbb89bbf979acdf73da722},
	affiliations = {Iran University of Science and Technology, Department of Computer Engineering, Tehran, 16846-13114, Iran; Carleton University, School of Computer Science, Ottawa, K1S 5B6, ON, Canada; Khatam University, Tehran Institute for Advanced Studies, Tehran, 1991813741, Iran},
	abstract = {With the increasing use of social media with its ability for users to share comments immediately, the extent of a system to identify offensive content has become a necessity in all languages. Due to the lack of publicly available resources on offensive language identification for Farsi, which has more than 110 million speakers, we present Pars-OFF, a three-layered annotated corpus for offensive language detection in Farsi to fill the existing gap. The introduced corpus contains 10,563 data samples. The tweets have been collected with a combination of similarity-based and keyword-based data selection techniques to avoid severe unbalancedness. Additionally, as a baseline, this article reports the performance of the traditional machine learning approaches and Transformer based models over the Pars-OFF dataset. The best performance was obtained by the BERT+fastText model, yielding the F1-Macro score of 89.57.  © 2010-2012 IEEE.},
	author_keywords = {Abusive language detection; farsi language; farsi social media; offensive language detection},
	keywords = {Data mining; Decision trees; Electronic mail; Job analysis; Learning systems; Social networking (online); Abusive language detection; Annotation; Cyber bullying; Data collection; Farsi language; Farsi social medium; Language detection; Offensive language detection; Offensive languages; Random forests; Social media; Task analysis; Blogs},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Park20231851,
	author = {Park, Jaeil and Cho, Sung-Bae},
	title = {Adversarial Discriminator to Mitigate Gender Bias in Abusive Language Detection},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {372},
	pages = {1851 – 1858},
	doi = {10.3233/FAIA230473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175870948&doi=10.3233%2fFAIA230473&partnerID=40&md5=07b5f7e060285ff665dae8d99eb91a86},
	affiliations = {Department of Computer Science, Yonsei University, Seoul, 03722, South Korea},
	abstract = {Abusive language detection models tend to have a gender bias problem in which the model is biased towards sentences containing identity words of specific gender groups. Previous studies to reduce bias, such as projection methods, tend to lose information in word vectors and sentence context, resulting in low detection accuracy. This paper proposes a novel method that mitigates gender bias while preserving original information by regularizing sentence embedding vectors based on information theory. Latent vectors generated by an autoencoder are debiased through dual regularization using a gender discriminator, an abuse classifier, and a decoder. While the gender discriminator labels are randomized, the discriminator confuses the gender feature, and the classifier retains the abuse information. Latent vectors are regularized through information theoretic adversarial optimization that disentangles and mitigates gender features. We show that the proposed method successfully orthogonalizes the direction of the correlated information and reduces the gender feature through calculation of subspaces and embedding vector visualization. Moreover, the proposed method maintains the highest accuracy among the four state-of-the-art bias mitigation methods and shows superior performance in reducing gender bias in four different Twitter datasets for abusive language detection. © 2023 The Authors.},
	keywords = {Classification (of information); Discriminators; Information theory; Vectors; Bias problems; Detection accuracy; Detection models; Embeddings; Gender bias; Language detection; Latent vectors; Novel methods; Projection method; Word vectors; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 26th European Conference on Artificial Intelligence, ECAI 2023; Conference date: 30 September 2023 through 4 October 2023; Conference code: 193052; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{García-Díaz20232893,
	author = {García-Díaz, José Antonio and Jiménez-Zafra, Salud María and García-Cumbreras, Miguel Angel and Valencia-García, Rafael},
	title = {Evaluating feature combination strategies for hate-speech detection in Spanish using linguistic features and transformers},
	year = {2023},
	journal = {Complex and Intelligent Systems},
	volume = {9},
	number = {3},
	pages = {2893 – 2914},
	doi = {10.1007/s40747-022-00693-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134252985&doi=10.1007%2fs40747-022-00693-x&partnerID=40&md5=563c827e73802ad8135d587301714df1},
	affiliations = {Facultad de Informática, Universidad de Murcia, Campus de Espinardo, Murcia, 30100, Spain; Computer Science Department, SINAI, CEATIC, Universidad de Jaén, Jaén, 23071, Spain},
	abstract = {The rise of social networks has allowed misogynistic, xenophobic, and homophobic people to spread their hate-speech to intimidate individuals or groups because of their gender, ethnicity or sexual orientation. The consequences of hate-speech are devastating, causing severe depression and even leading people to commit suicide. Hate-speech identification is challenging as the large amount of daily publications makes it impossible to review every comment by hand. Moreover, hate-speech is also spread by hoaxes that requires language and context understanding. With the aim of reducing the number of comments that should be reviewed by experts, or even for the development of autonomous systems, the automatic identification of hate-speech has gained academic relevance. However, the reliability of automatic approaches is still limited specifically in languages other than English, in which some of the state-of-the-art techniques have not been analyzed in detail. In this work, we examine which features are most effective in identifying hate-speech in Spanish and how these features can be combined to develop more accurate systems. In addition, we characterize the language present in each type of hate-speech by means of explainable linguistic features and compare our results with state-of-the-art approaches. Our research indicates that combining linguistic features and transformers by means of knowledge integration outperforms current solutions regarding hate-speech identification in Spanish. © 2022, The Author(s).},
	author_keywords = {Feature engineering; Hate-speech; Knowledge integration; Natural language processing; Text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Gold Open Access}
}

@ARTICLE{Chakravarthi2023,
	author = {Chakravarthi, Bharathi Raja and Jagadeeshan, Manoj Balaji and Palanikumar, Vasanth and Priyadharshini, Ruba},
	title = {Offensive language identification in dravidian languages using MPNet and CNN},
	year = {2023},
	journal = {International Journal of Information Management Data Insights},
	volume = {3},
	number = {1},
	doi = {10.1016/j.jjimei.2022.100151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145303478&doi=10.1016%2fj.jjimei.2022.100151&partnerID=40&md5=d218c53faf6a8195531179d2c51e66ed},
	affiliations = {School of Computer Science, University of Galway, Ireland; Birla Institute of Technology and Science Pilani, India; Chennai Institute of Technology, Chennai, India; The Gandhigram Rural Institute - Deemed University, India},
	abstract = {Social media has effectively replaced traditional forms of communication and marketing. As these platforms allow for the free expression of ideas and facts through text, images, and videos, there exists a significant need to screen them to safeguard people and organisations from objectionable information directed at them. Our work aims to categorise code-mixed social media comments and posts in Tamil, Malayalam, and Kannada into offensive or not offensive at different levels. We present a multilingual MPNet and CNN fusion model for detecting offensive language content directed at an individual (or group) in low-resource Dravidian languages at different levels. Our model is capable of handling data that has been code-mixed, such as Tamil and Latin scripts. The model was successfully validated on the datasets, achieving offensive language detection results better than those of other baseline models with weighted average F1-score of 0.85, 0.98, and 0.76, and performed better than the baseline models EWDT, and EWODT by 0.02, 0.02, 0.04 for Tamil, Malayalam, and Kannada respectively. © 2022 The Author(s)},
	author_keywords = {CNN; Code-mixing; Deep learning; Dravidian languages; MPNet; Offensive language identification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Gold Open Access}
}

@ARTICLE{Nasution20238423,
	author = {Nasution, Ananda Wongwatana and Zahran, Ariel and Akbar, Muhammad Fazar and Nabiilah, Ghinaa Zain and Rojali},
	title = {HATE SPEECH DETECTION USING LSTM AND NAÏVE BAYES ALGORITHM},
	year = {2023},
	journal = {Journal of Theoretical and Applied Information Technology},
	volume = {101},
	number = {24},
	pages = {8423 – 8429},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182910258&partnerID=40&md5=b4b041565b0ff6d2983cba416c54c149},
	affiliations = {School of Computer Science, Bina Nusantara University, Indonesia},
	abstract = {Hate speech detection requires effective strategies to ensure a safe and inclusive online environment. This research paper presents a comparative study of hate speech detection using Natural Language Processing (NLP) techniques, specifically Naïve Bayes and Long Short-Term Memory (LSTM) approaches. The objective is to develop models capable of automatically identifying and analyzing hate speech in written language. The prevalence and impact of hate speech are emphasized, as it can lead to psychological harm and incite criminal acts. NLP offers a valuable tool for automatically detecting potentially dangerous content and addressing this problem. The study utilizes a dynamically generated dataset containing diverse words and expressions to train and evaluate the Naïve Bayes and LSTM models. The results show that the LSTM and the Naïve Bayes model, achieving an accuracy of 74% and 64%. © 2023 Little Lion Scientific.},
	author_keywords = {Hate Speech; LSTM; Naive Bayes; NLP; Text Classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Valle-Cano2023,
	author = {Valle-Cano, Gloria del and Quijano-Sánchez, Lara and Liberatore, Federico and Gómez, Jesús},
	title = {SocialHaterBERT: A dichotomous approach for automatically detecting hate speech on Twitter through textual analysis and user profiles},
	year = {2023},
	journal = {Expert Systems with Applications},
	volume = {216},
	doi = {10.1016/j.eswa.2022.119446},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145665360&doi=10.1016%2fj.eswa.2022.119446&partnerID=40&md5=d86c248dacabb85fa7a4cba7e73e75f7},
	affiliations = {Escuela Politécnica Superior, Universidad Autonóma de Madrid, Madrid, Spain; UC3M-Santander Big Data Institute, Universidad Carlos III de Madrid, Madrid, Spain; School of Computer Science & Informatics, Cardiff University, United Kingdom; Dirección General de Coordinación y Estudios, Secretaría de Estado de Seguridad, Ministerio del Interior, Madrid, Spain},
	abstract = {Social media platforms have evolved into an online representation of our social interactions. We may use the resources they provide to analyze phenomena that occur within them, such as the development and viralization of offensive and hostile content. In today's polarized world, the escalating nature of this behavior is cause for concern in modern society. This research includes an in-depth examination of previous efforts and strategies for detecting and preventing hateful content on the social network Twitter, as well as a novel classification approach based on users’ profiles, related social environment and generated tweets. This paper's contribution is threefold: (i) an improvement in the performance of the HaterNet algorithm, an expert system developed in collaboration with the Spanish National Office Against Hate Crimes of the Spanish State Secretariat for Security (Ministry of the Interior) that is capable of identifying and monitoring the evolution of hate speech on Twitter using an LTSM + MLP neural network architecture. To that end, a model based on BERT, HaterBERT, has been created and tested using HaterNet's public dataset, providing results that show a significant improvement; (ii) A methodology to create a user database in the form of a relational network to infer textual and centrality features. This contribution, SocialGraph, has been independently tested with various traditional Machine Learning and Deep Learning algorithms, demonstrating its usefulness in spotting haters; (iii) a final model, SocialHaterBERT, that integrates the previous two approaches by analyzing features other than those inherent in the text. Experiment results reveal that this last contribution greatly improves outcomes, establishing a new field of study that transcends textual boundaries, paving the way for future research in coupled models from a diachronic and dynamic perspective. © 2022 The Author(s)},
	author_keywords = {BERT; Deep learning; Hate speech; Social network analysis; Topic modeling; Twitter},
	keywords = {Deep learning; Expert systems; Learning systems; Network architecture; Social networking (online); User profile; BERT; Deep learning; Hate speech; Online representation; Social media platforms; Social Network Analysis; Textual-analysis; Topic Modeling; Twitter; User's profiles; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zia Ur Rehman2023,
	author = {Zia Ur Rehman, Mohammad and Mehta, Somya and Singh, Kuldeep and Kaushik, Kunal and Kumar, Nagendra},
	title = {User-aware multilingual abusive content detection in social media},
	year = {2023},
	journal = {Information Processing and Management},
	volume = {60},
	number = {5},
	doi = {10.1016/j.ipm.2023.103450},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164708603&doi=10.1016%2fj.ipm.2023.103450&partnerID=40&md5=0a85ef383f4a246f93ad2659a64f1bd3},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Indore, India; National Institute of Technology Hamirpur, India},
	abstract = {Despite growing efforts to halt distasteful content on social media, multilingualism has added a new dimension to this problem. The scarcity of resources makes the challenge even greater when it comes to low-resource languages. This work focuses on providing a novel method for abusive content detection in multiple low-resource Indic languages. Our observation indicates that a post's tendency to attract abusive comments, as well as features such as user history and social context, significantly aid in the detection of abusive content. The proposed method first learns social and text context features in two separate modules. The integrated representation from these modules is learned and used for the final prediction. To evaluate the performance of our method against different classical and state-of-the-art methods, we have performed extensive experiments on SCIDN and MACI datasets consisting of 1.5M and 665K multilingual comments, respectively. Our proposed method outperforms state-of-the-art baseline methods with an average increase of 4.08% and 9.52% in the F1-score on SCIDN and MACI datasets, respectively. © 2023 Elsevier Ltd},
	author_keywords = {Abusive content detection; Deep learning; Hate speech detection; Low-resource languages; Machine learning; Multilingual; Social media},
	keywords = {Learning systems; Social networking (online); Speech recognition; Abusive content detection; Content detection; Deep learning; Hate speech detection; Low resource languages; Machine-learning; Multilingual; Social media; Speech detection; User-aware; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Gashroo2023,
	author = {Gashroo, Ovais Bashir and Mehrotra, Monica},
	title = {HiTACoD: Hierarchical Framework for Textual Abusive Content Detection},
	year = {2023},
	journal = {SN Computer Science},
	volume = {4},
	number = {6},
	doi = {10.1007/s42979-023-02213-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172157454&doi=10.1007%2fs42979-023-02213-1&partnerID=40&md5=86867276db5fb747ea2608496656a6ca},
	affiliations = {Department of Computer Science, Jamia Millia Islamia, Delhi, New Delhi, 110025, India},
	abstract = {The effects of textual abusive content on social media can be quite adverse. This study investigates the performance of different machine learning and deep learning models using various feature representation and data augmentation techniques for this task. Also, the need for a multi-classification framework and data balancing in the classification of abusive content is also studied in this paper. The experiments were conducted on a specific dataset and task, and the results indicate that the choice of feature representation and classifier is crucial in textual abusive content detection. The results suggest that Tf-idf representation is more effective than bag of words representation in capturing the meaning and context of words in a text, which can improve the performance of the classifiers in detecting abuse. Additionally, the results also suggest that unigram features might be more effective than bigram features in this dataset. Furthermore, the use of pre-trained word embeddings such as Word2Vec in deep learning models can improve the performance of the models in classification tasks. The results also indicate that the performance of the models improves when data augmentation techniques such as SMOTE and Contextual word embedding data augmenter using BERT-base-uncased model from nlpaug library are used. Overall, the results suggest that the use of pre-trained word embeddings and data augmentation for imbalanced data can be promising for abusive content detection. © 2023, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Deep learning; Machine learning; Natural language processing; Social media; Textual abusive content},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Anandhi2024,
	author = {Anandhi, R.J. and Anusuya Devi, V.S. and Kiruthika Devi, B.S. and Kavin, Balasubramanian Prabhu and Seng, Gan Hong},
	title = {CROA-based feature selection with BERT model for detecting the offensive speech in Twitter data},
	year = {2024},
	journal = {Journal of Autonomous Intelligence},
	volume = {7},
	number = {3},
	doi = {10.32629/jai.v7i3.1122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182234585&doi=10.32629%2fjai.v7i3.1122&partnerID=40&md5=2999d3191d652072fd0029fa102efa45},
	affiliations = {New Horizon College of Engineering, Ring Road, Bellandur Post, Bengaluru, 560103, India; School of Computing, Sathyabama Institute of Science and Technology, Jeppiaar Nagar, Rajiv Gandhi Salai, Chennai, 600119, India; Department of Data Science and Business Systems, SRM Institute of Science and Technology, Kattankulathur, 603203, India; School of AI and Advanced Computing, XJTLU Entrepreneur College (Taicang), Xi’an Jiaotong-Liverpool University, Suzhou, 215400, China},
	abstract = {Online hate speech has flourished on social networking sites due to the widespread availability of mobile computers and other Web knowledge. Extensive research has shown that online exposure to hate speech has real-world effects on marginalized communities. Research into methods of automatically identifying hate speech has garnered significant attention. Hate speech can affect any demographic, while some populations are more vulnerable than others. Relying solely on progressive learning is insufficient for achieving the goal of automatic hate speech identification. It need access to large amounts of labelled data to train a model. Inaccurate statistics on hate speech and preconceived notions have been the biggest obstacles in the field of hate speech research for a long time. This research provides a novel strategy for meeting these needs by combining a transfer-learning attitude-based BERT (Bidirectional Encoder Representations from Transformers) with a coral reef optimization-based approach (CROA). A feature selection (FC) optimization strategy for coral reefs, a coral reefs optimization method mimics coral behaviours for reef location and development. We might think of each potential answer to the problem as a coral trying to establish itself in the reefs. The results are refined at each stage by applying specialized operators from the coral reefs optimization algorithm. When everything is said and done, the optimal solution is chosen. We also use a cutting-edge fine-tuning method based on transfer learning to assess BERT’s ability to recognize hostile contexts in social media communications. The paper evaluates the proposed approach using Twitter datasets tagged for racist, sexist, homophobic, or otherwise offensive content. The numbers show that our strategy achieves 5%–10% higher precision and recall compared to other approaches. © 2024 by author(s).},
	author_keywords = {bidirectional encoder representations from transformers; coral reefs optimization; hate speech detection; natural language processing; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Garg2023,
	author = {Garg, Tanmay and Masud, Sarah and Suresh, Tharun and Chakraborty, Tanmoy},
	title = {Handling Bias in Toxic Speech Detection: A Survey},
	year = {2023},
	journal = {ACM Computing Surveys},
	volume = {55},
	number = {13s},
	doi = {10.1145/3580494},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159235320&doi=10.1145%2f3580494&partnerID=40&md5=b3d7b3395371bd8049a8a195e4d9093e},
	affiliations = {Iit Delhi, India},
	abstract = {Detecting online toxicity has always been a challenge due to its inherent subjectivity. Factors such as the context, geography, socio-political climate, and background of the producers and consumers of the posts play a crucial role in determining if the content can be flagged as toxic. Adoption of automated toxicity detection models in production can thus lead to a sidelining of the various groups they aim to help in the first place. It has piqued researchers' interest in examining unintended biases and their mitigation. Due to the nascent and multi-faceted nature of the work, complete literature is chaotic in its terminologies, techniques, and findings. In this article, we put together a systematic study of the limitations and challenges of existing methods for mitigating bias in toxicity detection.We look closely at proposed methods for evaluating and mitigating bias in toxic speech detection. To examine the limitations of existing methods, we also conduct a case study to introduce the concept of bias shift due to knowledge-based bias mitigation. The survey concludes with an overview of the critical challenges, research gaps, and future directions. While reducing toxicity on online platforms continues to be an active area of research, a systematic study of various biases and their mitigation strategies will help the research community produce robust and fair models.1. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {bias mitigation; bias shift; hate speech; social networks; Toxic speech; unintended bias},
	keywords = {Chemical detection; Knowledge based systems; Speech recognition; Bias mitigation; Bias shift; Hate speech; Political climate; Social network; Speech detection; Systematic study; Toxic speech; Toxicity detection; Unintended bias; Toxicity},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Green Open Access}
}

@ARTICLE{Glazkova2023,
	author = {Glazkova, Anna},
	title = {A comparison of text preprocessing techniques for hate and offensive speech detection in Twitter},
	year = {2023},
	journal = {Social Network Analysis and Mining},
	volume = {13},
	number = {1},
	doi = {10.1007/s13278-023-01156-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178435443&doi=10.1007%2fs13278-023-01156-y&partnerID=40&md5=f7e66f5e2971649e087b490b67c0cb25},
	affiliations = {School of Computer Science, University of Tyumen, 15a Perekopskaya street, Tyumen, 625003, Russian Federation},
	abstract = {Preprocessing is a crucial step for each task related to text classification. Preprocessing can have a significant impact on classification performance, but at present there are few large-scale studies evaluating the effectiveness of preprocessing techniques and their combinations. In this work, we explore the impact of 26 widely used text preprocessing techniques on the performance of hate and offensive speech detection algorithms. We evaluate six common machine learning models, such as logistic regression, random forest, linear support vector classifier, convolutional neural network, bidirectional encoder representations from transformers (BERT), and RoBERTa, on four common Twitter benchmarks. Our results show that some preprocessing techniques are useful for improving the accuracy of models while others may even cause a loss of efficiency. In addition, the effectiveness of preprocessing techniques varies depending on the chosen dataset and the classification method. We also explore two ways to combine the techniques that have proved effective during a separate evaluation. Our results show that combining techniques can produce different results. In our experiments, combining techniques works better for traditional machine learning methods than for other methods. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Hate speech; Offensive speech; Preprocessing; Social networks; Text classification; Twitter},
	keywords = {Classification (of information); Convolutional neural networks; Learning systems; Machine learning; Random forests; Social networking (online); Speech recognition; Text processing; Combining techniques; Hate speech; Offensive speech; Pre-processing techniques; Preprocessing; Social network; Speech detection; Text classification; Text preprocessing; Twitter; Logistic regression},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Brata202358,
	author = {Brata, Dwija Wisnu and Djunaidy, Arif and Siahaan, Daniel Oranova},
	title = {Comparison of Deep Learning Methods in Detecting Hate Speech in Indonesian Tweets},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {58 – 63},
	doi = {10.1145/3626641.3626925},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182402602&doi=10.1145%2f3626641.3626925&partnerID=40&md5=122f23ffcfae71c0695041ac583a289f},
	affiliations = {Department of Informatics, Institut Teknologi Sepuluh Nopember, Indonesia; Department of Information System, Brawijaya University, Indonesia},
	abstract = {Hate speech has negative effects on both the targeted victims and the listeners. The dissemination of hate speech can occur not only physically or verbally, but also in writing on social media. The emergence of hate speech on social media platforms can be difficult to identify in written communication. Currently, hate speech detection relies on machine learning. This study generates a vector representation of words using three pre-trained word insertion models: Global Vectors (GloVe), FastText, and Bidirectional Encoder Representations from Transformers (BERT). Synthetic Minority Oversampling Technique (SMOTE) and Random Over Sampling (ROS) were utilized as balancing methods to rectify data imbalance between classes. In addition, three distinct deep learning architectures were used to identify sentence-level hate speech in Indonesian tweets: Bidirectional Long Sort-Term Memory (BiLSTM), Convolution Neural Network (CNN), and Recurrent Neural Network (RNN). The dataset was collected by crawling the data via the Twitter API. After data underwent preprocessing, characteristics were extracted. Based on experimental results, classifiers employing RNN and BERT embedding and utilizing SMOTE produced the most accurate results (95.5%). © 2023 ACM.},
	author_keywords = {Deep Learning; Hate Speech; Imbalance Data; Indonesia Tweets; Word Embedding},
	keywords = {Balancing; Recurrent neural networks; Social networking (online); Speech communication; Deep learning; Embeddings; Hate speech; Imbalance datum; Indonesia; Indonesia tweet; Learning methods; Social media; Synthetic minority over-sampling techniques; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 8th International Conference on Sustainable Information Engineering and Technology, SIET 2023; Conference date: 24 October 2023 through 25 October 2023; Conference code: 196090}
}

@ARTICLE{Poojari2023638,
	author = {Poojari, Asmita and Pallavi, K.N. and Dsilva, McEnroe Ryan and Kalshetty, Jagadevi N.},
	title = {A Novel Deep Learning Technique for Detection of Violent Content in Videos},
	year = {2023},
	journal = {International Journal of Intelligent Systems and Applications in Engineering},
	volume = {11},
	number = {4},
	pages = {638 – 644},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174822322&partnerID=40&md5=c116c3c8d96c5e42677a29919659a0b3},
	affiliations = {NITTE (Deemed to be University), Dept. of Computer Science and Engineering, NMAM Institute of Technology, Karnataka, Nitte, 574110, India; Cloud Associate, Niveus Solutions, Karnataka, Udupi, 576101, India; Dept. of Computer Science and Engineering, Nitte Meenakshi Institute of Technology, Karnataka, Bengaluru, 560064, India},
	abstract = {With a data of 2.5 quintillion bytes worth of data that is being generated daily, regulation of media uploaded on the social media sites such as Facebook, Instagram, and Reddit is a challenge. In addition to social media platforms, there are also private messaging platforms like WhatsApp and Microsoft Teams which are used by private companies for information exchange, team collaborations, and team conversations which must be content regulated. Content moderation is performed by people (moderators) who have to manually classify content into safe and not safe for work. The exposure of human content moderators to harmful and violent-content over the internet makes moderation less desirable. In this study, we suggest and create a Machine Learning Model that can recognise violent video content and classify them as violent and non-violent. Audio and video are the two parameters we use as inputs. The input video along with the audio is initially processed, if the audio is classified as violent, then the video is marked and classified as violent video. The associated video is put into a video classifier where it is further classed as violent or non-violent if the audio classifier deems the audio to be non-violent. Performance indicators like precision, accuracy, sensitivity, and specificity are used to demonstrate the performance of the suggested model. © 2023, Ismail Saritas. All rights reserved.},
	author_keywords = {Content moderation; specificity; video classifier; violent video},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pamungkas2024450,
	author = {Pamungkas, Endang Wahyu and Purworini, Dian and Putri, Divi Galih Prasetyo and Akhtar, Sohail},
	title = {Enhancing hate speech detection in Indonesian using abusive words lexicon},
	year = {2024},
	journal = {Indonesian Journal of Electrical Engineering and Computer Science},
	volume = {33},
	number = {1},
	pages = {450 – 462},
	doi = {10.11591/ijeecs.v33.i1.pp450-462},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184617495&doi=10.11591%2fijeecs.v33.i1.pp450-462&partnerID=40&md5=f9c080ab5239497c0dcbb35a0fc20584},
	affiliations = {Department of Informatics Engineering, Faculty of Communication and Informatics, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia; Department of Communication Science, Faculty of Communication and Informatics, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia; Department of Electrical Engineering and Informatics, Vocational College, Universitas Gadjah Mada, Yogyakarta, Indonesia; Social Informatics Research Center, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia; Department of Computer Science, Faculty of Engineering Science, Bahria University, Islamabad, Pakistan},
	abstract = {Hate speech is a major challenge in Indonesia, a diverse country with multiple languages and a dynamic online landscape. This research explores the phenomenon of hate speech and its detection, particularly in language contexts with limited resources. We introduce a new abusive words lexicon, created by collecting words from various sources, adapted for Indonesian, Javanese and Sundanese. Our study investigates the practical implementation of this lexicon. We conducted extensive experiments using different datasets and machine learning models, aiming to improve hate speech detection. The results consistently show a positive impact of the lexicon, which significantly improves detection, especially in languages with fewer resources. But this research paves the way for further exploration. The lexicon can be expanded, broadening its scope. Additionally, we suggest investigating more sophisticated models, such as transformer-based models, to more effectively detect hate speech. In a world where hate speech is a growing problem, our research provides valuable insights and tools to combat it effectively in Indonesia and other countries. © 2024 Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Abusive language; Hate speech detection; Low-resource languages; Machine learning; Social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kumar20244819,
	author = {Kumar, Gunjan and Singh, Jyoti Prakash and Singh, Amit Kumar},
	title = {Autoencoder-Based Feature Extraction for Identifying Hate Speech Spreaders in Social Media},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {4},
	pages = {4819 – 4827},
	doi = {10.1109/TCSS.2023.3240098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148444171&doi=10.1109%2fTCSS.2023.3240098&partnerID=40&md5=035857c925c179925ca8adc67a931fd6},
	affiliations = {National Institute of Technology Patna, Department of Computer Science and Engineering, Patna, 800005, India},
	abstract = {Hate speech on social media has become a big problem, making regular users very upset and giving victims depression and suicidal thoughts. Early identification of the user spreading this type of hate speech may be a better solution, allowing hate speech to be stopped at source. In this article, we attempt to identify these hate speech spreaders by finding a representation for each user. Each user's comments are aggregated and fed to an auto-encoder to train it. The encoder part of the auto-encoder is used to get an encoded vector for each user. The encoded vector is used with different machine learning (ML) classifiers to determine if a user is spreading hate speech. The proposed model was tested using the dataset released by PAN 2021 (https://pan.webis.de/data.html) hate speech spreader profiling competition in English and Spanish. The experimental results show that support vector machine (SVM) with encoded vectors as features outperforms existing models with an accuracy of 92% for both English and Spanish dataset. The proposed features extraction technique is found to be equally effective at identifying fake news spreaders on fake news datasets provided by PAN 2020 yielding accuracy values of 95% and 83% for English and Spanish, respectively. © 2014 IEEE.},
	author_keywords = {Autoencoder; hate speech; hate speech spreader; long short-term memory (LSTM)},
	keywords = {Extraction; Job analysis; Learning systems; Long short-term memory; Signal encoding; Social networking (online); Support vector machines; Vectors; Auto encoders; Features extraction; Hate speech; Hate speech spreader; Long short-term memory; Social media; Social networking (online); Support vectors machine; Task analysis; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}@CONFERENCE{Fernando2023,
	author = {Fernando, Eranga and Deng, Jeremiah},
	title = {Enhancing Hate Speech Detection in Sinhala Language on Social Media using Machine Learning},
	year = {2023},
	journal = {Australasian Conference on Information Systems, ACIS 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200118706&partnerID=40&md5=d45a7e2474aedd3bb516e984650c0fcd},
	affiliations = {Department of Information Technology, University of Moratuwa, Sri Lanka; School of Computing, University of Otago, Dunedin, New Zealand},
	abstract = {To counter the harmful dissemination of hate speech on social media, especially abusive outbursts of racism and sexism, automatic and accurate detection is crucial. However, a significant challenge lies in the vast sparsity of available data, hindering accurate classification. This study presents a novel approach to Sinhala hate speech detection on social platforms by coupling a global feature selection process with traditional machine learning, the research scrutinizes hate speech intricacies. A class-based variable feature selection process evaluates significance via global and local scores, identifying optimal values for prevalent classifiers. Utilizing class-based and corpus-based evaluations, we pinpoint optimal feature values for classifiers like SVM, MNB, and RF. Our results reveal notable enhancements in performance, specifically the F1-Score, underscoring how feature selection and parameter tuning work in tandem to boost model efficacy. Furthermore, the study explores nuanced variations in classifier performance across training and testing datasets, emphasizing the importance of model generalization. Copyright © 2023 Fernando & Deng.},
	author_keywords = {Class-Based Assessment; Feature Selection; Hate Speech; High Sparsity},
	keywords = {Classification (of information); Couplings; Social networking (online); Speech recognition; Support vector machines; Class-based; Class-based assessment; Features selection; Global feature; Global score; Hate speech; High sparsity; Machine-learning; Social media; Speech detection; Feature Selection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 34th Australasian Conference on Information Systems, ACIS 2023; Conference date: 5 December 2023 through 8 December 2023; Conference code: 201040}
}

@CONFERENCE{Islam2023,
	author = {Islam, Md. Shamimul and Saha, Subrata and Alam, Md. Mahbub and Kumar Datta, Nayan and Ali, Md. Haidar and Mahbub Alam, Md. and Hossain, Md. Dulal and Golam Moazzam, Md.},
	title = {Natural Language Processing and Machine Learning Approaches to Detect Bangla Hate Speech on Social Media},
	year = {2023},
	journal = {2023 26th International Conference on Computer and Information Technology, ICCIT 2023},
	doi = {10.1109/ICCIT60459.2023.10441452},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187363676&doi=10.1109%2fICCIT60459.2023.10441452&partnerID=40&md5=60f1697c3ca06718cca5a82d31bfb33b},
	affiliations = {Institute of Computer Science (ICS), Bangladesh Atomic Energy Commission, Bangladesh; Institute of Electronics (IE), Bangladesh Atomic Energy Commission, Bangladesh; Jahangirnagar University, Dept. of Computer Science and Engineering, Bangladesh},
	abstract = {In this modern era, with the popularity of the Unicode system, many people use Bangla text to express their opinions, comments, emotions on Facebook, Twitter, and YouTube, etc. However, this social connectivity always does not create positive impacts. Trolling, cyberbullying, online harassment, sexual and political abuse, and cybercrime often create a huge negative physiological effect on victims. In most cases, women, children, and celebrities are the victims which may often lead them to depression and suicidal activity. Therefore, at the early stage, cyberbullying and hate speech detection can reduce these cyber crimes.A few researches have been carried out in the Bangla language to detect cyberbullying and hate speech due to annotated corpora, lexical and morphological analyzers. This research aims to design and develop an effective model to detect Bangla cyberbullying and hate speech text with the combination of Natural Language Processing (NLP) and Machine Learning Classifier algorithms. In this study, we have collected 6244 Bangla text data from various online social platforms consisting of 6 categories of hate speeches. Then, we labeled the data into two main classes-bullied and neutral that were used to train our classifiers after preprocessing and features extracted by the Bangla NLP tool and TF-IDF(Term Frequency -Inverse Document Frequency). Our comparative study outlines that, with an accuracy rate of 89% and considering parameters Recall, Precision, Specificity, F-Score, and ROC, the Random Forest Classifier achieves the best results compared to others.  © 2023 IEEE.},
	author_keywords = {Bangla text; classification; Detection; Hate Speech; machine learning; NLP},
	keywords = {Computer crime; Learning algorithms; Machine learning; Natural language processing systems; Social networking (online); Speech recognition; Text processing; Bangla text; Cyber bullying; Cyber-crimes; Detection; Hate speech; Language processing; Machine learning approaches; Machine-learning; Natural language processing; Natural languages; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 26th International Conference on Computer and Information Technology, ICCIT 2023; Conference date: 13 December 2023 through 15 December 2023; Conference code: 197664}
}

@CONFERENCE{Turjya2023660,
	author = {Turjya, Sapthak Mohajon and Kumari, Rina and Swain, Sujata and Bandyopadhyay, Anjan},
	title = {Multilingual Hate Speech and Offensive Language Detection},
	year = {2023},
	journal = {OCIT 2023 - 21st International Conference on Information Technology, Proceedings},
	pages = {660 – 664},
	doi = {10.1109/OCIT59427.2023.10431222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186700478&doi=10.1109%2fOCIT59427.2023.10431222&partnerID=40&md5=e06300e3f84392596cd31eb9c6f8a449},
	affiliations = {Kalinga Institute of Industrial Technology, School of Computer Engineering, Bhubaneswar, India},
	abstract = {Internet and social media usage has skyrocketed over the past two decades, changing how people communicate with one another on a basic level. Numerous favourable results have resulted from this. The risks and harms that come with it are also there. It is impossible for humans to control the amount of damaging content, such as hate speech, that is available online. Researching automated methods for hate speech identification has drawn more attention from academics. Through the creation of a single homogeneous dataset, we investigate various publicly accessible datasets in this work. We establish a baseline model and enhance model performance scores using various optimisation strategies after classifying them into two categories: hate or non-hate. After achieving a competitive performance score, we develop a tool that, using the same feedback, quickly locates and evaluates a page with an effective measure. This tool then retrains our model using the new data. In three languages: English, German, and Spanish. We demonstrate the superior performance of our multilingual approach. In comparison to most monolingual models, this results in performance that is equal to or better. © 2023 IEEE.},
	author_keywords = {BERT; Hate speech; Label classification; Non-hate speech},
	keywords = {Speech recognition; BERT; Hate speech; Internet media; Label classification; Language detection; Media usage; Non-hate speech; Offensive languages; Performance; Social media; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st OITS International Conference on Information Technology, OCIT 2023; Conference date: 13 December 2023 through 15 December 2023; Conference code: 197426}
}

@CONFERENCE{Ihtiyar20231543,
	author = {Ihtiyar, Musa Nuri and Özdemir, Ömer and Erengül, Mustafa Emre and Özgür, Arzucan},
	title = {A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {1543 – 1549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183294523&partnerID=40&md5=70007a199643281a33444a018431334d},
	affiliations = {Department of Computer Engineering, Boğaziçi University, Turkey},
	abstract = {Offensive language detection is crucial in natural language processing (NLP). We investigated the importance of context for detecting such language in reply tweets on Twitter, where the use of offensive language is widespread. We collected a Turkish tweet dataset where the target group was unvaccinated people during the Covid period. Tweets in the dataset were enriched with contextual information by adding the original tweet to which a particular tweet was posted as a reply. The dataset, which includes over 28,000 tweet-reply pairs, was manually labeled by human annotators and made publicly available. In addition, we compared the performance of different machine learning models with and without contextual information. Our results show that this type of contextual information was not very useful in improving the performance of the models in general, although it slightly increased the macro-averaged F1-score of certain models. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Contextual information; F1 scores; Language detection; Language processing; Machine learning models; Natural languages; Offensive languages; Performance; Target group; Turkishs; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@CONFERENCE{Chnini2023,
	author = {Chnini, Manel and Fredj, Nissaf and Bensaid, Fatma and Kacem, Yessine Hadj},
	title = {Violent Speech Detection in Educational Environments},
	year = {2023},
	journal = {Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA},
	doi = {10.1109/AICCSA59173.2023.10479330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190139907&doi=10.1109%2fAICCSA59173.2023.10479330&partnerID=40&md5=1b4351f8d98b97d8eff121c85f7de2e1},
	affiliations = {University of Gafsa, Faculty of Sciences of Gafsa, Gafsa, Tunisia; University of Sfax, Ces Laboratory, Sfax, Tunisia; University of Sfax, ReGIM Laboratory, Sfax, Tunisia},
	abstract = {Nowadays, social networks allow people to interact by exchanging messages, publishing public or private photos or videos. But sometimes they become a space of toxic language to criticise, insult, hate, and attack. In this context, researchers promote a strong intention to study, analyse and detect hate speech. By automating its detection, the spread of anxiety and the rise of hateful content can be limited, especially among children in the online schools. However, with the absence of online database of vulgar English speech by Students in schools, detecting violent speech becomes a difficult task. In this paper, we propose a new dataset-based framework for the detection of students violent speech using natural language processing and learning techniques. This focuses on a proposed ≪Students's Violent Speech (SVS) dataset ≫ with 7056 tagged tweets. The dataset is collected and pre-processed to be analyzed to show the performance and accuracy of the proposed model.  © 2023 IEEE.},
	author_keywords = {Dataset collection; Detection; Natural language processing; Students; Violent speech},
	keywords = {Learning systems; Natural language processing systems; Speech recognition; Dataset collection; Detection; Educational environment; Language processing; Natural language learning; Natural language processing; Natural languages; Online database; Speech detection; Violent speech; Students},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th ACS/IEEE International Conference on Computer Systems and Applications, AICCSA 2023; Conference date: 4 December 2023 through 7 December 2023; Conference code: 198546}
}

@CONFERENCE{Tillmann2023229,
	author = {Tillmann, Christoph and Trivedi, Aashka and Rosenthal, Sara and Borse, Santosh and Zhang, Rong and Sil, Avirup and Bhattacharjee, Bishwaranjan},
	title = {MUTED Î: Multilingual Targeted Offensive Speech Identification and Visualization},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings of the System Demonstrations},
	pages = {229 – 236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184663184&partnerID=40&md5=e24dc667d866b0d73dc4266ad15426fe},
	affiliations = {IBM Research AI, United States},
	abstract = {Offensive language such as hate, abuse, and profanity (HAP) occurs in various content on the web. While previous work has mostly dealt with sentence level annotations, there have been a few recent attempts to identify offensive spans as well. We build upon this work and introduce MUTED, a system to identify multilingual HAP content by displaying offensive ARGUMENTS and their TARGETS using heat maps to indicate their intensity. MUTED can leverage any transformer-based HAP-classification model and its attention mechanism out-of-the-box to identify toxic spans, without further fine-tuning. In addition, we use the spaCy library to identify the specific TARGETS and ARGUMENTS for the words predicted by the attention heatmaps. We present the model’s performance on identifying offensive spans and their targets in existing datasets and present new annotations on German text. Finally, we demonstrate our proposed visualization tool on multilingual inputs. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Attention mechanisms; Classification models; Fine tuning; Heat maps; Heatmaps; Offensive languages; Performance; Sentence level; Speech identification; Speech visualization; Visualization},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196540}
}

@ARTICLE{Almaliki2023,
	author = {Almaliki, Malik and Almars, Abdulqader M. and Gad, Ibrahim and Atlam, El-Sayed},
	title = {ABMM: Arabic BERT-Mini Model for Hate-Speech Detection on Social Media},
	year = {2023},
	journal = {Electronics (Switzerland)},
	volume = {12},
	number = {4},
	doi = {10.3390/electronics12041048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148897209&doi=10.3390%2felectronics12041048&partnerID=40&md5=54113efb83575e9acc70d9cdaa5225b7},
	affiliations = {College of Computer Science and Engineering, Taibah University, Yanbu, 966144, Saudi Arabia; Faculty of Science, Tanta University, Tanta, 31527, Egypt},
	abstract = {Hate speech towards a group or an individual based on their perceived identity, such as ethnicity, religion, or nationality, is widely and rapidly spreading on social media platforms. This causes harmful impacts on users of these platforms and the quality of online shared content. Fortunately, researchers have developed different machine learning algorithms to automatically detect hate speech on social media platforms. However, most of these algorithms focus on the detection of hate speech that appears in English. There is a lack of studies on the detection of hate speech in Arabic due to the language’s complex nature. This paper aims to address this issue by proposing an effective approach for detecting Arabic hate speech on social media platforms, namely Twitter. Therefore, this paper introduces the Arabic BERT-Mini Model (ABMM) to identify hate speech on social media. More specifically, the bidirectional encoder representations from transformers (BERT) model was employed to analyze data collected from Twitter and classify the results into three categories: normal, abuse, and hate speech. In order to evaluate our model and state-of-the-art approaches, we conducted a series of experiments on Twitter data. In comparison with previous works on Arabic hate-speech detection, the ABMM model shows very promising results with an accuracy score of 0.986 compared to the other models. © 2023 by the authors.},
	author_keywords = {Arabic Twitter; BERT Models; deep learning; hate speech; machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access}
}

@CONFERENCE{Naji2023,
	author = {Naji, Ezzaldeen Mahyoub and Maslekar, Ajit A. and Ahmed, Zeyad A. T. and Alharbi, Alhasan and Al-Sellami, Belal and Tawfik, Mohammed},
	title = {Advancing Arabic Hate Speech Detection via Neural Transfer Learning with BERT},
	year = {2023},
	journal = {2023 3rd International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2023},
	doi = {10.1109/SMARTGENCON60755.2023.10441885},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187572677&doi=10.1109%2fSMARTGENCON60755.2023.10441885&partnerID=40&md5=b1c05cfa06651556f37ada72a81f6d0f},
	affiliations = {Dr. Babasaheb Ambedkar Marathwada University, Dept. of Computer Science, Aurangabad, India; K.T Patil College of Bsc/Msc Computer Science, Dept. of Computer Science, Osmanabad, India},
	abstract = {Online hate speech poses grave societal dangers, necessitating automatic detection systems. However, limited efforts have focused on Arabic's complex dialects. This study investigates neural transfer learning for dialect Arabic hate speech detection. A public Levantine Twitter dataset with 5,846 expert annotated tweets is compiled spanning normal, offensive, and hate speech. Traditional machine learning models including SVM, logistic regression, and gradient boosting are benchmarked, achieving 80-83% accuracy. However, these models fail to capture nuanced contextual differences between offensive and hateful language. To address this, transfer learning is proposed using the pretrained Arabic BERT model ArabERT. ArabERT leverages BERT's bidirectional representations to model linguistic context. ArabERT is fine-tuned on the Levantine dataset for hate speech classification. Results show ArabERT significantly outperforms machine learning models, attaining 90% accuracy and 94% Fl-score specifically for hate speech detection. Detailed analysis demonstrates ArabERT's contextual modeling enables nuanced discernment between offensive and hateful tweets. The outcomes provide strong evidence that transfer learning approaches like ArabERT are crucial for handling informal multi-dialect Arabic. This work makes three key contributions - introducing an effective neural framework for Arabic hate speech detection, rigorous benchmarking, and providing insights into deep learning strategies. The findings showcase transfer learning's efficacy for low-resource Arabic NLP and pave promising directions for future progress. © 2023 IEEE.},
	author_keywords = {ArabERT; Arabic language; Deep Learning Transformer; Hate Speech; Machine Learning; NLP},
	keywords = {Adaptive boosting; Classification (of information); Deep learning; Learning systems; Linguistics; Logistic regression; Online systems; Speech recognition; Support vector machines; Transfer learning; ArabERT; Arabic languages; Automatic detection systems; Deep learning transformer; Hate speech; Machine learning models; Machine-learning; Speech detection; SVM-Logistic regression; Transfer learning; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2023; Conference date: 29 December 2023 through 31 December 2023; Conference code: 197687}
}

@CONFERENCE{Rameez Mohammed2023,
	author = {Rameez Mohammed, A. and Madhukumar, S.D.},
	title = {Hate Speech Detection in Indian Languages: A Brief Survey},
	year = {2023},
	journal = {2023 IEEE 2nd International Conference on Data, Decision and Systems, ICDDS 2023},
	doi = {10.1109/ICDDS59137.2023.10434756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186662542&doi=10.1109%2fICDDS59137.2023.10434756&partnerID=40&md5=689ffa4852d940d088b57d16c9ea40ac},
	affiliations = {National Institute of Technology, Dept. of Computer Science and Engineering, Kerala, Calicut, India},
	abstract = {Social media has revolutionized communication and content publishing. Anonymity and mobility afforded by social media is also an effective medium for dissemination of hate messages, which can lead to undesired outcomes in the society. Prevalence of hate speech is a global problem. This paper is intended to highlight the mechanisms to address the same in the Indian context. This work aims to provide a concise overview of the various machine learning, deep learning, and transformer methods to detect hate speech in social media text written in Indian languages, as detailed in recent research literature. Besides, a discussion some of the available monolingual and code-mixed datasets to train such classifiers and the commonly adopted strategies to address the data scarcity in Indian languages is also included. © 2023 IEEE.},
	author_keywords = {code-mixing; deep learning; hate speech; Indian languages; transfer learning; transformers},
	keywords = {Classification (of information); Codes (symbols); Learning systems; Social networking (online); Speech recognition; Code-mixing; Content publishing; Deep learning; Effective medium; Hate speech; Indian languages; Social media; Speech detection; Transfer learning; Transformer; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Data, Decision and Systems, ICDDS 2023; Conference date: 1 December 2023 through 2 December 2023; Conference code: 197456}
}

@CONFERENCE{Dhankhar2023494,
	author = {Dhankhar, Anu and Prakash, Amresh and Juneja, Sapna},
	title = {Feature Extraction from Text using Grasshopper optimization algorithm for identifying hate speech},
	year = {2023},
	journal = {2023 International Conference on Advances in Computation, Communication and Information Technology, ICAICCIT 2023},
	pages = {494 – 498},
	doi = {10.1109/ICAICCIT60255.2023.10466147},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189883779&doi=10.1109%2fICAICCIT60255.2023.10466147&partnerID=40&md5=9fbd4b9b7aca1ea1569b0dc425c25f28},
	affiliations = {Amity Institute of Biotechnology, Amity University, Gurugram, India; Kiet Group of Institutions, Ghaziabad, India},
	abstract = {The optimization algorithms have ability to eliminate features that are extraneous and redundant, shrink the vector space, manage computation time, and enhance performance on problems requiring more accurate classification. Feature selection and feature extraction have always been crucial, especially in text categorization. Using optimization algorithms, engineering methods are used in these can be improved still further. Using five machine learning (ML) models - Decision Tree (DT), Naive Bayes (NB), Random Forest (RF) and Multilayer Perceptron (MLP) and Deep Neural Network (DNN) - this paper implements one such optimization algorithm, Grasshopper optimization (GOA), using various feature extraction and selection methods on textual datasets. The machine learning model performs more effectively due to the suggested feature selection and feature extraction strategies. In order to identify hate speech, this study takes into consideration text-based datasets. The positive, negative, and neutral sentiments of tweets are extracted from the Twitter API to create the text collection. On the application of GAO, Combining Random Forest with the method of feature extraction TF-IDF shows a greatest accuracy improvement of 24% as compared with without applied any optimization algorithm and 13% accuracy increased as compared with another optimization algorithm i.e., ACO. GOA provides an accuracy of up to 93%, which is superior to ACO optimization algorithm's 80% accuracy when used with the Random Forest model. © 2023 IEEE.},
	author_keywords = {Grasshopper optimization algo; hate speech; machine learning; optimization algorithms; text-based},
	keywords = {Decision trees; Deep neural networks; Extraction; Learning systems; Multilayer neural networks; Optimization; Random forests; Text processing; Vector spaces; Features extraction; Features selection; Grasshopper optimization algo; Hate speech; Machine learning models; Machine-learning; Optimisations; Optimization algorithms; Random forests; Text-based; Feature Selection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Advances in Computation, Communication and Information Technology, ICAICCIT 2023; Conference date: 23 November 2023 through 24 November 2023; Conference code: 198271}
}

@CONFERENCE{Elsafoury202353,
	author = {Elsafoury, Fatma},
	title = {Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection},
	year = {2023},
	journal = {BigPicture 2023 - Big Picture Workshop, Proceedings},
	pages = {53 – 65},
	doi = {10.18653/v1/2023.bigpicture-1.5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184658795&doi=10.18653%2fv1%2f2023.bigpicture-1.5&partnerID=40&md5=ea6df8572637391e2ecce3be410e731b},
	affiliations = {Fraunhofer Research Institute (FOKUS), Berlin, Germany},
	abstract = {This paper is a summary of the work done in my PhD thesis. Where I investigate the impact of bias in NLP models on the task of hate speech detection from three perspectives: explainability, offensive stereotyping bias, and fairness. Then, I discuss the main takeaways from my thesis and how they can benefit the broader NLP community. Finally, I discuss important future research directions. The findings of my thesis suggest that the bias in NLP models impacts the task of hate speech detection from all three perspectives. And that unless we start incorporating social sciences in studying bias in NLP models, we will not effectively overcome the current limitations of measuring and mitigating bias in NLP models. © 2023 - Big Picture Workshop.All rights reserved},
	keywords = {Distillation; Speech recognition; Current limitation; Future research directions; PhD thesis; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st Big Picture Workshop: Crafting a Research Narrative, BigPicture 2023; Conference date: 7 December 2023; Conference code: 196513; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Su2023690,
	author = {Su, Leilei and Wang, Zezheng and Peng, Yifan and Sun, Cong},
	title = {Identification of Offensive Language in Social Media Using Prompt Learning},
	year = {2023},
	journal = {Proceedings - 2023 IEEE 11th International Conference on Healthcare Informatics, ICHI 2023},
	pages = {690 – 691},
	doi = {10.1109/ICHI57859.2023.00122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181575692&doi=10.1109%2fICHI57859.2023.00122&partnerID=40&md5=0da0995f763593008e24d6fd2f90b8ff},
	affiliations = {Hainan University, Department of Mathematics, Haikou, China; Hainan University, Department of Data Science and Big Data Technology, Haikou, China; Weill Cornell Medicine, Department of Population Health Sciences, New York, United States},
	abstract = {Offensive language refers to the use of language in a manner that may offend or harm others who are within earshot or view in a public place. Given the importance of identifying such language in social media for promoting emotional well-being, we propose a prompt learning method and compare its performance with fine-tuning on two widely used datasets, HatEval and OffensEval. Experimental results demonstrate that prompt learning can achieve a performance improvement over fine-tuning in a fully supervised setting. © 2023 IEEE.},
	author_keywords = {hate speech; language model; offensive language; prompt learning; text mining},
	keywords = {Social networking (online); Fine tuning; Hate speech; Language model; Offensive languages; Performance; Prompt learning; Public places; Social media; Text-mining; Well being; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th IEEE International Conference on Healthcare Informatics, ICHI 2023; Conference date: 26 June 2023 through 29 June 2023; Conference code: 195320}
}

@CONFERENCE{Chanda2023486,
	author = {Chanda, Supriya and Dhaka, Abhishek and Pal, Sukomal},
	title = {Crossing Borders: Multilingual Hate Speech Detection},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {486 – 500},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193955756&partnerID=40&md5=b503d7edded89080df97e820c6a0809e},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology (BHU), Varanasi, 221005, India; Department of Computer Science and Engineering, B.K. Birla Institute of Engineering&Technology, Pilani, 333031, India},
	abstract = {With the relentless growth of technology usage, particularly among younger generations, the alarming prevalence of hate speech on the internet has become an urgent global concern. This research paper addresses this critical need by presenting an extensive investigation encompassing three distinct hate speech detection tasks across a diverse linguistic landscape. The first task involves hate and offensive speech classification in Gujarati and Sinhala, assessing sentence-level hatefulness. The second task extends to fine-grained BIO tagging, enabling precise identification of hate speech within sentences. Finally, the third task expands the scope to hate speech classification in Bengali, Bodo, and Assamese using social media data, categorizing content as hateful or not. Employing state-of-the-art deep learning techniques tailored to each language’s characteristics, this research contributes significantly to the development of robust and culturally sensitive hate speech detection systems, imperative for nurturing safer online spaces and fostering cross-cultural understanding. Warning: The content of this paper may contain offensive material, reader discretion is advised. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Assamese; Bengali; Bodo; Gujrati; Hate Speech; Multilingual BERT; Sinhala; Social Media},
	keywords = {Classification (of information); Learning systems; Online systems; Social networking (online); Speech recognition; Assamese; Bengalis; Bodo; Gujrati; Hate speech; Multilingual BERT; Sinhalum; Social media; Speech classification; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Joshi2023427,
	author = {Joshi, Ananya and Joshi, Raviraj},
	title = {Harnessing Pre-Trained Sentence Transformers for Offensive Language Detection in Indian Languages},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {427 – 434},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193929403&partnerID=40&md5=52af30a1ff40a12052dade2701ac5e11},
	affiliations = {MKSSS Cummins College of Engineering for Women, Maharashtra, Pune, India; Indian Institute of Technology Madras, Tamil Nadu, Chennai, India; L3Cube, Pune, India},
	abstract = {In our increasingly interconnected digital world, social media platforms have emerged as powerful channels for the dissemination of hate speech and offensive content. This work delves into the domain of hate speech detection, placing specific emphasis on three low-resource Indian languages: Bengali, Assamese, and Gujarati. The challenge is framed as a text classification task, aimed at discerning whether a tweet contains offensive or non-offensive content. Leveraging the HASOC 2023 datasets, we fine-tuned pre-trained BERT and SBERT models to evaluate their effectiveness in identifying hate speech. Our findings underscore the superiority of monolingual sentence-BERT models, particularly in the Bengali language, where we achieved the highest ranking. However, the performance in Assamese and Gujarati languages signifies ongoing opportunities for enhancement. The goal of our team-’Sanvadita’ is to foster inclusive online spaces by countering hate speech proliferation. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; Hate-speech detection; Indian Regional Languages; IndicNLP; Low Resource Languages; Natural Language Processing; Offensive language detection; Sentence-BERT; Text Classification; Transformers},
	keywords = {Natural language processing systems; Speech recognition; Text processing; BERT; Hate-speech detection; Indian regional language; Indicnlp; Language detection; Language processing; Low resource languages; Natural language processing; Natural languages; Offensive language detection; Offensive languages; Sentence-BERT; Speech detection; Text classification; Transformer; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@ARTICLE{Ndenga202353,
	author = {Ndenga, Kennedy Malanga},
	title = {A DEEP DECISION FORESTS MODEL FOR HATE SPEECH DETECTION},
	year = {2023},
	journal = {Jordanian Journal of Computers and Information Technology},
	volume = {9},
	number = {1},
	pages = {53 – 62},
	doi = {10.5455/jjcit.71-1667394363},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150850081&doi=10.5455%2fjjcit.71-1667394363&partnerID=40&md5=1de26e158f463d0caebc056663fb20df},
	affiliations = {Department of Pure & Applied Sciences, Kirinyaga Univ., Kutus, Kenya},
	abstract = {Detecting and controlling propagation of hate speech over social-media platforms is a challenge. This problem is exacerbated by extremely fast flow, readily available audience and relative permanence of information on social media. The objective of this research is to propose a model that could be used to detect political hate speech that is propagated through social-media platforms in Kenya. Using Twitter textual data and Keras TensorFlow Decision Forests (TF-DF), three models were developed; i.e., Gradient Boosted Trees with Universal Sentence Embedding (USE), Gradient Boosted Trees and Random Forest, respectively. The Gradient Boosted Trees with USE model exhibited a superior performance with an accuracy of 98.86%, a recall of 0.9587, a precision of 0.9831 and an AUC of 0.9984. Therefore, this model can be utilized for detecting hate speech on social media platforms. © 2023, Scientific Research Support Fund of Jordan. All rights reserved.},
	author_keywords = {Gradient boosted trees; Hate speech detection; National cohesion and integration commission; TensorFlow decision forests; Universal sentence embedding},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Park20236236,
	author = {Park, Hyoungjun and Shim, Ho Sung and Lee, Kyuhan},
	title = {Uncovering the Root of Hate Speech: A Dataset for Identifying Hate Instigating Speech},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {6236 – 6245},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296136&partnerID=40&md5=2b7cb40801fd6550ef9246b37316f2a3},
	affiliations = {Department of Information Systems, Korea University Business School, Seoul, South Korea},
	abstract = {While many prior studies have applied computational approaches, such as machine learning, to detect and moderate hate speech, only scant attention has been paid to the task of identifying the underlying cause of hate speech. In this study, we introduce the concept of hate instigating speech, which refers to a specific type of textual posts on online platforms that stimulate or provoke others to engage in hate speech. The identification of hate instigating speech carries substantial practical implications for effective hate speech moderation. Rather than targeting individual instances of hate speech, by focusing on their roots, i.e., hate instigating speech, it becomes possible to significantly reduce the volume of content that requires review for moderation. Additionally, targeting hate instigating speech enables early prevention of the spread and propagation of hate speech, further enhancing the effectiveness of moderation efforts. However, several challenges hinder researchers from addressing the identification of hate instigating speech. First, there is a lack of comprehensive datasets specifically annotated for hate instigation, making it difficult to train and evaluate computational models effectively. Second, the subtle and nuanced nature of hate instigating speech (e.g., seemingly non-offensive texts serve as catalysts for triggering hate speech) makes it difficult to apply off-the-shelf machine learning models to the problem. To address these challenges, in this study, we have developed and released a multilingual dataset specifically designed for the task of identifying hate instigating speech. Specifically, it encompasses both English and Korean, allowing for a comprehensive examination of hate instigating speech across different linguistic contexts. We have applied existing machine learning models to our dataset and the results demonstrate that the extant models alone are insufficient for effectively detecting hate instigating speech. This finding highlights the need for further attention from the academic community to address this specific challenge. We expect our study and dataset to inspire researchers to explore innovative methods that can enhance the accuracy of hate instigating speech detection, ultimately contributing to more effective moderation and prevention of hate speech propagation online. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computational methods; Speech recognition; Academic community; Comprehensive examination; Computational approach; Computational modelling; Machine learning models; Machine-learning; Off-the-shelf machine; Online platforms; Underlying cause; ]+ catalyst; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@ARTICLE{Meske2023743,
	author = {Meske, Christian and Bunde, Enrico},
	title = {Design Principles for User Interfaces in AI-Based Decision Support Systems: The Case of Explainable Hate Speech Detection},
	year = {2023},
	journal = {Information Systems Frontiers},
	volume = {25},
	number = {2},
	pages = {743 – 773},
	doi = {10.1007/s10796-021-10234-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125542214&doi=10.1007%2fs10796-021-10234-5&partnerID=40&md5=4dc9da137e577e709de78dd30c17c5a0},
	affiliations = {Ruhr-Universität Bochum, Universitätsstr. 150, Bochum, 44801, Germany},
	abstract = {Hate speech in social media is an increasing problem that can negatively affect individuals and society as a whole. Moderators on social media platforms need to be technologically supported to detect problematic content and react accordingly. In this article, we develop and discuss the design principles that are best suited for creating efficient user interfaces for decision support systems that use artificial intelligence (AI) to assist human moderators. We qualitatively and quantitatively evaluated various design options over three design cycles with a total of 641 participants. Besides measuring perceived ease of use, perceived usefulness, and intention to use, we also conducted an experiment to prove the significant influence of AI explainability on end users’ perceived cognitive efforts, perceived informativeness, mental model, and trustworthiness in AI. Finally, we tested the acquired design knowledge with software developers, who rated the reusability of the proposed design principles as high. © 2022, The Author(s).},
	author_keywords = {Design principles; Design science research; Explainable artificial intelligence; Hate speech detection; Local explanations},
	keywords = {Computer software reusability; Decision support systems; Moderators; Reusability; Social networking (online); Software testing; Speech recognition; User interfaces; Design cycle; Design option; Design Principles; Design-science researches; Explainable artificial intelligence; Hate speech detection; Local explanation; Social media; Social media platforms; Speech detection; Artificial intelligence},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Bhatt2023,
	author = {Bhatt, Chandradeep and Saini, Nancy and Chauhan, Rahul and Sahoo, Ashok Kumar},
	title = {Machine Learning Techniques for Hate Speech Detection on Social Media},
	year = {2023},
	journal = {Proceedings - 2023 3rd International Conference on Innovative Sustainable Computational Technologies, CISCT 2023},
	doi = {10.1109/CISCT57197.2023.10351228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182953886&doi=10.1109%2fCISCT57197.2023.10351228&partnerID=40&md5=f52c8cba91df5e2f4a711bc4dbba9c17},
	affiliations = {Graphic Era Hill University, CSE Department, Dehradun, India},
	abstract = {social media are computer-based and internet-based technologies that offers a platform for the concept and distribution of information, thoughts, concerns, and point of view on somethings going in the world and expression through virtual communities and networks. People use social media like Instagram, Facebook, Twitter for sharing their views and their perspective towards things happening all around the world. Some people make offensive comments and videos on these platforms that may affect the other people and can change into conflicts. Hate Speech is one of the major reasons of the conflicts in the world. Conflicts can be in the individual-level or country-level.  © 2023 IEEE.},
	author_keywords = {hate speech; Machine Learning; social media; support vector machine; twitter},
	keywords = {Learning systems; Social networking (online); Speech recognition; Virtual reality; Hate speech; Internet based technology; Machine learning techniques; Machine-learning; Social media; Speech detection; Support vectors machine; Twitter; Virtual community; Virtual networks; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International Conference on Innovative Sustainable Computational Technologies, CISCT 2023; Conference date: 8 September 2023 through 9 September 2023; Conference code: 195751}
}

@CONFERENCE{Mejhed Mkhinini2023309,
	author = {Mejhed Mkhinini, Meriem and Sidibe, Aboubacar Sidiki and Benali, Khaoula and Bentaarit, Nouha and Khelifi, Aymen},
	title = {Image and Signal processing to detect violent content in social media videos},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {309 – 315},
	doi = {10.1145/3587716.3587767},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173824585&doi=10.1145%2f3587716.3587767&partnerID=40&md5=03fd04067adf6b253bb2c506efef1589},
	affiliations = {Kaisens Data, Paris, France; ENSI, National School of Computer Science, Tunis, Tunisia},
	abstract = {The amount of violent content shared on social networks makes it a very unhealthy space. Hence the birth of a growing research domain that involves filtering social media content using Artificial Intelligence-powered violence detection systems. In this paper, we propose a new approach based on deep learning to address this issue. We use a two layered model: First, a deep representation-based model that uses transfer learning concept to recognize violent content in a video. Second a text classifier to detect verbal violence using the audio cue. The result reports show that our approach is outperforming state-of-the art accuracies by learning most discriminating features, achieving 90% accuracy on the test set for physical violence detection and 89% for verbal violence detection.  © 2023 ACM.},
	author_keywords = {BERT; Computer Vision; Convolutional neural networks (CNN); Deep Learning; Gated recurrent unit (GRU); Violent content},
	keywords = {Convolutional neural networks; Learning systems; Recurrent neural networks; Social networking (online); Transfer learning; BERT; Convolutional neural network; Deep learning; Gated recurrent unit; Images processing; Signal-processing; Social media; Violence detections; Violent content; Computer vision},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th International Conference on Machine Learning and Computing, ICMLC 2023; Conference date: 17 February 2023 through 20 February 2023; Conference code: 192850}
}

@CONFERENCE{Yulfa2023,
	author = {Yulfa, Ramadhan Ihsani and Setiawan, Benediktus Hengki and Lourensius, Gerry Gilbert and Purwandari, Kartika},
	title = {Enhancing Hate Speech Detection in Social Media Using IndoBERT Model: A Study of Sentiment Analysis during the 2024 Indonesia Presidential Election},
	year = {2023},
	journal = {ICCA 2023 - 2023 5th International Conference on Computer and Applications, Proceedings},
	doi = {10.1109/ICCA59364.2023.10401700},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185201148&doi=10.1109%2fICCA59364.2023.10401700&partnerID=40&md5=8a3b69a918b37b990d22b16de5f9c9bc},
	affiliations = {Bina Nusantara University, School of Computer Science, Computer Science Department, Jakarta, 11480, Indonesia},
	abstract = {Legislative elections, presidential elections, and village head elections are all on the schedule for Indonesia in 2024. Law No. 7 of 2017 governs these elections, emphasizing the ideals of direct, public, free, confidential, honest, and fair elections. With the growth of social media, political personalities are employing these channels for campaign activity, resulting in a variety of user responses, including hate speech. Detecting hate speech is critical for preventing and mitigating the bad impact it may have on society. The purpose of this article is to investigate the usage of IndoBERT, a fine-tuned BERT model, to improve hate-speech identification during the 2024 Indonesia Presidential Election. The research focuses on hate speech in the context of the presidential election and the challenges raised by social media. In this paper, we utilized Twitter as a case study to develop effective hate-speech identification techniques. The method comprises fine-tuning IndoBERT using a dataset of Indonesian tweets on the election that have been preprocessed to reduce noise and classified as hate speech or non-hate speech using a pre-trained model. The accuracy, precision, recall, and F1-score of the model are used to assess its performance. The results reveal that the IndoBERT model detects hate speech in Indonesian Twitter data with high accuracy. A future study might look towards fixing typos in the dataset and examining expert recognition of hate speech scenarios.  © 2023 IEEE.},
	author_keywords = {Election; Hate-speech; IndoBERT; Transformer; Twitter},
	keywords = {Laws and legislation; Sentiment analysis; Social networking (online); Election; Hate-speech; IndoBERT; Indonesia; Presidential election; Social media; Speech detection; Speech identification; Transformer; Twitter; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th International Conference on Computer and Applications, ICCA 2023; Conference date: 28 November 2023 through 30 November 2023; Conference code: 196884}
}

@ARTICLE{Anand2023203,
	author = {Anand, M. and Sahay, Kishan Bhushan and Ahmed, Mohammed Altaf and Sultan, Daniyar and Chandan, Radha Raman and Singh, Bharat},
	title = {Deep learning and natural language processing in computation for offensive language detection in online social networks by feature selection and ensemble classification techniques},
	year = {2023},
	journal = {Theoretical Computer Science},
	volume = {943},
	pages = {203 – 218},
	doi = {10.1016/j.tcs.2022.06.020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135330551&doi=10.1016%2fj.tcs.2022.06.020&partnerID=40&md5=adf30a842d67f67943a4d9f1c3ce7764},
	affiliations = {Independent Researcher, India; Department of Electrical Engineering, Madan Mohan Malaviya University of Technology, Uttar Pradesh, Gorakhpur, Postal Pin Code-273010, India; Department of Computer Engineering, College of Computer Engineering & Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, 11942, Saudi Arabia; Al-Farabi Kazakh National University, Almaty, Kazakhstan; International Information Technology University, Almaty, Kazakhstan; Computer Science & Engineering, Shambhunath Institute of Engineering & Technology, India; Mechanical Engineering, GLA University Mathura, UP, Mathura, India},
	abstract = {Offensive communications have made their way into social media posts. Using computational algorithms to distinguish objectionable content is one of the most effective ways to deal with this problem. One of the most effective approaches to deal with this issue is to use computational methods to distinguish undesirable content. This research aims to tackle MOLD_DL (Multilingual Offensive Language Detection using deep learning) techniques and natural language processing used in feature selection and classification. Here the dataset has been collected from YouTube, Twitter and Facebook, which has been pre-processed for noise removal, filtering and removing the stop words and segmented. The feature selection has been carried out for segmented data using Fuzzy based convolutional neural network (FCNN). Then the extraction of selected features and classification has been carried out using ensemble architecture of Bi-LSTM model with Naïve Bayes architecture hybrid with Support Vector Machines (SVM). Evaluation of offensive language detection is classified automatically based on the emotions of the text. Here the experimental analysis has been carried out for YouTube, Twitter and Facebook datasets in terms of accuracy of 98%, precision of 95%, recall of 90%, F-1 score of 92.5% and RMSE of 45% with the confusion matrix in detecting offensive text of various languages. © 2022},
	author_keywords = {Classification; Deep learning; Feature selection; Multilingual offensive language detection; NLP; Offensive communications},
	keywords = {Convolutional neural networks; Feature Selection; Fuzzy neural networks; Long short-term memory; Natural language processing systems; Network architecture; Social networking (online); Support vector machines; Deep learning; Facebook; Features selection; Language detection; Language processing; Multilingual offensive language detection; Natural languages; Offensive communication; Offensive languages; YouTube; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42}
}

@CONFERENCE{Satapara2023344,
	author = {Satapara, Shrey and Madhu, Hiren and Ranasinghe, Tharindu and Dmonte, Alphaeus Eric and Zampieri, Marcos and Pandya, Pavan and Shah, Nisarg and Modha, Sandip and Majumder, Prasenjit and Mandl, Thomas},
	title = {Overview of the HASOC Subtrack at FIRE 2023: Hate-Speech Identification in Sinhala and Gujarati},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {344 – 350},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193918590&partnerID=40&md5=77a6e5e1490c64d4cefd88ef955fdc7e},
	affiliations = {Indian Institute of Technology, Hyderabad, India; Indian Institute of Science, Bangalore, India; Aston University, United Kingdom; George Mason University, United States; Indiana Bloomington University, United States; LDRP-ITR, Gandhinagar, India; DA-IICT, Gandhinagar, India; University of Hildesheim, Germany},
	abstract = {Detecting offensive and hateful content in low-resource languages poses a significant challenge due to the limited availability of benchmark datasets. It is crucial to address this gap by creating benchmark datasets tailored to these languages. This not only enhances the accuracy of detection but also provides valuable insights into the efficacy of identifying problematic content in comparison to high-resource languages. In line with this commitment to advancing research on low-resource languages, the Hate Speech and Offensive Content Identification (HASOC) shared task introduced a dedicated subtrack for Hate Speech Identification in Sinhala and Gujarati in 2023. This paper outlines the objectives of the task, discusses the characteristics of the data involved, and presents an analysis of the participants’ submissions. For Task 1a, we utilized an existing Sinhala dataset (SOLD) consisting of 10,000 tweets. Meanwhile, for Task 1b, focused on Gujarati, we curated a new dataset comprising 1,020 tweets. A total of 16 teams submitted experiments for Sinhala, with the leading team achieving an impressive F1 score of 0.83. In the case of the Gujarati task, 17 teams participated, and the highest-performing team achieved an F1 score of 0.84. These results highlight the significance of tailored datasets in facilitating the effective detection of offensive content in low-resource languages. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Benchmark; Deep Learning; Evaluation; Hate Speech; Language Resource; Low-Resource Language; Social Media; Social NLP},
	keywords = {Deep learning; Fires; Benchmark; Content identifications; Deep learning; Evaluation; Hate speech; Language resources; Low resource languages; Social media; Social NLP; Speech identification; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Toha2023,
	author = {Toha, Fariha Rahman and Akter, Khadiza and Tabassum, Lamisa and Islam, Md. Maynul},
	title = {Beyond Language Boundaries: Analysis and Ensemble Approach of Hate Speech Detection in South Asian Social Media},
	year = {2023},
	journal = {2023 26th International Conference on Computer and Information Technology, ICCIT 2023},
	doi = {10.1109/ICCIT60459.2023.10441513},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187360611&doi=10.1109%2fICCIT60459.2023.10441513&partnerID=40&md5=8738329d248e2ee1c9caae51046f3aca},
	affiliations = {Bangladesh University of Professionals, Department of ICT, Dhaka, Bangladesh},
	abstract = {Nowadays social media has become the common platform to be connected with many people all over the world. Due to the increased use of social media, sometimes users are exposed to great risk. The anonymity of user in social media is the sole facilitator of spreading hate in a community. Several studies have been published recently regarding detection of such offensive speech. The majority of these studies deal with English language data due to its availability. The primary goal of this paper is to present a comprehensive approach to hate speech detection, focusing specifically in South Asian languages. In this paper, a comparative analysis of various machine learning classifiers has been conducted on four South Asian languages: Bangla, Indonesian, Urdu and Sinhala. Also an ensemble approach consisting of XGBoost, CatBoost and LightGBM has been used to improve the overall performance resulting in an accuracy of 92% for Bangla, 85% for Indonesian, 90% for Urdu and 85% for Sinhala. Finally, a comparative analysis shows the most effectiveness of MLP (Multi Layer Perceptron) among the 9 classifiers, confirming the potential of our approach for efficient hate detection in mentioned four languages.  © 2023 IEEE.},
	author_keywords = {hate speech detection; Machine Learning; Multi Layer Perceptron (MLP); social media},
	keywords = {Social networking (online); Speech recognition; Comparative analyzes; Ensemble approaches; Hate speech detection; Language boundaries; Machine-learning; Multi layer perceptron; Multilayers perceptrons; Social media; South Asian languages; Speech detection; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 26th International Conference on Computer and Information Technology, ICCIT 2023; Conference date: 13 December 2023 through 15 December 2023; Conference code: 197664}
}

@CONFERENCE{Anand Kumar202317,
	author = {Anand Kumar, M.},
	title = {Multilingual Models for Sentiment and Abusive Language Detection for Dravidian Languages},
	year = {2023},
	journal = {LTEDI 2023 - 3rd Workshop on Language Technology for Equality, Diversity and Inclusion, associated with the 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023 - Proceedings},
	pages = {17 – 24},
	doi = {10.26615/978-954-452-084-7_003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185000748&doi=10.26615%2f978-954-452-084-7_003&partnerID=40&md5=fdc0fc6667e33b967ad6a04a767adf8c},
	affiliations = {Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India},
	abstract = {This work delves into the realm of abusive comment detection and sentiment analysis within code-mixed content, focusing specifically on Dravidian languages. The languages covered include Tulu, and Tamil. For this investigation, TFIDF-based Long Short-Term Memory (LSTM) and Hierarchical Attention Networks (HAN) are employed as the analytical tools. Interestingly, the research highlights the prevalence of traditional TF-IDF techniques over Hierarchical Attention models in both sentiment analysis and the identification of abusive language across the diverse linguistic landscape encompassing Tulu and Tamil. Of note is the Tulu sentiment analysis system, which demonstrates remarkable prowess in handling Positive and Neutral sentiments. In contrast, the sentiment analysis system tailored for Tamil exhibits comparatively lower performance levels. This discrepancy underscores the critical need for well-balanced datasets and intensified research endeavors to enhance the accuracy of sentiment analysis, particularly in the context of the Tamil language. Shifting focus to abusive language detection, the TF-IDF-LSTM models consistently outperform the Hierarchical Attention models. Intriguingly, the mixed models exhibit particular strength in classifying categories like "Homophobia" and "Xenophobia." This intriguing outcome accentuates the value of incorporating both code-mixed and original script data, presenting novel avenues for advancing social media analysis research in diverse linguistic scenarios involving the Dravidian languages. © 2023 LTEDI 2023 - 3rd Workshop on Language Technology for Equality, Diversity and Inclusion, associated with the 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023 - Proceedings. All rights reserved.},
	keywords = {Codes (symbols); Linguistics; Long short-term memory; Analysis system; Analytical tool; Attention model; Balanced datasets; Language detection; Performance:level; Sentiment analysis; Tamil language; TF-IDF technique; Well balanced; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd Workshop on Language Technology for Equality, Diversity and Inclusion, LTEDI 2023; Conference date: 7 September 2023; Conference code: 196595}
}

@CONFERENCE{Gayathri2023,
	author = {Gayathri, T. and Mahalakshmi, K. and Shilpa, M. and Jayanthi, M.G. and Kannadaguli, Prashanth},
	title = {Comparison of Hate Speech Identification in Kannada Language Using ML and DL Models},
	year = {2023},
	journal = {2023 Global Conference on Information Technologies and Communications, GCITC 2023},
	doi = {10.1109/GCITC60406.2023.10425987},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191716819&doi=10.1109%2fGCITC60406.2023.10425987&partnerID=40&md5=4c1202b21ff225b4e18f55dd9ded8be9},
	affiliations = {Cambridge Institute of Technology, Department of Information Science, Bangalore, India; Cambridge Institute of Technology, Department of Computer Science, Bangalore, India; Cambridge Institute of Technology, Department of Cse, Bangalore, India; Dhaarini Academy of Technical Education, Senior Data Science Trainer, Bengaluru, India},
	abstract = {The problem at hand is to create a discrimination system specifically for Indian languages, with an emphasis on Automatic Speech Recognition (ASR) implementations. Hate speech poses a serious challenge to online websites and social media, as well as causing harm, such as spreading hate, inciting violence, and promoting inequality. Macro skills are discriminatory, there is an urgent need for a similar system for regional languages as the country has many different languages and unique cultures. Therefore, this paper intends to gauge the overall performance of 4 characteristic engineering strategies and 4 gadget learning algorithms to examine their overall performance on a publicly-to-be-had dataset with two distinct classes. The experimental consequences confirmed that the bigram capabilities when used with the help vector machine set of rules great carried out with 88% accuracy in ML and 91% of accuracy in DL. This observation has practical implications and can be used as a basis for detecting automated hate speech messages. Moreover, the output of different affinity could be utilized as country-of-artwork strategies to compare destiny research for existing computerized text classification techniques. © 2023 IEEE.},
	author_keywords = {Audio; Deep Learning; Hate; Machine Learning; Offensive speech; Social Network; speech},
	keywords = {Classification (of information); Deep learning; Learning algorithms; Learning systems; Social networking (online); Text processing; Audio; Automatic speech recognition; Deep learning; Hate; Indian languages; Machine-learning; Offensive speech; Performance; Social network; Speech identification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 IEEE Global Conference on Information Technologies and Communications, GCITC 2023; Conference date: 1 December 2023 through 3 December 2023; Conference code: 198957}
}

@CONFERENCE{De la Peña Sarracén20234069,
	author = {De la Peña Sarracén, Gretel Liz and Litschko, Robert and Rosso, Paolo and Glavaš, Goran and Ponzetto, Simone Paolo},
	title = {Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive Language Detection},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {4069 – 4085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184827931&partnerID=40&md5=d8ed97a44167b16c141769bf57de884d},
	affiliations = {Universitat Politècnica de València, Spain; MaiNLP, LMU Munich, Germany; CAIDAS, University of Würzburg, Germany; DWS Group, University of Mannheim, Germany},
	abstract = {Cross-lingual transfer learning from high-resource to medium and low-resource languages has shown encouraging results. However, the scarcity of resources in target languages remains a challenge. In this work, we resort to data augmentation and continual pre-training for domain adaptation to improve cross-lingual abusive language detection. For data augmentation, we analyze two existing techniques based on vicinal risk minimization and propose MIXAG, a novel data augmentation method which interpolates pairs of instances based on the angle of their representations. Our experiments involve seven languages typologically distinct from English and three different domains. The results reveal that the data augmentation strategies can enhance few-shot cross-lingual abusive language detection. Specifically, we observe that consistently in all target languages, MIXAG improves significantly in multidomain and multilingual environments. Finally, we show through an error analysis how the domain adaptation can favour the class of abusive texts (reducing false negatives), but at the same time, declines the precision of the abusive language detection model. ©2023 Association for Computational Linguistics.},
	keywords = {Augmentation methods; Cross-lingual; Data augmentation; Domain adaptation; Language detection; Low resource languages; Pre-training; Risk minimization; Target language; Transfer learning; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196512}
}

@CONFERENCE{Fillies20235503,
	author = {Fillies, Jan and Hoffmann, Michael Peter and Paschke, Adrian},
	title = {Multilingual Hate Speech Detection: Comparison of Transfer Learning Methods to Classify German, Italian, and Spanish Posts},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {5503 – 5511},
	doi = {10.1109/BigData59044.2023.10386244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184981809&doi=10.1109%2fBigData59044.2023.10386244&partnerID=40&md5=4d6c1813822066b4a3aff4baaebabc05},
	affiliations = {Freie Universität Berlin, Institut für Angewandte Informatik, Leipzig, Germany; Freie Universität Berlin, Berlin, Germany; Institut für Angewandte Informatik, Freie Universität Berlin, Fraunhofer-Institut für Offene Kommunikationssysteme, Berlin, Germany},
	abstract = {With the increase of digital communication, a surge in online hate speech can be witnessed. Recent studies have concentrated on automated supervised detection of hate speech. However, there remains limited understanding of an effective strategy for identifying multilingual hate speech in social media posts. This study introduces an innovate experimental design for multilingual hate speech detection. It compares different approaches to automatically detect multilingual hate speech through a series of experiments and creates a classification algorithm for hate speech in German, Italian and Spanish text-based social media content. The study creates monolingual, multilingual, and translated datasets specific to the language triplet. Subsequently, the research explores suitable models for multilingual hate speech detection, evaluating a total of seven transformer-based models along with corresponding SVM models on the constructed datasets. The findings indicate that all chosen transformer-based models outperform the baseline SVM models. The research highlights the superiority of a multilingual approach, utilizing XLM-RoBERTa as a classifier model, over monolingual, multilingual, and translation-based approaches. Furthermore, the study demonstrates that translation-based methods in connection to the model DistillBERT can serve as viable alternatives to the multilingual XLM-RoBERTa approach, particularly in scenarios where computational resources are restricted and processing speed is of importance.  © 2023 IEEE.},
	author_keywords = {Big Data; Hate Speech; Machine Learning; Multilingual; NLP},
	keywords = {Digital communication systems; Learning systems; Social networking (online); Speech communication; Support vector machines; Text processing; Translation (languages); Classification algorithm; Digital communications; Hate speech; Machine-learning; Media content; Multilingual; Social media; Speech detection; SVM model; Transfer learning methods; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 IEEE International Conference on Big Data, BigData 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 196820}
}

@CONFERENCE{Yang20235490,
	author = {Yang, Yongjin and Kim, Joonkee and Kim, Yujin and Ho, Namgyu and Thorne, James and Yun, Se-Young},
	title = {HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning Warning: This paper contains examples of content that is offensive and may be upsetting},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {5490 – 5505},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183311922&partnerID=40&md5=b565529b6a54d72fa4650f6c576b3ba2},
	affiliations = {KAIST AI, South Korea},
	abstract = {With the proliferation of social media, accurate detection of hate speech has become critical to ensure safety online. To combat nuanced forms of hate speech, it is important to identify and thoroughly explain hate speech to help users understand its harmful effects. Recent benchmarks have attempted to tackle this issue by training generative models on free-text annotations of implications in hateful text. However, we find significant reasoning gaps in the existing annotations schemes, which may hinder the supervision of detection models. In this paper, we introduce a hate speech detection framework, HARE, which harnesses the reasoning capabilities of large language models (LLMs) to fill these gaps in explanations of hate speech, thus enabling effective supervision of detection models. Experiments on SBIC and Implicit Hate benchmarks show that our method, using model-generated data, consistently outperforms baselines, using existing free-text human annotations. Analysis demonstrates that our method enhances the explanation quality of trained models and improves generalization to unseen datasets. Our code is available at https://github.com/joonkeekim/hare-hate-speech.git. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Annotation scheme; Detection framework; Detection models; Free texts; Generative model; Harmful effects; Reasoning capabilities; Social media; Speech detection; Text annotations; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@CONFERENCE{Li202382,
	author = {Li, Zhenming and Shimada, Kazutaka},
	title = {Combination and Knowledge Extension of Pre-trained Language Model for Offensive Language Detection},
	year = {2023},
	journal = {Proceedings - 2023 14th IIAI International Congress on Advanced Applied Informatics, IIAI-AAI 2023},
	pages = {82 – 87},
	doi = {10.1109/IIAI-AAI59060.2023.00026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183459713&doi=10.1109%2fIIAI-AAI59060.2023.00026&partnerID=40&md5=a46122ef6f79e5a242f7f9bac0970dbd},
	affiliations = {Kyushu Institute of Technology, Department of Artificial Intelligence, Fukuoka, Japan},
	abstract = {Nowadays, more and more offensive comments are posted on social media. Those offensive comments can seriously cause mental damage to other people. Therefore, those toxic and harmful comments should be detected timely and accurate. In this paper, we exploit the powerful pre-train language models (PLM) in detecting offensive language. We consider two PLMs in our paper: BERT and DeepMoji. We finetune their combination and evaluate the performance with two datasets: Ask FM and Curious Cat. We found that DeepMoji outperforms BERT. We analyze the result from two aspects and conclude that the task and data of pre-training are important to PLM. Seeing that BERT is less effective than DeepMoji, it is possible to improve the performance of BERT. We then propose a 'Knowledge Extension' method to improve the performance of the BERT model. We find that the performance of PLM with high-quality extensional knowledge can be improved significantly.  © 2023 IEEE.},
	author_keywords = {machine learning; offensive language detection; pre-trained language model; social media},
	keywords = {Computational linguistics; Social networking (online); Extension methods; Language detection; Language model; Machine-learning; Offensive language detection; Offensive languages; Performance; Pre-trained language model; Pre-training; Social media; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th IIAI International Congress on Advanced Applied Informatics, IIAI-AAI 2023; Conference date: 8 July 2023 through 13 July 2023; Conference code: 196057}
}

@CONFERENCE{Kalita2023474,
	author = {Kalita, Gyandeep and Halder, Eisha and Taparia, Chetna and Vetagiri, Advaitha and Pakray, Partha},
	title = {Examining Hate Speech Detection Across Multiple Indo-Aryan Languages in Tasks 1 & 4},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {474 – 485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193999240&partnerID=40&md5=b725ffe8f157d23b7fc298dbc1b8dc37},
	affiliations = {National Institute of Technology, Silchar, India},
	abstract = {Hate speech continues to be a pressing concern in online social media (OSM) platforms, necessitating effective automated detection systems. In this paper, we propose a unified approach, encompassing both Task 1 & 4, to tackle the challenge of hate speech recognition within the HASOC 2023 framework. It addresses the complexities of multilingual OSM by employing cutting-edge Natural Language Processing (NLP) techniques and leveraging powerful language models put forward by team CNLP-NITS-PP. The key objective is optimising precision-recall trade-offs in hate speech detection, spanning English and Indo-Aryan languages. The empirical results demonstrate the effectiveness of our approach in isolating explicit signs of hate speech, emphasizing model efficiency, interpretability, and the importance of diverse linguistic nuances in creating safer online environments. This integrated work sets the stage for advancements in hate-span detection and underlines the significance of fostering responsible and inclusive online conversations across various language environments. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; BiLSTM; CNN; GPT-2; Multilingual; Named Entity Recognition; Natural Language Processing; Online social media},
	keywords = {Computational linguistics; Economic and social effects; Natural language processing systems; Online systems; Social networking (online); BERT; BiLSTM; GPT-2; Language processing; Multilingual; Named entity recognition; Natural language processing; Natural languages; Online social medias; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Park202314264,
	author = {Park, Chaewon and Kim, Soohwan and Park, Kyubyong and Park, Kunwoo},
	title = {K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {14264 – 14278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183307662&partnerID=40&md5=d9e3c763703d4c8a72f92f999b459f61},
	affiliations = {School of AI Convergence, Soongsil University, South Korea; TUNiB; Department of Intelligent Semiconductors, Soongsil University, South Korea},
	abstract = {Numerous datasets have been proposed to combat the spread of online hate. Despite these efforts, a majority of these resources are English-centric, primarily focusing on overt forms of hate. This research gap calls for developing high-quality corpora in diverse languages that also encapsulate more subtle hate expressions. This study introduces K-HATERS, a new corpus for hate speech detection in Korean, comprising approximately 192K news comments with target-specific offensiveness ratings. This resource is the largest offensive language corpus in Korean and is the first to offer target-specific ratings on a three-point Likert scale, enabling the detection of hate expressions in Korean across varying degrees of offensiveness. We conduct experiments showing the effectiveness of the proposed corpus, including a comparison with existing datasets. Additionally, to address potential noise and bias in human annotations, we explore a novel idea of adopting the Cognitive Reflection Test, which is widely used in social science for assessing an individual's cognitive ability, as a proxy of labeling quality. Findings indicate that annotations from individuals with the lowest test scores tend to yield detection models that make biased predictions toward specific target groups and are less accurate. This study contributes to the NLP research on hate speech detection and resource construction. The code and dataset can be accessed at https://github.com/ssu-humane/K-HATERS. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Cognitive ability; Detection models; High quality; Human annotations; Labelings; Likert scale; Offensive languages; Research gaps; Speech detection; Target group; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@ARTICLE{Frenda2023239,
	author = {Frenda, Simona},
	title = {Sarcasm and Implicitness in Abusive Language Detection: A Multilingual Perspective; [Sarcasmo e implícidad en el reconocimiento automático del lenguaje abusivo en una perspectiva multilingüe]},
	year = {2023},
	journal = {Procesamiento del Lenguaje Natural},
	number = {70},
	pages = {239 – 242},
	doi = {10.26342/2023-70-21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152735710&doi=10.26342%2f2023-70-21&partnerID=40&md5=0a8af95550519f52711957a6124fd3d3},
	affiliations = {PRHLT Research Center, Universitat Politècnica de València, Spain; Dipartimento di Informatica, Università degli Studi di Torino, Italy},
	abstract = {PhD thesis in Computer Science focused on Natural Language Processing, written by Simona Frenda under the supervision of Prof. Viviana Patti and Prof. Paolo Rosso. This thesis was developed in a co-tutelle program between the PRHLT Research Center of the Universitat Politècnica de València (Spain) and the Computer Science Department of the University of Turin (Italy). In this work, we analysed, linguistically and computationally, the characteristics of the implicit abusive language, especially when it is masked as sarcastic. The thesis defence was held in Torino on June 6th, 2022. The doctoral committee was composed by: Prof. Liviu Petrisor Dinu (University of Bucharest, Romania), Prof. Els Lefever (Ghent University, Belgium) and Prof. Elena Cabrio (Université Côte d’Azur, France). An international mention was achieved, and the work was graded as excellent and awarded Cum Laude. © 2023 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {Abusive Language Detection; Computational Linguistics; Irony Detection; Natural Language Processing; Stance Detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ghosal2023,
	author = {Ghosal, Sayani and Jain, Amita},
	title = {HateCircle and Unsupervised Hate Speech Detection Incorporating Emotion and Contextual Semantics},
	year = {2023},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {22},
	number = {4},
	doi = {10.1145/3576913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161597049&doi=10.1145%2f3576913&partnerID=40&md5=12a77df6b26dcec44f4a16b4591fb975},
	affiliations = {Netaji Subhas University of Technology East Campus (Erstwhile A.I.A.C.T.R.), Guru Gobind Singh Indraprastha University, Sector 16-C, Dwarka, New Delhi, 110078, India; Netaji Subhas University of Technology, Sec-3, Dwarka, New Delhi, 10078, India},
	abstract = {The explosive growth of social media has fueled an extensive increase in online freedom of speech. The worldwide platform of human voice creates possibilities to assail other users without facing any consequences, and flout social etiquettes, resulting in an inevitable increase of hate speech. Nowadays, English hate speech detection is a popular research area, but the prevalence of implicit hate content in regional languages desire effective language-independent models. The proposed research is the first unsupervised Hindi and Bengali hate content detection framework consisting of three significant concepts: HateCircle, hate tweet classification, and code-switch data preparation algorithms. The novel HateCircle method is proposed to detect hate orientation for each term by co-occurrence patterns of words, contextual semantics, and emotion analysis. The efficient multiclass hate tweet classification algorithm is proposed with parts of speech tagging, Euclidean distance, and the Geometric median methods. The detection of hate content is more efficient in the native script compared to the Roman script, so the transliteration algorithm is also proposed for code-switch data preparation. The experimentation evaluates the combination of various lexicons with our enriched hate lexicon that achieves a maximum of 0.74 F1-score for the Hindi and 0.88 F1-score for the Bengali datasets. The novel HateCircle and hate tweet detection framework evaluates with our proposed parts of speech tagging and Geometric median detection methods. Results reveal that HateCircle and hate tweet detection framework also achieves a maximum of 0.73 accuracy for the Hindi and 0.78 accuracy for the Bengali dataset. The experiment results signify that contextual semantic hate speech detection research with a language-independency feature offsets the growth of implicit abusive text in social media.  © 2023 Association for Computing Machinery.},
	author_keywords = {code-switch script; contextual semantics; emotion analysis; hate speech detection; Indian languages; Low-resource languages; parts-of-speech tagging; social media},
	keywords = {Classification (of information); Computational linguistics; Emotion Recognition; Semantics; Social networking (online); Code-switch script; Contextual semantics; Emotion analysis; Hate speech detection; Indian languages; Low resource languages; Part of speech tagging; Parts-of-speech tagging; Social media; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Mamluskar2023285,
	author = {Mamluskar, Vishal and Shaikh, Asad and Mane, Pranav and Jumb, Vijay},
	title = {Enhanced Hate Speech Detection Using Various Machine Learning Models and Performance Comparison},
	year = {2023},
	journal = {2023 6th IEEE International Conference on Advances in Science and Technology, ICAST 2023},
	pages = {285 – 290},
	doi = {10.1109/ICAST59062.2023.10455054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187778783&doi=10.1109%2fICAST59062.2023.10455054&partnerID=40&md5=d07a82f52fb15ecb51da733756d1b02a},
	affiliations = {Xavier Institute of Engineering, Dept. of Computer Engineering, Mumbai, India; MGM College of Engineering, Dept. of Computer Engineering, Navi Mumbai, India},
	abstract = {In this hate speech detection system, the team embarked on a mission to combat the rising tide of online hate speech, a prevalent issue in the digital landscape. Leveraging a diverse array of machine learning models, including Convolutional Neural Networks (CNN), Naive Bayes, Linear SVM, Logistic Regression, and Random Forest, the team meticulously evaluated their performance on a dataset sourced from Kaggle. The journey involved extensive data preprocessing, tokenization, and feature engineering, refining the dataset for rigorous analysis. Through a comprehensive assessment of accuracy, precision, recall, and F1-score metrics, the team unveiled the strengths and capabilities of each model. The findings from this provide valuable insights into the effectiveness of these models in identifying instances of hate speech, contributing to the ongoing efforts to foster inclusive and respectful online communication. © 2023 IEEE.},
	author_keywords = {AI; CNN; Deep Learning; emotion detection; Hate Speech Detection; Logistic Regression; Machine Learning; NLP; Random Forest; SVM; Text Classification},
	keywords = {Classification (of information); Convolutional neural networks; Deep learning; Emotion Recognition; Learning systems; Random forests; Speech communication; Speech recognition; Support vector regression; Transfer learning; Convolutional neural network; Deep learning; Emotion detection; Hate speech detection; Logistics regressions; Machine-learning; Random forests; Speech detection; SVM; Text classification; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th IEEE International Conference on Advances in Science and Technology, ICAST 2023; Conference date: 8 December 2023 through 9 December 2023; Conference code: 197834}
}

@CONFERENCE{Dalavi2023,
	author = {Dalavi, Sushil and Nivelkar, Tanvesh and Patil, Sarvesh and Sawant, Aadesh and Aylani, Amit},
	title = {Comparative Analysis of Vectorization Techniques and Machine Learning Models for Hate Speech Detection},
	year = {2023},
	journal = {2023 Global Conference on Information Technologies and Communications, GCITC 2023},
	doi = {10.1109/GCITC60406.2023.10426214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191734933&doi=10.1109%2fGCITC60406.2023.10426214&partnerID=40&md5=2f05538ccab7e1f19d233c3a0b8e2ab9},
	affiliations = {Vidyalankar Institute of Technology, Computer Department, Mumbai, India},
	abstract = {It is now more important than ever to identify hate speech in digital communication in order to preserve a welcoming and safe online community. Utilizing a three-class classification dataset, this research study gives a thorough analysis of hate speech detection for English textual data. We methodically investigated a variety of vectorization and embedding methods, such as Tfidf Vectorizer, Count Vectorizer, Word2Vec, and GloVe, along with a wide range of machine learning models, including Random Forest, AdaBoost, and Logistic Regression. In order to determine the best method for detecting hate speech in textual content, we rigorously evaluated and conducted extensive experiments to evaluate the effectiveness of different combinations. © 2023 IEEE.},
	author_keywords = {cyber-hate crimes; feature extraction; hate speech; logistic regression; machine learning; Social media; vectorizers},
	keywords = {Adaptive boosting; Classification (of information); Digital communication systems; Forestry; Learning systems; Logistic regression; Random forests; Social networking (online); Speech communication; Cybe-hate crime; Features extraction; Hate speech; Logistics regressions; Machine learning models; Machine-learning; Social media; Speech detection; Vectorizer; Vectorizers; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 IEEE Global Conference on Information Technologies and Communications, GCITC 2023; Conference date: 1 December 2023 through 3 December 2023; Conference code: 198957}
}

@CONFERENCE{Njoku2023979,
	author = {Njoku, Judith Nkechinyere and Eneh, Anthony Uchenna and Nwakanma, Cosmas Ifeanyi and Lee, Jae-Min and Kim, Dong-Seong},
	title = {MetaHate: Text-based Hate Speech Detection for Metaverse Applications using Deep Learning},
	year = {2023},
	journal = {International Conference on ICT Convergence},
	pages = {979 – 984},
	doi = {10.1109/ICTC58733.2023.10392437},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184591590&doi=10.1109%2fICTC58733.2023.10392437&partnerID=40&md5=1fc9b8f5c897046bbaea6dd6a49d14b3},
	affiliations = {It Convergence Engineering, South Korea; Africhange Technologies Ltd, Frontend Engineering Team, Tech and Product Department, Nigeria; Kumoh National Institute of Technology, Ict Convergence Research Center, South Korea},
	abstract = {The rise of digital communication and the metaverse has revolutionized interaction paradigms, while also introducing challenges in ensuring safe engagements. Hate speech, pervasive in digital spaces, threatens inclusivity. This research introduces a tailored hate speech detection system for the metaverse. Through a comprehensive evaluation of deep learning models, effective real-time detection approaches are identified. To guarantee reliable deployment in the metaverse, models are subjected to explainability assessments using Local Interpretable Model-Agnostic Explanations (LIME). A lightweight Convolutional Neural Network (CNN) model is developed and deployed on the Roblox server, exhibiting commendable accuracy and efficiency. Remarkably, quantization reduces the CNN model size by 93.59%. This pioneering study addresses the dearth of metaverse-focused hate speech research, fostering secure and inclusive virtual spaces. © 2023 IEEE.},
	author_keywords = {deep learning; explainableai; GloVe; hate speech; metaverse; offensive language},
	keywords = {Convolutional neural networks; Deep learning; Digital communication systems; Lime; Speech recognition; Virtual addresses; Virtual reality; Convolutional neural network; Deep learning; Digital communications; Explainableai; Glove; Hate speech; Metaverses; Neural network model; Offensive languages; Speech detection; Neural network models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Conference on Information and Communication Technology Convergence, ICTC 2023; Conference date: 11 October 2023 through 13 October 2023; Conference code: 196855}
}

@ARTICLE{Rajalakshmi2023,
	author = {Rajalakshmi, Ratnavel and Selvaraj, Srivarshan and Faerie Mattins, R. and Vasudevan, Pavitra and Anand Kumar, M.},
	title = {HOTTEST: Hate and Offensive content identification in Tamil using Transformers and Enhanced STemming},
	year = {2023},
	journal = {Computer Speech and Language},
	volume = {78},
	doi = {10.1016/j.csl.2022.101464},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141254531&doi=10.1016%2fj.csl.2022.101464&partnerID=40&md5=ab3e477093b559689d7cf2f59b6f1ffd},
	affiliations = {School of Computer Science and Engineering, Vellore Institute of Technology, Tamil Nadu, Chennai, India; Department of Information Technology, National Institute of Technology, Karnataka, Surathkal, India},
	abstract = {Offensive content or hate speech is defined as any form of communication that aims to annoy, harass, disturb, or anger an individual or community based on factors such as faith, ethnicity, appearance, or sexuality. Nowadays, offensive content posted in regional languages increased due to the popularity of social networks and other apps usage by common people. This work proposes a method to detect and identify hate speech or offensive content in Tamil. We have used the HASOC 2021 data set that contains YouTube comments in Tamil language and written in Tamil script. In this research work, an attempt is made to find suitable embedding techniques for Tamil text representation by applying TF-IDF and pre-trained transformer models like BERT, XLM-RoBERTa, IndicBERT, mBERT, TaMillion, and MuRIL. As Tamil is a morphologically rich language, a detailed analysis is made to study the performance of hate speech detection in Tamil by applying enhanced stemming algorithms. An extensive experimental study was performed with different classifiers such as logistic regression, SVM, stochastic Gradient Descent, decision tree, and ensemble learning models in combination with the above techniques. The results of this detailed experimental study show that stop word removal produces mixed results and does not guarantee improvement in the performance of the classifier to detect offensive content for Tamil data. However, the performance on stemmed data shows a significant improvement over un-stemmed data in Tamil texts. As the data is highly imbalanced, we also combined an oversampling/downsampling technique to analyze its role in designing the best offensive classifier for Tamil text. The highest performance was achieved by a combination of stemming the text data, embedding it with the multi-lingual model MuRIL and using a majority voting ensemble as the downstream classifier. We have achieved the F1-score of 84% and accuracy of 86% for detecting offensive content in Tamil YouTube comments. © 2022 Elsevier Ltd},
	author_keywords = {Deep learning; Hate Speech in Tamil YouTube comments; MuRIL; Offensive content identification in Tamil; Stop word removal and enhanced stemming for Tamil text; Tamil text data pre-processing; Transformers for Tamil},
	keywords = {Data handling; Decision trees; Deep learning; Gradient methods; Natural language processing systems; Speech communication; Speech recognition; Stochastic models; Content identifications; Data preprocessing; Deep learning; Hate speech in tamil youtube comment; MuRIL; Offensive content identification in tamil; Stop word; Stop word removal and enhanced stemming for tamil text; Tamil text data pre-processing; Text data; Transformer for tamil; Word removals; YouTube; Stochastic systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Jahan2023588,
	author = {Jahan, Md. Saroar and Hassan, Fadi and Aransa, Walid and Bouchekif, Abdessalam},
	title = {Multilingual Hate Speech Detection Using Ensemble of Transformer Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {588 – 597},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193928082&partnerID=40&md5=f79677c24288e8d5d2677f77c89d61c6},
	affiliations = {Huawei Finland Research Center, Finland},
	abstract = {The classification of hate speech and offensive language presents significant challenges, primarily due to the scarcity of low-resource datasets and the absence of pre-trained models. This paper offers a comprehensive overview of offensive language identification results in the context of HASOC-2023 across various languages and tasks, including Sinhala and Gujarati, Bengali, Assamese, and Bodo, and Hateful span detection. To address these challenges, we harnessed the power of BERT-based models, leveraging resources such as XLM-RoBERTa-large, l3-cube, BanglaHateBert, and BenglaBERT. Our research findings yielded promising results, notably showcasing the superior performance of XLM-RoBERTa-large over monolingual models in the majority of cases. For Task 3, SpanBERT performed outstandingly. Notably, our team FiRC-NLP contributions were acknowledged with top-ranking achievements, securing the first position in Task 1, and Task 3, while clinching the second position in Task 4. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Conversational Hate Detection; Hateful Span Detection; SpanBERT},
	keywords = {Natural language processing systems; Bengalis; Conversational hate detection; Hateful span detection; Language identification; Offensive languages; Performance; Power; SpanBERT; Speech detection; Transformer modeling; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Ojo2023383,
	author = {Ojo, Olumide Ebenezer and Adebanji, Olaronke Oluwayemisi and Calvo, Hiram and Gelbukh, Alexander and Feldman, Anna and Sidorov, Grigori},
	title = {Hate and Offensive Content Identification in Indo-Aryan Languages using Transformer-based Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {383 – 392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193945531&partnerID=40&md5=554f5b37429cd6625b3a36f40e66c1e3},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico; Montclair State University, United States},
	abstract = {Open exchange of hate speech, insults, derogatory remarks, and obscenities on social media platforms can undermine objective discourse and facilitate radicalization by spreading propaganda and exposing people to danger. People who have been targeted by these offensive and hateful content often experience physiological effects as a result. In this work, we present our models for detecting hate speech and offensive content in two Indo-Aryan languages submitted to HASOC 2023. Although Gujarati and Sinhala are considered low-resource languages, our models demonstrated commendable accuracy in detecting hate speech after fine-tuning them with language-specific hate speech datasets. Our experiments employed and fine-tuned two transformer models, namely DistilBERT and mBERT, and we show that these transformer models were effective in detecting hate speech in Indo-Aryan texts. mBERT achieved the macro F1-score of 0.6 in the Sinhala text and excelled further with a score of 0.8 in the Gujarati text classification. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Gujarati; Hate Speech; Offensive Content; Sinhala; Transformers},
	keywords = {Speech recognition; Text processing; Content identifications; Gujarati; Hate speech; Low resource languages; Offensive content; Physiological effects; Sinhalum; Social media platforms; Transformer; Transformer modeling; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Datta2023,
	author = {Datta, Abhradeep and Kumar, B. Monish and Singh Sairam, Ashok},
	title = {Detecting toxic comments from highly skewed social media data},
	year = {2023},
	journal = {International Symposium on Advanced Networks and Telecommunication Systems, ANTS},
	doi = {10.1109/ANTS59832.2023.10469000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189645640&doi=10.1109%2fANTS59832.2023.10469000&partnerID=40&md5=c395c99754569f69ebecfea66ed711d2},
	affiliations = {Iit Guwahati, Department of Mathematics, Assam, India; Iit Guwahati, Data Science Programme, Assam, India},
	abstract = {A user's online social media data, to a considerable extent, provides insight into the user's activity. Screening user-generated data for negative content has a wide range of applications, like background checks of an employee and spotting of terror elements. Researchers have focused on identifying toxic text in social media by exploiting deep-learning models in conjunction with pre-trained language models. However, the availability of labelled toxic text is limited. In this work, we apply data augmentation techniques to address the problem of imbalanced training data. The augmented labelled data is used to fine-tune an ensemble. The ensemble consists of one linear classifier and three sequence classifiers, Bi-RNN (Bi-directional Recurrent Neural Networks), Bi-GRU (Bi-directional Gated Recurrent Unit), and Bi-LSTM (Bi-directional Long-Short Term Memory). We use BERT (Bi-directional Encoder Representations from Transformers) as our pre-trained language model. We also experiment with various text preprocessing techniques on the training data and how it affects classification performance. We compare our best-identified model with other toxic text detection frameworks available in the literature.  © 2023 IEEE.},
	author_keywords = {BERT; deep learning; sentiment analysis; social media; toxic text detection},
	keywords = {Classification (of information); Computational linguistics; Long short-term memory; Personnel training; Social networking (online); Bi-directional; Bi-directional encoder representation from transformer; Deep learning; Language model; Sentiment analysis; Social media; Social media datum; Text detection; Toxic text detection; Training data; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 17th IEEE International Conference on Advanced Networks and Telecommunications Systems, ANTS 2023; Conference date: 17 December 2023 through 20 December 2023; Conference code: 198400}
}

@CONFERENCE{Xie2023,
	author = {Xie, Hetiao and Namvar, Morteza and Risius, Marten},
	title = {A Review of Hate Speech Detection: Challenges and Innovations},
	year = {2023},
	journal = {International Conference on Information Systems, ICIS 2023: "Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies"},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192526672&partnerID=40&md5=b63c189366083123dcb78986a535993c},
	affiliations = {Business School, The University of Queensland, Brisbane, QLD, Australia},
	abstract = {Hate speech on social media platforms has severe impacts on individuals, online communities, and society. Platforms are criticized for shirking their responsibilities to effectively moderate hate speech on their platforms. However, Various challenges, including implicit expressions, complicate the task of detecting hate speech. Consequently, developing and tuning algorithms for improving the automated detection of hate speech has emerged as a crucial research topic. This paper aims to contribute to this rapidly emerging field by outlining how the adoption of natural language processing and machine learning technologies has helped hate speech detection, delving into the latest mainstream detection techniques and their performance, and offering a comprehensive review of the literature on hate speech detection online including the notable challenges and respective mitigating efforts. This paper proposes the integration of interdisciplinary perspectives into deep learning models to enhance the generalization of models, providing a new agenda for future research. © 2023 International Conference on Information Systems, ICIS 2023: "Rising like a Phoenix: Emerging from the Pandemic and Reshaping Hu. All Rights Reserved.},
	author_keywords = {deep learning; hate speech detection; machine learning; natural language processing; social media; text classification},
	keywords = {Classification (of information); Deep learning; Information systems; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Text processing; Deep learning; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Social media; Social media platforms; Speech detection; Text classification; Information use},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 44th International Conference on Information Systems: Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies, ICIS 2023; Conference date: 10 December 2023 through 13 December 2023; Conference code: 199133}
}

@CONFERENCE{Rostamkhani2023403,
	author = {Rostamkhani, Mohammadmostafa and Eetemadi, Sauleh},
	title = {Detecting Hate Speech and Offensive Content in English and Indo-Aryan Texts},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {403 – 410},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193962253&partnerID=40&md5=8c7a1101467aaab148bf41727da139a1},
	affiliations = {Iran University of Science and Technology (IUST University), University of Science and Technology of Iran, University St., Hengam St., Resalat Square, Tehran, Iran},
	abstract = {In this paper, we address hate speech and offensive content detection for English and Indo-Aryan languages. It is a shared task in hate speech detection for Sinhala and Gujarati (Task 1A and 1B [1, 2, 3]), and English hateful span identification in a text already detected as hateful (Task 3 [4, 5, 6]). The study compares multilingual models on translated text against source language-specific fine-tuned models on source text and evaluates DistilBERT and XLM-RoBERTa for hateful span identification. Results show that fine-tuned source language models excel in hate speech detection, especially with ample high-quality source data. language models with good pre-training data (languages like Sinhala, and English) have superior performance but limited models in languages like Gujarati emphasize XLM-RoBERTa’s advantage against source-language models. This shows the importance of good pre-training data which language models are pre-trained on, for superior hate speech detection. Moreover, XLM-RoBERTa surpasses DistilBERT in identifying hateful spans for Task3. In Task 1A, we ranked 6th out of 16 teams, for Task 1B, we stood 13th among 17 teams, for Task 3, our method achieved 5th place in the public leaderboard (on 30% of test data) and ranked 2nd place in the private leaderboard (70% of test data) among 12 teams. For task 1, our team goes by the name”NAVICK,” and for task 3, we are identified as”Mohammadmostafa78”. In Task 1A, our highest achieved metrics include an Accuracy of 83.24, Precision of 84.03, Recall of 83.24, and an F1-score of 82.90. Turning to Task 1B, our best performance stands at a Precision of 70.38, Recall of 73.64, and an F1-score of 69.46. For Task 3, we attain peak results with a Precision of 48.81, Recall of 55.39, F1-score of 51.89, an impressive Accuracy of 90.09, along with a Public F1-score of 44.17 and a Private F1-score of 51.38. © 2023 Copyright for this paper by its authors.},
	author_keywords = {DistilBERT; English; Gujarati; Hate speech; Hateful span identification; Indo-Aryan languages; Multilingual models; Offensive content detection; Sinhala; Source language-specific fine-tuned models; Translated text; XLM-RoBERTa},
	keywords = {Computational linguistics; Translation (languages); Content detection; Distilbert; English; Gujarati; Hate speech; Hateful span identification; Indo-aryan language; Multilingual model; Offensive content detection; Sinhalum; Source language; Source language-specific fine-tuned model; Translated text; XLM-RoBERTa; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Wankhede2023,
	author = {Wankhede, Disha S. and Gaikwad Vidya, S. and Manikjade, Akshay and Meher, Nikita and Atkale, Tejas and Ghule, Aishwarya and Gujar, Deepika},
	title = {Analyzing the Performance of Naive Bayes, Logistic Regression, SVM and Random Forest for Identifying Hate speech from Twitter Social Media},
	year = {2023},
	journal = {2023 7th International Conference On Computing, Communication, Control And Automation, ICCUBEA 2023},
	doi = {10.1109/ICCUBEA58933.2023.10392242},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187270586&doi=10.1109%2fICCUBEA58933.2023.10392242&partnerID=40&md5=f2aa5a65b89adc94f100c674e6bd6b82},
	affiliations = {Vishwakarma Institute of Information Technology, Dept. of Computer Engg, Pune, India; Vishwakarma Institute of Information Technology, Dept. of Mechanical Engg, Pune, India; Vishwakarma Institute of Information Technology, Pune, India},
	abstract = {The spread of hate on social media and other platforms is of great concern because it has the implicit to be a serious detriment to society and the country and is disastrous. The development of mass media has led to lower exposure of hate speech and discrimination. detest speech generally refers to a person or group of people predicated on race, color, race, gender, race, religion, etc It's defined as humiliating communication grounded on certain characteristics. The donation of Structure through named images, type of caption and words used in the textbook of ) can explain the causes of virality and what is associated with it. Fake news and hate speech are not the result of the internet age. Fake news and hate have been around since the morning of mortal history, that is, for times- people have fabricated and fabricated all the time. still, the phenomenon of social media has changed how, where and what it's associated with fake news and hate speech. Where lies and culmination formerly appeared on the internet, now fake news and hate speech are taking their place on social media. The thing of the design is to propose results that stoners can use to identify and filter to count hate speech on Twitter. Using colorful bracket styles, we can determine whether tweets are hate speech. We use traditional shadowing algorithms Analogous as Naive Bayes, Logistic Regression, SVM and Random Forest. From data collection, preprocessing, point engineering and type to, we will estimate and give the delicacy and quality of all classifiers and their results in discrimination quests on Twitter..  © 2023 IEEE.},
	author_keywords = {classification; Fake news; hate speech; Naive Bayes; Random Forest; social media; SVM},
	keywords = {Fake detection; Forestry; Random forests; Social networking (online); Speech communication; Support vector machines; Fake news; Hate speech; Logistics regressions; Mass media; Naive bayes; Performance; Random forests; Regression forests; Social media; SVM; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 7th International Conference On Computing, Communication, Control And Automation, ICCUBEA 2023; Conference date: 18 August 2023 through 19 August 2023; Conference code: 196906}
}

@ARTICLE{Pamungkas202317,
	author = {Pamungkas, Endang Wahyu and Basile, Valerio and Patti, Viviana},
	title = {Towards multidomain and multilingual abusive language detection: a survey},
	year = {2023},
	journal = {Personal and Ubiquitous Computing},
	volume = {27},
	number = {1},
	pages = {17 – 43},
	doi = {10.1007/s00779-021-01609-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112315917&doi=10.1007%2fs00779-021-01609-1&partnerID=40&md5=138a031a5ad23cf23838f66df71e0c0e},
	affiliations = {Dipartimento di Informatica, University of Turin, Turin, Italy},
	abstract = {Abusive language is an important issue in online communication across different platforms and languages. Having a robust model to detect abusive instances automatically is a prominent challenge. Several studies have been proposed to deal with this vital issue by modeling this task in the cross-domain and cross-lingual setting. This paper outlines and describes the current state of this research direction, providing an overview of previous studies, including the available datasets and approaches employed in both cross-domain and cross-lingual settings. This study also outlines several challenges and open problems of this area, providing insights and a useful roadmap for future work. © 2021, The Author(s).},
	author_keywords = {Abusive language detection; Hate speech detection; Literature review; Multidomain; Multilingual},
	keywords = {Abusive language detection; Cross-domain; Cross-lingual settings; Hate speech detection; Language detection; Literature reviews; Multi-domains; Multilingual; On-line communication; Speech detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gupta2023,
	author = {Gupta, Geetika and Kadian, Karuna and Jain, Raksha and Dwivedi, Vimal and Sharma, Arun},
	title = {Real-time Hate Speech Detection in Live Streaming Platforms using Quantum Machine Learning},
	year = {2023},
	journal = {Proceedings of 2023 26th Conference of the Oriental COCOSDA International Committee for the Co-Ordination and Standardization of Speech Databases and Assessment Techniques, O-COCOSDA 2023},
	doi = {10.1109/O-COCOSDA60357.2023.10482977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190528912&doi=10.1109%2fO-COCOSDA60357.2023.10482977&partnerID=40&md5=fb29b8c242f12eee929e1631b402f2aa},
	affiliations = {Igdtuw, Electronics and Communication Dept., Delhi, India; Igdtuw, Computer Science and Engg Dept., Delhi, India; University of Tartu, Tartu, Estonia; Queen's University, Belfast, United Kingdom},
	abstract = {With the growth of technology, social media engagements have witnessed a significant surge, attracting individuals from all generations. These platforms serve as a means to connect with like-minded individuals worldwide, but they also face challenges related to trolls and hate speech. As the usage of virtual platforms increases, there is a pressing need to address the spread of hate speech in these online spaces. Incorporating traditional machine-learning classification models with quantum-inspired techniques, The model seeks to lessen the spread of hate speech to foster a more inviting and civil online community. The research validates the model's efficacy and potential impact by analyzing real-world datasets and simulations. This study strives to curb the spread of harmful online content by contributing to containing hate speech, making virtual platforms safer and more conducive to positive user interactions. © 2023 IEEE.},
	author_keywords = {Hate speech; Live Streaming Platforms; Quantum Machine Learning; Text Extraction; Twitch},
	keywords = {Media streaming; Social networking (online); Virtual addresses; Hate speech; Live streaming; Live streaming platform; Machine-learning; Quantum machine learning; Quantum machines; Real- time; Text extraction; Twitch; Virtual platform; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 26th Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardization of Speech Databases and Assessment Techniques, O-COCOSDA 2023; Conference date: 4 December 2023 through 6 December 2023; Conference code: 198562}
}

@CONFERENCE{Kavitha2023,
	author = {Kavitha, S. and Anchitaalagammai, J.V. and Murali, S. and Deepalakshmi, R. and Himal, L.R. and Suryakanth, M.S.},
	title = {Smart Language Checker: A Machine Learning Solution for Offensive Language detection in Social Media},
	year = {2023},
	journal = {2023 International Conference on Data Science, Agents and Artificial Intelligence, ICDSAAI 2023},
	doi = {10.1109/ICDSAAI59313.2023.10452454},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187784001&doi=10.1109%2fICDSAAI59313.2023.10452454&partnerID=40&md5=63705cb94709f9199526fe45d8258973},
	affiliations = {Velammal College of Engineering and Technology, Department of Computer Science and Engineering, Tamil Nadu, India},
	abstract = {Social media serves as a prominent platform for individuals to express their thoughts, often encompassing both positive and offensive language. Less resource-rich languages benefits from automated offensive language detection systems. This article addresses this gap by proposing a model tailored for the low-resource language. Leveraging a manually labeled dataset of 60,000 comments from the dataset collected from various social media sources, the proposed model explores three feature extraction techniques: bag-of-words (BoW), Vectorization-Term frequency-inverse document frequency (TF-IDF), and Tokenization methods. Employing both traditional classifiers and a deep sequence model, the study reveals that the random forest classifier excels, achieving a testing accuracy of 94.07% when considering unigrams, bigrams, and trigrams. Furthermore, TF-IDF yields a maximum accuracy of 93.90%.The corpus generated in this endeavor is made accessible to researchers in this field, facilitating advancements in offensive language detection for English. © 2023 IEEE.},
	author_keywords = {BoW; corpus; dataset; feature extraction; Natural Language Processing(NLP); Tokenization; Vectorization-TF-IDF},
	keywords = {Extraction; Information retrieval; Inverse problems; Learning algorithms; Natural language processing systems; Social networking (online); Text processing; Bag of words; Corpus; Dataset; Features extraction; Language processing; Natural language processing; Natural languages; Term frequencyinverse document frequency (TF-IDF); Tokenization; Vectorization; Vectorization-term frequency-inverse document frequency; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Data Science, Agents and Artificial Intelligence, ICDSAAI 2023; Conference date: 21 December 2023 through 23 December 2023; Conference code: 197827}
}

@CONFERENCE{Ghosh20236159,
	author = {Ghosh, Sreyan and Suri, Manan and Chiniya, Purva and Tyagi, Utkarsh and Kumar, Sonal and Manocha, Dinesh},
	title = {CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {6159 – 6173},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184825537&partnerID=40&md5=ff1694a66b99b9e78d277db01bbf2db8},
	affiliations = {University of Maryland, College Park, United States; MIDAS Labs, IIIT-Delhi, India},
	abstract = {The tremendous growth of social media users interacting in online conversations has led to significant growth in hate speech affecting people from various demographics. Most of the prior works focus on detecting explicit hate speech, which is overt and leverages hateful phrases, with very little work focusing on detecting hate speech that is implicit or denotes hatred through indirect or coded language. In this paper, we present CoSyn, a context synergized neural network that explicitly incorporates user- and conversational-context for detecting implicit hate speech in online conversations. CoSyn introduces novel ways to encode these external contexts and employs a novel context interaction mechanism that clearly captures the interplay between them, making independent assessments of the amounts of information to be retrieved from these noisy contexts. Additionally, it carries out all these operations in the hyperbolic space to account for the scale-free dynamics of social media. We demonstrate the effectiveness of CoSyn on 6 hate speech datasets and show that CoSyn outperforms all our baselines in detecting implicit hate speech with absolute improvements in the range of 1.24% - 57.8%. We make our code available. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Amount of information; Free dynamics; Hyperbolic networks; Hyperbolic spaces; Independent assessment; Interaction mechanisms; Neural-networks; Scale-free; Social media; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196512}
}

@CONFERENCE{Sharma2023492,
	author = {Sharma, Parshuram and Tiwari, Rakesh Kumar},
	title = {Deep Learning Approach for Hate and Non Hate Speech Detection in Online Social Media},
	year = {2023},
	journal = {Proceedings - International Conference on Technological Advancements in Computational Sciences, ICTACS 2023},
	pages = {492 – 496},
	doi = {10.1109/ICTACS59847.2023.10390417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185381466&doi=10.1109%2fICTACS59847.2023.10390417&partnerID=40&md5=ac3aa6f0970460a1a5e19d813dbcf71f},
	affiliations = {Technocrats Institute of Technology & Science, Dept. of Computer Science Engineering, Bhopal, India},
	abstract = {People's ability to freely and anonymously share their thoughts and feelings online on social media platforms is contributing to a rising issue of hate speech. Hate speech has the potential to hurt both people and groups, contribute to the polarisation of society, and even provoke acts of physical violence. Therefore, identifying and removing hate speech from online social media is an important task for the purpose of maintaining an online environment that is healthy and respectful. A method based on deep learning is proposed in this study for differentiating between hate speech and other types of communication that may be found in online social media. The solution that has been developed makes use of a natural language processing (NLP) and long term short memory (LSTM) model that is trained on a huge dataset consisting of tweets that have been annotated. Tweets that include hate speech and tweets that do not contain hate speech were both included in the dataset and were labelled by human annotators. Python software with IDE of Spyder version 3.7 is used to carry out the simulation work. The accuracy level reached overall is 91.14%.  © 2023 IEEE.},
	author_keywords = {Hate; LSTM; Machine Learning; NLP; Social Media; Speech; Twitter},
	keywords = {Audio signal processing; Computer software; E-learning; Learning systems; Natural language processing systems; Social networking (online); Speech communication; Hate; Language processing; Learning approach; Machine-learning; Natural language processing; Natural languages; Online social medias; Social media; Speech detection; Twitter; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 3rd International Conference on Technological Advancements in Computational Sciences, ICTACS 2023; Conference date: 1 November 2023 through 3 November 2023; Conference code: 196891}
}

@CONFERENCE{Agustian2023544,
	author = {Agustian, Surya and Idhafi, Zaky and Rihardi, Agit Fadillah},
	title = {Improving Detection of Hate Speech, Offensive Language and Profanity in Short Texts with SVM Classifier},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {544 – 552},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193912634&partnerID=40&md5=3c76d881b3b7f2869b2321b1b2fb0723},
	affiliations = {UIN Sultan Syarif Kasim, Jl. H.R. Soeberantas km 11.5 Panam, Riau, Pekanbaru, Indonesia},
	abstract = {Hate speech and offensive language in social media have become a global issue, affecting various nations and languages. Conflicts on social media, triggered by hate speech and offensive language, can lead to victims experiencing mental health problem, disruptions in their peace, and disturbances in their real-world social lives. HASOC 2023 organizes some shared tasks to detect hate speech and offensive language in several languages spoken on the Indian peninsula, which categorized as low-resource languages. Tasks 1A and 1B in Sinhala and Gujarati languages conceal underlying difficulties, requiring the use of particular techniques in the classification procedure. This study proposes an SVM classifier method with improvement strategies for optimization and feature selection based on FastText word embeddings. The experimental results indicate that the applied strategies significantly enhance performance compared to the baseline method. The improvement achieved for Sinhala is 5.37%, and for Gujarati, it is 26.08% over the baseline method which use bag-of-words input features. © 2023 Copyright for this paper by its authors.},
	author_keywords = {FastText word embeddings; feature selection; optimization; SVM classifier},
	keywords = {Classification (of information); Feature Selection; Social networking (online); Speech recognition; Support vector machines; Baseline methods; Embeddings; Fasttext word embedding; Features selection; Global issues; Offensive languages; Optimisations; Short texts; Social media; SVM classifiers; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Mim2023532,
	author = {Mim, Jhuma Kabir and Oussalah, Mourad and Singhal, Akash},
	title = {Cross-Linguistic Offensive Language Detection: BERT-Based Analysis of Bengali, Assamese, & Bodo Conversational Hateful Content from Social Media},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {532 – 543},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193997243&partnerID=40&md5=42130036c04ba75fcb4b2e04b49d29f0},
	affiliations = {CVPR, LUT University, Lappeenranta, Finland; CMVS, Faculty of ITEE, University of Oulu, Oulu, Finland; Dept of Computer Science, University of Helsinki, Helsinki, Finland},
	abstract = {In today’s age, social media reigns as the paramount communication platform, providing individuals with the avenue to express their conjectures, intellectual propositions, and reflections. Unfortunately, this freedom often comes with a downside as it facilitates the widespread proliferation of hate speech and offensive content, leaving a deleterious impact on our world. Thus, it becomes essential to discern and eradicate such offensive material from the realm of social media. This article delves into the comprehensive results and key revelations from the HASOC-2023 offensive language identification result. The primary emphasis is placed on the meticulous detection of hate speech within the linguistic domains of Bengali, Assamese, and Bodo, forming the framework for Task 4: Annihilate Hates. In this work, we used BERT models, including XML-Roberta, L3-cube, IndicBERT, BenglaBERT, and BanglaHateBERT. The research outcomes were promising and showed that XML-Roberta-lagre performed better than monolingual models in most cases. Our team’TeamBD’ achieved rank 3rd for Task 4 - Assamese, & 5th for Bengali. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT Model; HASOC-2023; Hate Speech; Multilingual Offensive language identification; Social Media},
	keywords = {Linguistics; Natural language processing systems; Social networking (online); Speech recognition; Bengalis; BERT model; Communication platforms; HASOC-2023; Hate speech; Language detection; Language identification; Multilingual offensive language identification; Offensive languages; Social media; XML},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Saha2023516,
	author = {Saha, Sougata and Sullivan, Michael and Srihari, Rohini},
	title = {Hate Speech Detection in Low Resource Indo-Aryan Languages},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {516 – 520},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193997001&partnerID=40&md5=9c4ca7bf78cf18a4b10a25a98b20057e},
	affiliations = {State University of New York, Buffalo, 14260, NY, United States},
	abstract = {This report outlines the problem formulation and methodology employed by team Chetona for identifying hate-speech in low resource languages from social media comments. We focus on HASSOC 2023 Task 4, which involves binary classification of Twitter, Facebook, and Youtube comments for hate speech in Bengali, Bodo, and Assamese languages. We propose ensembling IndicBERT and Naive Bayes, along with synthetic data upsampling techniques, and attain macro F1 scores of 0.73, 0.68, and 0.84 for Assamese, Bengali, and Bodo. The scores are significant improvements over existing baselines, placing us within the top 10 of the leaderboard for all languages. The code and method is available on Github. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Assamese; Bengali; Bodo; Hate Speech; Low resource language},
	keywords = {Speech recognition; Assamese; Bengalis; Binary classification; Bodo; Facebook; Hate speech; Low resource languages; Problem formulation; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Sifak2023170,
	author = {Sifak, Qomarudin and Setiawan, Erwin Budi},
	title = {Hate Speech Detection using CNN and BiGRU with Attention Mechanism on Twitter},
	year = {2023},
	journal = {Proceeding - COMNETSAT 2023: IEEE International Conference on Communication, Networks and Satellite},
	pages = {170 – 175},
	doi = {10.1109/COMNETSAT59769.2023.10420628},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186128129&doi=10.1109%2fCOMNETSAT59769.2023.10420628&partnerID=40&md5=e2f1adc7ab0da3c37c8072664c125b3e},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {Indonesia is the country that leads the most use of social media in Asia. Twitter is one of the most popular social media platforms in Indonesia. Twitter is a social media that is typically used for opinion exchange, criticism, and storytelling. This is frequently abused by Internet users, including the dissemination of hate speech directed at an individual or groups. Therefore, the aim of this research is to address these issues by building a hate speech detection system for Indonesian Twitter. This research uses 69.484 tweet data and implements hybrid deep learning models with Convolutional Neural Network (CNN) and Bidirectional Gated Recurrent Unit (BiGRU). Other methods applied are Bidirectional Encoder Representation from Transformer (BERT) used as word embedding to help the system better understand the context and meaning of tweets and attention mechanism to help the system to find the essential word from tweets. This research examines eight hybrid approaches in classification process, either CNN-BiGRU or BiGRU-CNN and adds attention mechanisms for those models. The result shows BIGRU-CNN hybrid model with attention mechanism for both layers achieving the highest accuracy of 88.12%.  © 2023 IEEE.},
	author_keywords = {attention mechanism; bidirectional gated recurrent unit; convolutional neural network; hate speech; twitter},
	keywords = {Convolution; Recurrent neural networks; Sentiment analysis; Social networking (online); Speech recognition; Attention mechanisms; Bidirectional gated recurrent unit; Convolutional neural network; Hate speech; Indonesia; Internet users; Social media; Social media platforms; Speech detection; Twitter; Convolutional neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2023; Conference date: 23 November 2023 through 25 November 2023; Conference code: 197147}
}

@CONFERENCE{Peng2023266,
	author = {Peng, Zhenghan and Ren, Yizhi and Wang, Dong and Zhang, Ling and Yuan, Lifeng and Ji, Yihao},
	title = {Feature Attribution-Guided Contrastive Learning: Mitigating Lexical Bias in Toxic Speech Detection},
	year = {2023},
	journal = {Proceedings of 2023 International Conference on New Trends in Computational Intelligence, NTCI 2023},
	pages = {266 – 272},
	doi = {10.1109/NTCI60157.2023.10403665},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185220679&doi=10.1109%2fNTCI60157.2023.10403665&partnerID=40&md5=852c4be671423e1f07b25755d32d4a07},
	affiliations = {School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China},
	abstract = {Automatic detection methods for toxic speech can potentially curb the dissemination of offensive, abusive, hateful, and other toxic speech on social media. However, these methods often show bias by overreacting to words such as identity terms, profanity, and swear words that occur in non-toxic speech and erroneously classifying them as toxic speech. Recent research has attempted to regularise relevant biased words in predefined lexicons to mitigate their impact on model classification. However, this approach faces two challenges. Firstly, words such as pro-fanity and swear words in biased words play a crucial role in the model's ability to identify toxic speech, and excessive suppression of these words using regularization methods can detrimentally affect the performance of the classification model. Secondly, due to the limitations of regularization techniques, existing methods rely on manually constructed biased word dictionaries, which can only mitigate bias associated with identity-related terms. This bias should not significantly impact hate speech prediction. It is challenging to encompass lexical biases such as profanity and swear words that are specific to different datasets beyond identity terms To address the above challenges, this paper proposes a novel feature attribution-guided contrastive learning method. The method consists of two repeated steps across epochs. In each epoch, first identifies keywords in sentences that are crucial for predicting toxicity through feature attribution. Then it applies contrastive learning to separate samples that have common toxic keywords but different labels. Experiments show that our approach can mitigate lexical bias in toxic speech detection without any data augmentation or prior knowledge and achieve competitive performance gains.  © 2023 IEEE.},
	author_keywords = {Bias Mitigation; Contrastive Learning; Feature Attribution; Toxic Speech},
	keywords = {Learning systems; Automatic detection method; Bias mitigation; Contrastive learning; Feature attribution; Lexical bias; Non-toxic; Recent researches; Social media; Speech detection; Toxic speech; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on New Trends in Computational Intelligence, NTCI 2023; Conference date: 3 November 2023 through 5 November 2023; Conference code: 196953}
}

@CONFERENCE{Luo202310948,
	author = {Luo, Chu Fei and Bhambhoria, Rohan and Dahan, Samuel and Zhu, Xiaodan},
	title = {Legally Enforceable Hate Speech Detection for Public Forums},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {10948 – 10963},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306755&partnerID=40&md5=bfcaef62cf85112b40dedc6212fc2230},
	affiliations = {Department of Electrical and Computer Engineering, Ingenuity Labs Research Institute, Queen's University, United Kingdom; Conflict Analytics Lab, Queen's University, United Kingdom; Cornell Law School, United States},
	abstract = {Hate speech causes widespread and deep-seated societal issues. Proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. This research introduces a new perspective and task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Complex task; Language model; Legal definition; Legal experts; Legal protection; Modeling decisions; Protecting group; Public forums; Societal issues; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@CONFERENCE{Saim2023,
	author = {Saim, Mohammad and Rizvi, Rehma Manaal and Kashif Khan, Mohammad},
	title = {Analyzing the Performance of Machine Learning and Deep Learning Models in Detecting Cyberbullying Comments},
	year = {2023},
	journal = {International Conference on Recent Advances in Science and Engineering Technology, ICRASET 2023},
	doi = {10.1109/ICRASET59632.2023.10419938},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186073684&doi=10.1109%2fICRASET59632.2023.10419938&partnerID=40&md5=d9493fd36a58390ec8397dfc2ecb3642},
	affiliations = {Aligarh Muslim University, Zakir Husain College of Engineering & Technology, Department of Computer Engineering, Aligarh, India},
	abstract = {With the proliferation of social media platforms, there has been a concerning escalation in cyberbullying and abusive language. Detecting such toxic comments in large volumes of user-generated data presents challenges. This research conducts a comparative analysis to evaluate the impact of natural language processing techniques on identifying cyberbullying. Using a dataset of 1,59,000 comments labelled across seven classes of toxicity, conventional machine learning and deep learning models are benchmarked across performance metrics. The study aims to quantify algorithmic capabilities to accurately classify bullying comments. The study finds that Support Vectors with a linear kernel surpass Logistic Regression in accurately identifying toxic comments. For deep learning techniques, the transformer models (BERT and Distil-BERT) deliver the highest performance among neural network architectures tested. The empirical evaluation provides insights into leveraging computational linguistics for automating the detection of online bullying at scale. © 2023 IEEE.},
	author_keywords = {Classification; Cyberbullying; Deep Learning; Machine Learning; Natural Language Processing},
	keywords = {Computer crime; Deep learning; Learning algorithms; Learning systems; Logistic regression; Natural language processing systems; Network architecture; Neural networks; Cyber bullying; Deep learning; Language processing; Large volumes; Learning models; Machine-learning; Natural language processing; Natural languages; Performance; Social media platforms; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Recent Advances in Science and Engineering Technology, ICRASET 2023; Conference date: 23 November 2023 through 24 November 2023; Conference code: 197160}
}

@CONFERENCE{Roy20236116,
	author = {Roy, Sarthak and Harshavardhan, Ashish and Mukherjee, Animesh and Saha, Punyajoy},
	title = {Probing LLMs for hate speech detection: strengths and vulnerabilities},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {6116 – 6128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183292027&partnerID=40&md5=5e64bcbeb9671916ce3fa51149457c2b},
	affiliations = {Indian Institute of Technology, Kharagpur, India},
	abstract = {Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select three large language models (GPT-3.5, text-davinci and Flan-T5) and three datasets - HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially (∼ 20−30%) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline (∼ 10 − 20%) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute 'jailbreak' prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large datasets; Semantics; Speech recognition; Zero-shot learning; Davinci; Detection process; In contexts; Language model; Modeling performance; Social media platforms; Speech detection; Target information; Pipelines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@CONFERENCE{Nakahara20231615,
	author = {Nakahara, Teruki and Ushiama, Taketoshi},
	title = {Personalized Prediction of Offensive News Comments by Considering the Characteristics of Commenters},
	year = {2023},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {1615 – 1622},
	doi = {10.1145/3555776.3577670},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162846873&doi=10.1145%2f3555776.3577670&partnerID=40&md5=ce641cdc23133fc0ca717b166211db85},
	affiliations = {Kyushu University, Japan},
	abstract = {When reading news articles on social networking services and news sites, readers can view comments marked by other people on these articles. By reading these comments, a reader can understand the public opinion about the news, and it is often helpful to grasp the overall picture of the news. However, these comments often contain offensive language that readers do not prefer to read. This study aims to predict such offensive comments to improve the quality of the experience of the reader while reading comments. By considering the diversity of the readers' values, the proposed method predicts offensive news comments for each reader based on the feedback from a small number of news comments that the reader rated as "offensive"in the past. In addition, we used a machine learning model that considers the characteristics of the commenters to make predictions, independent of the words and topics in news comments. The experimental results of the proposed method show that prediction can be personalized even when the amount of readers' feedback data used in the prediction is limited. In particular, the proposed method, which considers the commenters' characteristics, has a low probability of false detection of offensive comments.  © 2023 ACM.},
	author_keywords = {BERT; news; offensive comments; personalization; user embedding},
	keywords = {Social aspects; BERT; Embeddings; News; News articles; Offensive comment; Offensive languages; Personalizations; Public opinions; Social networking services; User embedding; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 38th Annual ACM Symposium on Applied Computing, SAC 2023; Conference date: 27 March 2023 through 31 March 2023; Conference code: 189263; All Open Access, Green Open Access}
}

@CONFERENCE{Cahyana2023283,
	author = {Cahyana, Rinda and Maulidevi, Nur Ulfa and Surendro, Kridanto},
	title = {A Framework for Actor-Oriented Automated Hate Speech Detection},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {283 – 289},
	doi = {10.1145/3587828.3587870},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163865121&doi=10.1145%2f3587828.3587870&partnerID=40&md5=0b31e63bdab7d6d467c0c54bc018497e},
	affiliations = {School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Indonesia},
	abstract = {The development of automated hate speech detection research has not yet detailed the actor who is the source of hatred, even though the forms of hate speech intervention for perpetrators and supporters are different. Previous research on this topic has paid much attention to the action component in the form of sentimental words. However, it has yet to pay attention to the actor component that can differentiate legal hate speech from illegal hate speech and transforms hateful or offensive speech into free speech, thus dealing with misclassification, as reported in a previous study. This research proposes a framework for the automated detection of hate speech that provides an actor and action component to solve the problem of such errors and meets the need for comprehensive interventions. This study shows how to apply the framework in a rule-based approach by considering the actor component in predicting hate speech and differentiating it from others. The prediction process is called actor-oriented automated hate speech detection. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {actor; classification; hate speech; intervention; syntactic},
	keywords = {Automation; Actor; Automated detection; Free speech; Hate speech; Intervention; Misclassifications; Prediction process; Rule-based approach; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th International Conference on Software and Computer Applications, ICSCA 2023; Conference date: 23 February 2023 through 25 February 2023; Conference code: 189662}
}

@CONFERENCE{Sharma2023,
	author = {Sharma, Shivam and Kumar, Shailender},
	title = {Hate Speech Detection Using Transformers},
	year = {2023},
	journal = {Proceedings of 3rd International Conference on Advanced Computing Technologies and Applications, ICACTA 2023},
	doi = {10.1109/ICACTA58201.2023.10391865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184806647&doi=10.1109%2fICACTA58201.2023.10391865&partnerID=40&md5=e0fa595238cb61d16e7024b2d36934cf},
	affiliations = {Delhi Technological University, Computer Science and Engineering, Delhi, India},
	abstract = {One of the most significant difficulties in recent decades has been identifying hate speech. These last few years have contributed to research based on identifying hate speech on social networking platforms. It appears to be a divisive communication that expresses a hate ideology through misunderstandings. The protected characteristics that are the target of hate speech include gender, religion, race, and disability. For some, it might be just fun but for others, it can become the reason for depression, anxiety, etc. Therefore, it is crucial to keep an eye on what a user is posting thus filtering out any that may be related to hate speech before it spreads. However, the technology to detect hate speech is still under development. Although some detection approach has yet been proposed. This paper also proposes an approach to build a classifier based on deep learning using transformers, convolution neural network(CNN) and long-short term memory (LSTM) (TCL) to detect hate speech. © 2023 IEEE.},
	author_keywords = {bert; CNN; hate; lstm; transformers},
	keywords = {Speech recognition; Bert; Convolution neural network; Detection approach; Hate; Lstm; Social-networking; Speech detection; Transformer; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Advanced Computing Technologies and Applications, ICACTA 2023; Conference date: 6 October 2023 through 7 October 2023; Conference code: 196857}
}

@CONFERENCE{Saha20231232,
	author = {Saha, Punyajoy and Das, Mithun and Mathew, Binny and Mukherjee, Animesh},
	title = {Hate Speech: Detection, Mitigation and beyond},
	year = {2023},
	journal = {WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining},
	pages = {1232 – 1235},
	doi = {10.1145/3539597.3572721},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149649920&doi=10.1145%2f3539597.3572721&partnerID=40&md5=dedae7a23fc4e4a1e88598fa64b6df4c},
	affiliations = {Department of Computer Science & Engineering, Indian Institute of Technology, West Bengal, Kharagpur, 721302, India},
	abstract = {Social media sites such as Twitter and Facebook have connected billions of people and given the opportunity to the users to share their ideas and opinions instantly. That being said, there are several negative consequences as well such as online harassment, trolling, cyber-bullying, fake news, and hate speech. Out of these, hate speech presents a unique challenge as it is deeply engraved into our society and is often linked with offline violence. Social media platforms rely on human moderators to identify hate speech and take necessary action. However, with the increase in online hate speech, these platforms are turning toward automated hate speech detection and mitigation systems. This shift brings several challenges to the plate, and hence, is an important avenue to explore for the computation social science community. In this tutorial, we present an exposition of hate speech detection and mitigation in three steps. First, we describe the current state of research in the hate speech domain, focusing on different hate speech detection and mitigation systems that have developed over time. Next, we highlight the challenges that these systems might carry like bias and the lack of transparency. The final section concretizes the path ahead, providing clear guidelines for the community working in hate speech and related domains. We also outline the open challenges and research directions for interested researchers. © 2023 ACM.},
	author_keywords = {counter speech; detection; hate speech; mitigation; social media},
	keywords = {Fake detection; Online systems; Social networking (online); Counter speech; Cyber bullying; Detection; Detection system; Facebook; Hate speech; Mitigation; Mitigation systems; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 16th ACM International Conference on Web Search and Data Mining, WSDM 2023; Conference date: 27 February 2023 through 3 March 2023; Conference code: 186955}
}

@ARTICLE{Ghozali20231105,
	author = {Ghozali, Imam and Sungkono, Kelly Rossa and Sarno, Riyanarto and Abdullah, Rachmad},
	title = {Synonym based feature expansion for Indonesian hate speech detection},
	year = {2023},
	journal = {International Journal of Electrical and Computer Engineering},
	volume = {13},
	number = {1},
	pages = {1105 – 1112},
	doi = {10.11591/ijece.v13i1.pp1105-1112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143871876&doi=10.11591%2fijece.v13i1.pp1105-1112&partnerID=40&md5=f488af182359be7692a79ec46428a698},
	affiliations = {Department of Informatics, Faculty of Intelligent Electrical and Informatics Technology, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia},
	abstract = {Online hate speech is one of the negative impacts of internet-based social media development. Hate speech occurs due to a lack of public understanding of criticism and hate speech. The Indonesian government has regulations regarding hate speech, and most of the existing research about hate speech only focuses on feature extraction and classification methods. Therefore, this paper proposes methods to identify hate speech before a crime occurs. This paper presents an approach to detect hate speech by expanding synonyms in word embedding and shows the classification comparison result between Word2Vec and FastText with bidirectional long short-term memory which are processed using synonym expanding process and without it. The goal is to classify hate speech and non-hate speech. The best accuracy result without the synonym expanding process is 0.90, and the expanding synonym process is 0.93. © 2023 Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Bidirectional long short-term memory; FastText; Hate speech; Synonym; Word2Vec},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Leo2023960,
	author = {Leo, Chelsea Olivia and Santoso, Bagus Jati and Pratomo, Baskoro Adi},
	title = {Enhancing Hate Speech Detection for Social Media Moderation: A Comparative Analysis of Machine Learning Algorithms},
	year = {2023},
	journal = {2023 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation, ICAMIMIA 2023 - Proceedings},
	pages = {960 – 964},
	doi = {10.1109/ICAMIMIA60881.2023.10427779},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186521916&doi=10.1109%2fICAMIMIA60881.2023.10427779&partnerID=40&md5=3303afbf99e871a889614cf167e65b4b},
	affiliations = {Bina Bangsa School, Jakarta, Indonesia; Institut Teknologi Sepuluh Nopember, Department of Informatics, Surabaya, Indonesia},
	abstract = {In our ever-advancing technological age, a pressing concern emerges the challenge of preserving freedom of expression while combatting hate speech. Hate speech, in simple terms, involves hurtful messages directed at specific groups based on attributes like race, gender, and religion. Social media platforms have sought to curb hate speech through user reporting and automated content scrutiny, but their effectiveness is under scrutiny.To improve hate speech detection, we explore several machine learning algorithms, such as Naive Bayes, Random Forest, Decision Trees, and Gradient Boosting. By tweaking these algorithms and comparing their performance across metrics like AUC, CA, F1 score, Precision, and Recall, we aim to identify the best approach. Furthermore, our study reviews the current state of hate speech detection, presents the methodology used, and discusses implications for social media moderation.Our results show Random Forest as the top performer, but challenges remain. Future research may involve advanced classifiers, algorithm hybridization, and deep learning to enhance model performance in addressing the intricate landscape of online hate speech. © 2023 IEEE.},
	author_keywords = {detection; hate speech; machine learning; social media},
	keywords = {Adaptive boosting; Deep learning; Learning systems; Social networking (online); Speech recognition; Comparative analyzes; Detection; Hate speech; Machine learning algorithms; Machine-learning; Pressung; Random forests; Simple++; Social media; Speech detection; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation, ICAMIMIA 2023; Conference date: 14 November 2023 through 15 November 2023; Conference code: 197393}
}

@CONFERENCE{Narayan2023574,
	author = {Narayan, Nikhil and Biswal, Mrutyunjay and Goyal, Pramod and Panigrahi, Abhranta},
	title = {Hate Speech and Offensive Content Detection in Indo-Aryan Languages: A Battle of LSTM and Transformers},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {574 – 587},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193965130&partnerID=40&md5=98f9d59016e616005257cdb9928b287f},
	affiliations = {Z-AGI Labs, India},
	abstract = {Social media platforms serve as accessible outlets for individuals to express their thoughts and experiences, resulting in an influx of user-generated data spanning all age groups. While these platforms enable free expression, they also present significant challenges, including the proliferation of hate speech and offensive content. Such objectionable language disrupts objective discourse and can lead to radicalization of debates, ultimately threatening democratic values. Consequently, social media platforms have taken steps to monitor and curb abusive behavior, necessitating automated methods for identifying suspicious posts. This paper contributes to Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC) 2023 shared tasks track for Hate Speech Detection in Low-Resource Languages. We, team Z-AGI Labs, conduct a comprehensive comparative analysis of hate speech classification across five distinct languages—Bengali, Assamese, Bodo, Sinhala, and Gujarati—within the context of the HASOC competition. Our study encompasses a wide range of pre-trained models, including Bert variants, XLM-R, and LSTM models, to assess their performance in identifying hate speech across these languages. Results reveal intriguing variations in model performance. Notably, Bert Base Multilingual Cased emerges as a strong performer across languages, achieving an F1 score of 0.67027 for Bengali and 0.70525 for Assamese. At the same time, it significantly outperforms other models with an impressive F1 score of 0.83009 for Bodo. In Sinhala, XLM-R stands out with an F1 score of 0.83493, whereas for Gujarati, a custom LSTM-based model outshined with an F1 score of 0.76601. This study offers valuable insights into the suitability of various pre-trained models for hate speech detection in multilingual settings. By considering the nuances of each, our research contributes to an informed model selection for building robust hate speech detection systems. © 2023 Copyright for this paper by its authors.},
	author_keywords = {CEUR-WS; HASOC-FIRE; Hate Speech; Indic Languages; Low-Resource Languages; Multilingual Models},
	keywords = {Long short-term memory; Social networking (online); Bengalis; CEUR-WS; F1 scores; HASOC-FIRE; Hate speech; Indic language; Low resource languages; Multilingual model; Social media platforms; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Singh2023894,
	author = {Singh, Kartik and Tripathi, Meenakshi and Agarwal, Basant and Sain, Abhay Kumar},
	title = {Ensemble of Transformer Based Approach for Hate Speech Detection on Twitter Data},
	year = {2023},
	journal = {2023 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering, UPCON 2023},
	pages = {894 – 899},
	doi = {10.1109/UPCON59197.2023.10434902},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187334225&doi=10.1109%2fUPCON59197.2023.10434902&partnerID=40&md5=395c163ebd65ab280b76f2a44ba95cd8},
	affiliations = {Malaviya National Institute of Technology (MNIT), Department of Computer Science and Engineering, Jaipur, India; Central University of Rajasthan, Department of Computer Science and Engineering, Ajmer, India},
	abstract = {Social media platforms like Twitter are popular for sharing opinions and ideas, but hate speech is a growing concern. Hate speech can harm individuals and communities, leading to discrimination and violence. Detecting and preventing hate speech on social media is now crucial. Different models such as BERT, CNN, LSTM, and XLM-ROBERTA have shown promising results in identifying hate speech, but each has its advantages and limitations. For example, BERT is good at capturing semantic meaning but not local patterns, while CNN is good at detecting local patterns but not context. LSTM can capture temporal dynamics but may struggle with long-term dependencies. XLM-ROBERTA can handle multilingual text but may not perform as well on certain types of hate speech. The BERT, BERT-CNN, and XLM-ROBERTA models have consistent outcomes but low precision in identifying hate speech. The BERT-LSTM model has the highest precision but lower overall performance. In this paper, we present ensembling approaches that combines the strengths of multiple models, more specifically, the proposed ensemble model relying on predictions from BERT, BERT-CNN, and XLM-ROBERTA, with BERT-LSTM used as a tiebreaker for hate speech classification. The ensemble learning methods described in this paper outperformed various deep learning models for identifying hate speech.  © 2023 IEEE.},
	author_keywords = {Ensemble learning; Hate speech detection; transformers; Twitter data},
	keywords = {Long short-term memory; Semantics; Social networking (online); Speech recognition; Ensemble learning; Hate speech detection; Local patterns; Long-term dependencies; Social media; Social media platforms; Speech detection; Temporal dynamics; Transformer; Twitter data; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering, UPCON 2023; Conference date: 1 December 2023 through 3 December 2023; Conference code: 197661}
}

@CONFERENCE{Guo20231568,
	author = {Guo, Keyan and Hu, Alexander and Mu, Jaden and Shi, Ziheng and Zhao, Ziming and Vishwamitra, Nishant and Hu, Hongxin},
	title = {An Investigation of Large Language Models for Real-World Hate Speech Detection},
	year = {2023},
	journal = {Proceedings - 22nd IEEE International Conference on Machine Learning and Applications, ICMLA 2023},
	pages = {1568 – 1573},
	doi = {10.1109/ICMLA58977.2023.00237},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190145285&doi=10.1109%2fICMLA58977.2023.00237&partnerID=40&md5=aa08cea408cf9393d4b6389486408155},
	affiliations = {University at Buffalo, United States; Union County Magnet High School, United States; East Chapel Hill High School, United States; Minhang Corsspoint Academy; University of Texas at San Antonio, United States},
	abstract = {Hate speech has emerged as a major problem plaguing our social spaces today. While there have been significant efforts to address this problem, existing methods are still significantly limited in effectively detecting hate speech online. A major limitation of existing methods is that hate speech detection is a highly contextual problem, and these methods cannot fully capture the context of hate speech to make accurate predictions. Recently, large language models (LLMs) have demonstrated state-of-the-art performance in several natural language tasks. LLMs have undergone extensive training using vast amounts of natural language data, enabling them to grasp intricate contextual details. Hence, they could be used as knowledge bases for context-aware hate speech detection. However, a fundamental problem with using LLMs to detect hate speech is that there are no studies on effectively prompting LLMs for context-aware hate speech detection. In this study, we conduct a large-scale study of hate speech detection, employing five established hate speech datasets. We discover that LLMs not only match but often surpass the performance of current benchmark machine learning models in identifying hate speech. By proposing four diverse prompting strategies that optimize the use of LLMs in detecting hate speech. Our study reveals that a meticulously crafted reasoning prompt can effectively capture the context of hate speech by fully utilizing the knowledge base in LLMs, significantly outperforming existing techniques. Furthermore, although LLMs can provide a rich knowledge base for the contextual detection of hate speech, suitable prompting strategies play a crucial role in effectively leveraging this knowledge base for efficient detection. © 2023 IEEE.},
	author_keywords = {few-shot learning; hate speech; large language model; prompt engineering},
	keywords = {Computational linguistics; Knowledge based systems; Knowledge management; Large datasets; Learning systems; Speech recognition; Context-Aware; Few-shot learning; Hate speech; Language model; Large language model; Natural languages; Prompt engineering; Real-world; Social spaces; Speech detection; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd IEEE International Conference on Machine Learning and Applications, ICMLA 2023; Conference date: 15 December 2023 through 17 December 2023; Conference code: 198226}
}

@CONFERENCE{Dalavi2023506,
	author = {Dalavi, Sushil and Nivelkar, Tanvesh and Patil, Sarvesh and Sawant, Aadesh and Vanwari, Pankaj},
	title = {Enhancing Hate Speech Detection through Emoji-based Classification using Bi-LSTM and GloVe Embeddings},
	year = {2023},
	journal = {2023 6th IEEE International Conference on Advances in Science and Technology, ICAST 2023},
	pages = {506 – 511},
	doi = {10.1109/ICAST59062.2023.10455077},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187789760&doi=10.1109%2fICAST59062.2023.10455077&partnerID=40&md5=a91f250a7b57d5febac24b3db977c62c},
	affiliations = {Vidyalankar Institute of Technology, Computer Department, Mumbai, India},
	abstract = {The emergence of user-friendly and affordable online networking platforms like YouTube and Instagram have provided people of all ages with a platform to express themselves and share their personal experiences. Regrettably, this has also resulted in surge of harmful and unwarranted statements being made on these platforms, with the aim of damaging someone's reputation or social status. To combat this, it is crucial for both the government and these platforms to acknowledge and take steps to curb hate speech. However, identifying hate speech automatically can be a daunting task, particularly in tech-savvy countries like India, where non-standard spellings, varied grammatical structures, and code-mixed language with emojis are prevalent. In this study, we delve into the identification of hateful speech within text that incorporates emojis through the implementation of machine learning and deep learning models on code-mixed social media content. Our approach involves analyzing approximately 42,000 tweets that feature both textual and emoji-based features. The results of our recommended approach have been favorable in detecting abusive language in relevant datasets. © 2023 IEEE.},
	author_keywords = {abusive; Bi-LSTM; Emoji-based hate speech model; GloVe; networking; TfidfVectorizer},
	keywords = {Codes (symbols); Learning systems; Speech recognition; Abusive; Bi-LSTM; Embeddings; Emoji-based hate speech model; Glove; Networking; Speech detection; Speech models; Tfidfvectorizer; User friendly; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th IEEE International Conference on Advances in Science and Technology, ICAST 2023; Conference date: 8 December 2023 through 9 December 2023; Conference code: 197834}
}

@CONFERENCE{Prajnashree2023563,
	author = {Prajnashree, M. and Rachana, K. and Hegde, Asha and Kavya, G. and Coelho, Sharal and Shashirekha, H.L.},
	title = {Taming Toxicity: Learning Models for Hate Speech and Offensive Language Detection in Social Media Text},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {563 – 573},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193921560&partnerID=40&md5=a447e1aeddc6ffd4db2c59781a0d98e9},
	affiliations = {Department of Computer Science, Mangalore University, Karnataka, Mangalore, India},
	abstract = {User-friendly social media platforms like Twitter, Facebook, etc., provide opportunities for their users’ to voice their opinions against anything and everything. People, irrespective of the age group, use these social media platforms to share every moment of their life making these sites flooded with user-generated text. However, the anonymity of users on these platforms is misused by some culprits to spread hate speech (hatred and unrealistic comments) and/or abusive/offensive content, against anybody with an ulterior motive to tarnish one’s image and status in the society. Identifying such messages and filtering them out to stop spreading further has become very crucial in maintaining a healthy social media ecosystem. With the increase in user-generated text in low-resourced Indo-Aryan languages, identifying Hate Speech and Offensive Content (HASOC) in these languages is increasing gradually. To address the challenges of identifying HASOC in Indo-Aryan languages, in this paper, we - team MUCS, describe the learning models submitted to”Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC) 2023” at Forum for Information Retrieval Evaluation (FIRE) 2023. This shared task has four subtasks and we participated in Task 1A and 1B (to identify hate speech, offensive language, and profanity, in Sinhala and Gujarati respectively) and Task 4 (to detect hate speech in Assamese, Bengali and Bodo). Several experiments are carried out with hand crafted features (syllable n-grams extracted from the given text and character (char) n-grams extracted from romanized text) and fastText word embeddings, to train various Machine Learning (ML) classifiers to identify HASOC in Task 1A and Task 4. Due to very small training data in Task 1B, this task is modeled as Few-Shot Learning (FSL) problem and experimented with Siamese Network using Long Short-Term Memory (LSTM) (trained with Gujarati fastText word embeddings) and Ensemble of ML classifers with hard voting (trained with Sentence Transformer (ST)), to identify HASOC in Gujarati. Among the proposed models, Support Vector Machine (SVM) trained with char n-grams features obtained a better macro F1 score of 0.78 for Sinhala language in Task 1A, and Siamese-LSTM model obtained a better macro F1 score of 0.72 for Gujarati language in Task 1B. Further, SVM trained with syllable n-grams and char n-grams of romanized text obtained better macro F1 scores of 0.688, 0.668, and 0.836 for Assamese, Bengali, and Bodo languages respectively in Task 4. © 2023 Copyright for this paper by its authors.},
	author_keywords = {character n-grams; Ensemble; fastText word embeddings; Few-shot learning; Machine learning; Syllable n-grams},
	keywords = {Brain; Computational linguistics; Long short-term memory; Social networking (online); Speech recognition; Syntactics; Character n-gram; Embeddings; Ensemble; F1 scores; Fasttext word embedding; Few-shot learning; Machine-learning; N-grams; Syllable n-gram; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@ARTICLE{Elzayady20231979,
	author = {Elzayady, Hossam and Mohamed, Mohamed S. and Badran, Khaled M. and Salama, Gouda I.},
	title = {A hybrid approach based on personality traits for hate speech detection in Arabic social media},
	year = {2023},
	journal = {International Journal of Electrical and Computer Engineering},
	volume = {13},
	number = {2},
	pages = {1979 – 1988},
	doi = {10.11591/ijece.v13i2.pp1979-1988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143850414&doi=10.11591%2fijece.v13i2.pp1979-1988&partnerID=40&md5=6506db437741ac548019634b4c7ddc3b},
	affiliations = {Department of Computer Engineering, Military Technical College, Cairo, Egypt},
	abstract = {In recent years, as social media has grown in popularity, people have gained the ability to freely share their views. However, this may lead to users' conflict and hostility, resulting in unattractive online environments. Hate speech relates to using expressions or phrases that are violent, offensive, or insulting to a minority of people. The number of Arab social media users is quickly rising, and this is being followed by an increase in the frequency of cyber hate speech in the area. Therefore, the automated detection of Arabic hate speech has become a major concern for many stakeholders. The intersection of personality learning and hate speech detection is a relatively less studied niche. We suggest a novel approach that is focused on extracting personality trait features and using these features to detect Arabic hate speech. The experimental results show that the proposed approach is superior in terms of the macro-F1 score by achieving 82.3% compared to previous work reported in the literature. © 2023 Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Deep learning; Hate speech; Machine learning; Personality traits; Text mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access}
}

@CONFERENCE{Sathishkumar2023,
	author = {Sathishkumar, R. and Karthikeyan, T. and Praveen, Kumar P and Shamsundar, S.M.},
	title = {Ensemble Text Classification with TF-IDF Vectorization for Hate Speech Detection in Social Media},
	year = {2023},
	journal = {2023 International Conference on System, Computation, Automation and Networking, ICSCAN 2023},
	doi = {10.1109/ICSCAN58655.2023.10395354},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185008943&doi=10.1109%2fICSCAN58655.2023.10395354&partnerID=40&md5=f0c5a0998fa61e215e31af896823b4b9},
	affiliations = {Manakula Vinayagar Institute of Technology, Department of Computer Science and Engineering, Puducherry, India; Sri Manakula Vinayagar Engineering College, Department of Computer Science and Business Systems, Puducherry, India; Sri Manakula Vinayagar Engineering College, Department of Information Technology, Puducherry, India},
	abstract = {The development of artificial intelligence (AI) has changed how hate speech is detected. In hate speech identification using machine learning, a number of methods are used to automatically find text that uses vocabulary that is considered to be derogatory, discriminatory, or motivated by hatred. Supervised learning techniques like neural networks, decision trees, and SVMs need a labelled dataset comprising samples of hate speech and non-hate speech. This project investigates the use of AI and machine learning techniques to automatically detect material that uses offensive, intolerant, or hostile words. A voting classifier and TF-IDF representations are combined to improve classification accuracy. The ensemble of classifiers, powered by AI approaches, shows impressive accuracy in identifying hate speech by training five different classifiers (Random Forest, Bagging, Support Vector Machine, AdaBoost, and Gradient Boosting) on a labelled dataset of tweets. The TF-IDF representation prioritises textual terms, whereas the ensemble method uses classifier diversity to capture distinctive patterns. Results from experiments show the strategy's effectiveness, with precision 0.95, recall 0.96, f1-score 0.95 and accuracy 0.97 for detecting hate speech. By successfully utilising AI's capacity to fight hate speech, this research helps the development of a diverse and secure online environment. The suggested approach works well for automatically identifying hate speech, making the internet a safer and more welcoming place for all users. © 2023 IEEE.},
	author_keywords = {Decision Tree Classifier; Hate Speech; Machine learning; Naive Bayes; Random Forest Classifier; Stochastic Gradient Descent; SVM},
	keywords = {Adaptive boosting; Classification (of information); Decision trees; Gradient methods; Learning systems; Social networking (online); Speech recognition; Support vector machines; Decision tree classifiers; Hate speech; Labeled dataset; Machine-learning; Naive bayes; Random forest classifier; Stochastic gradient descent; SVM; Text classification; Vectorization; Stochastic systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on System, Computation, Automation and Networking, ICSCAN 2023; Conference date: 17 November 2023 through 18 November 2023; Conference code: 196895}
}

@CONFERENCE{Andryan2023,
	author = {Andryan and Chandra, Nathalia and Pramunita, Putu Devi Ariska and Parmonangan, Ivan Halim and Diana},
	title = {Hate Speech Detection in Indonesian Song Lyric Using BERT},
	year = {2023},
	journal = {2023 IEEE 9th International Conference on Computing, Engineering and Design, ICCED 2023},
	doi = {10.1109/ICCED60214.2023.10425528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186730379&doi=10.1109%2fICCED60214.2023.10425528&partnerID=40&md5=8e9a97bc3f072d4ba5f864da82a0bdeb},
	affiliations = {Bina Nusantara University, School of Computer Science, Computer Science Department, Jakarta, Indonesia},
	abstract = {This study was conducted with the aim of detecting hate speech in song lyrics. The background of this study stems from the numerous negative impacts caused by hate speech. We focus on detecting hate speech in song lyrics because music is a popular form of art that can have significant impacts on people's lives. There have been many previous studies that attempted hate speech detection using various methods. However, one issue still persists, especially when dealing with slang or uncommon sentence structures. According to the previous works, deep learning algorithms, such as using pre-trained BERT model for sentiment analysis and R-CNN as a classifier, have shown promise in addressing these issues. Hence, we decided to utilize the BERT pre-trained model for sentiment analysis and R-CNN as the classifier in their study. The dataset used in this research was collected from the Twitter dataset on Kaggle and also utilized the Spotify API. The study resulted in an precision score of 100% a recall score of 37% and an F1-score of 54% for the hate speech detection. Our result suggests that more relevant data, such as datasets consisting of poetry or sentences with implicit meanings, will be beneficial to enhance hate speech detection in song lyrics. © 2023 IEEE.},
	author_keywords = {BERT; Hate Speech; Indonesian Song; Lyric; Music; R-CNN; Sentiment Analysis},
	keywords = {Deep learning; Music; Speech recognition; BERT; F1 scores; Hate speech; Indonesian song; Lyric; R-CNN; Sentence structures; Sentiment analysis; Speech detection; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th IEEE International Conference on Computing, Engineering and Design, ICCED 2023; Conference date: 7 November 2023 through 8 November 2023; Conference code: 197271}
}

@CONFERENCE{Zhang20236610,
	author = {Zhang, Zhehao and Chen, Jiaao and Yang, Diyi},
	title = {Mitigating Biases in Hate Speech Detection from A Causal Perspective},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {6610 – 6625},
	doi = {10.18653/v1/2023.findings-emnlp.440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183305275&doi=10.18653%2fv1%2f2023.findings-emnlp.440&partnerID=40&md5=f42c069a6e60e03776e30178b2ae0139},
	affiliations = {Dartmouth College, United States; Georgia Institute of Technology, United States; Stanford University, United States},
	abstract = {Warning: This paper discusses and contains offensive or upsetting content. Nowadays, many hate speech detectors are built to automatically detect hateful content. However, their training sets are sometimes skewed towards certain stereotypes (e.g., race or religion-related). As a result, the detectors are prone to depend on some shortcuts for predictions. Previous works mainly focus on token-level analysis and heavily rely on human experts' annotations to identify spurious correlations, which is not only costly but also incapable of discovering higher-level artifacts. In this work, we use grammar induction to find grammar patterns for hate speech and analyze this phenomenon from a causal perspective. Concretely, we categorize and verify different biases based on their spuriousness and influence on the model prediction. Then, we propose two mitigation approaches including Multi-Task Intervention and Data-Specific Intervention based on these confounders. Experiments conducted on 9 hate speech datasets demonstrate the effectiveness of our approaches. The code is available at https://github.com/SALT-NLP/Bias_Hate_Causal. © 2023 Association for Computational Linguistics.},
	keywords = {Speech recognition; Confounder; Expert annotations; Grammar induction; Human expert; Model prediction; Multi tasks; Speech detection; Training sets; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Garani2023,
	author = {Garani, Yogita and Joshi, Shreya and Kulkarni, Savitri},
	title = {Offensive Sentiment Detection with Chat GPT and Other Transformers in Kannada},
	year = {2023},
	journal = {2023 IEEE 2nd International Conference on Data, Decision and Systems, ICDDS 2023},
	doi = {10.1109/ICDDS59137.2023.10434684},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186658999&doi=10.1109%2fICDDS59137.2023.10434684&partnerID=40&md5=ddc98944bca7d8692ef1fcfea94273be},
	affiliations = {PES University South Campus, Bengaluru, India; KLETECH, KLE Technological University, Hubballi, India},
	abstract = {Social media has provided us the privilege of free speech. This liberty however is often subject to misappropriation by users. Active detection of the presence of offensive and foul language in online communication to prevent defamation of individuals and targeted groups thus has become imperative. This paper aims to improve offensive sentiment detection in social media comments in Kannada. We introduce a novel ensemble that combines the power of 4 large language models-XLM RoBERTa, mBERT, indicBERT and kannadaBERT to understand the complexity in the language and achieve a noticeable improvement in performance for detecting offensive sentiment in Kannada comments. We introduce a novel comparison with pre-trained Chat GPT that presents a remarkable lift in performance in comparison with the fine-tuned models-mBERT, XLM RoBERTa and the proposed ensemble. © 2023 IEEE.},
	author_keywords = {Bidirectional LSTM; ChatGPT; Ensembling; Large Language Models (LLMs); Offensive Sentiment; Transfer Learning; Transformers},
	keywords = {Computational linguistics; Long short-term memory; Bidirectional LSTM; ChatGPT; Ensembling; Language model; Large language model; Offensive sentiment; Performance; Social media; Transfer learning; Transformer; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd IEEE International Conference on Data, Decision and Systems, ICDDS 2023; Conference date: 1 December 2023 through 2 December 2023; Conference code: 197456}
}

@CONFERENCE{Bestgen2023411,
	author = {Bestgen, Yves},
	title = {Using Only Character Ngrams for Hate Speech and Offensive Content Identification in Five Low-Ressource Languages},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {411 – 417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193991406&partnerID=40&md5=0ff417fe53984a6c134e97844ff8f0f0},
	affiliations = {Laboratoire d’Analyse Statistique des Textes - Statistical Analysis of Text Laboratory (LAST - SATLab), Université Catholique de Louvain, 10 place Cardinal Mercier, Louvain-la-Neuve, 1348, Belgium},
	abstract = {This paper describes the system proposed by the SATLab for hate speech and offensive content identification in five low-ressource languages. This language-agnostic system applies a classical supervised learning to character n-grams, using no other data than the learning materials. After optimizing a series of parameters, it ranked first in the Bodo task and second in the Gujarati task, for which the learning material contained only 200 tweets. It also performed well in the Sinhala and Assamese task, but was outperformed by several systems in the Bengali task. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Character ngrams; gradient boosting decision tree; logistic regression; low-resource languages},
	keywords = {Logistic regression; Bengalis; Character ngram; Content identifications; Gradient boosting; Gradient boosting decision tree; Learning materials; Logistics regressions; Low resource languages; N-grams; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Sajja2023967,
	author = {Sajja, Bhavyesh and Singh, Anurag},
	title = {Detection of Violent Content in Videos Using 2D Attention-Augmented Convolutional Networks and Gated Recurrent Unit},
	year = {2023},
	journal = {2023 IEEE 20th India Council International Conference, INDICON 2023},
	pages = {967 – 972},
	doi = {10.1109/INDICON59947.2023.10440672},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187324682&doi=10.1109%2fINDICON59947.2023.10440672&partnerID=40&md5=9f2f5d89b6503ee38aec5c077f6bf90f},
	affiliations = {National Institute of Technology Delhi, Department of Computer Science and Engineering, New Delhi, India},
	abstract = {Nowadays, most online videos over the Internet contain violent and explicit content. These videos are available to anyone. Such content must be moderated as it can be disturbing to a majority of viewers and can negatively impact people of younger generations. Currently, researchers use LSTM and Transformer-based architectures to detect violent content, which requires high computing power that edge devices cannot offer. Hence, in this paper, a resource-efficient, attention-based deep learning technique is developed to identify and handle violent video content. The proposed model has been compared against the state-of-the-art models. Our model shows appreciable improvement in results with minimal computing power.  © 2023 IEEE.},
	author_keywords = {Edge Devices; Gated Recurrent Unit; Multi-headed Self-attention; Violence},
	keywords = {Convolutional neural networks; Learning systems; Long short-term memory; Computing power; Convolutional networks; Edge device; Gated recurrent unit; Multi-headed self-attention; Online video; Resource-efficient; Video over the Internet; Violence; Younger generations; Computing power},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th IEEE India Council International Conference, INDICON 2023; Conference date: 14 December 2023 through 17 December 2023; Conference code: 197663}
}

@ARTICLE{Aziz2023,
	author = {Aziz, Samia and Sarfraz, Muhammad Shahzad and Usman, Muhammad and Aftab, Muhammad Umar and Rauf, Hafiz Tayyab},
	title = {Geo-Spatial Mapping of Hate Speech Prediction in Roman Urdu},
	year = {2023},
	journal = {Mathematics},
	volume = {11},
	number = {4},
	doi = {10.3390/math11040969},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149005237&doi=10.3390%2fmath11040969&partnerID=40&md5=e6aff4ec59e3d81e8aeba59b2536f24f},
	affiliations = {Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Chiniot-Faisalabad Campus, Chiniot, 35400, Pakistan; Centre for Smart Systems, AI and Cybersecurity, Staffordshire University, Stoke-on-Trent, ST4 2DE, United Kingdom},
	abstract = {Social media has transformed into a crucial channel for political expression. Twitter, especially, is a vital platform used to exchange political hate in Pakistan. Political hate speech affects the public image of politicians, targets their supporters, and hurts public sentiments. Hate speech is a controversial public speech that promotes violence toward a person or group based on specific characteristics. Although studies have been conducted to identify hate speech in European languages, Roman languages have yet to receive much attention. In this research work, we present the automatic detection of political hate speech in Roman Urdu. An exclusive political hate speech labeled dataset (RU-PHS) containing 5002 instances and city-level information has been developed. To overcome the vast lexical structure of Roman Urdu, we propose an algorithm for the lexical unification of Roman Urdu. Three vectorization techniques are developed: TF-IDF, word2vec, and fastText. A comparative analysis of the accuracy and time complexity of conventional machine learning models and fine-tuned neural networks using dense word representations is presented for classifying and predicting political hate speech. The results show that a random forest and the proposed feed-forward neural network achieve an accuracy of 93% using fastText word embedding to distinguish between neutral and politically offensive speech. The statistical information helps identify trends and patterns, and the hotspot and cluster analysis assist in pinpointing Punjab as a highly susceptible area in Pakistan in terms of political hate tweet generation. © 2023 by the authors.},
	author_keywords = {deep learning; machine learning; natural language processing; spatial analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Sathya2023521,
	author = {Sathya, M. Krithik and Gopalakrishnan, K.H. and Manickam, P.A. and Balasundaram, Prabavathy},
	title = {Sinhala and Gujarati Hate Speech Detection},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {521 – 531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194003293&partnerID=40&md5=25ff1244faebe02a3201ee4f116c4788},
	affiliations = {Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, India; Department of Computer Science, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, India},
	abstract = {This study, conducted by the”Krispy Mango” research team, focuses on hate speech and offensive content detection in two low-resource Indo-Aryan languages, Sinhala and Gujarati, as part of the HASOC 2023 shared tasks. We address the difficulty of classifying tweets into Hate and Offensive (HOF) and Non-Hate and Offensive (NOT) categories by fine-tuning the BERT models. This work presents findings in the form of macro F1 scores and precision metrics for both languages. Our approach aims to advance the state-of-the-art in detecting hate speech while taking into account the particular linguistic characteristics and resource restrictions of these languages. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT Models; Hate Speech Detection; Multilingual NLP; Offensive Language Identification; Text Classification},
	keywords = {Linguistics; Natural language processing systems; Speech recognition; Text processing; BERT model; Content detection; Hate speech detection; Language identification; Multilingual NLP; Offensive language identification; Offensive languages; Research teams; Speech detection; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Singh2023,
	author = {Singh, Rohith Kumar and Sanjay, H.A. and Pramod Jain, S.A. and Rishi, Hrithik and Bhardwaj, Sachin},
	title = {NLP Based Hate Speech Detection And Moderation},
	year = {2023},
	journal = {7th IEEE International Conference on Computational Systems and Information Technology for Sustainable Solutions, CSITSS 2023 - Proceedings},
	doi = {10.1109/CSITSS60515.2023.10333320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181540891&doi=10.1109%2fCSITSS60515.2023.10333320&partnerID=40&md5=ea99823d6f2d55aa91b078298c47c00e},
	affiliations = {M S Ramaiah Institute of Technology, Dept. of Information Science & Engineering, Bangalore, India; Nitte Meenakshi Institute of Technology, Dept. of Information Science & Engineering, Bangalore, India},
	abstract = {As Social media penetration increases in day-to-day life so does the growth of hate speech. After 2016 due to affordability of internet many user on boarded the internet which not only increased social media interactions but also growth of hate speech. be it religion phobia, homophobia, gender, toxicity etc. To control hate speech, NLP based machine learning model has been proposed. The proposed model uses TFIDF feature generation method to which binarized naive bayes is applied to calculate maximum likelihood feature for each labels. Model has been trained with logistic regression on the maximum likelihood feature. which helps to classify hate speech and moderate accordingly. The proposed model produces an overall accuracy of 83 percent and able to achieve 5 percent improvement compared to multinomial naive bayes' production in identifying hate speech and classifying it under various labels. © 2023 IEEE.},
	author_keywords = {Hate Speech; Logistic Regression; Machine learning; Naive Bayes; NB-LR; NLP; TFIDF},
	keywords = {Machine learning; Maximum likelihood; Natural language processing systems; Social networking (online); Hate speech; Logistics regressions; Ma ximum likelihoods; Machine-learning; Maximum-likelihood; Naive bayes; NB-LR; Social media; Speech detection; TFIDF; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th IEEE International Conference on Computational Systems and Information Technology for Sustainable Solutions, CSITSS 2023; Conference date: 2 November 2023 through 4 November 2023; Conference code: 195266}
}

@CONFERENCE{Panda2023450,
	author = {Panda, Parnani and Mishra, Sushruta and Sharma, Vandana and Alkhayyat, Ahmed},
	title = {A Voting Enabled Predictive Approach for Hate Speech Detection},
	year = {2023},
	journal = {Proceedings of International Conference on Contemporary Computing and Informatics, IC3I 2023},
	pages = {450 – 454},
	doi = {10.1109/IC3I59117.2023.10397912},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187246432&doi=10.1109%2fIC3I59117.2023.10397912&partnerID=40&md5=9fab71336fe2a5e161c9d8b38b6a9362},
	affiliations = {School of Computer Engineering, Kalinga Institute of Industrial Technology, Bhubaneswar, India; CHRIST (Deemed to Be University), Computer Science Department, Delhi NCR, India; College of Technical Engineering, The Islamic University, Najaf, Iraq},
	abstract = {In today's digital environment, hate speech, which is defined as disparaging and discriminating communication based on personal characteristics, presents a big difficulty. Hate crimes and the rising amount of such content on social media platforms are two examples of how it is having an impact. Large volumes of textual data require manual analysis and categorization, which is tedious and subject to prejudice. Machine learning (ML) technologies have the ability to automate hate speech identification with increased objectivity and accuracy in order to overcome these constraints. This article intends to give a comparative analysis of various ML models for the identification of hate speech. The proliferation of such content online and its negative repercussions on people and society are explored, as is the necessity for automated hate speech recognition. This paper intends to support the creation of efficient hate speech detection systems by performing a comparative analysis of ML models. Random forest records the best performance with higher accuracy and low response delay period for hate speech detection. The results will help enhance automated text classification algorithms and, in the end, promote a safer and more welcoming online environment by illuminating the benefits and drawbacks of various approaches.  © 2023 IEEE.},
	author_keywords = {CountVectorizer; Hate speech detection; logistic regression; machine learning; Naive Bayes classifier; Random Forest classifier},
	keywords = {Classification (of information); Machine learning; Random forests; Speech communication; Speech recognition; Text processing; Comparative analyzes; Countvectorizer; Digital environment; Hate speech detection; Logistics regressions; Machine learning models; Machine-learning; Naive Bayes classifiers; Random forest classifier; Speech detection; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th International Conference on Contemporary Computing and Informatics, IC3I 2023; Conference date: 14 September 2023 through 16 September 2023; Conference code: 196902}
}

@CONFERENCE{Gaurav2023,
	author = {Gaurav, Akshat and Gupta, Brij B. and Chui, Kwok Tai and Arya, Varsha and Chaurasia, Priyanka},
	title = {Deep Learning Based Hate Speech Detection on Twitter},
	year = {2023},
	journal = {IEEE International Conference on Consumer Electronics - Berlin, ICCE-Berlin},
	doi = {10.1109/ICCE-Berlin58801.2023.10375620},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182924464&doi=10.1109%2fICCE-Berlin58801.2023.10375620&partnerID=40&md5=21f9c9e3df55b23fbe44b21a043315ca},
	affiliations = {Ronin Institute, Montclair, United States; Asia University, Department of Computer Science and Information Engineering, Taichung, 413, Taiwan; Hong Kong Metropolitan University (HKMU), Hong Kong; Asia University, Department of Business Administration, Taiwan; University of Ulster, United Kingdom},
	abstract = {There have been growing worries about the effects of the widespread use of hate speech and harsh language on social media sites like Twitter. Effective strategies for recognising and reducing such dangerous material are necessary for resolving this problem. In this research, we give a detailed analysis of four deep learning models for identifying hate speech and inflammatory language on Twitter: the Long Short-Term Memory (LSTM), the Recurrent Neural Network (RNN), the Bidirectional LSTM (Bi-LSTM), and the Gated Recurrent Unit (GRU). We downloaded a large dataset from Kaggle that was curated for hate speech identification and used it in our experiment. We built each model after preprocessing and tokenization, then tweaked their hyperparameters for maximum efficiency. The models' abilities to detect hate speech were evaluated using standard measures including accuracy, precision, recall, and Fl-score. Our findings show that there is a wide range of effectiveness amongst models in terms of identifying hate speech and inflammatory language on Twitter. In terms of accuracy and Fl-scores, the Bi-LSTM and GRU models were superior to the LSTM and RNN. The results of this study imply that using bidirectional and gated processes may increase the models' capability of understanding the interdependencies and contexts of tweets, and hence, their classification accuracy. © 2023 IEEE.},
	author_keywords = {Bi-LSTM; GRU; Hate Speech; LSTM; RNN; Twitter},
	keywords = {Large dataset; Social networking (online); Speech recognition; Bidirectional LSTM; Gated recurrent unit; Hate speech; Large datasets; Learning models; Social media; Speech detection; Speech identification; Tokenization; Twitter; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th IEEE International Conference on Consumer Electronics - Berlin, ICCE-Berlin 2023; Conference date: 4 September 2022 through 5 September 2022; Conference code: 196153}
}

@CONFERENCE{Kim202310964,
	author = {Kim, Youngwook and Park, Shinwoo and Namgoong, Youngsoo and Han, Yo-Sub},
	title = {CONPROMPT: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {10964 – 10980},
	doi = {10.18653/v1/2023.findings-emnlp.731},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183298123&doi=10.18653%2fv1%2f2023.findings-emnlp.731&partnerID=40&md5=1a614c0250ee0f542966b276baaf21c7},
	affiliations = {KT, Seoul, South Korea; Yonsei University, Seoul, South Korea},
	abstract = {Implicit hate speech detection is a challenging task in text classification since no explicit cues (e.g., swear words) exist in the text. While some pre-trained language models have been developed for hate speech detection, they are not specialized in implicit hate speech. Recently, an implicit hate speech dataset with a massive number of samples has been proposed by controlling machine generation. We propose a pre-training approach, CONPROMPT, to fully leverage such machine-generated data. Specifically, given a machine-generated statement, we use example statements of its origin prompt as positive samples for contrastive learning. Through pre-training with CONPROMPT, we present TOXIGEN-CONPROMPT, a pre-trained language model for implicit hate speech detection. We conduct extensive experiments on several implicit hate speech datasets and show the superior generalization ability of TOXIGEN-CONPROMPT compared to other pre-trained models. Additionally, we empirically show that CONPROMPT is effective in mitigating identity term bias, demonstrating that it not only makes a model more generalizable but also reduces unintended bias. We analyze the representation quality of TOXIGEN-CONPROMPT and show its ability to consider target group and toxicity, which are desirable features in terms of implicit hate speeches. © 2023 Association for Computational Linguistics.},
	keywords = {Classification (of information); Speech recognition; Text processing; Desirable features; Generalization ability; Language model; Number of samples; Pre-training; Speech detection; Target group; Text classification; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Balakrishnan2023,
	author = {Balakrishnan, Vimala and Govindan, Vithyatheri and Govaichelvan, Kumanan N.},
	title = {Tamil Offensive Language Detection: Supervised versus Unsupervised Learning Approaches},
	year = {2023},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {22},
	number = {4},
	doi = {10.1145/3575860},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161559459&doi=10.1145%2f3575860&partnerID=40&md5=efc1bf1b414ce8581ff5e72763d245e0},
	affiliations = {Faculty of Computer Science, Information Technology, Universiti Malaya, Federal Territory of Kuala Lumpur, Kuala Lumpur, 50603, Malaysia},
	abstract = {Studies on natural language processing are mainly conducted in English, with very few exploring languages that are under-resourced, including the Dravidian languages. We present a novel work in detecting offensive language using a corpus collected from YouTube containing comments in Tamil. The study specifically aims to compare two machine learning approaches - namely, supervised and unsupervised - to detect offensive patterns in textual communications. In the first setup, offensive language detection models were developed using traditional machine learning algorithms such as Random Forest, Logistic Regression, Support Vector Machine, and AdaBoost, and assessed based on human labeling. Conversely, we used K-means (K = 2) to cluster the unlabeled data before training the same set of machine learning algorithms to detect offensive communications. Performance scores indicate unsupervised clustering to be more effective than human labeling with ensemble classifiers achieving an impressive accuracy of 99.70% and 99.87% respectively for balanced and imbalanced datasets, hence showing that the unsupervised approach can be used effectively to detect offensive language in low-resourced languages.  © 2023 Association for Computing Machinery.},
	author_keywords = {Dravidian; machine learning; Offensive language; social media; Tamil},
	keywords = {Classification (of information); Forestry; K-means clustering; Learning systems; Logistic regression; Natural language processing systems; Random forests; Social networking (online); Support vector machines; Dravidian; Human labelling; Language detection; Learning approach; Machine learning algorithms; Machine-learning; Natural languages; Offensive languages; Social media; Tamil; Adaptive boosting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Daouadi20231319,
	author = {Daouadi, Kheir Eddine and Boualleg, Yaakoub and Guehairia, Oussama},
	title = {Deep Random Forest and AraBert for Hate Speech Detection from Arabic Tweets},
	year = {2023},
	journal = {Journal of Universal Computer Science},
	volume = {29},
	number = {11},
	pages = {1319 – 1335},
	doi = {10.3897/jucs.112604},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181470724&doi=10.3897%2fjucs.112604&partnerID=40&md5=b42422292227d0f5ee3cbdfec21c70f1},
	affiliations = {Laboratory of Vision and Artificial Intelligence (LAVIA), Echahid Cheikh Larbi Tebessi University, Tebessa, Algeria; Laboratory of LESIA, Mohamed Khider University of Biskra, Biskra, Algeria},
	abstract = {Nowadays, hate speech detection from Arabic tweets attracts the attention of many researchers. Numerous systems and techniques have been proposed to address this classification challenge. Nonetheless, three major limits persist: the use of deep learning models with an excess of hyperparameters, the reliance on hand-crafted features, and the requirement for a huge amount of training data to achieve satisfactory performance. In this study, we propose Contextual Deep Random Forest (CDRF), a hate speech detection approach that combines contextual embedding and Deep Random Forest. From the experimental findings, the Arabic contextual embedding model proves to be highly effective in hate speech detection, outperforming the static embedding models. Additionally, we prove that the proposed CDRF significantly enhances the performance of Arabic hate speech classification. © 2023, IICM. All rights reserved.},
	author_keywords = {Arabic Tweet Classification; Contextual Deep Random Forest; Fine-tuning; Hate Speech Detection; Pre-trained Contextual Embedding; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Stekel2023418,
	author = {Stekel, Avigail and Prives, Avital and HaCohen-Kerner, Yaakov},
	title = {Detecting Offensive Language in Bengali, Bodo, and Assamese using Word Unigrams, Char N-grams, Classical Machine Learning, and Deep Learning Methods},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {418 – 426},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193972081&partnerID=40&md5=42b0d5877eb59bde6c65e3b5894d0d92},
	affiliations = {Computer Science Department, Jerusalem College of Technology, Jerusalem, 9116001, Israel},
	abstract = {In this paper, we, the JCT team, describe our submissions for the HASOC 2023 track. We participated in task 4, which addresses the problem of hate speech and offensive language identification in three languages: Bengali, Bodo, and Assamese. We developed different models using five classical supervised machine learning methods: multinomial Naive Bayes)MNB(, support vector classifier, random forest, logistic regression (LR), and multi-layer perceptron. Our models were applied to word unigrams and/or character n-gram features. In addition, we applied two versions of relevant deep learning models. Our best model for the Assamese language is an MNB model with 5-gram features, which achieves a macro averaged F1-score of 0.6988. Our best model for Bengali is an MNB model with 6-gram features, which achieves a macro averaged F1-score of 0.66497. Our best submission for Bodo is a LR with all word unigrams in the training set. This model obtained a macro averaged F1-score of 0.85074. It was ranked in the shared 2nd-3rd place out of 20 teams. Our result is lower by only 0.00576 than the result of the team that was ranked in the 1st place. Our GitHub repository link is avigailst/co2023 (github.com). © 2023 Copyright for this paper by its authors.},
	author_keywords = {Char n-grams; hate speech; offensive language; supervised machine learning; word unigrams},
	keywords = {Deep learning; Learning systems; Logistic regression; Natural language processing systems; Supervised learning; Syntactics; Bengalis; Best model; Char n-gram; F1 scores; Hate speech; Logistics regressions; N-grams; Offensive languages; Supervised machine learning; Word unigram; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Gutha2023445,
	author = {Gutha, Abhinav Reddy and Adarsh, Nidamanuri Sai and Alekar, Ananya and Reddy, Dinesh},
	title = {Multilingual Hate Speech and Offensive Language Detection of Low Resource Languages},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {445 – 458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193983816&partnerID=40&md5=8b7dc8e96e3ee7357fcbf6018138ccfd},
	affiliations = {Indian Institute of Technology, Goa, 403401, India},
	abstract = {The last decade has seen a steep rise in the use and dependence of society on social media. The need for detection and prevention of hate and offensive speech is more than ever. The everchanging form of natural language makes the detection of hate speech challenging, involving code-mixed text. The task becomes even more daunting in a country like India, where different languages and dialects are spoken across the country. This paper details the Code Fellas team’s approaches in the context of HASOC 2023 - Task 4: Annihilate Hate, an initiative aimed at extending hate speech detection to Bengali, Bodo, and Assamese languages. Here we describe our approaches which broadly involve Long Short Term Memory (LSTM) coupled with Convolutional Neural Networks (CNN) and pre-trained Bidirectional Encoder Representations from Transformers (BERT) based models like IndicBERT [1] and MuRIL [2]. Notably, our results showcase the effectiveness of these approaches, with IndicBERT achieving a remarkable F1 score of 69.726% for Assamese, MuRIL achieving 71.955% for Bengali, and a BiLSTM model enhanced with an additional Dense Layer attaining an impressive 83.513% for Bodo. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Convolutional Neural Networks; Hate Speech; LSTM; Offensive Language; Transformers},
	keywords = {Codes (symbols); Convolution; Convolutional neural networks; Speech recognition; Bengalis; Convolutional neural network; Hate speech; Language detection; Low resource languages; Natural languages; Offensive languages; Social media; Speech detection; Transformer; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Fernando2023,
	author = {Fernando, Eranga and Deng, Jeremiah},
	title = {Enhancing Hate Speech Detection in Sinhala Language on Social Media using Machine Learning},
	year = {2023},
	journal = {International Conference on Information Systems, ICIS 2023: "Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies"},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184426327&partnerID=40&md5=efc20ef7d7adb2be2a751e8471b48499},
	affiliations = {Department of Information Technology, University of Moratuwa, Sri Lanka; School of Computing, University of Otago, Dunedin, New Zealand},
	abstract = {To counter the harmful dissemination of hate speech on social media, especially abusive outbursts of racism and sexism, automatic and accurate detection is crucial. However, a significant challenge lies in the vast sparsity of available data, hindering accurate classification. This study presents a novel approach to Sinhala hate speech detection on social platforms by coupling a global feature selection process with traditional machine learning, the research scrutinizes hate speech intricacies. A class-based variable feature selection process evaluates significance via global and local scores, identifying optimal values for prevalent classifiers. Utilizing class-based and corpus-based evaluations, we pinpoint optimal feature values for classifiers like SVM, MNB, and RF. Our results reveal notable enhancements in performance, specifically the F1-Score, underscoring how feature selection and parameter tuning work in tandem to boost model efficacy. Furthermore, the study explores nuanced variations in classifier performance across training and testing datasets, emphasizing the importance of model generalization. Copyright © 2023 Fernando & Deng.},
	author_keywords = {Class-Based Assessment; Feature Selection; Hate Speech; High Sparsity},
	keywords = {Classification (of information); Couplings; Social networking (online); Speech recognition; Support vector machines; Class-based; Class-based assessment; Features selection; Global feature; Global score; Hate speech; High sparsity; Machine-learning; Social media; Speech detection; Feature Selection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 44th International Conference on Information Systems: Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies, ICIS 2023; Conference date: 10 December 2023 through 13 December 2023; Conference code: 199133}
}

@CONFERENCE{Ranasinghe2023375,
	author = {Ranasinghe, Tharindu and Zampieri, Marcos},
	title = {A Text-to-Text Model for Multilingual Offensive Language Identification},
	year = {2023},
	journal = {IJCNLP-AACL 2023 - 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics, Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023},
	pages = {375 – 384},
	doi = {10.18653/v1/2023.findings-ijcnlp.33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188550806&doi=10.18653%2fv1%2f2023.findings-ijcnlp.33&partnerID=40&md5=fb9aa84b77f8e2b343d0b38f56b5b8a8},
	affiliations = {Aston University, Birmingham, United Kingdom; George Mason University, Fairfax, VA, United States},
	abstract = {The ubiquity of offensive content on social media is a growing cause for concern among companies and government organizations. Recently, transformer-based models such as BERT, XL-NET, and XLM-R have achieved state-of-the-art performance in detecting various forms of offensive content (e.g. hate speech, cyberbullying, and cyberaggression). However, the majority of these models are limited in their capabilities due to their encoder-only architecture, which restricts the number and types of labels in downstream tasks. Addressing these limitations, this study presents the first pre-trained model with encoder-decoder architecture for offensive language identification with text-to-text transformers (T5) trained on two large offensive language identification datasets; SOLID and CCTK. We investigate the effectiveness of combining two datasets and selecting an optimal threshold in semi-supervised instances in SOLID in the T5 retraining step. Our pre-trained T5 model outperforms other transformer-based models fine-tuned for offensive language detection, such as fBERT and HateBERT, in multiple English benchmarks. Following a similar approach, we also train the first multilingual pre-trained model for offensive language identification using mT5 and evaluate its performance on a set of six different languages (German, Hindi, Korean, Marathi, Sinhala, and Spanish). The results demonstrate that this multilingual model achieves a new state-of-the-art on all the above datasets, showing its usefulness in multilingual scenarios. Our proposed T5-based models will be made freely available to the community. © 2023 Asian Federation of Natural Language Processing.},
	keywords = {Natural language processing systems; Signal encoding; Cyber bullying; Down-stream; Encoder-decoder architecture; Government organizations; Language identification; Offensive languages; Optimal threshold; Social media; State-of-the-art performance; Text modeling; Large datasets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics: Findings of the Association for Computational Linguistic, IJCNLP-AACL 2023; Conference date: 1 November 2023 through 4 November 2023; Conference code: 197967; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhou20238,
	author = {Zhou, Li and Cabello, Laura and Cao, Yong and Hershcovich, Daniel},
	title = {Cross-Cultural Transfer Learning for Chinese Offensive Language Detection},
	year = {2023},
	journal = {Cross-Cultural Considerations in NLP at EACL, C3NLP 2023 - Proceedings of the Workshop},
	pages = {8 – 15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185219830&partnerID=40&md5=c5b17e3db9851024fa78886933a8f51f},
	affiliations = {University of Electronic Science and Technology of China, China; Department of Computer Science, University of Copenhagen, Denmark; Huazhong University of Science and Technology, China},
	abstract = {Detecting offensive language is a challenging task. Generalizing across different cultures and languages becomes even more challenging: besides lexical, syntactic and semantic differences, pragmatic aspects such as cultural norms and sensitivities, which are particularly relevant in this context, vary greatly. In this paper, we target Chinese offensive language detection and aim to investigate the impact of transfer learning using offensive language detection data from different cultural backgrounds, specifically Korean and English. We find that culture-specific biases in what is considered offensive negatively impact the transferability of language models (LMs) and that LMs trained on diverse cultural data are sensitive to different features in Chinese offensive language detection. In a few-shot learning scenario, however, our study shows promising prospects for non-English offensive language detection with limited resources. Our findings highlight the importance of cross-cultural transfer learning in improving offensive language detection and promoting inclusive digital spaces. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Transfer learning; Cultural backgrounds; Cultural norms; Digital space; Language detection; Language model; Learning scenarios; Offensive languages; Semantic difference; Transfer learning; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st Wokshop on Cross-Cultural Considerations in NLP, C3NLP 2023; Conference date: 5 May 2023; Conference code: 196553}
}

@CONFERENCE{Bensalem2023423,
	author = {Bensalem, Imene and Mout, Meryem Ait and Rosso, Paolo},
	title = {Offensive Language Detection in Arabizi},
	year = {2023},
	journal = {ArabicNLP 2023 - 1st Arabic Natural Language Processing Conference, Proceedings},
	pages = {423 – 434},
	doi = {10.18653/v1/2023.arabicnlp-1.36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183886494&doi=10.18653%2fv1%2f2023.arabicnlp-1.36&partnerID=40&md5=0b593fd02abdb444e095ffba5c4d278b},
	affiliations = {ESCF de Constantine, MISC Lab., Constantine 2 University, Algeria; Polytech Marseille, Aix-Marseille Université, France; Universitat Politècnica de València, Spain},
	abstract = {Detecting offensive language in under-resourced languages presents a significant real-world challenge for social media platforms. This paper is the first work focused on the issue of offensive language detection in Arabizi, an under-explored topic in an under-resourced form of Arabic. For the first time, a comprehensive and critical overview of the existing work on the topic is presented. In addition, we carry out experiments using different BERT-like models and show the feasibility of detecting offensive language in Arabizi with high accuracy. Throughout a thorough analysis of results, we emphasize the complexities introduced by dialect variations and out-of-domain generalization. We use in our experiments a dataset that we have constructed by leveraging existing, albeit limited, resources. To facilitate further research, we make this dataset publicly accessible to the research community. © 2023 Association for Computational Linguistics.},
	keywords = {Generalisation; High-accuracy; Language detection; Offensive languages; Publicly accessible; Real-world; Research communities; Social media platforms; Under-resourced; Under-resourced languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st Arabic Natural Language Processing Conference, ArabicNLP 2023; Conference date: 7 December 2023; Conference code: 196514; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhou202312684,
	author = {Zhou, Li and Karamolegkou, Antonia and Chen, Wenyu and Hershcovich, Daniel},
	title = {Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {12684 – 12702},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183292993&partnerID=40&md5=55dd10a70ae7023bd404da2c6ba0c10f},
	affiliations = {University of Electronic Science and Technology of China, China; Department of Computer Science, University of Copenhagen, Denmark},
	abstract = {The increasing ubiquity of language technology necessitates a shift towards considering cultural diversity in the machine learning realm, particularly for subjective tasks that rely heavily on cultural nuances, such as Offensive Language Detection (OLD). Current understanding underscores that these tasks are substantially influenced by cultural values, however, a notable gap exists in determining if cultural features can accurately predict the success of cross-cultural transfer learning for such subjective tasks. Addressing this, our study delves into the intersection of cultural features and transfer learning effectiveness. The findings reveal that cultural value surveys indeed possess a predictive power for cross-cultural transfer learning success in OLD tasks and that it can be further improved using offensive word distance. Based on these results, we advocate for the integration of cultural information into datasets. Additionally, we recommend leveraging data sources rich in cultural information, such as surveys, to enhance cultural adaptability. Our research signifies a step forward in the quest for more inclusive, culturally sensitive language technologies. © 2023 Association for Computational Linguistics.},
	keywords = {Transfer learning; 'current; Cultural diversity; Cultural informations; Cultural value; Feature learning; Language detection; Language technology; Machine-learning; Offensive languages; Transfer learning; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127}
}

@CONFERENCE{Züfle2023204,
	author = {Züfle, Maike and Dankers, Verna and Titov, Ivan},
	title = {Latent Feature-based Data Splits to Improve Generalisation Evaluation: A Hate Speech Detection Case Study},
	year = {2023},
	journal = {GenBench 2023 - GenBench: 1st Workshop on Generalisation (Benchmarking) in NLP, Proceedings},
	pages = {204 – 213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184516910&partnerID=40&md5=f7b42195ca35ea6f6ba9d090ac4b4e17},
	affiliations = {ILCC, University of Edinburgh, United Kingdom; ILLC, University of Amsterdam, Netherlands},
	abstract = {With the ever-growing presence of social media platforms comes the increased spread of harmful content and the need for robust hate speech detection systems. Such systems easily overfit to specific targets and keywords, and evaluating them without considering distribution shifts that might occur between train and test data overestimates their benefit. We challenge hate speech models via new train-test splits of existing datasets that rely on the clustering of models' hidden representations. We present two split variants (SUBSET-SUM-SPLIT and CLOSEST-SPLIT) that, when applied to two datasets using four pretrained models, reveal how models catastrophically fail on blind spots in the latent space. This result generalises when developing a split with one model and evaluating it on another. Our analysis suggests that there is no clear surface-level property of the data split that correlates with the decreased performance, which underscores that task difficulty is not always humanly interpretable. We recommend incorporating latent feature-based splits in model development and release two splits via the GenBench benchmark. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Blind spots; Case-studies; Clusterings; Detection system; Feature-based; Generalisation; Social media platforms; Speech detection; Speech models; Test data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st Workshop on Generalisation (Benchmarking) in NLP, GenBench 2023; Conference date: 6 December 2023; Conference code: 196543}
}

@ARTICLE{Seemann2023,
	author = {Seemann, Nina and Lee, Yeong Su and Höllig, Julian and Geierhos, Michaela},
	title = {The problem of varying annotations to identify abusive language in social media content},
	year = {2023},
	journal = {Natural Language Engineering},
	volume = {10772},
	number = {4},
	doi = {10.1017/S1351324923000098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151807505&doi=10.1017%2fS1351324923000098&partnerID=40&md5=2f6e493276aad8429c1c1139d56860ae},
	affiliations = {Research Institute Code, University of the Bundeswehr Munich, Neubiberg, Germany},
	abstract = {With the increase of user-generated content on social media, the detection of abusive language has become crucial and is therefore reflected in several shared tasks that have been performed in recent years. The development of automatic detection systems is desirable, and the classification of abusive social media content can be solved with the help of machine learning. The basis for successful development of machine learning models is the availability of consistently labeled training data. But a diversity of terms and definitions of abusive language is a crucial barrier. In this work, we analyze a total of nine datasets - five English and four German datasets - designed for detecting abusive online content. We provide a detailed description of the datasets, that is, for which tasks the dataset was created, how the data were collected, and its annotation guidelines. Our analysis shows that there is no standard definition of abusive language, which often leads to inconsistent annotations. As a consequence, it is difficult to draw cross-domain conclusions, share datasets, or use models for other abusive social media language tasks. Furthermore, our manual inspection of a random sample of each dataset revealed controversial examples. We highlight challenges in data annotation by discussing those examples, and present common problems in the annotation process, such as contradictory annotations and missing context information. Finally, to complement our theoretical work, we conduct generalization experiments on three German datasets. © The Author(s), 2023. Published by Cambridge University Press.},
	author_keywords = {Abusive Language; Dataset Analysis; Natural Language Processing},
	keywords = {Learning algorithms; Natural language processing systems; Social networking (online); Abusive language; Automatic detection systems; Data-set analysis; Language processing; Machine-learning; Media content; Natural language processing; Natural languages; Social media; User-generated; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hidayat2023213,
	author = {Hidayat, Muh. Fachrul and Setiawan, Erwin Budi},
	title = {Feature Expansion with GloVe for Hate Speech Detection Using Convolutional Neural Network (CNN) and Long Short-term Memory (LSTM) Methods on Twitter},
	year = {2023},
	journal = {Proceeding - COMNETSAT 2023: IEEE International Conference on Communication, Networks and Satellite},
	pages = {213 – 218},
	doi = {10.1109/COMNETSAT59769.2023.10420686},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186112145&doi=10.1109%2fCOMNETSAT59769.2023.10420686&partnerID=40&md5=0092514433ba326f918f82b3db079eb1},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {Hate speech is unwanted behavior that aims to attack individuals or groups. The spread of hate speech can be found on social media, one of which is on the Twitter platform. This problem can be solved by classifying hate speech. This research proposes to build a hybrid model of hate speech detection using three deep learning models CNN (Convolutional Neural Network), LSTM (Long-Short Term Memory), and a combination of both models. The dataset used comes from Twitter in the form of Indonesian tweets. TF-IDF (Term Frequency - Inverse Document Frequency) and GloVe (Global Vector) are used as feature extraction and feature expansion to improve the accuracy of each model. Several scenarios were tested to find the best features. The best results in this study used a dataset with a ratio of 90% train and 10% test after preprocessing, TF-IDF with Unigram + Bigram + Trigram weighting, and 10,000 feature vectors. The method with Top 10 feature expansion in the tweet corpus achieved the highest accuracy of 90.83% for the CNN-LSTM hybrid model and improved by 0.79% against the previously determined baseline followed by the LSTM-CNN model with a result of 91.72% which improved by 1.88% against the baseline.  © 2023 IEEE.},
	author_keywords = {CNN; GloVe; hate speech; hybrid; LSTM},
	keywords = {Brain; Convolution; Convolutional neural networks; Feature extraction; Inverse problems; Social networking (online); Speech recognition; Statistical tests; Text processing; Convolutional neural network; Features extraction; Global vector; Hate speech; Hybrid; Hybrid model; Learning models; Social media; Speech detection; Term frequencyinverse document frequency (TF-IDF); Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2023; Conference date: 23 November 2023 through 25 November 2023; Conference code: 197147}
}

@CONFERENCE{Mittal2023,
	author = {Mittal, Utkarsh},
	title = {Detecting Hate Speech Utilizing Deep Convolutional Network and Transformer Models},
	year = {2023},
	journal = {IEEE International Conference on Electrical, Electronics, Communication and Computers, ELEXCOM 2023},
	doi = {10.1109/ELEXCOM58812.2023.10370502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182946816&doi=10.1109%2fELEXCOM58812.2023.10370502&partnerID=40&md5=6a1edab738a42fd44721da78ee3fbf7f},
	affiliations = {Stanford University, Manager of Machine Learning and Automation, Gap Inc., Student Department of Computer Science, United States},
	abstract = {Online social networks exhibit a significant prevalence of hate speeches, which poses a potential threat to the society and fosters targeted animosity towards specific communities and authorities. Although online platforms are available to automate few mechanisms of hate speeches but classification w.r.t. to different domains and their accuracy are the big issues, and are challenging the researchers, media, and the academic world. The present study addresses the identifying of Hate Speeches through the comparative analysis of the classification efficacy and model intricacy of four distinct Deep Neural Network models; namely CNN (baseline), bidirectional LSTM with attention, pretrained BERT, and fine-tuned RoBERTa transformer models, and utilizing a ternary classification system (hate, offensive, non-hate). The performance of the subject under consideration was assessed through the application of Accuracy, F1-score, and Matthew's correlation coefficient (MCC) metrics on the test set.  © 2023 IEEE.},
	author_keywords = {BERT; CNN; Hate Speech; LSTM; MCC; Transformer},
	keywords = {Convolutional neural networks; Deep neural networks; Long short-term memory; BERT; Convolutional networks; Correlation coefficient; Hate speech; LSTM; Matthew correlation coefficient; Network models; Potential threats; Transformer; Transformer modeling; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 IEEE International Conference on Electrical, Electronics, Communication and Computers, ELEXCOM 2023; Conference date: 26 August 2023 through 27 August 2023; Conference code: 196101}
}

@ARTICLE{Ghosh2023760,
	author = {Ghosh, Soumitra and Ekbal, Asif and Bhattacharyya, Pushpak and Saha, Tista and Kumar, Alka and Srivastava, Shikha},
	title = {SEHC: A Benchmark Setup to Identify Online Hate Speech in English},
	year = {2023},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {10},
	number = {2},
	pages = {760 – 770},
	doi = {10.1109/TCSS.2022.3157474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127042823&doi=10.1109%2fTCSS.2022.3157474&partnerID=40&md5=832a960c85a6894795fe24ac35696b77},
	affiliations = {IIT Patna, Department of Computer Science and Engineering, Patna, 801106, India; Centre for Development of Telematics (C-DOT), New Delhi, 110030, India},
	abstract = {Thanks to the digital age, online speech and information may now be disseminated anonymously without regard for repercussions. Regulators face a unique problem with social media platforms because of the speed and volume of material and the lack of editorial supervision. The existing datasets on hate speech or offensive language identification lack diversity in the dataset's content. In this article, we create a multi-domain hate speech corpus (MHC) of English tweets that includes hate speech against religion, nationality, ethnicity, and gender in general and cover diverse domains, such as current affairs, politics, terrorism, technology, natural disasters, and human/drugs trafficking. Each instance in our dataset is manually annotated as hate or non-hate. We use the existing state-of-the-art models and present a stacked-ensemble-based hate speech classifier (SEHC) to identify hate speech from Twitter data. Our results indicate that the proposed method may serve as a strong baseline for future studies using this dataset. (The dataset is available at https://www.iitp.ac.in/ai-nlp-ml/resources.html#MHC.)  © 2014 IEEE.},
	author_keywords = {Annotated dataset; deep learning; ensemble learning; hate speech; neural networks; offensive language; social media; tweet classification},
	keywords = {Blogs; Deep learning; Disasters; Job analysis; Social networking (online); Speech recognition; Terrorism; Annotated datasets; Deep learning; Ensemble learning; Features extraction; Government; Hate speech; Neural-networks; Offensive languages; Social media; Social networking (online); Task analysis; Tweet classification.; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Manzoor2023,
	author = {Manzoor, Tahbib and Rahman Araf, Md. Wahidur and Sharker Omi, Monjurul and Abir, Tanvir Ahmed and Das Abir, Arpan and Orchi, Irin Hoque and Bin Ashraf, Faisal},
	title = {Mitigating Online Harassment: Machine Learning Approaches for Hate Speech Detection in Transliterated Bengali Comments},
	year = {2023},
	journal = {2023 26th International Conference on Computer and Information Technology, ICCIT 2023},
	doi = {10.1109/ICCIT60459.2023.10441244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187330133&doi=10.1109%2fICCIT60459.2023.10441244&partnerID=40&md5=a4f3f53399205f67c49cfc80f426ea63},
	affiliations = {Brac University, Department of Computer Science and Engineering, Bangladesh},
	abstract = {In the era of widespread online communication, the detection of hate speech has become increasingly critical for maintaining a healthy digital discourse. This significance is magnified when considering languages with unique characteristics, such as transliterated Bengali, where challenges in distinguishing hate speech abound. This work undertakes the task of exploring machine learning algorithms to tackle this challenge and contribute to the broader effort of fostering a respectful and inclusive online environment. The study introduces a novel dataset for hate speech detection in transliterated Bengali text, employing two distinct data preprocessing approaches - TF-IDF and Bag of Words. Eight diverse machine learning algorithms are then applied to evaluate their performance under each preprocessing technique. The results showcase the efficacy of specific algorithms, with Multinomial Naive Bayes excelling in the binary dataset and Logistic Regression emerging as a top performer in the multiclass dataset. Despite encountering challenges like imbalanced data and word length distribution, our models demonstrate enhanced precision and recall. This work not only contributes valuable insights to the field but also provides a new dataset, paving the way for future advancements in hate speech detection and model robustness.  © 2023 IEEE.},
	author_keywords = {Hate Speech Classification; Hate Speech Detection; Machine Learning; Natural Language Processing (NLP); Social Media},
	keywords = {E-learning; Learning systems; Logistic regression; Machine learning; Natural language processing systems; Social networking (online); Speech communication; Speech recognition; Bengalis; Hate speech classification; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Social media; Speech classification; Speech detection; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 26th International Conference on Computer and Information Technology, ICCIT 2023; Conference date: 13 December 2023 through 15 December 2023; Conference code: 197664}
}

@CONFERENCE{Kaati20234065,
	author = {Kaati, Lisa and Shrestha, Amendra and Akrami, Nazar},
	title = {General Risk Index A Measure for Predicting Violent Behavior Through Written Communication},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {4065 – 4070},
	doi = {10.1109/BigData59044.2023.10386789},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184978311&doi=10.1109%2fBigData59044.2023.10386789&partnerID=40&md5=59d599e4a45b8cea64e5670a07af6878},
	affiliations = {Stockholm University, Stockholm, Sweden; Mind Intelligence Lab, Uppsala, Sweden; Uppsala University, Uppsala, Sweden},
	abstract = {One of the most challenging threats to the security of society is attacks from violent lone offenders. Identifying potential offenders is difficult since they act alone and do not necessarily communicate with others. However, several targeted violent attacks have been preceded by communication published on social media and the internet. Such communication is a valuable component when conducting risk and threat assessments.In this paper, we introduce a diagnostic measure of the risk of violent behavior based on text analysis. Using automated text analysis, we extract psychological variables and warning indicators from a given text and summarize these in an index that we denote as the general risk index. When developing the general risk index, we analyzed data (text) from 208 288 users on 32 online environments with diverse ideologies/orientations, including 76 previous violent lone offenders. A receiver operating characteristics (ROC) analysis showed that, when using the general risk index, it was possible to correctly classify between 90% and 96% of the cases depending on the comparison sample. These results support the predictive validity of the general risk index, suggesting that the risk index can be used to identify individuals with an increased risk of committing violent attacks that need further investigation.  © 2023 IEEE.},
	keywords = {Behavior-based; Diagnostic measures; Risk indices; Risks assessments; Social media; Text analysis; Threat assessment; Valuable component; Violent behavior; Written communications; Risk assessment},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 IEEE International Conference on Big Data, BigData 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 196820}
}

@BOOK{Touahri2023190,
	author = {Touahri, Ibtissam},
	title = {Arabic Offensive Language and Hate Speech Detection Using Ensemble Transformers and Data Augmentation},
	year = {2023},
	journal = {Combatting Cyberbullying in Digital Media with Artificial Intelligence},
	pages = {190 – 202},
	doi = {10.1201/9781003393061-13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181778840&doi=10.1201%2f9781003393061-13&partnerID=40&md5=4facbd1deb1147d3b1debe87b066df5b},
	affiliations = {Department of Computer Science, University Moulay Ismail, Meknes, Morocco},
	abstract = {Offensive content is a harmful substance that has infiltrated the internet. Hence, preventing the spread of such a toxic language may help in the prevention of numerous psychological, social, and political harmful effects. A way to contribute is through the classification of social media comments as offensive/hate speech or not. In this chapter, we aim at detecting offensive content and hate speech on social media. We employed a multidomain data set whose comments were collected and annotated by the organizers of a shared task on offensive language and Hate speech. We base our system on AraBERT, MarBERT, and Qarib transformer models, and then improve the classification performance using ensemble learning, which handles the models outputs according to the F1-measure average. Since the studied data set is highly imbalanced, we have then performed augmentation of low represented data and investigated its effect on the classification. We then analyzed common and specific classification errors besides highlighting the main shortcomings and potential improvements. Our system based on transfer and ensemble learning achieved an improvement in comparison to the best ranked team in OSACT5 shared task, whose corpora are used within this study. © 2024 selection and editorial matter, Mohamed Lahby, Al-Sakib Khan Pathan and Yassine Maleh; individual chapters, the contributors.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Senapati2023553,
	author = {Senapati, Chandan and Roy, Utpal},
	title = {Bengali Hate Speech Detection Using Deep Learning Technique},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {553 – 562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193971439&partnerID=40&md5=adac8f0a2c6bb2e97a90a695f3d0f065},
	affiliations = {Visva-Bharati University, Department of Computer and System Sciences, Siksha-Bhavana, Visva-Bharati, W.B., Santiniketan, 731235, India},
	abstract = {Social media has become a part of life and a great platform to communicate with each other and share ideas. With the proliferation of online platforms, and social media, sharing of ideas, and posting comments on different issues, mainly posting abusive comments on religion, gender, political ideology, race, and other issues has become a significant concern in the digital era. These negative messages are collectively called hate speech. Hate speech promotes discrimination, hostility, or violence towards individuals or groups based on attributes such as race, religion, ethnicity, gender, etc. Hate speech in various languages has made a surge, including Bengali. Detecting hate speech in Bengali presents unique challenges due to the language’s linguistic complexity, diversity, and the absence of comprehensive resources. Social media is a place of interest for researchers in the fields of Natural Language Processing, Machine Learning and Deep Learning due to its huge collection of data. In this paper, we implement the deep learning model Long Short Term Memory (LSTM), a powerful recurrent neural network (RNN) architecture to automatically learn intricate patterns and contextual information from text data and detect hate speech. LSTM networks are well-suited for sequence modeling, making them particularly effective in capturing the context and nuances of natural language. We fine-tune the LSTM model to optimize its performance for Bengali text, considering factors such as word embeddings, tokenizing, stop words, architecture, etc. To evaluate the effectiveness of our approach, extensive experiments are conducted on the given dataset, employing various evaluation metrics such as precision, recall, Macro F1-score, and accuracy. The test dataset is labeled using our model. The results demonstrate the robustness and efficiency of our LSTM-based hate speech detection system in identifying offensive or hate content in Bengali text. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Hate speech; LSTM; Machine Learning; Natural Language Processing; RNN},
	keywords = {Computational linguistics; Learning algorithms; Learning systems; Modeling languages; Natural language processing systems; Network architecture; Social networking (online); Speech recognition; Statistical tests; Bengalis; Deep learning; Hate speech; Language processing; Learning techniques; Machine-learning; Natural language processing; Natural languages; Social media; Speech detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Sai2023435,
	author = {Sai, G. Gnana and Venkatesh, Aswath and Kishore, N. and Olirva, M. and Balaji, V.A. and Balasundaram, Prabavathy},
	title = {Enhancing Hate Speech Detection in Sinhala and Gujarati: Leveraging BERT Models and Linguistic Constraints},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {435 – 444},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193933756&partnerID=40&md5=1736a65ad8fdd98d307e6ea6a983f6c4},
	affiliations = {Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, India; Department of Computer Science, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, India},
	abstract = {This research paper, presented by the SSN_CSE_ML_TEAM, introduces a unified approach to hate speech and offensive language identification in two low-resource Indo-Aryan languages, Sinhala and Gujarati, as part of the HASOC 2023 shared tasks. Leveraging various BERT models, we address the challenge of classifying tweets into Hate and Offensive (HOF) and Non-Hate and Offensive (NOT) categories by fine-tuning the BERT models. Our approach seeks to advance the state-of-the-art in detecting hate speech while considering the unique linguistic characteristics and resource constraints of these languages. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT Models; Hate Speech Detection; Multilingual NLP; Offensive Language Identificationn; Text Classification},
	keywords = {Classification (of information); Computational linguistics; Speech recognition; Text processing; BERT model; Hate speech detection; Linguistic constraints; Model constraints; Multilingual NLP; Offensive language identificationn; Offensive languages; Research papers; Speech detection; Text classification; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Yuzbashyan20231,
	author = {Yuzbashyan, Nerses and Banar, Nikolay and Markov, Ilia and Daelemans, Walter},
	title = {An Exploration of Zero-Shot Natural Language Inference-Based Hate Speech Detection},
	year = {2023},
	journal = {LTEDI 2023 - 3rd Workshop on Language Technology for Equality, Diversity and Inclusion, associated with the 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023 - Proceedings},
	pages = {1 – 9},
	doi = {10.26615/978-954-452-084-7_001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184993538&doi=10.26615%2f978-954-452-084-7_001&partnerID=40&md5=469d1528a572c89c2e2f6a2ff9e851f6},
	affiliations = {University of Antwerp, Belgium; Vrije Universiteit, Amsterdam, Netherlands},
	abstract = {Conventional techniques for detecting online hate speech rely on the availability of a sufficient number of annotated instances, which can be costly and time consuming. For this reason, zero-shot or few-shot detection can offer an attractive alternative. In this paper, we explore a zero-shot detection approach based on natural language inference (NLI) models. The performance of the models in this approach depends heavily on the choice of a hypothesis, which represents a statement that is evaluated with a given sentence to determine the logical relationship between them. Our goal is to determine which factors affect the quality of detection. We conducted a set of experiments with three NLI models and four hate speech datasets. We demonstrate that a zero-shot NLI-based approach is competitive with approaches that require supervised learning, yet they are highly sensitive to the choice of hypothesis. In addition, our experiments indicate that the results for a set of hypotheses on different model-data pairs are positively correlated, and that the correlation is higher for different datasets when using the same model than it is for different models when using the same dataset. These results suggest that if we find a hypothesis that works well for a specific model and domain or for a specific type of hate speech, we can use that hypothesis with the same model also within a different domain. While another model might require different suitable hypotheses in order to demonstrate high performance. © 2023 LTEDI 2023 - 3rd Workshop on Language Technology for Equality, Diversity and Inclusion, associated with the 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023 - Proceedings. All rights reserved.},
	keywords = {Zero-shot learning; Conventional techniques; Detection approach; Inference models; Language inference; Logical relationships; Modeling data; Natural languages; Performance; Shot detection; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd Workshop on Language Technology for Equality, Diversity and Inclusion, LTEDI 2023; Conference date: 7 September 2023; Conference code: 196595}
}@CONFERENCE{Yadav2023,
	author = {Yadav, Sargam and Kaushik, Abhishek and McDaid, Kevin},
	title = {Hate Speech is not Free Speech: Explainable Machine Learning for Hate Speech Detection in Code-Mixed Languages},
	year = {2023},
	journal = {International Symposium on Technology and Society, Proceedings},
	doi = {10.1109/ISTAS57930.2023.10305996},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178521180&doi=10.1109%2fISTAS57930.2023.10305996&partnerID=40&md5=b7709df970cc3c5e5027a085a0b91fb3},
	affiliations = {School of Informatics and Creative Art, Dundalk Institute of Technology, Dundalk, Ireland},
	abstract = {The increase in connectivity provided by social media platforms comes with several disadvantages. It has become surprisingly easy for ill-intentioned individuals to stalk, harass and threaten others online on the basis of race, gender, religion, etc. Artificial intelligence models provide a valuable solution to the problem by automatically filtering such content. However, research for hate speech detection in low-resource languages is still nascent. To promote research in the area, several shared tasks are held in various languages and attract contributions with novel approaches. In this study, we use the English and Hindi code-mixed datasets provided by the HASOC Identification of Conversational Hate-Speech in Code-Mixed Languages (ICHCL) shared task to train and evaluate machine learning models and compare the performance of different vectorization techniques and model parameters. The Explainable Artificial Intelligence (XAI) technique Local Interpretable Model Agnostic Explanation (LIME) is also applied to the model results to ascertain if the model is behaving in a coherent and logical manner. The highest accuracy achieved is 67.61 % using Bernoulli Naive Bayes with count vectorizer and TF-IDF. The analysis suggests that many of the models may be heavily influenced by the presence of slur words while classifying a statement as hateful and offensive.  © 2023 IEEE.},
	author_keywords = {explainable artificial intelligence; hate speech; Hinglish; LIME; machine learning; mix-code; sentiment analysis; word2vec},
	keywords = {Internet of things; Lime; Machine learning; Speech recognition; Explainable artificial intelligence; Free speech; Hate speech; Hinglish; Local interpretable model agnostic explanation; Machine-learning; Mix-code; Sentiment analysis; Speech detection; Word2vec; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 29th Annual IEEE International Symposium on Technology and Society, ISTAS 2023; Conference date: 13 September 2023 through 15 September 2023; Conference code: 194386}
}

@BOOK{Usman2023195,
	author = {Usman and Quadri, S.M.K.},
	title = {Encoder/Decoder Transformer-Based Framework to Detect Hate Speech from Tweets},
	year = {2023},
	journal = {Intelligent Data Analytics, IoT, and Blockchain},
	pages = {195 – 207},
	doi = {10.1201/9781003371380-19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174766735&doi=10.1201%2f9781003371380-19&partnerID=40&md5=f50ddc623c45a191be381ae9806bcdc6},
	affiliations = {Jamia Millia Islamia University, New Delhi, India},
	abstract = {With the proliferation of social networking sites like Twitter, hate speech is spreading more rapidly and inflicting more harm than ever before. Existing approaches for detecting hate speech encounter difficulties in a number of areas, including addressing data scarcity, calculating model ambiguity, strengthening resilience against malicious assaults, and dealing with unintentional bias. There is an immediate need for precise, reliable, and equitable categorization of hateful speaking in online communities. In this paper, we have proposed an approach for hate speech detection in which we have generated hateful as well as non-hateful datasets using the GPT2 (generative pretrained transfer) model. Using this approach, the generated tweets will be automatically classified into three categories: 0 - hate speech, 1 - offensive language, 2 - neither should be considered. A deep learning-based model is applied to the generation of the data and machine learning models applied to the detection of the hate in the data. This model might function as a monitoring system between the user and Twitter. © 2024 Taylor & Francis Group, LLC.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Raghuram2023899,
	author = {Raghuram, A.S. and Bhoomika, B.R. and Gokul, D. and Kuppanda, Malavika and Khaleeq, Mohammed},
	title = {A Review on Detection of Offensive Language in Social Media},
	year = {2023},
	journal = {14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023},
	volume = {2023-June},
	pages = {899 – 903},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174408271&partnerID=40&md5=245000f2ab54615c505515746ca981e8},
	affiliations = {ATME College Of Engineering, Mysore, India},
	abstract = {Since the textual contents on online social media are highly unstructured, informal, and often misspelled, existing research on message-level offensive language detection cannot accurately detect offensive content. This feature of the social media to express something openly to the world have created the major problems for these online businesses and negatively impacted the well-being of the societal decorum. There are increasing cases of the abuse or offense on the social media like Hate speech, Cyber-bullying, Aggression or general Profanity. It is very much important to understand that this behavior can not only immensely affect the life of an individual or a group but could be suicidal in some cases adversely hampering the mental health of the victims . © Grenze Scientific Society, 2023.},
	author_keywords = {Hate speech; Offensive},
	keywords = {Cyber bullying; Hate speech; Language detection; Offensive; Offensive languages; Online business; Online social medias; Social media; Textual content; Well being; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023; Conference date: 15 June 2023 through 16 June 2023; Conference code: 192282}
}

@ARTICLE{Kazbekova2023793,
	author = {Kazbekova, Gulnur and Ismagulova, Zhuldyz and Kemelbekova, Zhanar and Tileubay, Sarsenkul and Baimurzayev, Boranbek and Bazarbayeva, Aizhan},
	title = {Offensive Language Detection on Online Social Networks using Hybrid Deep Learning Architecture},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {11},
	pages = {793 – 805},
	doi = {10.14569/IJACSA.2023.0141180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179385244&doi=10.14569%2fIJACSA.2023.0141180&partnerID=40&md5=4d70546a30a20c08da2437dcf9cf2210},
	affiliations = {Khoja Akhmet Yassawi International Kazakh-Turkish University, Turkistan, Kazakhstan; M. Auezov South Kazakhstan University, Shymkent, Kazakhstan; Korkyt Ata Kyzylorda University, Kyzylorda, Kazakhstan},
	abstract = {In the digital era, online social networks (OSNs) have revolutionized communication, creating spaces for vibrant public discourse. However, these platforms also harbor offensive language that can proliferates hate speech, cyberbullying, and discrimination, significantly undermining the quality of online interactions and posing severe social implications. This research paper introduces a sophisticated approach to offensive language detection on OSNs, employing a novel Hybrid Deep Learning Architecture (HDLA). The urgency of addressing offensive content is juxtaposed with the challenges inherent in accurately identifying nuanced communications, thus necessitating an advanced model that transcends the limitations of traditional natural language processing techniques. The proposed HDLA model synergistically integrates Convolutional Neural Networks (CNNs) with Long Short-Term Memory (LSTM) networks, capitalizing on the strengths of both methodologies. While the CNN component excels in the hierarchical extraction of spatial features within text data, identifying offensive patterns often concealed in the structural nuances, the LSTM network, adept in processing sequential data, captures the contextual dependencies in user posts over time. This duality ensures a comprehensive analysis of complex linguistic constructs, enhancing the detection accuracy for both overt and covert offensive content. Our research meticulously evaluates the HDLA model using extensive, multi-source datasets reflective of diverse OSN environments, establishing benchmarks against prevailing deep learning models. Results indicate a substantial improvement in precision, recall, and F1-score, demonstrating the model's efficacy in identifying offensive language amidst varying degrees of subtlety and complexity. Furthermore, the model maintains high interpretability, providing insights into the intricate mechanisms of offensive content propagation. Our findings underscore the potential of HDLA in fostering healthier online communities by efficiently curating digital content, thereby upholding the integrity of digital communication spaces. © (2023), (Science and Information Organization). All Rights Reserved.},
	author_keywords = {classification; deep learning; detection; machine learning; Offensive language; social media},
	keywords = {Backpropagation; Classification (of information); Complex networks; Convolutional neural networks; Data handling; Digital communication systems; E-learning; Learning systems; Long short-term memory; Natural language processing systems; Network architecture; Online systems; Convolutional neural network; Deep learning; Detection; Language detection; Learning architecture models; Learning architectures; Machine-learning; Memory network; Offensive languages; Social media; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Carhuancho-Bazan2023,
	author = {Carhuancho-Bazan, Alessandro and Nunez-Lazo, Sergio and Ugarte, Willy},
	title = {NoHateS: A Transformers-based Approach for Real-Time Hate Speech Detection in Spanish},
	year = {2023},
	journal = {Proceedings of the 2023 IEEE 30th International Conference on Electronics, Electrical Engineering and Computing, INTERCON 2023},
	doi = {10.1109/INTERCON59652.2023.10326033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179894711&doi=10.1109%2fINTERCON59652.2023.10326033&partnerID=40&md5=dea1677a33a23858b69c564cdbc24f61},
	affiliations = {Universidad Peruanas de Ciencias Aplicadas (UPC), Lima, Peru},
	abstract = {Hate speech detection is a challenging task, especially in the context of real-time monitoring on the internet. Manual detection is both exhausting and impractical due to the high volume and frequency of online data. This paper proposes a system called NoHateS. This system is made of multiple components, the main one is BETO-CNN, a Transformers-based model trained on a Spanish corpus, which is designed to actually detect whether a text contains hate speech or not. The second component is developed to ensure accessibility. This includes an API to allow seamless integration of the model into various applications, and a Discord Bot developed for easy manipulation of the aforementioned API in order to help users detect hate speech in text channels. This paper also includes tests with imbalanced data and applies data augmentation in order to deal with it and make more robust models. The results demonstrate the effectiveness of NoHateS in detecting hate speech and provide recommendations for future research in this domain as it achieves 72.63% and 72.94% F1-score on the non-augmented and augmented dataset respectively.  © 2023 IEEE.},
	author_keywords = {BERT; BETO; Hate speech; Transformer},
	keywords = {BERT; BETO; Hate speech; High frequency HF; High volumes; Online data; Real time monitoring; Real- time; Speech detection; Transformer; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th IEEE International Conference on Electronics, Electrical Engineering and Computing, INTERCON 2023; Conference date: 2 November 2023 through 4 November 2023; Conference code: 194797}
}

@CONFERENCE{Syahputri2023190,
	author = {Syahputri, Artisa Bunga and Sibaroni, Yuliant},
	title = {Comparative Analysis of CNN and LSTM Performance for Hate Speech Detection on Twitter},
	year = {2023},
	journal = {2023 11th International Conference on Information and Communication Technology, ICoICT 2023},
	volume = {2023-August},
	pages = {190 – 195},
	doi = {10.1109/ICoICT58202.2023.10262656},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174389036&doi=10.1109%2fICoICT58202.2023.10262656&partnerID=40&md5=f45d904d954a76a8fb1dde9e8dc70bba},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {The internet's current development has become one factor that gives social media users opportunities to leave comments and posts containing hate speech. Detecting hate speech on social media, particularly on Twitter, has recently become a widely researched topic. Research that has been conducted usually applies a standard machine learning approach. The deep learning approach has become popular because it provides better and more effective results. However, it's still rare to be applied to detect hate speech in Indonesian language texts. This research shows the results of a performance comparison from the deep learning approach using CNN, LSTM, and CNN+LSTM architecture models for detecting hate speech in tweets using the Indonesian language. The dataset used is divided into a general dataset which is the entire dataset and a specific topic dataset that deals with the topic of government, which was taken from the general dataset. The research shows better results when the CNN architecture model is implemented on Indonesian language tweet data compared to the results obtained from the LSTM architecture model and the combination of CNN+LSTM with accuracy and F1-score reaching 81%. Furthermore, the implementation of deep learning models in detecting hate speech performs better than previous research using the same dataset but applying machine learning models with feature extraction. This research also shows that specific data discussing a particular topic significantly impact the model's performance. Thus the version of the model becomes better when applied to data with a general topic and a more extensive vocabulary.  © 2023 IEEE.},
	author_keywords = {CNN; deep learning; hate speech; LSTM; Twitter},
	keywords = {Architecture; Learning systems; Long short-term memory; Social networking (online); Speech recognition; Architecture modeling; Comparative analyzes; Deep learning; Hate speech; Indonesian languages; Learning approach; LSTM; Performance; Social media; Twitter; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th International Conference on Information and Communication Technology, ICoICT 2023; Conference date: 23 August 2023 through 24 August 2023; Conference code: 193107}
}

@ARTICLE{Kusuma2023773,
	author = {Kusuma, Juanietto Forry and Chowanda, Andry},
	title = {Indonesian Hate Speech Detection Using IndoBERTweet and BiLSTM on Twitter},
	year = {2023},
	journal = {International Journal on Informatics Visualization},
	volume = {7},
	number = {3},
	pages = {773 – 780},
	doi = {10.30630/joiv.7.3.1035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172023585&doi=10.30630%2fjoiv.7.3.1035&partnerID=40&md5=f097cb6571a59c0972d552a55431d0c3},
	affiliations = {BINUS Graduate Program, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia},
	abstract = {Hate speech is an act of speech to spread hate to other people. In this digital era where everyone connects with social media, hate speech is growing rapidly and uncontrollably. Many people do not realize they are giving hate speech when critics something on social media due to a lack of awareness of the difference between hate speech and free speech. The results make victims feel alienated from society, and the people who spread it would often face the law. Detection in the sentences to identify whether it contains hate speech is essential to counter people's ignorance. For detecting such sentences, a machine learning algorithm is widely used to help identify each sentence. In this paper, we used a subset from machine learning named deep learning with the latest IndoBERT model named IndoBERTweet and combined it with RNN layer named BiLSTM. The appearance of IndoBERTweet opened more chances to further improve text classification performance with the addition of BiLSTM layer. The model first made a token representative from the sentence, then calculated it to analyze and made the classification based on the calculation. For this model to be effective, we trained our model with the labeled public dataset retrieved from Twitter. These datasets are classified into hate speech and non-hate speech, and these labels are applied to the models. We evaluated our model and achieved an accuracy of 93.7%, an improvement for classifying hate speech sentences from previous research. © 2023, Politeknik Negeri Padang. All rights reserved.},
	author_keywords = {BiLSTM; Hate speech; IndoBERTweet; text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Muaad2023429,
	author = {Muaad, Abdullah Y. and Hanumanthappa, J. (Jayappa Davanagere) and Prakash, S. P. Shiva and Al-Sarem, Mohammed and Ghabban, Fahad and Bibal Benifa, J.V. and Chola, Channabasava},
	title = {Arabic Hate Speech Detection Using Different Machine Learning Approach},
	year = {2023},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {179},
	pages = {429 – 438},
	doi = {10.1007/978-3-031-36258-3_38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171147978&doi=10.1007%2f978-3-031-36258-3_38&partnerID=40&md5=9286b5dbeee520c8805cc568a6847419},
	affiliations = {Department of Studies in Computer Science, University of Mysore, Manasagangothri, Mysore, 570006, India; IT Department, Sana’a Community College, Sana’a, 5695, Yemen; Department of Information Science and Engineering, JSS Science and Technology University, Karnataka, Mysuru, 570006, India; Department of Computer Science, Saba’a Region University, Mareb, Yemen; College of Computer Science and Engineering, Taibah University, Medina, 42353, Saudi Arabia; Department of Computer Science and Engineering, Indian Institute of Information Technology Kottayam, Kerala, Kottayam, India},
	abstract = {Hate speech is defined as an expression that targets an individual or community on the aspects like religion, sexual orientation, race, political opinion, and origin. Recently, hate speech on social media especially in the Arabic language has been exponentially increased and led to severe causes. Various studies had been conducted on social media platforms adopted by people to broadcast their opinions. This work aims to develop a model that is able to handle detection and classification of Arabic hate speech and offensive language. The experiments are carried out in using various machine learning (ML) and deep learning (DL) models. In this work, Arabic Hate Speech Detection (AHSD) model is proposed which composed of pre-processing, feature extraction, detection, and classification to identify hate speech on the Arabic benchmark dataset. The proposed model shows improved results. The transfer learning approach model exhibits superior performance compared to all other ML models in terms of accuracy, precision, recall, and F1 scores, achieving improvements of 84%, 79%, 80%, and 79%, respectively. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {AraBERT; Arabic Text Detection; Deep Learning; Hate speech Detection; Natural Language Processing (NLP)},
	keywords = {Classification (of information); Deep learning; Learning algorithms; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; AraBERT; Arabic text detection; Arabic texts; Deep learning; Hate speech detection; Language processing; Natural language processing; Natural languages; Speech detection; Text detection; Feature extraction},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@BOOK{Naskar2023447,
	author = {Naskar, Akash and Harchandani, Rohan and Thomas, K.T.},
	title = {Detection of toxic comments over the internet using deep learning methods},
	year = {2023},
	journal = {Artificial Intelligence, Blockchain, Computing and Security: Volume 1},
	volume = {1},
	pages = {447 – 454},
	doi = {10.1201/9781003393580-68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180023049&doi=10.1201%2f9781003393580-68&partnerID=40&md5=e6e8bf2b156b8eec2d4e59b40ecdf4c3},
	affiliations = {Department of Data Science, Department of Data Science CHRIST (Deemed to be University) Pune, CHRIST (Deemed to be University), Maharashtra, Lavasa, Pune, Lavasa, India},
	abstract = {People now share their ideas on a wide range of topics on social media, which has become an integral part of contemporary culture. The majority of people are increasingly turning to social media as a necessity, and there are numerous incidents of social media addiction that have been reported. Socialmedia channels. Socialmedia platforms have established their worth over time by bringing individuals from different backgrounds together, but they have also shown harmful side effects that could have serious consequences. One such unfavourable result is how extremely poisonous many discussions on social media are. Online abuse, hate speech, and occasionally outrage culture are now all considered to be toxic. In this study, we leverage the Transformers’ Bidirectional Encoder Representations to build an efficient model to detect and classify toxicity in user-generated content on social media. The Kaggle dataset with labelled toxic comments, was used to refine the BERT pre-trained model. Other Deep learning models, including Bidirectional LSTM, Bidirectional-LSTM with attention, and a few other models, were also tested to see which performed best in this classification task. We further evaluate the proposed models utilising dataset obtained from Twitter in order to find harmful content (tweets) using relevant hashtags. The findings showed how well the suggested methodology classified and analysed toxic comments. © 2024 selection and editorial matter, Arvind Dagur, Karan Singh, Pawan Singh Mehra & Dhirendra Kumar Shukla; individual chapters, the contributors.},
	author_keywords = {BER; BERT; BidirectionalLSTM; Finetuning; Hate speech; Language model; Neural networks; Pretraining; Sentiment analysis; Social media; Toxic; Toxic comment; Twitter},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ghosh2023941,
	author = {Ghosh, Koyel and Senapati, Apurbalal and Narzary, Mwnthai and Brahma, Maharaj},
	title = {HATE SPEECH DETECTION IN LOW-RESOURCE BODO AND ASSAMESE TEXTS WITH ML-DL AND BERT MODELS},
	year = {2023},
	journal = {Scalable Computing},
	volume = {24},
	number = {4},
	pages = {941 – 955},
	doi = {10.12694/scpe.v24i4.2469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178452999&doi=10.12694%2fscpe.v24i4.2469&partnerID=40&md5=89a840d79d85665f9613920515a8d8e5},
	affiliations = {Department of Computer Science and Engineering, Central Institute of Technology, Assam, Kokrajhar, India; Department of Computer Science and Engineering, IIT Hyderabad, India},
	abstract = {Hate speech detection research is a recent sizzling topic in natural language processing (NLP). Unburdened uses of social media platforms make people over-opinionative, which crosses the limit of leaving comments and posts toxic. A toxic outlook increases violence towards the neighbour, state, country, and continent. Several laws have been introduced in different countries to end the emergency problem. Now, all the media platforms have started working on restricting hate posts or comments. Hate speech detection is generally a text classification problem if considered a supervised observation. To tackle text in terms of computation perspective is challenging because of its semantic and complex grammatical nature. Resource-rich languages leverage their richness, whereas resource scarce language suffers significantly from a lack of dataset. This paper makes a multifaceted contribution encompassing resource generation, experimentation with Machine Learning (ML), Deep Learning (DL) and state-of-the-art transformer-based models, and a comprehensive evaluation of model performance, including thorough error analysis. In the realm of resource generation, it adds to the North-East Indian Hate Speech tagged dataset (NEIHS version 1), which encompasses two languages: Assamese and Bodo © 2023 SCPE. All Rights Reserved.},
	author_keywords = {Assamese; BERT; BiLSTM; Bodo; CNN; Deep Learning; Hate Speech Detection; LSTM; Machine Learning; Natural Language Processing; NB; NLP; SVM; Word2Vec},
	keywords = {Classification (of information); Learning algorithms; Learning systems; Long short-term memory; Natural language processing systems; Speech recognition; Support vector machines; Text processing; Assamese; BERT; BiLSTM; Bodo; Deep learning; Hate speech detection; Language processing; LSTM; Machine-learning; Natural language processing; Natural languages; NB; Speech detection; SVM; Word2vec; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Ibrahim20231222,
	author = {Ibrahim, Muhammad Amien and Arifin, Samsul and Purwanto, Eko Setyo},
	title = {Exploring Data Augmentation for Gender-Based Hate Speech Detection},
	year = {2023},
	journal = {Journal of Computer Science},
	volume = {19},
	number = {10},
	pages = {1222 – 1230},
	doi = {10.3844/JCSSP.2023.1222.1230},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175561376&doi=10.3844%2fJCSSP.2023.1222.1230&partnerID=40&md5=d62221c39d786a560a37ecdedeb18428},
	affiliations = {Department of Computer Science, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Department of Statistics, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia},
	abstract = {Social media moderation is a crucial component to establish healthy online communities and ensuring online safety from hate speech and offensive language. In many cases, hate speech may be targeted at specific gender which could be expressed in many different languages on social media platforms such as Indonesian Twitter. However, difficulties such as data scarcity and the imbalanced gender-based hate speech dataset in Indonesian tweets have slowed the development and implementation of automatic social media moderation. Obtaining more data to increase the number of samples may be costly in terms of resources required to gather and annotate the data. This study looks at the usage of data augmentation methods to increase the amount of textual dataset while keeping the quality of the augmented data. Three augmentation strategies are explored in this study: Random insertion, back translation, and a sequential combination of back translation and random insertion. Additionally, the study examines the preservation of the increased data labels. The performance result demonstrates that classification models trained with augmented data generated from random insertion strategy outperform the other approaches. In terms of label preservation, the three augmentation approaches have been shown to offer enough label preservation without compromising the meaning of the augmented data. The findings imply that by increasing the amount of the dataset while preserving the original label, data augmentation could be utilized to solve issues such as data scarcity and dataset imbalance. © 2023 Muhammad Amien Ibrahim, Samsul Arifin and Eko Setyo Purwanto. This open-access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license. All Rights Reserved.},
	author_keywords = {Data Augmentation; Dataset; Hate Speech Detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Aziz2023101,
	author = {Aziz, Abdul and Hossain, Md. Akram and Chy, Abu Nowshed},
	title = {CSECU-DSG@ Multimodal Hate Speech Event Detection 2023: Transformer-based Multimodal Hierarchical Fusion Model For Multimodal Hate Speech Detection},
	year = {2023},
	journal = {CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023},
	pages = {101 – 107},
	doi = {10.26615/978-954-452-089-2_014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180390323&doi=10.26615%2f978-954-452-089-2_014&partnerID=40&md5=5e1013b6ce256febd3ce2bcda65a3f8b},
	affiliations = {Department of Computer Science and Engineering, University of Chittagong, Chattogram, 4331, Bangladesh},
	abstract = {The emergence of social media and e-commerce platforms enabled the perpetrator to spread negativity and abuse individuals or organisations worldwide rapidly. It is critical to detect hate speech in both visual and textual content so that it may be moderated or excluded from online platforms to keep it sound and safe for users. However, multimodal hate speech detection is a complex and challenging task as people sarcastically present hate speech and different modalities i.e., image and text are involved in their content. This paper describes our participation in the CASE 2023 multimodal hate speech event detection task. In this task, the objective is to automatically detect hate speech and its target from the given text-embedded image. We proposed a transformer-based multimodal hierarchical fusion model to detect hate speech present in the visual content. We jointly fine-tune a language and a vision pre-trained transformer models to extract the visual-contextualized features representation of the text-embedded image. We concatenate these features and fed them to the multi-sample dropout strategy. Moreover, the contextual feature vector is fed into the BiLSTM module and the output of the BiLSTM module also passes into the multi-sample dropout. We employed arithmetic mean fusion to fuse all sample dropout outputs that predict the final label of our proposed method. Experimental results demonstrate that our proposed method obtains competitive performance and ranked 5th among the participants. © CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023.},
	keywords = {Natural language processing systems; Visual languages; Embedded images; Events detection; Fusion model; Hierarchical fusions; Multi-modal; Multi-samples; Social media commerces; Speech detection; Speech events; Visual content; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2023; Conference date: 7 September 2023; Conference code: 196554}
}

@CONFERENCE{Antypas2023231,
	author = {Antypas, Dimosthenis and Camacho-Collados, Jose},
	title = {Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical Evaluation},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {231 – 242},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174529804&partnerID=40&md5=b7b1f83b578631a341b3fb9902785a12},
	affiliations = {Cardiff NLP, School of Computer Science and Informatics, Cardiff University, United Kingdom},
	abstract = {The automatic detection of hate speech online is an active research area in NLP. Most of the studies to date are based on social media datasets that contribute to the creation of hate speech detection models trained on them. However, data creation processes contain their own biases, and models inherently learn from these dataset-specific biases. In this paper, we perform a large-scale cross-dataset comparison where we fine-tune language models on different hate speech detection datasets. This analysis shows how some datasets are more generalizable than others when used as training data. Crucially, our experiments show how combining hate speech detection datasets can contribute to the development of robust hate speech detection models. This robustness holds even when controlling by data size and compared with the best individual datasets. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Social networking (online); Speech recognition; Automatic Detection; Creation process; Data creation; Detection models; Empirical evaluations; Large-scales; Learn+; Research areas; Social media; Speech detection; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 7th Workshop on Online Abuse and Harms, WOAH 2023, co-located with ACL 2023; Conference date: 13 July 2023; Conference code: 193145}
}

@CONFERENCE{Ghosh2023368,
	author = {Ghosh, Koyel and Senapati, Apurbalal and Pal, Aditya Shankar},
	title = {Annihilate Hates (Task 4, HASOC 2023): Hate Speech Detection in Assamese, Bengali, and Bodo languages},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {368 – 382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180242511&partnerID=40&md5=a2ca3ee9fbfc6dd540fc63c6325d365e},
	affiliations = {Central Institute of Technology, Assam, Kokrajhar, India; Indian Statistical Institute, Kolkata, India},
	abstract = {In today’s world, social media can act as a tool for spreading hate towards a person or group based on their color, caste, sex, sexual orientation, political differences, etc. As social media continues to expand, the proliferation of hate speech is also surging at an alarming rate. Recently, Research on identifying hate speech in social media has gained significant prominence, with a specific need for investigations focused on languages other than English. The HASOC (Hate Speech and Offensive Content Identification) track intends to provide a platform for Hate Speech Detection since 2019 at FIRE (Forum for Information Retrieval Evaluation). HASOC 2023 is coordinating four tasks, with AH (Annihilate Hates, Task 4) being one of them. The AH task aims to develop and assess supervised machine learning systems on the three datasets. The three datasets presented for hate speech in three Indian languages (Assamese, Bengali, and Bodo) are collected from ™YouTube and ™Facebook comments. Each dataset is tagged with the binary classification (hate or non-hate) labels. In the Assamese language, 20 teams made 180 submissions, while 21 teams submitted 214 entries in the Bengali language, and for the Bodo language, 19 teams submitted a total of 175 submissions. The performance of the best classifiers for Assamese, Bengali, and Bodo are measured with the Macro F1 score of 0.73, 0.77, and 0.85, respectively. This article briefly summarizes the tasks, data development, and results. The variant of BERT architecture achieved the best performance in the task. However, other systems have also been successfully applied to the task. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Assamese; Bengali; BERT; Binary Classification; Bodo; Deep Learning; Hate Speech Detection; Machine Learning; Transformers},
	keywords = {Classification (of information); Learning systems; Social networking (online); Speech recognition; Supervised learning; Assamese; Bengalis; BERT; Binary classification; Bodo; Deep learning; Hate speech detection; Machine-learning; Speech detection; Transformer; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 15th Forum for Information Retrieval Evaluation, FIRE 2023; Conference date: 15 December 2023 through 18 December 2023; Conference code: 199455}
}

@CONFERENCE{Cam2023229,
	author = {Cam, Nur Bengisu and Ozgur, Arzucan},
	title = {Evaluation of ChatGPT and BERT-based Models for Turkish Hate Speech Detection},
	year = {2023},
	journal = {UBMK 2023 - Proceedings: 8th International Conference on Computer Science and Engineering},
	pages = {229 – 233},
	doi = {10.1109/UBMK59864.2023.10286663},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177606378&doi=10.1109%2fUBMK59864.2023.10286663&partnerID=40&md5=d1e52f8d5636f269585d0d6ce93c43d9},
	affiliations = {Bogazici University, Department of Computer Engineering, Istanbul, Turkey},
	abstract = {The popularity of large language models (LLMs) is increasing day by day. ChatGPT is one of the most popular LLMs. It is known for its success in many areas of natural language processing (NLP). Most importantly, we have yet to find zero-shot performance on various NLP tasks for low-level languages such as Turkish. Detection of hate speech is among the most important problems in NLP. With the growing social media usage, the prevalence of hate speech has also increased. However, automatic detection of hate speech in Turkish is rare compared to studies conducted in English. In our work, we analyzed the performance of ChatGPT and various fine-tuned BERT-based transformer models in detecting hate speech in Turkish. We found that ChatGPT provides similar results to the BERT-based models in detecting Turkish hate speech; thus, it is promising. In this study, a dataset consisting of 1000 Turkish tweets labeled 'hate,' 'aggressor,' and 'none' was used. © 2023 IEEE.},
	author_keywords = {BERT; ChatGPT; classification; hate speech; transformers; Turkish},
	keywords = {Speech recognition; Zero-shot learning; BERT; ChatGPT; Hate speech; Language model; Language processing; Natural languages; Performance; Speech detection; Transformer; Turkishs; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 8th International Conference on Computer Science and Engineering, UBMK 2023; Conference date: 13 September 2023 through 15 September 2023; Conference code: 193873}
}

@CONFERENCE{Sobhani20231121,
	author = {Sobhani, Nasim and Sengupta, Kinshuk and Delany, Sarah Jane},
	title = {Measuring Gender Bias in Natural Language Processing: Incorporating Gender-Neutral Linguistic Forms for Non-Binary Gender Identities in Abusive Speech Detection},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1121 – 1131},
	doi = {10.26615/978-954-452-092-2_119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179179997&doi=10.26615%2f978-954-452-092-2_119&partnerID=40&md5=81cc8c39912f5c4d7b6e8ca755c53ac7},
	affiliations = {SFI Centre for Research Training in Machine Learning, Technological University Dublin, Ireland; Microsoft, Dublin, Ireland},
	abstract = {Predictions from Machine Learning models can reflect bias in the data on which they are trained. Gender bias has been shown to be prevalent in Natural Language Processing models. The research into identifying and mitigating gender bias in these models predominantly considers gender as binary, male and female, neglecting the fluidity and continuity of gender as a variable. In this paper, we present an approach to evaluate gender bias in a prediction task, which recognises the non-binary nature of gender. We gender-neutralise a random subset of existing real-world hate speech data. We extend the existing template approach for measuring gender bias to include test examples that are genderneutral. Measuring the bias across a selection of hate speech datasets we show that the bias for the gender-neutral data is closer to that seen for test instances that identify as male than those that identify as female. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Speech recognition; Gender bias; Gender neutrals; Language processing; Machine learning models; Natural languages; Non-binary; Prediction tasks; Processing model; Random subsets; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 International Conference Recent Advances in Natural Language Processing: Large Language Models for Natural Language Processing, RANLP 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194755; All Open Access, Bronze Open Access}
}

@ARTICLE{Sheth2023559,
	author = {Sheth, Paaras and Kumarage, Tharindu and Moraffah, Raha and Chadha, Aman and Liu, Huan},
	title = {PEACE: Cross-Platform Hate Speech Detection - A Causality-Guided Framework},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14169 LNAI},
	pages = {559 – 575},
	doi = {10.1007/978-3-031-43412-9_33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174444261&doi=10.1007%2f978-3-031-43412-9_33&partnerID=40&md5=e1176c2a8c284904ae80dc02000ae098},
	affiliations = {Arizona State University, Tempe, AZ, United States; Stanford University, Stanford, CA, United States; Amazon Alexa AI, Sunnyvale, CA, United States},
	abstract = {Hate speech detection refers to the task of detecting hateful content that aims at denigrating an individual or a group based on their religion, gender, sexual orientation, or other characteristics. Due to the different policies of the platforms, different groups of people express hate in different ways. Furthermore, due to the lack of labeled data in some platforms it becomes challenging to build hate speech detection models. To this end, we revisit if we can learn a generalizable hate speech detection model for the cross platform setting, where we train the model on the data from one (source) platform and generalize the model across multiple (target) platforms. Existing generalization models rely on linguistic cues or auxiliary information, making them biased towards certain tags or certain kinds of words (e.g., abusive words) on the source platform and thus not applicable to the target platforms. Inspired by social and psychological theories, we endeavor to explore if there exist inherent causal cues that can be leveraged to learn generalizable representations for detecting hate speech across these distribution shifts. To this end, we propose a causality-guided framework, PEACE, that identifies and leverages two intrinsic causal cues omnipresent in hateful content: the overall sentiment and the aggression in the text. We conduct extensive experiments across multiple platforms (representing the distribution shift) showing if causal cues can help cross-platform generalization. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Causal Inference; Generalizability; Hate-Speech Detection},
	keywords = {Causal inferences; Cross-platform; Detection models; Generalisation; Generalizability; Group-based; Hate-speech detection; Learn+; Sexual orientations; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2023; Conference date: 18 September 2023 through 22 September 2023; Conference code: 301649}
}

@CONFERENCE{Macias2023,
	author = {Macias, Cesar and Soto, Miguel and Alcántara, Tania and Calvo, Hiram},
	title = {Impact of Text Preprocessing and Feature Selection on Hate Speech Detection in Online Messages Towards the LGBTQ+ Community in Mexico},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175335693&partnerID=40&md5=58e20c36718a70ea4e09afbc566031bf},
	affiliations = {Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico},
	abstract = {The prevalence of online hate speech targeting the LGBTQ+ community poses a significant challenge in maintaining a safe and inclusive digital environment. This paper deals with the importance of addressing this issue by proposing methods for detecting this offensive messages towards this community population in Mexican Spanish. The study explores a considerable variety of approaches to solve the task with classical machine learning algorithms and with different approaches for feature extraction. Additionally, text preprocessing techniques specific to Twitter data, and word embeddings are employed to enhance the performance of the models. Through experimentation and comparative analysis, we assess the effectiveness of these methods in identifying and classifying offensive messages. The findings of this research contribute to the development of robust tools for identifying and mitigating online hate speech, ultimately fostering a more inclusive and tolerant digital space for the LGBTQ+ community. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {gender identities; Hate speech; machine learning; natural language processing},
	keywords = {E-learning; Feature Selection; Natural language processing systems; Features selection; Gender identity; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Offensive messages; Text feature; Text preprocessing; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@ARTICLE{Gudumotu202327,
	author = {Gudumotu, Carol Eunice and Nukala, Sathvik Reddy and Reddy, Kartheeka and Konduri, Ashish and Gireesh, C.},
	title = {A Survey on Deep Learning Models to Detect Hate Speech and Bullying in Social Media},
	year = {2023},
	journal = {Intelligent Systems Reference Library},
	volume = {231},
	pages = {27 – 44},
	doi = {10.1007/978-3-031-12419-8_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172758802&doi=10.1007%2f978-3-031-12419-8_2&partnerID=40&md5=e8c6be73ee7f87df6fb11f5124c25b5a},
	affiliations = {Vasavi College of Engineering, Ibrahimbagh, Telangana, Hyderabad, India},
	abstract = {Any statement that is vituperative towards an individual or a group based on their traits like race, ethnicity, gender, sexual orientation, color, religion, nationality, or another attribute is described as hate speech. Hate speech and bullying, spreading uncontrolled might undermine society’s peace and harmony, becoming a societal issue. Especially when hate speech is used to hurt people or to hurt the respect of individuals, groups, or countries. This complicates the task since social media posts contain paralinguistic tools (e.g., emoticons and hash tags) and a lot of poor quality written text that does not follow grammatical norms. With the recent advancements in NLP, it is possible to analyze unstructured composite natural language content. The chapter first focuses on discussing various deep learning architectures such as DCNNs, Bi- LSTMs, Transformers and models like BERT and how they are applied in identifying hate speech in social media. The chapter examines the capacity of deep learning algorithms to capture hate speech on public media systematically. The chapter also reviews the accuracy of models on publicly available standard datasets. The findings of this study pave the way for more research into the discovery of spontaneous abusive conduct on social media in the future. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {BERT; Bullying; DCNNs; Deep learning; Hate speech detection; LSTMs; Natural language processing; Social media networks; Transfer learning},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Marrugo-Tobón2023,
	author = {Marrugo-Tobón, Duván Andres and Martinez-Santos, Juan Carlos and Puertas, Edwin},
	title = {Natural Language Content Evaluation System For Multiclass Detection of Hate Speech in Tweets Using Transformers},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175309460&partnerID=40&md5=5e7fd7958d9d3c6fcedfd36be3bc822a},
	affiliations = {Universidad Tecnologíca de Bolívar, Faculty of Engineering, Cartagena de Indias, 17013001, Colombia},
	abstract = {In natural language processing, accurate categorization of tweets, including detecting hate speech, plays a pivotal role in efficient information organization and analysis. This paper presents a Natural Language Contents Evaluation System specifically tailored for multi-class tweet categorization, focusing on hate speech detection. Our system enhances classification accuracy and efficiency by harnessing the power of Transformers, namely BERT and DistilBERT. By leveraging feature extraction techniques, we capture pertinent information from tweets, enabling practical analysis, categorization, and identification of hate speech instances. During training, we also tackle imbalanced corpora by employing techniques to ensure fair representation of different tweet categories, including hate speech. Our system achieves impressive accuracy through extensive training of 95%, showcasing Transformers' effectiveness in comprehending and categorizing tweets, including identifying hate speech. Furthermore, our system maintains a good accuracy during testing of 83%, highlighting the robustness and generalizability of the trained models for hate speech detection. This system contributes to advancing automated tweet categorization, specifically in hate speech detection, providing a reliable and efficient solution for organizing and analyzing diverse tweet datasets. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT; DistilBERT; Feature extraction; Hate speech detection; Natural language processing; Transformers; Tweet categorization},
	keywords = {Extraction; Natural language processing systems; Speech recognition; BERT; Distilbert; Features extraction; Hate speech detection; Language processing; Natural language processing; Natural languages; Speech detection; Transformer; Tweet categorization; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@CONFERENCE{Grotti2023,
	author = {Grotti, Leonardo and Quick, Patrick},
	title = {BERTicelli at HaSpeeDe 3: Fine-tuning and Cross-validating Large Language Models for Hate Speech Detection},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173559776&partnerID=40&md5=15dd6205e5162484927cbf9d838d71a1},
	affiliations = {Universiteit Antwerpen, Faculty of Arts, Prinsstraat 13, Antwerp, B-2000, Belgium; CLiPS Research Center, University of Antwerp, Belgium},
	abstract = {The present paper describes the results from the experiments carried out for the HaSpeeDe 3 shared task, an Italian-language Hate Speech (HS) detection task, at EVALITA 2023. Two BERT-based language models were selected: UmBERTo (cased) and Italian BERT (cased). For the Textual task, the models were fine-tuned and cross-validated across 5 folds. For the Contextual task, we adopted an ensemble approach: the additional features were added to the fine-tuned models through the GradientBoosterClassifier algorithm. The models perform better than the baselines (DummyClassifier and LogisticRegression) and above the average performance of participants in the shared task. While the addition of contextual features did not improve the performance of UmBERTo, it significantly bettered the results obtained with Italian BERT. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT-based language models; Contextual features; Fine-tuning; Hate Speech detection; Italian language},
	keywords = {Intelligent systems; Speech recognition; BERT-based language model; Contextual feature; Detection tasks; Ensemble approaches; Fine tuning; Hate speech detection; Italian language; Language model; Performance; Speech detection; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243}
}

@ARTICLE{Santhiya2023220,
	author = {Santhiya, S. and Jayadharshini, P. and Kogilavani, S.V.},
	title = {Transfer Learning Based Youtube Toxic Comments Identification},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1802 CCIS},
	pages = {220 – 230},
	doi = {10.1007/978-3-031-33231-9_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173560113&doi=10.1007%2f978-3-031-33231-9_15&partnerID=40&md5=37450a048ba9f072e182c8a70e5784f5},
	affiliations = {Department of Artificial Intelligence, Kongu Engineering College, Perundurai, 638060, India},
	abstract = {Online users are negatively affected by the spread of offensive content on social media sites. A fear, dislike, unease, or distrust of lesbian, gay, bisexual, or transgender persons is known as homophobia or transphobia. Homophobic/transphobic speech, which can be summed up as bigotry directed towards LGBT+ people, has grown to be a significant problem in recent years. The major social problem of online homopho- bia/transphobia threatens to eliminate equity, diversification, and acceptance while also making online places toxic and unwelcoming for LGBT+ people. It is found to be sensitive subject and untrained crowd sourced annotators have trouble in identifying homophobia due to cultural and other preconceptions. As a result, annotators had been educated and provided them with thorough annotation standards. 15,141 multilingual annotated comments make up the dataset. The proposed work identifies the best Machine Learning Classifier with BERT embedding model for the Code-Mixed Dravidian Languages in order to identify the toxic languages directed towards LGBTQ+ individuals. Adaboost classifier outperforms other three classifiers in terms of accuracy. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {BERT; Code-Mixed Language; Dravidian languages; Machine Learning Classifiers; Mixed-Feelings},
	keywords = {Adaptive boosting; Codes (symbols); BERT; Code-mixed language; Dravidian language; Learning classifiers; Machine learning classifier; Machine-learning; Mixed-feeling; Online users; Transfer learning; YouTube; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 1st International Conference on Speech and Language Technologies for Low-resource Languages, SPELLL 2022; Conference date: 23 November 2022 through 25 November 2022; Conference code: 295819}
}

@ARTICLE{Mishra2023201,
	author = {Mishra, Ritwik and Yadav, Ajeet and Shah, Rajiv Ratn and Kumaraguru, Ponnurangam},
	title = {Explaining Finetuned Transformers on Hate Speech Predictions Using Layerwise Relevance Propagation},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14418 LNCS},
	pages = {201 – 214},
	doi = {10.1007/978-3-031-49601-1_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180529564&doi=10.1007%2f978-3-031-49601-1_14&partnerID=40&md5=3f2d7cd1d5117ac6575e9e7b5c2fe225},
	affiliations = {Indraprastha Institute of Information Technology, Delhi, India; International Institute of Information Technology, Hyderabad, India},
	abstract = {Explainability of model predictions has become imperative for architectures that involve fine-tuning of a pretrained transformer encoder for a downstream task such as hate speech detection. In this work, we compare the explainability capabilities of three post-hoc methods on the HateXplain benchmark with different encoders. Our research is the first work to evaluate the effectiveness of Layerwise Relevance Propagation (LRP) as a post-hoc method for fine-tuned transformer architectures used in hate speech detection. The analysis revealed that LRP tends to perform less effectively than the other two methods across various explainability metrics. A random rationale generator was found to be providing a better interpretation than the LRP method. Upon further investigation, it was discovered that the LRP method assigns higher relevance scores to the initial tokens of the input text because fine-tuned encoders tend to concentrate the text information in the embeddings corresponding to early tokens of the text. Therefore, our findings demonstrate that LRP relevance values at the input of fine-tuning layers are not a good representative of the rationales behind the predicted score. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Explainability; Hate Speech; LIME; LRP; SHAP},
	keywords = {Signal encoding; Speech recognition; Down-stream; Explainability; Fine tuning; Hate speech; Layer-wise; Layerwise relevance propagation; Model prediction; Relevance propagation methods; SHAP; Speech detection; Lime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 11th International Conference on Big Data and Artificial Intelligence, BDA 2023; Conference date: 7 December 2023 through 9 December 2023; Conference code: 305369}
}

@CONFERENCE{Mitra2023,
	author = {Mitra, Sowmen and Kanungoe, Proma},
	title = {Detecting Public Hate Sentiment Using Transformers},
	year = {2023},
	journal = {2023 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023},
	doi = {10.1109/ICCCNT56998.2023.10308007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179848910&doi=10.1109%2fICCCNT56998.2023.10308007&partnerID=40&md5=d62cf73531a19ca9984620eaa6a2f73e},
	affiliations = {Hebei University of Technology, Department of Computer Science and Technology Department of Artifical Intelligence, Beijing, China; Vellore Institute of Technology, School of Information Technology and Engineering, Department of Information Technology, Vellore, India},
	abstract = {This research explores the application of deep learning techniques, specifically BERT and DistilBERT models, for detecting public hate sentiment in text data. Through a systematic analysis of the literature and a thorough understanding of the subject matter, we developed a groundbreaking method that leverages the power of these advanced models. Extensive experimentation and evaluation were conducted using a carefully curated dataset, employing techniques such as tokenization, padding, and truncating for preprocessing. The results demonstrate the efficacy of our approach, achieving high accuracy and precision in identifying and classifying hate sentiment. This research contributes to the field of natural language processing and provides valuable insights for effectively addressing and mitigating hate speech in online platforms. © 2023 IEEE.},
	author_keywords = {BERT; Deep learning; DistilBERT; Hate sentiment; Natural language processing; Text classification},
	keywords = {Classification (of information); Learning systems; Natural language processing systems; BERT; Deep learning; Distilbert; Hate sentiment; Language processing; Learning techniques; Natural language processing; Natural languages; Text classification; Text data; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023; Conference date: 6 July 2023 through 8 July 2023; Conference code: 194774}
}

@CONFERENCE{Goldzycher2023187,
	author = {Goldzycher, Janis and Preisig, Moritz and Amrhein, Chantal and Schneider, Gerold},
	title = {Evaluating the Effectiveness of Natural Language Inference for Hate Speech Detection in Languages with Limited Labeled Data},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {187 – 201},
	doi = {10.18653/v1/2023.woah-1.19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174546535&doi=10.18653%2fv1%2f2023.woah-1.19&partnerID=40&md5=36939de5ef81cf7649cc5e120c4968fd},
	affiliations = {Department of Computational Linguistics, University of Zurich, Switzerland},
	abstract = {Most research on hate speech detection has focused on English where a sizeable amount of labeled training data is available. However, to expand hate speech detection into more languages, approaches that require minimal training data are needed. In this paper, we test whether natural language inference (NLI) models which perform well in zero- and few-shot settings can benefit hate speech detection performance in scenarios where only a limited amount of labeled data is available in the target language. Our evaluation on five languages demonstrates large performance improvements of NLI fine-tuning over direct fine-tuning in the target language. However, the effectiveness of previous work that proposed intermediate finetuning on English data is hard to match. Only in settings where the English training data does not match the test domain, can our customised NLI-formulation outperform intermediate finetuning on English. Based on our extensive experiments, we propose a set of recommendations for hate speech detection in languages where minimal labeled training data is available. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Fine tuning; Inference models; Labeled data; Labeled training data; Language inference; Minimal training; Natural languages; Speech detection; Target language; Training data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th Workshop on Online Abuse and Harms, WOAH 2023, co-located with ACL 2023; Conference date: 13 July 2023; Conference code: 193145; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Jonathan2023197,
	author = {Jonathan, Vincent Williams and Setiawan, Erwin Budi},
	title = {Feature Expansion Using GloVe for Hate Speech Detection using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) Method in Twitter},
	year = {2023},
	journal = {2023 International Conference on Data Science and Its Applications, ICoDSA 2023},
	pages = {197 – 202},
	doi = {10.1109/ICoDSA58501.2023.10277204},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175611331&doi=10.1109%2fICoDSA58501.2023.10277204&partnerID=40&md5=c3897d4f3e27f05320aa1f7bd45893dc},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {In this day and age, people have easy access to social media, allowing them the freedom to express their opinions. Consequently, hate speech against individuals or groups can be easily found on social media platforms. This paper proposes a system to classify hate speech in Indonesian language tweets. Three distinct deep learning techniques were employed: Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Hybrid RNN-CNN. The dataset used for training and testing was collected from Twitter. The collected tweets were categorized into hate speech and non-hate speech. Feature extraction and expansion were performed using Term Frequency-Inverse Document Frequency (TFIDF) and Global Vectors (GloVe) methods. Several scenarios were considered to compare the effectiveness of various approaches and determine the model with the highest accuracy. Among these approaches, the RNN method with feature expansion on the top 5-word similarity achieved the highest accuracy rate of 91.34%. Following closely, the Hybrid RNN-CNN method with feature expansion on the top 5-word similarity obtained an accuracy of 90.69%, while the CNN method with feature expansion on the top 5-word similarity yielded an accuracy of 90.64%. Notably, all three highest models utilized a corpus constructed by combining the tweet and news datasets.  © 2023 IEEE.},
	author_keywords = {cnn; glove; hate speech; hybrid; rnn},
	keywords = {Convolution; Convolutional neural networks; Feature extraction; Learning systems; Recurrent neural networks; Social networking (online); Statistical tests; Text processing; Cnn; Convolutional neural network; Glove; Hate speech; High-accuracy; Hybrid; Neural network method; Rnn; Speech detection; Word similarity; Inverse problems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Data Science and Its Applications, ICoDSA 2023; Conference date: 9 August 2023 through 10 August 2023; Conference code: 193551}
}

@ARTICLE{Karim2023293,
	author = {Karim, Md. Rezaul and Dey, Sumon Kanti and Islam, Tanhim and Shajalal, Md and Chakravarthi, Bharathi Raja},
	title = {Multimodal Hate Speech Detection from Bengali Memes and Texts},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1802 CCIS},
	pages = {293 – 308},
	doi = {10.1007/978-3-031-33231-9_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173566054&doi=10.1007%2f978-3-031-33231-9_21&partnerID=40&md5=9b253a56ebf11f298ffe6c4715261930},
	affiliations = {Fraunhofer Institute for Applied Information Technology FIT, Sankt Augustin, Germany; RWTH Aachen University, Aachen, Germany; Noakhali Science and Technology University, Noakhali, Bangladesh; University of Siegen, Siegen, Germany; University of Galway, Galway, Ireland},
	abstract = {Numerous machine learning (ML) and deep learning (DL)-based approaches have been proposed to utilize textual data from social media for anti-social behavior analysis like cyberbullying, fake news detection, and identification of hate speech mainly for highly-resourced languages such as English. However, despite of having a lot of diversity and millions of native speakers, some languages like Bengali are under-resourced, which is due to lack of computational resources for natural language processing (NLP). Similar to other languages, Bengali social media contents also include images along with texts (e.g., multimodal memes are posted by embedding short texts into images on Facebook). Therefore, only the textual data is not enough to judge them since images might give extra context to make a proper judgement. This paper is about hate speech detection from multimodal Bengali memes and texts. We prepared the only multimodal hate speech dataset for-a-kind of problem for Bengali, which we use to train state-of-the-art neural architectures (e.g., Bi-LSTM/Conv-LSTM with word embeddings, ConvNets + pre-trained language models, e.g., monolingual Bangla BERT, multilingual BERT-cased/uncased, and XLM-RoBERTa) to jointly analyze textual and visual information for hate speech detection. Conv-LSTM and XLM-RoBERTa models performed best for texts, yielding F1 scores of 0.78 and 0.82, respectively. As of memes, ResNet-152 and DenseNet-161 models yield F1 scores of 0.78 and 0.79, respectively. As of multimodal fusion, XLM-RoBERTa + DenseNet-161 performed the best, yielding an F1 score of 0.83. Our study suggest that text modality is most useful for hate speech detection, while memes are moderately useful. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Bengali; Hate speech detection; Multimodal memes; Transformer language models; Under-resourced language; Word embeddings},
	keywords = {Computational linguistics; Fake detection; Long short-term memory; Natural language processing systems; Social networking (online); Speech recognition; Visual languages; Bengalis; Embeddings; Hate speech detection; Language model; Multi-modal; Multimodal meme; Speech detection; Transformer language model; Under-resourced languages; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 1st International Conference on Speech and Language Technologies for Low-resource Languages, SPELLL 2022; Conference date: 23 November 2022 through 25 November 2022; Conference code: 295819}
}

@ARTICLE{Nouas202357,
	author = {Nouas, Sihem and Boumahdi, Fatima and Madani, Amina and Berrhail, Fouaz},
	title = {Cyberbullying: A BERT Bi-LSTM Solution for Hate Speech Detection},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {760 LNNS},
	pages = {57 – 65},
	doi = {10.1007/978-3-031-40598-3_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172100209&doi=10.1007%2f978-3-031-40598-3_7&partnerID=40&md5=2ec71ce4a1c3a41b44636334828a74ee},
	affiliations = {University of Saad Dahleb, Blida, Somaa, Algeria},
	abstract = {With the growth of data on social networks, the semantic analysis of shared text has become essential for decision-making and knowledge extraction. It is also the case for the detection of abusive and hateful content. Most of the work done in this field so far proposed classical machine learning solutions. But recently, models based on deep learning have also been applied. In this paper, we propose a neural network model for hate speech classification using two imbalance datasets that were imbalanced, containing approximately 25 thousand and 10 thousand annotated text samples. The proposed approach is evaluated using the standard evaluation metrics, such as Accuracy and F-score. We compared our approach to the baseline results and it showed satisfying results. Moreover, our approach was able to detect more instances of the minority class compared to the baseline results. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {BERT; deep learning; hate speech; supervised learning},
	keywords = {Classification (of information); Decision making; Learning systems; Long short-term memory; Semantics; Text processing; Baseline results; BERT; Cyber bullying; Decisions makings; Deep learning; Hate speech; Knowledge extraction; Machine-learning; Semantic analysis; Speech detection; Neural network models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Proceedings of the 2nd International Conference on Applied Cyber Security, ACS 2023; Conference date: 29 April 2023 through 29 April 2023; Conference code: 300499}
}

@CONFERENCE{Faruqe2023,
	author = {Faruqe, Omar and Jahan, Mubassir and Faisal, Md. and Islam, Md. Shahidul and Khan, Riasat},
	title = {Bangla Hate Speech Detection System Using Transformer-Based NLP and Deep Learning Techniques},
	year = {2023},
	journal = {2023 3rd Asian Conference on Innovation in Technology, ASIANCON 2023},
	doi = {10.1109/ASIANCON58793.2023.10269919},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175614325&doi=10.1109%2fASIANCON58793.2023.10269919&partnerID=40&md5=4d7338d8d0ed017493cdb69ee45199e9},
	affiliations = {North South University, Electrical and Computer Engineering, Dhaka, Bangladesh},
	abstract = {Hate speech is a form of discriminatory communication disrupts community standards and breaches the line of self-limitation, causing harm to others and occasionally leading to cyberbullying. Hate speech spreads hatred toward a person or a particular group based on various characteristics, e.g., race, religion, gender, and so on is referred to as bias. The offensive speech detection system is the frontier where researchers are battling to provide secure internet using natural language processing and machine learning approaches. In this research, we strive to create an automatic Bangla hate speech detection system using natural language processing (NLP) and deep learning approaches. We utilized our custom dataset and some labeled data from an open-access repository in this work. 4,978 data from both sources were merged and implemented in our proposed model. Different data preprocessing techniques, tokenization, stemming, and removal of stopwords have been applied. Four deep learning and NLP-based classifiers have been applied to detect Bangla hate speech. Google API has been employed to convert text from Bangla to English. The emojis were removed from the datasets and the data were translated into Bangla. The GRU and Attention techniques performed best with 98.87% and 98% accuracies, respectively. © 2023 IEEE.},
	author_keywords = {Attention Model; BERT Fine Tuning; Bi-LSTM; cross-validation; GRU; hate speech detection; transformer; word embedding},
	keywords = {Long short-term memory; Natural language processing systems; Speech communication; Speech recognition; Attention model; BERT fine tuning; Bi-LSTM; Cross validation; Embeddings; Fine tuning; GRU; Hate speech detection; Speech detection; Transformer; Word embedding; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd IEEE Asian Conference on Innovation in Technology, ASIANCON 2023; Conference date: 25 August 2023 through 27 August 2023; Conference code: 193316}
}

@ARTICLE{Maste2023133,
	author = {Maste, Swati and Prabhu, Pallavi and Shetty, Chinmayi and Sharma, Richa and Arya, Arti},
	title = {Multi-step Online Hate Speech Detection and Classification Using Sentiment and Sarcasm Features},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {730 LNNS},
	pages = {133 – 145},
	doi = {10.1007/978-981-99-3963-3_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174445366&doi=10.1007%2f978-981-99-3963-3_11&partnerID=40&md5=f3cc63f059dd679e1dde52b54a91d706},
	affiliations = {PES University, Bengaluru, 560100, India},
	abstract = {With the increased popularity of different platforms like Instagram, Facebook, and Twitter, many people use these platforms to freely express their opinions. These platforms sometimes act as a bane for society as they have led to the rapid propagation of hatred. Therefore, Hate Speech Detection and Classification is a crucial task for moderators of these platforms, so that appropriate actions are taken against the offenders and make the Internet a safe place for all humans. This work proposes a two-step novel approach that detects online content as “Hate” or “Non-hate” speech in the first step and then subclassifies hate speech as “Racist”, “Sexist” or “Neither”. For rigorous testing of the trained models, a testing dataset was created by scrapping tweets about the controversial topic “#NupurSharma” from Twitter. Machine learning and Deep learning models with strong features like Sarcasm, Sentiment, TF-IDF and Pattern features were trained for this classification task and outperformed the existing works with an accuracy of 94.1% and 91.27% for primary and subclass classification tasks, respectively. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Feature extraction; Hate speech detection (HSD); Machine learning (ML); Natural language processing; Random forest (RF); XGBoost},
	keywords = {Classification (of information); Deep learning; E-learning; Forestry; Learning algorithms; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Statistical tests; Features extraction; Hate speech detection; Language processing; Machine learning; Machine-learning; Natural language processing; Natural languages; Random forest; Random forests; Speech detection; Xgboost; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on “Emerging Trends and Technologies on Intelligent Systems” (ETTIS-2023); Conference date: 23 February 2023 through 24 February 2023; Conference code: 301479}
}

@CONFERENCE{Preetham2023805,
	author = {Preetham, Jaladi and Anitha, J.},
	title = {Offensive Language Detection in Social Media Using Ensemble Techniques},
	year = {2023},
	journal = {Proceedings of the International Conference on Circuit Power and Computing Technologies, ICCPCT 2023},
	pages = {805 – 808},
	doi = {10.1109/ICCPCT58313.2023.10245673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173840757&doi=10.1109%2fICCPCT58313.2023.10245673&partnerID=40&md5=274ad72dd8322b47e438980c97574550},
	affiliations = {Karunya Institute of Technology and Sciences, Dept. of CSE, Coimbatore, India},
	abstract = {Hate speech and offensive content are deliberate attacks directed at a group or society based on their characteristics like religion, gender, or race, and pose a threat to society. The usage of Facebook and other social media platforms, WhatsApp, and Instagram led to an increase in this type of content. Detecting and preventing the spread of such content is crucial to avoid negative impacts on society. However, manually analyzing these vast and continuously rising texts is challenging as well as tedious. This work covers the usage of machine learning techniques to recognize offensive speech on social media. A comparative analysis of several popular algorithms, including Naive Bayes (NB), Support Vector Machines (SVM), Extreme Gradient Boosting (XGBoost), K Nearest Neighbor (KNN), Decision Tree, and Random Forest has been performed, and evaluate their performance using recall, precision, F1- score, and accuracy metrics. The experiments on a dataset of Twitter posts containing hate speech show that Random Forest is the most effective algorithm, achieving an accuracy of 97%. The effectiveness of the model has also been examined in relation to several feature extraction methodologies, such as bag-of-words and TF-IDF(term frequency-inverse document frequency). The obtained results show the effectiveness of Random Forest combined with TF-IDF as the best approach in detecting vile language in social media. © 2023 IEEE.},
	author_keywords = {Machine Learning; Offensive Speech Detection; Random Forest; Sentiment Analysis; Social Media; TF-IDF},
	keywords = {Adaptive boosting; Decision trees; Information retrieval; Learning systems; Nearest neighbor search; Random forests; Social networking (online); Speech recognition; Support vector machines; Ensemble techniques; Language detection; Machine-learning; Offensive languages; Offensive speech detection; Random forests; Sentiment analysis; Social media; Speech detection; Term frequencyinverse document frequency (TF-IDF); Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Circuit Power and Computing Technologies, ICCPCT 2023; Conference date: 10 August 2023 through 11 August 2023; Conference code: 192821}
}

@CONFERENCE{Rosauro2023,
	author = {Rosauro, Carlos Fernández and Cuadros, Montse},
	title = {Hate Speech Detection Against the Mexican Spanish LGBTQ+ Community Using BERT-based Transformers},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175321227&partnerID=40&md5=a19c2dd5cbea9950ac9ab458d3c7ae63},
	affiliations = {Universitat Oberta de Catalunya, Barcelona, Spain; SNLT group at Vicomtech Foundation, Basque Research and Technology Alliance (BRTA), Mikeletegi Pasealekua 57, Donostia/San-Sebastián, 20009, Spain},
	abstract = {In this paper we present our approach to the HOMO-MEX task: Hate speech detection in Online Messages directed tOwards the MEXican spanish speaking LGBTQ+ population. We present our results for both Track 1: Hate speech detection track, in which the aim is to indicate whether a set of tweets exhibit LGBT+phobic content or not, and Track 2: Fine-grained hate speech detection track (Multi-labeled), in which the tweets labeled as LGBT+phobic need to be classified according to the type of LGBT+phobia they show. We utilized both classical machine learning and Transformer-based deep learning models focused on BERT-like architectures to tackle both tracks. The model that achieved the best results in terms of F1-Score (0.84 in Track 1) and macro-average F1-Score (0.68 in Track 2) was robertuito-base-uncased. With this model our team reached the 2nd position in both tracks. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Deep Learning; Hate Speech; NLP; Text Classification},
	keywords = {Classification (of information); Deep learning; Text processing; Classifieds; Deep learning; F1 scores; Fine grained; Hate speech; Learning models; Machine-learning; Speech detection; Text classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@CONFERENCE{Castillo-López20231,
	author = {Castillo-López, Galo and Riabi, Arij and Seddah, Djamé},
	title = {Analyzing Zero-Shot transfer Scenarios across Spanish variants for Hate Speech Detection},
	year = {2023},
	journal = {ACL 2023 - 10th Workshop on NLP for Similar Languages, Varieties and Dialects, VarDial 2023 - Proceedings of the Workshop},
	pages = {1 – 13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175953036&partnerID=40&md5=da4d696d04cf2adbe3348d77418e537f},
	affiliations = {INRIA Paris, France; Université Paris-Saclay, France; Sorbonne Université, France},
	abstract = {Hate speech detection in online platforms has been widely studied in the past. Most of these works were conducted in English and a few rich-resource languages. Recent approaches tailored for low-resource languages have explored the interests of zero-shot cross-lingual transfer learning models in resource-scarce scenarios. However, languages variations between geolects such as American English and British English, Latin-American Spanish, and European Spanish is still a problem for NLP models that often relies on (latent) lexical information for their classification tasks. More importantly, the cultural aspect, crucial for hate speech detection, is often overlooked. In this work, we present the results of a thorough analysis of hate speech detection models performance on different variants of Spanish, including a new hate speech toward immigrants Twitter data set we built to cover these variants. Using mBERT and Beto, a monolingual Spanish Bert-based language model, as the basis of our transfer learning architecture, our results indicate that hate speech detection models for a given Spanish variant are affected when different variations of such language are not considered. Hate speech expressions could vary from region to region where the same language is spoken. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Learning systems; Speech recognition; Transfer learning; Zero-shot learning; American English; British English; Cross-lingual; Detection models; Language variation; Learning models; Low resource languages; Online platforms; Speech detection; Transfer learning; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 10th Workshop on NLP for Similar Languages, Varieties and Dialects, VarDial 2023; Conference date: 5 May 2023; Conference code: 192863}
}

@ARTICLE{Batarfi2023187,
	author = {Batarfi, Hanan A. and Alsaedi, Olaa A. and Wali, Arwa M. and Jamal, Amani T.},
	title = {Impact of Data Augmentation on Hate Speech Detection},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1876 CCIS},
	pages = {187 – 199},
	doi = {10.1007/978-3-031-40852-6_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172277560&doi=10.1007%2f978-3-031-40852-6_10&partnerID=40&md5=0db8645190530a1ca2ec0a5f32ca8bde},
	affiliations = {King Abdulaziz University, Jeddah, Saudi Arabia},
	abstract = {With the increase of social media platforms such as Facebook, Twitter, and YouTube, individuals from diverse cultures and societal backgrounds can communicate and express their viewpoints on several aspects of daily life. However, due to the differences in these cultures, along with the freedom of expression, hateful and offensive speech has increased and spread on these platforms. The detection of hate speech has significantly increased the interest of researchers in natural language processing (NLP). The OSACT5 shared task provides a new dataset that aims to detect the offensive language in addition to identifying the type of hate speech on Arabic social media. However, the available dataset is unbalanced, which leads to low performance, especially in the F1 score. Therefore, in this paper, we focused on overcoming such a problem by augmenting the text data. We fine-tuned and evaluated various pre-trained deep learning models in addition to augmenting the data to achieve the best performance. We observed that data augmentation increases the F1 score. After fine-tuning the QARiB model and augmenting the data we achieved the best F1 score of 0.49. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Class imbalance; Data augmentation; Hate speech detection; Text classification},
	keywords = {Deep learning; Natural language processing systems; Social networking (online); Speech recognition; Text processing; Class imbalance; Data augmentation; F1 scores; Facebook; Hate speech detection; Performance; Social media platforms; Speech detection; Text classification; YouTube; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Proceedings of the 23rd International Conference on Innovations for Community Services, I4CS 2023; Conference date: 11 September 2023 through 13 September 2023; Conference code: 300189}
}

@CONFERENCE{Kashif202384,
	author = {Kashif, Mohammad and Zohair, Mohammad and Ali, Saquib},
	title = {Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal Hate Speech Detection using Fused Ensemble Approach},
	year = {2023},
	journal = {CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023},
	pages = {84 – 91},
	doi = {10.26615/978-954-452-089-2_012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180398564&doi=10.26615%2f978-954-452-089-2_012&partnerID=40&md5=7938f7e51e8ce84fc2e5322e07d7985e},
	affiliations = {Jamia Millia Islamia, New Delhi, India},
	abstract = {With a surge in the usage of social media postings to express opinions, emotions, and ideologies, there has been a significant shift towards the calibration of social media as a rapid medium of conveying viewpoints and outlooks over the globe. Concurrently, the emergence of a multitude of conflicts between two entities has given rise to a stream of social media content containing propaganda, hate speech, and inconsiderate views. Thus, the issue of monitoring social media postings is rising swiftly, attracting major attention from those willing to solve such problems. One such problem is Hate Speech detection. To mitigate this problem, we present our novel ensemble learning approach for detecting hate speech, by classifying text-embedded images into two labels, namely "Hate Speech" and "No Hate Speech". We have incorporated state-of-art models including InceptionV3, BERT, and XLNet. Our proposed ensemble model yielded promising results with 75.21 and 74.96 as accuracy and F-1 score (respectively). We also present an empirical evaluation of the text-embedded images to elaborate on how well the model was able to predict and classify. We release our codebase here https://github.com/M0hammad-Kashif/MultiModalHateSpeech. © CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023.},
	keywords = {Conveying; Natural language processing systems; Petroleum reservoir evaluation; Social networking (online); ART model; Embedded images; Ensemble approaches; Ensemble learning approach; Events detection; Media content; Multi-modal; Social media; Speech detection; Speech events; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2023; Conference date: 7 September 2023; Conference code: 196554}
}

@CONFERENCE{Ayele202341,
	author = {Ayele, Abinew Ali and Dinter, Skadi and Yimam, Seid Muhie and Biemann, Chris},
	title = {Multilingual Racial Hate Speech Detection Using Transfer Learning},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {41 – 48},
	doi = {10.26615/978-954-452-092-2_005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179180409&doi=10.26615%2f978-954-452-092-2_005&partnerID=40&md5=ef1810f78fcf6e596b8f387071899c7e},
	affiliations = {Language Technology Group, Universität Hamburg, Germany; Faculty of Computing, BiT, Bahir Dar University, Ethiopia},
	abstract = {The rise of social media eases the spread of hateful content, especially racist content with severe consequences. In this paper, we analyze the tweets targeting the death of George Floyd in May 2020 as the event accelerated debates on racism globally. We focus on the tweets published in French for a period of one month since the death of Floyd. Using the Yandex Toloka platform, we annotate the tweets into categories as hate, offensive or normal. Tweets that are offensive or hateful are further annotated as racial or non-racial. We build French hate speech detection models based on the multilingual BERT and CamemBERT and apply transfer learning by fine-tuning the HateXplain model. We compare different approaches to resolve annotation ties and find that the detection model based on CamemBERT yields the best results in our experiments. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Transfer learning; Detection models; Fine tuning; Model-based OPC; Social media; Speech detection; Transfer learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 International Conference Recent Advances in Natural Language Processing: Large Language Models for Natural Language Processing, RANLP 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194755; All Open Access, Bronze Open Access}
}

@CONFERENCE{Gallardo2023184,
	author = {Gallardo, Jeschelle N. and Gloria, Ernest Dylan G. and Landicho, Natalie Rose P. and Sueno, Hajah T.},
	title = {Detection of Hate Speech Using Improved Deep Learning Techniques},
	year = {2023},
	journal = {2023 10th International Conference on Information Technology, Computer, and Electrical Engineering, ICITACEE 2023},
	pages = {184 – 189},
	doi = {10.1109/ICITACEE58587.2023.10277103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175648928&doi=10.1109%2fICITACEE58587.2023.10277103&partnerID=40&md5=533e974dad7db7b4ebc6a43cad9c9279},
	affiliations = {Notre Dame of Marbel University, College of Engineering and Technology, Koronadal City, Philippines; Notre Dame of Marbel University, College of Engineering and Technology, Koronadal City, South Cotabato, Philippines},
	abstract = {LSTM was introduced to solve the problem that RNNs faced, such as suffering from the vanishing gradient problem. Researchers have improved the LSTM model using various techniques. However, most improved models are still based on LSTM's network structure, which needs to address the weight parameters falling into local extrema. Moreover, they can suffer from poor learning efficiency and gradient disappearance. The paper presented an advanced deep learning methodology aimed at significantly improving the detection of hate speech using LSTM supported by feature extraction, feature selection, and RNN. Our model exhibits outstanding performance, achieving high precision, recall, F1-score, and accuracy at 97%. In comparison, the other models, such as RNN, achieved 56%, LSTM+RNN achieved 80%, By employing RNN with feature extraction and feature selection, an accuracy of 96% was achieved. Likewise, LSTM with feature extraction and feature selection demonstrated comparable results, reaching 96% accuracy across all performance metrics. This shows that the proposed model surpassed the Plain LSTM model employing deep learning techniques.  © 2023 IEEE.},
	author_keywords = {Hate Speech; Long-Short-Term Memory; Natural Language Processing; Recurrent Neural Network},
	keywords = {Extraction; Feature extraction; Learning algorithms; Learning systems; Natural language processing systems; Speech recognition; Feature extraction/selection; Features selection; Hate speech; Language processing; Learning techniques; Natural language processing; Natural languages; Network structures; Vanishing gradient; Weight parameters; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 10th International Conference on Information Technology, Computer, and Electrical Engineering, ICITACEE 2023; Conference date: 31 August 2023 through 1 September 2023; Conference code: 193550}
}

@ARTICLE{Kapil2023101460,
	author = {Kapil, Prashant and Kumari, Gitanjali and Ekbal, Asif and Pal, Santanu and Chatterjee, Arindam and Vinutha, B.N.},
	title = {HHSD: Hindi Hate Speech Detection Leveraging Multi-Task Learning},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {101460 – 101473},
	doi = {10.1109/ACCESS.2023.3312993},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171567560&doi=10.1109%2fACCESS.2023.3312993&partnerID=40&md5=e0fb03fcd1a4df964277f439b6b75ebc},
	affiliations = {Indian Institute of Technology Patna, Department of Computer Science and Engineering, Patna, 800013, India; Wipro AI, Bengaluru, 560035, India},
	abstract = {Hate speech is now a frequent occurrence on social media. Recently, the majority of study was devoted to identifying hate speech in languages with abundant resources (e.g., English). However, relatively few works are developed for languages with limited resources (e.g., Hindi, the third most widely used language on earth). In this study, Hindi Hate Speech Dataset (HHSD) is created following a novel hierarchical fine-grained four-layer annotation approach. The top layer separates the posts into hateful and non-hateful categories. The second layer further categorises hateful posts into explicit hateful and implicit hateful. The third layer is the multilabel tagging of the post into topics, such as political, religion, racism, or sexism. The fourth layer involves the identification of the targeted named entity, either explicitly or implicitly. Additionally, a thorough evaluation of the data annotation schema for trustworthy annotation is provided. The HHSD data is the largest multi-layer annotated corpora in Hindi compared with the existing multi-layer annotated data. Experiments on the dataset using the transformer-based approaches in single-task learning (STL) attain encouraging performances in accuracy and weighted-f1 score. The experiment leveraged multi-task learning (MTL) by including multiple related hate speech detection tasks from high-resource English and languages from the same linguistic family such as Urdu and Bangla with a transformer encoder as the shared layers to obtain a significant increment of 5.31% and 5.35% over STL in accuracy and weighted-f1 for layer A, 8.20%, and 22.83% for layer B. The MTL surpasses STL by 8.98% and 4.07% in exact match and hamming loss for layer C.  © 2013 IEEE.},
	author_keywords = {accuracy; F1 score; multi-task learning; Shared layers; Transformers},
	keywords = {Linearization; Speech recognition; Abundant resources; Accuracy; F1 scores; Fine grained; Multi-layers; Multitask learning; Shared layer; Single task learning; Social media; Transformer; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Guo202327,
	author = {Guo, Tengda and Lin, Lianxin and Liu, Hang and Zheng, Chengping and Tu, Zhijian and Wang, Haizhou},
	title = {Implicit Offensive Speech Detection Based on Multi-feature Fusion},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14118 LNAI},
	pages = {27 – 38},
	doi = {10.1007/978-3-031-40286-9_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173059177&doi=10.1007%2f978-3-031-40286-9_3&partnerID=40&md5=16af460032d037952eef7167a8097583},
	affiliations = {School of Cyber Science and Engineering, Sichuan University, Chengdu, 610207, China},
	abstract = {As social media platforms become increasingly strict in censorship of user posts, aggressive and insulting language has gradually shifted to implicit expressions using homophones, metaphors, and other forms of camouflage. This not only intensifies the satirical attacks of negative posts but also leads to a significant decrease in the effectiveness of models designed to detect offensive speech. This paper aims to achieve high accurate detection of implicit offensive speech. We conducted targeted investigations on the speech characteristics on Weibo, which is one of the largest social media platform in China. Based on the identified features of implicit offensive speech, including semantic, emotional, metaphorical, and fallacy characteristics, this paper constructs a BERT-based Multi-Task learning model named BMA (BERT-Mate-Ambiguity) to accurately detect the implicit offensive speech in the real world. Additionally, this paper establishes a dataset based on posts of Weibo that contain implicit offensive speech and conducts various comparative, robustness, and ablation experiments. The effectiveness of the model is demonstrated by comparing it to existing models that perform well in this field. Finally, this paper discusses some of its limitations and proposes future research work. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Classification; Deep Learning; Implicit Offensive Speech; Natural Language Processing; Weibo},
	keywords = {Deep learning; Feature extraction; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Deep learning; Implicit offensive speech; Language processing; Multi-feature fusion; Multitask learning; Natural language processing; Natural languages; Social media platforms; Speech detection; Weibo; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Knowledge Science, Engineering and Management - 16th International Conference, KSEM 2023, Proceedings; Conference date: 16 August 2023 through 18 August 2023; Conference code: 299379}
}

@CONFERENCE{Yigezu2023,
	author = {Yigezu, Mesay Gemeda and Kolesnikova, Olga and Sidorov, Grigori and Gelbukh, Alexander},
	title = {Transformer-Based Hate Speech Detection for Multi-Class and Multi-Label Classification},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175324972&partnerID=40&md5=04d5cf743f5611995c7bf552f8c5e234},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), NLP Lab, Mexico City, Mexico},
	abstract = {This paper focuses on identifying hate speech directed towards the LGBT+ community. The study involves two tasks, track 1 and track 2, which use a multi-class approach to identify LGBT+phobic content in tweets and detect fine-grained multi-label hate speech indicating different types of LGBT+phobias, respectively. The study employs pre-processing and oversampling techniques to address data imbalance problems. The results show that transformer-based approaches, such as BERT and RoBERTa, are effective in identifying hate speech directed at the LGBT+ community. The experiment performance is evaluated by the macro-average F1 measure. The study highlights the challenges associated with data imbalance, order bias, and limited training data, which can lead to bias in model performance and affect its ability to learn the underlying patterns in the data. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT; Hate speech; Multi-class; Multi-labeled; Roberta; Social media; Transformer-based},
	keywords = {Social networking (online); Speech recognition; BERT; Class labels; Data imbalance; Hate speech; Multi-class; Multi-labeled; Robertum; Social media; Speech detection; Transformer-based; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@CONFERENCE{Weitzel2023,
	author = {Weitzel, Leila and Daroz, Thalessa Hungerbuhler and Cunha, Luan Pereira and Helde, Rafael Von and Morais, Lucas Mendonca De},
	title = {Investigating Deep Learning Approaches for Hate Speech Detection in Social Media : Portuguese-BR tweets},
	year = {2023},
	journal = {Iberian Conference on Information Systems and Technologies, CISTI},
	volume = {2023-June},
	doi = {10.23919/CISTI58278.2023.10211751},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169786312&doi=10.23919%2fCISTI58278.2023.10211751&partnerID=40&md5=32585ec73e3f653f4337b0c613078e06},
	affiliations = {Universidade Federal Fluminense (UFF), Dept. Computer Science, Rio das Ostras, Brazil},
	abstract = {Social media constitutes a very open social network space, which lacks of barriers to access. It has become a way for some people to vent anger, fear, happiness, hate, hope, love and sadness without feeling self-conscious. Hate speech and offensive language published and diffused via online environments have the potential to cause harm and suffering to individuals and lead to social disorder beyond virtual space. Over the last decade, machine learning and natural language processing approaches have been developed to detect harmful user content on social media. This work aims to analyze and detect hate speech, on Portuguese language, during the2018 Brazilian presidential electioneering period. In order to achieve this goal, we experiment different configurations of Deep Learning networks, hyperparameter and features. As a result, the paper presents best settings of parameters for practical applications of hate speech mining. We also presented a Portuguese hate lexicon and a labeled dataset. All resources are available on our GitHub.  © 2023 ITMA.},
	author_keywords = {Deep Learning.; Hate Speech; Machine Learning; Word Embeddings},
	keywords = {Learning algorithms; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Deep learning.; Embeddings; Hate speech; Learning approach; Machine-learning; Network space; Offensive languages; Social media; Speech detection; Word embedding; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 18th Iberian Conference on Information Systems and Technologies, CISTI 2023; Conference date: 20 June 2023 through 23 June 2023; Conference code: 191760}
}

@CONFERENCE{Baruah2023,
	author = {Baruah, Nomi and Gogoi, Arjun and Phukan, Rituraj and Goutom, Pritom Jyoti},
	title = {Hate Speech Detection for a low level language (Assamese)},
	year = {2023},
	journal = {2023 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023},
	doi = {10.1109/ICCCNT56998.2023.10307931},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179839892&doi=10.1109%2fICCCNT56998.2023.10307931&partnerID=40&md5=182a08bb295d1677ef94b9ee66449866},
	affiliations = {Dibrugarh University, Computer Science and Engineering, Dibrugarh, India},
	abstract = {Numerous social media issues like 'Cyber conflict' have evolved as a result of the online community's explosive expansion, and they can negatively impact both individual and group social interactions. Social media networks struggle to control all of their users, necessitating the necessity for an automated hate-speech classifier. We tried to categorize hate words gathered from social media platforms like Facebook, YouTube, and Twitter despite a number of obstacles, including the absence of Unicode, text corpora, and other NLP tools in the Assamese language. The algorithms used in this work to examine hate speech in Assamese are Random Forest and Linear SVC. Additionally, we examine current works that address hate speech and antisocial behavior in all Indian languages. Our results show that both algorithms perform well, with Random Forest surpassing Linear SVC by 3.33 percent and an accuracy rate of 88.33 percent. We compared our suggested techniques to current studies in other Indian languages using both lemmatized and non-lemmatized versions of words, as there has been no study done in the Assamese language for Hate-Speech identification. © 2023 IEEE.},
	author_keywords = {Assamese; Facebook; Hate Speech; Linear SVC; Random Forest},
	keywords = {Speech recognition; 'current; Assamese; Facebook; Hate speech; Indian languages; Linear SVC; Low-level language; Random forests; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023; Conference date: 6 July 2023 through 8 July 2023; Conference code: 194774}
}

@CONFERENCE{Zampieri2023762,
	author = {Zampieri, Marcos and Morgan, Skye and North, Kai and Ranasinghe, Tharindu and Simmons, Austin and Khandelwal, Paridhi and Rosenthal, Sara and Nakov, Preslav},
	title = {Target-Based Offensive Language Identification},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {2},
	pages = {762 – 770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172243992&partnerID=40&md5=fbd624bfa47c0331046f854ba66d28b8},
	affiliations = {George Mason University, United States; Rochester Institute of Technology, United States; Aston University, United Kingdom; IBM Research, United States; Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates},
	abstract = {We present TBO, a new dataset for Target-based Offensive language identification. TBO contains post-level annotations regarding the harmfulness of an offensive post and token-level annotations comprising of the target and the offensive argument expression. Popular offensive language identification datasets for social media focus on annotation taxonomies only at the post level and more recently, some datasets have been released that feature only token-level annotations. TBO is an important resource that bridges the gap between post-level and token-level annotation datasets by introducing a single comprehensive unified annotation taxonomy. We use the TBO taxonomy to annotate post-level and token-level offensive language on English Twitter posts. We release an initial dataset of over 4,500 instances collected from Twitter and we carry out multiple experiments to compare the performance of different models trained and tested on TBO. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Social networking (online); Language identification; Offensive languages; Performance; Social media; Twitter posts; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160}
}

@ARTICLE{Pamungkas20231175,
	author = {Pamungkas, Endang Wahyu and Putri, Divi Galih Prasetyo and Fatmawati, Azizah},
	title = {Hate Speech Detection in Bahasa Indonesia: Challenges and Opportunities},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {6},
	pages = {1175 – 1181},
	doi = {10.14569/IJACSA.2023.01406125},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168806194&doi=10.14569%2fIJACSA.2023.01406125&partnerID=40&md5=cdbdb551f5017502c81ce21ae8434e3b},
	affiliations = {Informatics Engineering Department, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia; Software Engineering Department, Vocational School, Universitas Gadjah Mada, Yogyakarta, Indonesia; Social Informatics Research Center, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia},
	abstract = {This study aims to provide an overview of the current research on detecting abusive language in Indonesian social media. The study examines existing datasets, methods, and challenges and opportunities in this field. The research found that most existing datasets for detecting abusive language were col-lected from social media platforms such as Twitter, Facebook, and Instagram, with Twitter being the most commonly used source. The study also found that hate speech is the most researched type of abusive language. Various models, including traditional machine learning and deep learning approaches, have been im-plemented for this task, with deep learning models showing more competitive results. However, the use of transformer-based models is less popular in Indonesian hate speech studies. The study also emphasizes the importance of exploring more diverse phenomena, such as islamophobia and political hate speech. Additionally, the study suggests crowdsourcing as a potential solution for the annotation approach for labeling datasets. Furthermore, it encourages researchers to consider code-mixing issues in abusive language datasets in Indonesia, as it could improve the overall model performance for detecting abusive language in Indonesian data. The study also suggests that the lack of effective regulations and the anonymity afforded to users on most social networking sites, as well as the increasing number of Twitter users in Indonesia, have contributed to the rising prevalence of hate speech in Indonesian social media. The study also notes the importance of considering code-mixed language, out-of-vocabulary words, grammatical errors, and limited context when working with social media data. © (2023), All Rights Reserved.},
	author_keywords = {Abusive language; hate speech detection; machine learning; social media},
	keywords = {Codes (symbols); Learning systems; Social networking (online); Speech recognition; 'current; Abusive language; Facebook; Hate speech detection; Indonesia; Learning approach; Machine-learning; Social media; Social media platforms; Speech detection; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Kumar Kaliyar2023,
	author = {Kumar Kaliyar, Rohit and Goswami, Anurag and Sharma, Ujali and Kanojia, Kanika and Agrawal, Mohit},
	title = {HSDH: Detection of Hate Speech on social media with an effective deep neural network for code-mixed Hinglish data},
	year = {2023},
	journal = {2023 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023},
	doi = {10.1109/ICCCNT56998.2023.10306709},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179852963&doi=10.1109%2fICCCNT56998.2023.10306709&partnerID=40&md5=ff4bef8727a1b81c2732547a4e100967},
	affiliations = {Bennett University, School of Computer Science Engineering and Technology, India; Indira Gandhi Delhi Technical University for Women, School of AI-DS, India},
	abstract = {The phenomenal rise of social media platforms like Twitter, Facebook, Instagram, and Reddit has led to the blending of native languages or regional tongues with English for the purpose of improving communication in linguistically open geographic regions around the world. There are many ways in which Holocaust denial can lead to an increase in violence, from direct assault to purging out of compassion. Online, people are very hostile to one another. Distinguishing between language that incites hatred and language that is disparaging is a fundamental challenge in the categorization and tracking of extremely toxic lexical features. Our research focuses on identifying harmful tweets composed in Hinglish, a fusion of Hindi and the Roman alphabet. We propose a system in this paper for classifying tweets as either abusive, neutral, or offensive. The help of Hindi-English offensive tweet dataset is comprised of tweets written in the code-transferred language of Hindi and is further subdivided into three groups: neutral, abusive, and hateful. We studied the abusive and hate speech dataset with transfer learning and pre-trained the proposed model on Hinglish-processed English tweets. With our proposed model, we were able to improve accuracy to 98.54 percent. © 2023 IEEE.},
	author_keywords = {Classification; Deep Neural Network; Hate Speech; Social Media},
	keywords = {Blending; Codes (symbols); Deep neural networks; Network coding; Purging; Social networking (online); Speech recognition; Facebook; Geographics; Hate speech; Lexical features; Native language; Research focus; Social media; Social media platforms; Transfer learning; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023; Conference date: 6 July 2023 through 8 July 2023; Conference code: 194774}
}

@CONFERENCE{Abhishek20232875,
	author = {Abhishek, A. and Raj, Vijay and Ganesh, Shriram and Rithvik, Joseph and Vigil, M.S. Antony},
	title = {Hate Speech Detection using Logistic Regression on Bag of Words Model},
	year = {2023},
	journal = {14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023},
	volume = {2023-June},
	pages = {2875 – 2880},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174405946&partnerID=40&md5=111f3ca03b9e00982d58979bf54ea67d},
	affiliations = {SRMIST, Department of Computer Science Engineering, Chennai, India},
	abstract = {Hate speech is a conundrum that is spreading like wildfire. Social networks allow members to connect by a variety of common interests and share information. These channels create and also help communities engage in discussing specific topics related to said news. However, they are also used as a medium to spread hate and offensive news. News on social media spread like a forest fire. Not only social media, but other forms of online media and precedence may cause hate speech to spread. Therefore, trying to prevent it beforehand is much better than causing an outrage. The objective of this paper is to try to establish a reliable model to identify hate speech in sentences. The purpose of this project is to analyze the sentiments of speech used sentences using certain ML algorithms. The Bag of Words model and Document Frequency Inverse Term Frequency (TFIDF) are used to process the text in sentences. Then we use the Logistic Regression algorithm on our bag of words. © Grenze Scientific Society, 2023.},
	author_keywords = {Bag of words; Logistic Regression; Sentiment Analysis; Speech Classification; TF-IDF},
	keywords = {Deforestation; Information retrieval; Logistic regression; Social networking (online); Bag of words; Bag-of-words models; Common interests; Common shares; Logistics regressions; Sentiment analysis; Social media; Speech classification; Speech detection; TF-IDF; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023; Conference date: 15 June 2023 through 16 June 2023; Conference code: 192282}
}

@ARTICLE{Maity2023139,
	author = {Maity, Krishanu and Bhattacharya, Shaubhik and Phosit, Salisa and Kongsamlit, Sawarod and Saha, Sriparna and Pasupa, Kitsuchart},
	title = {Ex-ThaiHate: A Generative Multi-task Framework for Sentiment and Emotion Aware Hate Speech Detection with Explanation in Thai},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14174 LNAI},
	pages = {139 – 156},
	doi = {10.1007/978-3-031-43427-3_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174443992&doi=10.1007%2f978-3-031-43427-3_9&partnerID=40&md5=2a61b473a953422a4addeb5829b14f3b},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, 801103, India; School of Information Technology, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, 10520, Thailand},
	abstract = {Social media platforms have both positive and negative impacts on users in diverse societies. One of the adverse effects of social media platforms is the usage of hate and offensive language, which not only fosters prejudice but also harms the vulnerable. Additionally, a person’s sentiment and emotional state heavily influence the intended content of any social media post. Despite extensive research being conducted to detect online hate speech in English, there is a lack of similar studies on low-resource languages such as Thai. The recent enactment of laws like the “right to explanations” in the General Data Protection Regulation has stimulated the development of interpretable models rather than solely focusing on performance. Motivated by this, we created the first benchmark hate speech corpus, called Ex-ThaiHate, in the Thai language. Each post is annotated with four labels, namely hate, sentiment, emotion, and rationales (explainability), which specify the phrases that are responsible for annotating the post as hate. In order to investigate the effect of sentiment and emotional information on detecting hate speech posts, we propose a unified generative framework called GenX, which redefines this multi-task problem as a text-to-text generation task to simultaneously solve four tasks: hate-speech identification, rationale detection, sentiment, and emotion detection. Our extensive experiments demonstrate that GenX significantly outperforms all baselines and state-of-the-art models, thereby highlighting its effectiveness in detecting hate speech and identifying the rationales in low-resource languages. The code and dataset are available at https://github.com/dsmlr/Ex-ThaiHate. Disclaimer: The article contains offensive text and profanity. This is due to the nature of the work and does not reflect any opinion or stance of the authors. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Emotion; Explainability; Hate Speech; Multi-task; Sentiment; Thai},
	keywords = {Laws and legislation; Social networking (online); Adverse effect; Emotion; Explainability; Hate speech; Low resource languages; Multi tasks; Sentiment; Social media platforms; Speech detection; Thai; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2023; Conference date: 18 September 2023 through 22 September 2023; Conference code: 301649}
}

@ARTICLE{Haider2023218,
	author = {Haider, Farhatul and Dipty, Ismotara and Rahman, Fiaj and Assaduzzaman, Md and Sohel, Amir},
	title = {Social Media Hate Speech Detection Using Machine Learning Approach},
	year = {2023},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {673},
	pages = {218 – 229},
	doi = {10.1007/978-3-031-38296-3_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172418917&doi=10.1007%2f978-3-031-38296-3_17&partnerID=40&md5=e88d31e87ccb0308294146c8aebf2f34},
	affiliations = {Department of CSE, Daffodil International University, Dhaka, Bangladesh},
	abstract = {Humanity has profited enormously from the interchange of information and the expanding use of social media but it has also raised a number of challenges, such as the persistence of hate speech. This growing problem on social media platforms, latterly studies used a different type of point engineering system and machine literacy algorithms to automatically descry hate comments on numerous data. As we know, several studies have been done so far and compared several point engineering strategies with machine literacy algorithms to discover which strategy is the most productive. This investigation aims to examine the performance of multiple engineering approaches with five machine literacy algorithms. The data sets contain the class orders hate speech, not hate speech and offensive comments independently. These social media posts are split into these two groups. To recognize the particular traits of hate speech text messages, the appropriate n-gram feature sets are extracted. The n-gram TF-IDF weights provide the foundation for these feature models. The main aspiration of this research work is to analyze, and resolve the above problem and compare algorithms and features used in machine learning to automatically detect hate speech and specified them like labeling into various classes like hate speech, offensive, and neither, etc. After using different classifiers, “Random Forest” has come up with better accuracy, precision, and recall compared to SVM (Support Vector Machine), Naive Bayes, Logistic Regression, Ada Boost, and Gradient boost algorithms. This system achieved an accuracy of 90.26% using a Random Forest. The experimental result showed that the “Random Forest” provided the best all-around accuracy from the model that has been made and it is more accurate than compare to other work done in recent times on this. So, the result obtain from the model, based on the resulting intensity of the comments can be extracted. © 2023, IFIP International Federation for Information Processing.},
	author_keywords = {Hate Speech; Machine learning Techniques; Random Forest},
	keywords = {Character recognition; Engineering research; Forestry; Learning systems; Random forests; Social networking (online); Speech recognition; Engineering machines; Engineering systems; Hate speech; Machine learning approaches; Machine learning techniques; N-grams; Random forests; Social media; Social media platforms; Speech detection; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Proceedings of the 6th IFIP TC 12 International Conference on Computational Intelligence in Data Science, ICCIDS 2023; Conference date: 23 February 2023 through 25 February 2023; Conference code: 298609}
}

@CONFERENCE{Shridhara2023204,
	author = {Shridhara, Manohar Gowdru and Pristaš, Viktor and Kotvytskiy, Albert and Antoni, L’ubomír and Semanišin, Gabriel},
	title = {A short review on hate speech detection: Challenges towards datasets and techniques},
	year = {2023},
	journal = {DISA 2023 - World Symposium on Digital Intelligence for Systems and Machines, Proceedings},
	pages = {204 – 209},
	doi = {10.1109/DISA59116.2023.10308906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179512465&doi=10.1109%2fDISA59116.2023.10308906&partnerID=40&md5=34dee319981ed00565d3c8aa17cfb310},
	affiliations = {Institute of Computer Science, Faculty of Science, Pavol Jozef Šafárik University in Košice, Košice, Slovakia; Faculty of informatics, V. N. Karazin, Kharkiv National University, Kharkiv, Ukraine; Faculty of Science, Pavol Jozef Šafárik University in Košice, Košice, Slovakia},
	abstract = {Hate speech detection can be seen as the process of categorizing and identifying speech or written content that promotes discrimination, or violence towards individuals or groups. It can include various computational algorithms, natural language processing methods, and machine learning algorithms to automatically analyze and classify text data for the presence of hate speech. In this paper, we present the review of several approaches for hate speech detection and their challenges towards datasets and techniques. We highlight the examples of the architectures for hate speech detection based on combination of classical and deep learning classifiers. Moreover, we illustrate the examples of multi-labels for hate speech detection from various datasets. We found that there are still issues with defining and detection hate speech. Thus, the investigation of machine learning methods for hate speech detection is still a fruitful research area. © 2023 IEEE.},
	author_keywords = {convolutional neural networks; detection techniques; hate speech; language models; multi-labels; sentence classification},
	keywords = {Classification (of information); Convolutional neural networks; Deep learning; Learning algorithms; Learning systems; Natural language processing systems; Computational algorithm; Convolutional neural network; Detection technique; Hate speech; Language model; Language processing; Multi-labels; Natural languages; Sentence classifications; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 World Symposium on Digital Intelligence for Systems and Machines, DISA 2023; Conference date: 21 September 2023 through 22 September 2023; Conference code: 194437}
}

@CONFERENCE{Sacristán2023,
	author = {Sacristán, David Borregón and Muñoz, Antonio Pérez and Peris, Lucas Sebastián},
	title = {Building Robust Models for Detecting Offensive Content and Quantifying Prejudice in Online Platforms},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175095782&partnerID=40&md5=2d81cd0ac164dd5502a3a32c495cfcdf},
	affiliations = {Universitat Politècnica de València, Spain},
	abstract = {In this paper, we present a comprehensive project focused on developing models that address three critical tasks related to prejudicial humour recognition: Hurtful Humour Detection, Prejudice Target Detection, and Degree of Prejudice Prediction. Offensive and prejudiced language are prevalent in online platforms, posing significant challenges for content moderation and fostering inclusive communities. Therefore, our work aims to contribute to the identification and quantification of such problematic content through the application of state-of-the-art natural language processing (NLP) techniques. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {degree of prejudice prediction; hate speech; hurtful humour detection; natural language processing; offensive content; prejudice target detection},
	keywords = {Degree of prejudice prediction; Hate speech; Hurtful humor detection; Language processing; Natural language processing; Natural languages; Offensive content; Online platforms; Prejudice target detection; Targets detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@CONFERENCE{Spiesberger20232683,
	author = {Spiesberger, Anika A. and Triantafyllopoulos, Andreas and Tsangko, Iosif and Schuller, Björn W.},
	title = {Abusive Speech Detection in Indic Languages Using Acoustic Features},
	year = {2023},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	volume = {2023-August},
	pages = {2683 – 2687},
	doi = {10.21437/Interspeech.2023-789},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171535629&doi=10.21437%2fInterspeech.2023-789&partnerID=40&md5=f6378bf6a821bc41165d2d7652c641d3},
	affiliations = {Embedded Intelligence for Health Care and Wellbeing, University of Augsburg, Germany; audEERING GmbH, Gilching, Germany; GLAM - Group on Language, Audio, & Music, Imperial College, United Kingdom},
	abstract = {Abusive content in online social networks is a well-known problem that can cause serious psychological harm and incite hatred. The ability to upload audio data increases the importance of developing methods to detect abusive content in speech recordings. However, simply transferring the mechanisms from written abuse detection would ignore relevant information such as emotion and tone. In addition, many current algorithms require training in the specific language for which they are being used. This paper proposes to use acoustic and prosodic features to classify abusive content. We used the ADIMA data set, which contains recordings from ten Indic languages, and trained different models in multilingual and cross-lingual settings. Our results show that it is possible to classify abusive and non-abusive content using only acoustic and prosodic features. The most important and influential features are discussed. © 2023 International Speech Communication Association. All rights reserved.},
	author_keywords = {abusive content; computational paralinguistics; speech prosody},
	keywords = {Audio recordings; Classification (of information); Speech communication; Speech recognition; 'current; Abusive content; Acoustic features; Audio data; Computational paralinguistic; Paralinguistic; Prosodic features; Speech detection; Speech prosody; Speech recording; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 24th International Speech Communication Association, Interspeech 2023; Conference date: 20 August 2023 through 24 August 2023; Conference code: 191724}
}

@ARTICLE{Chakraborty202357,
	author = {Chakraborty, Angana and Joardar, Subhankar and Ahmed Sekh, Arif},
	title = {BSVM: A BERT-Based Support Vector Machine for Hindi Hostile Content Detection},
	year = {2023},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1046 LNEE},
	pages = {57 – 68},
	doi = {10.1007/978-981-99-2710-4_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172205046&doi=10.1007%2f978-981-99-2710-4_6&partnerID=40&md5=fd68110725b4caf189e789a44b5f3036},
	affiliations = {Haldia Institute of Technology, Haldia, India; XIM University, Bhubaneswar, India},
	abstract = {Social media platforms are increasingly providing hostile content. This has caused a requirement for accurate hostile post detection so that appropriate countermove can be made. Increasingly hostile content in various electronic media has created new obstacles for language comprehension. Regional languages make it more challenging. Despite being a good number of studies have been done in the English language, there has not been much progress in Regional languages because the appropriate datasets and tools are not yet available. Hindi is the native language of 615M persons. This research offers a Bidirectional Encoder Representations from Transformers (BERT)-based contextual embedding approach with a combination of Support Vector Machine (SVM) in order to categorize social media posts in Hindi Devanagari script as hostile or non-hostile using the Constraint 2021 Hindi Dataset. Offensive, fake, defamatory, and hateful posts are further evaluated to determine their status. In this research work, several SOTA BERT-based techniques are also subjected to comparative analysis. Our proposed model is found to perform better than the baseline model for all the hostile subclasses (defamation, fake, hate, and offensive). © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {BERT; Hindi language; Hostility detection; Natural language processing; Social media; SVM},
	keywords = {Fake detection; Natural language processing systems; Social networking (online); Bidirectional encoder representation from transformer; Content detection; Hindi language; Hostility detection; Language processing; Natural language processing; Natural languages; Social media; Social media platforms; Support vectors machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th International Conference on Communication, Devices and Computing (ICCDC 2023); Conference date: 1 March 2023 through 3 March 2023; Conference code: 298839}
}

@CONFERENCE{Sachi2023276,
	author = {Sachi, Savya and Singh, Ajay Kumar and Jain, Arpit and Devi, Suman and Sharma, Yogesh Kumar and Athithan, Senthil},
	title = {Hate Speech Detection Using the GPT-2 and Natural Language Processing},
	year = {2023},
	journal = {1st International Conference of Intelligent Methods, Systems and Applications, IMSA 2023},
	pages = {276 – 280},
	doi = {10.1109/IMSA58542.2023.10217745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171786792&doi=10.1109%2fIMSA58542.2023.10217745&partnerID=40&md5=3492e03ab4a360912625b5647025b083},
	affiliations = {Lalit Narayan Mishra College of Business Management, Department of Information Technology, Bihar, Muzaffarpur, 842001, India; Allenhouse Institute of Technology, Uttar Pradesh, Kanpur, India; Koneru Lakshmaiah Education Foundation, Department of Computer Science & Engineering, A.P., Guntur, India; Chaudhary Devi Lal University, Department of Computer Science and Engineering, Haryana, Sirsa, India; Koneru Lakshmaiah Education Foundation, Department of Computer Science & Engineering, AP, Guntur, India; Koneru Lakshmaiah Education Foundation, Department of Computer Science and Engineering, A.P., Vaddeswaram, India},
	abstract = {Hate speech on social media has increased as people use it to communicate and express their thoughts. Automatic hate speech detection has been studied in several languages. This study investigates the conclusion of the performance evaluation of the machine learning model GPT-2 (Generative Pre-trained Transformation 2) for natural language processing. The proposed model is developed and evaluated using a hate speech dataset. We attained an accuracy of about 97.12 percent, higher than the existing models called biLSTM, CNN, CNN-LSTM, and BERT.  © 2023 IEEE.},
	author_keywords = {BERT; biLSTM; CNN; CNN-LSTM; GPT-2; Natural Language Processing},
	keywords = {Learning algorithms; Long short-term memory; Natural language processing systems; BERT; BiLSTM; CNN-LSTM; Generative pre-trained transformation 2; Language processing; Natural language processing; Natural languages; Performances evaluation; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 1st International Conference of Intelligent Methods, Systems and Applications, IMSA 2023; Conference date: 15 July 2023 through 16 July 2023; Conference code: 192003}
}

@ARTICLE{Chhikara2023779,
	author = {Chhikara, Monika and Malik, Sanjay Kumar},
	title = {Abusive Content Detection on Social Networks Using Machine Learning},
	year = {2023},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1078 LNEE},
	pages = {779 – 787},
	doi = {10.1007/978-981-99-5974-7_62},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177828426&doi=10.1007%2f978-981-99-5974-7_62&partnerID=40&md5=2cb88595fa55d655fd20e0b6b3d4bba4},
	affiliations = {USIC&T, Dwarka, New Delhi, India},
	abstract = {For online social media, automatically identifying abusive language is a challenging but essential task. In recent years, finding abusive language in user-generated internet content has gained substantial attention. Our analysis focuses on human rights, including the development of fresh methods for identifying and defending the freedom of speech. In this paper, we consider strategies for distinguishing defamatory text from common profanity while detecting it. We have used the benchmark dataset of the Hate Speech Twitter Corpus, which contains 136,052 total tweets. Furthermore, this research uses the Long Short-Term Memory (LSTM) model for the method of classifying hate speech and abusive language. The final accuracy is ~82%. The technique revolves around including an extension that will accept the website's content (mostly text) as input, assess the contents for abusive purposes using specially developed neural networks, and hide the unethical content from the user. In contrast to the traditional way of users reporting abusive content, our solution does not require any human involvement and thereby limits offensive language by automatically recognizing and blocking it. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.},
	author_keywords = {Abusive language; Hate speech; Machine learning; Profane; Social network analysis; Social networks; Text classification},
	keywords = {Classification (of information); Social networking (online); Text processing; Abusive language; Content detection; Hate speech; Machine-learning; Online social medias; Profane; Social network; Social Network Analysis; Text classification; User-generated; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Advances and Applications of Artificial Intelligence and Machine Learning, ICAAAIML 2022; Conference date: 16 September 2022 through 17 September 2022; Conference code: 304349}
}

@ARTICLE{Hamza20231691,
	author = {Hamza, Manar Ahmed and Alshahrani, Hala J. and Tarmissi, Khaled and Yafoz, Ayman and Aziz, Amira Sayed A. and Mahzari, Mohammad and Zamani, Abu Sarwar and Yaseen, Ishfaq},
	title = {Improved Attentive Recurrent Network for Applied Linguistics-Based Offensive Speech Detection},
	year = {2023},
	journal = {Computer Systems Science and Engineering},
	volume = {47},
	number = {2},
	pages = {1691 – 1707},
	doi = {10.32604/csse.2023.034798},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169705799&doi=10.32604%2fcsse.2023.034798&partnerID=40&md5=58efa3f566c102fe226852082edc3281},
	affiliations = {Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia; Department of Applied Linguistics, College of Languages, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Makkah, Saudi Arabia; Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Digital Media, Faculty of Computers and Information Technology, Future University in Egypt, New Cairo, 11835, Egypt; Department of English, College of Science & Humanities, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia},
	abstract = {Applied linguistics is one of the fields in the linguistics domain and deals with the practical applications of the language studies such as speech processing, language teaching, translation and speech therapy. The ever-growing Online Social Networks (OSNs) experience a vital issue to confront, i.e., hate speech. Amongst the OSN-oriented security problems, the usage of offensive language is the most important threat that is prevalently found across the Internet. Based on the group targeted, the offensive language varies in terms of adult content, hate speech, racism, cyberbullying, abuse, trolling and profanity. Amongst these, hate speech is the most intimidating form of using offensive language in which the targeted groups or individuals are intimidated with the intent of creating harm, social chaos or violence. Machine Learning (ML) techniques have recently been applied to recognize hate speech-related content. The current research article introduces a Grasshopper Optimization with an Attentive Recurrent Network for Offensive Speech Detection (GOARN-OSD)model for social media. TheGOARNOSD technique integrates the concepts of DL and metaheuristic algorithms for detecting hate speech. In the presented GOARN-OSD technique, the primary stage involves the data pre-processing and word embedding processes. Then, this study utilizes the Attentive Recurrent Network (ARN) model for hate speech recognition and classification. At last, the GrasshopperOptimization Algorithm (GOA) is exploited as a hyperparameter optimizer to boost the performance of the hate speech recognition process. To depict the promising performance of the proposed GOARN-OSD method, a widespread experimental analysis was conducted. The comparison study outcomes demonstrate the superior performance of the proposed GOARN-OSD model over other state-of-the-art approaches. © 2023 CRL Publishing. All rights reserved.},
	author_keywords = {Applied linguistics; deep learning; grasshopper optimization algorithm; hate speech; natural language processing; offensive language},
	keywords = {Classification (of information); Data handling; Learning algorithms; Learning systems; Linguistics; Natural language processing systems; Optimization; Recurrent neural networks; Social networking (online); Speech processing; Applied linguistic; Deep learning; Grasshopper optimization algorithm; Hate speech; Language processing; Natural language processing; Natural languages; Offensive languages; Optimization algorithms; Recurrent networks; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Khondaker202396,
	author = {Khondaker, Md Tawkat Islam and Abdul-Mageed, Muhammad and Lakshmanan, Laks V.S.},
	title = {Cross-Platform and Cross-Domain Abusive Language Detection with Supervised Contrastive Learning},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {96 – 112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174538969&partnerID=40&md5=d3e5682e1de0c1c872763113306fa0fd},
	affiliations = {The University of British Columbia, Canada; MBZUAI, United Arab Emirates},
	abstract = {The prevalence of abusive language on different online platforms has been a major concern that raises the need for automated cross-platform abusive language detection. However, prior works focus on concatenating data from multiple platforms, inherently adopting Empirical Risk Minimization (ERM) method. In this work, we address this challenge from the perspective of domain generalization objective. We design SCL-Fish, a supervised contrastive learning integrated meta-learning algorithm to detect abusive language on unseen platforms. Our experimental analysis shows that SCL-Fish achieves better performance over ERM and the existing state-of-the-art models. We also show that SCL-Fish is data-efficient and achieves comparable performance with the large-scale pre-trained models upon finetuning for the abusive language detection task. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Learning algorithms; Cross-domain; Cross-platform; Empirical risk minimization; Generalisation; Language detection; Metalearning; Minimization methods; Multiple platforms; Online platforms; Performance; Fish},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th Workshop on Online Abuse and Harms, WOAH 2023, co-located with ACL 2023; Conference date: 13 July 2023; Conference code: 193145}
}

@CONFERENCE{Avanthika202366,
	author = {Avanthika, K. and Mrithula, K.L. and Thenmozhi, D.},
	title = {SSN-NLP-ACE@Multimodal Hate Speech Event Detection 2023: Detection of Hate Speech and Targets using Logistic Regression and SVM},
	year = {2023},
	journal = {CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023},
	pages = {66 – 70},
	doi = {10.26615/978-954-452-089-2_009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180387876&doi=10.26615%2f978-954-452-089-2_009&partnerID=40&md5=544bb65dc025d355840e41b601c336de},
	affiliations = {SSN College of Engineering, Tamil Nadu, India},
	abstract = {Hate speech has become a noteworthy concern in the digital age owing to its ability to brew violence, spread discrimination, and foster a belligerent atmosphere. Identifying and distinguishing hate speech from harmless discourse on online platforms is essential to maintain a safe and inclusive digital environment. In this research paper, we propose a multimodal approach to hate speech detection, directed towards the identification of hate speech and its related targets. Our method uses logistic regression and support vector machines (SVMs) to analyse textual content extracted from social media platforms. We exploit natural language processing techniques to preprocess and extract relevant features from textual content, capturing linguistic patterns, sentiment, and contextual information. These features are fed into logistic regression and SVM classifiers and trained on the labelled dataset. In addition, we performed a comparative analysis to evaluate the effectiveness of the multimodal approach compared to the use of existing methods. The proposed method holds promise for automated hate speech detection systems, facilitating censorship, and proactive intervention to mitigate the harmful effects of hate speech on online platforms. © CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023.},
	keywords = {Classification (of information); Logistic regression; Natural language processing systems; Online systems; Speech recognition; Logistic support; Logistics regressions; Multi-modal; Multi-modal approach; Online platforms; Regression vectors; Speech detection; Speech events; Support vectors machine; Textual content; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2023; Conference date: 7 September 2023; Conference code: 196554}
}

@CONFERENCE{Prasad202331,
	author = {Prasad, Deepak and Kadambari, K.V. and Mukati, Raghav and Singariya, Sunny},
	title = {Real-Time Multi-Lingual Hate and Offensive Speech Detection in Social Networks Using Meta-Learning},
	year = {2023},
	journal = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
	pages = {31 – 35},
	doi = {10.1109/TENCON58879.2023.10322364},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179525286&doi=10.1109%2fTENCON58879.2023.10322364&partnerID=40&md5=bb15e16597e4e4cb4832c171946e698a},
	affiliations = {National Institute of Technology, Computer Science and Engineering, Warangal, India},
	abstract = {A rapid increase in users on social media has given rise to a vast amount of user-generated content, including hate speech and offensive language. Such content can have serious negative consequences, ranging from psychological harm to inciting violence and discrimination. Existing studies have explored different deep learning and Natural language processing (NLP) methods to perform hate speech detection, and these solutions have yielded significant performance. Most existing solutions are limited to detecting hate speech only in English with less focus on content generated in other languages, particularly in low-resource or regional languages. The goal of this paper is to address this challenge of hate speech detection for low-resource languages and propose a tool that could provide a real-time prediction for social media posts. In this study, the main focus was on English, Hindi, Hinglish, Bengali, and Marathi languages which are commonly used in social media platforms in India. A meta-learning-based model was employed to perform hate speech detection in these languages. The proposed method helps to overcome the limitation of data scarcity and provides fast adaptation to an unseen target language. Extensive experiments were conducted on datasets comprised of different regional languages spoken in India. Accuracy, Precision, recall, and F1-score metrics are used to evaluate the model's performance. The results show that when the dataset size is small, meta-learning-based models perform better than traditional fine-tuned language models.  © 2023 IEEE.},
	author_keywords = {Hate speech; meta-learning; Offensive language},
	keywords = {Deep learning; Learning systems; Natural language processing systems; Social networking (online); Hate speech; Learning Based Models; Learning languages; Metalearning; Natural languages; Offensive languages; Real- time; Social media; Speech detection; User-generated; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 38th IEEE Region 10 Conference, TENCON 2023; Conference date: 31 October 2023 through 3 November 2023; Conference code: 194660}
}

@CONFERENCE{Rathod2023,
	author = {Rathod, Rutuja G. and Barve, Yashoda and Saini, Jatinderkumar R. and Rathod, Sourav},
	title = {From Data Pre-processing to Hate Speech Detection: An Interdisciplinary Study on Women-targeted Online Abuse},
	year = {2023},
	journal = {2023 3rd International Conference on Intelligent Technologies, CONIT 2023},
	doi = {10.1109/CONIT59222.2023.10205571},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169919063&doi=10.1109%2fCONIT59222.2023.10205571&partnerID=40&md5=1ec0cd4731129601ff72517fd1ec4a0e},
	affiliations = {Surayadatta College of Management Information & Research Technology, Pune, India; Symbiosis Institute of Computer Studies and Research, Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Technology, Symbiosis International (Deemed University), AI&ML Deparment, Pune, India},
	abstract = {The term 'misogyny' conveys hatred and disrespect for women. It is a type of sexism that stems from the idea that women are less valuable than men and can take many forms, such as verbal abuse, sexual harassment, and physical violence. One area where misogyny is particularly prevalent is in online spaces. Women who speak out and share their experiences online often face vicious attacks, including violence, rape, and death threats. This phenomenon, often referred to as 'online harassment,' can have devastating effects on women's mental health and well-being. Despite the growing recognition of this issue, there is still a lack of understanding about the nature and extent of hate speech toward women on social media. In this paper, the authors aim to address this gap by analyzing a dataset of tweets on Twitter containing hate speech toward women. The authors introduced the Measuring Hate Speech corpus, a dataset used while studying hate speech towards women. From this dataset, the authors extract some of them to build the model. And authors proposed Machine Learning algorithms like Logistic Regression with 0.92% accuracy. And to look further to fill the gap, the authors developed Support Vector Machine (SVM) algorithm, Topic Modeling technique to extract the topics from the corpus. This study contributes to a better understanding of hate speech on social media platforms as Twitter informs strategies for resisting this pervasive problem.  © 2023 IEEE.},
	author_keywords = {Hate speech; Machine Learning; Misogyny; Sexism; social media; Twitter; Women's human rights},
	keywords = {Data handling; E-learning; Learning algorithms; Learning systems; Logistic regression; Social networking (online); Speech recognition; Data preprocessing; Hate speech; Human rights; Machine-learning; Misogyny; Sexism; Social media; Speech detection; Twitter; Woman human right; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd IEEE International Conference on Intelligent Technologies, CONIT 2023; Conference date: 23 June 2023 through 25 June 2023; Conference code: 191552}
}

@CONFERENCE{De Paula2023,
	author = {De Paula, Angel Felipe Magnossão and Rosso, Paolo and Spina, Damiano},
	title = {Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection},
	year = {2023},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	volume = {2023-June},
	doi = {10.1109/IJCNN54540.2023.10191347},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169567342&doi=10.1109%2fIJCNN54540.2023.10191347&partnerID=40&md5=d0da1c20311e5c8e61e35f1435414172},
	affiliations = {Universitat Politècnica de València, Department of Computer Systems and Computation, València, 46022, Spain; School of Computing Technologies, Rmit University, Melbourne, 3000, Australia},
	abstract = {This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks. © 2023 IEEE.},
	author_keywords = {Deep Learning; Multi-task Learning; Natural Language Processing; Negative Transfer},
	keywords = {Learning algorithms; Learning systems; Linearization; Natural language processing systems; Speech recognition; Deep learning; Language detection; Language processing; Multitask learning; Natural language processing; Natural languages; Negative transfer; Performance; Task awareness; Transfer problems; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 International Joint Conference on Neural Networks, IJCNN 2023; Conference date: 18 June 2023 through 23 June 2023; Conference code: 191330; All Open Access, Green Open Access}
}

@CONFERENCE{Li2023339,
	author = {Li, Dongfang and Liu, Jing and Tan, Li and Shang, Ziliang and Liu, Zikang},
	title = {MNVLD: Violent Language Detection Model with Optimized Loss Function},
	year = {2023},
	journal = {2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2023},
	pages = {339 – 342},
	doi = {10.1109/ICBAIE59714.2023.10281299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175943990&doi=10.1109%2fICBAIE59714.2023.10281299&partnerID=40&md5=8111cd795d772c8a57f0a4c660abb151},
	affiliations = {Beijing Technology and Business University, School of Law, Beijing, 100048, China; Beijing Technology and Business University, School of Computer Science and Engineering, Beijing, 100048, China; Chongqing Institute of Microelectronics Industry Technology, Chongqing, 400000, China},
	abstract = {Violent language on the Internet has become a serious problem on social platforms, posing a threat to users' sense of security and a conducive communication environment. Most existing methods focus on creating violent language dictionaries and classifying texts using support vector machines (SVM) and naive Bayesian techniques. However, these methods face challenges when confronted with tens of thousands of text comments or commenters using obscure words. Additionally, the current network violence language detection technology performs poorly in multi-domain settings. This paper aims to enhance the MFND model in the context of rumor detection. We propose the MNVLD model, which incorporates an appropriate loss function based on the characteristics of the network violence language dataset, to effectively detect violent language across multiple domains. © 2023 IEEE.},
	author_keywords = {deep learning; loss function; multi-domain; social media; violent language},
	keywords = {Deep learning; Social networking (online); Communication environments; Deep learning; Detection models; Language detection; Loss functions; Multi-domains; Sense of security; Social media; Support vectors machine; Violent language; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2023; Conference date: 25 August 2023 through 27 August 2023; Conference code: 193634}
}

@CONFERENCE{Abbes2023739,
	author = {Abbes, Mariem and Kechaou, Zied and Alimi, Adel M.},
	title = {Deep learning approach for Tunisian hate Speech detection on Facebook},
	year = {2023},
	journal = {Proceedings - IEEE Symposium on Computers and Communications},
	volume = {2023-July},
	pages = {739 – 744},
	doi = {10.1109/ISCC58397.2023.10217909},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171986453&doi=10.1109%2fISCC58397.2023.10217909&partnerID=40&md5=242fc3c6934732a1a73b013c2f30aee9},
	affiliations = {University of Sousse, Isitcom, Sousse, Tunisia; University of National En-gineering School of Sfax (ENIS), REsearch Groups Intelligent Machines(REGIM-Lab), Sfax, Tunisia; University of Sfax, Higher Business School of Sfax (ESCS), Sfax, Tunisia; University of Johannesburg, Faculty of Engineering and the Built Environment, Departement of Electrical and Electronic Engineering Science, South Africa},
	abstract = {We have witnessed a sharp increase in violence in Tunisia over the past few years. Violence affecting households, minorities, political parties, and public figures has increased more widely on social media. As a result, it has become easier for extremist, racist, misogynistic, and offensive articles, posts, and comments to be shared. Today, various international and governmental groups vowed to fight internet hate speech. This paper proposes a deep-learning solution to find hateful and offensive speech on Arabic social media sites like Facebook. We introduce two models: A Bi-LSTM based on an attention mechanism with integrating the BERT for Facebook comment classification toward hate speech detection. For this task, we collected 2k Tunisian dialect comments from Facebook. The proposed approach has been evaluated on three datasets, and the obtained results demonstrate that the proposed models can improve Arabic hate detection with an accuracy of 98.89%. © 2023 IEEE.},
	author_keywords = {Abusive speech; Attention mechanism; BERT; Bi-LSTM; Embedding; Hate speech; Social media; Tunisian dialect},
	keywords = {Social networking (online); Speech recognition; Abusive speech; Attention mechanisms; BERT; Bi-LSTM; Embeddings; Facebook; Hate speech; Social media; Speech detection; Tunisian dialect; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 28th IEEE Symposium on Computers and Communications, ISCC 2023; Conference date: 9 July 2023 through 12 July 2023; Conference code: 192145}
}

@ARTICLE{Frenda202334,
	author = {Frenda, Simona and Patti, Viviana and Rosso, Paolo},
	title = {When Sarcasm Hurts: Irony-Aware Models for Abusive Language Detection},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14163 LNCS},
	pages = {34 – 47},
	doi = {10.1007/978-3-031-42448-9_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172361941&doi=10.1007%2f978-3-031-42448-9_4&partnerID=40&md5=9bcf8e49e4157b4dcaea37ee941d28f0},
	affiliations = {University of Turin, Turin, Italy; aequa-tech srl, Turin, Italy; Universitat Politècnica de València, Valencia, Spain},
	abstract = {Linguistic literature on irony discusses sarcasm as a form of irony characterized by its biting nature and the intention to mock a victim. This particular trait makes sarcasm apt to convey hate speech and not only humour. Previous works on abusive language stressed the need to address ironic language to lead the system to recognize correctly hate speech, especially in spontaneous texts, like tweets [13]. In this context, our main hypothesis is that information about the presence of sarcasm could help to improve the detection of hateful messages, especially when they are camouflaged as sarcastic. To corroborate this hypothesis: i) we perform analysis on HaSpeeDe20_ext, an Italian corpus of tweets about the integration of cultural minorities in Italy, ii) we carry out computational experiments injecting the knowledge of sarcasm in a system of hate speech detection, and iii) we adopt strategies of validation in terms of performance and significance of the obtained results. Results confirm our hypothesis and overcome the state of the art. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Abusive Language Detection; Irony Detection; Multi-Task Learning},
	keywords = {Learning systems; Abusive language detection; Computational experiment; Irony detection; Language detection; Multitask learning; Performance; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Proceedings of the 14th International Conference of the Cross-Language Evaluation Forum for European Languages, CLEF 2023; Conference date: 18 September 2023 through 21 September 2023; Conference code: 300519}
}

@ARTICLE{Almazroi202327,
	author = {Almazroi, Abdulwahab A. and Shah, Asad A. and Mohammed, Fathey},
	title = {Social Media and Online Islamophobia: A Hate Behavior Detection Model},
	year = {2023},
	journal = {International Journal of Engineering Trends and Technology},
	volume = {71},
	number = {11},
	pages = {27 – 32},
	doi = {10.14445/22315381/IJETT-V71I11P203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177076939&doi=10.14445%2f22315381%2fIJETT-V71I11P203&partnerID=40&md5=19686a3a8e846e4e979fb5c47ef33a5e},
	affiliations = {College of Computing and Information Technology at Khulais, Department of Information Technology, University of Jeddah, Jeddah, Saudi Arabia; Sunway Business School, Sunway University, Selangor, Malaysia},
	abstract = {Since 9/11, the Muslim community has faced a lot of hatred towards them due to the rise in Islamophobia. Taking no measures to control Islamophobia can create fear among the Muslim community while at the same time giving others an open hand to spread hate and toxic remarks toward Muslims. While Muslim leaders and countries are taking measures to stop Islamophobia through awareness and building content to share Islam’s true peaceful and moderate image, it does not help control the spread of Islamophobia on social media platforms. In this regard, this research proposes a framework capable of detecting Islamophobic content. The proposed solution achieves this using natural language and artificial intelligence techniques such as keyword detection, tone analyzer, machine learning, impartiality ratio, and more. The proposed model is also capable of categorizing comments based on their severity and context. The research is hopeful that the proposed framework would allow experts to detect such posts causing Islamophobia early and report them so they can be taken down timely before being widespread. The successful completion of this research will not only have positive implications for the Muslim community but will also allow experts and researchers from other areas to use the same model in combating hateful and toxic speech on other platforms. © 2023 Seventh Sense Research Group®},
	author_keywords = {Detection; Hate; Islamophobia; Social Media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Clarke2023364,
	author = {Clarke, Christopher and Hall, Matthew and Mittal, Gaurav and Yu, Ye and Sajeev, Sandra and Mars, Jason and Chen, Mei},
	title = {Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {364 – 376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174405530&partnerID=40&md5=56006284aa178eec5bc3d529cdd3cee8},
	affiliations = {University of Michigan, Ann Arbor, MI, United States; Microsoft, Redmond, WA, United States},
	abstract = {Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms. In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches. We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding. © 2023 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Deep learning; Heuristic methods; Speech recognition; Customizable; Data-driven model; Exemplar-based; Heuristics approaches; Learning approach; Logical rules; Neural modelling; Performance; Rule-based heuristics; Speech detection; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160}
}

@ARTICLE{Perera2023116,
	author = {Perera, Suresha and Ahangama, Supunmali and Perera, Indika and Hathnapitiya, Sandunika},
	title = {Predicting Twitter Hate User Behavior Using Big Five Personality Traits and Ensemble Machine Learning},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14025 LNCS},
	pages = {116 – 130},
	doi = {10.1007/978-3-031-35915-6_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169016076&doi=10.1007%2f978-3-031-35915-6_10&partnerID=40&md5=eb1687dc4b4ad568231084b54d74d047},
	affiliations = {University of Moratuwa, Katubedda, 10400, Sri Lanka},
	abstract = {Twitter has grown in popularity as a microblogging social media platform for people of all ages and locations to exchange and discuss important events, information, and news. Some Twitter users exhibit unique behaviors, and they use such platforms maliciously to spread hate content over social media platforms. These materials may be harmful to the mental health of people and cause suicide ideation, criminal behavior, or racism. On social media, hateful content spreads more quickly than other types of content by nature. Early detection of hate users can help to lessen its damaging effects. Different personality types exist among social media users, and these personality types influence how a person interacts with others, processes information, and makes decisions. This study determines whether personality is associated with the sharing of hate content by hate users, identifying the HIGH/LOW availability of Big Five personality traits. Meanwhile, three psychologists determine the personalities of Twitter users based on their profiles. With more than 80% accuracy for each personality trait, the ensemble approach (SVM, Random Forest, XGBoost) was used in this study to examine how the Big Five personality traits of Twitter users may be predicted using their Twitter user profiles’ attributes and Twitter activity considering both English and Sinhala language Tweets in the Sri Lankan context. The findings of this study provide new empirical proof that there is a considerable relationship between people’s personality traits and their harmful intentions, with neuroticism and extraversion being closely associated with hate users by raising anti-social traits in them. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Big Five personality traits; Hate speech propagators; Hate user behaviour; Twitter},
	keywords = {Behavioral research; Forestry; Random forests; Social networking (online); User profile; Big five; Big five personality trait; Hate speech propagator; Hate user behavior; Personality traits; Personality types; Social media; Social media platforms; Twitter; User behaviors; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th International Conference on Social Computing and Social Media, SCSM 2023, held as part of the 25th International Conference on Human-Computer Interaction, HCII 2023; Conference date: 23 July 2023 through 28 July 2023; Conference code: 297799}
}

@CONFERENCE{Vargas20231187,
	author = {Vargas, Francielle and Carvalho, Isabelle and Hürriyetoǧlu, Ali and Pardo, Thiago A. S. and Benevenuto, Fabrício},
	title = {Socially Responsible Hate Speech Detection: Can Classifiers Reflect Social Stereotypes?},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1187 – 1196},
	doi = {10.26615/978-954-452-092-2_126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179180014&doi=10.26615%2f978-954-452-092-2_126&partnerID=40&md5=e7510a73a5421b8dfaa72fcee89b52ac},
	affiliations = {Institute of Mathematical and Computer Sciences, University of São Paulo, Brazil; Computer Science Department, Federal University of Minas Gerais, Brazil; KNAW Humanities Cluster, DHLab, Netherlands},
	abstract = {Recent studies have shown that hate speech technologies may propagate social stereotypes against marginalized groups. Nevertheless, there has been a lack of realistic approaches to assess and mitigate biased technologies. In this paper, we introduce a new approach to analyze the potential of hate-speech classifiers to reflect social stereotypes through the investigation of stereotypical beliefs by contrasting them with counter-stereotypes. We empirically measure the distribution of stereotypical beliefs by analyzing the distinctive classification of tuples containing stereotypes versus counterstereotypes in machine learning models and datasets. Experiment results show that hate speech classifiers attribute unreal or negligent offensiveness to social identity groups by reflecting and reinforcing stereotypical beliefs regarding minorities. Furthermore, we also found out that models that embed expert and context information from offensiveness markers present promising results to mitigate social stereotype bias towards socially responsible hate speech detection. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Speech recognition; Context information; Expert informations; Learning dataset; Machine learning models; New approaches; Social identity; Speech detection; Speech technology; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2023 International Conference Recent Advances in Natural Language Processing: Large Language Models for Natural Language Processing, RANLP 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194755; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Jafari2023105330,
	author = {Jafari, Amir Reza and Li, Guanlin and Rajapaksha, Praboda and Farahbakhsh, Reza and Crespi, Noel},
	title = {Fine-Grained Emotions Influence on Implicit Hate Speech Detection},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {105330 – 105343},
	doi = {10.1109/ACCESS.2023.3318863},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173054807&doi=10.1109%2fACCESS.2023.3318863&partnerID=40&md5=60974efbac23785f68d048c06ccd3e46},
	affiliations = {Institut Polytechnique de Paris, Samovar, Telecom SudParis, Palaiseau, 91120, France},
	abstract = {Recent years brought an exponential growth of social media which revolutionized freedom of speech but significantly increased the propagation of hate speech and hate-based activities. Therefore, constructive countermeasures are necessary to prevent escalating hateful content on online social media. Many recent works target explicit hate speech, but only a few studies have utilized multiple fused features such as sentiment, targets, and emotions as attributes to enhance the detection of hate speech. In general, sentiment features help to discern feelings such as positivity or negativity, and emotion features provide a deeper level of granularity, focusing on a more comprehensive understanding of sensitivities. The aim of this paper is to investigate the significance of incorporating fine-grained emotions as an essential feature in improving the classification of implicit hate speech. First, we analyzed emotion variations of hateful and non-hateful content and explored their major fine-grained emotion discrepancies targeting implicit hateful content. Next, we introduce a multi-task learning approach that integrates emotions and sentiment features to classify implicit expressions of hatred. To evaluate the effectiveness of our multi-task learning approach, we compared it with baseline models using single-task learning approaches. The experimental results show that our multi-task approach outperformed in classifying implicit hate speech compared to the baseline models and demonstrates that fine-grained emotional knowledge decreases the classification error across multiple implicit hate categories.  © 2013 IEEE.},
	author_keywords = {emotion analysis; Hate speech; implicit hate; multi-task learning; social media},
	keywords = {Classification (of information); Emotion Recognition; Feature extraction; Learning systems; Multitasking; Social networking (online); Speech recognition; Emotion analysis; Emotion recognition; Features extraction; Hate speech; Implicit hate; Multitask learning; Social media; Social networking (online); Transformer; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Maity2023132,
	author = {Maity, Krishanu and Jha, Prince and Jain, Raghav and Saha, Sriparna and Bhattacharyya, Pushpak},
	title = {“Explain Thyself Bully”: Sentiment Aided Cyberbullying Detection with Explanation},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14189 LNCS},
	pages = {132 – 148},
	doi = {10.1007/978-3-031-41682-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173581672&doi=10.1007%2f978-3-031-41682-8_9&partnerID=40&md5=93dbfa1d13037c4588f3c0487a51b8a7},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, India; Department of Computer Science and Engineering, Indian Institute of Technology Bombay, Bombay, India},
	abstract = {Cyberbullying has become a big issue with the popularity of different social media networks and online communication apps. While plenty of research is going on to develop better models for cyberbullying detection in monolingual language, there is very little research on the code-mixed languages and explainability aspect of cyberbullying. Recent laws like “right to explanations” of General Data Protection Regulation, have spurred research in developing interpretable models rather than focusing on performance. Motivated by this we develop the first interpretable multi-task model called mExCB for automatic cyberbullying detection from code-mixed languages which can simultaneously solve several tasks, cyberbullying detection, explanation/rationale identification, target group detection and sentiment analysis. We have introduced BullyExplain, the first benchmark dataset for explainable cyberbullying detection in code-mixed language. Each post in BullyExplain dataset is annotated with four labels, i.e., bully label, sentiment label, target and rationales (explainability), i.e., which phrases are being responsible for annotating the post as a bully. The proposed multitask framework (mExCB) based on CNN and GRU with word and sub-sentence (SS) level attention is able to outperform several baselines and state of the art models when applied on BullyExplain dataset. Disclaimer: The article contains offensive text and profanity. This is owing to the nature of the work, and do not reflect any opinion or stand of the authors.(The code and dataset are available at https://github.com/MaityKrishanu/BullyExplain-ICDAR.) © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Code-Mixed; Cyberbullying; Explainability; Multi-task; Sentiment},
	keywords = {Codes (symbols); Computer crime; Code-mixed; Cyber bullying; Explainability; General data protection regulations; Multi tasks; Network communications; On-line communication; Performance; Sentiment; Social media networks; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 17th International Conference on Document Analysis and Recognition, ICDAR 2023; Conference date: 21 August 2023 through 26 August 2023; Conference code: 299469}
}

@CONFERENCE{Esackimuthu202379,
	author = {Esackimuthu, Sarika and Balasundaram, Prabavathy},
	title = {VerbaVisor@Multimodal Hate Speech Event Detection 2023: Hate Speech Detection using Transformer Model},
	year = {2023},
	journal = {CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023},
	pages = {79 – 83},
	doi = {10.26615/978-954-452-089-2_011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180398259&doi=10.26615%2f978-954-452-089-2_011&partnerID=40&md5=8c4a8e82945ec397f31e0fdd4be736f1},
	affiliations = {Department of Computer Science and Engineering, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, 603110, India},
	abstract = {Thapa et al. (2023) task focuses on identifying hate speech or not from text-embedded images and also identify the targets of hate speech. Hate speech detection has emerged as a critical research area in recent years due to the rise of online social platforms and the proliferation of harmful content targeting individuals or specific groups. This task highlights the importance of detecting hate speech in text-embedded images. By leveraging deep learning models, this research aims to uncover the connection between hate speech and the entities it targets. © CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023.},
	keywords = {Deep learning; Natural language processing systems; Critical researches; Embedded images; Events detection; Learning models; Multi-modal; Research areas; Speech detection; Speech events; Transformer modeling; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2023; Conference date: 7 September 2023; Conference code: 196554}
}

@CONFERENCE{Plaza-Del-Arco202360,
	author = {Plaza-Del-Arco, Flor Miriam and Nozza, Debora and Hovy, Dirk},
	title = {Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {60 – 68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173560837&partnerID=40&md5=48d8eaa4f75ee15bf57de4ec2b3e6869},
	affiliations = {Bocconi University, Via Sarfatti 25, Milan, Italy},
	abstract = {Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large dataset; Learning systems; Zero-shot learning; Accurate prediction; Benchmark datasets; Labeled data; Language model; Model-making; Performance; Specific knowledge; Speech detection; Under-resourced languages; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 7th Workshop on Online Abuse and Harms, WOAH 2023, co-located with ACL 2023; Conference date: 13 July 2023; Conference code: 193145}
}

@CONFERENCE{Armenta-Segura202353,
	author = {Armenta-Segura, Jesús and Núñez-Prado, César-Jesús and Sidorov, Grigori and Gelbukh, Alexander and Román-Godínez, Rodrigo},
	title = {Ometeotl@Multimodal Hate Speech Event Detection 2023: Hate Speech and Text-Image Correlation Detection in Real Life Memes Using Pre-Trained BERT Models over Text},
	year = {2023},
	journal = {CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023},
	pages = {53 – 59},
	doi = {10.26615/978-954-452-089-2_007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180394175&doi=10.26615%2f978-954-452-089-2_007&partnerID=40&md5=92a664916e39d6b54820c9055882ca67},
	affiliations = {Instituto Politécnico Nacional, Centro de Investigación en Computación, Mexico City, Mexico},
	abstract = {Hate speech detection during times of war has become crucial in recent years, as evident with the recent Russo-Ukrainian war. In this paper, we present our submissions for both subtasks from the Multimodal Hate Speech Event Detection contest at CASE 2023, RANLP 2023. We used pre-trained BERT models in both submission, achieving a F1 score of 0.809 in subtask A, and F1 score of 0.567 in subtask B. In the first subtask, our result was not far from the first place, which led us to realize the lower impact of images in real-life memes about feelings, when compared with the impact of text. However, we observed a higher importance of images when targeting hateful feelings towards a specific entity. The source code to reproduce our results can be found at the github repository https://github.com/JesusASmx/OmeteotlAtCASE2023. © CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023.},
	keywords = {Natural language processing systems; Correlation detection; Events detection; F1 scores; Image correlations; Low impacts; Multi-modal; Speech detection; Speech events; Subtask; Text images; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2023; Conference date: 7 September 2023; Conference code: 196554}
}

@CONFERENCE{Sahana2023,
	author = {Sahana, N.V. and Prerana, R. and Niharika, S. and Rakshitha, S. and Bhanushree, K.J.},
	title = {Automatic Hate Speech Detection using Ensemble Method and Natural Language Processing Techniques},
	year = {2023},
	journal = {2023 International Conference on Network, Multimedia and Information Technology, NMITCON 2023},
	doi = {10.1109/NMITCON58196.2023.10276372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175403930&doi=10.1109%2fNMITCON58196.2023.10276372&partnerID=40&md5=a2051099f53660efb2bafc22a07af0f0},
	affiliations = {Computer Science and Engineering Bangalore Institute of Technology, Bangalore, India},
	abstract = {The use of social media has exploded in recent years, and sharing information has numerous benefits for society. Hateful content has increased as a result of the increased usage of social media. Hate speech can exist in any sort of content designed to slander, dishonor, or incite hatred toward certain affecting various communities, organizations and individuals. It is critical to distinguish between hate and offensive texts to detect hate and offensive speech in any given text. Since no previous work has been done utilizing both English and Hinglish (Hindi- English code combined) data sets for multi class prediction, an ensemble model has been proposed to categorize any given input sentence into one of the three categories: hatred, offensive, or neither. Data collection, data pre-processing, feature extraction, and text categorization are significant processes needed for the proposed approach to detect hate speech. The data set collected for this model is a publicly available Twitter data set in English and Hindi-English code mix language to which data preprocessing is done. Extraction of n-grams as features is done using the term frequency-inverse document frequency (TFIDF) extraction method. Several single classification methods, such as Decision tree, SVC, Logistic Regression, Random Forest, and Naive Bayes are considered, evaluated and compared, combinations of various single classification models are done to form a better ensemble model with a combination of Random Forest and Support Vector Classifier. When tested against the testing dataset, the proposed ensemble model achieved an accuracy of 90.7.  © 2023 IEEE.},
	author_keywords = {ensemble; hate speech; n-gram; offensive speech; TFIDF},
	keywords = {Computational linguistics; Data acquisition; Data handling; Decision trees; Extraction; Feature extraction; Logistic regression; Natural language processing systems; Social networking (online); Speech recognition; Statistical tests; Text processing; Data preprocessing; Data set; Ensemble; Ensemble models; Hate speech; N-grams; Offensive speech; Random forests; Social media; Term frequencyinverse document frequency (TF-IDF); Inverse problems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 IEEE International Conference on Network, Multimedia and Information Technology, NMITCON 2023; Conference date: 1 September 2023 through 2 September 2023; Conference code: 193544}
}

@ARTICLE{Haq20231,
	author = {Haq, Ijazul and Qiu, Weidong and Guo, Jie and Tang, Peng},
	title = {Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT},
	year = {2023},
	journal = {PeerJ Computer Science},
	volume = {9},
	pages = {1 – 26},
	doi = {10.7717/PEERJ-CS.1617},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175080058&doi=10.7717%2fPEERJ-CS.1617&partnerID=40&md5=5d59196a36fa17241d5216860a68eee2},
	affiliations = {School of Cyber Science and Engineering, Shanghai Jiao Tong University, Minhang, Shanghai, China},
	abstract = {Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: ‘‘offensive’’ and ‘‘not offensive’’. To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%. © 2023 Haq et al.},
	author_keywords = {BERT; Large language models; LLMs; Low-resource languages; NLP; Offensive language detection; Osn; Pashto; Social media; Text processing},
	keywords = {Computational linguistics; Deep learning; Large dataset; Learning systems; Natural language processing systems; Social networking (online); Transfer learning; BERT; Language detection; Language model; Large language model; LLM; Low resource languages; Offensive language detection; Offensive languages; Osn; Pashto; Social media; Text-processing; Text processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Di Bonaventura2023,
	author = {Di Bonaventura, Chiara and Muti, Arianna and Stranisci, Marco Antonio},
	title = {O-Dang at HODI and HaSpeeDe3: A Knowledge-Enhanced Approach to Homotransphobia and Hate Speech Detection in Italian},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173573144&partnerID=40&md5=198199f704c5e253d766d66a65bcf862},
	affiliations = {King's College London, United Kingdom; University of Bologna, Italy; University of Turin, Italy},
	abstract = {This paper describes our methods implemented during the EVALITA 2023 campaign for homotransphobia (HODI task) and hate speech detection (HaSpeeDe3 task) in Italian. We present three knowledge-enhanced approaches, namely via triple verbalisation, via prompting and via a majority vote, and we compare them to the AlBERTo baseline. These systems leverage the knowledge graph O-Dang, which contains information about named entities in Italian dangerous speech. Our knowledge-enhanced systems outperformed all the competition's baselines. Our best submissions achieved the macro-F1 score of 0.912 for HaSpeeDe3 and 0.795 for HODI, reaching the 1st and 3rd place, respectively. These results were achieved by using our baseline for HODI, and a majority voting approach for HaSpeeDe3. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {data augmentation; entity linking; hate speech; knowledge graph; prompting},
	keywords = {Computational linguistics; Knowledge management; Speech recognition; Data augmentation; Entity linking; F1 scores; Hate speech; Knowledge graphs; Majority voter; Named entities; Prompting; Speech detection; Voting approach; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243}
}

@CONFERENCE{Hangya2023,
	author = {Hangya, Viktor and Fraser, Alexander},
	title = {LMU at HaSpeeDe3: Multi-Dataset Training for Cross-Domain Hate Speech Detection},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173560957&partnerID=40&md5=c6eae63bd2f1eb3c9d998f468f75347e},
	affiliations = {Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning, Germany},
	abstract = {We describe LMU Munich's hate speech detection system for participating in the cross-domain track of the HaSpeeDe3 shared task at EVALITA 2023. The task focuses on the politics and religion domains, having no in-domain training data for the latter. Our submission combines multiple training sets from various domains in a multitask prompt-training system. We experimented with both Italian and English source datasets as well as monolingual Italian and multilingual pre-trained language models. We found that the Italian out-of-domain datasets are the most influential on the performance in the test domains and that combining both monolingual and multilingual language models using an ensemble gives the best results. Our system ranked second in both domains. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {hate speech detection; multitask learning; prompt-training},
	keywords = {Speech recognition; Cross-domain; Detection system; Hate speech detection; Language model; Multiple training sets; Multitask learning; Prompt-training; Speech detection; Training data; Training Systems; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243}
}

@CONFERENCE{El-Sayed2023,
	author = {El-Sayed, Tharwat and Mustafa, Abdallah and El-Sayed, Ayman and Elrashidy, Mohamed},
	title = {Hate speech detection by classic machine learning},
	year = {2023},
	journal = {ICEEM 2023 - 3rd IEEE International Conference on Electronic Engineering},
	doi = {10.1109/ICEEM58740.2023.10319569},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179551306&doi=10.1109%2fICEEM58740.2023.10319569&partnerID=40&md5=9bf1ac1ebf8beeb8da3a3361418b4638},
	affiliations = {Menoufia University, Faculty of Electronic Eng., Computer Science & Eng. Dept., Menouf, 32952, Egypt},
	abstract = {It is becoming increasingly important for society to identify hate speech on social media. Differentiating hate speech from other instances involving offensive language is a significant difficulty for automatic hate speech tracking on social media. To distinguish between these categories, we train various classical machine learning models such as logistic regression, decision trees, random forest, naive Bayes, k-nearest neighbors, and support vector machines (SVM) - support vector classifier (SVC) on a dataset divided into three groups: those containing hate speech, those containing only offensive language, and those containing neither. From our practical trials, we found that the Logistic Regression algorithm and the SVM-SVC algorithm perform well in detecting hate speech and offensive language. © 2023 IEEE.},
	author_keywords = {Artificial Intelligence; Hate speech; Machine Learning; Natural Language Processing; Offensive language; People with special needs},
	keywords = {Classification (of information); Learning systems; Logistic regression; Natural language processing systems; Nearest neighbor search; Random forests; Social networking (online); Speech recognition; Support vector regression; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Offensive languages; People with special need; Social media; Special needs; Support vectors machine; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd IEEE International Conference on Electronic Engineering, ICEEM 2023; Conference date: 7 October 2023 through 8 October 2023; Conference code: 194630}
}

@ARTICLE{Kaliyar2023282,
	author = {Kaliyar, Rohit Kumar and Goswami, Anurag and Sharma, Ujali and Kanojia, Kanika},
	title = {ACDNet: Abusive Content Detection on Social Media with an Effective Deep Neural Network Using Code-Mixed Hinglish Data},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1782 CCIS},
	pages = {282 – 293},
	doi = {10.1007/978-3-031-35644-5_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169470975&doi=10.1007%2f978-3-031-35644-5_22&partnerID=40&md5=2bdd930d7880ab95abd891d0218f30de},
	affiliations = {Bennett University, Greater Noida, India; Indira Gandhi Delhi Technical University for Women, New Delhi, India},
	abstract = {In linguistically open geographic regions around the world, the amazing growth of social media platforms like Twitter, Facebook, and Instagram has led to the blending of native languages or regional tongues with English for the purpose of improving communication. Holocaust denial is a significant social problem that has the potential to escalate violence in a number of ways, from violent attacks to compassionate purging. A fundamental challenge in the categorization and tracking of extremely toxic lexical features is differentiating between language that incites hatred and language that is disparaging. Our study concentrates on locating abusive tweets written in Hinglish, a combination of Hindi and Roman Script. In this paper, we propose an approach for classifying tweets into three categories: hate speech, non-offensive speech, and abusive speech. Using the Hindi-English offensive tweet dataset, which includes tweets in the Hindi-English code transferred language and is divided into three categories: non-offensive, abusive, and hate speech. We utilized transfer learning to conduct research on the abusive and hate speech datasets and pre-trained the proposed model on English tweets that have been pre-processed using Hinglish Tweets. We were able to achieve 98.92% accuracy using the proposed model. © 2023, Springer Nature Switzerland AG.},
	author_keywords = {Hate Speech Social Media Deep Neural Network Classification Fake News},
	keywords = {Blending; Classification (of information); Codes (symbols); Fake detection; Network coding; Social networking (online); Content detection; Facebook; Geographics; Hate speech social medium deep neural network classification fake news; Native language; Neural network classification; Social media; Social media platforms; Social problems; Three categories; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th International Advanced Computing Conference, IACC 2022; Conference date: 16 December 2022 through 17 December 2022; Conference code: 298199}
}

@ARTICLE{Kumar202359,
	author = {Kumar, Ashwini and Kumar, Santosh},
	title = {Hate Speech Detection in Multi-social Media Using Deep Learning},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1920},
	pages = {59 – 70},
	doi = {10.1007/978-3-031-45121-8_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175949962&doi=10.1007%2f978-3-031-45121-8_6&partnerID=40&md5=210c3aaa2b60cbb635d6d4db25ce4d83},
	affiliations = {Graphic Era Deemed to be University, Uttarakhand, Dehradun, India},
	abstract = {In recent days lots of advancements on the Internet and various social media such as Facebook, Twitter, Gab, Reddit, YouTube, Stromfornt, etc., many people continue to use multiple online social media platforms to express their views or comments and sometimes post Hate Speech or Offensive Language. It is challenging to detect hate speech manually, especially from social media data. A robust mechanism is essential to handle this issue, which will automatically detect hate speech on social networks. Many researchers have addressed this issue through many means. However, most methods are not accurate enough in detecting hate speech because of the massive volume of data, data dependencies, excessive parameters, and the use of only homogeneous social media data. To resolve this issue, we have Investigated a cross-platform hate speech recognition mechanism for Social Media Interactions and developed a Deep Neural Network (DNN) approach to tackle heterogeneous multi-social media data as a generic platform. This paper proposes a model for hate speech detection based on Deep Learning architecture. This model comprises multiple Deep neural networks combining Bidirectional-Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNN) to produce the best performance on numerous social media datasets of 0.2 million (202377) annotated Tweets or comments. And also, the performance of the BiLSTM-CNN model has been analyzed, measured, and compared with existing classical machine learning methods. Our model is trained using ten epochs to split the dataset, 80% for training and 20% as validation data. Our proposed model’s performance is evaluated using the precision, recall, and accuracy parameters. Finally, we compared the performance of our model with many machine learning methods such as Decision Trees, Support Vector Machine (SVM) Linear, Logistic Regression, and Naive Bayes methods. It is evident from the result that our proposed model achieved an accuracy of 92.5%, and the F1-score value is 92.1% in the detection of hate speech. Overall, the proposed model outperforms other state-of-art methods. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {CNN; Deep Learning; Hate Speech; LSTM; social media},
	keywords = {Convolutional neural networks; Decision trees; Learning systems; Logistic regression; Long short-term memory; Social networking (online); Speech recognition; Support vector machines; Convolutional neural network; Deep learning; Facebook; Hate speech; Machine learning methods; Performance; Social media; Social media datum; Speech detection; YouTube; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2nd International Conference on Advanced Communication and Intelligent Systems, ICACIS 2023; Conference date: 16 June 2023 through 17 June 2023; Conference code: 302859}
}

@ARTICLE{Chinivar2023289,
	author = {Chinivar, Sneha and Roopa, M.S. and Arunalatha, J.S. and Venugopal, K.R.},
	title = {Online Hate Speech Identification Using Fine-tuned ALBERT},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {719 LNNS},
	pages = {289 – 300},
	doi = {10.1007/978-981-99-3758-5_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174705486&doi=10.1007%2f978-981-99-3758-5_27&partnerID=40&md5=e77d52705a45253bb76958465176c3af},
	affiliations = {Department of CSE UVCE, Bangalore University, Bengaluru, India; Department of CSE, Dayananda Sagar College of Engineering, Bengaluru, India},
	abstract = {The increased use of social media platforms has escalated the outspread of online hate speech. Hate speech can take numerous forms, such as political, racial, religious, LGBTQ+, gender-based, nationality-based and disability-based; It can overlap and intersect with various forms of oppression and discrimination and can lead to severe and harmful impacts on society. It is crucial to combat online hate speech and create a more inclusive and secure online environment. Several approaches have already been investigated, such as n-grams, Convolutional Neural Networks (CNN), Recurrent units, Gated Recurrent Units (GRU), and even their combinations to recognize text-based online hate speech. Even though they were able to give satisfactory results, their contextual understanding of the text needed to be stronger as it is a bit of a complex concept. The main reasons these approaches fail are the non-availability of larger datasets to take full benefit of the model’s architecture and their lack of context understanding capability. In this work, we have explored the usage of one of the transformer-based architectures named A Lite Bidirectional Encoder Representations from Transformers (ALBERT) to address the problem of contextual understanding and recognize online textual hate speech efficiently with limited resources and a smaller dataset. Even in the untrained form, ALBERT provides a better understanding of context than any recurrent unit. Thus the ALBERT, pre-trained on a large corpus, gave the flexibility of using a smaller dataset to fine-tune them to a particular downstream task of hate speech identification as it already has a notion of language. ALBERT has already proved its contextual understanding capability with various benchmarked datasets, viz., SQuAD and GLUE. Thus, fine-tuning them to our downstream task allows utilizing this to our benefit. With this approach, we achieved better results than the state-of-art in terms of all four metrics: Precision (6.16%), Recall (6.59%), F1-Score (6.41%), and Accuracy (10.9%). © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.},
	author_keywords = {Fine-tuned ALBERT; Online hate speech; Social media},
	keywords = {Character recognition; Convolutional neural networks; Large dataset; Network architecture; Social networking (online); Speech recognition; Contextual understanding; Down-stream; Fine-tuned A lite bidirectional encoder representation from transformer; N-grams; Online environments; Online hate speech; Small data set; Social media; Social media platforms; Speech identification; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Information and Communication Technology for Intelligent Systems, ICTIS 2023; Conference date: 27 April 2023 through 28 April 2023; Conference code: 300129}
}

@CONFERENCE{Diallo2023121,
	author = {Diallo, Abdoul Karim and Abainia, Kheireddine},
	title = {Offensive Language Detection in Code-Mixed Bambara-French Corpus: Evaluating machine learning and deep learning classifiers},
	year = {2023},
	journal = {2023 International Conference on Decision Aid Sciences and Applications, DASA 2023},
	pages = {121 – 125},
	doi = {10.1109/DASA59624.2023.10286577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177466570&doi=10.1109%2fDASA59624.2023.10286577&partnerID=40&md5=75a85e9347a01ca4034c7990546c91da},
	affiliations = {Université 8 Mai 1945 Guelma, Guelma, Algeria; Université 8 Mai 1945 Guelma, PI:MIS Lab, Guelma, Algeria},
	abstract = {In this paper, we deal with offensive and abusive language detection on Bambara language, which is an under-resourced language mainly spoken in Mali and some other African countries. As a first work on this language, we aim to release OBAM v1.0 corpus compiling 4k of texts that are labeled as normal, offensive and abusive. In addition, we have carried out a set of experiments with different configurations using various machine learning and deep learning classifiers. In overall, the classifiers produced acceptable results (0.80 and 0.73 of F-score in two-category and three-category classification, respectively), but they could be improved by expanding the corpus and proposing new features.  © 2023 IEEE.},
	author_keywords = {Abusive language; Bambara Language; Mande languages; Offensive language},
	keywords = {Learning systems; Abusive language; Bambarum language; F-score; Language detection; Learning classifiers; Machine-learning; Mande language; Offensive languages; Three categories; Under-resourced languages; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Decision Aid Sciences and Applications, DASA 2023; Conference date: 16 September 2023 through 17 September 2023; Conference code: 193872}
}

@CONFERENCE{Jain20231144,
	author = {Jain, Archika and Sharma, Sandhya},
	title = {GUI: An Interface for Hate Speech Detection using NLP Technique},
	year = {2023},
	journal = {Proceedings of the 2023 2nd International Conference on Augmented Intelligence and Sustainable Systems, ICAISS 2023},
	pages = {1144 – 1148},
	doi = {10.1109/ICAISS58487.2023.10250527},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173624861&doi=10.1109%2fICAISS58487.2023.10250527&partnerID=40&md5=af85f2390bd9856867a21ed0c592400b},
	affiliations = {Suresh Gyan Vihar University, Department of Computer Engineering, Jaipur, India; Suresh Gyan Vihar University, Department of Electronics & Communication, Jaipur, India},
	abstract = {On social media, hate speech is a growing issue that has a harmful impact on both individuals and society at large. Social media platform moderators require technological help in order to recognize questionable material and respond appropriately. This article develops and discusses the design principles that provide the most successful user interfaces for decision support systems that leverage Artificial Intelligence (AI) technology to assist human moderators. An experiment has been done to show the effects of AI and explain the ability on end users' perceptions of cognitive effort, formativeness, mental model, and AI trustworthiness. Assessing perceived utility, perceived utility of use, and intention to use. Finally, the tweets are given as input to the proposed GUI model and then the GUI predict that tweet as hate or speech. © 2023 IEEE.},
	author_keywords = {Deep Learning Classifier; GUI; Hate Speech; LSTM; Machine Learning; NLP},
	keywords = {Decision support systems; Graphical user interfaces; Learning systems; Long short-term memory; Social networking (online); Deep learning classifier; Design Principles; Hate speech; Learning classifiers; LSTM; Machine-learning; Perceived utility; Social media; Social media platforms; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Augmented Intelligence and Sustainable Systems, ICAISS 2023; Conference date: 23 August 2023 through 25 August 2023; Conference code: 192825}
}

@CONFERENCE{Lai2023,
	author = {Lai, Mirko and Celli, Fabio and Ramponi, Alan and Tonelli, Sara and Bosco, Cristina and Patti, Viviana},
	title = {HaSpeeDe3 at EVALITA 2023: Overview of the Political and Religious Hate Speech Detection task},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173569480&partnerID=40&md5=e9a06683036bdaf8844539d3b3e48a14},
	affiliations = {Università degli Studi di Torino, Torino, Italy; Maggioli s.p.a., University of Trento, Trento, Italy; Fondazione Bruno Kessler (FBK), Trento, Italy},
	abstract = {The Hate Speech Detection (HaSpeeDe3) task is the third edition of a shared task on the detection of hateful content in Italian tweets. It differs from the previous editions while maintaining continuity in analysing and contrasting hate speech (HS) on social media. While HaSpeeDe and HaSpeeDe2 were focused on HS against immigrants, Muslims and Roms, HaSpeeDe3 explores hate speech in strong polarised debates, concerning in particular politics and religion. It is articulated in two different tasks: A) In-domain political hate speech detection and B) Cross-domain hate speech detection about political and religious tweets. Task A consists in two different subtasks for which participants i) can only use the provided textual content of the tweet, or ii) can additionally employ contextual information about the tweet and its author. In Task B, that consists in two subtasks, participants are allowed to use any kind of external data for detecting hate speech in tweets about i) politics and ii) religion. Six teams from both academia and industry participated in the evaluation, with a total of 13 submitted runs for Task A and 16 for Task B. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Hate speech detection; polarised debates; political hate speech; religious hate speech; shared task; social media analysis},
	keywords = {Social networking (online); Detection tasks; Hate speech detection; Polarized debate; Political hate speech; Religious hate speech; Shared task; Social media; Social media analysis; Speech detection; Subtask; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243}
}

@CONFERENCE{Krisdianto202391,
	author = {Krisdianto, Ricky and Apriani, Ivana and Halim, Peter Miracle and Anggreainy, Maria Susan and Kurniawan, Afdhal},
	title = {An Analysis of Hate Speech Detection Techniques},
	year = {2023},
	journal = {2023 4th International Conference on Artificial Intelligence and Data Sciences: Discovering Technological Advancement in Artificial Intelligence and Data Science, AiDAS 2023 - Proceedings},
	pages = {91 – 96},
	doi = {10.1109/AiDAS60501.2023.10284673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176581401&doi=10.1109%2fAiDAS60501.2023.10284673&partnerID=40&md5=9c1ba69a522a3e1751a722f50d6f95ff},
	affiliations = {School of Computer Science, Bina Nusantara University, Computer Science Departement, Jakarta, 11480, Indonesia; Bina Nusantara University, Binus Graduate Program Doctor of Computer Science, Computer Science Departement, Jakarta, 11480, Indonesia},
	abstract = {Hate speech is any act of provoking or insulting another person or group based on their ethnicity, religion, race, gender, sexual orientation, physical ability, or other characteristics. This can be done in a variety of ways. Because of this, a study was conducted that focused on ascertaining the most effective technique for identifying hate speech. It was discovered that LSTM, a form of recurrent neural network (RNN) that is particularly good at modeling sequential data, is the most successful technique to apply. Many natural language processing (NLP) activities may be performed with it, including hate speech detection, which makes LSTM have advantages over other techniques, both in terms of long-term memory mechanisms. LSTM, also able to handle long and complex text sequences, capable of recognizing more complex patterns, able to understand and consider the context in the text, to recognize the meaning of a word or phrase in a broader context. Then, based on the dataset obtained from the Kaggle website with a total of 24783 data, then the dataset is divided into training data and validation data, with a ratio of training data to validation data. of 80%: 20%. Then, the testing step results in an accuracy value of 87.10%. © 2023 IEEE.},
	author_keywords = {Dataset; Hate Speech Detection; Hate Speech Methods; LSTM},
	keywords = {Character recognition; Complex networks; Long short-term memory; Natural language processing systems; Dataset; Group-based; Hate speech detection; Hate speech method; LSTM; Sequential data; Sexual orientations; Speech detection; Training data; Validation data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Artificial Intelligence and Data Sciences, AiDAS 2023; Conference date: 6 September 2023 through 7 September 2023; Conference code: 193844}
}

@CONFERENCE{Leite2023631,
	author = {Leite, João A. and Scarton, Carolina and Silva, Diego F.},
	title = {Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {631 – 640},
	doi = {10.26615/978-954-452-092-2_068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179183673&doi=10.26615%2f978-954-452-092-2_068&partnerID=40&md5=4f0d2dbeeedf0884b7765f075b68ddcf},
	affiliations = {Department of Computer Science, The University of Sheffield, Sheffield, United Kingdom; Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos, Brazil},
	abstract = {Online social media is rife with offensive and hateful comments, prompting the need for their automatic detection given the sheer amount of posts created every second. Creating highquality human-labelled datasets for this task is difficult and costly, especially because nonoffensive posts are significantly more frequent than offensive ones. However, unlabelled data is abundant, easier, and cheaper to obtain. In this scenario, self-training methods, using weakly-labelled examples to increase the amount of training data, can be employed. Recent "noisy" self-training approaches incorporate data augmentation techniques to ensure prediction consistency and increase robustness against noisy data and adversarial attacks. In this paper, we experiment with default and noisy self-training using three different textual data augmentation techniques across five different pre-trained BERT architectures varying in size. We evaluate our experiments on two offensive/hate-speech datasets and demonstrate that (i) self-training consistently improves performance regardless of model size, resulting in up to +1.5% F1-macro on both datasets, and (ii) noisy self-training with textual data augmentations, despite being successfully applied in similar settings, decreases performance on offensive and hate-speech domains when compared to the default method, even with state-ofthe-art augmentations such as backtranslation. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Augmentation techniques; Automatic Detection; Data augmentation; Detection tasks; High quality; Labeled dataset; Online social medias; Self-training; Speech detection; Textual data; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference Recent Advances in Natural Language Processing: Large Language Models for Natural Language Processing, RANLP 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194755; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Alfarano20233,
	author = {Alfarano, Andrea and De Magistris, Giorgio and Mongelli, Leonardo and Russo, Samuele and Starczewski, Janusz and Napoli, Christian},
	title = {A Novel ConvMixer Transformer Based Architecture for Violent Behavior Detection},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14126 LNAI},
	pages = {3 – 16},
	doi = {10.1007/978-3-031-42508-0_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174445443&doi=10.1007%2f978-3-031-42508-0_1&partnerID=40&md5=b6ca1a685df9256614934a1274f8d6e6},
	affiliations = {Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Roma, 00185, Italy; Department of Psychology, Sapienza University of Rome, Via dei Marsi 78, Roma, 00185, Italy; Department of Computational Intelligence, Czestochowa University of Technology, al. Armii Krajowej 36, Czestochowa, 42-200, Poland; Institute for Systems Analysis and Computer Science, Italian National Research Council, Via dei Taurini 19, Roma, 00185, Italy},
	abstract = {Nowadays most of the streets, squares and buildings are monitored by a large number of surveillance cameras. Nevertheless, these cameras are used only to record scenes to be analyzed after crimes or thefts, and not to prevent violent actions in an automatic way. In few cases there may be a guard who checks the videos manually in real-time, but it is a very inefficient and expensive process. In this paper we proposes a novel approach to Violence Detection task using a recent architecture named ConvMixer, a simple CNN which uses patch-based embeddings in order to obtain superior performance with fewer parameters and computation resources. We also use an interesting technique that consists in arranging frames into super images to encode the temporal information into the spatial dimensions. Our tests on popular “Real Life Violence Situations” dataset highlight a remarkable accuracy of 0.95, placing our proposed model at the second position of the leader board on the same dataset. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Action Recognition; ConvMixer; SuperImage; Violence Detection},
	keywords = {Security systems; Statistical tests; Action recognition; Behavior detection; Convmixer; Detection tasks; Real- time; Simple++; Superimage; Surveillance cameras; Violence detections; Violent behavior; Cameras},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 22nd International Conference on Artificial Intelligence and Soft Computing, ICAISC 2023; Conference date: 18 June 2023 through 22 June 2023; Conference code: 300739}
}

@CONFERENCE{Dinh202395,
	author = {Dinh, Van-Co and Vo, Tran-Dai and Nguyen, Mai-Phuong T. and Do, Trong-Hop},
	title = {A Scalable Hate Speech Detection System for Vietnamese Social Media using Real-time Big Data Processing and Distributed Deep Learning},
	year = {2023},
	journal = {International Conference on Advanced Technologies for Communications},
	pages = {95 – 100},
	doi = {10.1109/ATC58710.2023.10318848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179125986&doi=10.1109%2fATC58710.2023.10318848&partnerID=40&md5=c7e7b1ca532a90bff640314d165e85ae},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {In this study, a system to detect hate and offensive social network comments in real-time using big data and distributed deep learning technology is presented. In the offline phase, state-of-the-art deep learning models are trained in a distributed manner using to BigDL library. The trained models are then integrated into the real-time big data processing component powered by Apache Spark, which a big data framework capable of processing a huge amount of comments in real-time. In the online phase, continuous stream of comments from Facebook are crawled and channeled through Kafka to this real-time big data processing component to output hate speech detection results. These results are then are then analyzed, and the statistical data is displayed in a web-app powered by Flask. Therefore, this work not only focuses on the accuracy but also emphasizes the system's practicality. Thanks to state-of-the-art deep learning models, the system can achieve high accuracy in the hate speech detection. With the deployed big data technology, the system can collect and process huge amounts of Facebook comments and produce statistical results in real-time.  © 2023 IEEE.},
	author_keywords = {Big data; Distributed Deep Learning; Hate speech detection; Real-time; Social network},
	keywords = {Data handling; Deep learning; Learning systems; Social networking (online); Social sciences computing; Speech recognition; Detection system; Distributed deep learning; Facebook; Hate speech detection; Learning models; Real- time; Social network; Speech detection; State of the art; Vietnamese; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 16th International Conference on Advanced Technologies for Communications, ATC 2023; Conference date: 19 October 2023 through 21 October 2023; Conference code: 194622}
}

@CONFERENCE{García-Díaz2023,
	author = {García-Díaz, José Antonio and Jiménez-Zafra, Salud María and Valencia-García, Rafael},
	title = {UMUTeam at HOMO-MEX 2023: Fine-tuning Large Language Models integration for solving hate-speech detection in Mexican Spanish},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175292947&partnerID=40&md5=c867e9a25aa1b620712cdab177cb50a4},
	affiliations = {Facultad de Informática, Universidad de Murcia, Campus de Espinardo, 30100, Spain; Computer Science Department, SINAI, CEATIC, Universidad de Jaén, 23071, Spain},
	abstract = {This work describes the participation of the UMUTeam in the HOMO-MEX shared task at IberLEF 2023, on Hate speech detection in Online Messages directed tOwards the MEXican Spanish speaking LGBTQ+ population. We have addressed the two proposed tasks: Task 1, consisting of identifying the category of hate speech and, Task 2, on determining the types of phobia from a given set of tweets. For both tasks, we have evaluated different approaches based on the combination of sentence embeddings using ensemble learning and knowledge integration. Specifically, the sentence embeddings have been extracted from several Spanish and multilingual Large Language Models after fine-tuning them for each task separately. In total, 11 teams participated in Task 1 and 9 teams in Task 2. The best run sent by our team placed in position 3rd for Task1 and position 8th for Task 2 with an F1-score of 0.842 and a macro-average F1-score of 0.669, respectively, with 0.885 and 0.696 being the results obtained by the teams ranked in 1st position. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Ensemble learning; Feature Engineering; Hate-speech Identification; Knowledge Integration; Natural Language Processing; Transformers},
	keywords = {Computational linguistics; Integration; Natural language processing systems; Speech recognition; Ensemble learning; Feature engineerings; Fine tuning; Hate-speech identification; Knowledge integration; Language processing; Natural language processing; Natural languages; Speech identification; Transformer; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@BOOK{Goswami2023331,
	author = {Goswami, Abhishek and Rawat, Ayushi and Tongaria, Shubham and Jhingran, Sushant},
	title = {Detection of hate speech in multi-modal social post},
	year = {2023},
	journal = {Artificial Intelligence, Blockchain, Computing and Security: Volume 1},
	volume = {1},
	pages = {331 – 336},
	doi = {10.1201/9781003393580-50},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180040582&doi=10.1201%2f9781003393580-50&partnerID=40&md5=92d9ea24e6362b0a025cefe9eabdf249},
	affiliations = {Sharda University, Greater Noida, India},
	abstract = {It has been observed in the past few years, multi-modal problems have been capable of attaining the interest of a large number of people. The core challenges faced in such problems are its representation, alignment, fusion, co-learning, and translation. The focus of this paper is on the analysis of multimodal memes for hate speech. On the evaluation of the dataset, we found out that the common statistics factors which were hateful initially became benign simply by unfolding the picture of the meme. Correspondingly, a bulk of the multi-modal baselines gives hate speech more options. In order to deal with such issues, we discover the visiblemodality through the use of item detection and image captioning fashions to realize the “real caption” after which we integrate it with multi-modal illustration to carry out binary classification. The method challenges the benign textual content co-founders present in the dataset to enhance the enactment. The second method that we use to test is to enhance the prediction with sentiment evaluation. It includes a unimodal sentiment to complement the features. Also we carry out in depth evaluation of the above methods stated, supplying compelling motives in want of the methodologies used. © 2024 selection and editorial matter, Arvind Dagur, Karan Singh, Pawan Singh Mehra & Dhirendra Kumar Shukla; individual chapters, the contributors.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mahardika2023256,
	author = {Mahardika, Muhammad Razi and Wijaya, I Putu Janardana and Prayoga, Arvin Rayhandi and Lucky, Henry and Iswanto, Irene Anindaputri},
	title = {Exploring the Performance of BERT Models for Multi-Label Hate Speech Detection on Indonesian Twitter},
	year = {2023},
	journal = {2023 4th International Conference on Artificial Intelligence and Data Sciences: Discovering Technological Advancement in Artificial Intelligence and Data Science, AiDAS 2023 - Proceedings},
	pages = {256 – 261},
	doi = {10.1109/AiDAS60501.2023.10284596},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176560455&doi=10.1109%2fAiDAS60501.2023.10284596&partnerID=40&md5=02aeff6bec7386c4a7aa7b7d3f34744f},
	affiliations = {School of Computer Science, Bina Nusantara University, Computer Science Department, Jakarta, Indonesia},
	abstract = {Due to its widespread distribution and the anonymity it offers users, hate speech on social media platforms, particularly Twitter, is a major problem. Because of Twitter's echo chamber algorithm and viral nature, hate speech can spread quickly and lead to societal unrest. The use of BERT-based models for hate speech identification in the Indonesian language has been studied in previous research. This study compares how well several pre-trained BERT models, IndoBERT and mBERT, perform in identifying hate speech on Twitter. The methodology includes gathering datasets, preparing the data, and utilizing the proper metrics to assess the models. IndoBERT successfully outperforms mBERT model according to the average of each evaluation metric shown. By carrying out this study, we hope to advance knowledge of techniques for identifying hate speech on Indonesian social media platforms and enhance the use of BERT models for such analysis. © 2023 IEEE.},
	author_keywords = {BERT; Hate Speech Detection; IndoBERT; mBERT; Twitter},
	keywords = {Social networking (online); BERT; Hate speech detection; IndoBERT; MBERT; Multi-labels; Performance; Social media platforms; Speech detection; Speech identification; Twitter; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th International Conference on Artificial Intelligence and Data Sciences, AiDAS 2023; Conference date: 6 September 2023 through 7 September 2023; Conference code: 193844}
}

@ARTICLE{Singh20231,
	author = {Singh, Ravinder and Subramani, Sudha and Du, Jiahua and Zhang, Yanchun and Wang, Hua and Miao, Yuan and Ahmed, Khandakar},
	title = {Antisocial Behavior Identification from Twitter Feeds Using Traditional Machine Learning Algorithms and Deep Learning.},
	year = {2023},
	journal = {EAI Endorsed Transactions on Scalable Information Systems},
	volume = {10},
	number = {4},
	pages = {1 – 17},
	doi = {10.4108/eetsis.v10i3.3184},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171575771&doi=10.4108%2feetsis.v10i3.3184&partnerID=40&md5=74d2ff3138fcfbeca431579f6b9e01ff},
	affiliations = {Institute for Sustainable Industries and Liveable Cities, Victoria University, Melbourne, Australia},
	abstract = {Antisocial behavior (ASB) is one of the ten personality disorders included in ‘The Diagnostic and Statistical Manual of Mental Disorders (DSM-5) and falls in the same cluster as Borderline Personality Disorder, Histrionic Personality Disorder, and Narcissistic Personality Disorder. It is a prevalent pattern of disregard for and violation of the rights of others. Online antisocial behavior is a social problem and a public health threat. An act of ASB might be fun for a perpetrator; however, it can drive a victim into depression, self-confinement, low self-esteem, anxiety, anger, and suicidal ideation. Online platforms such as Twitter and Reddit can sometimes become breeding grounds for such behavior by allowing people suffering from ASB disorder to manifest their behavior online freely. In this paper, we propose a proactive approach based on natural language processing and deep learning that can enable online platforms to actively look for the signs of antisocial behavior and intervene before it gets out of control. By actively searching for such behavior, social media sites can prevent dire situations leading to someone committing suicide. Copyright © 2023 Ravinder Singh et al., licensed to EAI. This is an open access article distributed under the terms of the CC BY-NCSA 4.0, which permits copying, redistributing, remixing, transformation, and building upon the material in any medium so long as the original work is properly cited.},
	author_keywords = {Antisocial Behavior Disorder; Behavior Classification; Deep Learning; Machine Learning; Online Antisocial Behavior; Personality Disorder},
	keywords = {Deep learning; E-learning; Health risks; Learning systems; Natural language processing systems; Social networking (online); Antisocial behavior; Antisocial behavior disorder; Behavior identifications; Behaviour classification; Deep learning; Machine-learning; Online antisocial behavior; Online platforms; Personality disorder; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Gajo2023,
	author = {Gajo, Paolo and Bernardini, Silvia and Ferraresi, Adriano and Barrón-Cedeño, Alberto},
	title = {Hate Speech Detection in an Italian Incel Forum Using Bilingual Data for Pre-Training and Fine-Tuning},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3596},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181170430&partnerID=40&md5=bf853a3165d7a823586002235717d318},
	affiliations = {Department of Interpreting and Translation, Università di Bologna, Corso della Repubblica, 136, FC, Forlì, 47121, Italy},
	abstract = {In this study, we aim to enhance hate speech detection in Italian incel posts. We pre-train monolingual (Italian) and multilingual Transformer models on corpora built from two incel forums, one in Italian and one in English, using masked language modeling. Then, we fine-tune the models on combinations of English and Italian corpora, annotated for hate speech. Experiments on a hate speech corpus derived from the Italian incel forum show that the best results are achieved by training multilingual models on bilingual data, rather than training monolingual models on Italian-only data. This emphasizes the importance of using training and testing data from a similar linguistic domain, even when the languages differ. Italiano. In questo studio, ci proponiamo di migliorare il rilevamento dei discorsi d'odio in post tratti da un forum italiano di incel. Addestriamo modelli Transformer mono (italiano) e multilingue su corpora ottenuti da due forum di incel, uno in italiano e uno in inglese, con il masked language modeling. Facciamo quindi il fine-tuning dei modelli su corpora in italiano e inglese con annotazioni indicanti se un post esprime odio. Sperimentando su un corpus annotato per i discorsi di odio ottenuto da un forum italiano di incel mostriamo che i risultati migliori si ottengono addestrando modelli multilingue su combinazioni bilingue di corpora e non con modelli italiani e dati monolingue. Ciò sottolinea l'importanza di utilizzare dati di addestramento appartenenti a un contesto linguistico simile a quello dei dati di valutazione, anche con lingue differenti. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {bert; hate speech; incels; masked language modeling; multilingual masked language modeling; multilingual mlm; transformers},
	keywords = {Modeling languages; Speech recognition; Bert; Hate speech; Incel; Language model; Masked language modeling; Multilingual masked language modeling; Multilingual mlm; Speech detection; Transformer; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th Italian Conference on Computational Linguistics, CLiC-it 2023; Conference date: 30 November 2023 through 2 December 2023; Conference code: 195716}
}

@CONFERENCE{Ocampo20232758,
	author = {Ocampo, Nicolas and Cabrio, Elena and Villata, Serena},
	title = {Playing the Part of the Sharp Bully: Generating Adversarial Examples for Implicit Hate Speech Detection},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2758 – 2772},
	doi = {10.18653/v1/2023.findings-acl.173},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175461585&doi=10.18653%2fv1%2f2023.findings-acl.173&partnerID=40&md5=7c9fd620b9cb5711a404b6f14e3d64ff},
	affiliations = {Universite Côte d'Azur, CNRS, Inria, I3S, France},
	abstract = {Research on abusive content detection on social media has primarily focused on explicit forms of hate speech (HS), that are often identifiable by recognizing hateful words and expressions. Messages containing linguistically subtle and implicit forms of hate speech still constitute an open challenge for automatic hate speech detection. In this paper, we propose a new framework for generating adversarial implicit HS short-text messages using Auto-regressive Language Models. Moreover, we propose a strategy to group the generated implicit messages by their complexity levels (EASY, MEDIUM, and HARD categories) characterizing how challenging these messages are for supervised classifiers. Finally, relying on (Dinan et al., 2019; Vidgen et al., 2021), we propose a “build it, break it, fix it”, training scheme using HARD messages showing how iteratively retraining on HARD messages substantially leverages SOTA models' performances on implicit HS benchmarks. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Auto-regressive; Complexity levels; Content detection; Explicit form; Implicit form; Language model; Short text messages; Social media; Speech detection; Supervised classifiers; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Singh2023136,
	author = {Singh, Karanpreet and Vajrobol, Vajratiya and Aggarwal, Nitisha},
	title = {IIC Team@Multimodal Hate Speech Event Detection 2023: Detection of Hate Speech and Targets using Xlm-Roberta-base},
	year = {2023},
	journal = {CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023},
	pages = {136 – 143},
	doi = {10.26615/978-954-452-089-2_018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180396051&doi=10.26615%2f978-954-452-089-2_018&partnerID=40&md5=53082087f74540dbab0e2373b3438839},
	affiliations = {Institute of Informatics and Communication, University of Delhi, Delhi, India},
	abstract = {Hate speech has emerged as a pressing issue on social media platforms, fueled by the increasing availability of multimodal data and easy internet access. Addressing this problem requires collaborative efforts from researchers, policymakers, and online platforms. In this study, we investigate the detection of hate speech in multimodal data, comprising text-embedded images, by employing advanced deep learning models. The main objective is to identify effective strategies for hate speech detection and content moderation. We conducted experiments using four state-of-the-art classifiers: XLM-Roberta-base, BiLSTM, XLNet base cased, and ALBERT, on the CrisisHateMM dataset, consisting of over 4700 text-embedded images related to the Russia-Ukraine conflict. The best findings reveal that XLM-Roberta-base exhibits superior performance, outperforming other classifiers across all evaluation metrics, including an impressive F1 score of 84.62 for sub-task 1 and 69.73 for sub-task 2. Additionally, it is worth highlighting that our study achieved the remarkable feat of securing the 3rd position in both sub-tasks. The future scope of this study lies in exploring multimodal approaches to enhance hate speech detection accuracy, integrating ethical considerations to address potential biases, promoting fairness, and safeguarding user rights. Additionally, leveraging larger and more diverse datasets will contribute to developing more robust and generalised hate speech detection solutions. © CASE 2023 - Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, associated with 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023.},
	keywords = {Classification (of information); Deep learning; Natural language processing systems; Embedded images; Events detection; Internet access; Multi-modal; Multi-modal data; Pressung; Social media platforms; Speech detection; Speech events; Subtask; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 6th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2023; Conference date: 7 September 2023; Conference code: 196554}
}

@CONFERENCE{Mnassri20232852,
	author = {Mnassri, Khouloud and Rajapaksha, Praboda and Farahbakhsh, Reza and Crespi, Noel},
	title = {Hate Speech and Offensive Language Detection Using an Emotion-Aware Shared Encoder},
	year = {2023},
	journal = {IEEE International Conference on Communications},
	volume = {2023-May},
	pages = {2852 – 2857},
	doi = {10.1109/ICC45041.2023.10279690},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178301123&doi=10.1109%2fICC45041.2023.10279690&partnerID=40&md5=537f96ef1d3abf0c8384a56d517e2b1c},
	affiliations = {Institut Polytechnique de Paris, Samovar, Telecom SudParis, Palaiseau, 91120, France},
	abstract = {The rise of emergence of social media platforms has fundamentally altered how people communicate, and among the results of these developments is an increase in online use of abusive content. Therefore, automatically detecting this content is essential for banning inappropriate information, and reducing toxicity and violence on social media platforms. The existing works on hate speech and offensive language detection produce promising results based on pre-trained transformer models, however, they considered only the analysis of abusive content features generated through annotated datasets. This paper addresses a multi-task joint learning approach which combines external emotional features extracted from another corpora in dealing with the imbalanced and scarcity of labeled datasets. Our analysis are using two well-known Transformer-based models, BERT and mBERT, where the later is used to address abusive content detection in multi-lingual scenarios. Our model jointly learns abusive content detection with emotional features by sharing representations through transformers' shared encoder. This approach increases data efficiency, reduce overfitting via shared representations, and ensure fast learning by leveraging auxiliary information. Our findings demonstrate that emotional knowledge helps to more reliably identify hate speech and offensive language across datasets. Our hate speech detection Multi-task model exhibited 3% performance improvement over baseline models, but the performance of multi-task models were not significant for offensive language detection task. More interestingly, in both tasks, multi-task models exhibits less false positive errors compared to single task scenario.  © 2023 IEEE.},
	author_keywords = {BERT; emotional knowledge; Hate speech; Multi-task learning; Multilingual BERT; Natural Language Processing; offensive language; shared encoder; Social media; Twitter},
	keywords = {Feature extraction; Linguistics; Natural language processing systems; Signal encoding; Social networking (online); Speech recognition; BERT; Emotional knowledge; Hate speech; Language processing; Multilingual BERT; Multitask learning; Natural language processing; Natural languages; Offensive languages; Shared encoder; Social media; Twitter; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 IEEE International Conference on Communications, ICC 2023; Conference date: 28 May 2023 through 1 June 2023; Conference code: 193943; All Open Access, Green Open Access}
}

@ARTICLE{Gandhi2023241,
	author = {Gandhi, Hetvi and Bachwani, Rounak and Nanade, Archana},
	title = {Detecting Toxic Comments Using FastText, CNN, and LSTM Models},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1848 CCIS},
	pages = {241 – 252},
	doi = {10.1007/978-3-031-37940-6_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172267857&doi=10.1007%2f978-3-031-37940-6_20&partnerID=40&md5=287d44896e29ed9ef5872344b247b56d},
	affiliations = {Computer Engineering Department, Mukesh Patel School of Technology Management, and Engineering, NMIMS University, Mumbai, India},
	abstract = {The use of social media has become a necessary daily activity. It provides a platform to share news, information, and social interaction. However, many people now take social media platforms for granted, using them to harass and threaten others, which results in cyberbullying. Toxic comments are online remarks that are insulting, abusive, or inappropriate, and frequently cause other users to quit a debate. People are unable to openly express their thoughts owing to cyberbullying and harassment. Identifying and classifying such remarks by hand is a time-consuming, inefficient, and unreliable operation. To solve this issue, this research article focuses on developing a deep learning system to analyze toxicity and produce efficient results in order to restrict its negative consequences, which will aid institutions to put the necessary measures into practice. Our proposed model uses Long Short-Term Memory (LSTM) along with FastText word embedding, resulting in a model with high performance. To make the social networking experience better, this model tries to improve the detection of different sorts of toxicity. Toxic, Severe Toxic, Obscene, Threat, Insult, and Identity-hate are the six categories that our methodology divides such comments into. Multi-Label Classification aids us in providing an automatic answer to the problem of poisonous remarks that were faced. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Convolutional Neural Network (CNN); FastText; Long Short-Term Memory (LSTM); Natural language processing (NLP); Text classification; Toxic comments},
	keywords = {Brain; Classification (of information); Computer crime; Convolutional neural networks; Learning systems; Natural language processing systems; Social networking (online); Text processing; Toxicity; Convolutional neural network; Cyber bullying; Fasttext; Language processing; Long short-term memory; Natural language processing; Natural languages; Text classification; Toxic comment; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Proceedings of the 7th International Conference on Advances in Computing and Data Sciences, ICACDS 2023; Conference date: 27 April 2023 through 28 April 2023; Conference code: 298639}
}

@CONFERENCE{Shahiki-Tash2023,
	author = {Shahiki-Tash, Moein and Armenta-Segura, Jesús and Ahani, Zahra and Kolesnikova, Olga and Sidorov, Grigori and Gelbukh, Alexander},
	title = {LIDOMA at HOMO-MEX2023@IberLEF: Hate Speech Detection Towards the Mexican Spanish-Speaking LGBT+ Population. The Importance of Preprocessing Before Using BERT-Based Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175302371&partnerID=40&md5=17194ed3b0e3c341873c43bb1aecd4f6},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico city, Mexico Instituto Politécnico Nacional, Centro de Investigación en Computación (CIC IPN), Juan de Dios Bátiz Av., Gustavo A. Madero, Ciudad de México, 07738, Mexico},
	abstract = {Hate speech targeting LGBT+ individuals poses a deeply ingrained problem with wide-ranging consequences, encompassing substance abuse disorders and discrimination. These specific concerns are particularly amplified in Mexico. In this paper, we present our submission on the first track of the HOMO-MEX: Hate Speech Detection towards the Mexican Spanish-Speaking LGBT+ Population. We explore the dataset and we employ transformer architectures, who have demonstrated significant efficacy in similar sentiment analysis tasks. Specifically, we utilize BERT-based models and we show the importance of preprocessing by reaching the last place in the competition with a Macro F1 score of 0.73. The source code to reproduce our results can be found at https://github.com/moeintash72. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT-based models; CEUR-WS; Hate Speech Detection; LGBT+phobia; Natural Language Processing; Preprocessing},
	keywords = {Speech recognition; BERT-based model; CEUR-WS; Hate speech detection; Language processing; LGBT+phobia; Natural language processing; Natural languages; Preprocessing; Speech detection; Substance abuse; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference date: 26 September 2023; Conference code: 193167}
}

@ARTICLE{Molero202395639,
	author = {Molero, Jose Maria and Perez-Martin, Jorge and Rodrigo, Alvaro and Penas, Anselmo},
	title = {Offensive Language Detection in Spanish Social Media: Testing from Bag-of-Words to Transformers Models},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {95639 – 95652},
	doi = {10.1109/ACCESS.2023.3310244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169683958&doi=10.1109%2fACCESS.2023.3310244&partnerID=40&md5=2041eb2158f0f4d836a958cdf12dcfe7},
	affiliations = {Universidad Nacional de Educación A Distancia (UNED), Computer Engineering School, Madrid, 28040, Spain},
	abstract = {Social networks allow us to communicate with people around the world. However, some users usually take advantage of anonymity for writing offensive comments to others, which might affect those who receive offensive messages or discourage the use of these networks. However, it is impossible to manually check every message. This has promoted several proposals for automatic detection systems. Current state-of-the-art systems are based on the transformers' architecture and most of the work has been focused on the English language. However, these systems do not pay too much attention to the unbalanced nature of data, since there are fewer offensive comments than non-offensive in a real environment. Besides, these previous works have not studied the impact on the final results of pre-processing or the corpora used for pre-training the models. In this work, we propose and evaluate a series of automatic methods aimed at detecting offensive language in Spanish texts addressing the unbalanced nature of data. We test different learning models, from those based on classical Machine Learning algorithms using Bag-of-Words as data representation to those based in large language models and neural networks such as transformers, paying more attention to minor classes and the corpora used for pre-training the transformer-based models. We show how transformer-based models continue obtaining the best results, but we improved previous results by a 6,2% by adding new steps of pre-processing and using models pre-trained with Spanish social-media data, setting new state-of-the-art results.  © 2013 IEEE.},
	author_keywords = {natural language processing; Offensive language; transformers-based models},
	keywords = {Blogs; Electric transformer testing; Learning algorithms; Learning systems; Sentiment analysis; Social networking (online); Features extraction; Hate speech; Language processing; Natural language processing; Natural languages; Offensive languages; Social networking (online); Task analysis; Transformer; Transformer-based model; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{Zhou20238,
	author = {Zhou, Li and Cabello, Laura and Cao, Yong and Hershcovich, Daniel},
	title = {Cross-Cultural Transfer Learning for Chinese Offensive Language Detection},
	year = {2023},
	journal = {EACL 2023 - Cross-Cultural Considerations in NLP @ EACL, Proceedings of the Workshop},
	pages = {8 – 15},
	doi = {10.18653/v1/2023.c3nlp-1.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174993994&doi=10.18653%2fv1%2f2023.c3nlp-1.2&partnerID=40&md5=7dbd142abd1a58201702fc76f8119c1c},
	affiliations = {University of Electronic Science and Technology of China, China; Department of Computer Science, University of Copenhagen, Denmark; Huazhong University of Science and Technology, China},
	abstract = {Detecting offensive language is a challenging task. Generalizing across different cultures and languages becomes even more challenging: besides lexical, syntactic and semantic differences, pragmatic aspects such as cultural norms and sensitivities, which are particularly relevant in this context, vary greatly. In this paper, we target Chinese offensive language detection and aim to investigate the impact of transfer learning using offensive language detection data from different cultural backgrounds, specifically Korean and English. We find that culture-specific biases in what is considered offensive negatively impact the transferability of language models (LMs) and that LMs trained on diverse cultural data are sensitive to different features in Chinese offensive language detection. In a few-shot learning scenario, however, our study shows promising prospects for non-English offensive language detection with limited resources. Our findings highlight the importance of cross-cultural transfer learning in improving offensive language detection and promoting inclusive digital spaces. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Transfer learning; Cultural backgrounds; Cultural norms; Digital space; Language detection; Language model; Learning scenarios; Offensive languages; Semantic difference; Transfer learning; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 1st Workshop on Cross-Cultural Considerations in NLP, C3NLP 2023; Conference date: 5 May 2023; Conference code: 192794; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Acar2023267,
	author = {Acar, Ayse Nida and Omurca, Sevinc Ilhan},
	title = {Offensive Language Detection in Social Media for Turkish Language},
	year = {2023},
	journal = {UBMK 2023 - Proceedings: 8th International Conference on Computer Science and Engineering},
	pages = {267 – 270},
	doi = {10.1109/UBMK59864.2023.10286812},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177556079&doi=10.1109%2fUBMK59864.2023.10286812&partnerID=40&md5=0a45e6e401a767044ebc0012f392137d},
	affiliations = {Kocaeli University, Department of Computer Engineering, Kocaeli, Turkey},
	abstract = {It is known that the use of offensive language in social media posts has increased considerably in recent years. In this study, it is aimed to determine the use of offensive language in Turkish language. A comprehensive and original data set was obtained by combining two data sets previously used in the literature. There are 31277 data in the first data set (Offenseval-2020) and 35285 data in the second data set (A Corpus of Turkish Offensive Language-troff). The first data set, the second data set and the original data set created from them were preprocessed separately. Afterwards, three data sets were trained in the model created by the LSTM method. The model was tested with 20% of the data set. The experimental results of the study were measured using metrics such as accuracy, precision score, F1 score, and sensitivity score. With the new data set created, higher success has been achieved compared to other data sets. With these successful results, a contribution has been made to the literature in order to determine the use of offensive language in the Turkish language. © 2023 IEEE.},
	author_keywords = {Cyberbullying; Offensive Language; Text Classification; Turkish},
	keywords = {Classification (of information); Long short-term memory; Social networking (online); Cyber bullying; Data set; F1 scores; Language detection; Offensive languages; Social media; Text classification; Turkish language; Turkishs; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 8th International Conference on Computer Science and Engineering, UBMK 2023; Conference date: 13 September 2023 through 15 September 2023; Conference code: 193873}
}@CONFERENCE{Bourgeade20233477,
	author = {Bourgeade, Tom and Chiril, Patricia and Benamara, Farah and Moriceau, Véronique},
	title = {What Did You Learn To Hate? A Topic-Oriented Analysis of Generalization in Hate Speech Detection},
	year = {2023},
	journal = {EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {3477 – 3490},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159850455&partnerID=40&md5=35813b286595b6b0c000c5acc0c494ab},
	affiliations = {IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; IPAL, CNRS-NUS-ASTAR, Singapore; University of Chicago, Chicago, IL, United States},
	abstract = {Warning: This paper includes messages that may contain instances of vulgarity, degrading terms, or hate speech, which may be offensive or upsetting to some readers. Hate speech has unfortunately become a significant phenomenon on social media platforms, and it can cover various topics (misogyny, sexism, racism, xenophobia, etc.) and targets (e.g., black people, women). Various hate speech detection datasets have been proposed, some annotated for specific topics, and others for hateful speech in general. In either case, they often employ different annotation guidelines, which can lead to inconsistencies, even in datasets focusing on the same topics. This can cause issues in models trying to generalize across more data and more topics in order to improve detection accuracy. In this paper, we propose, for the first time, a topic-oriented approach to study generalization across popular hate speech datasets. We first perform a comparative analysis of the performances of Transformer-based models in capturing topic-generic and topic-specific knowledge when trained on different datasets. We then propose a novel, simple yet effective approach to study more precisely which topics are best captured in implicit manifestations of hate, showing that selecting combinations of datasets with better out-of-domain topical coverage improves the reliability of automatic hate speech detection. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Comparative analyzes; Detection accuracy; Generalisation; Learn+; Performance; Simple++; Social media platforms; Specific knowledge; Speech detection; Topic-oriented; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424}
}

@CONFERENCE{Ava20231527,
	author = {Ava, Lamima Tabassum and Karim, Asif and Hassan, Md. Mehedi and Faisal, Fahad and Azam, Sami and Al Haque, A.S.M. Farhan and Zaman, Sadika},
	title = {Intelligent identification of hate speeches to address the increased rate of individual mental degeneration},
	year = {2023},
	journal = {Procedia Computer Science},
	volume = {219},
	pages = {1527 – 1537},
	doi = {10.1016/j.procs.2023.01.444},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164249529&doi=10.1016%2fj.procs.2023.01.444&partnerID=40&md5=6f09890d101410ddc807d910e21a42c6},
	affiliations = {Computer Science and Engineering, Bangladesh University of Business and Technology Dhaka, Bangladesh; College of Engineering, IT and Environment, Charles Darwin University, NT, Australia; Department of Computer Science and Engineering, North Western University, Khulna, Bangladesh; Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh; Department of Electronic Systems, Aalborg University Copenhagen, Denmark; Department of Computer Science and Engineering, North Western University, Khulna, Bangladesh},
	abstract = {Hate speech is a public statement that demonstrates resentment or provokes disturbance towards a person or group often based upon race, age, religion, sexual orientation, minority group, psychical disability, political belief, etc. Such an act is a leading cause of mental degeneration in individuals observed throughout the world. We have witnessed an upsurge in the spreading of hateful speech through videos in recent times due to increased social media usage. Researchers are working on this issue because it has become more frequent on several social media platforms, and it leads to low self-esteem and has significant negative impacts on human life. In this work, we focus on collecting data from such videos as nowadays people are sharing numerous videos of this negative nature on platforms like Facebook and YouTube. The audio data of these videos were then converted into text to build the dataset, and we applied some classifier models to our dataset. In this paper, we utilized a transfer learning Bidirectional Encoder Representations from Transformers (BERT) model that gives state-of-The-Art outcomes. More precisely, we fine-Tuned our model based on transfer learning to evaluate BERT's capacity to capture hostile contexts inside YouTube videos. We examined Fine-Tuning BERT; with different learning rates and listed the outcomes. We train the BERT by freezing all the hyperparameters but with various random seeds to evaluate our suggested Fine-Tuning approach. Compared to previous methodologies that used our dataset, our proposition fared better in terms of accuracy and execution time.  © 2022 The Authors. Published by ELSEVIER B.V.},
	author_keywords = {Hate Speech; Hyperparameter; MP4 to Text; BERT; NLP; Random Seed},
	keywords = {Learning systems; Social networking (online); Transfer learning; Bidirectional encoder representation from transformer; Fine tuning; Hate speech; Hyper-parameter; Intelligent identification; MP4 to text;; Random seeds; Sexual orientations; Transfer learning; YouTube; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 International Conference on ENTERprise Information Systems, CENTERIS 2022 - International Conference on Project MANagement, ProjMAN 2022 and International Conference on Health and Social Care Information Systems and Technologies, HCist 2022; Conference date: 9 November 2022 through 11 November 2022; Conference code: 189385; All Open Access, Gold Open Access}
}

@CONFERENCE{Patil2023322,
	author = {Patil, Prachi and Raul, Sakshi and Raut, Dhanisha and Nagarhalli, Tatwadashi},
	title = {Hate Speech Detection using Deep Learning and Text Analysis},
	year = {2023},
	journal = {Proceedings of the 7th International Conference on Intelligent Computing and Control Systems, ICICCS 2023},
	pages = {322 – 330},
	doi = {10.1109/ICICCS56967.2023.10142895},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163802541&doi=10.1109%2fICICCS56967.2023.10142895&partnerID=40&md5=d45bbec8d194a1e9d64e388beac83fa5},
	affiliations = {University of Mumbai, Computer Engineering Vidyavardhinis' College of Engg. and Tech., Vasai, India},
	abstract = {Hate speech is any form of speech, gesture, written or physical expression that threatens a person or a group based on their race, ethnicity, religion, gender, sexual orientation, nationality, disability, or any other characteristic that is protected by law. Hate speech can take many forms, ranging from verbal harassment to physical violence. Hate speech detection has become an important task in NLP due to the growing frequency of hate speech on online forums and social media. The proposed research work aims to improve hate speech detection by doing modification in standard i.e., Modified bi-LS TM model vs RCNN. The study examines how well the modified model performs on tasks involving the classification of hate speech when compared to a conventional LS TM model. The improved bi-LS TM model is intended to capture the context and relationships more accurately between the words in hate speech utterances.The study uses a publicly accessible dataset of tweets containing hate speech and tweets without any hate speech. The proposed model is trained and tested with the help of various performance metrics such as F1-score, accuracy and precision, recall. The research outcomes show that the proposed model outperforms the standard IS TM model in detecting hate speech. © 2023 IEEE.},
	author_keywords = {ANN (Artificial Neural Network); BERT; Bi-LSTM (Bidirectional Long Short-Term Memory); CNN (Convolutional Neural Network); DCNN (Deep Convolution Neural Network; Deep Learning (DL); GRU (Gated Recurrent Unit); Lexical Syntactical Feature (LSF); LSTM (long short-term memory networks); Recurrent Convolutional Neural Network(RCNN); RNN (Recurrent Neural Network); SVM (Support Vector Machine)},
	keywords = {Brain; Convolution; Convolutional neural networks; Deep neural networks; Learning systems; Social networking (online); Speech recognition; Support vector machines; Artificial neural network; BERT; Bidirectional long short-term memory; Convolution neural network; Convolutional neural network; DCNN (deep convolution neural network; Deep learning; Gated recurrent unit; Lexical syntactical feature; Long short-term memory network; Memory network; Recurrent convolutional neural network; Recurrent neural network; Support vector machine; Support vectors machine; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th International Conference on Intelligent Computing and Control Systems, ICICCS 2023; Conference date: 17 May 2023 through 19 May 2023; Conference code: 189354}
}

@CONFERENCE{Reddy2023,
	author = {Reddy, B. Ajay Chandrasekhar and Chandra, Girish Kumar and Sisodia, Dilip Singh and Anuragi, Arti},
	title = {Balancing Techniques for Improving Automated Detection of Hate Speech and Offensive Language on Social Media},
	year = {2023},
	journal = {2023 2nd International Conference for Innovation in Technology, INOCON 2023},
	doi = {10.1109/INOCON57975.2023.10101157},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157963238&doi=10.1109%2fINOCON57975.2023.10101157&partnerID=40&md5=1946a909e70f92283fafa01ef0440283},
	affiliations = {National Institute of Technology, Department of Computer Science and Engineering, Raipur, India},
	abstract = {On social media networks like Twitter, Facebook, and Tumblr, people frequently share information. However, these platforms are also notorious for the spread of hate speech and insults, often posted anonymously. Hate speech involves using violent, abusive, or aggressive language towards a particular group based on factors such as gender, race, religion, or region. The prevalence of hate speech on these websites is a major concern, and manually detecting it can be time-consuming. To address this issue, this study presents an automated hate speech detection model that is evaluated on a publicly available Twitter dataset. The proposed method emphasizes data pre-processing, including stemming, term frequency-inverse document frequency (TF-IDF) for feature extraction, and various sampling techniques (random sampler, synthetic minority over-sampling technique (SMOTE), and ALL-KNN) to balance an imbalanced dataset. The logistic regression, support vector machine (SVM), and k-nearest neighbor (k-NN) machine learning classifiers were trained and tested using hold-out cross-validation to reduce overfitting and evaluate performance. The performance was evaluated using metrics such as accuracy, precision, and confusion matrix. The results showed that the logistic regression classifier using the SMOTE approach had the best performance, with an accuracy of 82%, a macro average of precision, recall, and an F1-score of 80%, 82%, and 79%, respectively.  © 2023 IEEE.},
	author_keywords = {Hate speech; logistic regression; offensive language; Sampling techniques; Sentimental analysis; TF-ID features},
	keywords = {Balancing; Data handling; Feature extraction; Inverse problems; Learning systems; Nearest neighbor search; Social networking (online); Support vector machines; Text processing; Automated detection; Balancing techniques; Hate speech; Logistics regressions; Offensive languages; Performance; Sampling technique; Sentimental analyse; Synthetic minority over-sampling techniques; TF-ID feature; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2nd International Conference for Innovation in Technology, INOCON 2023; Conference date: 3 March 2023 through 5 March 2023; Conference code: 188077}
}

@CONFERENCE{Pamungkas2022104,
	author = {Pamungkas, Endang Wahyu and Fatmawati, Azizah and Salam, Farah Danisha},
	title = {Hate Speech Detection on Indonesian Social Media: A Preliminary Study on Code-Mixed Language Issue},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {104 – 109},
	doi = {10.1145/3582768.3582771},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168772661&doi=10.1145%2f3582768.3582771&partnerID=40&md5=5ed5d59af84200b8aab7890a1fd4ebf5},
	affiliations = {Informatics Department, Universitas Muhammadiyah Surakarta, Central Java, Surakarta, Indonesia},
	abstract = {Nowadays, social media becomes an important media for online communication, facilitating its users to publish content and providing a medium to express their opinions and feelings about anything. At the same time, abusive language is becoming a relevant problem on social media platforms such as Facebook and Twitter. Geographically, Indonesia consists of several regions with their own local languages. A recent report shows 718 local languages used by different regions and tribes in Indonesia. Indonesian tend to use a mix of their own local language and Bahasa to communicate on social media platforms, such as Twitter. Similar to other languages, code-mixed is also becoming the main issue and challenge of detecting hate speech in Indonesian social media. In this study, we conduct a preliminary experiment to study the detection of hate speech in Indonesian social media, specifically Twitter. Our experiment used 6,115 tweets in Indonesian-Javanese code-mixed and 2,945 tweets in Indonesian-Sundanese code-mixed. The overall results show that the traditional machine learning model with lexical-based features obtained the best performance in Javanese-Indonesian, while the LSTM network achieved the best performance in Sundanese-Indonesian. We also found that translating the code-mixed data into more resource-rich languages could not help to improve the classification performance.  © 2022 ACM.},
	keywords = {Long short-term memory; Speech recognition; Facebook; Indonesia; Issues and challenges; Local language; Machine learning models; On-line communication; Performance; Social media; Social media platforms; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th International Conference on Natural Language Processing and Information Retrieval, NLPIR 2022; Conference date: 16 December 2022 through 18 December 2022; Conference code: 191070}
}

@ARTICLE{Park2023813,
	author = {Park, Semi and Lee, Kyungho},
	title = {Tackling Faceless Killers: Toxic Comment Detection to Maintain a Healthy Internet Environment},
	year = {2023},
	journal = {Computers, Materials and Continua},
	volume = {76},
	number = {1},
	pages = {813 – 826},
	doi = {10.32604/cmc.2023.035313},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164284764&doi=10.32604%2fcmc.2023.035313&partnerID=40&md5=71d707db8b8c6ced4126b7e478f8ef0d},
	affiliations = {School of Cybersecurity, Korea University, Seoul, 02841, South Korea},
	abstract = {According to BBC News, online hate speech increased by 20% during the COVID-19 pandemic. Hate speech from anonymous users can result in psychological harm, including depression and trauma, and can even lead to suicide. Malicious online comments are increasingly becoming a social and cultural problem. It is therefore critical to detect such comments at the national level and detect malicious users at the corporate level. To achieve a healthy and safe Internet environment, studies should focus on institutional and technical topics. The detection of toxic comments can create a safe online environment. In this study, to detect malicious comments, we used approximately 9,400 examples of hate speech from a Korean corpus of entertainment news comments. We developed toxic comment classification models using supervised learning algorithms, including decision trees, random forest, a support vector machine, and K-nearest neighbors. The proposed model uses random forests to classify toxic words, achieving an F1-score of 0.94. We analyzed the trained model using the permutation feature importance, which is an explanatory machine learning method. Our experimental results confirmed that the toxic comment classifier properly classified hate words used in Korea. Using this research methodology, the proposed method can create a healthy Internet environment by detecting malicious comments written in Korean. © 2023 Tech Science Press. All rights reserved.},
	author_keywords = {healthy internet environment; machine learning; Toxic comments; toxic text classification},
	keywords = {Classification (of information); Learning algorithms; Learning systems; Nearest neighbor search; Support vector machines; Text processing; Corporate level; Healthy internet environment; Internet environment; Machine-learning; National level; Online environments; Random forests; Text classification; Toxic comment; Toxic text classification; Decision trees},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Srikissoon2023203,
	author = {Srikissoon, Trishanta and Marivate, Vukosi},
	title = {Combating Hate: How Multilingual Transformers Can Help Detect Topical Hate Speech},
	year = {2023},
	journal = {EPiC Series in Computing},
	volume = {93},
	pages = {203 – 215},
	doi = {10.29007/1cm6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161627890&doi=10.29007%2f1cm6&partnerID=40&md5=948fb1e7919189327681a17624d24d90},
	affiliations = {Department of Computer Science, University of Pretoria, South Africa},
	abstract = {Automated hate speech detection is important to protecting people’s dignity, online experiences, and physical safety in Society 5.0. Transformers are sophisticated pre-trained language models that can be fine-tuned for multilingual hate speech detection. Many studies consider this application as a binary classification problem. Additionally, research on topical hate speech detection use target-specific datasets containing assertions about a particular group. In this paper we investigate multi-class hate speech detection using target-generic datasets. We assess the performance of mBERT and XLM-RoBERTA on high and low resource languages, with limited sample sizes and class imbalance. We find that our fine-tuned mBERT models are performant in detecting gender-targeted hate speech. Our Urdu classifier produces a 31% lift on the baseline model. We also present a pipeline for processing multilingual datasets for multi-class hate speech detection. Our approach could be used in future works on topically focused hate speech detection for other low resource languages, particularly African languages which remain under-explored in this domain. © 2023, EasyChair. All rights reserved.},
	keywords = {Pipeline processing systems; African languages; Baseline models; Binary classification problems; Class imbalance; Language model; Low resource languages; Performance; Sample sizes; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Society 5.0, 2023; Conference date: 5 June 2023 through 6 June 2023; Conference code: 295199; All Open Access, Bronze Open Access}
}

@CONFERENCE{Park20231112,
	author = {Park, San-Hee and Kim, Kang-Min and Lee, O-Joun and Kang, Youjin and Lee, Jaewon and Lee, Su-Min and Lee, SangKeun},
	title = {“Why do I feel offended?’ Korean Dataset for Offensive Language Identification},
	year = {2023},
	journal = {EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023},
	pages = {1112 – 1123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159861064&partnerID=40&md5=2254d92b7017f8d1af54b537823ded7b},
	affiliations = {Korea University, Seoul, South Korea; The Catholic University of Korea, Bucheon, South Korea; Seoul National University, Seoul, South Korea},
	abstract = {Offensive content is an unavoidable issue on social media. Most existing offensive language identification methods rely on the compilation of labeled datasets. However, existing methods rarely consider low-resource languages that have relatively less data available for training (e.g., Korean). To address these issues, we construct a novel KOrean Dataset for Offensive Language Identification (KODOLI). KODOLI comprises more fine-grained offensiveness categories (i.e., not offensive, likely offensive, and offensive) than existing ones. A likely offensive language refers to texts with implicit offensiveness or abusive language without offensive intentions. In addition, we propose two auxiliary tasks to help identify offensive languages: abusive language detection and sentiment analysis. We provide experimental results for baselines on KODOLI and observe that pre-trained language models suffer from identifying "LIKELY" offensive statements. Quantitative results and qualitative analysis demonstrate that jointly learning offensive language, abusive language and sentiment information improves the performance of offensive language identification. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Fine grained; Identification method; Labeled dataset; Language detection; Language identification; Language model; Low resource languages; Offensive languages; Sentiment analysis; Social media; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023 - Findings of EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188432}
}

@CONFERENCE{Rishab2023600,
	author = {Rishab, K.S. and Mayuravarsha, P. and Yashwal, K.S. and Mr, Pranav and Ravish, Roopa},
	title = {Detection of Violent Content in Videos using Audio Visual Features},
	year = {2023},
	journal = {IEEE International Conference on Advances in Electronics, Communication, Computing and Intelligent Information Systems, ICAECIS 2023 - Proceedings},
	pages = {600 – 605},
	doi = {10.1109/ICAECIS58353.2023.10170034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166380479&doi=10.1109%2fICAECIS58353.2023.10170034&partnerID=40&md5=76e3d9bcc2c5c240042602c0c543e42e},
	affiliations = {Pes University, Department of Computer Science, Bengaluru, India},
	abstract = {Content moderation is an essential part of the internet, which makes the internet a safe place for people of all age groups. Content moderation is usually done manually by humans, who flag the content as violent or non-violent. The content moderators are exposed to various violent content, which affects them mentally and emotionally. In this research, we introduce a machine learning model that can identify and categorizing videos as either violent or non-violent based on the presence of violent content. Two parameters are taken as inputs namely audio and video. The audio is separated from the video initially. The audio component is processed through an audio classifier which distinguishes between violent and nonviolent sounds. If the audio classifier classifies audio as nonviolent, then the corresponding video is fed into a video classifier where it is categorized into violent or non-violent video. © 2023 IEEE.},
	author_keywords = {C3D; computer vision; image processing; spectrogram; video processing; violence detection; violence using deep learning},
	keywords = {Audio acoustics; Deep learning; Video signal processing; Age groups; Audio-visual features; C3D; Exposed to; Images processing; Safer places; Spectrograms; Video processing; Violence detections; Violence using deep learning; Computer vision},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st IEEE International Conference on Advances in Electronics, Communication, Computing and Intelligent Information Systems, ICAECIS 2023; Conference date: 19 April 2023 through 21 April 2023; Conference code: 190540}
}

@ARTICLE{Khan20224335,
	author = {Khan, Shakir and Fazil, Mohd and Sejwal, Vineet Kumar and Alshara, Mohammed Ali and Alotaibi, Reemiah Muneer and Kamal, Ashraf and Baig, Abdul Rauf},
	title = {BiCHAT: BiLSTM with deep CNN and hierarchical attention for hate speech detection},
	year = {2022},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	volume = {34},
	number = {7},
	pages = {4335 – 4344},
	doi = {10.1016/j.jksuci.2022.05.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132429990&doi=10.1016%2fj.jksuci.2022.05.006&partnerID=40&md5=270026e3dda30a2c128c5fdd84a3a17c},
	affiliations = {College of Computer and Information Sciences in Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia; Center for Transformative Learning, University of Limerick, Ireland; Directorate of Education, New Delhi, India; ACL Digital, Bengaluru, India},
	abstract = {Online social networks(OSNs) face the challenging problem of hate speech, which should be moderated for the growth of OSNs. The machine learning approaches dominate the existing set of approaches for hate speech detection. In this study, we introduce BiCHAT: a novel BiLSTM with deep CNN and Hierarchical ATtention-based deep learning model for tweet representation learning toward hate speech detection. The proposed model takes the tweets as input and passes through a BERT layer followed by an attention-aware deep convolutional layer. The convolutional encoded representation further passes through an attention-aware Bidirectional LSTM network. Finally, the model labels the tweet as hateful or normal through a softmax layer. The proposed model is trained and evaluated over the three benchmark datasets extracted from Twitter and outperforms the state-of-the-art (SOTA) (Khan et al., 2022; Roy et al., 2020; Ding et al., 2019) and baseline methods with an improvement of 8%,7% and 8% in terms of precision, recall, and f-score, respectively. BiCHAT also demonstrates good performance considering training and validation accuracy with an improvement of 5% and 9%, respectively. We also examined the impact of different constituting neural network components on the model. On analysis, we observed that the exclusion of the deep convolutional layer has the highest impact on the performance of the proposed model. We also investigated the efficacy of different embedding techniques, activation function, batch size, and optimization algorithms on the performance of the BiCHAT model. © 2022 The Author(s)},
	author_keywords = {BiCHAT; Deep learning; Hate speech detection; Social network security; Twitter data analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68; All Open Access, Gold Open Access}
}

@ARTICLE{Plaza-del-Arco2022,
	author = {Plaza-del-Arco, Flor Miriam and Molina-González, M. Dolores and Ureña-López, L. Alfonso and Martín-Valdivia, María-Teresa},
	title = {Integrating implicit and explicit linguistic phenomena via multi-task learning for offensive language detection},
	year = {2022},
	journal = {Knowledge-Based Systems},
	volume = {258},
	doi = {10.1016/j.knosys.2022.109965},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140302483&doi=10.1016%2fj.knosys.2022.109965&partnerID=40&md5=79f9ecd99b2ecae0e7a07ca6c2d48265},
	affiliations = {Department of Computer Science, Advanced Studies Center in Information and Communication Technologies (CEATIC), Universidad de Jaen, Campus Las Lagunillas, Jaen, E-23071, Spain},
	abstract = {The analysis and detection of offensive content in textual information have become a great challenge for the Natural Language Processing community. Most of the research conducted so far on offensive language detection have addressed this task as a sole optimization objective. However, other linguistic phenomena that are arguably correlated with offensive language and therefore could be beneficial to recognize this type of problematic content on the Web, have not been explored in depth so far. Thus, the goal of this study is to investigate whether explicit and implicit concepts involved in the expression of offensive language help in the detection of this phenomenon and how to incorporate these concepts in a computational system. We propose a multi-task learning approach that includes such concepts according to the relevance shown by a feature selection method called mutual information. Our experiments show that some phenomena such as constructiveness, target group and person, figurative language (sarcasm and mockery), insults, improper language, and emotions combined together help to optimize the offensive language detection task, outperforming a state-of-the-art method (the transformer BETO) that we use as our baseline to compare the results. © 2022 Elsevier B.V.},
	author_keywords = {Linguistic phenomena; Multi-task learning; Natural language processing; Offensive language; Spanish},
	keywords = {Linguistics; Natural language processing systems; Language detection; Language processing; Linguistic phenomena; Multitask learning; Natural language processing; Natural languages; Offensive languages; Optimisations; Spanish; Textual information; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@ARTICLE{Oliveira2023,
	author = {Oliveira, Luciana and Azevedo, Joana},
	title = {Using Social Media Categorical Reactions as a Gateway to Identify Hate Speech in COVID-19 News},
	year = {2023},
	journal = {SN Computer Science},
	volume = {4},
	number = {1},
	doi = {10.1007/s42979-022-01421-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139849218&doi=10.1007%2fs42979-022-01421-5&partnerID=40&md5=93c7bf50a26d259e485de835cf3d9e25},
	affiliations = {CEOS.PP ISCAP Polytechnic of Porto, Rua Jaime Lopes Amorim, s/n, S. Mamede de Infesta, 4465-004, Portugal; ISCAP Polytechnic of Porto, Rua Jaime Lopes Amorim, s/n, S. Mamede de Infesta, 4465-004, Portugal},
	abstract = {The spread of COVID-19 news on social media provided a particularly prolific ground for emotional commotion, disinformation and hate speech, as uncertainty and fear grew by the day. In this paper, we examine the media coverage of the COVID-19 outburst in Portugal (March–May 2020), the subsequent emotional engagement of audiences and the entropy-based emotional controversy generated as a gateway to detect the presence of hate speech, using computer-assisted qualitative data analysis (CAQDAS) embedded in a cross-sectional descriptive methodology. Our results reveal that negative and volatile categorical emotions (“Angry”, “Haha” and “Wow”) serve as main engines for controversy, and that controversial news have the highest sharing ratio. Moreover, using a small sample of the most controversial news with the highest overall emotional engagement, we establish a relation between the entropy-based emotional controversy obtained from Facebook’s click-based reactions and the presence of cultural and ethnic hate speech, plausibly confirming the click-based categorical emotions as a gateway to hatred comment pools. In doing so, we also reveal that negative emotions alone do not always indicate the presence of hate speech, which may sprout in seemingly humorous social media posts where irony proliferates, and negativity is not apparent. This work adds to the literature on social media categorical emotion detection and its implications for the detection of hate speech. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Controversy; COVID-19; Emotions; Entropy; Facebook; Hate speech; Media coverage; Social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Smuc2023953,
	author = {Smuc, Eva and Delac, Goran and Silic, Marin and Vladimir, Klemo},
	title = {A Transfer Learning Method for Hate Speech Detection},
	year = {2023},
	journal = {2023 46th ICT and Electronics Convention, MIPRO 2023 - Proceedings},
	pages = {953 – 958},
	doi = {10.23919/MIPRO57284.2023.10159777},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164924042&doi=10.23919%2fMIPRO57284.2023.10159777&partnerID=40&md5=335cab07158e5f9e8911d104fcf25945},
	affiliations = {University of Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia},
	abstract = {In this work we explore the possibilities of using transfer learning techniques to enhance performance of hate speech detection models by relying on similar linguistic problems (e.g. toxic language detection). Multiple algorithms are trained for similar linguistic tasks on larger datasets, and the obtained models are used for getting predictions on the ETHOS dataset, which we chose as the target dataset of our work. The obtained predictions are used as sole or additional features in the subsequently performed experiments. Multiple algorithms are evaluated, including Logistic Regression, SVM, RidgeClassifier, Decision Tree, Random Forest, AdaBoost, GradBoost, Bagging. Furthermore, multiple textual representations are taken into account including Tf-Idf, Bert embeddings and BERT embeddings combined with the aforementioned additional features. Transformer-based models BERT and DistilBERT are introduced and fine-tuned on ETHOS dataset. All the obtained models are evaluated and the resulting performance metrics are compared to results obtained by the authors of the ETHOS dataset. In order to explore the remaining underlying issues, model-agnostic method LIME is used to obtain explanations for incorrect predictions. © 2023 MIPRO Croatian Society.},
	author_keywords = {deep learning; feature extraction; hate speech detection; transfer learning},
	keywords = {Adaptive boosting; Decision trees; Deep learning; Embeddings; Forecasting; Lime; Linguistics; Microelectronics; Speech recognition; Support vector machines; Transfer learning; Deep learning; Embeddings; Features extraction; Hate speech detection; Learning techniques; Multiple algorithms; Performance; Speech detection; Transfer learning; Transfer learning methods; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 46th ICT and Electronics Convention, MIPRO 2023; Conference date: 22 May 2023 through 26 May 2023; Conference code: 190157}
}

@CONFERENCE{Chiu2023724,
	author = {Chiu, Anna and Sood, Kanika and Rincon, Ariadne and Doran, Davina},
	title = {Detecting Hate Speech on Social Media with Respect to Adolescent Vulnerability},
	year = {2023},
	journal = {2023 IEEE 13th Annual Computing and Communication Workshop and Conference, CCWC 2023},
	pages = {724 – 728},
	doi = {10.1109/CCWC57344.2023.10099373},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156221026&doi=10.1109%2fCCWC57344.2023.10099373&partnerID=40&md5=4d95ea3b4fbb3c7683511f98381807b1},
	affiliations = {California State University, Fullerton, Department of Computer Science, Fullerton, United States},
	abstract = {Social media has become one of the biggest plat-forms for children and young adolescents to spend their free time. Due to the rising age gap between people using social media, tweens can be exposed to offensive and provocative posts made by others that are older. Twitter allows children aged 13 and up to create an account on their platform. While this is a common age restriction on most social media platforms, it can be damaging to young adolescents who are at a crucial time developing their morals and beliefs based on what they see online. Identifying hate speech within a timely matter is crucial for censoring hate speech for kids. This can impact the overall environment on social media to be less toxic and uplifting to all users. In this work, we propose to use multiple machine learning techniques: SVM, k-nearest neighbor, Naive Bayes, and soft-voting ensemble classifier.  © 2023 IEEE.},
	author_keywords = {Classification; Ensemble Method; Hate speech recognition; K-Nearest Neighbor; Machine Learning; Naive Bayes; SVM},
	keywords = {Learning systems; Motion compensation; Nearest neighbor search; Social networking (online); Support vector machines; Ensemble methods; Exposed to; Hate speech recognition; K-near neighbor; Machine-learning; Naive bayes; Nearest-neighbour; Social media; Social media platforms; SVM; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 13th IEEE Annual Computing and Communication Workshop and Conference, CCWC 2023; Conference date: 8 March 2023 through 11 March 2023; Conference code: 188061}
}

@CONFERENCE{Mittal2023118,
	author = {Mittal, Dipti and Singh, Harmeet},
	title = {Enhancing Hate Speech Detection through Explainable AI},
	year = {2023},
	journal = {Proceedings - 2023 3rd International Conference on Smart Data Intelligence, ICSMDI 2023},
	pages = {118 – 123},
	doi = {10.1109/ICSMDI57622.2023.00028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161815393&doi=10.1109%2fICSMDI57622.2023.00028&partnerID=40&md5=ab1ccc217393658adbb1ebe5a7557b40},
	affiliations = {Ct University, Department of Computer Science and Application, Punjab, Sidhwan Khurd, 142024, India},
	abstract = {The potential of XAI in detecting hate speech using deep learning models is versatile and multifaceted. To better understand the decision-making process of complex AI models, this study applied XAI to the dataset and investigated the interpretability and explanation of their decisions. The data was preprocessed by cleaning, tokenizing, lemmatizing, and removing inconsistencies in tweets. Simplification of categorical variables was also performed during training. Exploratory data analysis was conducted to identify patterns and insights in the dataset. The study used a set of existing models, including LIME, SHAP, XGBoost, and KTrain, to analyze the accuracy. The KTrain model achieved the highest accuracy and lowest loss among the variants developed to increase explainability.  © 2023 IEEE.},
	author_keywords = {hate speech; Knowledge Transfer for Deep Learning and Explainable Artificial Intelligence; Local Interpretable Model-Agnostic Explanations; offensive languages; SHapley Additive exPlanations},
	keywords = {Decision making; Deep learning; Knowledge management; Learning systems; Speech recognition; Decision-making process; Hate speech; Knowledge transfer; Knowledge transfer for deep learning and explainable artificial intelligence; Learning models; Local interpretable model-agnostic explanation; Offensive languages; Shapley; Shapley additive explanation; Speech detection; Lime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 3rd International Conference on Smart Data Intelligence, ICSMDI 2023; Conference date: 30 March 2023 through 31 March 2023; Conference code: 189014}
}

@ARTICLE{Ganfure2022,
	author = {Ganfure, Gaddisa Olani},
	title = {Comparative analysis of deep learning based Afaan Oromo hate speech detection},
	year = {2022},
	journal = {Journal of Big Data},
	volume = {9},
	number = {1},
	doi = {10.1186/s40537-022-00628-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131145303&doi=10.1186%2fs40537-022-00628-w&partnerID=40&md5=a0e86ebca55fe04f4000da9edcaddb05},
	affiliations = {Computer Science, Dire Dawa University Institute of Technology, Sabean, Dire Dawa, 1362, Ethiopia},
	abstract = {Social media platforms like Facebook, YouTube, and Twitter are banking on developing machine learning models to help stop the spread of hateful speech on their platforms. The idea is that machine learning models that utilize natural language processing will detect hate speech faster and better than people can. Despite numerous progress has been made for resource reach language, only a few attempts have been made for Ethiopian Languages such as Afaan Oromo. This paper examines the viability of deep learning models for Afaan Oromo hate speech recognition. Toward this, the biggest dataset of hate speech was collected and annotated by the language experts. Variations of profound deep learning models such as CNN, LSTMs, BiLSTMs, LSTM, GRU, and CNN-LSTM are examined to evaluate their viability in identifying Afaan Oromo Hate speeches. The result uncovers that the model dependent on CNN and Bi-LSTM outperforms all the other investigated models with an average F1-score of 87%. © 2022, The Author(s).},
	author_keywords = {Afaan Oromo; Artificial Intelligence; Deep Learning; Ethiopian Languages; Hate Speech Detection},
	keywords = {Learning algorithms; Learning systems; Long short-term memory; Natural language processing systems; Social networking (online); Afaan oromo; Comparative analyzes; Deep learning; Ethiopian language; Facebook; Hate speech detection; Learning models; Machine learning models; Social media platforms; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Bhat20231137,
	author = {Bhat, Aruna and Vashisht, Vaibhav and Sahni, Vaibhav Raj and Meena, Sumit},
	title = {Hate Speech Detection using Multimodal Meme Analysis},
	year = {2023},
	journal = {Proceedings of the 2nd International Conference on Applied Artificial Intelligence and Computing, ICAAIC 2023},
	pages = {1137 – 1142},
	doi = {10.1109/ICAAIC56838.2023.10140393},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163646102&doi=10.1109%2fICAAIC56838.2023.10140393&partnerID=40&md5=30358d008a4a8fce184206d4f74062be},
	affiliations = {Delhi Technological University, Computer Engineering, Delhi, India},
	abstract = {Hateful memes, which often contain offensive language and derogatory images, have become increasingly prevalent on social media platforms, posing a significant challenge to content moderation efforts. To address this issue, the proposed approach explores the detection of hateful memes through a multimodal analysis that utilizes both visual and textual modalities. A novel lightweight architecture is proposed which involves generating object tags and image captions and utilising them to combine the visual and textual cues. In the final classification phase, various classification models, such as Support Vector Classifier and Gradient Boosted Decision Trees, are trained. This layer combines the results of concurrent processing branches (textual and visual) to provide predictions for the sample. © 2023 IEEE.},
	author_keywords = {BERT; Gradient Boosted Decision Tree; Hate speech; Logistic Regression; Multimodal Analysis; ResNet; Support Vector Classifier; Unimodal Analysis},
	keywords = {Logistic regression; Modal analysis; Support vector machines; BERT; Boosted decision trees; Gradient boosted decision tree; Hate speech; Logistics regressions; Multimodal analysis; Resnet; Support vector classifiers; Unimodal; Unimodal analyse; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd International Conference on Applied Artificial Intelligence and Computing, ICAAIC 2023; Conference date: 4 May 2023 through 6 May 2023; Conference code: 189334}
}

@CONFERENCE{Putra2023,
	author = {Putra, Cendra Devayana and Wang, Hei-Chia},
	title = {Automate Lifelong Hate Speech Detection: Current Challenge In Cross-Domain Adaption},
	year = {2023},
	journal = {2023 International Conference on Emerging Smart Computing and Informatics, ESCI 2023},
	doi = {10.1109/ESCI56872.2023.10099738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158102370&doi=10.1109%2fESCI56872.2023.10099738&partnerID=40&md5=1215a6f4449e4ae70c10751d176ad4e9},
	affiliations = {Institute of Information Management, National Cheng Kung University, Taiwan},
	abstract = {Hate speech is a phenomenon which presents offensive content that people may find on social networking sites. Recognizing and reducing inappropriate content is critical for preventing and reducing hate speech. This article highlights the diversity of possible hate speech datasets and developed challenges in four domains by investigating 27 related papers in several trusted databases. The findings point to future system development directions to trace objectionable content transformations over time on various online social platforms and domains. © 2023 IEEE.},
	author_keywords = {Cross-Domain Hate Speech; Hate Speech Dataset; Hate Speech Future Challenge},
	keywords = {'current; Cross-domain; Cross-domain hate speech; Domain adaptions; Future challenges; Hate speech dataset; Hate speech future challenge; Social-networking; Speech detection; System development; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 5th International Conference on Emerging Smart Computing and Informatics, ESCI 2023; Conference date: 1 March 2023 through 3 March 2023; Conference code: 188070}
}

@ARTICLE{Sultan20232115,
	author = {Sultan, Daniyar and Toktarova, Aigerim and Zhumadillayeva, Ainur and Aldeshov, Sapargali and Mussiraliyeva, Shynar and Beissenova, Gulbakhram and Tursynbayev, Abay and Baenova, Gulmira and Imanbayeva, Aigul},
	title = {Cyberbullying-related Hate Speech Detection Using Shallow-to-deep Learning},
	year = {2023},
	journal = {Computers, Materials and Continua},
	volume = {74},
	number = {1},
	pages = {2115 – 2131},
	doi = {10.32604/cmc.2023.032993},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139784742&doi=10.32604%2fcmc.2023.032993&partnerID=40&md5=fe0fed11f7e7733e9da844927ff4dc98},
	affiliations = {Al-Farabi Kazakh National University, Almaty, Kazakhstan; International Information Technology University, Almaty, Kazakhstan; Akhmet Yassawi International Kazakh-Turkish University, Turkistan, Kazakhstan; L.N.Gumilyov Eurasian National University, Astana, Kazakhstan; South Kazakhstan State Pedagogical University, Shymkent, Kazakhstan; M. Auezov South Kazakhstan University, Shymkent, Kazakhstan; University of Friendship of People’s Academician A. Kuatbekov, Shymkent, Kazakhstan; National Academy of Education named after Y. Altynsarin, Astana, Kazakhstan},
	abstract = {Communication in society had developed within cultural and geographical boundaries prior to the invention of digital technology. The latest advancements in communication technology have significantly surpassed the conventional constraints for communication with regards to time and location. These new platforms have ushered in a new age of user-generated content, online chats, social network and comprehensive data on individual behavior. However, the abuse of communication software such as social media websites, online communities, and chats has resulted in a new kind of online hostility and aggressive actions. Due to widespread use of the social networking platforms and technological gadgets, conventional bullying has migrated from physical form to online, where it is termed as Cyberbullying. However, recently the digital technologies as machine learning and deep learning have been showing their efficiency in identifying linguistic patterns used by cyberbullies and cyberbullying detection problem. In this research paper, we aimed to evaluate shallow machine learning and deep learning methods in cyberbullying detection problem. We deployed three deep and six shallow learning algorithms for cyberbullying detection problems. The results show that bidirectional long-short-term memory is the most efficient method for cyberbullying detection, in terms of accuracy and recall. © 2023 Tech Science Press. All rights reserved.},
	author_keywords = {classification; Cyberbullying; deep learning; machine learning; NLP},
	keywords = {Computer crime; Deep learning; Learning algorithms; Learning systems; Social networking (online); Speech recognition; Communicationtechnology; Cyber bullying; Deep learning; Detection problems; Digital technologies; Individual behavior; Machine-learning; New age; Speech detection; User-generated; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access}
}

@ARTICLE{Mehta2022,
	author = {Mehta, Harshkumar and Passi, Kalpdrum},
	title = {Social Media Hate Speech Detection Using Explainable Artificial Intelligence (XAI)},
	year = {2022},
	journal = {Algorithms},
	volume = {15},
	number = {8},
	doi = {10.3390/a15080291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137146369&doi=10.3390%2fa15080291&partnerID=40&md5=f703b2d38a651c891f9ed142d954769f},
	affiliations = {School of Engineering and Computer Science, Laurentian University, Sudbury, P3E 2C6, ON, Canada},
	abstract = {Explainable artificial intelligence (XAI) characteristics have flexible and multifaceted potential in hate speech detection by deep learning models. Interpreting and explaining decisions made by complex artificial intelligence (AI) models to understand the decision-making process of these model were the aims of this research. As a part of this research study, two datasets were taken to demonstrate hate speech detection using XAI. Data preprocessing was performed to clean data of any inconsistencies, clean the text of the tweets, tokenize and lemmatize the text, etc. Categorical variables were also simplified in order to generate a clean dataset for training purposes. Exploratory data analysis was performed on the datasets to uncover various patterns and insights. Various pre-existing models were applied to the Google Jigsaw dataset such as decision trees, k-nearest neighbors, multinomial naïve Bayes, random forest, logistic regression, and long short-term memory (LSTM), among which LSTM achieved an accuracy of 97.6%. Explainable methods such as LIME (local interpretable model—agnostic explanations) were applied to the HateXplain dataset. Variants of BERT (bidirectional encoder representations from transformers) model such as BERT + ANN (artificial neural network) with an accuracy of 93.55% and BERT + MLP (multilayer perceptron) with an accuracy of 93.67% were created to achieve a good performance in terms of explainability using the ERASER (evaluating rationales and simple English reasoning) benchmark. © 2022 by the authors.},
	author_keywords = {BERT; explainable artificial intelligence; hate speech detection; LIME; neural networks; offensive languages},
	keywords = {Benchmarking; Decision trees; Lime; Multilayer neural networks; Nearest neighbor search; Random forests; Social networking (online); Speech recognition; Bidirectional encoder representation from transformer; Explainable artificial intelligence; Hate speech detection; Intelligence models; Learning models; Local interpretable model—agnostic explanation; Neural-networks; Offensive languages; Social media; Speech detection; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Gold Open Access}
}

@ARTICLE{Maity2023425,
	author = {Maity, Krishanu and Bhattacharya, Shaubhik and Saha, Sriparna and Janoai, Suwika and Pasupa, Kitsuchart},
	title = {FastThaiCaps: A Transformer Based Capsule Network for Hate Speech Detection in Thai Language},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13624 LNCS},
	pages = {425 – 437},
	doi = {10.1007/978-3-031-30108-7_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161679542&doi=10.1007%2f978-3-031-30108-7_36&partnerID=40&md5=d1584cbda8d88c196c13bb7ed7df7765},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, India; School of Information Technology, King Mongkut’s Institute of Technology, Bangkok, Ladkrabang, 10520, Thailand},
	abstract = {The advent of technology has led to people sharing their views openly like never before. Parallelly, cyberbullying and hate speech content have also increased as a side effect that is potentially hazardous to society. While plenty of research is going on to detect online hate speech in English, there is very little research on the Thai language. To investigate how noisy Thai posts can be handled effectively, in this work, we have developed a two-channel deep learning model FastThaiCaps based on BERT and FastText embedding along with a capsule network. The input to one channel is the BERT language model, and that to the other is the pre-trained FastText embedding. Our model has been evaluated on a benchmark Thai dataset categorized into four categories, i.e., peace speech, neutral speech, level-1 hate speech, and level-2 hate speech. Experiments show that FastThaiCaps outperforms state-of-the-art methods by up to 3.11% in terms F1 score. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Capsule Network; FastText; Hate Speech; Thai; Transformer},
	keywords = {Deep learning; Speech recognition; Capsule network; Cyber bullying; Embeddings; Fasttext; Hate speech; Speech content; Speech detection; Thai; Thai language; Transformer; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 29th International Conference on Neural Information Processing, ICONIP 2022; Conference date: 22 November 2022 through 26 November 2022; Conference code: 293409}
}

@ARTICLE{Akuma20223629,
	author = {Akuma, Stephen and Lubem, Tyosar and Adom, Isaac Terngu},
	title = {Comparing Bag of Words and TF-IDF with different models for hate speech detection from live tweets},
	year = {2022},
	journal = {International Journal of Information Technology (Singapore)},
	volume = {14},
	number = {7},
	pages = {3629 – 3635},
	doi = {10.1007/s41870-022-01096-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138520876&doi=10.1007%2fs41870-022-01096-4&partnerID=40&md5=287f7e61cf27f67e73d3487adc848ddf},
	affiliations = {Department of Mathematics, Computer Science and Statistics, Benue State University, Makurdi, Nigeria},
	abstract = {Social media platforms such as Twitter have revolutionized online communication and interactions but often contain components of disdain for its growing user base. This discomforting feed creates instability leading to mental breakdown, and loss of human lives and properties among other results of misuse. Even though the problem posed by the content of social media is obvious, the challenge of detecting hateful content persists. Several algorithms and techniques have been used in the past for detecting hateful content on social media but there is room for improvement. The goal of this paper is to detect hate speech from live tweets on Twitter via a combination of mechanisms. The comparison results of Term Frequency-Inverse Document Frequency (TF-IDF) and Bag of Words (BoW) with machine learning models of Logistic Regression, Naïve Bayes, Decision Tree, and K-Nearest Neighbour (KNN), is used to select the best performing model. This model which is integrated into a web system developed with Twitter Application Programming Interface (API) is used in identifying live tweets which are hateful or not. The outcome of the comparative study presented showed that Decision Tree performed better than the other three models with an accuracy of 92.43% using TF-IDF which gives optimal results compared to BoW. © 2022, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.},
	author_keywords = {Bag of Words; Hate speech; Machine learning algorithm; Sentiment analysis; Social media; TF-IDF; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 61}
}

@ARTICLE{Wikandiputra2022811,
	author = {Wikandiputra, Atmaja and Afiahayati and Sutanto, Vincent Michael},
	title = {IDENTIFYING HATE SPEECH IN BAHASA INDONESIA WITH LEXICON-BASED FEATURES AND SYNONYM-BASED QUERY EXPANSION},
	year = {2022},
	journal = {ICIC Express Letters},
	volume = {16},
	number = {8},
	pages = {811 – 818},
	doi = {10.24507/icicel.16.08.811},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133818980&doi=10.24507%2ficicel.16.08.811&partnerID=40&md5=ee584e83d5a828cd5296aca44c298362},
	affiliations = {Mindimedia, Jl. Nuansa Timur X No. 9 Jimbaran, Bali, 80361, Indonesia; Department of Computer Science and Electronics, Faculty of Mathematics and Natural Sciences, Universitas Gadjah Mada, Jalan Bulaksumur Ged Pusat UGM Lt 3, Special Region of Yogyakarta, 55281, Indonesia; Division of Information Science, Nara Institute of Science and Technology, 8916-5 Takayama-cho, Nara, Ikoma, 630-0192, Japan},
	abstract = {Freedom of social media users who are not controlled in giving opinions can make it easier for users to attack certain people, objects, or environments with hateful language or commonly called hate speech. According to the Indonesia Criminal Investigation Police, 80% of cybercrimes reported were expressions of hatred. Preventive actions taken by Facebook & Twitter are deemed ineffective because checking hate speech is still manually through user reports. In this study, we used a machine learning algorithm, which is Support Vector Machine (SVM), to identify whether a speech is considered as hate speech or not. We combined the SVM with the Lexicon-based Features and Synonym-based Query Expansion method. The models were trained and evaluated by calculating Accuracy, Precision, Recall, and F-measure. This study shows that the use of the Synonym-based Query Expansion method can improve the performance of the SVM model with Lexicon-based as its feature. © 2022 ICIC International. All rights reserved.},
	author_keywords = {Classification; Hate speech; Lexicon-based; Support Vector Machine; Synonym},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ganganwar2022,
	author = {Ganganwar, Vaishali and Rajalakshmi, Ratnavel},
	title = {MTDOT: A Multilingual Translation-Based Data Augmentation Technique for Offensive Content Identification in Tamil Text Data},
	year = {2022},
	journal = {Electronics (Switzerland)},
	volume = {11},
	number = {21},
	doi = {10.3390/electronics11213574},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141652628&doi=10.3390%2felectronics11213574&partnerID=40&md5=bfbc758e97ef82cd4d944f4fc19f4e26},
	affiliations = {School of Computer Science and Engineering, Vellore Institute of Technology, Tamilnadu, Chennai, 600127, India},
	abstract = {The posting of offensive content in regional languages has increased as a result of the accessibility of low-cost internet and the widespread use of online social media. Despite the large number of comments available online, only a small percentage of them are offensive, resulting in an unequal distribution of offensive and non-offensive comments. Due to this class imbalance, classifiers may be biased toward the class with the most samples, i.e., the non-offensive class. To address class imbalance, a Multilingual Translation-based Data augmentation technique for Offensive content identification in Tamil text data (MTDOT) is proposed in this work. The proposed MTDOT method is applied to HASOC’21, which is the Tamil offensive content dataset. To obtain a balanced dataset, each offensive comment is augmented using multi-level back translation with English and Malayalam as intermediate languages. Another balanced dataset is generated by employing single-level back translation with Malayalam, Kannada, and Telugu as intermediate languages. While both approaches are equally effective, the proposed multi-level back-translation data augmentation approach produces more diverse data, which is evident from the BLEU score. The MTDOT technique proposed in this work achieved a promising improvement in (Formula presented.) -score over the widely used SMOTE class balancing method by 65%. © 2022 by the authors.},
	author_keywords = {back translation; data augmentation; imbalanced data; MuRIL; offensive content identification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@ARTICLE{Toktarova2023396,
	author = {Toktarova, Aigerim and Syrlybay, Dariga and Myrzakhmetova, Bayan and Anuarbekova, Gulzat and Rakhimbayeva, Gulbarshin and Zhylanbaeva, Balkiya and Suieuova, Nabat and Kerimbekov, Mukhtar},
	title = {Hate Speech Detection in Social Networks using Machine Learning and Deep Learning Methods},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {5},
	pages = {396 – 406},
	doi = {10.14569/IJACSA.2023.0140542},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161199800&doi=10.14569%2fIJACSA.2023.0140542&partnerID=40&md5=7fe07021af688131d6206def7ee94fdf},
	affiliations = {Khoja Akhmet Yassawi International Kazakh, Turkish University, Turkistan, Kazakhstan; M. Auezov South Kazakhstan Universtiy, Shymkent, Kazakhstan; South Kazakhstan State Pedagogical University, Shymkent, Kazakhstan; Abai Kazakh National Pedagogical University, Almaty, Kazakhstan; Asfendiyarov Kazakh National Medical University, Almaty, Kazakhstan; Yessenov University, Aktau, Kazakhstan; University of Friendship of People’s Academician A. Kuatbekov, Shymkent, Kazakhstan},
	abstract = {Hate speech on social media platforms like Twitter is a growing concern that poses challenges to maintaining a healthy online environment and fostering constructive communication. Effective detection and monitoring of hate speech are crucial for mitigating its adverse impact on individuals and communities. In this paper, we propose a comprehensive approach for hate speech detection on Twitter using both traditional machine learning and deep learning techniques. Our research encompasses a thorough comparison of these techniques to determine their effectiveness in identifying hate speech on Twitter. We construct a robust dataset, gathered from diverse sources and annotated by experts, to ensure the reliability of our models. The dataset consists of tweets labeled as hate speech, offensive language, or neutral, providing a more nuanced representation of online discourse. We evaluate the performance of LSTM, BiLSTM, and CNN models against traditional shallow learning methods to establish a baseline for comparison. Our findings reveal that deep learning techniques outperform shallow learning methods, with BiLSTM emerging as the most accurate model for hate speech detection. The BiLSTM model demonstrates improved sensitivity to context, semantic nuances, and sequential patterns in tweets, making it adept at capturing the intricate nature of hate speech. Furthermore, we explore the integration of word embeddings, such as Word2Vec and GloVe, to enhance the performance of our models. The incorporation of these embeddings significantly improves the models' ability to discern between hate speech and other forms of online communication. This paper presents a comprehensive analysis of various machine learning methods for hate speech detection on Twitter, ultimately demonstrating the superiority of deep learning techniques, particularly BiLSTM, in addressing this critical issue. Our findings pave the way for further research into advanced methods of tackling hate speech and facilitating healthier online interactions. © 2023, International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {classification; deep learning; hate speech; Machine learning; social network},
	keywords = {Embeddings; Long short-term memory; Social networking (online); Speech communication; Speech recognition; Deep learning; Embeddings; Hate speech; Learning methods; Learning techniques; Machine-learning; Performance; Social media platforms; Social network; Speech detection; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Gold Open Access}
}

@ARTICLE{El-Alami20226048,
	author = {El-Alami, Fatima-zahra and Ouatik El Alaoui, Said and En Nahnahi, Noureddine},
	title = {A multilingual offensive language detection method based on transfer learning from transformer fine-tuning model},
	year = {2022},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	volume = {34},
	number = {8},
	pages = {6048 – 6056},
	doi = {10.1016/j.jksuci.2021.07.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111989334&doi=10.1016%2fj.jksuci.2021.07.013&partnerID=40&md5=7d4b516dcef4516137b1450bc53fc1af},
	affiliations = {Laboratory of Informatics, Signals, Automatic and Cognitivism, FSDM, Sidi Mohamed Ben Abdellah University, Fez, Morocco; Engineering Sciences Laboratory, National School of Applied Sciences, Ibn Tofail University, Kenitra, Morocco},
	abstract = {Offensive communications have invaded social media content. One of the most effective solutions to cope with this problem is using computational techniques to discriminate offensive content. Moreover, social media users are from linguistically different communities. This study aims to tackle the Multilingual Offensive Language Detection (MOLD) task using transfer learning models and the fine-tuning phase. We propose an effective approach based on the Bidirectional Encoder Representations from Transformers (BERT) that has shown great potential in capturing the semantics and contextual information within texts. The proposed system consists of several stages: (1) Preprocessing, (2) Text representation using BERT models, and (3) Classification into two categories: Offensive and non-offensive. To handle multilingualism, we explore different techniques such as the joint-multilingual and translation-based ones. The first consists in developing one classification system for different languages, and the second involves the translation phase to transform all texts into one universal language then classify them. We conduct several experiments on a bilingual dataset extracted from the Semi-supervised Offensive Language Identification Dataset (SOLID). The experimental findings show that the translation-based method in conjunction with Arabic BERT (AraBERT) achieves over 93% and 91% in terms of F1-score and accuracy, respectively. © 2021 The Authors},
	author_keywords = {Multilingual; Natural language processing; Offensive language detection; Social media; Text classification; Transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 50; All Open Access, Gold Open Access}
}

@CONFERENCE{Theodoridis2022141,
	author = {Theodoridis, Dion and Caselli, Tommaso},
	title = {All That Glitters is Not Gold: Transfer-learning for Offensive Language Detection in Dutch},
	year = {2022},
	journal = {Computational Linguistics in the Netherlands Journal},
	volume = {12},
	pages = {141 – 164},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171446490&partnerID=40&md5=2dc3425e698c2b0348bbe1efcfaabcc9},
	affiliations = {Center for Language of Cognition, University of Groningen, Netherlands},
	abstract = {Creating datasets for language phenomena to fill gaps in the language resource panorama of specific natural languages is not a trivial task. In this work, we explore the application of transferlearning as strategy to boost both the creation of language-specific datasets and systems. We use offensive language in Dutch tweets directed at Dutch politicians as a case study. In particular, we trained a multilingual model using the Political Speech Project (Bröckling et al. 2018) dataset to automatically annotate tweets in Dutch. The automatically annotated tweets have been used to further train a monolingual language model in Dutch (BERTje) adopting different strategies and combination of manually curated data. Our results show that: (i) transfer learning is an effective strategy to boost the creation of new datasets for specific language phenomena by reducing the annotation efforts; (ii) using a monolingual language model fine-Tuned with automatically annotated data (i.e., silver data) is a competitive baseline against the zero-shot transfer of a multilingual model; and finally, (iii) less surprisingly, the addition of automatically annotated data to manually curated ones is a source of errors for the systems, degrading their performances. © 2022 Computational Linguistics in the Netherlands. All rights reserved.},
	keywords = {Gold; Transfer learning; Zero-shot learning; Case-studies; Language detection; Language model; Language resources; Natural languages; Offensive languages; Performance; Specific languages; Transfer learning; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 32nd Meeting of Computational Linguistics in the Netherlands, CLIN 2022; Conference date: 17 June 2022; Conference code: 191871}
}

@CONFERENCE{Roychowdhury2023125,
	author = {Roychowdhury, Sumegh and Gupta, Vikram},
	title = {Data-Efficient Methods For Improving Hate Speech Detection},
	year = {2023},
	journal = {EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023},
	pages = {125 – 132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159855800&partnerID=40&md5=18cded941e3bebf724304dc3abb5616d},
	affiliations = {IIT Kharagpur, India; ShareChat, India},
	abstract = {Scarcity of large-scale datasets, especially for resource-impoverished languages encouraged exploration of data-efficient methods for hate speech detection. In this work, we progress implicit and explicit hate speech detection using an input-level data augmentation technique, task reformulation using entailment and cross-learning across five languages. Our proposed data augmentation technique EasyMixup, improves the F1 performance across languages by 0.5-9%. We also observe substantial F1 gains of 1-8% by reformulating hate speech detection as Entailment-style problem. We further probe the contextual models and observe that higher layers encode implicit hate while lower layers focus on explicit hate, highlighting the importance of token-level understanding for explicit and context-level for implicit hate speech detection. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large dataset; Augmentation techniques; Contextual modeling; Data augmentation; Large-scale datasets; Performance; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023 - Findings of EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188432}
}

@CONFERENCE{Vijay202318,
	author = {Vijay, V. and Verma, Pushpneel},
	title = {Variants of Naïve Bayes Algorithm for Hate Speech Detection in Text Documents},
	year = {2023},
	journal = {2023 International Conference on Artificial Intelligence and Smart Communication, AISC 2023},
	pages = {18 – 21},
	doi = {10.1109/AISC56616.2023.10085511},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153497149&doi=10.1109%2fAISC56616.2023.10085511&partnerID=40&md5=e7425c434a0ed7ad70b5ccdd8aaa1d97},
	affiliations = {Bhagwant University, Department of Computer Science and Engineering, Sikar Road Rajasthan, Ajmer, India},
	abstract = {Social media provides an inexpensive way to communicate with millions of users. These websites provide a platform to propagate your ideas to millions of people. The power of social media is often misused. Freedom of expressing opinions and beliefs on social media websites has been resulted in spread of hate speech. It has become a major challenge to check the dissemination of hate speech on websites of social media. We used Naive Bayes algorithm to classify text tweets into three classes i.e., tweets containing hate speech, tweets containing offensive language and tweets containing neither hate speech nor offensive language. It is a supervised machine learning based algorithm. We performed experiments with three variations of Naive Bayes i.e., Bernoulli's, multinomial and Gaussian Naive Bayes classifier. Bernoulli's and Multinomial Naïve Bayes delivered the best accuracy values.  © 2023 IEEE.},
	author_keywords = {Bernoulli's Naïve Bayes; Gaussian Naïve Bayes; hate speech; Multinomial Naïve Bayes},
	keywords = {Classifiers; Social networking (online); Speech recognition; Bernoulli; Bernoulli naive baye; Gaussian naive baye; Gaussians; Hate speech; Multinomial naive bayes; Naive bayes; Naive-Bayes algorithm; Social media; Supervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2023 International Conference on Artificial Intelligence and Smart Communication, AISC 2023; Conference date: 27 January 2023 through 29 January 2023; Conference code: 187724}
}

@ARTICLE{Perez202330575,
	author = {Perez, Juan Manuel and Luque, Franco M. and Zayat, Demian and Kondratzky, Martin and Moro, Agustin and Serrati, Pablo Santiago and Zajac, Joaquin and Miguel, Paula and Debandi, Natalia and Gravano, Agustin and Cotik, Viviana},
	title = {Assessing the Impact of Contextual Information in Hate Speech Detection},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {30575 – 30590},
	doi = {10.1109/ACCESS.2023.3258973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151495817&doi=10.1109%2fACCESS.2023.3258973&partnerID=40&md5=cb7123b24d9b99133035d60158ddf6c4},
	affiliations = {Instituto de Ciencias de la Computación, CONICET, Universidad de Buenos Aires (UBA), Buenos Aires, 1053, Argentina; Facultad de Astronomía, Matemática y Física, Universidad Nacional de Córdoba, Córdoba, 5000, Argentina; Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, 1033, Argentina; Universidad de Buenos Aires, Facultad de Derecho, Buenos Aires, 1053, Argentina; Universidad de Buenos Aires, Facultad de Filosofía y Letras, Buenos Aires, 1053, Argentina; Universidad Nacional Del Centro de la Provincia de Buenos Aires, Tandil, 7300, Argentina; Instituto de Investigaciones Gino Germani, Facultad de Ciencias Sociales, Universidad de Buenos Aires, Buenos Aires, 1053, Argentina; Universidad de San Martín, Escuela Interdisciplinaria de Altos Estudios Sociales, San Martín, 1650, Argentina; Universidad Nacional de Río Negro, Rio Negro, 8500, Argentina; Universidad Torcuato di Tella, Escuela de Negocios, Buenos Aires, 7350, Argentina; Universidad Torcuato di Tella, Laboratorio de Inteligencia Artificial, Buenos Aires, 7350, Argentina; Universidad de Buenos Aires, Facultad de Ciencias Exactas y Naturales, Departamento de Computación, Buenos Aires, 1053, Argentina},
	abstract = {Social networks and other digital media deal with huge amounts of user-generated contents where hate speech has become a problematic more and more relevant. A great effort has been made to develop automatic tools for its analysis and moderation, at least in its most threatening forms, such as in violent acts against people and groups protected by law. One limitation of current approaches to automatic hate speech detection is the lack of context. The spotlight on isolated messages, without considering any type of conversational context or even the topic being discussed, severely restricts the available information to determine whether a post on a social network should be tagged as hateful or not. In this work, we assess the impact of adding contextual information to the hate speech detection task. We specifically study a subdomain of Twitter data consisting of replies to digital newspapers posts, which provides a natural environment for contextualized hate speech detection. We built a new corpus in Spanish (Rioplatense variant) focused on hate speech associated to the COVID-19 pandemic, annotated using guidelines carefully designed by our interdisciplinary team. Our classification experiments using state-of-the-art transformer-based machine learning techniques show evidence that adding contextual information improves the performance of hate speech detection for two proposed tasks: binary and multi-label prediction, increasing their Macro F1 by 4.2 and 5.5 points, respectively. These results highlight the importance of using contextual information in hate speech detection. Our code, models, and corpus has been made available for further research.  © 2013 IEEE.},
	author_keywords = {contextual information; COVID-19 hate speech; hate speech detection; NLP; Spanish corpus; text classification},
	keywords = {Classification (of information); Job analysis; Learning systems; Social networking (online); Speech recognition; Text processing; Context- awareness; Contextual information; COVID-19 hate speech; Fake news; Hate speech; Hate speech detection with contextual information; Medium; Social networking (online); Spanish annotated corpus; Speech detection; Task analysis; Text classification; COVID-19},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Soto202227111,
	author = {Soto, Claver P. and Nunes, Gustavo M. S. and Gomes, José Gabriel R. C. and Nedjah, Nadia},
	title = {Application-specific word embeddings for hate and offensive language detection},
	year = {2022},
	journal = {Multimedia Tools and Applications},
	volume = {81},
	number = {19},
	pages = {27111 – 27136},
	doi = {10.1007/s11042-021-11880-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123489713&doi=10.1007%2fs11042-021-11880-2&partnerID=40&md5=a830cd9f2d57c8ccd305f2f5c3298857},
	affiliations = {Department of Computation, Federal Rural University of Rio de Janeiro, Rio de Janeiro, Brazil; Electrical Engineering Program, Federal University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Electronics Engineering and Telecommunications, Engineering Faculty, State University of Rio de Janeiro, Rio de Janeiro, Brazil},
	abstract = {For the task of hate speech and offensive language detection, this paper explores the potential advantages of using small datasets to develop efficient word embeddings used in models for deep learning. We investigate the impact of feature vectors generated by four selected word embedding techniques (word2vec, wang2vec, fastText, and GloVe) applied to text datasets with size in the order of a billion tokens. After training the classifiers using pre-trained word embeddings, we compare the classification performance with the results from using feature vectors generated from small datasets with size in the order of thousands of tokens. Using numerical examples, we show that the word embeddings with the smallest size yield slightly worse accuracy values but, in combination with smaller training times, such embeddings lead to non-dominated solutions. That fact has an immediate application in significantly reducing training time at a small penalty in classification accuracy. We explore two ways to rank the studied alternatives based on performance factors and on PROMETHEE-II scores. According to both rankings, GloVe is the best method for NILC-embedding, and fastText is the best method for dataset-specific embedding. It is expected that specific word embedding should yield a better fit to a particular dataset, which should yield shorter training and better accuracy. However, the obtained results indicate that NILC-embeddings would lead to an equally good fit. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Convolutional neural network; Hate and offensive language detection; Multi-criteria analysis; Word embeddings},
	keywords = {Classification (of information); Convolutional neural networks; Deep learning; Speech recognition; Convolutional neural network; Embeddings; Features vector; Hate and offensive language detection; Language detection; Multicriteria analysis; Offensive languages; Small data set; Training time; Word embedding; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Jacobs2023436,
	author = {Jacobs, Christiaan and Rakotonirina, Nathanaël Carraz and Chimoto, Everlyn Asiko and Bassett, Bruce A. and Kamper, Herman},
	title = {Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili},
	year = {2023},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	volume = {2023-August},
	pages = {436 – 440},
	doi = {10.21437/Interspeech.2023-421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165666313&doi=10.21437%2fInterspeech.2023-421&partnerID=40&md5=243019c049d581f2d8db890f98c17b4b},
	affiliations = {Department of Electrical & Electronic Engineering, Stellenbosch University, South Africa; Universitat Pompeu Fabra, Spain; African Institute for Mathematical Sciences, Cape Town, South Africa; Department of Mathematics & Applied Mathematics, University of Cape Town, South Africa; VoxCroft Analytics, Cape Town, South Africa},
	abstract = {We consider hate speech detection through keyword spotting on radio broadcasts. One approach is to build an automatic speech recognition (ASR) system for the target low-resource language. We compare this to using acoustic word embedding (AWE) models that map speech segments to a space where matching words have similar vectors. We specifically use a multilingual AWE model trained on labelled data from well-resourced languages to spot keywords in data in the unseen target language. In contrast to ASR, the AWE approach only requires a few keyword exemplars. In controlled experiments on Wolof and Swahili where training and test data are from the same domain, an ASR model trained on just five minutes of data outperforms the AWE approach. But in an in-the-wild test on Swahili radio broadcasts with actual hate speech keywords, the AWE model (using one minute of template data) is more robust, giving similar performance to an ASR system trained on 30 hours of labelled data. © 2023 International Speech Communication Association. All rights reserved.},
	author_keywords = {acoustic word embeddings; hate speech detection; spotting; zero-resource speech processing},
	keywords = {Radio broadcasting; Speech communication; Speech processing; Speech recognition; Vector spaces; Acoustic word embedding; Automatic speech recognition; Automatic speech recognition system; Embeddings; Hate speech detection; Labeled data; Low resource languages; Speech detection; Spotting; Zero-resource speech processing; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 24th International Speech Communication Association, Interspeech 2023; Conference date: 20 August 2023 through 24 August 2023; Conference code: 191724; All Open Access, Green Open Access}
}

@ARTICLE{Velankar2023121,
	author = {Velankar, Abhishek and Patil, Hrushikesh and Joshi, Raviraj},
	title = {Mono vs Multilingual BERT for Hate Speech Detection and Text Classification: A Case Study in Marathi},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13739 LNAI},
	pages = {121 – 128},
	doi = {10.1007/978-3-031-20650-4_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142722629&doi=10.1007%2f978-3-031-20650-4_10&partnerID=40&md5=672c93fbe8532c59d10de32ddbd28580},
	affiliations = {Pune Institute of Computer Technology, Maharashtra, Pune, India; Indian Institute of Technology Madras, Tamilnadu, Chennai, India; L3Cube, Pune, India},
	abstract = {Transformers are the most eminent architectures used for a vast range of Natural Language Processing tasks. These models are pre-trained over a large text corpus and are meant to serve state-of-the-art results over tasks like text classification. In this work, we conduct a comparative study between monolingual and multilingual BERT models. We focus on the Marathi language and evaluate the models on the datasets for hate speech detection, sentiment analysis, and simple text classification in Marathi. We use standard multilingual models such as mBERT, indicBERT, and xlm-RoBERTa and compare them with MahaBERT, MahaALBERT, and MahaRoBERTa, the monolingual models for Marathi. We further show that Marathi monolingual models outperform the multilingual BERT variants in five different downstream fine-tuning experiments. We also evaluate sentence embeddings from these models by freezing the BERT encoder layers. We show that monolingual MahaBERT-based models provide rich representations as compared to sentence embeddings from multi-lingual counterparts. However, we observe that these embeddings are not generic enough and do not work well on out-of-domain social media datasets. We consider two Marathi hate speech datasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification dataset L3Cube-MahaSent, and Marathi Headline, Articles classification datasets. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {BERT; Hate speech detection; Marathi BERT; Natural language processing; Sentiment analysis; Text classification},
	keywords = {Classification (of information); Embeddings; Speech recognition; BERT; Embeddings; Hate speech detection; Language processing; Marathi BERT; Natural language processing; Natural languages; Sentiment analysis; Speech detection; Text classification; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; Conference name: 10th IAPR TC3 International Workshop on Artificial Neural Networks in Pattern Recognition, ANNPR 2022; Conference date: 24 November 2022 through 26 November 2022; Conference code: 286239}
}

@ARTICLE{Apostolopoulos2023536,
	author = {Apostolopoulos, George C. and Liakos, Panagiotis and Delis, Alex},
	title = {A Social-Aware Deep Learning Approach for Hate-Speech Detection},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13421 LNCS},
	pages = {536 – 544},
	doi = {10.1007/978-3-031-25158-0_43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151133707&doi=10.1007%2f978-3-031-25158-0_43&partnerID=40&md5=f0434d8fac062fb23527a779717f2e57},
	affiliations = {University of Athens, Athens, 15703, Greece},
	abstract = {Despite considerable efforts to automatically identify hate-speech in online social networks, users still face an uphill battle with toxic posts that seek to sow hatred. In this paper, we initially observe that there is a great deal of social properties transcending both hateful passages and respective authors. We then exploit this observation by i) developing deep learning neural networks that classify online posts as either hate or non-hate based on their content, and ii) proposing an architecture that may invigorate any such text-based classifier with the use of additional social features. Our combined approach considerably enhances the classification accuracy of previously proposed state-of-the-art models and our evaluation reveals social attributes that are the most helpful in our classification effort. We also contribute the first publicly-available dataset for hate-speech detection that features social properties. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Social features; Twitter; User profile},
	keywords = {Deep learning; Feature extraction; Speech recognition; User profile; Deep learning; Learning approach; Learning neural networks; Network users; Social feature; Social properties; Social-aware; Speech detection; Twitter; User's profiles; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th International Joint Conference on Asia-Pacific Web (APWeb) and Web-Age Information Management (WAIM), APWeb-WAIM 2022; Conference date: 25 November 2022 through 27 November 2022; Conference code: 291629}
}

@ARTICLE{Fkih20237,
	author = {Fkih, Fethi and Moulahi, Tarek and Alabdulatif, Abdulatif},
	title = {Machine Learning Model for Offensive Speech Detection in Online Social Networks Slang Content},
	year = {2023},
	journal = {WSEAS Transactions on Information Science and Applications},
	volume = {20},
	pages = {7 – 15},
	doi = {10.37394/23209.2023.20.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149718382&doi=10.37394%2f23209.2023.20.2&partnerID=40&md5=25df52e41562ee687f9fe973b338cb4b},
	affiliations = {Department of Computer Science, College of Computer, Qassim University, Buraydah, 52571, Saudi Arabia; Department of Information Technology, College of Computer, Qassim University, Buraydah, 52571, Saudi Arabia},
	abstract = {The majority of the world’s population (about 4 billion people) now uses social media such as Facebook, Twitter, Instagram, and others. Social media has evolved into a vital form of communication, allowing individuals to interact with each other and share their knowledge and experiences. On the other hand, social media can be a source of malevolent conduct. In fact, nasty and criminal activity, such as cyberbullying and threatening, has grown increasingly common on social media, particularly among those who use Arabic. Detecting such behavior, however, is a difficult endeavor since it involves natural language, particularly Arabic, which is grammatically and syntactically rich and fruitful. Furthermore, social network users frequently employ Arabic slang and fail to correct obvious grammatical norms, making automatic recognition of bullying difficult. Meanwhile, only a few research studies in Arabic have addressed this issue. The goal of this study is to develop a method for recognizing and detecting Arabic slang offensive speech in Online Social Networks (OSNs). As a result, we propose an effective strategy based on the combination of Artificial Intelligence and statistical approach due to the difficulty of setting linguistic or semantic rules for modeling Arabic slang due to the absence of grammatical rules. An experimental study comparing frequent machine learning tools shows that Random Forest (RF) outperforms others in terms of precision (90%), recall (90%), and f1-score (90%). © World Scientific and Engineering Academy and Society. All rights reserved.},
	author_keywords = {Arabic slang; Arabic social media; Classifications; Cyberbullying; Machine Learning; offensive speech detection; Social Network},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Alhejaili2023467,
	author = {Alhejaili, Ruba and Alsaeedi, Abdullah and Yafooz, Wael M. S.},
	title = {Detecting Hate Speech in Arabic Tweets During COVID-19 Using Machine Learning Approaches},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {479},
	pages = {467 – 475},
	doi = {10.1007/978-981-19-3148-2_39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142767354&doi=10.1007%2f978-981-19-3148-2_39&partnerID=40&md5=f1f6293ad7f346b6c506c6cc5b8c1810},
	affiliations = {Department of Computer Science, College of Computer Science and Engineering, Taibah University, Madinah, Saudi Arabia},
	abstract = {Content on the Web is increasing day by day, especially on social media, as all users can express their opinions freely and without restrictions. Accordingly, many negative activities have appeared, such as abusive language, racism, and hate speech. Hate speech is one of the negative social media manifestations that require tools to be detected. In this paper, we try to detect hate speech in Arabic tweets published during the COVID-19 pandemic. We compiled a dataset during the pandemic period from January 31 to March 6, 2021. We used a set of machine learning models, namely support vector machine (SVM), random forest (RF), logistic regression (DT), decision tree, AdaBoost, k-nearest neighbors (KNN), and Gaussian naïve Bayes (GNB). For feature extraction, we used TF-IDF, where we trained the dataset in three types: unigram, bigram, and trigram. The best results were achieved by LR, RF, and SVM, with an accuracy of 90.8% for LR. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Coronavirus classification; Feature extraction; Hate speech; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 3rd Doctoral Symposium on Computational Intelligence, DoSCI 2022; Conference date: 5 March 2022 through 5 March 2022; Conference code: 286199}
}

@ARTICLE{Saleh2023,
	author = {Saleh, Hind and Alhothali, Areej and Moria, Kawthar},
	title = {Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model},
	year = {2023},
	journal = {Applied Artificial Intelligence},
	volume = {37},
	number = {1},
	doi = {10.1080/08839514.2023.2166719},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147730544&doi=10.1080%2f08839514.2023.2166719&partnerID=40&md5=fada26a7ae9a88223ebac34ab3491b70},
	affiliations = {Computer Science Department, University of Tabuk, Tabuk, Saudi Arabia; Computer Science Department, King Abdulaziz University Jeddah, Makkah, Saudi Arabia},
	abstract = {There is an increased demand for detecting online hate speech, especially with the recent changing policies of hate content and free-of-speech right of online social media platforms. Detecting hate speech will reduce its negative impact on social media users. A lot of effort in the Natural Language Processing (NLP) field aimed to detect hate speech in general or detect specific hate speech such as religion, race, gender, or sexual orientation. Hate communities tend to use abbreviations, intentional spelling mistakes, and coded words in their communication to evade detection, which adds more challenges to hate speech detection tasks. Word representation from its domain will play an increasingly pivotal role in detecting hate speech. This paper investigates the feasibility of leveraging domain-specific word embedding as features and a bidirectional LSTM-based deep model as a classifier to automatically detect hate speech. This approach guarantees that the word is assigned its negative meaning, which is a very helpful technique to detect coded words. Furthermore, we investigate the use of the transfer learning language model (BERT) on the hate speech problem as a binary classification task as it provides high-performance results for many NLP tasks. The experiments showed that domain-specific word embedding with the bidirectional LSTM-based deep model achieved a 93% f1-score, while BERT achieved 96% f1-score on a combined balanced dataset from available hate speech datasets. The results proved that the performance of pre-trained models is influenced by the size of the trained data. Although there is a huge variation in the corpus size, the first approach achieved a very close result compared to BERT, which is trained on a huge data corpus, this is because it is trained on data related to the same domain. The first approach was very helpful to detect coded words while the second approach achieved better performance because it is trained on much larger data. To conclude, it is very helpful to build large pre-trained models from rich domains specific content in current social media platforms. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	keywords = {Embeddings; Long short-term memory; Natural language processing systems; Social networking (online); Speech communication; Domain specific; Embeddings; F1 scores; Gender orientation; Language processing; Natural languages; Online social medias; Performance; Social media; Social media platforms; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 50; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Themeli2023424,
	author = {Themeli, Chrysoula and Giannakopoulos, George and Pittaras, Nikiforos},
	title = {A Study of Text Representations for Hate Speech Detection},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13452 LNCS},
	pages = {424 – 437},
	doi = {10.1007/978-3-031-24340-0_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149982344&doi=10.1007%2f978-3-031-24340-0_32&partnerID=40&md5=3b06ecc5925f56789950070f059ea869},
	affiliations = {Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, Greece; NCSR Demokritos, Athens, Greece; SciFY PNPC, Athens, Greece},
	abstract = {The pervasiveness of the Internet and social media have enabled the rapid and anonymous spread of Hate Speech content on microblogging platforms such as Twitter. Current EU and US legislation against hateful language, in conjunction with the large amount of data produced in these platforms has led to automatic tools being a necessary component of the Hate Speech detection task and pipeline. In this study, we examine the performance of several, diverse text representation techniques paired with multiple classification algorithms, on the automatic Hate Speech detection and abusive language discrimination task. We perform an experimental evaluation on binary and multiclass datasets, paired with significance testing. Our results show that simple hate-keyword frequency features (BoW) work best, followed by pre-trained word embeddings (GLoVe) as well as N-gram graphs (NGGs): a graph-based representation which proved to produce efficient, very low-dimensional but rich features for this task. A combination of these representations paired with Logistic Regression or 3-layer neural network classifiers achieved the best detection performance, in terms of micro and macro F-measure. © 2023, Springer Nature Switzerland AG.},
	author_keywords = {Classification; Hate speech; Natural language processing; Social media},
	keywords = {Graphic methods; Natural language processing systems; Social networking (online); Text processing; Hate speech; Internet media; Language processing; Micro-blogging platforms; Natural language processing; Natural languages; Social media; Speech content; Speech detection; Text representation; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing 2019; Conference date: 7 April 2019 through 13 April 2019; Conference code: 291019}
}

@ARTICLE{Akhter20221925,
	author = {Akhter, Muhammad Pervez and Jiangbin, Zheng and Naqvi, Irfan Raza and AbdelMajeed, Mohammed and Zia, Tehseen},
	title = {Abusive language detection from social media comments using conventional machine learning and deep learning approaches},
	year = {2022},
	journal = {Multimedia Systems},
	volume = {28},
	number = {6},
	pages = {1925 – 1940},
	doi = {10.1007/s00530-021-00784-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103410481&doi=10.1007%2fs00530-021-00784-8&partnerID=40&md5=9b94f8dbb9f9534ec04f52d94b2e6c9a},
	affiliations = {School of Software and Microelectronics, Northwestern Polytechnical University, Xian, 710072, China; School of Computer Science and Technology, Northwestern Polytechnical University, Xian, 710072, China; Department of Computer Science, COMSATS University, Islamabad, 44000, Pakistan},
	abstract = {With the increase in the culture of social media and netizen, every day, millions of comments are posted on the uploaded posts. The use of abusive language in user comments has been increased rapidly. Abusive language in online comments initiates cyber-bullying that targets individuals (celebrity, politician, and product) and a group of people (specific country, age, and religion). It is important to detect and analyze abusive language from online comments automatically. There have been several attempts in the literature to detect abusive language for English. In this study, we perform abusive language detection from Urdu and Roman Urdu comments using five diverse ML models (NB, SVM, IBK, Logistic, and JRip) and four DL models (CNN, LSTM, BLSTM, and CLSTM). We apply these models on a large dataset with ten thousands of Roman Urdu comments and a small dataset with more than two thousand comments of Urdu. Natural language constructs, English-like nature of Roman Urdu script, and Nastaleeq style of Urdu make it more challenging to process and classify the comments of both scripts using deep learning and machine learning approaches. From experiments, we find that the convolutional neural network outperforms the other models and achieves 96.2% and 91.4% accuracy on Urdu and Roman Urdu. Our results also reveal that the one-layer architectures of deep learning models give better results than two-layer architectures. Further, we compare the performance of deep learning models with five conventional machine learning models and conclude that deep learning models perform significantly better than machine learning models. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Abusive language; Cyberbullying; Deep learning; Machine learning; Natural language processing},
	keywords = {Convolutional neural networks; Learning algorithms; Learning systems; Long short-term memory; Natural language processing systems; Network architecture; Social networking (online); Support vector machines; Abusive language; Cyber bullying; Deep learning; Language detection; Language processing; Learning models; Machine-learning; Natural language processing; Natural languages; Social media; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}

@CONFERENCE{Cooke2023541,
	author = {Cooke, Shane and Graux, Damien and Dev, Soumyabrata},
	title = {Multi Platform-Based Hate Speech Detection},
	year = {2023},
	journal = {International Conference on Agents and Artificial Intelligence},
	volume = {3},
	pages = {541 – 549},
	doi = {10.5220/0011698600003393},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165966848&doi=10.5220%2f0011698600003393&partnerID=40&md5=f2884ee604d5b7a57e1ad81d190ae45d},
	affiliations = {ADAPT SFI Research Centre, School of Computer Science, University College Dublin, Ireland; ADAPT SFI Research Centre, Trinity College Dublin, Ireland},
	abstract = {A major issue faced by social media platforms today is the detection, and handling of hateful speech. The intricacies and imperfections of online communication make this a difficult task, and the rapidly changing use of both non-hateful, and hateful language in the online sphere means that researchers must constantly update and modify their hate speech detection methodologies. In this study, we propose an accurate and versatile multi-platform model for the detection of hate speech, using first-hand data scraped from some of the most popular social media platforms, that we share to the community. We explore and optimise 50 different model approaches, and evaluate their performances using several evaluation metrics. Overall, we successfully build a hate speech detection model, pairing the USE word embeddings with the SVC machine learning classifier, to obtain an average accuracy of 95.65% and achieved a maximum accuracy of 96.89%. We also develop and share an application allowing users to test sentences against a collection of the most accurate hate speech detection models. Our application then returns a aggregated hate speech classification, together with a confidence level, and a breakdown of the methodologies used to produce the final classification for explainability. © 2023 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Combining Embeddings and Classifiers; Hate Speech Detection; Multi-Platform},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th International Conference on Agents and Artificial Intelligence, ICAART 2023; Conference date: 22 February 2023 through 24 February 2023; Conference code: 301209; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Nelatoori20237884,
	author = {Nelatoori, Kiran Babu and Kommanti, Hima Bindu},
	title = {Attention-Based Bi-LSTM Network for Abusive Language Detection},
	year = {2023},
	journal = {IETE Journal of Research},
	volume = {69},
	number = {11},
	pages = {7884 – 7892},
	doi = {10.1080/03772063.2022.2034534},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124727664&doi=10.1080%2f03772063.2022.2034534&partnerID=40&md5=f5e35d32564ab901dbecd6a9a1b41c65},
	affiliations = {Department of Computer Science and Engineering, National Institute of Technology, Andhra Pradesh, Tadepalligudem, 534 101, India},
	abstract = {Prevention of abusive content in social media platforms has received a lot of attention in recent years. The problem is still a challenge due to the nuances present in the content posted and the tactics of users to pass through the abusive detection algorithms employed by the social media giants. This paper presents a robust deep learning model that takes the advantage of both character and word representations, to address the challenges associated with the text content of a social media post for detecting abusive content. The proposed model uses character CNN to capture morphological information and learns the important features to distinguish abusive content with the help of an Attention-based Bi-LSTM network. In addition, it uses the pooling layer to avoid spatial translations. We confined our model to only the text content of the social media posts due to the limitations of collecting user characteristics for existing datasets and to honour the privacy concerns of users. Our model is dataset agnostic, as revealed by the empirical results on the data sets of multiple social media platforms. It outperformed all previous methods for abusive language detection with text-only features. © 2023 IETE.},
	author_keywords = {Abusive language; Average pooling; Bi-LSTM network; Character CNN; Contextual attention; HateMap; Toxic comments; Word embedding},
	keywords = {Bismuth compounds; Social networking (online); Abusive language; Average pooling; Bi-LSTM network; Character CNN; Contextual attention; Embeddings; Hatemap; Social media; Toxic comment; Word embedding; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Nayla2023644,
	author = {Nayla, Adine and Setianingsih, Casi and Dirgantoro, Burhanuddin},
	title = {Hate Speech Detection on Twitter Using BERT Algorithm},
	year = {2023},
	journal = {ICCoSITE 2023 - International Conference on Computer Science, Information Technology and Engineering: Digital Transformation Strategy in Facing the VUCA and TUNA Era},
	pages = {644 – 649},
	doi = {10.1109/ICCoSITE57641.2023.10127831},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163091006&doi=10.1109%2fICCoSITE57641.2023.10127831&partnerID=40&md5=7fbe297d95ed269fbab102af04420e10},
	affiliations = {Telkom University, School of Electrical Engineering, Bandung, Indonesia},
	abstract = {Hate speech on one social media platform, Twitter, is uncommon. Users on the Twitter platform can freely obtain, exchange information, and express opinions. This is one of the main factors that a person can be exposed to hate speech on Twitter. Victims who are exposed to hate speech may suffer from mental health disorders because most victims of hate speech are attacked verbally or emotionally. However, the lack of countermeasures against the detection of hate speech on the Twitter social media platform is still rare. In this study, a simulation was carried out using the website, along with testing and analyzing the detection of hate speech. The test is done by inputting a text on the hate speech website, and then the website will do a preprocessing and analyze this text using the BERT algorithm to classify whether the word is hate speech or not. The training results found that the detection of hate speech on Twitter user accounts using the BERT Algorithm has a 78.69% accuracy, a 78.90% precision, a 78.69% recall, and a 78.77% F1 score against the classification of hate speech groups. Thus users will more easily detect hate speech on Twitter by using the hate speech website. © 2023 IEEE.},
	author_keywords = {BERT Algorithm; Hate Speech; Twitter; Web Application},
	keywords = {Speech recognition; BERT algorithm; Exposed to; Hate speech; Health disorders; Mental health; Social media platforms; Speech detection; Twitter; WEB application; Web applications; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2023 International Conference on Computer Science, Information Technology and Engineering, ICCoSITE 2023; Conference date: 16 February 2023; Conference code: 188965}
}

@CONFERENCE{Al-Dabet2023,
	author = {Al-Dabet, Saja and Elmassry, Ahmed and Alomar, Ban and Alshamsi, Abdullah},
	title = {Transformer-based Arabic Offensive Speech Detection},
	year = {2023},
	journal = {2023 International Conference on Emerging Smart Computing and Informatics, ESCI 2023},
	doi = {10.1109/ESCI56872.2023.10100134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158149006&doi=10.1109%2fESCI56872.2023.10100134&partnerID=40&md5=b42c6318691b155eb6bc0c74208db77f},
	affiliations = {United Arab Emerites University, Computer Science, United Arab Emirates; Higher Colleges of Technology, Department of Computer Information Systems, United Arab Emirates},
	abstract = {The prevalence of social media platforms prompted detecting any language that is intended to harm or intimidate another person or group of people in online posts and comments. On Twitter, for instance, users are susceptible to cyberbullying and hate speech, which may develop into physical and psychological violence. A transformer-based approach is presented in this study to address the offensive speech detection issue. This model employs versions of the CAMeLBERT model and is validated using a mixture of four benchmark Twitter Arabic datasets annotated for hate speech detection task, including the (OSACT5 2022) workshop shared task dataset. The presented model was capable of recognizing Arabic tweets containing offensive speech with 87.15 % accuracy and 83.6 % F1 score. © 2023 IEEE.},
	author_keywords = {Arabic dataset; Cyberbullying; Offensive Speech; Transformer},
	keywords = {Computer crime; Social networking (online); Arabic dataset; Cyber bullying; Detection tasks; F1 scores; Offensive speech; Social media platforms; Speech detection; Transformer; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 5th International Conference on Emerging Smart Computing and Informatics, ESCI 2023; Conference date: 1 March 2023 through 3 March 2023; Conference code: 188070}
}

@ARTICLE{Song2022,
	author = {Song, Rui and Giunchiglia, Fausto and Shen, Qiang and Li, Nan and Xu, Hao},
	title = {Improving Abusive Language Detection with online interaction network},
	year = {2022},
	journal = {Information Processing and Management},
	volume = {59},
	number = {5},
	doi = {10.1016/j.ipm.2022.103009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133907362&doi=10.1016%2fj.ipm.2022.103009&partnerID=40&md5=e5c0d53d2f8b2a379a638894fbb975d0},
	affiliations = {School of Artificial Intelligence, Jilin University, Changchun, 130012, China; College of Computer Science and Technology, Jilin University, Changchun, 130012, China; Department of Information Engineering and Computer Science, University of Trento, Italy; Chongqing Research Institute, Jilin University, Chongqing, 401123, China},
	abstract = {The rapid development of online social media makes Abusive Language Detection (ALD) a hot topic in the field of affective computing. However, most methods for ALD in social networks do not take into account the interactive relationships among user posts, which simply regard ALD as a task of text context representation learning. To solve this problem, we propose a pipeline approach that considers both the context of a post and the characteristics of interaction network in which it is posted. Specifically, our method is divided into pre-training and downstream tasks. First, to capture fine contextual features of the posts, we use Bidirectional Encoder Representation from Transformers (BERT) as Encoder to generate sentence representations. Later, we build a Relation-Special Network according to the semantic similarity between posts as well as the interaction network structural information. On this basis, we design a Relation-Special Graph Neural Network (RSGNN) to spread effective information in the interaction network and learn the classification of texts. The experiment proves that our method can effectively improve the detection effect of abusive posts over three public datasets. The results demonstrate that injecting interaction network structure into the abusive language detection task can significantly improve the detection results. © 2022},
	author_keywords = {Abusive Language Detection; BERT; Graph neural network; Interaction network; Social network},
	keywords = {Classification (of information); Economic and social effects; Network coding; Semantics; Social networking (online); Abusive language detection; Affective Computing; Bidirectional encoder representation from transformer; Graph neural networks; Hot topics; Interaction networks; Language detection; Online interaction; Online social medias; Social network; Graph neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{de Oliveira2023374,
	author = {de Oliveira, Aillkeen Bezerra and de Souza Baptista, Cláudio and Firmino, Anderson Almeida and de Paiva, Anselmo Cardoso},
	title = {Using Multilingual Approach in Cross-Lingual Transfer Learning to Improve Hate Speech Detection},
	year = {2023},
	journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	volume = {1},
	pages = {374 – 384},
	doi = {10.5220/0011851800003467},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160752047&doi=10.5220%2f0011851800003467&partnerID=40&md5=917d80dec2f5227334548b2348b36fdb},
	affiliations = {Federal University of Campina Grande, Rua Aprigio Veloso, 882 - Universitário, Paraiba, Campina Grande, Brazil; Federal University of Maranhão, Av. dos Portugueses, 1966 - Vila Bacanga, Maranhão, São Luís, Brazil},
	abstract = {In the Internet age people are increasingly connected. They have complete freedom of speech, being able to share their opinions with the society on social media. However, freedom of speech is often used to spread hate speech. This type of behavior can lead to criminality and may result in negative psychological effects. Therefore, the use of computer technology is very useful for detecting and consequently mitigating this kind of cyber attacks. Thus, this paper proposes the use of a state-of-the-art model for detecting political-related hate speech on social media. We used three datasets with a significant lexical distance between them. The datasets are in English, Italian, and Filipino languages. To detect hate speech, we propose the use of a Pre-Trained Language Model (PTLM) with Cross-Lingual Learning (CLL) along with techniques such as Zero-Shot (ZST), Joint Learning (JL), Cascade Learning (CL), and CL/JL+. We achieved 94.3% in the F-Score metric using CL/JL+ strategy with the Italian and Filipino datasets as the source language and the English dataset as the target language. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)},
	author_keywords = {Cross-Lingual Learning; Hate Speech Detection; Natural Language Processing},
	keywords = {Learning algorithms; Learning systems; Natural language processing systems; Network security; Speech recognition; Zero-shot learning; Cross-lingual; Cross-lingual learning; Freedom of speech; Hate speech detection; Joint learning; Language processing; Natural language processing; Natural languages; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 25th International Conference on Enterprise Information Systems, ICEIS 2023; Conference date: 24 April 2023 through 26 April 2023; Conference code: 188803; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ghosh2023,
	author = {Ghosh, Koyel and Sonowal, Debarshi and Basumatary, Abhilash and Gogoi, Bidisha and Senapati, Apurbalal},
	title = {Transformer-Based Hate Speech Detection in Assamese},
	year = {2023},
	journal = {2023 IEEE Guwahati Subsection Conference, GCON 2023},
	doi = {10.1109/GCON58516.2023.10183497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167340593&doi=10.1109%2fGCON58516.2023.10183497&partnerID=40&md5=b758f55f6c63ef64e4d859f917039e8f},
	affiliations = {Central Institute of Technology, Computer Science and Engineering, Assam, Kokrajhar, India},
	abstract = {Hate speech or hate content detection in a text is one of the emerging research in Natural Language Processing. Over several years, the popularity of social media has sky-rocketed, where anyone can share their feelings, desire, anger, etc. Sometimes, these posts include offensive information that hurts others, intentionally or unconsciously. Depending on the forum's visibility, such posts instantly spread over millions of people, which may lead to violence. In these circumstances, it is an essential task to identify whether the comment is hateful. In the Indian language context, this task presents greater complexity due to its multilingual nature and limited availability of resources. This situation motivated us to analyze hate speech in the Assamese language. The paper's contribution is in two aspects: firstly, it involves the development of a tagged dataset in Assamese comprising 4,000 sentences; secondly, by fine-tuning the mBERT-cased (bert-base-multilingual-cased) and the Bangla-BERT (sagorsarker/bangla-bert-base) model using the Assamese data to detect instances of hate speech effectively. Based on what we know, it is one of the pioneering attempts at detecting hate speech in the Assamese language.  © 2023 IEEE.},
	author_keywords = {Assamese dataset; BERT; Hate Speech detection; Transformer},
	keywords = {Natural language processing systems; Assamese dataset; BERT; Content detection; Hate speech detection; Indian languages; Language processing; Natural languages; Social media; Speech detection; Transformer; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 2023 IEEE Guwahati Subsection Conference, GCON 2023; Conference date: 23 June 2023 through 25 June 2023; Conference code: 190967}
}

@CONFERENCE{Gala20233240,
	author = {Gala, Jay and Gandhi, Deep and Mehta, Jash and Talat, Zeerak},
	title = {A Federated Approach for Hate Speech Detection},
	year = {2023},
	journal = {EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {3240 – 3251},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159857605&partnerID=40&md5=3721b26a48d8ffcc1867e75bf0998b65},
	affiliations = {AI4Bharat; University of Alberta, Canada; Georgia Institute of Technology, United States; MBZUAI, United Arab Emirates},
	abstract = {Hate speech detection has been the subject of high research attention, due to the scale of content created on social media. In spite of the attention and the sensitive nature of the task, privacy preservation in hate speech detection has remained under-studied. The majority of research has focused on centralised machine learning infrastructures which risk leaking data. In this paper, we show that using federated machine learning can help address privacy the concerns that are inherent to hate speech detection while obtaining up to 6.81% improvement in terms of F1-score. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Centralised; F1 scores; Machine-learning; Privacy preservation; Social media; Speech detection; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424}
}

@CONFERENCE{Lala2023,
	author = {Lala, Chirag and Dwivedi, Pulkit},
	title = {Hate Speech Detection Network Using LSTM},
	year = {2023},
	journal = {2023 International Conference for Advancement in Technology, ICONAT 2023},
	doi = {10.1109/ICONAT57137.2023.10080786},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153299854&doi=10.1109%2fICONAT57137.2023.10080786&partnerID=40&md5=1d0d14eb96b4d462a6044cc8588493c2},
	affiliations = {Chandigarh University, AIT CSE, India},
	abstract = {Socia1 media is an extremely popular form of communication today. People offer their opinions and insights on a variety of topics, including politics, video games, and their personal lives. These platforms are occasionally used by some people to propagate false information about another person or group of people. The term 'hate statement' refers to this kind of offensive material. One of the most well-known social media platforms is Twitter. But many people also use Twitter to disseminate offensive material. It is very hard to manually weed out abusive comments from the hundreds of millions of tweets that are generated every day on Twitter. Therefore, these offensive tweets ought to be automatically filtered out. In this study, we are developing an LSTM model for categorising tweets as either containing hate content or not. The dataset used is a publicly available dataset on Kaggle. This model has an accuracy of 98.04% on the training dataset and 97.19% on the validation dataset. For the test dataset, a precision of 0.98 is obtained for non-hate tweets and 0.93 for hate statement tweets.  © 2023 IEEE.},
	author_keywords = {CNN; Deep Learning; LSTM; Natural Language Processing; RNN},
	keywords = {Long short-term memory; Natural language processing systems; Social networking (online); Speech recognition; Deep learning; Detection networks; Language processing; LSTM; Natural language processing; Natural languages; Personal lives; RNN; Speech detection; Video-games; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd International Conference for Advancement in Technology, ICONAT 2023; Conference date: 24 January 2023 through 26 January 2023; Conference code: 187687}
}

@ARTICLE{Naveed202315,
	author = {Naveed, Hafsa and Sohail, Abid and Zain, Jasni Mohamad and Saleem, Noman and Ali, Rao Faizan and Anwar, Shahid},
	title = {Detection of Toxic Content on Social Networking Platforms Using Fine Tuned ULMFiT Model},
	year = {2023},
	journal = {Intelligent Automation and Soft Computing},
	volume = {35},
	number = {1},
	pages = {15 – 30},
	doi = {10.32604/iasc.2023.023277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135005700&doi=10.32604%2fiasc.2023.023277&partnerID=40&md5=248d0a5695a8d7f8c9425cd718f8a96a},
	affiliations = {Department of Software Engineering, Faculty of Science, University of Lahore, Pakistan; Department of Computer Science, COMSATS University Islamabad, Lahore Campus, Pakistan; Institute for Big Data Analytics and Artificial Intelligence (IBDAAI), Kompleks Al-Khawarizmi, Universiti Teknologi MARA, Shah Alam Selangor, 40450, Malaysia; TechnoGenics SMC PVT LTD, Lahore, Pakistan; Department of Computer and Information Science, Universiti Teknologi PETRONAS, Bandar Seri Iskandar Tronoh, Perak, Malaysia; Department of Information Engineering Technology, National Skills University Islamabad, Sector H-8/1 Faiz Ahmed Faiz Road, Islamabad, Pakistan},
	abstract = {Question and answer websites such as Quora, Stack Overflow, Yahoo Answers and Answer Bag are used by professionals. Multiple users post questions on these websites to get the answers from domain specific professionals. These websites are multilingual meaning they are available in many different languages. Current problem for these types of websites is to handle meaningless and irrelevant content. In this paper we have worked on the Quora insincere questions (questions which are based on false assumptions or questions which are trying to make a statement rather than seeking for helpful answers) dataset in order to identify user insincere questions, so that Quora can eliminate those questions from their platform and ultimately improve the communication among users over the platform. Previously, a research was carried out with recurrent neural network and pretrained glove word embeddings, that achieved the F1 score of 0.69. The proposed study has used a pre-trained ULMFiT model. This model has outperformed the previous model with an F1 score of 0.91, which is much higher than the previous studies. © 2023, Tech Science Press. All rights reserved.},
	author_keywords = {Artificial intelligence; Machine learning; Natural language processing; Quora mining; Text mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jarquín-Vásquez2023283,
	author = {Jarquín-Vásquez, Horacio and Escalante, Hugo Jair and Montes-y-Gómez, Manuel},
	title = {Improving the Identification of Abusive Language Through Careful Design of Pre-training Tasks},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13902 LNCS},
	pages = {283 – 292},
	doi = {10.1007/978-3-031-33783-3_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164252576&doi=10.1007%2f978-3-031-33783-3_27&partnerID=40&md5=7339224539d5d2f8ca7d8ca25a4d6cb9},
	affiliations = {Instituto Nacional de Astrofísica, Óptica y Electrónica (INAOE), Puebla, Mexico},
	abstract = {The use of Deep Learning-based solutions has become popular in Natural Language Processing due to their remarkable performance in a wide variety of tasks. Specifically, Transformer-based models (e.g. BERT) have become popular in recent years due to their outstanding performance and their ease of adaptation (fine-tuning) in a large number of domains. Despite their outstanding results, the fine-tuning of these models under the presence of informal language writing, especially the one that contains offensive words and expressions, remains a challenging task, due to the lack of vocabulary coverage and proper task contextual information. To overcome this issue, we proposed the domain adaptation of the BERT language model to the abusive language detection task. In order to achieve this, we constrain the language model with the adaptation of two default pre-trained tasks, through the retraining of the model parameters. The obtained configurations were evaluated in six abusive language datasets, showing encouraging results; a remarkable improvement was achieved with the use of the proposed approaches in comparison with its base model. In addition to this, competitive results were obtained with respect to state-of-the-art approaches, thus obtaining a robust and easy-to-train model for the identification of abusive language. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Abusive language; Pretraining tasks; Transformer models},
	keywords = {Computational linguistics; Natural language processing systems; Abusive language; Contextual information; Fine tuning; Language model; Language processing; Natural languages; Performance; Pre-training; Pretraining task; Transformer modeling; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th Mexican Conference on Pattern Recognition, MCPR 2023; Conference date: 21 June 2023 through 24 June 2023; Conference code: 296369}
}

@ARTICLE{Motwakel20233321,
	author = {Motwakel, Abdelwahed and Al-Onazi, Badriyya B. and Alzahrani, Jaber S. and Alazwari, Sana and Othman, Mahmoud and Zamani, Abu Sarwar and Yaseen, Ishfaq and Abdelmageed, Amgad Atta},
	title = {Improved Ant Lion Optimizer with Deep Learning Driven Arabic Hate Speech Detection},
	year = {2023},
	journal = {Computer Systems Science and Engineering},
	volume = {46},
	number = {3},
	pages = {3321 – 3338},
	doi = {10.32604/csse.2023.033901},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158816408&doi=10.32604%2fcsse.2023.033901&partnerID=40&md5=c2769ba41e6703942e6e51740947f08b},
	affiliations = {Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia; Department of Language Preparation, Arabic Language Teaching Institute, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Industrial Engineering, College of Engineering at Alqunfudah, Umm Al-Qura University, Saudi Arabia; Department of Information Technology, College of Computers and Information Technology, Taif University, Taif, P.O. Box 11099, Taif, 21944, Saudi Arabia; Department of Computer Science, Faculty of Computers and Information Technology, Future University in Egypt, New Cairo, 11835, Egypt},
	abstract = {Arabic is the world's first language, categorized by its rich and complicated grammatical formats. Furthermore, the Arabic morphology can be perplexing because nearly 10,000 roots and 900 patterns were the basis for verbs and nouns. The Arabic language consists of distinct variations utilized in a community and particular situations. Social media sites are a medium for expressing opinions and social phenomena like racism, hatred, offensive language, and all kinds of verbal violence. Such conduct does not impact particular nations, communities, or groups only, extending beyond such areas into people's everyday lives. This study introduces an Improved Ant Lion Optimizer with Deep Learning Dirven Offensive and Hate Speech Detection (IALODL-OHSD) on Arabic Cross-Corpora. The presented IALODL-OHSD model mainly aims to detect and classify offensive/hate speech expressed on social media. In the IALODL-OHSD model, a threestage process is performed, namely pre-processing, word embedding, and classification. Primarily, data pre-processing is performed to transform the Arabic social media text into a useful format. In addition, the word2vec word embedding process is utilized to produce word embeddings. The attentionbased cascaded long short-term memory (ACLSTM) model is utilized for the classification process. Finally, the IALO algorithm is exploited as a hyperparameter optimizer to boost classifier results. To illustrate a brief result analysis of the IALODL-OHSD model, a detailed set of simulations were performed. The extensive comparison study portrayed the enhanced performance of the IALODL-OHSD model over other approaches. © 2023 CRL Publishing. All rights reserved.},
	author_keywords = {Arabic corpora; Hate speech; natural language processing; offensive speech; social networks},
	keywords = {Data handling; Deep learning; Natural language processing systems; Social networking (online); Speech recognition; Arabic corpus; Detection models; Hate speech; Language processing; Natural language processing; Natural languages; Offensive speech; Optimizers; Social network; Speech detection; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Anbukkarasi20237893,
	author = {Anbukkarasi, S. and Varadhaganapathy, S.},
	title = {Deep Learning-based Hate Speech Detection in Code-mixed Tamil Text},
	year = {2023},
	journal = {IETE Journal of Research},
	volume = {69},
	number = {11},
	pages = {7893 – 7898},
	doi = {10.1080/03772063.2022.2043786},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126487354&doi=10.1080%2f03772063.2022.2043786&partnerID=40&md5=7741f01da2236329bbcb8e9e055e6eef},
	affiliations = {Department of Computer Science and Engineering, Kongu Engineering College, Tamilnadu, Erode, India; Department of Information Technology, Kongu Engineering College, Tamilnadu, Erode, India},
	abstract = {Social media is a great source of communication. People use various social media platforms, such as Twitter, Facebook, and Instagram, for sharing their ideas, opinions, and feelings. Users of different age groups, cultures, education backgrounds manipulate these powerful mediums of communication. Even though it gives all the benefits of knowledge sharing among the users, it has a dark side too. Despite setting restrictions from the corresponding sites, many users use abusive language to blemish the status and image of someone. So it is highly the need of the hour for the government or the particular social media platform to sift out those unwanted hate texts before diffusing them. Finding the hate text is one of the emerging research topics in Natural Language Processing where the model predicts the given text as hate text or not. This automated hate text detection becomes tedious when we consider the Indian languages due to a lack of data. Moreover, Indian people are multilingual and use code-mixed patterns to express their thoughts. The unavailability of the annotated Tamil-English dataset and the lack of a standard model make this task more challenging. In our paper, to handle such code-mixed data, a dataset is created with 10000 Tamil-English code-mixed texts collected from Twitter. These are annotated as hate text/non-hate text. In this paper, we use a synonym-based Bi-LSTM model for classifying hate non-hate text in tweets. © 2023 IETE.},
	author_keywords = {Code-mixed text; Deep learning; Hate speech text},
	keywords = {Codes (symbols); Long short-term memory; Social networking (online); Speech recognition; Age groups; Code-mixed text; Deep learning; Different ages; Facebook; Hate speech text; Knowledge-sharing; Social media; Social media platforms; Speech detection; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Turki2022,
	author = {Turki, Turki and Roy, Sanjiban Sekhar},
	title = {Novel Hate Speech Detection Using Word Cloud Visualization and Ensemble Learning Coupled with Count Vectorizer},
	year = {2022},
	journal = {Applied Sciences (Switzerland)},
	volume = {12},
	number = {13},
	doi = {10.3390/app12136611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133622974&doi=10.3390%2fapp12136611&partnerID=40&md5=ec2e4b684f996e551bd44743c6436a29},
	affiliations = {Department of Computer Science, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, 632014, India},
	abstract = {A plethora of negative behavioural activities have recently been found in social media. Incidents such as trolling and hate speech on social media, especially on Twitter, have grown considerably. Therefore, detection of hate speech on Twitter has become an area of interest among many researchers. In this paper, we present a computational framework to (1) examine out the computational challenges behind hate speech detection and (2) generate high performance results. First, we extract features from Twitter data by utilizing a count vectorizer technique. Then, we provide the labeled dataset of constructed features to adopted ensemble methods, including Bagging, AdaBoost, and Random Forest. After training, we classify new tweet examples into one of the two categories, hate speech or non-hate speech. Experimental results show (1) that Random Forest has surpassed other methods by generating 95% using accuracy performance results and (2) word cloud displays the most prominent tweets that are responsible for hateful sentiments. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {ensemble methods; hate speech; Twitter; vectorization; word cloud},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35; All Open Access, Gold Open Access}
}

@ARTICLE{Roy2022,
	author = {Roy, Pradeep Kumar and Bhawal, Snehaan and Subalalitha, Chinnaudayar Navaneethakrishnan},
	title = {Hate speech and offensive language detection in Dravidian languages using deep ensemble framework},
	year = {2022},
	journal = {Computer Speech and Language},
	volume = {75},
	doi = {10.1016/j.csl.2022.101386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129399321&doi=10.1016%2fj.csl.2022.101386&partnerID=40&md5=4904c1889921ab5366818418dcdb4660},
	affiliations = {Department of Computer Science & Engineering, Indian Institute of Information Technology, Surat, India; School of Computer Engineering, Kalinga Institute of Industrial Technology, Odisha, Bhubaneswar, India; Department of Computing Technologies, SRM Institute of Science and Technology, Kattankulathur, Tamilnadu, India},
	abstract = {Social networking platforms gained widespread popularity and are used for various activities like: promoting products, sharing news, achievements and many more. On the other hand, it is also used for spreading rumors, bullying people, and abusing certain groups of people with hateful words. The hate and offensive posts must be detected and removed as early as possible from the social platforms because such posts are spread very quickly and tend to have a lot of negative impacts on human beings. In the last few years, offensive content and hate speech detection has become popular topic of research. Detecting hate speech on social platforms has many challenges, one of them being the use of code-mixed language. Majority of the social media users usually post their messages in code-mixed languages such as Hindi–English, Tamil–English, Malayalam–English, Telugu–English and others. In this exhaustive study, we explore and compare the use of various machine learning and deep learning approaches. An ensemble model by combining the outcomes of transformer and deep learning-based models is suggested to detect hate speech and offensive language on social networking platforms. The experimental outcomes of the proposed weighted ensemble framework outperformed state-of-the-art models by achieving 0.802 and 0.933 weighted F1-score for Malayalam and Tamil code-mixed datasets. © 2022 Elsevier Ltd},
	author_keywords = {BERT; Deep learning; Dravidian language; Hate speech; Low-resource; Offensive language; Transfer learning},
	keywords = {Deep learning; Social networking (online); Speech recognition; BERT; Deep learning; Dravidian language; Hate speech; Language detection; Low-resource; Malayalams; Offensive languages; Social-networking; Transfer learning; Speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68}
}

@ARTICLE{Elzayady2023559,
	author = {Elzayady, Hassam and Mohamed, Mohamed S. and Badran, Khaled and Salama, Gouda and Abdel-Rahim, Ahmed},
	title = {Arabic Hate Speech Identification by Enriching MARBERT Model with Hybrid Features},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {579},
	pages = {559 – 566},
	doi = {10.1007/978-981-19-7663-6_53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149915260&doi=10.1007%2f978-981-19-7663-6_53&partnerID=40&md5=dbd549f54ad3c5d59ee4187b7205a2df},
	affiliations = {Department of Computer Engineering and Artificial Intelligence, Military Technical College, Cairo, Egypt; Department of Civil and Environmental Engineering, University of Idaho, Moscow, 83844, ID, United States},
	abstract = {The propagation of hate speech has grown more particularly apparent on social media sites as their usage for communication and unrestricted thought has increased on a worldwide scale. However, this could cause disagreement and antagonism among users, creating an unattractive online environment. Countries, companies, and academic institutions have all invested heavily in finding an effective solution to this challenge. There has been less study done in Arabic compared to other languages to develop automated systems for recognizing hate speech. Additionally, Arabic research on the correlation between personality traits and hate speech still remains rather limited. In this paper, we propose a novel method for enriching MARBERT model that incorporates static word embedding (AraVec 2.0) and personality trait features for Arabic hate speech detection. The experimental results indicate that the suggested methodology exceeds in terms of macro-F1 score by achieving 86.4% compared to previous research reported in the literature. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Arabic hate speech; Deep learning; MARBERT; Personality traits},
	keywords = {Automation; Concentration (process); Speech communication; Speech recognition; Academic institutions; Arabic hate speech; Deep learning; Effective solution; Hybrid features; MARBERT; Online environments; Personality traits; Social media; Speech identification; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th World Conference on Smart Trends in Systems, Security and Sustainability, WS4 2022; Conference date: 24 August 2022 through 27 August 2022; Conference code: 289469}
}

@ARTICLE{Wullach2022,
	author = {Wullach, Tomer and Adler, Amir and Minkov, Einat},
	title = {Character-level HyperNetworks for Hate Speech Detection},
	year = {2022},
	journal = {Expert Systems with Applications},
	volume = {205},
	doi = {10.1016/j.eswa.2022.117571},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131226452&doi=10.1016%2fj.eswa.2022.117571&partnerID=40&md5=01a4e4a238515231f1036eec66798bcd},
	affiliations = {Department of Information Systems, University of Haifa, Israel; Department of Electrical Engineering, Braude College of Engineering, Karmiel, Israel; McGovern Institute for Brain Research, MIT, Cambridge, MA, United States},
	abstract = {The massive spread of hate speech, hateful content targeted at specific subpopulations, is a problem of critical social importance. Automated methods of hate speech detection typically employ state-of-the-art deep learning (DL)-based text classifiers—large pretrained neural language models of over 100 million parameters, adapting these models to the task of hate speech detection using relevant labeled datasets. Unfortunately, there are only a few public labeled datasets of limited size that are available for this purpose. We make several contributions with high potential for advancing this state of affairs. We present HyperNetworks for hate speech detection, a special class of DL networks whose weights are regulated by a small-scale auxiliary network. These architectures operate at character-level, as opposed to word or subword-level, and are several orders of magnitude smaller compared to the popular DL classifiers. We further show that training hate detection classifiers using additional large amounts of automatically generated examples is beneficial in general, yet this practice especially boosts the performance of the proposed HyperNetworks. We report the results of extensive experiments, assessing the performance of multiple neural architectures on hate detection using five public datasets. The assessed methods include the pretrained language models of BERT, RoBERTa, ALBERT, MobileBERT and CharBERT, a variant of BERT that incorporates character alongside subword embeddings. In addition to the traditional setup of within-dataset evaluation, we perform cross-dataset evaluation experiments, testing the generalization of the various models in conditions of data shift. Our results show that the proposed HyperNetworks achieve performance that is competitive, and better in some cases, than these pretrained language models, while being smaller by orders of magnitude. © 2022 Elsevier Ltd},
	author_keywords = {Hate speech detection; Neural networks; Text generation},
	keywords = {Classification (of information); Computational linguistics; Deep learning; Large dataset; Network architecture; Speech recognition; Statistical tests; Character level; Hate speech detection; Hypernetwork; Labeled dataset; Language model; Neural-networks; Performance; Speech detection; Sub words; Text generations; Speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{Toliyat2022,
	author = {Toliyat, Amir and Levitan, Sarah Ita and Peng, Zheng and Etemadpour, Ronak},
	title = {Asian hate speech detection on Twitter during COVID-19},
	year = {2022},
	journal = {Frontiers in Artificial Intelligence},
	volume = {5},
	doi = {10.3389/frai.2022.932381},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136906550&doi=10.3389%2ffrai.2022.932381&partnerID=40&md5=02732321406ccc50064fa06feea705b7},
	affiliations = {Computer Science Program, Graduate Center, City University of New York, New York, NY, United States; Computer Science Program, Hunter College, City University of New York, New York, NY, United States; Computer Science Program, City College, City University of New York, New York, NY, United States},
	abstract = {Coronavirus disease 2019 (COVID-19) started in Wuhan, China, in late 2019, and after being utterly contagious in Asian countries, it rapidly spread to other countries. This disease caused governments worldwide to declare a public health crisis with severe measures taken to reduce the speed of the spread of the disease. This pandemic affected the lives of millions of people. Many citizens that lost their loved ones and jobs experienced a wide range of emotions, such as disbelief, shock, concerns about health, fear about food supplies, anxiety, and panic. All of the aforementioned phenomena led to the spread of racism and hate against Asians in western countries, especially in the United States. An analysis of official preliminary police data by the Center for the Study of Hate & Extremism at California State University shows that Anti-Asian hate crime in 16 of America's largest cities increased by 149% in 2020. In this study, we first chose a baseline of Americans' hate crimes against Asians on Twitter. Then we present an approach to balance the biased dataset and consequently improve the performance of tweet classification. We also have downloaded 10 million tweets through the Twitter API V-2. In this study, we have used a small portion of that, and we will use the entire dataset in the future study. In this article, three thousand tweets from our collected corpus are annotated by four annotators, including three Asian and one Asian-American. Using this data, we built predictive models of hate speech using various machine learning and deep learning methods. Our machine learning methods include Random Forest, K-nearest neighbors (KNN), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Logistic Regression, Decision Tree, and Naive Bayes. Our Deep Learning models include Basic Long-Term Short-Term Memory (LSTM), Bidirectional LSTM, Bidirectional LSTM with Drop out, Convolution, and Bidirectional Encoder Representations from Transformers (BERT). We also adjusted our dataset by filtering tweets that were ambiguous to the annotators based on low Fleiss Kappa agreement between annotators. Our final result showed that Logistic Regression achieved the best statistical machine learning performance with an F1 score of 0.72, while BERT achieved the best performance of the deep learning models, with an F1-Score of 0.85. Copyright © 2022 Toliyat, Levitan, Peng and Etemadpour.},
	author_keywords = {Asian hate crime; COVID-19; machine learning; natural language processing; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Chhabra2023,
	author = {Chhabra, Anusha and Vishwakarma, Dinesh Kumar},
	title = {A Truncated SVD Framework for Online Hate Speech Detection on the ETHOS Dataset},
	year = {2023},
	journal = {2023 International Conference on Innovative Trends in Information Technology, ICITIIT 2023},
	doi = {10.1109/ICITIIT57246.2023.10068574},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151924006&doi=10.1109%2fICITIIT57246.2023.10068574&partnerID=40&md5=a8bf1e936dcc87e60519d300cf7d193a},
	affiliations = {Delhi Technological University, Biometric Research Laboratory, Department of Information Technology, Delhi, 110042, India},
	abstract = {Hate content on social media is currently one of the most significant risks, where the victim is either a single individual or a group of people. In the current scenario, online web platforms are one of the most prominent ways to contribute to an individual's opinions and thoughts. Free sharing of ideas on an event or situation also bulks on the web. Information sharing is sometimes a bane for society if primarily used platforms are utilized with some lousy intention to spread hatred for intentionally creating chaos/ confusion among the public. Users take this as an opportunity to spread hate to get some monetary benefits, the detection of which is of paramount importance. This article utilizes the concept of truncated singular value decomposition (SVD) for detecting hate content on the ETHOS (Binary-Label) dataset. Compared with the baseline results, our framework has performed better in various machine learning algorithms like SVM, Logistic Regression, XGBoost, and Random Forest.  © 2023 IEEE.},
	author_keywords = {Binary-label Classification; Hate Speech; Machine Learning; SVD; TF-IDF},
	keywords = {Classification (of information); E-learning; Logistic regression; Random forests; Support vector regression; 'current; Binary labels; Binary-label classification; Hate speech; Information sharing; Machine-learning; Social media; Speech detection; TF-IDF; Truncated singular value decomposition; Singular value decomposition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Innovative Trends in Information Technology, ICITIIT 2023; Conference date: 11 February 2023 through 12 February 2023; Conference code: 187451}
}

@ARTICLE{Zhong2022,
	author = {Zhong, Weiyu and Wu, Qiaofeng and Lu, Guojun and Xue, Yun and Hu, Xiaohui},
	title = {Keyword-Enhanced Multi-Expert Framework for Hate Speech Detection},
	year = {2022},
	journal = {Mathematics},
	volume = {10},
	number = {24},
	doi = {10.3390/math10244706},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144680719&doi=10.3390%2fmath10244706&partnerID=40&md5=3ed801f7dc23653130ce491e6b589c22},
	affiliations = {School of Electronics and Information Engineering, South China Normal University, Foshan, 528225, China},
	abstract = {The proliferation of hate speech on the Internet is harmful to the psychological health of individuals and society. Thus, establishing and supporting the development of hate speech detection and deploying evasion techniques is a vital task. However, existing hate speech detection methods tend to ignore the sentiment features of target sentences and have difficulty identifying some implicit types of hate speech. The performance of hate speech detection can be significantly improved by gathering more sentiment features from various sources. In the use of external sentiment information, the key information of the sentences cannot be ignored. Thus, this paper proposes a keyword-enhanced multiexperts framework. To begin, the multi-expert module of multi-task learning is utilized to share parameters and thereby introduce sentiment information. In addition, the critical features of the sentences are highlighted by contrastive learning. This model focuses on both the key information of the sentence and the external sentiment information. The final experimental results on three public datasets demonstrate the effectiveness of the proposed model. © 2022 by the authors.},
	author_keywords = {contrastive learning; hate speech detection; multi-task learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Shah2023221,
	author = {Shah, Seyed Muzaffar Ahmad and Singh, Satwinder},
	title = {Hate Speech and Offensive Language Detection in Twitter Data Using Machine Learning Classifiers},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {565 LNNS},
	pages = {221 – 237},
	doi = {10.1007/978-981-19-7455-7_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161388137&doi=10.1007%2f978-981-19-7455-7_17&partnerID=40&md5=52c596aa490e18eaa8753c93395a65a5},
	affiliations = {Department of Computer Science and Technology, Central University of Punjab, Bathinda, India},
	abstract = {Social media is rapidly growing in popularity and has its advantages and disadvantages. Users posting their daily updates and opinions on social media may inadvertently hurt the feelings of others. Detecting hate speech and harmful information on social media is critical these days, lest it led to calamity. In this research, machine learning classifiers such as Naïve Bayes, support vector machines, logistic regression, and pre-trained models BERT and RoBERTa, developed by Google and Facebook, respectively, are used to detect hate speech and offensive content from Twitter data on a newly created dataset that included tweets and articles/blogs. The sentiments were obtained using the VADER sentiment analyzer. The results depicted that the pre-trained classifiers outperformed the machine learning classifiers utilized in this study. An accuracy score of 96% and 93% was scored by BERT and RoBERTa, respectively, on the tweet dataset, whereas on a dataset of articles/blogs, accuracy of 97% and 98%, respectively, was achieved by both the classifiers outperforming other classifiers used in this work. Further, it can also be depicted that neutral content is shared more in articles/blogs, hate content is mostly shared equally in both the tweets and article/blogs, whereas offensive content is shared higher in tweets than articles/blogs. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {BERT; Hate speech; Offensive language; RoBERTa; Tweets; VADER},
	keywords = {Classification (of information); Learning systems; Logistic regression; Social networking (online); Speech recognition; BERT; Hate speech; Language detection; Learning classifiers; Machine-learning; Offensive languages; RoBERTa; Social media; Tweet; VADER; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 10th International Conference on Innovations in Computer Science and Engineering, ICICSE 2022; Conference date: 16 September 2022 through 17 September 2022; Conference code: 294389}
}

@ARTICLE{Elzayady2023533,
	author = {Elzayady, Hossam and Mohamed, Mohamed S. and Badran, Khaled and Salama, Gouda},
	title = {Improving Arabic Hate Speech Identification Using Online Machine Learning and Deep Learning Models},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {448},
	pages = {533 – 541},
	doi = {10.1007/978-981-19-1610-6_46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135897705&doi=10.1007%2f978-981-19-1610-6_46&partnerID=40&md5=d5420ceb831a1d01b633c01e4b11ee34},
	affiliations = {Department of Computer Engineering, Military Technical College, Cairo, Egypt},
	abstract = {Due to the rising use of social media platforms on a global scale to interact and express thoughts freely, the spread of hate speech has become very noticeable on these platforms. Governments, organizations, and academic institutions have all spent substantially on discovering effective solutions to handle this issue. Numerous researches have been performed in several languages to find automated methods for identifying hate speech, but there has been minimal work done in Arabic. The findings of a performance evaluation of two machine learning models, namely the passive-aggressive classifier (PAC) and the Bidirectional Gated Recurrent Unit (Bi-GRU) augmented with an attention layer, are investigated in this work. Proposed models are developed and evaluated using a multi-platform Arabic hate speech dataset. We employ term frequency-inverse document frequency (TF-IDF) and Arabic word embeddings for feature extraction techniques after running a variety of pre-processing steps. The experimental results reveal that the two proposed models (PAC, Bi-GRU with attention layer) provide an accuracy of 98.4% and 99.1%, respectively, outperforming existing methods reported in the literature. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Arabic hate speech; Deep learning; Online machine learning; Text mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th International Congress on Information and Communication Technology, ICICT 2022; Conference date: 21 February 2022 through 24 February 2022; Conference code: 280489}
}

@ARTICLE{Subramanian2022,
	author = {Subramanian, Malliga and Ponnusamy, Rahul and Benhur, Sean and Shanmugavadivel, Kogilavani and Ganesan, Adhithiya and Ravi, Deepti and Shanmugasundaram, Gowtham Krishnan and Priyadharshini, Ruba and Chakravarthi, Bharathi Raja},
	title = {Offensive language detection in Tamil YouTube comments by adapters and cross-domain knowledge transfer},
	year = {2022},
	journal = {Computer Speech and Language},
	volume = {76},
	doi = {10.1016/j.csl.2022.101404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134605883&doi=10.1016%2fj.csl.2022.101404&partnerID=40&md5=533e93a6a7d662b6efcfa795fc60cfb8},
	affiliations = {Kongu Engineering College, Perundurai, Tamil Nadu, Erode, India; Indian Institute Of Information Technology and Management-Kerala, Kerala, India; PSG College of Arts and Science, Tamil Nadu, Coimbatore, India; ULTRA Arts and Science College, Tamil Nadu, Madurai, India; Insight SFI Research Centre for Data Analytics, Data Science Institute, National University of Ireland Galway, Galway, Ireland},
	abstract = {Over the past few years, researchers have been focusing on the identification of offensive language on social networks. In places where English is not the primary language, social media users tend to post/comment using a code-mixed form of text. This poses various hitches in identifying offensive texts, and when combined with the limited resources available for languages such as Tamil, the task becomes considerably more challenging. This study undertakes multiple tests in order to detect potentially offensive texts in YouTube comments, made available through the HASOC-Offensive Language Identification track in Dravidian Code-Mix FIRE 2021. To detect the offensive texts, models based on traditional machine learning techniques, namely Bernoulli Naïve Bayes, Support Vector Machine, Logistic Regression, and K-Nearest Neighbor, were created. In addition, pre-trained multilingual transformer-based natural language processing models such as mBERT, MuRIL (Base and Large), and XLM-RoBERTa (Base and Large) were also attempted. These models were used as fine-tuner and adapter transformers. In essence, adapters and fine-tuners accomplish the same goal, but adapters function by adding layers to the main pre-trained model and freezing their weights. This study shows that transformer-based models outperform machine learning approaches. Furthermore, in low-resource languages such as Tamil, adapter-based techniques surpass fine-tuned models in terms of both time and efficiency. Of all the adapter-based approaches, XLM-RoBERTa (Large) was found to have the highest accuracy of 88.5%. The study also demonstrates that, compared to fine-tuning the models, the adapter models require training of a fewer parameters. In addition, the tests revealed that the proposed models performed notably well against a cross-domain data set. © 2022},
	author_keywords = {Adapter; Cross-domain analysis; Finetuning; HASOC; Machine learning models; Multilingual; Offensive texts; Transformer models},
	keywords = {Codes (symbols); Domain Knowledge; Knowledge management; Learning algorithms; Learning systems; Natural language processing systems; Nearest neighbor search; Support vector machines; Adapter; Cross-domain; Cross-domain analyse; Domain analysis; Finetuning; HASOC; Machine learning models; Multilingual; Offensive text; Transformer modeling; Statistical tests},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 50}
}

@ARTICLE{Manerba2023483,
	author = {Manerba, Marta Marchiori and Morini, Virginia},
	title = {Exposing Racial Dialect Bias in Abusive Language Detection: Can Explainability Play a Role?},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1752 CCIS},
	pages = {483 – 497},
	doi = {10.1007/978-3-031-23618-1_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149840160&doi=10.1007%2f978-3-031-23618-1_32&partnerID=40&md5=d77bffc77eed9cae5cf2ccc67ad4c1e5},
	affiliations = {Computer Science Department, University of Pisa, Pisa, Italy; KDD Laboratory, ISTI, National Research Council, Pisa, Italy},
	abstract = {Biases can arise and be introduced during each phase of a supervised learning pipeline, eventually leading to harm. Within the task of automatic abusive language detection, this matter becomes particularly severe since unintended bias towards sensitive topics such as gender, sexual orientation, or ethnicity can harm underrepresented groups. The role of the datasets used to train these models is crucial to address these challenges. In this contribution, we investigate whether explainability methods can expose racial dialect bias attested within a popular dataset for abusive language detection. Through preliminary experiments, we found that pure explainability techniques cannot effectively uncover biases within the dataset under analysis: the rooted stereotypes are often more implicit and complex to retrieve. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Algorithmic auditing; Algorithmic bias; Bias discovery; Data awareness; Discrimination; Explainability; Fairness in ML; Interpretability; ML; ML Evaluation; NLP},
	keywords = {Algorithmic auditing; Algorithmic bias; Algorithmics; Bias discovery; Data awareness; Discrimination; Explainability; Fairness in ML; Interpretability; ML; ML evaluation; Algorithmic languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Workshops on SoGood, NFMCP, XKDD, UMOD, ITEM, MIDAS, MLCS, MLBEM, PharML, DALS, IoT-PdM 2022, held in conjunction with the 21st Joint European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2022; Conference date: 19 September 2022 through 23 September 2022; Conference code: 290969}
}

@ARTICLE{Miran2023765,
	author = {Miran, Ara Zozan and Yahia, Hazha Saeed},
	title = {Hate Speech Detection in Social Media (Twitter) Using Neural Network},
	year = {2023},
	journal = {Journal of Mobile Multimedia},
	volume = {19},
	number = {3},
	pages = {765 – 798},
	doi = {10.13052/jmm1550-4646.1936},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152786096&doi=10.13052%2fjmm1550-4646.1936&partnerID=40&md5=751ddf8ba80658bd7d60a5bbd9f30256},
	affiliations = {Department of Information Technology, Lebanese French University, Kurdistan Region, Iraq},
	abstract = {Hate speech recently became a real threat in social media, and almost all social media users are intended to in different ways. Hate speech is not limited to a group or society. It affects many people and can be classified as abusive, offensive, sexism, racism, political affiliation, religious hate, nationality, skin color, disability, gender-based, ethnicity, sexual orientation, immigrants, and others. Many researchers and authorities attempt to discover new procedures to sense hate speech in social media, especially on Facebook and Twitter, and many methods, models, and algorithms are used for this purpose. One of the most valuable models for detecting hate speech is Convolutional Neural Network (CNN). This review aims to assort academic studies on hate speech detection in Twitter using CNN-based models summarize the results of each model to expand the understanding of the recent circumstances of hate speech detection in Twitter. For this purpose, we implemented a broad, automated search using Boolean and Snowballing searching methods to find academic works in this area. Studies and papers have been distinguished, and the following information was obtained and aggregated from each article: authors, publication’s year, the journal name or the conference name, proposed model/method, the aim of the study, the outcome, and the quality of each study. According to the findings, the CNN and CNN-based models are standard models for hate speech detection. Besides, the findings show that other new models have a great compact on hate speech detection, and there is good progress in this field. However, the problems that still exist with hate speech detection models mainly are; most of the models cannot detect hate speech automatically. The methods are not suitable with all the languages, and they are working only with one language; most are best suited with the English language, and when they are used with datasets with other languages. Besides, the models are suffering from confusion in speech classification. Finally, most models are not considering a user-to-user speech in social media. © 2023 River Publishers.},
	author_keywords = {convolutional neural network; cyberbullying; Hate speech; toxic; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Sharma2023,
	author = {Sharma, Anushka and Kaushal, Rishabh},
	title = {Detecting Hate Speech in Hindi in Online Social Media},
	year = {2023},
	journal = {2023 3rd International Conference on Intelligent Communication and Computational Techniques, ICCT 2023},
	doi = {10.1109/ICCT56969.2023.10075749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152212404&doi=10.1109%2fICCT56969.2023.10075749&partnerID=40&md5=1f5742bf20af9d1c85b748597fa48a5e},
	affiliations = {Indira Gandhi Delhi Technical University for Women, Dept. of Information Technology, New Delhi, India},
	abstract = {Because of the rise in online hatred, the research communities of artificial intelligence, particularly natural language processing, have been developing models for identifying online hatred. Recently, code-mixing, or the usage of multiple languages in social media conversations, has made multilingual hatred a significant difficulty for automated detection. The crucial task involved in NLP is identifying inciting hatred in writings on social networking sites. This work has several relevant applications, including analysis of sentiments, cyberbullying in online world, and societal & political conflict studies. Using tweets that have been put online on Twitter, we analyze the issue of hatred detection in multilingual functionality in this paper. The tweets have the text annotations and the speech category (Normal speech or Hate speech) to which these belong. We, therefore, recommend a monitored method for detecting hatred. Additionally, the classification approach is provided, which uses certain characters level, words level, and lexicons-based features for identifying hate speech in the corpus. We obtain results of 96% accuracy in identifying posts across four classifiers. Index Terms - Hate speech, Multilingual, Code-mixing, NLP  © 2023 IEEE.},
	author_keywords = {Code-mixing; Hate speech; Multilingual; NLP},
	keywords = {Codes (symbols); Mixing; Social networking (online); Speech recognition; Automated detection; Code-mixing; Hate speech; Language processing; Multilingual; Multiple languages; Natural languages; Online social medias; Research communities; Social media; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Intelligent Communication and Computational Techniques, ICCT 2023; Conference date: 19 January 2023 through 20 January 2023; Conference code: 187561}
}

@CONFERENCE{Ali2022317,
	author = {Ali, Mohsan and Muhammad, Ali and Asad, Muhammad and Sajawal, Makhdoom and Alexopoulos, Charalampos and Charalabidis, Yannis},
	title = {Towards Perso-Arabic Urdu Language Hate Detection Using Machine Learning: A Comparative Study Based on a Large Dataset and Time-Complexity},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {317 – 321},
	doi = {10.1145/3575879.3576011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152134720&doi=10.1145%2f3575879.3576011&partnerID=40&md5=592b4bc160f594459404470e20f3c534},
	affiliations = {University of the Aegean, Mytilene, Mytilene, Greece; Air University, Islamabad, Islamabad, Pakistan},
	abstract = {Social media users are growing daily, with hundreds of millions of active users per month on certain networking sites. For any administrative institution, the manual method for regulating user content is challenging. There are hundreds of languages through which you can direct your attention on the web. The Urdu language is among the most widely utilized languages in the world. We have proposed a quick way of detecting the content of Urdu language hate using machine learning models. We used the open data set and manually created instances to make this investigation viable on a balanced data set. Our experimental set-up has demonstrated that support vector machine in the detection of Urdu hatred detection is 81.87% accurate. The training time, testing time, and accuracy helped us select the best model for Urdu hate detection on social media sites. We also compared the training and testing times of various methods. Additionally, we demonstrated k and stratified folding via indexing to provide a better understanding of folding in machine learning. Finally, we compared our findings to those of previously published works in the field of Urdu hate detection. © 2022 ACM.},
	author_keywords = {Hatred Content Detection; Machine Learning; Natural Language Processing; Urdu Speech},
	keywords = {Learning algorithms; Learning systems; Natural language processing systems; Open Data; Social networking (online); Support vector machines; Content detection; Data set; Hatred content detection; Language processing; Machine-learning; Natural language processing; Natural languages; Social media; Training time; Urdu speech; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 26th Pan-Hellenic Conference on Informatics, PCI 2022; Conference date: 25 November 2022 through 27 November 2022; Conference code: 187583; All Open Access, Bronze Open Access}
}

@ARTICLE{Nascimento2022,
	author = {Nascimento, Francimaria R.S. and Cavalcanti, George D.C. and Da Costa-Abreu, Márjory},
	title = {Unintended bias evaluation: An analysis of hate speech detection and gender bias mitigation on social media using ensemble learning},
	year = {2022},
	journal = {Expert Systems with Applications},
	volume = {201},
	doi = {10.1016/j.eswa.2022.117032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128186550&doi=10.1016%2fj.eswa.2022.117032&partnerID=40&md5=ae5cae2135c0b488f508c65de999f294},
	affiliations = {Centro de Informática (CIn), Universidade Federal de Pernambuco (UFPE), Av. Jornalista Anibal Fernandes s/n, Recife, Brazil; Department of Computing, Sheffield Hallam University, Sheffield, United Kingdom},
	abstract = {Hate speech on online social media platforms is now at a level that has been considered a serious concern by governments, media outlets, and scientists, especially because it is easily spread, promoting harm to individuals and society, and made it virtually impossible to tackle with using just human analysis. Automatic approaches using machine learning and natural language processing are helpful for detection. For such applications, amongst several different approaches, it is essential to investigate the systems’ robustness to deal with biases towards identity terms (gender, race, religion, for example). In this work, we analyse gender bias in different datasets and proposed a ensemble learning approach based on different feature spaces for hate speech detection with the aim that the model can learn from different abstractions of the problem, namely unintended bias evaluation metrics. We have used nine different feature spaces to train the pool of classifiers and evaluated our approach on a publicly available corpus, and our results demonstrate its effectiveness compared to state-of-the-art solutions. © 2022 Elsevier Ltd},
	author_keywords = {Ensemble learning; Gender bias; Hate speech detection; Multi-features},
	keywords = {Feature extraction; Learning algorithms; Learning systems; Natural language processing systems; Speech recognition; Ensemble learning; Feature space; Gender bias; Hate speech detection; Media outlets; Multifeatures; Online social medias; Social media; Social media platforms; Speech detection; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Green Open Access}
}

@ARTICLE{Keya202379697,
	author = {Keya, Ashfia Jannat and Kabir, Md. Mohsin and Shammey, Nusrat Jahan and Mridha, M.F. and Islam, Md. Rashedul and Watanobe, Yutaka},
	title = {G-BERT: An Efficient Method for Identifying Hate Speech in Bengali Texts on Social Media},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {79697 – 79709},
	doi = {10.1109/ACCESS.2023.3299021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165912173&doi=10.1109%2fACCESS.2023.3299021&partnerID=40&md5=918f0ce20ea19be145f29ff937cd5331},
	affiliations = {Bangladesh University of Business and Technology, Department of Computer Science and Engineering, Dhaka, 1216, Bangladesh; University of Girona, Superior Polytechnic School, Girona, 17071, Spain; American International University-Bangladesh, Department of Computer Science and Engineering, Dhaka, 1229, Bangladesh; University of Asia Pacific, Department of Computer Science and Engineering, Dhaka, 1205, Bangladesh; The University of Aizu, School of Computer Science and Engineering, Aizuwakamatsu, 965-8580, Japan},
	abstract = {The rapid increase in Internet users has increased online concerns such as hate speech, abusive texts, and harassment. In Bangladesh, hate text in Bengali is frequently used on various social media platforms to condemn and abuse individuals. However, Research on recognizing hate speech in Bengali texts is lacking. The pervasive negative impact of hate speech on individuals' well-being and the urgent need for effective measures to address hate speech in Bengali texts have created a significant research gap in the Bengali hate speech detection field. This study suggests a technique for identifying hate speech in Bengali social media posts that may harm individuals' sentiments. Our approach utilizes the Bidirectional Encoder Representations from Transformers (BERT) architecture to extract Bengali text properties, whereas hate speech is categorized using a Gated Recurrent Units (GRU) model with a Softmax activation function. We propose a new model, G-BERT, that combines both models. We compared our model's performance with several other algorithms and achieved an accuracy, precision, recall, and F1-score of 95.56%, 95.07%, 93.63%, and 92.15%, respectively. Our proposed model outperformed all other classification algorithms tested. Our findings show that the strategy we have suggested is successful in locating hate speech in Bengali texts posted on social media platforms, which can aid in mitigating online hate speech and promoting a more respectful online environment.  © 2013 IEEE.},
	author_keywords = {Bidirectional encoder representations from transformers; deep learning; gated recurrent unit; hate speech; social platform},
	keywords = {Bit error rate; Deep learning; Feature extraction; Signal encoding; Speech recognition; Bidirectional encoder representation from transformer; Bit-error rate; Deep learning; Features extraction; Gated recurrent unit; Hate speech; Medium; Social networking (online); Social platform; Transformer; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access}
}

@ARTICLE{Maslej-Krešňáková2022,
	author = {Maslej-Krešňáková, Viera and Sarnovský, Martin and Jacková, Júlia},
	title = {Use of Data Augmentation Techniques in Detection of Antisocial Behavior Using Deep Learning Methods},
	year = {2022},
	journal = {Future Internet},
	volume = {14},
	number = {9},
	doi = {10.3390/fi14090260},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138745468&doi=10.3390%2ffi14090260&partnerID=40&md5=1cab7eb607bda6baa411480ee24a1c8c},
	affiliations = {Department of Cybernetics and Artificial Intelligence, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Kosice, 040 01, Slovakia},
	abstract = {The work presented in this paper focuses on the use of data augmentation techniques applied in the domain of the detection of antisocial behavior. Data augmentation is a frequently used approach to overcome issues related to the lack of data or problems related to imbalanced classes. Such techniques are used to generate artificial data samples used to improve the volume of the training set or to balance the target distribution. In the antisocial behavior detection domain, we frequently face both issues, the lack of quality labeled data as well as class imbalance. As the majority of the data in this domain is textual, we must consider augmentation methods suitable for NLP tasks. Easy data augmentation (EDA) represents a group of such methods utilizing simple text transformations to create the new, artificial samples. Our main motivation is to explore EDA techniques’ usability on the selected tasks from the antisocial behavior detection domain. We focus on the class imbalance problem and apply EDA techniques to two problems: fake news and toxic comments classification. In both cases, we train the convolutional neural networks classifier and compare its performance on the original and EDA-extended datasets. EDA techniques prove to be very task-dependent, with certain limitations resulting from the data they are applied on. The model’s performance on the extended toxic comments dataset did improve only marginally, gaining only 0.01 improvement in the F1 metric when applying only a subset of EDA methods. EDA techniques in this case were not suitable enough to handle texts written in more informal language. On the other hand, on the fake news dataset, the performance was improved more significantly, boosting the F1 score by 0.1. Improvement was most significant in the prediction of the minor class, where F1 improved from 0.67 to 0.86. © 2022 by the authors.},
	author_keywords = {antisocial behavior; data augmentation; deep learning; EDA; fake news detection; toxic comments},
	keywords = {Classification (of information); Convolutional neural networks; Fake detection; Learning systems; Antisocial behavior; Augmentation techniques; Behavior detection; Data augmentation; Deep learning; Easy data augmentation; Fake news detection; Performance; Toxic comment; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access}
}

@ARTICLE{Vadesara2023382,
	author = {Vadesara, Abhilasha and Tanna, Purna},
	title = {Corpus Building for Hate Speech Detection of Gujarati Language},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1788 CCIS},
	pages = {382 – 395},
	doi = {10.1007/978-3-031-27609-5_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151057509&doi=10.1007%2f978-3-031-27609-5_30&partnerID=40&md5=fb29daadb82b781df79e062b4f1050f5},
	affiliations = {GLS University, Gujarat, Ahmedabad, India},
	abstract = {Social media is a rapidly expanding platform where users share their thoughts and feelings about various issues as well as their opinions. However, this has also led to a number of issues, such as the dissemination and sharing of hate speech messages. Hence, there is a need to automatically identify speech that uses hateful language. Hate speech refers to the aggressive, offensive language that focuses on a specific people or group as far as their ethnic group or race (i.e., racism), gender (i.e., sexism), beliefs, and religion. The aim of this paper is to examine how hate speech contrasts with non-hate speech. A corpus of Gujarati tweets has been collected from Twitter. The dataset was cleaned and pre-processed by removing unnecessary symbols, URLs, characters, and stop words, and the cleaned text was analyzed. Pre-processed data was annotated by twenty-five people and has achieved Fleiss’s Kappa coefficient with 0.87 accuracies for agreement between the annotators. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Gujarati language; Hate speech; Kappa’s coefficient; Sentiment analysis; Text mining},
	keywords = {Social networking (online); Speech recognition; Ethnic groups; Gujarati language; Hate speech; Kappa’s coefficient; Offensive languages; Sentiment analysis; Social media; Speech detection; Stop word; Text-mining; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th International Conference on Soft Computing and its Engineering Applications, icSoftComp 2022; Conference date: 9 December 2022 through 10 December 2022; Conference code: 291189}
}

@ARTICLE{Asiri2022,
	author = {Asiri, Yousef and Halawani, Hanan T. and Alghamdi, Hanan M. and Abdalaha Hamza, Saadia Hassan and Abdel-Khalek, Sayed and Mansour, Romany F.},
	title = {Enhanced Seagull Optimization with Natural Language Processing Based Hate Speech Detection and Classification},
	year = {2022},
	journal = {Applied Sciences (Switzerland)},
	volume = {12},
	number = {16},
	doi = {10.3390/app12168000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136598427&doi=10.3390%2fapp12168000&partnerID=40&md5=6f6ee2d94fd1a38165410f6572cdb5f1},
	affiliations = {Department of Computer Science, College of Computer Science and Information Systems, Najran University, Najran, 61441, Saudi Arabia; Department of Computer Science, College of Computing Al Qunfidhah, Umm Al-Qura University, Mecca, 24382, Saudi Arabia; Department of Computer Science, College of Science and Humanities, Prince Sattam Bin AbdulAziz University, Slayel, 11913, Saudi Arabia; Department of Mathematics, Faculty of Science, Sohag University, Sohag, 82524, Egypt; Department of Mathematics, College of Science, Taif University, Taif, 21944, Saudi Arabia; Department of Mathematics, Faculty of Science, New Valley University, El-Kharga, 72511, Egypt},
	abstract = {Hate speech has become a hot research topic in the area of natural language processing (NLP) due to the tremendous increase in the usage of social media platforms like Instagram, Twitter, Facebook, etc. The facelessness and flexibility provided through the Internet have made it easier for people to interact aggressively. Furthermore, the massive quantity of increasing hate speech on social media with heterogeneous sources makes it a challenging task. With this motivation, this study presents an Enhanced Seagull Optimization with Natural Language Processing Based Hate Speech Detection and Classification (ESGONLP-HSC) model. The major intention of the presented ESGONLP-HSC model is to identify and classify the occurrence of hate speech on social media websites. To accomplish this, the presented ESGONLP-HSC model involves data pre-processing at several stages, such as tokenization, vectorization, etc. Additionally, the Glove technique is applied for the feature extraction process. In addition, an attention-based bidirectional long short-term memory (ABLSTM) model is utilized for the classification of social media text into three classes such as neutral, offensive, and hate language. Moreover, the ESGO algorithm is utilized as a hyperparameter optimizer to adjust the hyperparameters related to the ABLSTM model, which shows the novelty of the work. The experimental validation of the ESGONLP-HSC model is carried out, and the results are examined under diverse aspects. The experimentation outcomes reported the promising performance of the ESGONLP-HSC model over recent state of art approaches. © 2022 by the authors.},
	author_keywords = {data classification; deep learning; hate speech; natural language processing; social networking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Polignano2022184,
	author = {Polignano, Marco and Colavito, Giuseppe and Musto, Cataldo and De Gemmis, Marco and Semeraro, Giovanni},
	title = {Lexicon Enriched Hybrid Hate Speech Detection with Human-Centered Explanations},
	year = {2022},
	journal = {UMAP2022 - Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization},
	pages = {184 – 191},
	doi = {10.1145/3511047.3537688},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135148968&doi=10.1145%2f3511047.3537688&partnerID=40&md5=a6ffb9448809d5dd92ced9bbb7ab3b22},
	affiliations = {Universita Degli Studi di Bari Aldo Moro, Italy; Dipartimento di Informatica, University of Bari, Italy; University of Bari Aldo Moro, Dept. of Computer Science, Italy},
	abstract = {The phenomenon of hate messages on the web is unfortunately in continuous expansion and evolution. Even if the big companies that offer their users a social network service have expressly included in their terms of services rules against hate messages, they are still produced at a huge rate. Therefore, moderators are often employed to monitor these platforms and use their critical skills to decide if the content is offensive or not. Unfortunately, this censorship process is complex and costly in terms of human resources. The system we propose in this work is a system that supports moderators by providing them a set of candidate elements to censor with annexed explanations in natural language. It will then be a task of the human operator to understand if to proceed with the censorship and eventually supply feedback to the result of the classification algorithm to extend its data set of examples and improve its future performances. The proposed system has been designed to merge information coming from data, syntactic tags and a manually annotated lexicon. The messages are then processed through deep learning approaches based on both transformer and deep neural network architecture. The output is consequently supported by an explanation in a human-like form. The model has been evaluated on three state-of-the-art datasets showing excellent effectiveness and clear and understandable explanations. © 2022 ACM.},
	author_keywords = {Deep Learning; Explanation; Hate Lexicon; Hate speech; Transformer Model; Transparency},
	keywords = {Deep neural networks; Moderators; Network architecture; Personnel; Deep learning; Explanation; Hate lexicon; Hate speech; Natural languages; Service rules; Social network services; Speech detection; Terms of services; Transformer modeling; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 30th ACM Conference on User Modeling, Adaptation and Personalization, UMAP2022; Conference date: 4 July 2022 through 7 July 2022; Conference code: 180576}
}

@ARTICLE{Sari2022895,
	author = {Sari, Tiara Intana and Ardilla, Zalfa Natania and Hayatin, Nur and Maskat, Ruhaila},
	title = {Abusive comment identification on Indonesian social media data using hybrid deep learning},
	year = {2022},
	journal = {IAES International Journal of Artificial Intelligence},
	volume = {11},
	number = {3},
	pages = {895 – 904},
	doi = {10.11591/ijai.v11.i3.pp895-904},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132370327&doi=10.11591%2fijai.v11.i3.pp895-904&partnerID=40&md5=0533bd9252b99408ce7969985da66e37},
	affiliations = {Department of Informatics, Faculty of Engineering, University of Muhammadiyah Malang, Malang, Indonesia; Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA Shah Alam, Selangor, Malaysia},
	abstract = {Half of the entire social media users in Indonesia has experienced cyberbullying. Cyberbullying is one of the treatments received as an attack with abusive words. An abusive word is a word or phrase that contained harassment and is expressed be it spoken or in the form of text. This is a serious problem that must be controlled because the act has an impact on the victim's psychology and causes trauma resulting in depression. This study proposed to identify abusive comments from social media in Indonesian language using a deep learning approach. The architecture used is a hybrid model, a combination between recurrent neural network (RNN) and long short-term memory (LSTM). RNN can map the input sequences to fixed-size vectors on hidden vector components and LSTM implemented to overcome gradient vector growth components that have the potential to exist in RNN. The steps carried out include preprocessing, modelling, implementation, and evaluation. The dataset used is indonesian abusive and hate speech from Twitter data. The evaluation result showed that the model proposed produced an f-measure value of 94% with an increase in accuracy of 23%. © 2022, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Abusive comments; Deep learning; Long short-term memory; network Sentiment analysis; Recurrent neural},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Rachidi2023,
	author = {Rachidi, Rabia and Ouassil, Mohamed Amine and Errami, Mouaad and Cherradi, Bouchaib and Hamida, Soufiane and Silkan, Hassan},
	title = {Social Media's Toxic Comments Detection Using Artificial Intelligence Techniques},
	year = {2023},
	journal = {2023 3rd International Conference on Innovative Research in Applied Science, Engineering and Technology, IRASET 2023},
	doi = {10.1109/IRASET57153.2023.10153015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164161341&doi=10.1109%2fIRASET57153.2023.10153015&partnerID=40&md5=5a6efb264bd9c128894921c213a38b55},
	affiliations = {Chouaib Doukali University, LaROSERI Laboratory, Faculty of Science, El Jadida, Morocco; Hassan Ii University of Casablanca, Eeis Laboratory, Enset of Mohammedia, Mohammedia, Morocco; Stie Team, Crmef Casablanca-Settat, Mohammedia, Morocco; Eeis Laboratory, Enset of Mohammedia, Hassan Ii University of Casablanca, Mohammedia, Morocco; Genius Laboratory, SupMTI of Rabat, Mohammedia, Morocco},
	abstract = {Cyberbullying takes its place in social media and has increased throughout the past few years. The damage that cyberbullying has on the users is undeniable they get attacked either on their appearances, ethnicities, religions, and even their thoughts and personal opinion. The attack causes these users anxiety, depression, low self-esteem, and in the worst scenarios suicide. These harmful actions toward the users drive researchers to identify and detect cyberbullying to fight it. Unfortunately, most of the previous approaches were on English texts, hardly any on other languages. This paper presents a cyberbullying detection system in the Moroccan dialect on an Instagram-collected dataset. The experiment results gave accuracies of around 77% to 91% from both the ML and DL algorithms. The LSTM model gave the best outcome by 91.24% outperforming the ML models. © 2023 IEEE.},
	author_keywords = {cyberbullying; deep learning; Instagram; machine learning; Moroccan dialect; natural language processing; social media; toxicity},
	keywords = {Learning algorithms; Learning systems; Long short-term memory; Natural language processing systems; Social networking (online); Artificial intelligence techniques; Cyber bullying; Deep learning; Instagram; Language processing; Machine-learning; Moroccan dialect; Natural language processing; Natural languages; Social media; Computer crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International Conference on Innovative Research in Applied Science, Engineering and Technology, IRASET 2023; Conference date: 18 May 2023 through 19 May 2023; Conference code: 189776}
}

@BOOK{Patil2022149,
	author = {Patil, Pratik and Naik, Deepali Nilesh},
	title = {Hate speech detection and analysis using machine learning},
	year = {2022},
	journal = {Artificial Intelligence in Information and Communication Technologies, Healthcare and Education: A Roadmap Ahead},
	pages = {149 – 156},
	doi = {10.1201/9781003342755-16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145247215&doi=10.1201%2f9781003342755-16&partnerID=40&md5=497f69956ba663f92df5262e7e9620b6},
	affiliations = {PES's Modern College of Engineering, Savitribai Phule Pune University, Pune, Maharashtra, India; Pimpri Chinchwad College of Engineering, Pune, Maharashtra, India},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kothuru20222934,
	author = {Kothuru, Srinivasulu and Santhanavijayan, A.},
	title = {Automatic hate speech detection using aspect based feature extraction and Bi-LSTM model},
	year = {2022},
	journal = {International Journal of System Assurance Engineering and Management},
	volume = {13},
	number = {6},
	pages = {2934 – 2943},
	doi = {10.1007/s13198-022-01763-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140652931&doi=10.1007%2fs13198-022-01763-6&partnerID=40&md5=c6c03dfa2c048b4da26a470309a6abe6},
	affiliations = {Department of Computer Science and Engineering, National Institute of Technology, Tiruchirappalli, India},
	abstract = {The various social media platforms are used for easy access of information from the distinctive field that might constitute an offensive discussion. Therefore, existing studies are examined to reduce offensive harassment cases online. The spread of hate speech is growing with the ubiquity and anonymity through the means of social media for many years. Thus, the increase in demand showed an automated model for the detection of hate speech. The existing models utilized deep learning models failed to analyze the syntax and grammar or even modify original data’s meaning due to its complex patterns. Therefore, the present research work utilizes an Activation Function known as Soft-plus in Bidirectional Long Short Term Memory (Bi-LSTM) models for hate speech detection which helps the network to learn complex patterns in the data. The proposed Soft-plus Bi-LSTM learned the c complex patterns present in the network data and the activation function made an end decision that should be fired out into the next neuron. The classification results showed that the proposed Soft-plus Bi-LSTM classified the reviews as abusive or non-abusive speech. The results obtained better precision values of 60.09% when compared to the existing models Auto-Encoder and Multi-task learning model showed a precision of 53.9% and 55.7% respectively. © 2022, The Author(s) under exclusive licence to The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden.},
	author_keywords = {Activation function; Deep learning models; Offensive Schemes; Social media platform; Soft-plus bidirectional long short term memory},
	keywords = {Brain; Chemical activation; Complex networks; Feature extraction; Learning systems; Social networking (online); Speech recognition; Activation functions; Complex pattern; Deep learning model; Features extraction; Learning models; Memory modeling; Offensive scheme; Social media platforms; Soft-plus bidirectional long short term memory; Speech detection; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Al-Hassan20221963,
	author = {Al-Hassan, Areej and Al-Dossari, Hmood},
	title = {Detection of hate speech in Arabic tweets using deep learning},
	year = {2022},
	journal = {Multimedia Systems},
	volume = {28},
	number = {6},
	pages = {1963 – 1974},
	doi = {10.1007/s00530-020-00742-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099570604&doi=10.1007%2fs00530-020-00742-w&partnerID=40&md5=d3671df5eca0cf7fb6a8397b6713f625},
	affiliations = {Information Systems Department, College of Computer Science and Information Systems, King Saud University, Riyadh, Saudi Arabia},
	abstract = {Nowadays, people are communicating through social networks everywhere. However, for whatever reason it is noticeable that verbal misbehaviors, such as hate speech is now propagated through the social networks. One of the most popular social networks is Twitter which has gained widespread in the Arabic region. This research aims to identify and classify Arabic tweets into 5 distinct classes: none, religious, racial, sexism or general hate. A dataset of 11 K tweets was collected and labelled and SVM model was used as a baseline to be compared against 4 deep learning models: LTSM, CNN + LTSM, GRU and CNN + GRU. The results show that all the 4 deep learning models outperform the SVM model in detecting hateful tweets. Although the SVM achieves an overall recall of 74%, the deep learning models have an average recall of 75%. However, adding a layer of CNN to LTSM enhances the overall performance of detection with 72% precision, 75% recall and 73% F1 score. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE part of Springer Nature.},
	author_keywords = {Arabic NLP; Arabic tweets; Deep learning; Hate speech; Multiclassification; Social networks; Text mining},
	keywords = {Deep learning; Learning systems; Social networking (online); Speech recognition; Arabic NLP; Arabic tweet; Deep learning; Hate speech; Learning models; Misbehaviour; Multi-classification; Social network; SVM model; Text-mining; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65}
}

@CONFERENCE{A2023,
	author = {A, Julia and da Silva, Felix Leonel V. and Costa, Wesley and Carvalho, Rodrigo B. and Bender, Alexandre T. and Correa, Ulisses B. and de Freitas, Larissa A.},
	title = {BERTimbau in Action: An Investigation of its Abilities in Sentiment Analysis, Aspect Extraction, Hate Speech Detection, and Irony Detection},
	year = {2023},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {36},
	doi = {10.32473/flairs.36.133186},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161358399&doi=10.32473%2fflairs.36.133186&partnerID=40&md5=4a3aa72932960b4a0e828f06d475a33f},
	affiliations = {CDTEC, Universidade Federal de Pelotas, 96010-610, Brazil},
	abstract = {Social Media has revolutionized how individuals, groups, and communities interact. This immense quantity of unstructured data holds valuable information expressed in informal language. However, automatically extracting this information using Natural Language Processing requires adaptations of traditional methods or the development of new strategies capable of extracting information tackling web-prone language. BERT, a Deep Learning methodology proposed by Google in 2018, brought transfer learning to Natural Language Processing. In this work, we used a BERT model for the Portuguese language called BERTimbau to create models for Sentiment Analysis, Aspect Extraction, Hate Speech Detection, and Irony Detection. We ex-perimented with the two BERTimbau models, base and large. Finally, we compared the results obtained in each task. Experiments with BERTimbau based models ob-tained improved results, F-Measure of 0.88 and 0.89 in Sentiment Analysis and Hate Speech Detection tasks, respectively, compared to classical Machine Learning approaches. © 2023 by the authors. All rights reserved.},
	author_keywords = {Aspect Extraction; BERTimbau; Hate Speech Detection; Irony Detection; Portuguese; Sentiment Analysis},
	keywords = {Deep learning; Learning systems; Sentiment analysis; Speech recognition; Aspect extraction; Bertimbau; Hate speech detection; Irony detection; Language processing; Natural languages; Portuguese; Sentiment analysis; Social media; Speech detection; Extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 36th International Florida Artificial Intelligence Research Society Conference, FLAIRS-36 2023; Conference date: 14 May 2023 through 17 May 2023; Conference code: 294329}
}

@ARTICLE{Shibly2023695,
	author = {Shibly, F.H.A. and Sharma, Uzzal and Naleer, H.M.M.},
	title = {Performance Comparison of Machine Learning and Deep Learning Algorithms in Detecting Online Hate Speech},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {473},
	pages = {695 – 706},
	doi = {10.1007/978-981-19-2821-5_59},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140452080&doi=10.1007%2f978-981-19-2821-5_59&partnerID=40&md5=fbfb1f90834e049ea0d53c23633d8b79},
	affiliations = {Assam Don Bosco University, South Eastern University of Sri Lanka, Oluvil, Sri Lanka; Department of Computer Applications, School of Technology, Assam Don Bosco University, Guwahati, India; Department of Computer Science, Faculty of Applied Sciences, South Eastern University of Sri Lanka, Oluvil, Sri Lanka},
	abstract = {The main objective of this research is to analyze and compare the performance of machine learning (ML) and deep learning (DL) algorithms in detecting online hate speech. Therefore, Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), Logistic Regression (LR), Convolution Neural Network (CNN), Recurrent Neural Network_Long Short-Term Memory (RNN_LSTM), BERT (Bidirectional Encoder Representations from Transformers), and Distil BERT algorithms have been explored and analyzed in this research. This research has applied the dataset on hate speech which was developed by Andry Samoshyn which is publicly available in Kaggle. ML algorithms and DL algorithms have got good scores in accuracy. In ML, SVM, RF, and LR have got top accuracy values. In DL algorithms, RNN_LSTM, Distil BERT, and BERT have performed well in accuracy. Based on F-measurement, DL classifiers have outperformed ML algorithms. Distil BERT has obtained the highest F-measurement scores. When we compare the overall performances, DL is performed well rather than ML in detecting hate speech. Especially transformer-based models of DL are more efficient than other DL and ML algorithms. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {And performance comparison; Deep learning Twitter; Hate speech; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Innovative Computing and Communication, ICICC 2022; Conference date: 19 February 2022 through 20 February 2022; Conference code: 283899}
}

@CONFERENCE{Agnes20231368,
	author = {Agnes, S. Akila and Solomon, A. Arun and Tamilmaran, D. Joseph Charles},
	title = {Abusive Comment Detection in Social Media with Bidirectional LSTM Model},
	year = {2023},
	journal = {Proceedings - 5th International Conference on Smart Systems and Inventive Technology, ICSSIT 2023},
	pages = {1368 – 1373},
	doi = {10.1109/ICSSIT55814.2023.10060887},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150684377&doi=10.1109%2fICSSIT55814.2023.10060887&partnerID=40&md5=72c121972e9e3f1b8eb7e8aab636afda},
	affiliations = {Gmr Institute of Technology, Department of Computer Science and Engg., Andhra Pradesh, India; Gmr Institute of Technology, Department of Civil Engineering, Andhra Pradesh, India; Kristu Jayanti College, Department of Mba, Karnataka, India},
	abstract = {Social media is becoming more vulnerable to problems like personal attacks and undesirable behaviour like cyberbullying. Online abusive language includes abusive comment, indiscriminate slang, harsh language, and vulgarity, which serve as an instrument for very intense and cruel cyber abuse. The abusive comments on other people's thoughts and beliefs can be hurtful and demeaning to those who express their views on social media. Manually reviewing each comment takes a significant amount of time and effort to determine which comments to delete. Therefore, an automatic process of identifying and preventing negative posts would not only save time but also give users comfort on social media platforms. In this work, a bidirectional long short term memory (BIS TM) model is implemented to identify abusive Twitter comments by classifying them into offensive and non- offensive comments. And the effectiveness of machine learning based abusive comment detection models with TF-IDF and Word2vec text representation techniques are compared with the proposed BLS TM model. The performance of abusive comment recognition models are evaluated using 10-fold cross validation with various performance metrics such as AUC, precision, recall, fl score, and accuracy. The experimental results showed that the best performance was yielded by the deep learning model BLS TM on the offensive language identification dataset(OLID).  © 2023 IEEE.},
	author_keywords = {abusive language detection; Biiffrectional longshort term memhoty; natural language processing; text classification; word embedding},
	keywords = {Classification (of information); Computer crime; Learning algorithms; Learning systems; Natural language processing systems; Social networking (online); Text processing; Abusive language detection; Biiffrectional longshort term memhoty; Embeddings; Language detection; Language processing; Natural language processing; Natural languages; Social media; Text classification; Word embedding; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 5th International Conference on Smart Systems and Inventive Technology, ICSSIT 2023; Conference date: 23 January 2023 through 25 January 2023; Conference code: 187202}
}

@CONFERENCE{Casula20233351,
	author = {Casula, Camilla and Tonelli, Sara},
	title = {Generation-Based Data Augmentation for Offensive Language Detection: Is It Worth It?},
	year = {2023},
	journal = {EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {3351 – 3369},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159853303&partnerID=40&md5=8aed0def4b5014f21c3c97a0078831b9},
	affiliations = {Fondazione Bruno Kessler, Trento, Italy; University of Trento, Italy},
	abstract = {Generation-based data augmentation (DA) has been presented in several works as a way to improve offensive language detection. However, the effectiveness of generative DA has been shown only in limited scenarios, and the potential injection of biases when using generated data to classify offensive language has not been investigated. Our aim is that of analyzing the feasibility of generative data augmentation more in-depth with two main focuses. First, we investigate the robustness of models trained on generated data in a variety of data augmentation setups, both novel and already presented in previous work, and compare their performance on four widely-used English offensive language datasets that present inherent differences in terms of content and complexity. In addition to this, we analyze models using the HateCheck suite, a series of functional tests created to challenge hate speech detection systems. Second, we investigate potential lexical bias issues through a qualitative analysis of the generated data. We find that the potential positive impact of generative data augmentation on model performance is unreliable, and generative DA can also have unpredictable effects on lexical bias. © 2023 Association for Computational Linguistics.},
	keywords = {Data augmentation; Detection system; Functional test; Language detection; Lexical bias; Offensive languages; Performance; Qualitative analysis; Robustness of model; Speech detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424}
}

@ARTICLE{Lu20232787,
	author = {Lu, Junyu and Lin, Hongfei and Zhang, Xiaokun and Li, Zhaoqing and Zhang, Tongyue and Zong, Linlin and Ma, Fenglong and Xu, Bo},
	title = {Hate Speech Detection via Dual Contrastive Learning},
	year = {2023},
	journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
	volume = {31},
	pages = {2787 – 2795},
	doi = {10.1109/TASLP.2023.3294715},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164684583&doi=10.1109%2fTASLP.2023.3294715&partnerID=40&md5=e0efb58c5b44b2c5a94f8093aa2b2f0e},
	affiliations = {Dalian University of Technology, School of Computer Science and Technology, Dalian, 116024, China; Dalian University of Technology, School of Software, Dalian, 116024, China; Pennsylvania State University, College of Information Science and Technology, Center Valley, 16801, PA, United States},
	abstract = {The fast spread of hate speech on social media impacts the Internet environment and our society by increasing prejudice and hurting people. Detecting hate speech has aroused broad attention in the field of natural language processing. Although hate speech detection has been addressed in recent work, this task still faces two inherent unsolved challenges. The first challenge lies in the complex semantic information conveyed in hate speech, particularly the interference of insulting words in hate speech detection. The second challenge is the imbalanced distribution of hate speech and non-hate speech, which may significantly deteriorate the performance of models. To tackle these challenges, we propose a novel dual contrastive learning (DCL) framework for hate speech detection. Our framework jointly optimizes the self-supervised and the supervised contrastive learning loss for capturing span-level information beyond the token-level emotional semantics used in existing models, particularly detecting speech containing abusive and insulting words. Moreover, we integrate the focal loss into the dual contrastive learning framework to alleviate the problem of data imbalance. We conduct experiments on two publicly available English datasets, and experimental results show that the proposed model outperforms the state-of-the-art models and precisely detects hate speeches.  © 2014 IEEE.},
	author_keywords = {contrastive learning; data imbalance; emotion analysis; hate speech detection; Natural language processing},
	keywords = {Emotion Recognition; Job analysis; Speech processing; Speech recognition; Context models; Contrastive learning; Data imbalance; Emotion analysis; Hate speech; Hate speech detection; Language processing; Natural language processing; Natural languages; Speech detection; Task analysis; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access}
}

@ARTICLE{Mollas20224663,
	author = {Mollas, Ioannis and Chrysopoulou, Zoe and Karlos, Stamatis and Tsoumakas, Grigorios},
	title = {ETHOS: a multi-label hate speech detection dataset},
	year = {2022},
	journal = {Complex and Intelligent Systems},
	volume = {8},
	number = {6},
	pages = {4663 – 4678},
	doi = {10.1007/s40747-021-00608-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127491041&doi=10.1007%2fs40747-021-00608-2&partnerID=40&md5=f607bcc2e02cbe5c171c7ad5824b4b14},
	affiliations = {Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece},
	abstract = {Online hate speech is a recent problem in our society that is rising at a steady pace by leveraging the vulnerabilities of the corresponding regimes that characterise most social media platforms. This phenomenon is primarily fostered by offensive comments, either during user interaction or in the form of a posted multimedia context. Nowadays, giant corporations own platforms where millions of users log in every day, and protection from exposure to similar phenomena appears to be necessary to comply with the corresponding legislation and maintain a high level of service quality. A robust and reliable system for detecting and preventing the uploading of relevant content will have a significant impact on our digitally interconnected society. Several aspects of our daily lives are undeniably linked to our social profiles, making us vulnerable to abusive behaviours. As a result, the lack of accurate hate speech detection mechanisms would severely degrade the overall user experience, although its erroneous operation would pose many ethical concerns. In this paper, we present ‘ETHOS’ (multi-labEl haTe speecH detectiOn dataSet), a textual dataset with two variants: binary and multi-label, based on YouTube and Reddit comments validated using the Figure-Eight crowdsourcing platform. Furthermore, we present the annotation protocol used to create this dataset: an active sampling procedure for balancing our data in relation to the various aspects defined. Our key assumption is that, even gaining a small amount of labelled data from such a time-consuming process, we can guarantee hate speech occurrences in the examined material. © 2021, The Author(s).},
	author_keywords = {Active learning; Classification; Dataset; Hate speech; Machine learning; Multi-label},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 72; All Open Access, Gold Open Access}
}

@CONFERENCE{Fetahi2023,
	author = {Fetahi, Endrit and Hamiti, Mentor and Susuri, Arsim and Shehu, Visar and Besimi, Adrian},
	title = {Automatic Hate Speech Detection using Natural Language Processing: A state-of-the-art literature review},
	year = {2023},
	journal = {12th Mediterranean Conference on Embedded Computing, MECO 2023},
	doi = {10.1109/MECO58584.2023.10155070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164957789&doi=10.1109%2fMECO58584.2023.10155070&partnerID=40&md5=caa93fb4d28bee4a94952be569cf9991},
	affiliations = {South East European University, Faculty of Contemporary Sciences and Technologies, Tetovo, North Macedonia; University of Prizren Ukshin Hoti, Faculty of Computer Science, Prizren, Serbia},
	abstract = {Social network usage is growing daily, making it impossible to manage the enormous amount of data being generated. The presence of abusive behavior and hate speech is a clearly harmful phenomenon that is evident on these networks. Due to its importance, recent studies have revealed a significant concern in this field. This review aims to provide insight into the tasks and procedures associated with the automatic detection and classification of texts containing hate speech. As the domain of hate speech is wide, an analysis of definitions is conducted and a comprehensive and unifying definition is proposed. This paper also investigates the latest datasets across languages used to train AI models. Recent studies show that feature selection plays a key role in detecting hate speech. In this research, we analyze which are the most utilized and impactful features from works done in this domain. While various classification algorithms have been used for hate speech detection, we investigate numerous research studies using multiple types of machine learning and deep learning models and present the most recent and relevant methods.  © 2023 IEEE.},
	author_keywords = {Classification; Deep Learning; Feature Extraction; Hate speech detection; HS Datasets; Machine Learning},
	keywords = {Classification (of information); Deep learning; Learning algorithms; Learning systems; Natural language processing systems; Speech recognition; Deep learning; Features extraction; Hate speech detection; HS dataset; Language processing; Literature reviews; Machine-learning; Natural languages; Speech detection; State of the art; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 12th Mediterranean Conference on Embedded Computing, MECO 2023; Conference date: 6 June 2023 through 10 June 2023; Conference code: 190017}
}

@CONFERENCE{Rao2023960,
	author = {Rao, Matta Chenna and Yelavarti, Kalyan Chakravarti and Kalyan, Nakka Pavan},
	title = {A Framework for Hate Speech Detection using Different ML Algorithms},
	year = {2023},
	journal = {7th International Conference on Trends in Electronics and Informatics, ICOEI 2023 - Proceedings},
	pages = {960 – 966},
	doi = {10.1109/ICOEI56765.2023.10125942},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161252756&doi=10.1109%2fICOEI56765.2023.10125942&partnerID=40&md5=cfb13c303a0edca1f904832bdbb0aaad},
	affiliations = {Information Technology Velagapudi Ramakrishna, Siddhartha Engineering College, Vijayawada, India; Velagapudi Ramakrishna, Siddhartha Engineering College, Dept of It, Vijayawada, India},
	abstract = {Social media is one among the most widely used platforms in the world. People use social media for communication and many other purposes. However, this has led to a number of issues, including the proliferation of hate messages. It is becoming increasingly difficult to identify hate speech. While there have been some completed works on this topic, research works still need to be improved in terms of accuracy. To address this problem on social media, this study proposes various ML methods to mark hateful contents on various datasets. Text classification tasks are commonly used to model hate speech concerns. This study makes a contribution by combining features extracted through feature engineering techniques and comparing the performance of ML algorithms on publicly available dataset with three different categories.  © 2023 IEEE.},
	author_keywords = {Hateful speech; Machine learning; Natural language processing; Text categorization; Virtual networking platforms},
	keywords = {Classification (of information); E-learning; Natural language processing systems; Social networking (online); Text processing; Hateful speech; Language processing; Machine-learning; Natural language processing; Natural languages; Social media; Speech detection; Text categorization; Virtual networking; Virtual networking platform; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th International Conference on Trends in Electronics and Informatics, ICOEI 2023; Conference date: 11 April 2023 through 13 April 2023; Conference code: 188936}
}

@ARTICLE{Fazil202316801,
	author = {Fazil, Mohd and Khan, Shakir and Albahlal, Bader M. and Alotaibi, Reemiah Muneer and Siddiqui, Tamanna and Shah, Mohd Asif},
	title = {Attentional Multi-Channel Convolution With Bidirectional LSTM Cell Toward Hate Speech Prediction},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {16801 – 16811},
	doi = {10.1109/ACCESS.2023.3246388},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149172058&doi=10.1109%2fACCESS.2023.3246388&partnerID=40&md5=68874cc62c05e9c5968f238821c70174},
	affiliations = {University of Limerick, Center for Transformative Learning, Limerick, V94 T9PX, Ireland; Imam Mohammad Ibn Saud Islamic University, College of Computer and Information Sciences, Riyadh, 11432, Saudi Arabia; University Center for Research and Development, Department of Computer Science and Engineering, Chandigarh University, Mohali, 140413, India; Aligarh Muslim University, Department of Computer Science, Uttar Pradesh, Aligarh, 202002, India; Department of Economics, Kebri Dehar University, Kebri Dehar, 250, Ethiopia; Woxsen University, Kamkole Sadasivpet, School of Business, Hyderabad, Telangana, 502345, India; Lovely Professional University, Division of Research and Development, Punjab, Phagwara, 144001, India},
	abstract = {Online social networks(OSNs) facilitate their users in real-time communication but also open the door for several challenging problems like hate speech and fake news. This study discusses hate speech on OSNs and presents an automatic method to identify hate messages. We introduce an attentional multi-channel convolutional-BiLSTM network for the classification of hateful content. Our model uses existing word representation techniques in a multi-channel environment having several filters with different kernel sizes to capture semantics relations at various windows. The encoded representation from multiple channels passes through an attention-aware stacked 2-layer BiLSTM network. The output from stacked 2-layer BiLSTM is weighted by an attention layer and further concatenated and passes via a dense layer. Finally, an output layer employing a sigmoid function classifies the text. We investigate the efficacy of the presented model on three Twitter-related benchmark datasets considering four evaluation metrics. In comparative evaluation, our model beats the five state-of-the-art and the same number of baseline models. The ablation study shows that the exclusion of channels and attention mechanism has the highest impact on the performance of the presented model. The empirical analysis analyzing the impact of different word representation techniques, optimization algorithms, activation functions, and batch size on the presented model ascertains the use of their optimal values.  © 2013 IEEE.},
	author_keywords = {data-driven cyber security; hate speech; Multi-channel deep learning; online social networks},
	keywords = {Activation analysis; Activation energy; Convolution; E-learning; Function evaluation; Long short-term memory; Semantics; Speech communication; 2 layer; Cyber security; Data driven; Data-driven cybe security; Hate speech; Multi channel; Multi-channel deep learning; Real-time communication; Representation techniques; Word representations; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access}
}

@CONFERENCE{Sonare2023,
	author = {Sonare, Babita and Dewan, Jaya and Jadhav, Anuja and Bamboriya, Anvita and Gaikwad, Mansi and Kokare, Gayatri},
	title = {RAEEUCCI2023-Comparative study of Hate Speech detection using different Machine Learning Classifiers},
	year = {2023},
	journal = {2023 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence, RAEEUCCI 2023},
	doi = {10.1109/RAEEUCCI57140.2023.10134512},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161589474&doi=10.1109%2fRAEEUCCI57140.2023.10134512&partnerID=40&md5=23711c0cb2bc59f59b8f9217202c8714},
	affiliations = {Pimpri Chinchwad College of Engineering, Department of Information Technology, Pune, India},
	abstract = {Social media involves people getting closer to different parts of the world. The Creation of networks among different types and regions of the world consists of a clash of opinions and interests. This may lead to sharing of hate amongst people. Many social media platforms involve the concept of 'Freedom to speech.' But this also incorporates some restrictions as it can lead to huge problems of spreading hate messages. To have a peaceful environment around and prevent any kind of misinformation, there is a need of having a mechanism to automatically detect hate speech. So, this research paper solves this problem by using five different classifiers with a dataset with three classes. The classes are classified as offensive speech, hate speech, or offensive speech. The classifiers involved are Gaussian Naive Bayes, Random Forest, Support Vector Machine classifier, Logistic Regression, Decision Tree Classifier, and a TF IDF -based feature engineering technique. Maximum accuracy was achieved through RandomForest which was over 90%. Moreover, accuracy can be increased by using other feature engineering techniques and a combination of classifiers. © 2023 IEEE.},
	author_keywords = {Algorithms; Classifiers; Data Processing; Decision tree; GridSearchCv; Hate speech; hyperparameter tuning; Logistic Regression; Random forest; SVM; TF-IDF},
	keywords = {Classification (of information); Classifiers; Data handling; Logistic regression; Random forests; Social networking (online); Speech recognition; Support vector machines; Engineering techniques; Feature engineerings; Gridsearchcv; Hate speech; Hyper-parameter; Hyperparameter tuning; Logistics regressions; Random forests; SVM; TF-IDF; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2023 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence, RAEEUCCI 2023; Conference date: 19 April 2023 through 21 April 2023; Conference code: 189082}
}

@ARTICLE{Khanday2022,
	author = {Khanday, Akib Mohi Ud Din and Rabani, Syed Tanzeel and Khan, Qamar Rayees and Malik, Showkat Hassan},
	title = {Detecting twitter hate speech in COVID-19 era using machine learning and ensemble learning techniques},
	year = {2022},
	journal = {International Journal of Information Management Data Insights},
	volume = {2},
	number = {2},
	doi = {10.1016/j.jjimei.2022.100120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138023533&doi=10.1016%2fj.jjimei.2022.100120&partnerID=40&md5=dd23c73d2beeb8dc5657d66aafa4db4b},
	affiliations = {Department of Computer Sciences Baba Ghulam Shah University, Jammu & Kashmir, Rajouri, 185234, India; Department of Computer Sciences University of Kashmir, Jammu & Kashmir, Srinagar, 190006, India},
	abstract = {The COVID-19 pandemic has impacted every nation, and social isolation is the major protective method for the coronavirus. People express themselves via Facebook and Twitter. People disseminate disinformation and hate speech on Twitter. This research seeks to detect hate speech using machine learning and ensemble learning techniques during COVID-19. Twitter data was extracted from using its API with the help of trending hashtags during the COVID-19 pandemic. Tweets were manually annotated into two categories based on different factors. Features are extracted using TF/IDF, Bag of Words and Tweet Length. The study found the Decision Tree classifier to be effective. Compared to other typical ML classifiers, it has 98% precision, 97% recall, 97% F1-Score, and 97% accuracy. The Stochastic Gradient Boosting classifier outperforms all others with 99 percent precision, 97 percent recall, 98 percent F1-Score, and 98.04 percent accuracy. © 2022 The Author(s)},
	author_keywords = {COVID-19; Ensemble learning; Hate speech; Machine leaning; Misinformation; Social networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Gold Open Access}
}

@CONFERENCE{Satapara20224,
	author = {Satapara, Shrey and Majumder, Prasenjit and Mandl, Thomas and Modha, Sandip and Madhu, Hiren and Ranasinghe, Tharindu and Zampieri, Marcos and North, Kai and Premasiri, Damith},
	title = {Overview of the HASOC Subtrack at FIRE 2022: Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {4 – 7},
	doi = {10.1145/3574318.3574326},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146650899&doi=10.1145%2f3574318.3574326&partnerID=40&md5=eeab22d9df8131ec75e1ca06718f2590},
	affiliations = {Indian Institute of Technology, Hyderabad, India; DA-IICT Gandhinagar, India; University of Hildesheim, Germany; LDRP-ITR, Gandhinagar, India; Indian Institute of Science, India; University of Wolverhampton, United Kingdom; George Mason University, United States},
	abstract = {In recent years, the spread of online offensive content has become of great concern, motivating researchers to develop robust systems capable of identifying such content automatically. To carry out a fair evaluation of these systems, several international shared tasks have been organized, providing the community with essential benchmark data and evaluation methods for various languages. Organized since 2019, the HASOC (Hate Speech and Offensive Content Identification) shared task is one of these initiatives. In its fourth iteration, HASOC 2022 included three tasks for English-Hindi codemix, German and Marathi. Tasks 1 and 2 were on conversational hate speech detection. The idea is to detect supporting hate speech, profanity, or other forms of offensiveness depending on the surrounding context of Twitter posts. Task 1 was offered in Hindi-English codemix and German. Task 2 was provided for Hindi-English codemix, and it was focused on further classifying the problematic tweets in conversational hate speech into standalone and contextual hate. This paper presents a brief description of tasks, data, and participation.  © 2022 Owner/Author.},
	author_keywords = {Datasets; Hate Speech; Machine Learning; Marathi; Offensive Language; Text Classification},
	keywords = {Classification (of information); Iterative methods; Online systems; Text processing; Benchmark data; Benchmark evaluation; Content identifications; Dataset; Hate speech; Machine-learning; Marathi; Offensive languages; Robust systems; Text classification; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 14th Annual Forum for Information Retrieval Evaluation; Conference date: 9 December 2022 through 13 December 2022; Conference code: 185946; All Open Access, Green Open Access}
}

@ARTICLE{Khalaf2023450,
	author = {Khalaf, Suadad Zaidan and Shujaa, Mohamed Ibrahim and Alwahhab, Ahmed Bahaaulddin A.},
	title = {Utilizing Machine Learning and Computer Vision for the Detection of Abusive Behavior in IoT Systems},
	year = {2023},
	journal = {International Journal of Intelligent Engineering and Systems},
	volume = {16},
	number = {4},
	pages = {450 – 460},
	doi = {10.22266/ijies2023.0831.36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164599977&doi=10.22266%2fijies2023.0831.36&partnerID=40&md5=e44921968f406e4fd40ce06add49186e},
	affiliations = {Department of Computer Techniques Engineering, Middle Technical University, Baghdad, Iraq},
	abstract = {Law enforcement and civilian protection are increasingly dependent on surveillance technologies. To prevent social, economic, and environmental harm, video surveillance situations like those in train stations, schools, and hospitals must automatically detect aggressive and suspicious behavior. Intelligent video surveillance systems now enable human interaction monitoring. Despite its security benefits, crowds and the camera's vision make it difficult to distinguish regular from abnormal activity. Therefore, there is a great deal of investigation into the many methods of identifying violent behavior. The detection approach presented in this research can be broken down into three distinct subfields. The classification methods employed led to the formation of these classes. Classifications include Gradient Descent (SGD), Adaptive boosting (ADA), Naive Base (NB), and Logistic Regression (LR) for detecting violent acts with machine learning. Methods for feature extraction and violence detection are derived using Principal Component Analysis (PCA). Dataset learning-based models for violence detection can also be evaluated using the AIRTLab dataset, a model developed to test the robustness of algorithms against false positives. In order to determine if the proposed model's resistance to false positives, accuracy (ACC) metrics were computed on the proposed model and used to set a benchmark for the AIRTLab dataset. According to the research literature, the proposed models are accurate of 98.31% with the logistic regression classifier having superior generalization skills. © 2023, International Journal of Intelligent Engineering and Systems. All Rights Reserved.},
	author_keywords = {Computer vision; Human behavior analysis; Machine learning; Violence},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@CONFERENCE{Zhou2023,
	author = {Zhou, Yingzi},
	title = {Detection of Violent Crowd Behavior based on Mean Kinetic Streak Flow},
	year = {2023},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {12566},
	doi = {10.1117/12.2667803},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159721751&doi=10.1117%2f12.2667803&partnerID=40&md5=4523f336280369de0200535796b848ed},
	affiliations = {Panzhihua University, Panzhihua, China},
	abstract = {With the frequent occurrence of global security problems, violent crowd behavior endangers public security seriously. Meanwhile, intelligent surveillance video technology can be applied for violent crowd behavior detection as more and more surveillance cameras are installed in public and sensitive areas. In this paper, we propose a novel mean kinetic violent flow (MKViF) algorithm for violent crowd behavior detection by extracting the kinetic energy feature of video flow. Specifically, A is firstly calculating the mean kinetic energy by streak flow of each corner in each frame. Then, we obtain a binary indicator of kinetic energy change by calculating the amplitude change between sequence frames. Finally, the MKViF vector for a sequence of frames is obtained by averaging these binary indicators of each pixel in all frames. Experimental results show that the proposed MKViF algorithm behaves better in classification performance and realtime processing performance (45 frames per second) than the existing algorithms. © 2023 SPIE.},
	author_keywords = {mean kinetic violent flow; streak flow; violent crowd behavior detection},
	keywords = {Behavioral research; Kinetic energy; Security systems; Behavior detection; Behavior-based; Crowd behavior; Flow algorithm; Global Security; Mean kinetic violent flow; Public security; Security problems; Streak flow; Violent crowd behavior detection; Kinetics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Computer Information Science and Artificial Intelligence, CISAI 2022; Conference date: 16 September 2022 through 18 September 2022; Conference code: 188133}
}

@ARTICLE{Bourgeade2023367,
	author = {Bourgeade, Tom and Chiril, Patricia and Benamara, Farah and Moriceau, Véronique},
	title = {Topic Refinement in Multi-level Hate Speech Detection},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13981 LNCS},
	pages = {367 – 376},
	doi = {10.1007/978-3-031-28238-6_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150939937&doi=10.1007%2f978-3-031-28238-6_26&partnerID=40&md5=3f2c82c97fedfb598f753993842925c3},
	affiliations = {IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; IPAL, CNRS-NUS-ASTAR, Singapore, Singapore; University of Chicago, Chicago, IL, United States},
	abstract = {Hate speech detection is quite a hot topic in NLP and various annotated datasets have been proposed, most of them using binary generic (hateful vs. non-hateful) or finer-grained specific (sexism/racism/etc.) annotations, to account for particular manifestations of hate. We explore in this paper how to transfer knowledge across both different manifestations, and different granularity or levels of hate speech annotations from existing datasets, relying for the first time on a multilevel learning approach which we can use to refine generically labelled instances with specific hate speech labels. We experiment with an easily extensible Text-to-Text approach, based on the T5 architecture, as well as a combination of transfer and multitask learning. Our results are encouraging and constitute a first step towards automatic annotation of hate speech datasets, for which only some or no fine-grained annotations are available. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	keywords = {Learning systems; Annotated datasets; Automatic annotation; Different granularities; Fine grained; Hot topics; Learning approach; Multilevels; Multitask learning; Speech detection; Transfer learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 45th European Conference on Information Retrieval, ECIR 2023; Conference date: 2 April 2023 through 6 April 2023; Conference code: 292029}
}

@ARTICLE{AbdelHamid2022,
	author = {AbdelHamid, Medyan and Jafar, Assef and Rahal, Yasser},
	title = {Levantine hate speech detection in twitter},
	year = {2022},
	journal = {Social Network Analysis and Mining},
	volume = {12},
	number = {1},
	doi = {10.1007/s13278-022-00950-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137148802&doi=10.1007%2fs13278-022-00950-4&partnerID=40&md5=bec7cf70866755d63429b142f90c7f6e},
	affiliations = {Department of Informatics, Higher Institute for Applied Sciences and Technology, Damascus, Syrian Arab Republic},
	abstract = {Nowadays, people use Online Social Networks to express feelings and ideas and to communicate and share information. With the freedom space provided by such networks, some people tend to propagate hate speech and insults. An early detection of such content is crucial for predicting conflicts and could prevent the emotions from becoming actions or spreading widely. Hate speech detection work on the Arabic text is sparse and scant compared to other languages like English. Furthermore, the Arabic corpora of short texts in the Levantine dialect for hate speech are also scant. In this paper, we build our dataset of Arabic tweets from Syria and its neighbors with annotations of Normal and Hate. Therefore, word embedding with a combination of term frequency and inverse document frequency (TF-IDF) was concatenated for text representation in traditional classifiers; we used multiple classification algorithms, including Random Forest, Support Vector Machines, and three deep learning classifiers (AraBERT, ArabicBERT, and GigaBERT) which provide on our dataset to validate the effectiveness of our augmented dataset and different used feature representations. The experiment results show that concatenating word embedding and TF-IDF can improve the classification performance; besides, deep learning classifiers show better results compared to traditional ones. Our best model with GigaBERT significantly outperforms other used models with a 94.6% under the AUC-ROC curve (0.81 macro F1-score). These tests were made against other several datasets, and we got the best results for our dataset. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Arabic; Hate speech; Natural language processing; Offensive; Social networks},
	keywords = {Classification (of information); Decision trees; Deep learning; Natural language processing systems; Social networking (online); Speech recognition; Statistical tests; Support vector machines; Text processing; Arabic; Embeddings; Hate speech; Language processing; Natural language processing; Natural languages; Offensive; Social network; Speech detection; Term Frequency; Embeddings},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Shubhang2023536,
	author = {Shubhang, S. and Kumar, Sudhanshu and Jindal, Uttkarsha and Kumar, Ashutosh and Roy, Nihar Ranjan},
	title = {Identification of Hate Speech and Offensive Content using BI-GRU-LSTM-CNN Model},
	year = {2023},
	journal = {IDCIoT 2023 - International Conference on Intelligent Data Communication Technologies and Internet of Things, Proceedings},
	pages = {536 – 541},
	doi = {10.1109/IDCIoT56793.2023.10053415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149779474&doi=10.1109%2fIDCIoT56793.2023.10053415&partnerID=40&md5=b0f59da74ff0ffdc6e833cf34b04495a},
	affiliations = {Sharda University, School of Engineering and Technology, Greater Noida, India; Sharda University, Center for Cyber Security and Cryptology, Greater Noida, India},
	abstract = {The propagation of hateful speech on social media has increased in past few years, creating an urgent need for strong counter-measures. Governments, corporations, and scholars have all made considerable investments in these measurements. Hate speech on social media platforms can lead to cyber-conflict that can impact social life at the individual and national levels. It can make people feel isolated, anxious and fearful. It can also lead to hate crimes. However, social media platforms are not able to monitor all content posted by users. This is why there is a need for automated identification of hate speech. The English text is notorious for its difficulty, complexity and lack of resources. When examining each class individually, it should be noticed that a many hateful tweets have been misclassified. As a result, it is advised to further examine the forecasts and mistakes to obtain additional understanding on the misclassification. To automatically detect hate speech in social media data, we propose a NLP model that blends convolutional and recurrent layers. Using the proposed model, we were able to identify occurrences of hate on the test dataset. According to our research, doing so could considerably raise test scores. Proposed model uses a deep learning technique based on the Bi-GRU-LSTM-CNN classifier with an accuracy of 77.16%.  © 2023 IEEE.},
	author_keywords = {Bi-GRU-LSTM-CNN; Deep Learning; Hate Speech; Machine learning; Natural Language Processing; Sentiment Analysis; Social Media Text; Social-Media; Support Vector Machine; Systematic Review; Text Classification; Vietnamese},
	keywords = {Classification (of information); Convolutional neural networks; Learning systems; Long short-term memory; Social networking (online); Speech recognition; Statistical tests; Support vector machines; Bi-GRU-LSTM-CNN; Deep learning; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Sentiment analysis; Social media; Social medium text; Support vectors machine; Systematic Review; Text classification; Vietnamese; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2023 International Conference on Intelligent Data Communication Technologies and Internet of Things, IDCIoT 2023; Conference date: 5 January 2023 through 7 January 2023; Conference code: 187004}
}

@ARTICLE{Toktarova2023814,
	author = {Toktarova, Aigerim and Abushakhma, Aktore and Adylbekova, Elvira and Manapova, Ainur and Kaldarova, Bolganay and Atayev, Yerzhan and Kassenova, Bakhyt and Aidarkhanova, Ainash},
	title = {Offensive Language Identification in Low Resource Languages using Bidirectional Long-Short-Term Memory Network},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {6},
	pages = {814 – 821},
	doi = {10.14569/IJACSA.2023.0140687},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165122797&doi=10.14569%2fIJACSA.2023.0140687&partnerID=40&md5=002d40f03d0d471c211889b50d4cfd8c},
	affiliations = {Khoja Akhmet Yassawi International Kazakh, Turkish University, Turkistan, Kazakhstan; Khoja Akhmet Yassawi International Kazakh, Turkish University, Turkistan, Kazakhstan; South Kazakhstan State Pedagogical University, Shymkent, Kazakhstan; Narxoz University, Almaty, Kazakhstan; Kokshetau University named after Sh. Ualijhanov, Kazakhstan},
	abstract = {Offensive language identification is a critical task in today's digital era, enabling the development of effective content moderation systems. However, it poses unique challenges in low resource languages where limited annotated data is available. This research paper focuses on addressing the problem of offensive language identification specifically in the context of a low resource language, namely the Kazakh language. To tackle this challenge, we propose a novel approach based on Bidirectional Long-Short-Term Memory (BiLSTM) networks, which have demonstrated strong performance in natural language processing tasks. By leveraging the bidirectional nature of the BiLSTM architecture, we capture both contextual dependencies and long-term dependencies in the input text, enabling more accurate offensive language identification. Our approach further utilizes transfer learning techniques to mitigate the scarcity of annotated data in the low resource setting. Through extensive experiments on a Kazakh offensive language dataset, we demonstrate the effectiveness of our proposed approach, achieving state-of-the-art results in offensive language identification in the low resource Kazakh language. Moreover, we analyze the impact of different model configurations and training strategies on the performance of our approach. The findings from our study provide valuable insights into offensive language identification techniques in low resource languages and pave the way for more robust content moderation systems tailored to specific linguistic contexts. © 2023, International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {classification; deep learning; low resource language; machine learning; natural language processing; Offensive language},
	keywords = {Brain; Classification (of information); Learning algorithms; Learning systems; Natural language processing systems; Deep learning; Language identification; Language processing; Low resource languages; Machine-learning; Memory network; Natural language processing; Natural languages; Offensive languages; Performance; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Yang20224505,
	author = {Yang, Chuanpeng and Zhu, Fuqing and Liu, Guihua and Han, Jizhong and Hu, Songlin},
	title = {Multimodal Hate Speech Detection via Cross-Domain Knowledge Transfer},
	year = {2022},
	journal = {MM 2022 - Proceedings of the 30th ACM International Conference on Multimedia},
	pages = {4505 – 4514},
	doi = {10.1145/3503161.3548255},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151166888&doi=10.1145%2f3503161.3548255&partnerID=40&md5=94601482cb226d4e8c6612fa4504a063},
	affiliations = {Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China},
	abstract = {Nowadays, the hate speech diffusion of texts and images in social network has become the mainstream compared with the diffusion of texts-only, raising the pressing needs of multimodal hate speech detection task. Current research on this task mainly focuses on the construction of multimodal models without considering the influence of the unbalanced and widely distributed samples for various attacks in hate speech. In this situation, introducing enhanced knowledge is necessary for understanding the attack category of hate speech comprehensively. Due to the high correlation between hate speech detection and sarcasm detection tasks, this paper makes an initial attempt of common knowledge transfer based on the above two tasks, where hate speech detection and sarcasm detection are defined as primary and auxiliary tasks, respectively. A scalable cross-domain knowledge transfer (CDKT) framework is proposed, where the mainstream vision-language transformer could be employed as backbone flexibly. Three modules are included, bridging the semantic, definition and domain gaps simultaneously between primary and auxiliary tasks. Specifically, semantic adaptation module formulates the irrelevant parts between image and text in primary and auxiliary tasks, and disentangles with the text representation to align the visual and word tokens. Definition adaptation module assigns different weights to the training samples of auxiliary task by measuring the correlation between samples of the auxiliary and primary task. Domain adaptation module minimizes the feature distribution gap of samples in two tasks. Extensive experiments show that the proposed CDKT provides a stable improvement compared with baselines and produces a competitive performance compared with some existing multimodal hate speech detection methods.  © 2022 ACM.},
	author_keywords = {hate speech; knowledge transfer; multimodal; vision-language},
	keywords = {Domain Knowledge; Semantics; Speech recognition; Adaptation module; Cross-domain; Detection tasks; Domain knowledge; Hate speech; Knowledge transfer; Multi-modal; Pressung; Speech detection; Vision-language; Knowledge management},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; Conference name: 30th ACM International Conference on Multimedia, MM 2022; Conference date: 10 October 2022 through 14 October 2022; Conference code: 183235; All Open Access, Bronze Open Access}
}

@CONFERENCE{Manikanta2023,
	author = {Manikanta, P. Pavan V S N and Bhavani, R. and Anbazhagan, K.},
	title = {Detecting Cyberbullying Behavior in Cyber Data using Bagging Classifier and comparing its Capability over Support Vector Machine Algorithm},
	year = {2023},
	journal = {Proceedings of 8th IEEE International Conference on Science, Technology, Engineering and Mathematics, ICONSTEM 2023},
	doi = {10.1109/ICONSTEM56934.2023.10142893},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163156443&doi=10.1109%2fICONSTEM56934.2023.10142893&partnerID=40&md5=c3143fe60d7060530a5bfb9a8131af12},
	affiliations = {Saveetha University, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Department of Computer Science and Engineering, Tamilnadu, Chennai, 602105, India},
	abstract = {Aim: The suggested research will attempt to perform novel cyberbullying detection by classifying between offensive and non-offensive tweets from Twitter and from its dataset using Bagging Classifier and Support Vector Machine. Materials and Methods: A dataset of abusive and non-offensive tweets is used to develop the Bagging Classifier. Bagging Classifier uses and develops a machine learning method to identify tweets as offensive or not. The sample size was calculated to be 40 per set, and the quality was verified and recorded using Gpower of 80%. Results: The accuracy was maximum in classifications of offensive and non-offensive tweets using Bagging Classifier (94.2%) with a minimum mean error and compared to Support Vector Machine (89.4%). The differences between the classifiers are statistically negligible (p=0.44). Conclusion: In the classification of offensive and non-offensive tweets, the study shows that the Bagging Classifier algorithm outperforms the SVM approach.  © 2023 IEEE.},
	keywords = {Classification (of information); Computer crime; Learning systems; Classifier algorithms; Cyber bullying; Machine learning methods; Mean errors; Sample sizes; Support vector machines algorithms; Support vectors machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 8th IEEE International Conference on Science, Technology, Engineering and Mathematics, ICONSTEM 2023; Conference date: 6 April 2023 through 7 April 2023; Conference code: 189244}
}

@ARTICLE{Du2022,
	author = {Du, Pengfei and Gao, Yali and Li, Xiaoyong},
	title = {Towards an Intrinsic Interpretability Approach for Multimodal Hate Speech Detection},
	year = {2022},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	volume = {36},
	number = {13},
	doi = {10.1142/S0218001422500409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140312450&doi=10.1142%2fS0218001422500409&partnerID=40&md5=837ea8b4b38760744e231cff56821eb5},
	affiliations = {Key Laboratory of Trustworthy Distributed Computing and Service Ministry of Education, Beijing University of Posts and Telecommunications (BUPT), Beijing, China},
	abstract = {With the development of social media, multimodal hate speech that relies on images and text has become an emerging way of spreading hate. The detection of multimodal hate speech is gradually becoming an increasingly challenging task. While many works based on neural networks and multimodal machine learning were proposed to detect multimodal hate speech, only few attempts have been made in terms of the interpretability of the task. This leads to difficulties in analyzing prediction results and model improvement. Therefore, this paper investigates the interpretable multimodal hate speech detection task and develops an intrinsically interpretable deep learning method by leveraging the multimodal architecture. Specifically, we leverage a multimodal pretrained model as the backbone of the final detection results and parallel an interpretability module via a joint training approach, which calculates the input tokens and fine-grained tags through a filter-gate attention mechanism. The interpretability module provides an interpretable basis for the final result judgment. We conduct experiments on the hate speech detection dataset and demonstrate that our proposed method not only significantly outperforms other methods but also provides interpretable insights into the decisions of our model.  © 2022 World Scientific Publishing Company.},
	author_keywords = {interpretation; Multimodal hate speech detection; multimodal machine learning},
	keywords = {Deep learning; Learning systems; Interpretability; Interpretation; Machine-learning; Multi-modal; Multimodal hate speech detection; Multimodal machine learning; Neural-networks; Social media; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kumari2023115,
	author = {Kumari, Kavita and Jamatia, Anupam},
	title = {An Approach of Hate Speech Identification on Twitter Corpus},
	year = {2023},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {326 SIST},
	pages = {115 – 125},
	doi = {10.1007/978-981-19-7513-4_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161368596&doi=10.1007%2f978-981-19-7513-4_11&partnerID=40&md5=fdd6fae932108a71ee061717105bea8d},
	affiliations = {Department of Computer Science and Engineering, National Institute of Technology, Agartala, India},
	abstract = {In recent times, the Internet and social media are very well-known and popular among people. Usage of social media is increased exponentially during the last few years globally, and it allows people to engage with one another and share ideas, thoughts, opinions, etc. Every day, massive amounts of data are disseminated at breakneck speed via social media platforms, reaching a massive audience. Furthermore, the ability to write anonymous posts and comments makes expressing and spreading hate speech even easier. To improve the users’ experience, social media sites are attempting to remove hateful remarks. In this research work, the main focus is on developing automated hate speech and offensive language detection models. Started with traditional hate speech and offensive language identification approaches, than reaches to advanced hate speech recognition methods for social media. This brings a need for integrated datasets and the hate speech prediction method. This paper describes the study on hate speech and offensive content identification in English language by using the various approaches based on machine learning algorithms (Support vector machine, decision tree, and so on) and NLP, along with the features used for the classification problem. The models were tested on the HASOC (2021) datasets and concluded that the ensemble model perform better than other algorithms with the test dataset for different tasks. Results and analysis part of this paper offers researchers a comprehensive picture of approaches. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Hate speech; Machine learning; Natural language processing; Offensive language; Online social networks; Text classification; Twitter},
	keywords = {Classification (of information); Decision trees; E-learning; Learning algorithms; Natural language processing systems; Speech recognition; Statistical tests; Support vector machines; Text processing; Hate speech; Language processing; Machine-learning; Natural language processing; Natural languages; Offensive languages; Social media; Speech identification; Text classification; Twitter; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 10th International Conference on Frontiers in Intelligent Computing: Theory and Applications, FICTA 2022; Conference date: 18 June 2022 through 19 June 2022; Conference code: 293909}
}

@ARTICLE{Mansur202316226,
	author = {Mansur, Zainab and Omar, Nazlia and Tiun, Sabrina},
	title = {Twitter Hate Speech Detection: A Systematic Review of Methods, Taxonomy Analysis, Challenges, and Opportunities},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {16226 – 16249},
	doi = {10.1109/ACCESS.2023.3239375},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147299223&doi=10.1109%2fACCESS.2023.3239375&partnerID=40&md5=929dbbc230c72790a5b91963b6239c10},
	affiliations = {Universiti Kebangsaan Malaysia, Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Bangi, 43600, Malaysia; Omar Al-Mukhtar University, Faculty of Sciences, Department of Computer Science, Al Bayda, Libya},
	abstract = {Hate speech detection has substantially increased interest among researchers in the domain of natural language processing (NLP) and text mining. The number of studies on this topic has been growing dramatically. Thus, the purpose of this analysis is to develop a resource that consists of an outline of the approaches, methods, and techniques employed to address the issue of Twitter hate speech. This study can be used to aid researchers in the development of a more effective model for future studies. This review focused on studies published over the past eight years, i.e., from 2015 to 2022. This systematic search was carried out in December 2020 and updated in July 2022. Ninety-one articles published within the mentioned period met the set criteria and were selected for this review. From the evaluation of these works, it is clear that a perfect solution has yet to be found. To conclude, this paper focused on presenting an in-depth understanding of current perspectives and highlighted research opportunities to boost the quality of hate speech detection systems. In turn, this helps social networking services that seek to detect hate messages generated by users before they are posted, thus reducing the risk of targeted harassment.  © 2013 IEEE.},
	author_keywords = {automatic detection; classification; Hate speech; natural language processing; social media; systematic review; twitter},
	keywords = {Blogs; Data mining; Learning algorithms; Learning systems; Natural language processing systems; Speech recognition; Automatic Detection; Hate speech; Language processing; Machine-learning; Medium; Natural language processing; Natural languages; Social media; Social networking (online); Systematic; Systematic Review; Twitter; Social networking (online)},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Gold Open Access}
}@CONFERENCE{Doan2022155,
	author = {Doan, Long-An and Nguyen, Phuong-Thao and Phan, Thi-Oanh and Do, Trong-Hop},
	title = {An Implementation of Large Scale Hate Speech Detection System for Streaming Social Media Data},
	year = {2022},
	journal = {Proceeding - IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2022},
	pages = {155 – 159},
	doi = {10.1109/COMNETSAT56033.2022.9994299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146710435&doi=10.1109%2fCOMNETSAT56033.2022.9994299&partnerID=40&md5=a8cbe6a72cc7e55307023b8d68048866},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {The omnipresence of online social media brings various positive and negative consequences for society. Besides benefits, social media can cause big problem caused by hate and offensive contents. Detecting and removing those toxic contents using machine learning is a major research topic in social network. Two of the challenges of this topic are that the volume of social media data is so big and that these data need to be processed in real-time. In this paper, we set out to develop system to detect hate speech in Vietnamese YouTube comments using machine learning and big data technology. The streaming data from Youtube is processed in real-time using Kafka, Spark, and machine learning technology. Finally, a dashboard powered by Streamlit will be used to display the results. © 2022 IEEE.},
	author_keywords = {Big Data; Hate Speech Detection; Social Network; Streaming},
	keywords = {Machine learning; Media streaming; Social networking (online); Speech recognition; Detection system; Hate speech detection; Large-scales; Machine-learning; Real- time; Social media datum; Social network; Speech detection; Streaming; YouTube; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 11th IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2022; Conference date: 3 November 2022 through 5 November 2022; Conference code: 185811}
}

@CONFERENCE{Ranasinghe2022489,
	author = {Ranasinghe, Tharindu and North, Kai and Premasiri, Damith and Zampieri, Marcos},
	title = {Overview of the HASOC Subtrack at FIRE 2022: Offensive Language Identification in Marathi},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {489 – 501},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146652623&partnerID=40&md5=ff65a48f2d8251398c78fc6522d63f1b},
	affiliations = {University of Wolverhampton, United Kingdom; George Mason University, United States},
	abstract = {The widespread of offensive content online has become a reason for great concern in recent years, motivating researchers to develop robust systems capable of identifying such content automatically. With the goal of carrying out a fair evaluation of these systems, several international competitions have been organized, providing the community with important benchmark data and evaluation methods for various languages. Organized since 2019, the HASOC (Hate Speech and Offensive Content Identification) shared task is one of these initiatives. In its fourth iteration, HASOC 2022 included three subtracks for English, Hindi, and Marathi. In this paper, we report the results of the HASOC 2022 Marathi subtrack which provided participants with a dataset containing data from Twitter manually annotated using the popular OLID taxonomy. The Marathi track featured three additional subtracks, each corresponding to one level of the taxonomy: Task A - offensive content identification (offensive vs. non-offensive); Task B - categorization of offensive types (targeted vs. untargeted), and Task C - offensive target identification (individual vs. group vs. others). Overall, 59 runs were submitted by 10 teams. The best systems obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of traditional and deep learning approaches. © 2022 Copyright for this paper by its authors.},
	author_keywords = {hate speech; Marathi; offensive language; text categorization},
	keywords = {Competition; Deep learning; Iterative methods; Natural language processing systems; Online systems; Text processing; Benchmark data; Benchmark evaluation; Content identifications; Hate speech; International competitions; Language identification; Marathi; Offensive languages; Robust systems; Text categorization; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@ARTICLE{Bose2022,
	author = {Bose, Saugata},
	title = {Hate Speech Detection: Performance Based upon a Novel Feature Detection †},
	year = {2022},
	journal = {Engineering Proceedings},
	volume = {31},
	number = {1},
	doi = {10.3390/ASEC2022-13788},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163592081&doi=10.3390%2fASEC2022-13788&partnerID=40&md5=cc531228ebee75a1ce3a8aa9cff55aa4},
	affiliations = {School of Computing and Information Technology, Faculty of Science and Engineering and Information Sciences, University of Wollongong, Wollongong, 2500, NSW, Australia},
	abstract = {Hate speech is abusive or stereotyping speech against a group of people, based on characteristics such as race, religion, sexual orientation, and gender. Internet and social media have made it possible to spread hatred easily, fast, and anonymously. The large scale of data produced through social media platforms requires the development of effective automatic methods to detect such content. Hate speech detection in short text on social media has become an active research topic in recent years, as it differs from the traditional information retrieval for documents. My research is to develop a method to effectively detect hate speech based on deep learning techniques. I have proposed a novel feature based on the lexicon of short text. Experiments have shown that proposed deep-neural-network-based models improve the performance when a novel feature combines with CNN and SVM. © 2022 by the author.},
	author_keywords = {CNN; feature detection; hate speech; SVM},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Mnassri20224649,
	author = {Mnassri, Khouloud and Rajapaksha, Praboda and Farahbakhsh, Reza and Crespi, Noel},
	title = {BERT-based Ensemble Approaches for Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - IEEE Global Communications Conference, GLOBECOM},
	pages = {4649 – 4654},
	doi = {10.1109/GLOBECOM48099.2022.10001325},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146931824&doi=10.1109%2fGLOBECOM48099.2022.10001325&partnerID=40&md5=8941a1519c539598680ba45e8ac1a7ea},
	affiliations = {Telecom SudParis, IMT, Institut Polytechnique de Paris, Palaiseau, 91764, France},
	abstract = {With the freedom of communication provided in online social media, hate speech has increasingly generated. This leads to cyber conflicts affecting social life at the individual and national levels. As a result, hateful content classification is becoming increasingly demanded for filtering hate content before being sent to the social networks. This paper focuses on classifying hate speech in social media using multiple deep models that are implemented by integrating recent transformer-based language models such as BERT, and neural networks. To improve the classification performances, we evaluated with several ensemble techniques, including soft voting, maximum value, hard voting and stacking. We used three publicly available Twitter datasets (Davidson, HatEval2019, OLID) that are generated to identify offensive languages. We fused all these datasets to generate a single dataset (DHO dataset), which is more balanced across different labels, to perform multi-label classification. Our experiments have been held on Davidson dataset and the DHO corpora. The later gave the best overall results, especially F1 macro score, even it required more resources (time execution and memory). The experiments have shown good results especially the ensemble models, where stacking gave F1 score of 97% on Davidson dataset and aggregating ensembles 77% on the DHO dataset. © 2022 IEEE.},
	author_keywords = {BERT; deep neural networks; ensemble learning; hate speech detection; Twitter},
	keywords = {Audio signal processing; Classification (of information); Social networking (online); Speech communication; Speech recognition; BERT; Davidson; Ensemble approaches; Ensemble learning; Hate speech detection; Online social medias; Social life; Speech detection; Stackings; Twitter; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 2022 IEEE Global Communications Conference, GLOBECOM 2022; Conference date: 4 December 2022 through 8 December 2022; Conference code: 185952; All Open Access, Green Open Access}
}

@CONFERENCE{Chanda2022502,
	author = {Chanda, Supriya and Sheth, Sacchit D. and Pal, Sukomal},
	title = {Coarse and Fine-Grained Conversational Hate Speech and Offensive Content Identification in Code-Mixed Languages using Fine-Tuned Multilingual Embedding},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {502 – 512},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146672592&partnerID=40&md5=eca507ea851a737f0adda47e3f6a12df},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology (BHU), Varanasi, 221005, India},
	abstract = {We are seeing an increase in hateful and offensive tweets and comments on social media platforms like Facebook and Twitter, impacting our social lives. Because of this, there is an increasing need to identify online postings that can violate accepted norms. For resource-rich languages like English, the challenge of identifying hateful and offensive posts has been well investigated. However, it remains unexplored for languages with limited resources like Marathi. Code-mixing frequently occurs in the social media sphere. Therefore identification of conversational hate and offensive posts and comments in Code-Mixed languages is also challenging and unexplored. In three different objectives of the HASOC 2022 shared task, we proposed approaches for recognizing offensive language on Twitter in Marathi and two code-mixed languages (i.e., Hinglish and German). Some tasks can be expressed as binary classification (also known as coarse-grained, which entails categorizing hate and offensive tweets as either present or absent). At the same time, others can be expressed as multi-class classification (also known as fine-grained, where we must further categorize hate and offensive tweets as Standalone Hate or Contextual Hate). We concatenate the parent-comment-reply data set to create a dataset with additional context. We use the multilingual bidirectional encoder representations of the transformer (mBERT), which has been pre-trained to acquire the contextual representations of tweets. We have carried out several trials using various pre-processing methods and pre-trained models. Finally, the highest-scoring models were used for our submissions in the competition, which ranked our team (irlab@iitbhu) second out of 14, seventh out of 11, sixth out of 10, fourth out of 7, and fifth out of six for the ICHCL task 1, ICHCL task 2, Marathi subtask 3A, subtask 3B and subtask 3C respectively. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Code-Mixed; GermanBERT; Hate Speech; Hinglish; Marathi; Multilingual BERT; Offensive Language; Social Media},
	keywords = {Machine learning; Coarse-grained; Code-mixed; Germanbert; Hate speech; Hinglish; Marathi; Multilingual BERT; Offensive languages; Social media; Subtask; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Fernando2022166,
	author = {Fernando, W.S.S. and Weerasinghe, Ruvan and Bandara, E.R.A.D.},
	title = {Sinhala Hate Speech Detection in Social Media Using Machine Learning and Deep Learning},
	year = {2022},
	journal = {22nd International Conference on Advances in ICT for Emerging Regions, ICTer 2022},
	pages = {166 – 171},
	doi = {10.1109/ICTer58063.2022.10024082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147857460&doi=10.1109%2fICTer58063.2022.10024082&partnerID=40&md5=65c75348efc5c832ddfc072bbcd33fbc},
	affiliations = {University of Colombo, Faculty of Science, Department of Statistics, Colombo, Sri Lanka; University of Colombo, School of Computing, 35, Reid Avenue, Colombo, Sri Lanka},
	abstract = {Communication and presentation of beliefs became easier than in previous decades due to the rapid rise of information technology and computer science. Because social media is accessible worldwide via the internet, anyone can simply target someone or a group who adheres to a different culture or belief. While everyone has the freedom to express their own opinions, it should not be destructive, and everyone has the right to be free of hate speech. Because there are no automatic mechanisms for detecting hate speech on social media, anyone can be readily targeted. Because social media service providers do not have extensive linguistic expertise of some languages, such as Sinhala, it may take a few days for them to delete hate-related comments from the material after they become aware of them. As a result, detecting hate speech in the Sinhala language is an urgent and crucial task. Machine learning and deep learning based algorithms were employed in this study to automatically recognize Sinhala hate speeches broadcast on social media. Bag of words, Tf-idf, Word2Vec, and FastText feature extraction methods were used to extract features from the comments. Logistic Regression, Multinomial Naïve Bayes, Support Vector Machine, XGBoost, Random Forest machine learning models and CNN, RNN, LSTM deep learning models were trained using two pre-collected datasets with different sizes. The best six models were then chosen and test set performances were shown. According to this study, FastText with RNN has the greatest AUC ROC 0.71 with 70% accuracy for the test set.  © 2022 IEEE.},
	author_keywords = {Deep Learning; Hate speech detection; Machine Learning; Natural Language Processing; Sinhala},
	keywords = {Forestry; Learning systems; Logistic regression; Long short-term memory; Natural language processing systems; Random forests; Social networking (online); Speech recognition; Deep learning; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Sinhalum; Social media; Speech detection; Test sets; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 22nd International Conference on Advances in ICT for Emerging Regions, ICTer 2022; Conference date: 30 November 2022 through 1 December 2022; Conference code: 186255}
}

@CONFERENCE{McGillivray202239,
	author = {McGillivray, Barbara and Alahapperuma, Malithi and Cook, Jonathan and Di Bonaventura, Chiara and Meroño-Peñuela, Albert and Tyson, Gareth and Wilson, Steven R.},
	title = {Leveraging time-dependent lexical features for offensive language detection},
	year = {2022},
	journal = {EvoNLP 2022 - 1st Workshop on Ever Evolving NLP, Proceedings of the Workshop},
	pages = {39 – 54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156169150&partnerID=40&md5=f902b098d09580f5b16de43a634e33e0},
	affiliations = {King's College London, The Alan Turing Institute, United Kingdom; University of Oxford, United Kingdom; King's College London, United Kingdom; Hong Kong University of Science and Technology (GZ), Hong Kong; Oakland University, United States},
	abstract = {We present a study on the integration of time-sensitive information in lexicon-based offensive language detection systems. Our focus is on Offenseval sub-task A, aimed at detecting offensive tweets. We apply a semantic change detection algorithm over a short time span of two years to detect words whose semantics has changed and we focus particularly on those words that acquired or lost an offensive meaning between 2019 and 2020. Using the output of this semantic change detection approach, we train an Support Vector Machine (SVM) classifier on the Offenseval 2019 training set. We build on the already competitive SINAI system submitted to Offenseval 2019 by adding new lexical features, including those that capture the change in usage of words and their association with emerging offensive usages. We discuss the challenges, opportunities and limitations of integrating semantic change detection in offensive language detection models. Our work draws attention to an often neglected aspect of offensive language, namely that the meanings of words are constantly evolving and that NLP systems that account for this change can achieve good performance even when not trained on the most recent training data. © 2022 Association for Computational Linguistics.},
	keywords = {Change detection; Classification (of information); Computational linguistics; Support vector machines; Change detection; Change detection algorithms; Detection system; Language detection; Lexical features; Lexicon-based; Offensive languages; Subtask; Time dependent; Time-sensitive information; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 1st Workshop on Ever Evolving NLP, EvoNLP 2022, co-located with EMNLP 2022; Conference date: 7 December 2022; Conference code: 187851}
}

@CONFERENCE{Li20225,
	author = {Li, Zhenming and Shimada, Kazutaka},
	title = {Combining Pre-Trained Language Models and Features for Offensive Language Detection},
	year = {2022},
	journal = {Proceedings - 2022 13th International Congress on Advanced Applied Informatics Winter, IIAI-AAI-Winter 2022},
	pages = {5 – 10},
	doi = {10.1109/IIAI-AAI-Winter58034.2022.00012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160906880&doi=10.1109%2fIIAI-AAI-Winter58034.2022.00012&partnerID=40&md5=165f59435cd926a94b0cddeeac18f764},
	affiliations = {Kyushu Institute of Technology, Department of Artificial Intelligence, Fukuoka, Japan},
	abstract = {Nowadays, people often express their abusive and offensive thoughts to others on social media easier. The abusive and toxic comments hurt others seriously. Therefore those abusive and toxic comments should be detected properly through natural language processing. In this paper, we focus on two types of features in offensive language: word-level and sentence-level fea-tures. We use lexicon-based and standard bag-of-words features as the word level. We introduce BERT-based and DeepMoji-based features as the sentence level. We apply the four features to a machine learning approach: support vector machines. We evaluate the method using the combinations of four features with a dataset, Curious Cat. The best F1 score was generated by the method with all features. This result shows the effectiveness of our proposed method. In addition, the experimental result indicates that DeepMoji generated from Twitter data is better than BERT which is generated from written language, for an offensive language detection task about social media data. © 2022 IEEE.},
	author_keywords = {Features for ma-chine learning; Offensive language detection; Pre-trained language model; Social media},
	keywords = {Computational linguistics; Feature extraction; Learning systems; Natural language processing systems; Social networking (online); Feature for ma-chine learning; Language detection; Language features; Language model; Offensive language detection; Offensive languages; Pre-trained language model; Sentence level; Social media; Word level; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 13th IIAI International Congress on Advanced Applied Informatics Winter, IIAI-AAI-Winter 2022; Conference date: 12 December 2022 through 14 December 2022; Conference code: 188822}
}

@CONFERENCE{Marhaba202264,
	author = {Marhaba, Sara and Abdelrahman, Arwa and Alomairi, Afnan and Alazwari, Hatoon and Heiba, Fatma and Althubaity, Areej},
	title = {Detecting Hate speech in Arabic Literahire Tweets},
	year = {2022},
	journal = {Proceedings of 2022 5th National Conference of Saudi Computers Colleges, NCCC 2022},
	pages = {64 – 70},
	doi = {10.1109/NCCC57165.2022.10067582},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152529357&doi=10.1109%2fNCCC57165.2022.10067582&partnerID=40&md5=b313325a430cd390737938ad26b1b40d},
	affiliations = {King Abdulazize University, Computer Sciences, Fcit, Jeddah, Saudi Arabia; Umm Al-Qura University, Computer Science, Cis, Makkah, Saudi Arabia},
	abstract = {Middle Eastern people are one of the largest populations on Twitter. In recent years, more Arabic writers, especially young ones, have used Twitter to publish their literary works to a wider audience. This research focused on two literary genres: prose and poetry, to detect hate speech in Arabic literary texts that were published in Twitter platform. Arabic tweets wm be scraped, pre-processed, and classified into hate or non-hate tweets using five different machine learning algorithms; namely: Support Vector Machines, Naive Bayes, Random Forest, Gradient Boosted Decision Trees, and Extra Tree Classmer in three different scenarios: unbalance, undersampling data, and over-sampling data. We compare the performance of these algorithms based on four evaluation metrics; namely: accuracy, precision, recall, and Fl-score. Our results show that the RF algorithm produces 95.45% accuracy, 98.63% precision, 92.17% recall, and 95.29% F1-score; hence, we decided to display RF classified tweets on a website called ( ), that means Wnters' Legacy in the English language, to preserve and enable readers to easily access Arabic literature tweets.  © 2022 IEEE.},
	author_keywords = {Arabic NLP; Arabic text classification.; hate-speech classification; Machine Learning; Web scraping},
	keywords = {Classification (of information); Learning algorithms; Learning systems; Social networking (online); Support vector machines; Text processing; Arabic NLP; Arabic text classification.; Arabic texts; Classifieds; Hate-speech classification; Large population; Machine-learning; Speech classification; Text classification; Web scrapings; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th National Conference of Saudi Computers Colleges, NCCC 2022; Conference date: 21 December 2022 through 22 December 2022; Conference code: 187441}
}

@CONFERENCE{Lohitha2022492,
	author = {Lohitha, Bhusarapu and Mogana, V. and Amarnath, J Jegan},
	title = {A Comparison of Different Models for the Detection of Hate Speech},
	year = {2022},
	journal = {2022 1st International Conference on Computational Science and Technology, ICCST 2022 - Proceedings},
	pages = {492 – 496},
	doi = {10.1109/ICCST55948.2022.10040400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149374985&doi=10.1109%2fICCST55948.2022.10040400&partnerID=40&md5=203fecc299b997c24960fe4f52a81cd2},
	affiliations = {Sri Sairam Engineering College, Computer Science Engineering, Chennai, India; Sri Sairam Engineering College, Department of Cse, Chennai, India},
	abstract = {With the increasing usage of social media, we have seen an increase in inflammatory and hate speech along racial and ethnic lines on platforms such as Twitter, Instagram, and Facebook. This issue has become a serious setback for humanity, and in order to address it, we used machine learning to recognise hate speech messages across a variety of datasets. Despite the fact that machine learning has been successful at detecting offensive and hate speech in a variety of English contexts, there is yet no proper study to compare multiple machine learning algorithms that outperform a typical publicly available dataset, to the best of what we have known. With this in mind, we've developed a set of feature engineering approaches and machine learning algorithms to assess the performance of models on a large scale. © 2022 IEEE.},
	keywords = {Learning algorithms; Social networking (online); Speech recognition; Facebook; Feature engineerings; Large-scales; Machine learning algorithms; Machine-learning; Multiple machine; Performance; Sets of features; Social media; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Computational Science and Technology, ICCST 2022; Conference date: 9 November 2022 through 10 November 2022; Conference code: 186752}
}

@CONFERENCE{Johari2022325,
	author = {Johari, Nurina Farhanah Binti and Jaafar, Juliana},
	title = {A Malay Language Cyberbullying Detection Model on Twitter using Supervised Machine Learning},
	year = {2022},
	journal = {IVIT 2022 - Proceedings of 1st International Visualization, Informatics and Technology Conference},
	pages = {325 – 332},
	doi = {10.1109/IVIT55443.2022.10033395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148648035&doi=10.1109%2fIVIT55443.2022.10033395&partnerID=40&md5=843ccb93518afd0c0556d34a7cc241dc},
	affiliations = {Universiti Kuala Lumpur, Malaysian Institute of Information Technology, Kuala Lumpur, 50250, Malaysia},
	abstract = {This research detects cyberbullying for the Malay language using supervised machine learning (ML) and Natural Language Processing (NLP). Due to the high number of cyberbullying cases in Malaysia over the years and the belief that there is an increased number of unreported cyberbullying cases, there needs an intelligent way to detect cyberbullying on social media. Thus, this research explores how supervised ML and NLP can help detect cyberbullying incidents for the Malay language on social media. The dataset was collected from Twitter by scrapping tweets based on some common Malay words used in cyberbullying incidents before being labelled into six cyberbullying classes: appearance, intellectual, political, racial, sexual, and non-abusive. The resulting cyberbullying dataset is an imbalanced dataset with 45,580 tweets. The model is then built using Logistic Regression (LR), Naïve Bayes (NB), Support Vector Machine (SVM) and Random Forest (RF) algorithms combined with three different feature extraction techniques, that is Bag of Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF) and Word2Vec. The result indicates that the best model uses LR combined with the TF-IDF feature extraction technique. The model was improved further by using an oversampling technique (Synthetic Minority Oversampling Technique, SMOTE) to deal with the imbalanced dataset and tuning the model hyperparameters. The F-Score of the optimised TF-IDF - LR is 0.46. © 2022 IEEE.},
	author_keywords = {Cyberbullying Detection; Malay Cyberbullying; Text Pre-Processing; Tweets Classification)},
	keywords = {Computer crime; Extraction; Feature extraction; Forestry; Learning algorithms; Learning systems; Logistic regression; Natural language processing systems; Social networking (online); Text processing; Cyber bullying; Cyberbullying detection; Logistics regressions; Malay cyberbullying; Malay languages; Pre-processing; Supervised machine learning; Text pre-processing; Tweet classification); Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 1st International Visualization, Informatics and Technology Conference, IVIT 2022; Conference date: 1 November 2022 through 2 November 2022; Conference code: 186601}
}

@ARTICLE{Husain2022,
	author = {Husain, Fatemah and Uzuner, Ozlem},
	title = {Investigating the Effect of Preprocessing Arabic Text on Offensive Language and Hate Speech Detection},
	year = {2022},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {21},
	number = {4},
	doi = {10.1145/3501398},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130502532&doi=10.1145%2f3501398&partnerID=40&md5=90c1802c93aa74301afd90e34b6c5788},
	affiliations = {Sabah AlSalem University City (Alshadadiya), Kuwait University, P.O. Box 5969, Safat, 13060, Kuwait; George Mason University, 4400 University Drive 5359 Nguyen Engineering Building, Fairfax, 22030, VA, United States},
	abstract = {Preprocessing of input text can play a key role in text classification by reducing dimensionality and removing unnecessary content. This study aims to investigate the impact of preprocessing on Arabic offensive language classification. We explore six preprocessing techniques: conversion of emojis to Arabic textual labels, normalization of different forms of Arabic letters, normalization of selected nouns from dialectal Arabic to Modern Standard Arabic, conversion of selected hyponyms to hypernyms, hashtag segmentation, and basic cleaning such as removing numbers, kashidas, diacritics, and HTML tags. We also experiment with raw text and a combination of all six preprocessing techniques. We apply different types of classifiers in our experiments including traditional machine learning, ensemble machine learning, Artificial Neural Networks, and Bidirectional Encoder Representations from Transformers (BERT)-based models to analyze the impact of preprocessing. Our results demonstrate significant variations in the effects of preprocessing on each classifier type and on each dataset. Classifiers that are based on BERT do not benefit from preprocessing, while traditional machine learning classifiers do. However, these results can benefit from validation on larger datasets that cover broader domains and dialects.  © 2022 Association for Computing Machinery.},
	author_keywords = {Arabic language; Artificial neural networks; Machine learning; Natural language processing; Offensive language detection},
	keywords = {Classification (of information); Learning algorithms; Machine learning; Natural language processing systems; Text processing; Arabic languages; Arabic texts; Dialectal arabics; Language detection; Normalisation; Offensive language detection; Offensive languages; Pre-processing techniques; Speech detection; Textual labels; Neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@CONFERENCE{Shukla2022642,
	author = {Shukla, Shubham and Nagpal, Sushama and Sabharwal, Sangeeta},
	title = {Hate Speech Detection in Hindi language using BERT and Convolution Neural Network},
	year = {2022},
	journal = {3rd IEEE 2022 International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2022},
	pages = {642 – 647},
	doi = {10.1109/ICCCIS56430.2022.10037649},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149108029&doi=10.1109%2fICCCIS56430.2022.10037649&partnerID=40&md5=e457104a059a0c9d0e8d93b023027d50},
	affiliations = {Netaji Subhas University of Technology, Department of Computer Science and Engineering, Sector-3 Dwarka, Delhi, India},
	abstract = {Social media has become crucial in our lives; it inculcates our opinions by providing untreated information. Whether we might be not participating actively but indirectly everyone became part of its coverage. Wide spread of information over the internet without any validation made it hard to analyze the impact of misleading information. Cyber hate, which is used as a tool to incite violence against a group of people based on ethnicity, nationality, language, sexual orientation, religious faiths, etc., poses a disgraceful utilization of social media. Previous apposite studies reported hate speech mainly in the English language. Less effort has been made for the resource-constraint language such as Hindi, Marathi, Kannada, etc. This work entitles hate speech detection in low-resource Hindi language using BERT and Deep Convolution Neural Network. The proposed Hindi Hate Speech BERT Convolution Neural Network model intends to detect hate speech in real-time so that any harmful incidence can be avoided as early as possible. This model presents a two-stage architecture: In the first stage, we have applied a pre-trained BERT encoder to generate encodings. In the second stage, a convolution neural network followed by a sigmoid layer is used to detect text as hatred or non-hatred. Our model achieved 0.84 & 0.77 f1-score for Hasoc 2020 and Hasoc 2021 dataset respectively.  © 2022 IEEE.},
	author_keywords = {BERT; convolution neural network; Hate speech detection; Hindi text; social media},
	keywords = {Convolution; Multilayer neural networks; Social networking (online); Speech recognition; BERT; Convolution neural network; Hate speech detection; Hindi text; Misleading informations; Sexual orientations; Social media; Speech detection; Spread of informations; Wide spreads; Neural network models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 3rd IEEE International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2022; Conference date: 4 November 2022 through 5 November 2022; Conference code: 186665}
}

@CONFERENCE{Kirk202252,
	author = {Kirk, Hannah Rose and Vidgen, Bertie and Hale, Scott A.},
	title = {Is More Data Better? Re-thinking the Importance of Efficiency in Abusive Language Detection with Transformers-Based Active Learning},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {12},
	pages = {52 – 61},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148767347&partnerID=40&md5=80fb1dc5352d069952762b4fcbd0eaf6},
	affiliations = {University of Oxford, United Kingdom; The Alan Turing Institute, United Kingdom; Rewire, Israel; Meedan, United States},
	abstract = {Annotating abusive language is expensive, logistically complex and creates a risk of psychological harm. However, most machine learning research has prioritized maximizing effectiveness (i.e., F1 or accuracy score) rather than data efficiency (i.e., minimizing the amount of data that is annotated). In this paper, we use simulated experiments over two datasets at varying percentages of abuse to demonstrate that transformers-based active learning is a promising approach to substantially raise efficiency whilst still maintaining high effectiveness, especially when abusive content is a smaller percentage of the dataset. This approach requires a fraction of labeled data to reach performance equivalent to training over the full dataset. © 2022 MMMPIE. All Rights Reserved.},
	keywords = {Artificial intelligence; Active Learning; Labeled data; Language detection; Machine learning research; Performance; Simulated experiments; Efficiency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 3rd Workshop on Threat, Aggression and Cyberbullying, TRAC 2022 at 29th International Conference on Computational Linguistics. COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 192733}
}

@ARTICLE{Hooda2022213,
	author = {Hooda, Rhea and Jaiswal, Arunima and Bansal, Isha and Jain, Mehak and Singh, Pranjli and Sachdeva, Nitin},
	title = {Detection of Offensive Comments for Textual Data Using Machine Learning},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1738 CCIS},
	pages = {213 – 223},
	doi = {10.1007/978-3-031-23724-9_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149673270&doi=10.1007%2f978-3-031-23724-9_20&partnerID=40&md5=ef5883198fc873bfdb7a9f227842dc1c},
	affiliations = {Indira Gandhi Delhi Technical University for Women, Delhi, India; Galgotia’s College of Engineering and Technology, Greater Noida, India},
	abstract = {Social Media is an essential part of our lives today that provides us to connect with others all around the world. Social Media facilitates the sharing and spreading of information, thoughts, and ideas. However, just like any other innovation, it influences people in a harsh or another way. They have become a platform for spreading hatred, negative comments, and cyberbullying. Cyberbullying is bullying that occurs via digital technologies for example social media, messaging platforms, gaming platforms, and mobile phones. Cyberbullying includes posting, sending or sharing negative, mean, and harmful content. A lot of efforts are being made by researchers for the detection of cyberbullying on social networking sites. The research in this paper focuses on detecting offensive comments for textual data. The data set has been taken from Kaggle, containing 35,000 comments. A rigorous testing has been performed using various Machine learning techniques, among them SVM outperforms with an accuracy of 92.2%. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Comments; Cyberbullying; Machine learning; Offensive; Social media},
	keywords = {Computer crime; Social networking (online); Comment; Cyber bullying; Data set; Digital technologies; Machine learning techniques; Machine-learning; Offensive; Social media; Social-networking; Textual data; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Advancements in Interdisciplinary Research, AIR 2022; Conference date: 6 May 2022 through 7 May 2022; Conference code: 290609}
}

@CONFERENCE{Liu20227416,
	author = {Liu, Jiexi and Kong, Dehan and Huang, Longtao and Mao, Dinghui and Xue, Hui},
	title = {Multiple Instance Learning for Offensive Language Detection},
	year = {2022},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2022},
	pages = {7416 – 7425},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149869502&partnerID=40&md5=d86f9ff8d67fdf2632abfb9d97c36efc},
	affiliations = {Alibaba Group, China},
	abstract = {Automatic offensive language detection has become a crucial issue in recent years. Existing researches on this topic are usually based on a large amount of data annotated at sentence level to train a robust model. However, sentence-level annotations are expensive in practice as the scenario expands, while there exist a large amount of natural labels from historical information on online platforms such as reports and punishments. Notably, these natural labels are usually in bag-level corresponding to the whole documents (articles, user profiles, conversations, etc.). Therefore, we target at proposing an approach capable of utilizing the bag-level labeled data for offensive language detection in this study. For this purpose, we formalize this task into a multiple instance learning (MIL) problem. We break down the design of existing MIL methods and propose a hybrid fusion MIL model with mutual-attention mechanism. In order to verify the validity of the proposed method, we present two new bag-level labeled datasets for offensive language detection: OLID-bags and MINOR. Experimental results based on the proposed datasets demonstrate the effectiveness of the mutual-attention method at both sentence level and bag level. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; User profile; Historical information; Language detection; Large amounts; Large amounts of data; Multiple-instance learning; Offensive languages; Online platforms; Robust modeling; Sentence level; User's profiles; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2022 Findings of the Association for Computational Linguistics: EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186900}
}

@CONFERENCE{Fortuna202211794,
	author = {Fortuna, Paula and Domínguez, Mónica and Wanner, Leo and Talat, Zeerak},
	title = {Directions for NLP Practices Applied to Online Hate Speech Detection},
	year = {2022},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {11794 – 11805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149436237&partnerID=40&md5=aa94d65a3cc1d5c1a2f77b08e5711422},
	affiliations = {NLP Group, Pompeu Fabra University, Barcelona, Spain; ICREA, Pompeu Fabra University, Barcelona, Spain; Simon Fraser University, Vancouver, Burnaby, Canada},
	abstract = {Addressing hate speech in online spaces has been conceptualized as a classification task that uses Natural Language Processing (NLP) techniques. Through this conceptualization, the hate speech detection task has relied on common conventions and practices from NLP. For instance, inter-annotator agreement is conceptualized as a way to measure dataset quality and certain metrics and benchmarks are used to assure model generalization. However, hate speech is a deeply complex and situated concept that eludes such static and disembodied practices. In this position paper, we critically reflect on these methodologies for hate speech detection, we argue that many conventions in NLP are poorly suited for the problem and encourage researchers to develop methods that are more appropriate for the task. © 2022 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Speech recognition; Classification tasks; Detection tasks; Language processing; Language processing techniques; Model generalization; Natural languages; Position papers; Speech detection; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895}
}

@CONFERENCE{Ghosh2022563,
	author = {Ghosh, Koyel and Senapati, Apurbalal and Garain, Utpal},
	title = {Baseline BERT models for Conversational Hate Speech Detection in Code-mixed tweets utilizing Data Augmentation and Offensive Language Identification in Marathi},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {563 – 574},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146649982&partnerID=40&md5=683bdb05045de029fef8d435dbf3acdc},
	affiliations = {Central Institute of Technology, Assam, Kokrajhar, India; Indian Statistical Institute, Kolkata, India},
	abstract = {In today’s world, social media plays a vital role in spreading hate towards a person or group based on their color, caste, sex, sexual orientation, political differences, etc. Most of the work is done on a single tweet or comment classification, which lacks the conversation’s context. The tweet, corresponding comments, and reply often helps us understand the context of the entire discussion. This paper discusses the used system and the performance of the team CITK_ISI on the first available code-mixed dataset on Hindi-English and German conversation scrapped from Twitter. Data augmentation is used with a baseline transfer-based BERT model and achieved a macro F1 score of 0.6653 for ICHCL Hinglish and German codemix binary classification. The system also identifies hate speech and offensive language in Marathi, a binary classification that secures a macro F1 score of 0.9019. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Binary classification; Code-Mixed Languages; German; Hate Speech; Hindi-English; Marathi; Multiclass-classification; Transformers},
	keywords = {Social networking (online); Speech recognition; Binary classification; Code-mixed language; Data augmentation; German; Hate speech; Hindi-english; Marathi; Multi-class classification; Offensive languages; Transformer; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Ghosal2022,
	author = {Ghosal, Sayani and Jain, Amita and Tayal, Devendra Kumar},
	title = {An approach to detect abusive content incorporating Word2Vec and Multilayer Perceptron},
	year = {2022},
	journal = {IBSSC 2022 - IEEE Bombay Section Signature Conference},
	doi = {10.1109/IBSSC56953.2022.10037274},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149124744&doi=10.1109%2fIBSSC56953.2022.10037274&partnerID=40&md5=c124eadf4f94b7735e74f79926b04b99},
	affiliations = {Guru Gobind Singh Indraprastha University, Computer Science & Engineering, Nsut East Campus (Erstwhile A.I.A. C.T.R.), Delhi, India; Netaji Subhas University of Technology, Computer Science & Engineering, Delhi, India; Indira Gandhi Delhi University for Women, Computer Science & Engineering, Delhi, India},
	abstract = {With the rapid growth of social media text, millions of negative comments are flowing on social webs and social networking sites. Abusive content is harmful to people and societies that can provoke various criminal offenses like hate crimes. Hate speech is also a form of abusive content. An automatic and improved detection system for hate speech can help to reduce this problem. Implicit abusive content requires contextual semantic and syntactical analysis. We propose a novel abusive text detection model with the word2vec model and compositional vector model to analyze text more semantically and syntactically. The proposed model considers the English language dataset for abusive text. The abusive content detection model exhibits achievable performance compare to various deep learning and machine learning classifiers. Among all models, Multilayer Perceptron classifier achieves 86% accuracy compared to other models. © 2022 IEEE.},
	author_keywords = {Abusive Text Detection; Compositional Vector Model; Multilayer Perceptron; Natural Language Processing; Word2Vec},
	keywords = {Deep learning; Learning algorithms; Learning systems; Multilayer neural networks; Multilayers; Natural language processing systems; Semantics; Abusive text detection; Compositional vector model; Detection models; Language processing; Multilayers perceptrons; Natural language processing; Natural languages; Text detection; Vector-modeling; Word2vec; Crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 4th IEEE Bombay Section Signature Conference, IBSSC 2022; Conference date: 8 December 2022 through 10 December 2022; Conference code: 186735}
}

@ARTICLE{Ali2022,
	author = {Ali, Raza and Farooq, Umar and Arshad, Umair and Shahzad, Waseem and Beg, Mirza Omer},
	title = {Hate speech detection on Twitter using transfer learning},
	year = {2022},
	journal = {Computer Speech and Language},
	volume = {74},
	doi = {10.1016/j.csl.2022.101365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126137565&doi=10.1016%2fj.csl.2022.101365&partnerID=40&md5=ae1c225f20073078f23c0dbb1b191c71},
	affiliations = {National University of Computer and Emerging Sciences, Foundation for the Advancement of Science and Technology, 3 A.K. Brohi Road, H-11/4, Islamabad, 46000, Pakistan},
	abstract = {Social Media has become an ultimate driver of social change in the global society. Implications of the events, that take place in one corner of the word, reverberate across the globe in various geographies. This is so because the huge amount of data generated on these platforms, reaches the far corners of the world in the blink of an eye. Developers of these platforms are facing numerous challenges to keep cyber space as inclusive and healthy as possible. However, in recent years, the phenomena of offensive speech and hate speech have risen their ugly heads. Despite manual efforts, the scope of this problem is so immense that it cannot be tackled by using concerted teams. In fact, there is a need that an automated technique is designed that detects and removes offensive and hateful comments before the materialization of their harmful impacts. In this research work, we develop an Urdu language hate lexicon, on the basis of this lexicon we formulate annotated dataset of 10,526 Urdu tweets. Furthermore, as baseline experiments, we use various machine learning techniques for hate speech detection. In addition, we use transfer learning to exploit pre-trained FastText Urdu word embeddings and multi-lingual BERT embeddings for our task. Finally, we experiment with four different variants of BERT to exploit transfer learning, and we show that BERT, xlm-roberta and distil-Bert are able to achieve encouraging F1-scores of 0.68, 0.68 and 0.69 respectively, on our multi class classification task. All these models exhibited success to varying degree but outperform a number of deep learning and machine learning baseline models. © 2022 Elsevier Ltd},
	author_keywords = {Deep learning; Hate speech; Machine Learning; Social Media; Transfer learning},
	keywords = {Classification (of information); Deep learning; Embeddings; Space platforms; Speech; Speech recognition; Cyberspaces; Deep learning; Embeddings; Global society; Hate speech; Machine-learning; Social changes; Social media; Speech detection; Transfer learning; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 73}
}

@CONFERENCE{Kumar2022542,
	author = {Kumar, Gunjan and Singh, Jyoti Prakash},
	title = {Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages using Machine Learning Models},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {542 – 551},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160725398&partnerID=40&md5=e207465aeb973822d8ce96c030379be1},
	affiliations = {National Institute of Technology, Bihar, Patna, 800005, India},
	abstract = {The social media platform is widespread among users to share information, opinion, and comments. Hate speech harms society, so its detection is crucial. The HASOC (Hate Speech and Offensive Content Identification) develop a multilingual dataset of hate speech. It can be exceedingly difficult to identify hate speech, cyber-aggression, and offensive language in codemix language posted by social media users. This paper presents the HASOC task for Hindi-English datasets. We are intrigued to offer a model to distinguish between hate speech, offensive language, stand-alone hate, and contextual hate because it is essential for online social health. We have experimented with two different feature extraction: character level feature and word level. These experiments have been associated with comments on code-mixed Hindi-English social media text. The combined word-level and character-level features performed better than pre-trained fastText embedding and GloVe embedding for the code-mixed Hindi-English dataset. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Hatespeech; Machine Learning; Multilingual; Offensive Language},
	keywords = {Codes (symbols); Embeddings; Social networking (online); Speech recognition; Character level; Content identifications; Deep learning; Embeddings; Hatespeech; Machine-learning; Multilingual; Offensive languages; Social media; Word level; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@ARTICLE{Mangaonkar20221263,
	author = {Mangaonkar, Amrita and Pawar, Rohit and Chowdhury, Nahida Sultana and Raje, Rajeev R.},
	title = {Enhancing collaborative detection of cyberbullying behavior in Twitter data},
	year = {2022},
	journal = {Cluster Computing},
	volume = {25},
	number = {2},
	pages = {1263 – 1277},
	doi = {10.1007/s10586-021-03483-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122814569&doi=10.1007%2fs10586-021-03483-1&partnerID=40&md5=7077677d0b97394f583b58bbe6923019},
	affiliations = {Department of Computer and Information Science, Indiana University-Purdue University Indianapolis, Indianapolis, IN, United States},
	abstract = {Cyberbullying is a menace in today’s socially networked world. It can have damaging physical and mental effects on the victims and hence, it needs to be tackled efficiently—several detection approaches are proposed in literature but those are mostly standalone. In this paper, we revisit the distributed and collaborative approach for detecting cyberbullying behavior using machine learning algorithms—a comprehensive enhancement of our past work—that uses many local and cloud-based collaborative configurations and different datasets. It contains a set of nodes, called detection nodes, which can identify cyberbullying employing Machine Learning classification algorithms and collaborate with each other as needed. Several experiments, consisting of various collaborative patterns, different scales, and failure scenarios, have been carried out using different Twitter© datasets in this study. The empirical results obtained from the experimentation show that the proposed approach is generic (i.e., allows the incorporation of different learning and collaborative techniques), and achieves better recall and precision values when compared with the stand-alone paradigm. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Cyberbullying; Machine learning algorithms; Twitter},
	keywords = {Learning algorithms; Machine learning; Social networking (online); Classification algorithm; Cloud based collaborative; Collaborative approach; Collaborative detection; Collaborative patterns; Cyber bullying; Detection approach; Distributed approaches; Machine learning algorithms; Machine learning classification; Computer crime},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Gladwin2022,
	author = {Gladwin, Ivander and Renjiro, Evan Vitto and Valerian, Bryan and Edbert, Ivan Sebastian and Suhartono, Derwin},
	title = {Toxic Comment Identification and Classification using BERT and SVM},
	year = {2022},
	journal = {Proceedings - 2022 8th International Conference on Science and Technology, ICST 2022},
	doi = {10.1109/ICST56971.2022.10136295},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162061046&doi=10.1109%2fICST56971.2022.10136295&partnerID=40&md5=47dcd230a396066e9cea835d89d4a4f3},
	affiliations = {School of Computer Science Bina Nusantara University, Computer Science Department, Jakarta, 11480, Indonesia},
	abstract = {Bullying cases like toxic comments on many social media platforms cause a negative impact that occurs in every age circles. From those cases, we would like to make a system that can identify and classify toxic words from a comment before it is sent and seen by others. By utilizing a Machine Learning application, hopefully, the produced system can be useful in reducing bullying cases that are many in social media. Lot of experiments have been done to find the settlement for this problem, but various algorithms and models are used. In this research, we will be doing a comparison of two models, the BERT (Bidirectional Encoder Representations from Transformers) model which is usually used to solve NLP (Natural Language Processing) tasks, and SVM (Support Vector Machine) model which is great at classifying. Both models will be compared to find out which model is better in identifying and classifying toxic comments. The result that is gotten shows that BERT model is said to be superior compared to SVM model, with an accuracy of 98.3% including other metric evaluation scores that show a significant result compared to the result achieved by SVM model.  © 2022 IEEE.},
	author_keywords = {Machine Learning; Natural Language Processing; Support Vector Machine; Toxic Comments; Transformer Model},
	keywords = {Learning algorithms; Learning systems; Natural language processing systems; Social networking (online); Language processing; Machine learning applications; Machine-learning; Natural language processing; Natural languages; Social media platforms; Support vector machine models; Support vectors machine; Toxic comment; Transformer modeling; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 8th International Conference on Science and Technology, ICST 2022; Conference date: 7 September 2022 through 8 September 2022; Conference code: 189091}
}

@CONFERENCE{Lumbantoruan2022,
	author = {Lumbantoruan, Rosni and Siregar, Rifka Uli and Manik, Indah and Tambunan, Nadya and Simanjuntak, Humasak},
	title = {Analysis Comparison of FastText and Word2vec for Detecting Offensive Language},
	year = {2022},
	journal = {ICOSNIKOM 2022 - 2022 IEEE International Conference of Computer Science and Information Technology: Boundary Free: Preparing Indonesia for Metaverse Society},
	doi = {10.1109/ICOSNIKOM56551.2022.10034886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149184950&doi=10.1109%2fICOSNIKOM56551.2022.10034886&partnerID=40&md5=c445ad5b78088f62d14a37928ccda988},
	affiliations = {Institut Teknologi Del, Faculty of Informatics and Engineering, Laguboti, Indonesia},
	abstract = {Twitter is one of the most popular platforms for sharing opinions, ideas, feelings and information. Tweets on Twitter may have language that is similar to that of a group or individual that is considered offensive. One issue brought on by offensive language is cyberbullying, which can encourage someone to ask questions online and use strong language to discuss hate. As a result, many users who interact online, including on social media, run the risk of being made fun out or harassed using abusive language that can affect the users mentally. Thus, identifying offensive language is both a necessary and useful task especially in social media platform. Offensive language can be classified to irony, sarcasm, and figurative. Currently, many research on offensive language detection simply pay attention to one of irony or sarcasm. However, offensive language may contain multi-class classification such as figurative that consist of both irony and sarcasm label. Here, we suggest categorizing tweets into four categories: irony, sarcasm, figurative or not an offensive at all (regular). Specifically, we first identify the relationship between each word using Word2vec and FastText word embedding using Continuous Bag of Words Model (CBOW) and Skip-gram architectures, and then we classify the offensive language label using CNN-BiLSTM, a combination of deep learning approaches Convolutional Neural Networks (CNN) and Bidirectional-Long Short Term Memory (Bi-LSTM) by first examining the impact of hyper-parameters on language classification. The experiment indicates using the Kaggle Dataset, CNN-BiLSTM with Word2vec with CBOW architecture outperforms CNN-BiLSTM with FastText.  © 2022 IEEE.},
	author_keywords = {CNN-BiLSTM; FastText; Multi-class; Offensive Language Detection; Word2vec},
	keywords = {Convolutional neural networks; Information retrieval; Long short-term memory; Network architecture; Bag-of-words models; Convolutional neural network; Convolutional neural network-BiLSTM; Fasttext; Language detection; Multi-class; Offensive language detection; Offensive languages; Popular platform; Word2vec; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th IEEE International Conference of Computer Science and Information Technology, ICOSNIKOM 2022; Conference date: 19 October 2022 through 21 October 2022; Conference code: 186730}
}

@ARTICLE{Shi2022,
	author = {Shi, Xiayang and Liu, Xinyi and Xu, Chun and Huang, Yuanyuan and Chen, Fang and Zhu, Shaolin},
	title = {Cross-lingual offensive speech identification with transfer learning for low-resource languages},
	year = {2022},
	journal = {Computers and Electrical Engineering},
	volume = {101},
	doi = {10.1016/j.compeleceng.2022.108005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130610944&doi=10.1016%2fj.compeleceng.2022.108005&partnerID=40&md5=4e75625758fc637eaf6e0d4d4151667e},
	affiliations = {College of Software Engineering, Zhengzhou University of Light Industry, Zhengzhou, 450000, China; College of Mathematics and Information Science, Zhengzhou University of Light Industry, Zhengzhou, 450000, China; College of Computer, University of Finance and Economics, Urumqi, 830012, China; School of Foreign Languages, the Renmin University of China, Beijing, 100080, China; Medical department, Henan university of traditional Chinese medicine, Zhengzhou, 450000, China},
	abstract = {Most of research on the identification of offensive speech on social media platforms exist in English and other rich languages. A series of recently proposed methods for detecting low-resource offensive languages require labeled data. In this work, we propose an unsupervised model that can detect offensive speech for low-resource languages. Our method does not depend on any labeled data of low-resource languages. In detail, we propose an agreement regularized training that combines adversarial learning and transfer learning. Augmenting low-resource training data with sample regeneration methods to maintain the performance of the trained offensive speech identification model from rich-resource to low-resource languages. Extensive experiments on four low-resource languages demonstrate that our model either is on par or outperforms the supervised methods, without employing any annotated data on real-world offensive speech detection tasks for low-resource languages. © 2022 Elsevier Ltd},
	author_keywords = {Adversarial learning; Cross-lingual; Low-resource languages; Offensive speech; Transfer learning},
	keywords = {Speech recognition; Adversarial learning; Cross-lingual; Labeled data; Low resource languages; Offensive languages; Offensive speech; Social media platforms; Speech identification; Training data; Transfer learning; Speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Singh2022513,
	author = {Singh, Neeraj Kumar and Garain, Utpal},
	title = {An Analysis of Transformer-based Models for Code-mixed Conversational Hate-speech Identification},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {513 – 521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146656020&partnerID=40&md5=e8f2105830677ab9c541d57ac3dd9fa7},
	affiliations = {Indian Statistical Institute, ISI, Kolkata, India},
	abstract = {The current surge in social media usage has resulted in the widespread availability of harmful and hateful content. Such inflammatory content identification in social media is a crucial NLP problem. Recent research has repeatedly demonstrated that context-level semantics matter more than word-level semantics for assessing the existence of hate content. This paper investigates many state-of-the-art transformer-based models for hate content detection in code-mixed datasets. We emphasize transformer-based models since they capture context-level semantics. In particular, we concentrate on Google-MuRIL, XLM-Roberta-base, and Indic-BERT. Additionally, we have experimented with an ensemble of the three mentioned models. Based on substantial empirical evidence, we observe that Google-MuRIL emerges as the top model with macro F1-scores of 0.708 and 0.445 for HASOC shared tasks 1 and 2, placing us 1st and 6tℎ on the overall leaderboard standings respectively. © 2022 Copyright for this paper by its authors.},
	author_keywords = {BERT; Codemixed Language; HateSpeech; Hinglish; Offensive Tweets},
	keywords = {Codes (symbols); Social networking (online); BERT; Codemixed language; Current surges; Google+; Hatespeech; Hinglish; Media usage; Offensive tweet; Social media; Speech identification; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Salomon2022208,
	author = {Salomon, Pale Ollo and Kechaou, Zied and Wali, Ali},
	title = {Arabic hate speech detection system based on AraBERT},
	year = {2022},
	journal = {Proceedings of 2022 IEEE 21st International Conference on Cognitive Informatics and Cognitive Computing, ICCI*CC 2022},
	pages = {208 – 213},
	doi = {10.1109/ICCICC57084.2022.10101577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158862596&doi=10.1109%2fICCICC57084.2022.10101577&partnerID=40&md5=b67b56b51714e645f313705cff924c58},
	affiliations = {Higher Institute of Computer, Science and Multimedia of Sfax, sfax, Tunisia; REGIM-lab: Research Groups on Intelligent Machines Universty of Sfax, National Engineering School of Sfax (ENIS), sfax, Tunisia},
	abstract = {Tunisia has entered a phase freedom of speech with access to social media since the Jasmine Revolution in 2011. Toxic contents such as abusive and hateful speeches have become omnipresent on Tunisian social media. Considering the side effects of these toxic contents on the psychology of users, it is necessary to detect them automatically. The dialect of Tunisian is underrepresented. As a consequence, there is not enough data set. In this paper, we present the data collection process with the aim of having a Tunisian reference dataset, to evaluate different models of hate speech and abuse detection. We also present our neural network model based on AraBERT. Our experimental results on our dataset shows that the AraBERT model performs better with an F1 score of 0.99.  © 2022 IEEE.},
	author_keywords = {Arabert; Hate speech; Social media; Tunisian dialect},
	keywords = {Neural network models; Speech recognition; Arabert; Data set; Detection system; Freedom of speech; Hate speech; Side effect; Social media; Speech detection; Tunisia; Tunisian dialect; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 21st IEEE International Conference on Cognitive Informatics and Cognitive Computing, ICCI*CC 2022; Conference date: 8 December 2022 through 10 December 2022; Conference code: 188113}
}

@CONFERENCE{Röttger20225674,
	author = {Röttger, Paul and Nozza, Debora and Bianchi, Federico and Hovy, Dirk},
	title = {Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages},
	year = {2022},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {5674 – 5691},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149439596&partnerID=40&md5=96ab66c59f3a559d84fa50c895818302},
	affiliations = {University of Oxford, United Kingdom; Bocconi University, Italy; Stanford University, United States},
	abstract = {Hate speech is a global phenomenon, but most hate speech datasets so far focus on English-language content. This hinders the development of more effective hate speech detection models in hundreds of languages spoken by billions across the world. More data is needed, but annotating hateful content is expensive, time-consuming and potentially harmful to annotators. To mitigate these issues, we explore data-efficient strategies for expanding hate speech detection into under-resourced languages. In a series of experiments with mono- and multilingual models across five non-English languages, we find that 1) a small amount of target-language fine-tuning data is needed to achieve strong performance, 2) the benefits of using more such data decrease exponentially, and 3) initial fine-tuning on readily-available English data can partially substitute target-language data and improve model generalisability. Based on these findings, we formulate actionable recommendations for hate speech detection in low-resource language settings. Content warning: This article contains illustrative examples of hateful language. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Detection models; Efficient strategy; English languages; Fine tuning; Language content; Non-English languages; Performance; Speech detection; Target language; Under-resourced languages; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895}
}

@CONFERENCE{Kumar2022171,
	author = {Kumar, Sanjay and Nagar, Abhishek and Kumar, Akash and Singh, Amar},
	title = {Hate Speech Detection:A Survey},
	year = {2022},
	journal = {Proceedings - 2022 4th International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2022},
	pages = {171 – 176},
	doi = {10.1109/ICAC3N56670.2022.10074044},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152188425&doi=10.1109%2fICAC3N56670.2022.10074044&partnerID=40&md5=6c326974cd4b0514a0ff46f3278d7343},
	affiliations = {Delhi Technological University, Dept. of Computer Science & Engineering, New Delhi, India},
	abstract = {Social media has been continuously acting as a medium for people to share and convey their emotions and information. At the same time, it has been observed that people utilize social media platforms like Facebook, Twitter, etc. to post offensive and hateful content. This happens on a large scale which makes it extremely challenging to monitor them manually, paving way for automation in hate speech. This survey paper explores, summarises, and compares various methods that target hate speech detection, how they are being utilized at solving past challenges, and dive into the current and future prospects for hate speech detection. © 2022 IEEE.},
	author_keywords = {Deep Learning text classification; Hate speech review; Machine learning classifier},
	keywords = {Deep learning; Learning systems; Social networking (online); Speech recognition; Text processing; Deep learning text classification; Hate speech review; Learning classifiers; Learning text; Machine learning classifier; Machine-learning; Social media; Social media platforms; Speech detection; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 4th International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2022; Conference date: 16 December 2022 through 17 December 2022; Conference code: 187556}
}

@ARTICLE{Hussain2022,
	author = {Hussain, Sajid and Malik, Muhammad Shahid Iqbal and Masood, Nayyer},
	title = {Identification of offensive language in Urdu using semantic and embedding models},
	year = {2022},
	journal = {PeerJ Computer Science},
	volume = {8},
	doi = {10.7717/PEERJ-CS.1169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147797771&doi=10.7717%2fPEERJ-CS.1169&partnerID=40&md5=cc66679171a46497f5fed925342fc510},
	affiliations = {Department of Computer Science, Capital university of Science and Technology, Islamabad, Pakistan},
	abstract = {Automatic identification of offensive/abusive language is very necessary to get rid of unwanted behavior. However, it is more challenging to generalize the solution due to the different grammatical structures and vocabulary of each language. Most of the prior work targeted western languages, however, one study targeted a low-resource language (Urdu). The prior study used basic linguistic features and a small dataset. This study designed a new dataset (collected from popular Pakistani Facebook pages) containing 7,500 posts for offensive language detection in Urdu. The proposed methodology used four types of feature engineering models: three are frequency-based and the fourth one is the embedding model. Frequency-based are either determined by the term frequency-inverse document frequency (TF-IDF) or bag-of-words or word n-gram feature vectors. The fourth is generated by the word2vec model, trained on the Urdu embeddings using a corpus of 196,226 Facebook posts. The experiments demonstrate that the stacking-based ensemble model with word2vec shows the best performance as a standalone model by achieving 88.27% accuracy. In addition, the wrapper-based feature selection method further improves performance. The hybrid combination of TF-IDF, bag-of-words, and word2vec feature models achieved 90% accuracy and 97% AUC. In addition, it outperformed the baseline with an improvement of 3.55% in accuracy, 3.68% in the recall, 3.60% in f1-measure, 3.67% in precision, and 2.71% in AUC. The findings of this research provide practical implications for commercial applications and future research. © 2022 Hussain et al.},
	author_keywords = {Emebedding model; Identification; Natural language processing; Offensive langauge; Semantic; TF-IDF; Urdu; word2vec},
	keywords = {Automation; Information retrieval; Inverse problems; Natural language processing systems; Semantics; Social networking (online); Text processing; Embeddings; Emebedding model; Identification; Language processing; Natural language processing; Natural languages; Offensive langauge; Term frequencyinverse document frequency (TF-IDF); Urdu; Word2vec; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Kankevičiūtė2022117,
	author = {Kankevičiūtė, Eglė and Songailaitė, Milita and Mandravickaitė, Justina and Kalinauskaitė, Danguolė and Krilavičius, Tomas},
	title = {A comparison of deep learning models for hate speech detection},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3611},
	pages = {117 – 123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182272226&partnerID=40&md5=e973d99e3c2dc8a29da34c2b3c644065},
	affiliations = {Vytautas Magnus University, Faculty of Informatics, Vileikos street 8, Kaunas, LT-44404, Lithuania; Centre for Applied Research and Development, Lithuania},
	abstract = {Hate speech is a complex and non-trivial phenomenon that is difficult to detect. Existing datasets used for training hate speech detection models are annotated based on different definitions of this phenomenon, and similar instances can be assigned to different annotation categories based on these differences. The goal of our experiment is to evaluate selected hate speech detection models for English language from the perspective of inter-annotator agreement, i.e. how the selected models “agree” in terms of annotation of hate speech instances. For model comparison we used English dataset from HASOC 2019 shared task and 3 models: BERT-HateXplain, HateBERT and BERT. Inter-annotator agreement was measured with pairwise Cohen’s kappa and Fleiss’ kappa. Accuracy was used as additional metric for control. The experiment results showed that even if the accuracy is high, the reliability, measured via inter-annotator agreement, can be low. We found that the best accuracy in hate speech detection was achieved with BERT-HateXplain model, however, Cohen’s kappa metric for the results of this model was close to 0, meaning that the results were random and not reliable for real life use. On the other hand, comparison of BERT and HateBERT models revealed that annotations are quite similar and they have the best Cohen’s kappa score, suggesting that similar neural network architectures can deliver not only high accuracy, but also correlating results and reliability. As for Fleiss’ kappa, a comparison of expert annotations and three selected models gave an estimate of a slight agreement, confirming that high accuracy can go together with low reliability of the model. © 2022 Copyright for this paper by its authors.},
	author_keywords = {deep learning; English language; HASOC 2019 dataset; Hate speech; model comparison},
	keywords = {Deep learning; Learning systems; Network architecture; Neural networks; Speech recognition; Deep learning; Detection models; English languages; Fleiss' kappas; HASOC 2019 dataset; Hate speech; High-accuracy; Learning models; Models comparisons; Speech detection; Reliability},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 27th International Conference on Information Society and University Studies, IVUS 2022; Conference date: 12 May 2022; Conference code: 196167}
}

@CONFERENCE{Breitwieser2022126,
	author = {Breitwieser, Kim},
	title = {Can Contextualizing User Embeddings Improve Sarcasm and Hate Speech Detection?},
	year = {2022},
	journal = {NLPCSS 2022 - 5th Workshop on Natural Language Processing and Computational Social Science ,NLP+CSS, Held at the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {126 – 139},
	doi = {10.18653/v1/2022.nlpcss-1.14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154598134&doi=10.18653%2fv1%2f2022.nlpcss-1.14&partnerID=40&md5=feb141b8807a60a35913827cc1f574a8},
	affiliations = {MaibornWolff GmbH, Germany},
	abstract = {While implicit embeddings so far have been mostly concerned with creating an overall representation of the user, we evaluate a different approach. By only considering content directed at a specific topic, we create sub-user embeddings, and measure their usefulness on the tasks of sarcasm and hate speech detection. In doing so, we show that task-related topics can have a noticeable effect on model performance, especially when dealing with intended expressions like sarcasm, but less so for hate speech, which is usually labelled as such on the receiving end. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Embeddings; Modeling performance; Speech detection; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th Workshop on Natural Language Processing and Computational Social Science, NLPCSS 2022, Held at the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 November 2022; Conference code: 187861; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ahmed2022170,
	author = {Ahmed, Ibrahim and Abbas, Mostafa and Hatem, Rany and Ihab, Andrew and Fahkr, Mohamed Waleed},
	title = {Fine-Tuning Arabic Pre-Trained Transformer Models for Egyptian-Arabic Dialect Offensive Language and Hate Speech Detection and Classification},
	year = {2022},
	journal = {Proceedings of the 20th Conference on Language Engineering, ESOLEC 2022},
	pages = {170 – 174},
	doi = {10.1109/ESOLEC54569.2022.10009167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147256712&doi=10.1109%2fESOLEC54569.2022.10009167&partnerID=40&md5=f002e8258b05dd8a703131e1e9e823f8},
	affiliations = {Arab Academy for Science, Dept of Computer Engineering, Technology and Maritime Transport, Cairo, Egypt},
	abstract = {Offensive language and Hate Speech are rampant on social media platforms (Facebook, Twitter, etc.) in Egypt for quite a while now, appearing in Tweets, Facebook posts and comments, etc., It is an increasingly outreaching problem that needs immediate attention. This paper focuses on the problem of detecting and classifying both offensive language and Hate Speech using State-of-The-Art techniques in text classification. Pre-Trained transformer models have gained a reputation of astounding general language underst and ing that could be fine-Tuned for language-specific tasks like Text classification, We collected an Egyptian-Arabic dialect Custom dataset of about 8,000 text samples manually labelled into 5 distinct classes: (Neutral, Offensive, Sexism, Religious Discrimination, Racism), It was used to fine-Tune and evaluate multiple different Arabic pre-Trained transformer models based on different transformer architectures and pre-Training approaches for the Natural Language Processing downstream task of text classification. We achieved an average accuracy of about 96% across all fine-Tuned transformer models.  © 2022 IEEE.},
	author_keywords = {Arabic Hate Speech; Natural Language Processing; Text Classification; Transformers},
	keywords = {Natural language processing systems; Social networking (online); Speech recognition; Text processing; Arabic dialects; Arabic hate speech; Egyptians; Language processing; Natural language processing; Natural languages; Offensive languages; Text classification; Transformer; Transformer modeling; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 20th International Conference on Language Engineering, ESOLEC 2022; Conference date: 12 October 2022 through 13 October 2022; Conference code: 186070}
}

@ARTICLE{Eronen2022,
	author = {Eronen, Juuso and Ptaszynski, Michal and Masui, Fumito and Arata, Masaki and Leliwa, Gniewosz and Wroczynski, Michal},
	title = {Transfer language selection for zero-shot cross-lingual abusive language detection},
	year = {2022},
	journal = {Information Processing and Management},
	volume = {59},
	number = {4},
	doi = {10.1016/j.ipm.2022.102981},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131220483&doi=10.1016%2fj.ipm.2022.102981&partnerID=40&md5=33eb830578ed4e085932fa1f93fb94c9},
	affiliations = {Kitami Institute of Technology, 165, Koencho, Kitami, 090-0015, Hokkaido, Japan; Samurai Labs, Aleja Zwyciȩstwa 96/98, Gdynia, 81-451, Poland},
	abstract = {We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance between the languages using several language similarity measures, especially by quantifying the World Atlas of Language Structures. We show that there is a correlation between linguistic similarity and classifier performance. This discovery allows us to choose an optimal transfer language for zero shot abusive language detection. © 2022 Elsevier Ltd},
	author_keywords = {Abusive language detection; Linguistics; Transfer learning; Zero-shot learning},
	keywords = {Abusive language detection; Cross-lingual; Detection system; Language detection; Language structure; Linguistic similarities; Low resource languages; Similarity measure; Transfer learning; Zero-shot learning; Linguistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Okpala20221606,
	author = {Okpala, Ebuka and Cheng, Long and Mbwambo, Nicodemus and Luo, Feng},
	title = {AAEBERT: Debiasing BERT-based Hate Speech Detection Models via Adversarial Learning},
	year = {2022},
	journal = {Proceedings - 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022},
	pages = {1606 – 1612},
	doi = {10.1109/ICMLA55696.2022.00053},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152214978&doi=10.1109%2fICMLA55696.2022.00053&partnerID=40&md5=72fb407a512520aee2358ca055173d45},
	affiliations = {Clemson University, School of Computing, Clemson, United States},
	abstract = {Hate speech datasets contain bias which machine learning models propagate. When these models classify tweets written in African American English (AAE), they predict AAE tweets as hate/abusive at a higher rate than tweets written in Standard American English (SAE). This paper assesses bias in language models fine-tuned for hate speech detection and the effectiveness of adversarial learning in reducing such bias. We introduce AAEBERT, a pre-trained language model for African American English obtained by re-training BERT-base on AAE tweets. AAEBERT is used to extract the representation of each tweet in the various hate speech datasets and to classify tweets into two classes - AAE dialect and non-AAE dialect. A three-layer feedforward neural network that takes the representation from AAEBERT and a dialect label as input is used as the adversarial network for debiasing. We evaluate bias in language models fine-tuned for hate speech detection. Then assess the effectiveness of adversarial debiasing in these models by comparing results before and after adversarial debiasing is applied. Analysis reveals that the fine-tuned models are biased towards AAE, and adversarial debiasing is effective in reducing bias.  © 2022 IEEE.},
	author_keywords = {adversarial learning; BERT; hate speech detection; language model},
	keywords = {Classification (of information); Computational linguistics; Learning systems; Multilayer neural networks; Network layers; Adversarial learning; African American; American English; BERT; De-biasing; Detection models; Hate speech detection; Language model; Machine learning models; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022; Conference date: 12 December 2022 through 14 December 2022; Conference code: 187486}
}

@CONFERENCE{Ripoll2022552,
	author = {Ripoll, Maria Luisa and Hassan, Fadi and Attieh, Joseph and Collell, Guillem and Bouchekif, Abdessalam},
	title = {Multi-Lingual Contextual Hate Speech Detection Using Transformer-Based Ensembles},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {552 – 562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146732847&partnerID=40&md5=a4915afbef221243ea574d414a98169f},
	affiliations = {Huawei Technologies Oy., Finland},
	abstract = {We present three different transformer-based approaches to contextual hate speech detection, submitted respectively to the three tasks of the HASOC 2022 competition [1]. To deal with the scarce dataset we use an ensemble of cross-validation trained models (CV ensemble) that makes use of all available data while still having validation sets to apply early stopping. We try different methods such as ensemble of ensembles, cross validation trained ensembles and embedding isotropy optimization. Furthermore, we compare different base models for the ensembles as well as different solution proposals to the tasks. Our team, hate-busters, ranked 3rd in task 1, 5th in task 2, 3rd in task 3A, 1st in task 3B and 4th in task 3C. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Ensemble; HASOC 2022; Hate Speech; Multi-Lingual NLP},
	keywords = {Linguistics; Cross validation; Early stopping; Embeddings; Ensemble; HASOC 2022; Hate speech; Multi-lingual NLP; Optimisations; Speech detection; Validation sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Li20221477,
	author = {Li, Xiang and Zeng, Zhi and Wu, Mingmin and Huang, Zhongqiang and Sha, Ying and Shi, Lei},
	title = {An Offensive Language Identification Based on Deep Semantic Feature Fusion},
	year = {2022},
	journal = {2022 IEEE 8th International Conference on Computer and Communications, ICCC 2022},
	pages = {1477 – 1483},
	doi = {10.1109/ICCC56324.2022.10066011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151706770&doi=10.1109%2fICCC56324.2022.10066011&partnerID=40&md5=546ea03ae6536c347c34203427bc4ce3},
	affiliations = {College of Informatics, Huazhong Agricultural University, Wuhan, China; Key Laboratory of Smart Farming for Agricultural Animals, Wuhan, China; Hubei Engineering Technology Research Center of Agricultural Big Data, Wuhan, China; Engineering Research Center of Intelligent Technology for Agriculture, Ministry of Education, China},
	abstract = {Various forms of social interactions are often char-acterized by toxic or offensive words that can be collectively referred to as offensive languages, which has become a unique linguistic phenomenon in social media platforms. How to detect and identify these offensive languages in social media platforms has become one of the important research in the field of natural language processing. Existing methods utilize machine learning algorithms or text representation models based on deep learning to learn the features of offensive languages and identify them, which have achieved good performances. However, traditional machine learning-based methods mainly rely on keyword identi-fication and blocking, deep learning-based methods do not ade-quately explore the fused deep semantic features of the content by combining word-level embeddings and sentence-level deep semantic feature representations of sentences, which cannot ef-fectively identify offensive languages that do not contain common offensive words but indicate offensive meanings. In this research, we propose a novel offensive language identification model based on deep semantic feature fusion, which uses the pre-trained model Bert to obtain word-level embedding representations of offensive languages, and then integrates the RCNN that combines with the attention mechanism to extract the fused deep semantic feature representations of offensive languages, and label encoder and offensive predictor to improve the identification accuracy and generalization ability of the model so that the performances of the model do not rely on the offensive language lexicon entirely and can identify offensive languages that do not contain common offensive words but indicate offensive meanings. Experimental results on Wikipedia and Twitter comment datasets show that our proposed model can better understand the context and discover potential offensive meanings, and outperforms existing methods.  © 2022 IEEE.},
	author_keywords = {attention mechanism; deep semantic feature; label encoder; offensive language identification},
	keywords = {Deep learning; Natural language processing systems; Semantics; Signal encoding; Social networking (online); Attention mechanisms; Deep semantic feature; Features fusions; Label encoder; Language identification; Model-based OPC; Offensive language identification; Offensive languages; Semantic features; Social media platforms; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 8th IEEE International Conference on Computer and Communications, ICCC 2022; Conference date: 9 December 2022 through 12 December 2022; Conference code: 187407}
}

@CONFERENCE{Manikandan2022106,
	author = {Manikandan, Deepalakshmi and Subramanian, Malliga and ShanmugaVadivel, Kogilavani},
	title = {A SYSTEM FOR DETECTING ABUSIVE CONTENTS AGAINST LGBT COMMUNITY USING DEEP LEARNING BASED TRANSFORMER MODELS},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {106 – 116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146639425&partnerID=40&md5=92e5f9802a065009128556456f8c30e9},
	affiliations = {Department of Computer Science and Engineering, Kongu Engineering College, Tamil Nadu, Erode, India},
	abstract = {The dissemination of harmful and unfriendly content has exponentially increased in the modern world as a result of social media. Many in the community of natural language processing have recently become interested in hate speech, inciting language, and abusive language. In this article, we suggest using transformer-based model methodologies like BERT and XLMROBERTa models to identify Non-Anti LGBT content (NALC), transphobic and homophobic insults directed at transgender people. In this work, English language dataset with 990 comments is tested without label. Based on the experimental results, the XLM-RoBERTa achieved superior results with respect to the precision, recall and f-measure than BERT model. Also, with respect to the accuracy the BERT gives 91% and XLM-RoBERTa gives 93%. With an accuracy of 93% in the XLMROBERTa exceeds the BERT model. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Abusive language; BERT; Hate Speech; Transformer; XLMROBERTa},
	keywords = {Learning algorithms; Natural language processing systems; Abusive language; BERT; Hate speech; Language processing; Modeling methodology; Natural languages; Social media; Transformer; Transformer modeling; XLMROBERTa; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Assem202219,
	author = {Assem, Samar and Alansary, Sameh},
	title = {Sentiment Analysis from Subjectivity to (Im)Politeness Detection: Hate Speech from a Socio-Pragmatic Perspective},
	year = {2022},
	journal = {Proceedings of the 20th Conference on Language Engineering, ESOLEC 2022},
	pages = {19 – 23},
	doi = {10.1109/ESOLEC54569.2022.10009298},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147248682&doi=10.1109%2fESOLEC54569.2022.10009298&partnerID=40&md5=53a3dccfabcb1adc5213cc7cb3173846},
	affiliations = {Alexandria University, Faculty of Arts, Alexandria, Egypt},
	abstract = {Although sentiment analysis by definition is that field of Natural Language processing which focuses on analyzing texts that tackle evaluating, analyzing and detecting the state of mind of the human beings towards a range of domains, most of the studies limit it to opinion mining. Yet, opinion mining is just one sub-field of three others under the umbrella of sentiment analysis which are; opinion mining, emotion mining and ambiguity detection. Noticeably, ambiguity detection is considered to be a combination of the other two sub-fields thanks to its linguistic nature that considers statistical and /or syntactic-semantic levels of analysis are not adequate to reach a satisfying level of disambiguating human language. Henceforth, the current paper proposes digging deeply to reach pragmatic and socio-pragmatic levels of analysis in order to eliminate ambiguity and avoid misjudgments over texts and social media posts specifically in the sub-Tasks of detecting hate speech. Accordingly, it suggests utilizing an eclectic linguistic model of analysis includes speech act theory and the theory of (im)politeness.  © 2022 IEEE.},
	author_keywords = {(im)politeness; Hate Speech; Sentiment Analysis; Socio-Pragmatic},
	keywords = {Data mining; Semantics; (im)politeness; Hate speech; Human being; Language processing; Levels of analysis; Natural languages; Opinion mining; Sentiment analysis; Socio-pragmatic; Sub fields; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 20th International Conference on Language Engineering, ESOLEC 2022; Conference date: 12 October 2022 through 13 October 2022; Conference code: 186070}
}

@ARTICLE{Aljuhani2022394,
	author = {Aljuhani, Khulood O. and Alyoubi, Khaled H. and Alotaibi, Fahd S.},
	title = {Detecting Arabic Offensive Language in Microblogs Using Domain-Specific Word Embeddings and Deep Learning},
	year = {2022},
	journal = {Tehnicki Glasnik},
	volume = {16},
	number = {3},
	pages = {394 – 400},
	doi = {10.31803/tg-20220305120018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147522633&doi=10.31803%2ftg-20220305120018&partnerID=40&md5=7e807447df96ab96202a668ee65fe35d},
	affiliations = {Information Systems Department, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia},
	abstract = {In recent years, social media networks are emerging as a key player by providing platforms for opinions expression, communication, and content distribution. However, users often take advantage of perceived anonymity on social media platforms to share offensive or hateful content. Thus, offensive language has grown as a significant issue with the increase in online communication and the popularity of social media platforms. This problem has attracted significant attention for devising methods for detecting offensive content and preventing its spread on online social networks. Therefore, this paper aims to develop an effective Arabic offensive language detection model by employing deep learning and semantic and contextual features. This paper proposes a deep learning approach that utilizes the bidirectional long short-term memory (BiLSTM) model and domain-specific word embeddings extracted from an Arabic offensive dataset. The detection approach was evaluated on an Arabic dataset collected from Twitter. The results showed the highest performance accuracy of 0.93% with the BiLSTM model trained using a combination of domain-specific and agnostic-domain word embeddings. © 2023 Tehnicki Glasnik. All rights reserved.},
	author_keywords = {Arabic Natural Language Processing; Arabic Tweets; Offensive Language; Offensive Language Detection; Word Embeddings},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Gamage202245,
	author = {Gamage, Kavishka and Welgama, Viraj and Weerasinghe, Ruvan},
	title = {Improving Sinhala Hate Speech Detection Using Deep Learning},
	year = {2022},
	journal = {22nd International Conference on Advances in ICT for Emerging Regions, ICTer 2022},
	pages = {45 – 50},
	doi = {10.1109/ICTer58063.2022.10024103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147854843&doi=10.1109%2fICTer58063.2022.10024103&partnerID=40&md5=87b5c605b05594ac09844453a4c1187b},
	affiliations = {University of Colombo, School of Computing, 35, Reid Avenue, Colombo, 00700, Sri Lanka},
	abstract = {Automatic Hate Speech Detection is a fine-grained sentiment analysis task that has been the focus of many researchers around the world. This has been a difficult task due to challenges such as the usage of native languages and distinct vocabularies, as well as the distortion of words. However, based on the findings of previous studies on Sinhala hate speech identification, this has proven to be more difficult for low-resource languages like Sinhala. The effectiveness of pretrained embedding for Sinhala hate speech detection has not been investigated. We investigated several embeddings as well as frequency-based features, including bag of words, n-grams, and TF-IDF to address this shortcoming. We present results from several machine learning experiments, including deep learning experiments and transfer learning experiments on state-of-the-art cross-lingual transformers. With an f1-score of 0.764 and a recall value of 0.788 in our study, the XLMR model outperformed other baseline algorithms and deep learning models.  © 2022 IEEE.},
	author_keywords = {Deep learning; Hate speech; Sinhala language; Supervised Learning; Word embedding},
	keywords = {Deep learning; Sentiment analysis; Speech recognition; Deep learning; Embeddings; Fine grained; Hate speech; Native language; Sentiment analysis; Sinhalum language; Speech detection; Speech identification; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 22nd International Conference on Advances in ICT for Emerging Regions, ICTer 2022; Conference date: 30 November 2022 through 1 December 2022; Conference code: 186255}
}

@ARTICLE{Madukwe20221129,
	author = {Madukwe, Kosisochukwu Judith and Gao, Xiaoying and Xue, Bing},
	title = {Token replacement-based data augmentation methods for hate speech detection},
	year = {2022},
	journal = {World Wide Web},
	volume = {25},
	number = {3},
	pages = {1129 – 1150},
	doi = {10.1007/s11280-022-01025-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125453583&doi=10.1007%2fs11280-022-01025-2&partnerID=40&md5=8f930f9a51fcba84d78287fd794124b8},
	affiliations = {School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington, 6012, New Zealand},
	abstract = {Hate speech detection mostly involves the use of text data. This data, usually sourced from various social media platforms, have been known to be plagued with numerous issues that result in a reduction of its quality and hence, the quality of the trained models. Some of these issues are the lack of diversity and the diminutive class of interest in the dataset which results in overfitted models that do not generalize well on other or newly collected data. The different ways of handling these issues include augmenting the data with diverse samples, engineering non-redundant features or designing robust classification models. In this study, the focus is on the data augmentation aspect. Data augmentation is a popular method for improving the quality of existing datasets by generating synthetic samples that mimic the distribution of the original samples. There is a lack of extensive studies on how hate speech texts respond to varying textual data augmentation techniques and methods. Specifically, we provide further insight into the token replacement method of textual data augmentation by performing empirical studies that investigate which embedding method(s) is a robust source of synonym for replacement process, what effective method(s) can be used to select words to be replaced, and how to confirm if the label within each class is preserved. Our proposed methods, validated on two commonly used hate speech datasets affected by a known lack of diversity and diminutive class of interest issues, significantly improve classification performance and provides insights into token replacement methods. © 2022, The Author(s).},
	author_keywords = {Data augmentation; Data generation; Hate speech data; Text data; Token substitution; Word replacement},
	keywords = {Classification (of information); Speech; Augmentation methods; Data augmentation; Data generation; Hate speech data; Speech data; Speech detection; Text data; Textual data; Token substitution; Word replacement; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kalra2022596,
	author = {Kalra, Sakshi and Maheshwari, Kushank and Goel, Saransh and Sharma, Yashvardhan},
	title = {Hate Speech Detection in Marathi and Code-Mixed Languages using TF-IDF and Transformers-Based BERT-Variants},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {596 – 610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160805047&partnerID=40&md5=aeeb6ee184fd605ad1f73797c27b0525},
	affiliations = {Department of CSIS, BITS Pilani, Rajasthan, 333031, India},
	abstract = {People now express their ideas on social media on a global scale. Online attacks against others can be made without fear of repercussions due to the increased sense of freedom provided by the anonymity feature, which eventually leads to the spread of hate speech. The current attempts to filter online information and stop the propagation of hatred are insufficient. Regional languages’ popularity on social media and the lack of hate speech detectors that can be used in multiple languages are two aspects that contribute to this. This paper discusses two aspects of fake news detection namely: Identification of Conversational Hate-Speech in Code-Mixed Languages like Hindi, English and German, while second part discusses about Offensive Language Identification in Marathi. Our approach uses TF-IDF word embedding combined with Machine Learning models and transformer based BERT models for the classification of hate speech in each of the two sub tasks. The MuRIL-BERT model produces the best results, with an accuracy of 73.1% and a Macro-F1 score of 0.727 for the code-mixed language and a macro F1-score of 0.8306 on Marathi data, which is 6% more from previous year. © 2022 Copyright for this paper by its authors.},
	author_keywords = {BERT; Code Mixed; Cyber hate; Distil-BERT; HASOC; Machine Learning; Multilingual BERT; MuRIL; Social Media; Text Classification; TF-IDF; Tokenizer; Transformers model},
	keywords = {Classification (of information); Codes (symbols); Fake detection; Natural language processing systems; Social networking (online); Speech recognition; Text processing; BERT; Code mixed; Cybe hate; Distill-BERT; HASOC; Machine-learning; Multilingual BERT; MuRIL; Social media; Text classification; TF-IDF; Tokenizer; Transformer modeling; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Elsafoury202231,
	author = {Elsafoury, Fatma},
	title = {Darkness can not drive out darkness: Investigating Bias in Hate Speech Detection Models},
	year = {2022},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {31 – 43},
	doi = {10.18653/v1/2022.acl-srw.4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149111293&doi=10.18653%2fv1%2f2022.acl-srw.4&partnerID=40&md5=f3855eec7a1d78a8bcbe6d2eecdaf263},
	affiliations = {School of Physics, Engineering, and Computing, The University of The West of Scotland, United Kingdom},
	abstract = {It has become crucial to develop tools for automated hate speech and abuse detection. These tools would help to stop the bullies and the haters and provide a safer environment for individuals especially from marginalized groups to freely express themselves. However, recent research shows that machine learning models are biased and they might make the right decisions for the wrong reasons. In this thesis, I set out to understand the performance of hate speech and abuse detection models and the different biases that could influence them. I show that hate speech and abuse detection models are not only subject to social bias but also to other types of bias that have not been explored before. Finally, I investigate the causal effect of the social and intersectional bias on the performance and unfairness of hate speech detection models. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Detection models; Machine learning models; Performance; Recent researches; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181735; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Lin202231,
	author = {Lin, Jessica},
	title = {Leveraging World Knowledge in Implicit Hate Speech Detection},
	year = {2022},
	journal = {NLP4PI 2022 - 2nd Workshop on NLP for Positive Impact, Proceedings of the Workshop},
	pages = {31 – 39},
	doi = {10.18653/v1/2022.nlp4pi-1.4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154573426&doi=10.18653%2fv1%2f2022.nlp4pi-1.4&partnerID=40&md5=8e5a37dedf693e9602c7350929197939},
	affiliations = {Department of Linguistics, Georgetown University, United States},
	abstract = {Warning: This paper contains content that may be offensive or disturbing. While much attention has been paid to identifying explicit hate speech, implicit hateful expressions that are disguised in coded or indirect language are pervasive and remain a major challenge for existing hate speech detection systems. This paper presents the first attempt to apply Entity Linking (EL) techniques to both explicit and implicit hate speech detection, where we show that such real world knowledge about entity mentions in a text does help models better detect hate speech, and the benefit of adding it into the model is more pronounced when explicit entity triggers (e.g., rally, KKK) are present. We also discuss cases where real world knowledge does not add value to hate speech detection, which provides more insights into understanding and modeling the subtleties of hate speech. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge management; Detection system; HELP model; Real-world; Speech detection; World knowledge; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2nd Workshop on NLP for Positive Impact, NLP4PI 2022 held in conjunction with the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022; Conference code: 187860; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Caron2022788,
	author = {Caron, Matthew and Bäumer, Frederik S. and Müller, Oliver},
	title = {Towards Automated Moderation: Enabling Toxic Language Detection with Transfer Learning and Attention-Based Models},
	year = {2022},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2022-January},
	pages = {788 – 797},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152124028&partnerID=40&md5=62cc51ff9ab4ce8514b1b8ae1e0db9e3},
	affiliations = {Paderborn University, Germany; Bielefeld University of Applied Sciences, Germany},
	abstract = {Our world is more connected than ever before. Sadly, however, this highly connected world has made it easier to bully, insult, and propagate hate speech on the cyberspace. Even though researchers and companies alike have started investigating this real-world problem, the question remains as to why users are increasingly being exposed to hate and discrimination online. In fact, the noticeable and persistent increase in harmful language on social media platforms indicates that the situation is, actually, only getting worse. Hence, in this work, we show that contemporary ML methods can help tackle this challenge in an accurate and cost-effective manner. Our experiments demonstrate that a universal approach combining transfer learning methods and state-of-the-art Transformer architectures can trigger the efficient development of toxic language detection models. Consequently, with this universal approach, we provide platform providers with a simplistic approach capable of enabling the automated moderation of user-generated content, and as a result, hope to contribute to making the web a safer place. © 2022 IEEE Computer Society. All rights reserved.},
	keywords = {Learning systems; Transfer learning; Cost effective; Cyberspaces; Exposed to; Language detection; Real-world problem; Social media platforms; State of the art; Transfer learning; Transfer learning methods; Universal approach; Cost effectiveness},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 55th Annual Hawaii International Conference on System Sciences, HICSS 2022; Conference date: 3 January 2022 through 7 January 2022; Conference code: 187534}
}

@CONFERENCE{Bose20226656,
	author = {Bose, Tulika and Aletras, Nikolaos and Illina, Irina and Fohr, Dominique},
	title = {Domain Classification-based Source-specific Term Penalization for Domain Adaptation in Hate-speech Detection},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {1},
	pages = {6656 – 6666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165758374&partnerID=40&md5=06eee23aac26ffb31703f3abfaa23f6c},
	affiliations = {Universite de Lorraine, CNRS, Inria, LORIA, Nancy, F-54000, France; University of Sheffield, United Kingdom},
	abstract = {Warning: this paper contains content that may be offensive and distressing. State-of-the-art approaches for hate-speech detection usually exhibit poor performance in out-of-domain settings. This occurs, typically, due to classifiers overemphasizing source-specific information that negatively impacts its domain invariance. Prior work has attempted to penalize terms related to hate-speech from manually curated lists using feature attribution methods, which quantify the importance assigned to input terms by the classifier when making a prediction. We, instead, propose a domain adaptation approach that automatically extracts and penalizes source-specific terms using a domain classifier, which learns to differentiate between domains, and feature-attribution scores for hate-speech classes, yielding consistent improvements in cross-domain evaluation. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.},
	keywords = {Computational linguistics; Speech recognition; Cross-domain evaluations; Domain adaptation; Learn+; Penalisation; Poor performance; Specific information; Speech detection; State-of-the-art approach; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893}
}

@CONFERENCE{Munir2022,
	author = {Munir, Muhammad Sohail and Parveen, Kausar and Farooq, Umer and Shaalan, Khaled and Abualkishik, Abedallah Zaid and Mohammed, Abdul Salam},
	title = {Use of Different Machine Learning Algorithms for Hate Speech Detection},
	year = {2022},
	journal = {International Conference on Cyber Resilience, ICCR 2022},
	doi = {10.1109/ICCR56254.2022.9995800},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146493924&doi=10.1109%2fICCR56254.2022.9995800&partnerID=40&md5=b72a90abd8f5eb8b09dcd43ab219c18a},
	affiliations = {National College of Business Administration University, Computer Science Department, Lahore, Pakistan; Lahore Garrison University, Department of Computer Science, Lahore, Pakistan; Faculty of Engineering and It, The British University in Dubai, United Arab Emirates; American University in the Emirates (AUE), Department Chair of Information Technology Management, United Arab Emirates; Skyline University, Sharjah, United Arab Emirates},
	abstract = {With the speedy advancement of the web, a consistently expanding number of people that utilize online social media. Subsequently, hate speech becomes uncontrolled in social media, and it is critical to group the hate speech and control it before it spread. With the presentation and the advancement of deep learning, hate speech recognition becomes practice. Many examinations use information from social platforms, for example, Twitter and Facebook along with machine learning or deep learning advances to identify and perceive hate speech. In any case, there are insufficient surveys about this area. After studying various article's and research papers, no such review is available to see assortment of feature extraction/engineering methods (FEM) and ML-Algorithms that assess, which feature extraction/engineering procedure and ML-Algorithms can perform better on open source or openly accessible dataset. Thus, the purpose of this research paper is to look at 3-FET or strategies and 8-ML-Algorithums to assess their performance on an openly accessible dataset and this dataset has 3 classes. The research outcomes exhibited that SVM-Algorithm with BIGRAM features performed better with almost 80% accuracy. This research paper shows viable ramifications what's more, can be used as a gauge concentrate on to identifying hate speech communications/messages. Also, the result of various correlations will be utilized as condition of- workmanship strategies to look at future explores for existing mechanized text classification procedures. © 2022 IEEE.},
	author_keywords = {decision tree; deep learning; hate speech detection; logistic regression; natural language processing},
	keywords = {Classification (of information); Deep learning; Extraction; Feature extraction; Learning algorithms; Learning systems; Logistic regression; Natural language processing systems; Social networking (online); Speech recognition; Support vector machines; Text processing; Deep learning; Features extraction; Hate speech detection; Language processing; Logistics regressions; Machine learning algorithms; Natural language processing; Natural languages; Research papers; Speech detection; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 International Conference on Cyber Resilience, ICCR 2022; Conference date: 6 October 2022 through 7 October 2022; Conference code: 185824}
}

@CONFERENCE{Pamungkas2022,
	author = {Pamungkas, Endang Wahyu and Fatmawati, Azizah and Nugroho, Yusuf Sulistyo and Gunawan, Dedi and Sudarmilah, Endah},
	title = {Hate Speech Detection in Code-Mixed Indonesian Social Media: Exploiting Multilingual Languages Resources},
	year = {2022},
	journal = {2022 7th International Conference on Informatics and Computing, ICIC 2022},
	doi = {10.1109/ICIC56845.2022.10006940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146918800&doi=10.1109%2fICIC56845.2022.10006940&partnerID=40&md5=722e8b88941001261db0a8f1678ef79d},
	affiliations = {Universitas Muhammadiyah Surakarta, Informatics Department, Surakarta, Indonesia},
	abstract = {Hate speech in social media is becoming a relevant issue recently. Several studies have been proposed to deal with the hate speech phenomena in online communication. However, detecting hate speech messages from social media data is not a trivial task. Previous works have mentioned the problem of code-mixed languages in hate speech detection. As a matter of fact, Indonesia consists of several regions, each with its own local languages. Naturally, Indonesians tend to mix their own local language with Bahasa Indonesia when communicating in everyday conversation, including in social media communication, which contributes to the difficulty of processing Indonesian social media data. In this study, we plan to investigate hate speech detection in code-mixed Indonesian social media by exploiting several available multilingual language resources. Our experiment shows that the current available multilingual language model could not improve the model performance compared to the models which utilized the monolingual Indonesian language model. We also found that the most recent neural-based models are able to obtain better performance than the traditional model. For future work, we plan to implement a transfer learning approach to detect hate speech in Indonesian social media, specifically to deal with the code-mixed issue.  © 2022 IEEE.},
	author_keywords = {- abusive language detection; code-mixed; hate speech detection; social media},
	keywords = {Computational linguistics; Speech communication; Speech recognition; - abusive language detection; Code-mixed; Hate speech detection; Indonesia; Language detection; Language resources; Local language; Social media; Social media datum; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th International Conference on Informatics and Computing, ICIC 2022; Conference date: 8 December 2022 through 9 December 2022; Conference code: 185993}
}

@CONFERENCE{Kaati2022396,
	author = {Kaati, Lisa and Shrestha, Amendra and Akrami, Nazar},
	title = {A Machine Learning Approach to Identify Toxic Language in the Online Space},
	year = {2022},
	journal = {Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2022},
	pages = {396 – 402},
	doi = {10.1109/ASONAM55673.2022.10068619},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152023525&doi=10.1109%2fASONAM55673.2022.10068619&partnerID=40&md5=9aa947f0971dc648bc98ac3f8a63edc5},
	affiliations = {Stockholm University, Stockholm, Sweden; Mind Intelligence Lab, Uppsala, Sweden; Uppsala University, Uppsala, Sweden},
	abstract = {In this study, we trained three machine learning models to detect toxic language on social media. These models were trained using data from diverse sources to ensure that the models have a broad understanding of toxic language. Next, we evaluate the performance of our models on a dataset with samples of data from a large number of diverse online forums. The test dataset was annotated by three independent annotators. We also compared the performance of our models with Perspective API-a toxic language detection model created by Jigsaw and Google's Counter Abuse Technology team. The results showed that our classification models performed well on data from the domains they were trained on (Fl = 0.91, 0.91, & 0.84, for the RoBERTa, BERT, & SVM respectively), but the performance decreased when they were tested on annotated data from new domains (Fl = 0.80, 0.61, 0.49, & 0.77, for the RoBERTa, BERT, SVM, & Google perspective, respectively). Finally, we used the best-performing model on the test data (RoBERTa, ROC = 0.86) to examine the frequency (/proportion) of toxic language in 21 diverse forums. The results of these analyses showed that forums for general discussions with moderation (e.g., Alternate history) had much lower proportions of toxic language compared to those with minimal moderation (e.g., 8Kun). Although highlighting the complexity of detecting toxic language, our results show that model performance can be improved by using a diverse dataset when building new models. We conclude by discussing the implication of our findings and some directions for future research.  © 2022 IEEE.},
	keywords = {Classification (of information); E-learning; Large dataset; Learning systems; Social networking (online); Support vector machines; Classification models; Detection models; Google+; Language detection; Machine learning approaches; Machine learning models; Online forums; Performance; Social media; Test data; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2022; Conference date: 10 November 2022 through 13 November 2022; Conference code: 187484}
}

@CONFERENCE{Kim20226667,
	author = {Kim, Youngwook and Park, Shinwoo and Han, Yo-Sub},
	title = {Generalizable Implicit Hate Speech Detection using Contrastive Learning},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {1},
	pages = {6667 – 6679},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152002330&partnerID=40&md5=3ad584c381a70f4345b233cda03428f6},
	affiliations = {Department of Computer Science, Yonsei University, Seoul, South Korea; Department of Artificial Intelligence, Yonsei University, Seoul, South Korea},
	abstract = {Hate speech detection has gained increasing attention with the growing prevalence of hateful contents. When a text contains an obvious hate word or expression, it is fairly easy to detect it. However, it is challenging to identify implicit hate speech in nuance or context when there are insufficient lexical cues. Recently, there are several attempts to detect implicit hate speech leveraging pre-trained language models such as BERT and HateBERT. Fine-tuning on an implicit hate speech dataset shows satisfactory performance when evaluated on the test set of the dataset used for training. However, we empirically confirm that the performance drops at least 12.5%p in F1 score when tested on the dataset that is different from the one used for training. We tackle this cross-dataset underperforming problem using contrastive learning. Based on our observation of common underlying implications in various forms of hate posts, we propose a novel contrastive learning method, ImpCon, that pulls an implication and its corresponding posts close in representation space. We evaluate the effectiveness of ImpCon by running cross-dataset evaluation on three implicit hate speech benchmarks. The experimental results on cross-dataset show that ImpCon improves at most 9.10% on BERT, and 8.71% on HateBERT. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.},
	keywords = {Computational linguistics; Learning systems; Statistical tests; Cross-dataset evaluation; F1 scores; Fine tuning; Language model; Learning methods; Performance; Representation space; Speech detection; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893}
}

@CONFERENCE{Jain2022,
	author = {Jain, Archika and Sharma, Sandhya},
	title = {A Survey on Identification of Hate Speech on Social Media Post},
	year = {2022},
	journal = {ICAN 2022 - 3rd International Conference on Computing, Analytics and Networks - Proceedings},
	doi = {10.1109/ICAN56228.2022.10007283},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146959396&doi=10.1109%2fICAN56228.2022.10007283&partnerID=40&md5=58181f06ee78bc1f3dc5820aab029e5d},
	affiliations = {Suresh Gyan Vihar University, Department of Computer Engineering, Jaipur, India; Suresh Gyan Vihar University, Department of Electronics & Communication, Jaipur, India},
	abstract = {In the age of social media and mobile internet, the development of autonomous methods for online detection of hate speech or abusive language is vital for societal and community empowerment because social media is accessible worldwide via the internet. Anybody may simply attack someone or a group who adheres to a different culture or ideology on social media. While everyone has the freedom to express their own opinions, it should not be destructive, and everyone has the right to be free to say anything. To learn about hate speech, a review process include a large number of research articles which were published in the period of year 2017 to year 2022. After an exhaustive review process, we have found the common findings, strengths, weaknesses, gaps and solution approaches & their results.  © 2022 IEEE.},
	author_keywords = {and accuracy; hate speech; machine learning; social media; tweet dataset},
	keywords = {Social networking (online); Speech recognition; And accuracy; Community empowerments; Hate speech; Learn+; Machine-learning; Mobile Internet; On-line detection; Review process; Social media; Tweet dataset; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 3rd International Conference on Computing, Analytics and Networks, ICAN 2022; Conference date: 18 November 2022 through 19 November 2022; Conference code: 185995}
}

@CONFERENCE{Jiang20221271,
	author = {Jiang, Yushan and Zhou, Bin and Zhao, Xuechen and Zou, Jiaying and Xie, Feng and Li, Liang},
	title = {Domain-adaptive Graph based on Post-hoc Explanation for Cross-domain Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
	volume = {2022-October},
	pages = {1271 – 1276},
	doi = {10.1109/ICTAI56018.2022.00192},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156161575&doi=10.1109%2fICTAI56018.2022.00192&partnerID=40&md5=202bd35982ccc846ddf7c50bd3de4b89},
	affiliations = {School of Computer, National University of Defence Technology, Changsha, China; National University of Defence Technology, Key Lab. of Software Engineering for Complex Systems, Changsha, China},
	abstract = {Hate speech detection is hampered by the scarcity and topical and lexical biases of annotated data, leading to poor generalization. It is imperative to devise a cross-domain approach to solve this problem. The ability to learn transferable knowledge is critical for cross-domain hate speech detection. In this work, We propose a domain-adaptive dependency graph method based on post-hoc explanation (DPDG). We extract post-hoc explanations from fine-tuned BERT classifiers as the importance score for hate representation. Based on these, we construct in-domain graph and cross-domain graph to better learn in-domain hate representation and adapt to the target domain respectively. Finally, we use interactive GCN blocks to interactively and adaptively learn and adjust the domain adaptive graph representation. The results of cross-domain experiments on multiple domains show that our proposed model outperforms competitive baselines in cross-domain hate speech detection. © 2022 IEEE.},
	author_keywords = {cross-domain hate speech detection; graph neural network; natural language processing},
	keywords = {Graph neural networks; Natural language processing systems; Speech recognition; Cross-domain; Cross-domain hate speech detection; Graph neural networks; Graph-based; Language processing; Learn+; Lexical bias; Natural language processing; Natural languages; Speech detection; Graphic methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 34th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2022; Conference date: 31 October 2022 through 2 November 2022; Conference code: 188065}
}

@CONFERENCE{Al-Saqqa2022,
	author = {Al-Saqqa, Samar and Awajan, Arafat and Hammo, Bassam},
	title = {Performance Comparison of Word2Vec Models for Detecting Arabic Hate Speech on Social Networks},
	year = {2022},
	journal = {2022 International Conference on Emerging Trends in Computing and Engineering Applications, ETCEA 2022 - Proceedings},
	doi = {10.1109/ETCEA57049.2022.10009734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146926535&doi=10.1109%2fETCEA57049.2022.10009734&partnerID=40&md5=9d07f93d7d6180414f63c3aceb2a67b7},
	affiliations = {Princess Sumaya University for Technology, Department of Computer Science, Amman, Jordan; The University of Jordan, King Abdullah II School for IT, Department of Information Technology, Amman, Jordan; Mutha University, Department of Computer Science, Amman, Jordan; Princess Sumaya University for Technology, Department of Software Engineering, Amman, Jordan; The University of Jordan, King Abdullah II School for IT, Department of CIS, Amman, Jordan},
	abstract = {Detecting hate speech has become increasingly important for online communities. Despite emerging research to address the problem, more efforts are still needed to improve the performance of detection methods for the Arabic language. In this paper, we compare the performance of two Word2Vec models; the continuous bag of words (CBoW) and skip-gram using a dataset collected from multiple social media platforms; Facebook, Twitter, YouTube, and Instagram. We compared seven machine learning (ML) algorithms and measured their performance using different evaluation metrics. The CBoW model outperformed the skip-gram model in terms of accuracy. In addition, using a higher embedding dimensional value resulted in a better performance.  © 2022 IEEE.},
	author_keywords = {AraVec; CBOW; embedding; hate speech; Machine learning; Skip-Gram; Word2vec},
	keywords = {Embeddings; Information retrieval; Social networking (online); Aravec; CBOW; Embeddings; Hate speech; Machine-learning; On-line communities; Performance; Performance comparison; Skip-gram; Word2vec; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 International Conference on Emerging Trends in Computing and Engineering Applications, ETCEA 2022; Conference date: 23 November 2022 through 25 November 2022; Conference code: 186022}
}

@CONFERENCE{Mkhinini202269,
	author = {Mkhinini, Meriem Mejhed and Sidibe, Aboubacar Sidiki and Benali, Khaoula and Bentaarit, Nouha and Madji, Youcef and Khelifi, Aymen},
	title = {Violence Content Detection in Videos},
	year = {2022},
	journal = {Proceedings - 2022 International Conference on Intelligent Manufacturing and Industrial Big Data, ICIMIBD 2022},
	pages = {69 – 76},
	doi = {10.1109/ICIMIBD58123.2022.00024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178261937&doi=10.1109%2fICIMIBD58123.2022.00024&partnerID=40&md5=67956319d1128c66570514f70330ae74},
	affiliations = {Kaisens Data, Paris, France; National School of Comp. Sci, Tunis, Tunisia},
	abstract = {Social networks are not safe, because of the amount of violent content shared on these platforms. That's why, filtering such content using a violence detection system powered by Artificial Intelligence is necessary and has become a growing research domain. In this paper, we propose a deep-learning-based approach to address this issue. We use a two layered model: First, a deep representation-based model that uses transfer learning concept to recognize violent content in a video. Second a text classifier to detect verbal violence using the audio cue. The result reports show that our approach is outperforming state-of-the art accuracies by learning most discriminating features achieving 90% as accuracy on the test set for physical violence detection and 89% for verbal violence detection.  © 2022 IEEE.},
	author_keywords = {BERT; computer vision; convolutional neural networks (CNN); deep learning; gated recurrent unit (GRU); violent content},
	keywords = {Convolutional neural networks; Recurrent neural networks; Transfer learning; BERT; Content detection; Convolutional neural network; Deep learning; Detection system; Gated recurrent unit; Research domains; Violence detections; Violent content; Computer vision},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 International Conference on Intelligent Manufacturing and Industrial Big Data, ICIMIBD 2022; Conference date: 9 December 2022 through 11 December 2022; Conference code: 194001}
}

@ARTICLE{Abebaw2022175,
	author = {Abebaw, Zeleke and Rauber, Andreas and Atnafu, Solomon},
	title = {Design and Implementation of a Multichannel Convolutional Neural Network for Hate Speech Detection in Social Networks},
	year = {2022},
	journal = {Revue d'Intelligence Artificielle},
	volume = {36},
	number = {2},
	pages = {175 – 183},
	doi = {10.18280/RIA.360201},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133277302&doi=10.18280%2fRIA.360201&partnerID=40&md5=4bc3e45337128540bfd40534af6ebb49},
	affiliations = {IT Doctoral Program, Addis Ababa University, Addis Ababa, 1176, Ethiopia; Institute of Information Systems Engineering, Technical University of Vienna, Favoritenstraße 9-11/194-01, Vienna, A-1040, Austria; Department of Computer Science, Addis Ababa University, Addis Ababa, 1176, Ethiopia},
	abstract = {As the number of social media comments available online grows, the spread of hate speech has grown gradually. When someone uses hate speech as a weapon to injure, degrade, and humiliate others, their freedom, dignity, and personhood can be jeopardized. Deep neural network-based hate speech detection models, such as the conventional single channel convolutional neural network (SC-CNN), have recently demonstrated promising results. The success of the models, however, is dependent on the type of language they are trained on and the training data size. Even with a small amount of training data, the model's performance can be improved by using a multichannel convolutional neural network (MC-CNN) model. The study assesses and compares the performance of a multichannel convolutional neural network model to single channel convolutional neural network models using a support vector machine (SVM) as a baseline. The models' F1 score values are computed, and promising results are obtained. The MC-CNN model outperforms the SC-CNN models in all three hate speech datasets. The study's findings indicate that the proposed MC-CNN model could be used as a deep learning-based alternative for hate speech detection. © 2022 Lavoisier. All rights reserved.},
	author_keywords = {Amharic hate speech detection; deep learning; multichannel convolutional neural network; single channel; social media comment; word embedding},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@CONFERENCE{Gupta2022,
	author = {Gupta, Vikram and Roychowdhury, Sumegh and Das, Mithun and Banerjee, Somnath and Saha, Punyajoy and Mathew, Binny and Vanchinathan, Hastagiri and Mukherjee, Animesh},
	title = {MACD: Multilingual Abusive Comment Detection at Scale for Indic Languages},
	year = {2022},
	journal = {Advances in Neural Information Processing Systems},
	volume = {35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163164988&partnerID=40&md5=e671090682015bbc161afde91a2d6281},
	affiliations = {ShareChat, India; Indian Institute of Technology, Kharagpur, India},
	abstract = {Social media platforms were conceived to act as online 'town squares' where people could get together, share information and communicate with each other peacefully. However, harmful content borne out of bad actors are constantly plaguing these platforms slowly converting them into 'mosh pits' where the bad actors take the liberty to extensively abuse various marginalised groups. Accurate and timely detection of abusive content on social media platforms is therefore very important for facilitating safe interactions between users. However, due to the small scale and sparse linguistic coverage of Indic abusive speech datasets, development of such algorithms for Indic social media users (one-sixth of global population) is severely impeded. To facilitate and encourage research in this important direction, we contribute for the first time MACD - a large-scale (150K), human-annotated, multilingual (5 languages), balanced (49% abusive content) and diverse (70K users) abuse detection dataset of user comments, sourced from a popular social media platform - ShareChat2. We also release AbuseXLMR, an abusive content detection model pretrained on large number of social media comments in 15+ Indic languages which outperforms XLM-R and MuRIL on multiple Indic datasets. Along with the annotations, we also release the mapping between comment, post and user id's to facilitate modelling the relationship between them. We share competitive monolingual, cross-lingual and few-shot baselines so that MACD can be used as a dataset benchmark for future research. Dataset, code and AbuseXLMR are available at: https://github.com/ShareChatAI/MACD. © 2022 Neural information processing systems foundation. All rights reserved.},
	keywords = {Linguistics; Social networking (online); Content detection; Cross-lingual; Detection models; Global population; Large-scales; Small scale; Social media; Social media platforms; User ID; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185}
}

@CONFERENCE{Grolman2022143,
	author = {Grolman, Edita and Binyamini, Hodaya and Shabtai, Asaf and Elovici, Yuval and Morikawa, Ikuya and Shimizu, Toshiya},
	title = {HateVersarial: Adversarial Attack Against Hate Speech Detection Algorithms on Twitter},
	year = {2022},
	journal = {UMAP2022 - Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization},
	pages = {143 – 152},
	doi = {10.1145/3503252.3531309},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135175816&doi=10.1145%2f3503252.3531309&partnerID=40&md5=7e960cda46af118ffa75b4fff8372c48},
	affiliations = {Ben-Gurion University of the Negev, Israel; Fujitsu Limited, Japan},
	abstract = {Machine learning (ML) models are commonly used to detect hate speech, which is considered one of the main challenges of online social networks. However, ML models have been shown to be vulnerable to well-crafted input samples referred to as adversarial examples. In this paper, we present an adversarial attack against hate speech detection models and explore the attack's ability to: (1) prevent the detection of a hateful user, which should result in termination of the user's account, and (2) classify normal users as hateful, which may lead to the termination of a legitimate user's account. The attack is targeted at ML models that are trained on tabular, heterogeneous datasets (such as the datasets used for hate speech detection) and attempts to determine the minimal number of the most influential mutable features that should be altered in order to create a successful adversarial example. To demonstrate and evaluate the attack, we used the open and publicly available "Hateful Users on Twitter"dataset. We show that under a black-box assumption (i.e., the attacker does not have any knowledge on the attacked model), the attack has a 75% success rate, whereas under a white-box assumption (i.e., the attacker has full knowledge on the attacked model), the attack has an 88% success rate. © 2022 ACM.},
	author_keywords = {adversarial attack; hate speech; social media; Twitter},
	keywords = {Chemical detection; Signal detection; Speech recognition; Adversarial attack; Detection models; Hate speech; Input sample; Legitimate users; Machine learning models; Social media; Speech detection; Speech detection algorithm; Twitter; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 30th ACM Conference on User Modeling, Adaptation and Personalization, UMAP2022; Conference date: 4 July 2022 through 7 July 2022; Conference code: 180575}
}

@ARTICLE{Liu2022,
	author = {Liu, Junjie and Yang, Yong and Fan, Xiaochao and Ren, Ge and Yang, Liang and Ning, Qian},
	title = {Offensive-Language Detection on Multi-Semantic Fusion Based on Data Augmentation},
	year = {2022},
	journal = {Applied System Innovation},
	volume = {5},
	number = {1},
	doi = {10.3390/asi5010009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123862522&doi=10.3390%2fasi5010009&partnerID=40&md5=3ac1b101a85d6732aca48c2566a74ac0},
	affiliations = {School of Computer Science and Technology, Xinjiang Normal University, Urumqi, 830000, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, 116000, China; School of Physics and Electronic Engineering, Xinjiang Normal University, Urumqi, 830000, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, 610000, China},
	abstract = {The rapid identification of offensive language in social media is of great significance for preventing viral spread and reducing the spread of malicious information, such as cyberbullying and content related to self-harm. In existing research, the public datasets of offensive language are small; the label quality is uneven; and the performance of the pre-trained models is not satisfactory. To overcome these problems, we proposed a multi-semantic fusion model based on data augmentation (MSF). Data augmentation was carried out by back translation so that it reduced the impact of too-small datasets on performance. At the same time, we used a novel fusion mechanism that combines word-level semantic features and n-grams character features. The experimental results on the two datasets showed that the model proposed in this study can effectively extract the semantic information of offensive language and achieve state-of-the-art performance on both datasets. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Data augmentation; MSF; Offensive language},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Dowlagar2022,
	author = {Dowlagar, Suman and Mamidi, Radhika},
	title = {Hate Speech Detection on Code-Mixed Dataset Using a Fusion of Custom and Pre-trained Models with Profanity Vector Augmentation},
	year = {2022},
	journal = {SN Computer Science},
	volume = {3},
	number = {4},
	doi = {10.1007/s42979-022-01189-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130724655&doi=10.1007%2fs42979-022-01189-8&partnerID=40&md5=252b9c19dc7db320162e464cb1e2b567},
	affiliations = {LTRC, IIIT-Hyderabad, Telangana, Hyderabad, 500032, India},
	abstract = {With the increase in user-generated content on social media networks, hate speech and offensive language content are also increasing. From the perspective of computer science, automatic detection of such hate speech and offensive language content is an interesting problem to solve. The natural language community has taken a step to identify such content via automated hate speech and offensive content detection. The hate speech content is generated mostly on social media, and automatic hate speech and offensive language detection face many challenges due to non-standard spelling and grammar variations. Specifically, in a multilingual community, the hate content would be in code-mixed form, making the task further challenging. In this article, we propose a model for code-mixed hate speech detection. This model embeds the knowledge from both user-trained and multilingual pre-trained models. The proposed method also calculates the profanity word list and augments it. Experimental results on code-mixed hate speech and offensive language detection benchmarks show that our method outperforms the existing baselines. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Code-mixing; Hate speech detection; Neural network models; Profanity word list},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Priya2022132,
	author = {Priya and Gupta, Sachin},
	title = {Hate Speech Detection using OpenAI and GPT-3},
	year = {2022},
	journal = {International Journal of Emerging Technology and Advanced Engineering},
	volume = {12},
	number = {5},
	pages = {132 – 138},
	doi = {10.46338/ijetae0522_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130118570&doi=10.46338%2fijetae0522_15&partnerID=40&md5=81a081e2f3c39e3cf20843a9f966730c},
	affiliations = {MVN University, Haryana, Palwal, India},
	abstract = {The toxicity of speech being spewed via cyber media is a critical issue of concern in the cyberverse these days. This problem is associated with using offensive, violent or abusive phrases countering any person, any group or some minority community. Amongst the latest advanced and high-level language models for natural language processing (NLP) is the generative pre-trained transformer model from OpenAI, code named GPT-3 which could both produce and predict hatred-based text that bullies the specific community or group. With this capability, the concern is anyhow the large language models could be used for analysis and identification of hated speech and also the classification as positive or negative. GPT-3 classifies text as hate or non-hate speech with different learning models including zero to a few shot versions. Amongst these, the zero- and one-shot based learning models achieve an accuracy between 45 to 72 percent, while using few shots learning models, accuracy could be achieved up to 80 percent. The results of this study indicate that in hate and toxic speech detection, large language models play a vital role that also need development so as to counter the toxic content resulting in hatred and can help with safe cyberspace. © 2022 IJETAE Publication House. All Rights Reserved.},
	author_keywords = {Cybersafety; GPT-3; Language models; NLP; Toxicity in speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@CONFERENCE{Das202232,
	author = {Das, Mithun and Banerjee, Somnath and Mukherjee, Animesh},
	title = {Data Bootstrapping Approaches to Improve Low Resource Abusive Language Detection for Indic Languages},
	year = {2022},
	journal = {HT 2022: 33rd ACM Conference on Hypertext and Social Media - Co-located with ACM WebSci 2022 and ACM UMAP 2022},
	pages = {32 – 42},
	doi = {10.1145/3511095.3531277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134265489&doi=10.1145%2f3511095.3531277&partnerID=40&md5=c792b102190a74f68fe59e98522818a0},
	affiliations = {Indian Institute of Technology, West Bengal, Kharagpur, India},
	abstract = {Abusive language is a growing concern in many social media platforms. Repeated exposure to abusive speech has created physiological effects on the target users. Thus, the problem of abusive language should be addressed in all forms for online peace and safety. While extensive research exists in abusive speech detection, most studies focus on English. Recently, many smearing incidents have occurred in India, which provoked diverse forms of abusive speech in online space in various languages based on the geographic location. Therefore it is essential to deal with such malicious content. In this paper, to bridge the gap, we demonstrate a large-scale analysis of multilingual abusive speech in Indic languages. We examine different interlingual transfer mechanisms and observe the performance of various multilingual models for abusive speech detection for eight different Indic languages. We also experiment to show how robust these models are on adversarial attacks. Finally, we conduct an in-depth error analysis by looking into the models' misclassified posts across various settings. We have made our code and models public for other researchers1. © 2022 ACM.},
	author_keywords = {Abusive language; detection; multilingual; social media},
	keywords = {Speech recognition; Abusive language; Detection; Geographic location; Language detection; Large-scale analysis; Multilingual; Physiological effects; Social media; Social media platforms; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 33rd ACM Conference on Hypertext and Social Media, HT 2022 - Co-located with ACM WebSci 2022 and ACM UMAP 2022; Conference date: 28 June 2022 through 1 July 2022; Conference code: 180456; All Open Access, Green Open Access}
}

@CONFERENCE{Lee20223530,
	author = {Lee, Jean and Lim, Taejun and Lee, Heejun and Jo, Bogeun and Kim, Yangsok and Yoon, Heegeun and Han, Soyeon Caren},
	title = {K-MHaS: A Multi-label Hate Speech Detection Dataset in Korean Online News Comment},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {1},
	pages = {3530 – 3538},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162626974&partnerID=40&md5=52aafb3cf126407bd1a37e774195a247},
	affiliations = {The University of Sydney, Australia; The University of Western Australia, Australia; BigWave AI, South Korea; Keimyung University, South Korea; National Information Society Agency},
	abstract = {Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS1, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Korean language; Language patterns; Multi-label classifications; Multi-labels; Online content; Online news; Speech detection; Tokenizer; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893}
}

@CONFERENCE{Kim20226644,
	author = {Kim, Jiyun and Lee, Byounghan and Sohn, Kyung-Ah},
	title = {Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {1},
	pages = {6644 – 6655},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150635665&partnerID=40&md5=b72adeb01c3f9c9c27411899dd0466c5},
	affiliations = {Ajou University, South Korea},
	abstract = {In a hate speech detection model, we should consider two critical aspects in addition to detection performance–bias and explainability. Hate speech cannot be identified based solely on the presence of specific words; the model should be able to reason like humans and be explainable. To improve the performance concerning the two aspects, we propose Masked Rationale Prediction (MRP) as an intermediate task. MRP is a task to predict the masked human rationales–snippets of a sentence that are grounds for human judgment–by referring to surrounding tokens combined with their unmasked rationales. As the model learns its reasoning ability based on rationales by MRP, it performs hate speech detection robustly in terms of bias and explainability. The proposed method generally achieves state-of-the-art performance in various metrics, demonstrating its effectiveness for hate speech detection. Warning: This paper contains samples that may be upsetting. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.},
	keywords = {Computational linguistics; Speech recognition; Detection models; Detection performance; Human judgments; Learn+; Reasoning ability; Speech detection; State-of-the-art performance; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893}
}

@CONFERENCE{Busuioc2022133,
	author = {Busuioc, Gabriel-Razvan and Paraschiv, Andrei and Dascalu, Mihai},
	title = {FB-RO-Offense - A Romanian Dataset and Baseline Models for Detecting Offensive Language in Facebook Comments},
	year = {2022},
	journal = {Proceedings - 2022 24th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2022},
	pages = {133 – 142},
	doi = {10.1109/SYNASC57785.2022.00029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163111247&doi=10.1109%2fSYNASC57785.2022.00029&partnerID=40&md5=6ad931812fedaf5f6e83ba8c6aa48d9b},
	affiliations = {University Politehnica of Bucharest, Computer Science Department, Bucharest, Romania},
	abstract = {In the past decade, social media platforms gained a lot of popularity amongst people all around the globe, some of them seizing this opportunity to proliferate offensive language and hate speech. In addition, platforms that choose not to consider text filtering techniques are being exploited by users who tend to use offensive and abusive language. This paper presents the creation and annotation of a novel Romanian language corpus for offensive language detection, FB-RO-Offense, an offensive speech dataset containing 4,455 organic generated comments from Facebook live broadcasts annotated not only for coarse-grained binary detection tasks but also fine-grained, based on the degree of the offense. We describe the data collection process and the annotation procedure and analyze the content of the corpus. Additionally, we present the results of automatic classification processes using state-of-the-art classification processes and establish a strong baseline for this new dataset including SVM, BERT-based, and CNN architectures, with results that show an F1-score of 0.83 for a four-way classification and an F1-score of 0.90 for the binary classification. © 2022 IEEE.},
	author_keywords = {offensive language classification; offensive language dataset; Romanian language processing},
	keywords = {Crime; Seizing; Social networking (online); Support vector machines; Classification process; F1 scores; Facebook; Language processing; Offensive language classification; Offensive language dataset; Offensive languages; Romanian language; Romanian language processing; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 24th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2022; Conference date: 12 September 2022 through 15 September 2022; Conference code: 189021}
}

@CONFERENCE{AlKhamissi20222109,
	author = {AlKhamissi, Badr and Ladhak, Faisal and Iyer, Srini and Stoyanov, Ves and Kozareva, Zornitsa and Li, Xian and Fung, Pascale and Mathias, Lambert and Celikyilmaz, Asli and Diab, Mona},
	title = {TOKEN: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection},
	year = {2022},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {2109 – 2120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149165096&partnerID=40&md5=5f2e4736ac5f29280bd25e952313a5c2},
	affiliations = {Meta AI},
	abstract = {Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its "constituent" parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. ATOMIC2020 ) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Decomposition; Large dataset; Absolute gain; Annotated datasets; Commonsense reasoning; Large-scales; Learning tasks; Performance; Speech detection; Task decomposition; Task knowledge; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895}
}

@CONFERENCE{Dash2022290,
	author = {Dash, Swayam Samparna and Kar, Nikunja Bihari},
	title = {Challenges and Approaches of Code-mixed Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - 2022 International Conference on Machine Learning, Computer Systems and Security, MLCSS 2022},
	pages = {290 – 295},
	doi = {10.1109/MLCSS57186.2022.00060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152471079&doi=10.1109%2fMLCSS57186.2022.00060&partnerID=40&md5=eaf7d68ff60702a7ac75e26090143a5d},
	affiliations = {Siksha 'o' Anusandhan (Deemed to Be University), Department of Computer Science and Engineering Iter, Odisha, Bhubaneswar, India},
	abstract = {The online platform and social media are very eye catchy for internet users. Platforms like YouTube, Twitter, Instagram, etc., are higher in demand due to their brilliant services. Users of these sights frequently comment on others' posts which may contain toxic speech. Some platforms also raise concerns about emerging of this activity. As the increase of hate speech is just next to impossible to control, the need to detect these contents through automated hate speech detection technologies arises. In this work, we focused on multi-lingual issues, especially Indo-European code-mixed languages. At first, we identified some issues related to code-mixed Indian languages. Then, we focused on the available solutions to this problem. We have gone through the works performed on machine learning and deep learning techniques and identified the limitations of those works. We have analyzed the present solutions and gone through the comparative studies of those. Our implementation is conducted on code-mixed twitter datasets providing several perceptions on hate speech. We have performed the experimental work on HASOC 2021 dataset. Our work contributes to the field of hate speech detection by comparing feature extraction and classifier algorithms (Machine Learning and Deep Learning). More specifically, the proposed work aimed at distinguishing Hate and Non-Hate speech from normal text. © 2022 IEEE.},
	author_keywords = {Code-mixed; Feature Extraction; Hate Speech; Machine Learning and Deep Learning},
	keywords = {Codes (symbols); Deep learning; Extraction; Learning systems; Social networking (online); Speech recognition; Code-mixed; Features extraction; Hate speech; Internet users; Machine learning and deep learning; Machine-learning; Online platforms; Social media; Speech detection; YouTube; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Machine Learning, Computer Systems and Security, MLCSS 2022; Conference date: 5 August 2022 through 6 August 2022; Conference code: 187574}
}

@CONFERENCE{Duong20225698,
	author = {Duong, Charles and Zhang, Lei and Lu, Chang-Tien},
	title = {HateNet: A Graph Convolutional Network Approach to Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022},
	pages = {5698 – 5707},
	doi = {10.1109/BigData55660.2022.10020510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147965440&doi=10.1109%2fBigData55660.2022.10020510&partnerID=40&md5=78b9eb57fa454978211d191c461eb41b},
	affiliations = {Brown University, Providence, RI, United States; Virginia Tech, Falls Church, VA, United States},
	abstract = {The COVID-19 pandemic has caused hate speech on online social networks to become a growing issue in recent years, affecting millions. Our work aims to improve automatic hate speech detection to prevent escalation to hate crimes. The first c hallenge i n h ate s peech r esearch i s t hat e xisting datasets suffer from quite severe class imbalances. The second challenge is the sparsity of information in textual data. The third challenge is the difficulty i n b alancing t he t radeoff b etween utilizing semantic similarity and noisy network language. To combat these challenges, we establish a framework for automatic short text data augmentation by using a semi-supervised hybrid of Substitution Based Augmentation and Dynamic Query Expansion (DQE), which we refer to as SubDQE, to extract more data points from a specific c lass f rom T witter. W e a lso p ropose the HateNet model, which has two main components, a Graph Convolutional Network and a Weighted Drop-Edge. First, we propose a Graph Convolutional Network (GCN) classifier, using a graph constructed from the thresholded cosine similarities between tweet embeddings to provide new insights into how ideas are connected. Second, we propose a weighted Drop-Edge based stochastic regularization technique, which removes edges randomly based on weighted probabilities assigned by the semantic similarities between Tweets. Using 3 different SubDQE-augmented datasets, we compare our HateNet model using eight different tweet embedding methods, six other baseline classification models, and seven other baseline data augmentation techniques previously used in the realm of hate speech detection. Our results show that our proposed HateNet model matches or exceeds the performance of the baseline models, as indicated by the accuracy and F1 score. © 2022 IEEE.},
	author_keywords = {dynamic query expansion; graph convolutional network; hate speech; machine learning; social media data mining},
	keywords = {C (programming language); Classification (of information); Convolution; COVID-19; Data mining; Embeddings; Graphic methods; Machine learning; Semantics; Social networking (online); Speech recognition; Stochastic systems; Class imbalance; Convolutional networks; Data augmentation; Dynamic query expansions; Graph convolutional network; Hate speech; Machine-learning; Semantic similarity; Social media data minings; Speech detection; Drops},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2022 IEEE International Conference on Big Data, Big Data 2022; Conference date: 17 December 2022 through 20 December 2022; Conference code: 186390}
}

@CONFERENCE{Chen2022611,
	author = {Chen, Haoyang and Han, Zhongyuan and Kong, Leilei and Zhang, Zhijie and Li, Zengyao and Guo, Mingcan and Qi, Haoliang},
	title = {Mixture Models based on BERT for Hate Speech Detection},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {611 – 616},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146670144&partnerID=40&md5=f74a8cf7df936692c8c98bb887bdaf4e},
	affiliations = {Foshan University, Foshan, China},
	abstract = {While social platforms such as Twitter have brought convenience to people, they have also become a hotbed for spreading hate speech. Identifying hate speech and offensive content has become an important task. This paper presents our team's experiments on two shared tasks of HASOC 2022, where we fine-tuned three pre-trained models based on indic-abusive and multilingual BERT to perform hate speech detection on tweets in code-mixed languages. We try to reduce the impact of data imbalance by combining model predictions. Our team obtained 5th (with macro f1: 0.6388) in the dichotomous subtask 1 for Hinglish and German and 3rd (with macro f1: 0.4769) in subtask 2 for Hinglish with multiple classifications. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; Classification; Hate Speech Detection; Hinglish},
	keywords = {BERT; Combining model; Data imbalance; Hate speech detection; Hinglish; Mixture modeling; Model prediction; Model-based OPC; Speech detection; Subtask; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Athira Krishnan2022110,
	author = {Athira Krishnan, R. and Poornachandran, Prabaharan and Sujadevi, V.G. and Rajendran, Gayathri and Vinayak, K.S. and Vijayan, Vishnu and Ram, Arjun},
	title = {MalHate : Hate Speech Detection in Malayalam Regional Language},
	year = {2022},
	journal = {7th IEEE International Conference on Recent Advances and Innovations in Engineering, ICRAIE 2022 - Proceedings},
	pages = {110 – 115},
	doi = {10.1109/ICRAIE56454.2022.10054339},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150024338&doi=10.1109%2fICRAIE56454.2022.10054339&partnerID=40&md5=6b8c9276c09e7dba8e60be464dd2db2a},
	affiliations = {Amrita Vishwa Vidyapeetham, Centre for Internet Studies and Artificial Intelligence, Kollam, Amritapuri, India},
	abstract = {Hate speech is a deceptive problem on social media and its impact on society is quite prominent and striking. As part of regulatory measures, analysis on them has been active research in the past recent years. Social media is a tool on the common man's hand hence the use of native language is quite often. Thus we find utmost importance to be given to regional language analysis as well. There are different approaches proposed by researchers from time to time for Hate Speech analysis. In this research, we are focusing on a particular regional language, Malayalam for Vernacular Hate Speech Detection. We have analysed using the deep learning techniques and achieved the best F1 score 0.85 for pure malayalam dataset.  © 2022 IEEE.},
	author_keywords = {BERT; Deep Learning; DistilBERT; Hate Speech Detection; Indic; Malayalam; Multilingual; XLMR},
	keywords = {Social networking (online); Speech analysis; BERT; Deep learning; Distilbert; Hate speech detection; Indic; Malayalams; Multilingual; Social media; Speech detection; XLMR; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th IEEE International Conference on Recent Advances and Innovations in Engineering, ICRAIE 2022; Conference date: 1 December 2022 through 3 December 2022; Conference code: 187045}
}

@CONFERENCE{Chavan2022522,
	author = {Chavan, Tanmay and Patankar, Shantanu and Kane, Aditya and Gokhale, Omkar and Joshi, Raviraj},
	title = {A Twitter BERT Approach for Offensive Language Detection in Marathi},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {522 – 528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146690373&partnerID=40&md5=52074a7862f030a99cad8616cd8d1725},
	affiliations = {Pune Institute of Computer Technology, Pune, India; Indian Institute of Technology Madras, Chennai, India; L3Cube, Pune, India},
	abstract = {Automated offensive language detection is essential in combating the spread of hate speech, particularly in social media. This paper describes our contribution to the HASOC 2022 Shared Task on Offensive Language Identification in Marathi (Subtask-3A), which handles this crucial task of offensive speech detection in the Marathi Language. In this task, we have to classify a tweet as offensive or non-offensive. We evaluate different mono-lingual and multi-lingual BERT models on this classification task, focusing on BERT models pre-trained with social media datasets. We compare the performance of MuRIL, MahaTweetBERT, MahaTweetBERT-Hateful, and MahaBERT on HASOC 2022 and a combination of HASOC 2021 and HASOC 2022 Marathi datasets. The MahaTweetBERT, a BERT model, pre-trained on Marathi tweets when fine-tuned on the combined dataset (HASOC 2021 + HASOC 2022), outperforms all models with an F1 score of 95.88 on the HASOC 2022 test set. © 2022 Copyright for this paper by its authors.},
	author_keywords = {HASOC 2022; Hate speech detection; Marathi BERT; Marathi Tweet BERT; Transformers},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Social networking (online); Speech recognition; HASOC 2022; Hate speech detection; Language detection; Language identification; Marathi BERT; Marathi tweet BERT; Offensive languages; Social media; Speech detection; Transformer; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@ARTICLE{Amjad2022143,
	author = {Amjad, Maaz and Ashraf, Noman and Sidorov, Grigori and Zhila, Alisa and Chanona-Hernandez, Liliana and Gelbukh, Alexander},
	title = {Automatic Abusive Language Detection in Urdu Tweets},
	year = {2022},
	journal = {Acta Polytechnica Hungarica},
	volume = {19},
	number = {10},
	pages = {143 – 163},
	doi = {10.12700/APH.19.10.2022.10.9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159128524&doi=10.12700%2fAPH.19.10.2022.10.9&partnerID=40&md5=23068cab4c78a825aa7ccbfdebca87f4},
	affiliations = {Instituto Politécnico Nacional, Centro de Investigación en Computación (CIC), Gustavo A. Madero, Mexico City, 07738, Mexico; San Francisco, 94103, CA, United States; Instituto Politécnico Nacional, Escuela Superior de Ingeniería Mecánica y Eléctrica (ESIME), Gustavo A. Madero, Mexico City, 07340, Mexico},
	abstract = {Abusive language detection is an essential task in our modern times. Multiple studies have reported this task, in various languages, because it is essential to validate methods in many different languages. In this paper, we address the automatic detection of abusive language for tweets in the Urdu language. The study introduces the first dataset of tweets in the Urdu language, annotated for offensive expressions and evaluates it by comparing several machine learning methods. The Twitter dataset contains 3,500 tweets, all manually annotated by human experts. This research uses three text representation techniques: two count-based feature vectors and the pre-trained fastText word embeddings. The count-based features contain the character and word n-gram, while the pre-trained fastText model comprises word embeddings extracted from the Urdu tweets dataset. Moreover, this study uses four non-neural network models (SVM, LR, RF, AdaBoost) and two neural networks (CNN, LSTM). The study finding reveals that SVM outperforms other classifiers and obtains the best results for any text representation. Character tri-grams perform well with SVM and get an 82.68% of F1 score. The best-performing words n-grams are unigrams with SVM, which obtain 81.85% F1 score. The fastText word embeddings-based representation yields insignificant results. © 2022, Budapest Tech Polytechnical Institution. All rights reserved.},
	author_keywords = {Abusive language detection; Machine learning; Twitter corpus; Urdu language},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access}
}

@CONFERENCE{Omar2022887,
	author = {Omar, Marwan and Mohaisen, David},
	title = {Making Adversarially-Trained Language Models Forget with Model Retraining: A Case Study on Hate Speech Detection},
	year = {2022},
	journal = {WWW 2022 - Companion Proceedings of the Web Conference 2022},
	pages = {887 – 893},
	doi = {10.1145/3487553.3524667},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137477914&doi=10.1145%2f3487553.3524667&partnerID=40&md5=7ae7066b91a65c28c561af3c69cfba2e},
	affiliations = {University of Central Florida, Orlando, FL, United States},
	abstract = {Adversarial training has become almost the de facto standard for robustifying Natural Language Processing models against adversarial attacks. Although adversarial training has proven to achieve accuracy gains and boost the performance of algorithms, research has not shown how adversarial training will stand "the test of times"when models are deployed and updated with new non-adversarial data samples. In this study, we aim to quantify the temporal impact of adversarial training on naturally-evolving language models using the hate speech task. We conduct extensive experiments on the Tweet Eval benchmark dataset using multiple hate speech classification models. In particular, our findings indicate that adversarial training is highly task-dependent as well as dataset dependent as models trained on the same dataset achieve high prediction accuracy but fare poorly when tested with new dataset even after retraining models with adversarial examples. We attribute this temporal and limited effect of adversarial training to distribution shift of the training data which implies that models' quality will degrade over-time as models are deployed in the real world and start serving new data.  © 2022 ACM.},
	author_keywords = {adversarial training; concept drift; Hate speech detection; robustness},
	keywords = {Computational linguistics; Natural language processing systems; Speech recognition; Adversarial training; Case-studies; Concept drifts; De facto standard; Hate speech detection; Language model; Language processing; Natural languages; Robustness; Speech detection; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 31st ACM Web Conference, WWW 2022; Conference date: 25 April 2022; Conference code: 181993; All Open Access, Bronze Open Access}
}

@ARTICLE{Nayak2022209,
	author = {Nayak, Richi and Baek, Hee Sook},
	title = {Machine Learning for Identifying Abusive Content in Text Data},
	year = {2022},
	journal = {Learning and Analytics in Intelligent Systems},
	volume = {24},
	pages = {209 – 229},
	doi = {10.1007/978-3-030-93052-3_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179870554&doi=10.1007%2f978-3-030-93052-3_9&partnerID=40&md5=2b472fca016c99883da787959ca1b5ab},
	affiliations = {Faculty of Science, School of Computer Science & Center for Data science, Queensland University of Technology, Brisbane, Australia},
	abstract = {The proliferation of social media has created new norms in society. Incidents of abuse, hate, harassment and misogyny are widely spread across social media platforms. With the advancements in machine learning techniques, advanced text mining methods have been developed to analyse text data. Social media data poses additional challenges to these methods due to their nature of short content and the presence of ambiguity, errors and noises in content. In the past decade, machine learning researchers have focused on finding solutions dealing with these challenges. Outcomes of these methods boost the social media monitoring capability and can assist policymakers and governments to focus on key issues. This chapter will review various types of machine learning techniques including the currently popular deep learning methods that can be used in the analysis of social media data for identifying abusive content. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Abusive content detection; Attention model; Deep learning; Generative model; Hate speech detection; Natural language processing; Transformer model},
	keywords = {Deep learning; Learning systems; Natural language processing systems; Social networking (online); Speech recognition; Abusive content detection; Attention model; Content detection; Deep learning; Generative model; Hate speech detection; Language processing; Natural language processing; Natural languages; Speech detection; Transformer modeling; Learning algorithms},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zhang2022675,
	author = {Zhang, Chunyun and Zhang, Xi and Wang, Quan and Liang, Jiayi and Zhang, Ge and Guo, Sanchuan and Zang, Wenyu and Zhang, Yongdong},
	title = {Abusive Language Detection with Graph based Multi-task Learning},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022},
	pages = {675 – 684},
	doi = {10.1109/BigData55660.2022.10020761},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147899845&doi=10.1109%2fBigData55660.2022.10020761&partnerID=40&md5=1ad40f306c2c36b3e38d6decccfe53ff},
	affiliations = {Beijing University of Posts and Telecommunications, Beijing, China; Beijing Academy of Artificial Intelligence, Beijing, China; China Electronics Corporation, Beijing, China; University of Science and Technology of China, Beijing, China},
	abstract = {To counter the online abusive language in social media, it is desirable to develop automated detection methods. Previous research has primarily formulated this problem as a sentence-level classification task, ignoring the crucial role of abusive lexicons that can strengthen the model explainability and enable more faithful predictions. Although a few methods have introduced the abusive lexicons for detection, the lexicons they use are either externally provided or labeled by human annotators, suffering from two limitations: (1) lack adaptability to diverse and evolving offensive scenarios; (2) require large human efforts to annotate the words.This paper overcomes the limitations of prior work with a multi-task abusive language detection framework. It combines sentence-level and word-level classification tasks, based on dependency tree based graph attention networks (GAT). With the two tasks, it is encouraged to capture both global and local data properties to produce better sentence representations. It is also advantageous in automatic lexicon construction during the learning process, without human annotations. Extensive experiments on two public datasets exhibit that our proposal can outperform the state-of-the-art baselines. Case studies show that the model explainability can be strengthened with the abusive parts identified by our framework. Our code is released to public. 1 © 2022 IEEE.},
	author_keywords = {abusive language detection; graph attention networks; multi-task learning; word classification task},
	keywords = {Graphic methods; Learning systems; Abusive language detection; Classification tasks; Graph attention network; Graph-based; Language detection; Multitask learning; Sentence level; Social media; Word classification; Word classification task; Trees (mathematics)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2022 IEEE International Conference on Big Data, Big Data 2022; Conference date: 17 December 2022 through 20 December 2022; Conference code: 186390}
}

@ARTICLE{Arango2022,
	author = {Arango, Aymé and Pérez, Jorge and Poblete, Barbara},
	title = {Hate speech detection is not as easy as you may think: A closer look at model validation (extended version)},
	year = {2022},
	journal = {Information Systems},
	volume = {105},
	doi = {10.1016/j.is.2020.101584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087929876&doi=10.1016%2fj.is.2020.101584&partnerID=40&md5=99392bd1de06e2f427ebd4c6c4fdaeb3},
	affiliations = {Department of Computer Science, University of Chile, Beauchef 851, Santiago, 837-0456, Chile; IMFD, Santiago, Chile},
	abstract = {Hate speech is an important problem that is seriously affecting the dynamics and usefulness of online social communities. Large scale social platforms are currently investing important resources into automatically detecting and classifying hateful content, without much success. On the other hand, the results reported by state-of-the-art systems indicate that supervised approaches achieve almost perfect performance but only within specific datasets, most of them in English language. In this work, we analyze this apparent contradiction between existing literature and actual applications. We study closely the experimental methodology used in prior work and their generalizability to other datasets. Our findings evidence methodological issues, as well as an important dataset bias. As a consequence, performance claims of the current state-of-the-art have become significantly overestimated. The problems that we have found are mostly related to data overfitting and sampling issues. We discuss the implications for current research and re-conduct experiments to give a more accurate picture of the current state-of-the art methods. Moreover, we design some baseline approaches to perform cross-lingual experiments, using English and Spanish datasets. © 2020 Elsevier Ltd},
	author_keywords = {Deep learning; Experimental evaluation; Hate speech classification; Social media},
	keywords = {Information systems; English languages; Experimental methodology; Extended versions; Online social communities; Speech detection; State of the art; State-of-the-art methods; State-of-the-art system},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36}
}

@CONFERENCE{Zimmermann-Janssen2022,
	author = {Zimmermann-Janssen, Vita E.M. and Gier, Nadine R.},
	title = {Chances and Limits of Community-Based Hate Speech Detection - Results from a Combined Behavioral-NeuroIS Study},
	year = {2022},
	journal = {International Conference on Information Systems, ICIS 2022: "Digitization for the Next Generation"},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192535952&partnerID=40&md5=fb8d908a3babb8fb2184ced388faca9c},
	affiliations = {Heinrich Heine University, Universitätsstr. 1, Düsseldorf, 40225, Germany},
	abstract = {Communication via social media is characterized by immediacy and anonymity, enabling free expression and sharing of opinions, but also the abuse of language in form of hate speech. Given the volume of online content, IS research offers approaches to efficiently detect hate speech. However, research and politics call for more independent, transparent, and social approaches to increase credibility and acceptance. In response, this two-part behavioral and neural study investigates flagging as a community-based solution to hate speech detection. By experimentally varying the displayed shares of flagging users and testing behavioral responses, results reveal opposing behavioral patterns as a function of the valuation of hate speech prevention. Moreover, by framing the display of the user community's flagging behavior as a sort of social normative information and hate speech prevention as a public good, the theoretical model might help explain (seemingly) conflicting results in social norm and public goods research. © 2022 International Conference on Information Systems, ICIS 2022: "Digitization for the Next Generation". All Rights Reserved.},
	author_keywords = {altruism theory; collective action; crowd-based solutions; crowding-out; flagging; fNIRS; Hate speech; NeuroIS; public goods; social media; social norms},
	keywords = {Information systems; Information use; Social networking (online); Speech communication; Altruism theory; Collective action; Crowd-based solution; Crowding out; Flagging; FNIRS; Hate speech; NeuroIS; Public goods; Social media; Social norm; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 43rd International Conference on Information Systems: Digitization for the Next Generation, ICIS 2022; Conference date: 9 December 2022 through 14 December 2022; Conference code: 199132}
}

@CONFERENCE{Bestgen2022584,
	author = {Bestgen, Yves},
	title = {Confirming the Effectiveness of a Simple Language-Agnostic Yet Very Strong System for Hate Speech and Offensive Content Identification},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {584 – 589},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146661765&partnerID=40&md5=0624f7dda94b08dc95df9d84ef0fd01d},
	affiliations = {Laboratoire d’analyse statistique des textes - Statistical Analysis of Text Laboratory (LAST - SATLab), Université catholique de Louvain, 10 place Cardinal Mercier, Louvain-la-Neuve, 1348, Belgium},
	abstract = {At the 2021 edition of HASOC, the SATLab team proposed a very simple language-agnostic system for hate speech and offensive content identification. This system proved to be extremely effective for the two less resourced languages (e.g., Hindi and Marathi). The present paper describes the use of the same system for task 3 of the 2022 edition of HASOC on hate speech and offensive content identification in Marathi. It consists of a logistic regression applied to character n-grams. It ranked fifth on subtask 3A (macro-F1 = 0.937), quite close to the first ones, second on subtask 3B (macro-F1 = 0.915), very close to the first one, and first (macro-F1 = 0.961) with more than 16 Macro F1 points ahead of the second one in subtask 3C. These results confirm the effectiveness of the approach and suggest that studies evaluating different systems for this kind of problem should employ a character n-gram based approach as a baseline. They also show that the task is extremely simple since all macro-F1s are greater than or equal to 0.915. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Character n-grams; logistic regression; low-resource languages},
	keywords = {Logistic regression; Character n-gram; Content identifications; Logistics regressions; Low resource languages; N-grams; Simple++; Subtask; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@ARTICLE{Anezi2022,
	author = {Anezi, Faisal Yousif Al},
	title = {Arabic Hate Speech Detection Using Deep Recurrent Neural Networks},
	year = {2022},
	journal = {Applied Sciences (Switzerland)},
	volume = {12},
	number = {12},
	doi = {10.3390/app12126010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132402081&doi=10.3390%2fapp12126010&partnerID=40&md5=123455b8896e906c356876bfd2675cd4},
	affiliations = {Management Information System Department, Prince Mohammad bin Fahd University, Al-Khobar, 34754, Saudi Arabia},
	abstract = {With the vast number of comments posted daily on social media and other platforms, manually monitoring internet activity for possible national security risks or cyberbullying is an impossible task. However, with recent advances in machine learning (ML), the automatic monitoring of such posts for possible national security risks and cyberbullying becomes feasible. There is still the issue of privacy on the internet; however, in this study, only the technical aspects of designing an automated system that could monitor and detect hate speech in the Arabic language were targeted, which many companies, such as Facebook, Twitter, and others, could use to prevent hate speech and cyberbullying. For this task, a unique dataset consisting of 4203 comments classified into seven categories, including content against religion, racist content, content against gender equality, violent content, offensive content, insulting/bullying content, normal positive comments, and normal negative comments, was designed. The dataset was extensively preprocessed and labeled, and its features were extracted. In addition, the use of deep recurrent neural networks (RNNs) was proposed for the classification and detection of hate speech. The proposed RNN architecture, called DRNN-2, consisted of 10 layers with 32 batch sizes and 50 iterations for the classification task. Another model consisting of five hidden layers, called DRNN-1, was used only for binary classification. Using the proposed models, a recognition rate of 99.73% was achieved for binary classification, 95.38% for the three classes of Arabic comments, and 84.14% for the seven classes of Arabic comments. This accuracy was high for the classification of a complex language, such as Arabic, into seven different classes. The achieved accuracy was higher than that of similar methods reported in the recent literature, whether for binary classification, three-class classification, or seven-class classification, as discussed in the literature review section. © 2022 by the author. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Arabic comment classification; bidirectional RNN; deep learning; hate speech detection; natural language processing; recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access}
}

@CONFERENCE{Goldzycher202275,
	author = {Goldzycher, Janis and Schneider, Gerold},
	title = {Hypothesis Engineering for Zero-Shot Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {12},
	pages = {75 – 90},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165177569&partnerID=40&md5=b64e0c48b13f24e4aef0826b8be864ae},
	affiliations = {Department of Computational Linguistics, University of Zurich, Switzerland},
	abstract = {Standard approaches to hate speech detection rely on sufficient available hate speech annotations. Extending previous work that repurposes natural language inference (NLI) models for zero-shot text classification, we propose a simple approach that combines multiple hypotheses to improve English NLI-based zero-shot hate speech detection. We first conduct an error analysis for vanilla NLI-based zero-shot hate speech detection and then develop four strategies based on this analysis. The strategies use multiple hypotheses to predict various aspects of an input text and combine these predictions into a final verdict. We find that the zero-shot baseline used for the initial error analysis already outperforms commercial systems and fine-tuned BERT-based hate speech detection models on HateCheck. The combination of the proposed strategies further increases the zero-shot accuracy of 79.4% on HateCheck by 7.9 percentage points (pp), and the accuracy of 69.6% on ETHOS by 10.0pp. © 2022 MMMPIE. All Rights Reserved.},
	keywords = {Classification (of information); Speech recognition; Text processing; Commercial systems; Inference models; Initial errors; Language inference; Multiple hypothesis; Natural languages; Simple approach; Speech detection; Strategy use; Text classification; Error analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 3rd Workshop on Threat, Aggression and Cyberbullying, TRAC 2022 at 29th International Conference on Computational Linguistics. COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 192733}
}

@ARTICLE{Dascălu2022,
	author = {Dascălu, Ștefan and Hristea, Florentina},
	title = {Towards a Benchmarking System for Comparing Automatic Hate Speech Detection with an Intelligent Baseline Proposal},
	year = {2022},
	journal = {Mathematics},
	volume = {10},
	number = {6},
	doi = {10.3390/math10060945},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127487450&doi=10.3390%2fmath10060945&partnerID=40&md5=16430cb30c17f320b52161e685c232a9},
	affiliations = {Department of Computer Science, University of Bucharest, 14, Academiei Str., Sector 1, Bucharest, 010014, Romania},
	abstract = {Hate Speech is a frequent problem occurring among Internet users. Recent regulations are being discussed by U.K. representatives (“Online Safety Bill”) and by the European Commission, which plans on introducing Hate Speech as an “EU crime”. The recent legislation having passed in order to combat this kind of speech places the burden of identification on the hosting websites and often within a tight time frame (24 h in France and Germany). These constraints make automatic Hate Speech detection a very important topic for major social media platforms. However, recent literature on Hate Speech detection lacks a benchmarking system that can evaluate how different approaches compare against each other regarding the prediction made concerning different types of text (short snippets such as those present on Twitter, as well as lengthier fragments). This paper intended to deal with this issue and to take a step forward towards the standardization of testing for this type of natural language processing (NLP) application. Furthermore, this paper explored different transformer and LSTM-based models in order to evaluate the performance of multi-task and transfer learning models used for Hate Speech detection. Some of the results obtained in this paper surpassed the existing ones. The paper concluded that transformer-based models have the best performance on all studied Datasets. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {BERT; Hate Speech detection; LSTM; multi-task learning; RoBERTa; transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Chinivar2022,
	author = {Chinivar, Sneha and Roopa, M.S. and Arunalatha, J.S. and Venugopal, K.R.},
	title = {Comparision of Varied Embedding and Machine Learning Classifiers for Fine Grained Offensive Content Identification},
	year = {2022},
	journal = {2022 IEEE International Conference for Women in Innovation, Technology and Entrepreneurship, ICWITE 2022 - Proceedings},
	doi = {10.1109/ICWITE57052.2022.10176223},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166466703&doi=10.1109%2fICWITE57052.2022.10176223&partnerID=40&md5=5439eb134d0b94bbbde9f5fc945414c7},
	affiliations = {UVCE, Bangalore University, Dept. of CSE, Bengaluru, India; Dayananda Sagar College of Engineering, Dept. of CSE, Bengaluru, India; UVCE, Bangalore University, Former Vice Chancellor, Bengaluru, India},
	abstract = {Online offensive behaviour is becoming a serious threat with the increased access to technology for all. Specifically, social media is being used more to exhibit this derogatory behaviour. Researchers tried to address these hostile practices using numerous techniques, but most previous works have ignored the multi-class categorization of online bullying content. Our work aims to efficiently identify the online offensive content and further classify the recognized bullying content into multi-class categories viz age, gender, religion, ethnicity, and others to understand what qualities or features most online offenders target. Used a balanced dataset and experimented with numerous embedding models to generate the most fitting vectors. These vectors are further given as input to baseline machine-learning algorithms for the appropriate classification of identified offensive content into fine-grained categories. We have compared the results obtained from the various combinations of word embedding techniques and Machine Learning classifiers.  © 2022 IEEE.},
	author_keywords = {Machine Learning; Online Offensive Behaviour; Social media},
	keywords = {Behavioral research; E-learning; Machine learning; Social networking (online); Balanced datasets; Comparision; Content identifications; Embeddings; Fine grained; Learning classifiers; Machine-learning; Multi-class categorization; Online offensive behavior; Social media; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 IEEE International Conference for Women in Innovation, Technology and Entrepreneurship, ICWITE 2022; Conference date: 1 December 2022 through 3 December 2022; Conference code: 190683}
}

@ARTICLE{Shishah202282,
	author = {Shishah, Wesam and Fajri, Ricky Maulana},
	title = {Large Comparative Study of Recent Computational Approach in Automatic Hate Speech Detection},
	year = {2022},
	journal = {TEM Journal},
	volume = {11},
	number = {1},
	pages = {82 – 93},
	doi = {10.18421/TEM111-10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125712142&doi=10.18421%2fTEM111-10&partnerID=40&md5=9a504fbf45f7660f3463202486f3d8a3},
	affiliations = {College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia; Dept of Computer Science, University of Indo Global Mandiri, Palembang, 30129, Indonesia},
	abstract = {Social media has become a constant in our everyday life. However, its steady growth has increased the hate speech and hostile content problem. To curb this, hate speech detection and recognition is required, but it is faced to two major challenges - laws and enforcement, and automatic computerized hate speech detection. Although many studies are already implemented in detecting hate content, many of these are done in a single setting showing a single dataset in comparison to machine learning or deep learning models. Thus, there is no comparison between previous approaches and recent inventions such as transformer model. Therefore, in this work we explored and compared recent advanced approaches in automatic hate speech detection. Our aim is to analyze the influence different approaches in detecting hate content and its applicability in the real world. Several experiments were conducted on eight real hate speech datasets from recent studies. We present the results of each comparison which shows that the recent transformer model approach is able to outmatch many of the previous hate speech recognition models by significant G-Means and F1 scores. To the author’s knowledge, this paper is the first attempt to present a large comparative study of approaches in hate speech detection. © 2022 Wesam Shishah & Ricky Maulana Fajri; published by UIKTEN. This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 License.},
	author_keywords = {Hate speech; Machine learning and deep learning; Transformer model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Montariol2022347,
	author = {Montariol, Syrielle and Riabi, Arij and Seddah, Djame},
	title = {Multilingual Auxiliary Tasks Training: Bridging the Gap between Languages for Zero-Shot Transfer of Hate Speech Detection Models},
	year = {2022},
	journal = {2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing - Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022},
	pages = {347 – 363},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153357201&partnerID=40&md5=3a9be0f39fdd57a1df7fdd260653d3f4},
	affiliations = {Inria Paris, France},
	abstract = {Zero-shot cross-lingual transfer learning hasbeen shown to be highly challenging for tasksinvolving a lot of linguistic specificities orwhen a cultural gap is present between languages, such as in hate speech detection. Inthis paper, we highlight this limitation for hatespeech detection in several domains and languages using strict experimental settings. Then,we propose to train on multilingual auxiliarytasks sentiment analysis, named entity recognition, and tasks relying on syntactic information to improve zero-shot transfer of hatespeech detection models across languages. Weshow how hate speech detection models benefitfrom a cross-lingual knowledge proxy broughtby auxiliary tasks fine-tuning and highlightthese tasks' positive impact on bridging thehate speech linguistic and cultural gap betweenlanguages. © AACL-IJCNLP 2022.All rights reserved},
	keywords = {Linguistics; Speech recognition; Zero-shot learning; Cross-lingual; Detection models; Fine tuning; Named entity recognition; Sentiment analysis; Speech detection; Syntactic information; Task trainings; Transfer learning; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, AACL-IJCNLP 2022; Conference date: 20 November 2022 through 23 November 2022; Conference code: 187662}
}

@CONFERENCE{Sharma202254,
	author = {Sharma, Amit and Bhalla, Rajni},
	title = {Automatic and Advance Techniques for Hate Speech Detection on Social Media: A Review},
	year = {2022},
	journal = {Proceedings - 2022 Algorithms, Computing and Mathematics Conference, ACM 2022},
	pages = {54 – 61},
	doi = {10.1109/ACM57404.2022.00017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169059597&doi=10.1109%2fACM57404.2022.00017&partnerID=40&md5=725b631befce5f6cbfeb4d77155c3750},
	affiliations = {School of Computer Application, Lovely Professional University, Phagwara, India},
	abstract = {The aim of the study is to review automatic and advanced techniques for investigating hate and offensive speech from social media (SM) platforms. Finding hateful speech from social media is a text classification problem. In the proposed paper explains the methodology of automatic text classification through the medium of traditional machine learning and advanced deep learning algorithms. On social media, people share their opinion and different content, but some users post hateful and offensive content. Detecting and classifying hate speech from social sites is not a small challenge. There are simply five steps that are collecting the data, data cleaning and pre-processing, applying feature extraction techniques, training and testing data in the classification algorithm, and comparative analysis of the algorithm's performance. This review, analyzes the performance of the confusing metrics concepts using four metrics precision (Pr), recall (Re), F1-score, and accuracy (A). Role of this study is to update the researchers and readers on the state-of-the-art model and technology for hateful speech classification. In the last of, this review paper explains some challenges and research gaps for identifying the hate speech in existing models. © 2022 IEEE.},
	author_keywords = {confusion metrics; deep learning; hate speech detection; machine learning algorithms; sentiment analysis; text classification},
	keywords = {Classification (of information); Deep learning; Learning algorithms; Social networking (online); Speech recognition; Automatic text classification; Confusion metric; Deep learning; Hate speech detection; Machine learning algorithms; Sentiment analysis; Social media; Social media platforms; Speech detection; Text classification; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 Algorithms, Computing and Mathematics Conference, ACM 2022; Conference date: 29 August 2022 through 30 August 2022; Conference code: 191527}
}

@ARTICLE{Cruz2022,
	author = {Cruz, Rafael M.O. and de Sousa, Woshington V. and Cavalcanti, George D.C.},
	title = {Selecting and combining complementary feature representations and classifiers for hate speech detection},
	year = {2022},
	journal = {Online Social Networks and Media},
	volume = {28},
	doi = {10.1016/j.osnem.2021.100194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123832213&doi=10.1016%2fj.osnem.2021.100194&partnerID=40&md5=e6736feaace1362b32381e5e05757817},
	affiliations = {LIVIA, École de Technologie Supérieure, University of Quebec, Montreal, Québec, Canada; Centro de Informática, Universidade Federal de Pernambuco, Recife, PE, Brazil},
	abstract = {Hate speech is a major issue in social networks due to the high volume of data generated daily. Recent works demonstrate the usefulness of machine learning (ML) in dealing with the nuances required to distinguish between hateful posts from just sarcasm or offensive language. Many ML solutions for hate speech detection have been proposed by either changing how features are extracted from the text or the classification algorithm employed. However, most works consider only one type of feature extraction and classification algorithm. This work argues that a combination of multiple feature extraction techniques and different classification models is needed. We propose a framework to analyze the relationship between multiple feature extraction and classification techniques to understand how they complement each other. The framework is used to select a subset of complementary techniques to compose a robust multiple classifiers system (MCS) for hate speech detection. The experimental study considering four hate speech classification datasets demonstrates that the proposed framework is a promising methodology for analyzing and designing high-performing MCS for this task. MCS system obtained using the proposed framework significantly outperforms the combination of all models and the homogeneous and heterogeneous selection heuristics, demonstrating the importance of having a proper selection scheme. Source code, figures and dataset splits can be found in the GitHub repository: https://github.com/Menelau/Hate-Speech-MCS. © 2022 Elsevier B.V.},
	author_keywords = {Hate speech; Machine learning; Multiple classifiers system; Natural language processing; Text classification},
	keywords = {Classification (of information); Extraction; Feature extraction; Learning algorithms; Natural language processing systems; Speech; Speech recognition; Text processing; Classification algorithm; Complementary features; Feature classifiers; Feature extraction and classification; Feature extraction techniques; Hate speech; Multiple classifier systems; Multiple features; Speech detection; Text classification; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access}
}

@ARTICLE{Baydogan2022149,
	author = {Baydogan, Cem and Alatas, Bilal},
	title = {Deep-Cov19-Hate: A Textual-Based Novel Approach for Automatic Detection of Hate Speech in Online Social Networks throughout COVID-19 with Shallow and Deep Learning Models},
	year = {2022},
	journal = {Tehnicki Vjesnik},
	volume = {29},
	number = {1},
	pages = {149 – 156},
	doi = {10.17559/TV-20210708143535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122139625&doi=10.17559%2fTV-20210708143535&partnerID=40&md5=f613b024941f75bf8181f28386b30242},
	affiliations = {Department of Software Engineering, Faculty of Technology, Firat University, Elazig, 23119, Turkey; Department of Software Engineering, Faculty of Engineering, Firat University, Elazig, 23119, Turkey},
	abstract = {The use of various online social media platforms rising day by day caused an increase in the correct or incorrect information shared by users, especially during COVID-19. The introduction of COVID-19 on the world agenda gave rise to an overall bad reaction against East Asia (esp. China) in online social media platforms. The social media users who spread degrading, racist, disrespectful, abusive, discriminatory, critical, abuse, harsh, offensive, etc. posts accused the Asian people of being responsible for the outbreak of COVID-19. For this reason, the development of the Hate Speech Detection (HSD) system was necessary in order to prevent the spread of these posts about COVID-19. In this article, a textual-based study on COVID-19-related hate speech (HS) sharing in online social networks was carried out with Shallow Learning (SL) and Deep Learning (DL) methods. In the first step of this study, typical Natural Language Processing (NLP) pipeline was applied for gathered two different datasets. This NLP pipeline was performed using bag of words, term frequency, document matrix, etc. techniques for features extraction representing datasets. Then, ten different SL and DL models were fine-tuned for HS datasets related to COVID-19. Accuracy, precision, sensitivity, and F-score performance measurement criteria were calculated to compare the performance of the SL and DL algorithms for the problem of HSD. The RNN, one of the models proposed for the first and second dataset in HSD, prevailed with the highest accuracy values of 78.7% and 90.3%, respectively. Due to the promising results of all approaches operated in the HSD, they are forecasted to be chosen in the solution of many other social media and network problems related to COVID-19. © 2022, Strojarski Facultet. All rights reserved.},
	author_keywords = {COVID-19; Hate speech detection; Shallow and deep learning models; Social media analysis; Social network problems},
	keywords = {Deep learning; Natural language processing systems; Pipelines; Speech recognition; COVID-19; Hate speech detection; Learning models; Network problems; Online social medias; Shallow and deep learning model; Social media analysis; Social media platforms; Social network problem; Speech detection; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access}
}

@ARTICLE{Karayiğit2022356,
	author = {Karayiğit, Habibe and Akdagli, Ali and Aci, Çiğdem İnan},
	title = {Homophobic and Hate Speech Detection Using Multilingual-BERT Model on Turkish Social Media},
	year = {2022},
	journal = {Information Technology and Control},
	volume = {51},
	number = {2},
	pages = {356 – 375},
	doi = {10.5755/j01.itc.51.2.29988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133233467&doi=10.5755%2fj01.itc.51.2.29988&partnerID=40&md5=5728f05bd1dfd60e480553448cb033c0},
	affiliations = {Department of Electrical and Electronics Engineering, Mersin University, 33343, Turkey; Department of Computer Engineering, Mersin University, 33343, Turkey},
	abstract = {Homophobic expressions are a form of insulting the sexual orientation or personality of people. Severe psychological traumas may occur in people who are exposed to this type of communication. It is important to develop automatic classification systems based on language models to examine social media content and distinguish homophobic discourse. This study aims to present a pre-trained Multilingual Bidirectional Encoder Representations from Transformers (M-BERT) model that can successfully detect whether Turkish comments on social media contain homophobic or related hate comments (i.e., sexist, severe humiliation, and defecation expressions). Comments in the Homophobic-Abusive Turkish Comments (HATC) dataset were collected from Instagram to train the detection models. The HATC dataset was manually labeled at the sentence level and combined with the Abusive Turkish Comments (ATC) dataset that has developed in our previous study. The HATC dataset has been balanced using the resampling method and two forms of the dataset (i.e., resHATC and original HATC) were used in the experiments. Afterward, the M-BERT model was compared with DL-based models (i.e., Long-Short Term Memory, Bidirectional Long-Short Term Memory (BiLSTM), Gated Recurrent Unit), Traditional Machine Learning (TML) classifiers (i.e., Support Vector Machine, Naive Bayes, Random Forest) and Ensemble Classifiers (i.e., Adaptive Boosting, eXtreme Gradient Boosting, Gradient Boosting) for the best model selection. The performance of the detection models was evaluated using F1-score, precision, and recall performance metrics. Results showed the best performance (homophobic F1-score: 82.64%, hateful F1-score: 91.75%, neutral F1-score: 96.08%, average F1-score: 90.15%) were achieved with the M-BERT model on the HATC dataset. The M-BERT detection model can increase the effectiveness of filters in detecting Turkish homophobic and related hate speech in social networks. It can be used to detect homophobic and related hate speech for different languages since the M-BERT model has multilingual pre-trained data. © 2022, Kauno Technologijos Universitetas. All rights reserved.},
	author_keywords = {deep learning; Homophobic speech detection; multilingual BERT; sentiment analysis; text classification; transfer learning; Turkish social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access}
}

@CONFERENCE{Deng202211580,
	author = {Deng, Jiawen and Zhou, Jingyan and Sun, Hao and Zheng, Chujie and Mi, Fei and Meng, Helen and Huang, Minlie},
	title = {COLD: A Benchmark for Chinese Offensive Language Detection Disclaimer: The paper contains content that may be profane, vulgar, or offensive},
	year = {2022},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {11580 – 11599},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149165123&partnerID=40&md5=b14b3c2fe317e85c141f5c2e2e531dd4},
	affiliations = {The CoAI group, DCST, Institute for Artificial Intelligence, State Key Lab of Intelligent Technology and Systems, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, 100084, China; Dept. of Systems Engineering & Engineering Management, The Chinese University of Hong Kong, Hong Kong; Huawei Noah's Ark Lab},
	abstract = {Offensive language detection is increasingly crucial for maintaining a civilized social media platform and deploying pre-trained language models. However, this task in Chinese is still under exploration due to the scarcity of reliable datasets. To this end, we propose a benchmark - COLD for Chinese offensive language analysis, including a Chinese Offensive Language Dataset - COLDATASET and a baseline detector - COLDETECTOR which is trained on the dataset. We show that the COLD benchmark contributes to Chinese offensive language detection which is challenging for existing resources. We then deploy the COLDETECTOR and conduct detailed analyses on popular Chinese pre-trained language models. We first analyze the offensiveness of existing generative models and show that these models inevitably expose varying degrees of offensive issues. Furthermore, we investigate the factors that influence the offensive generations, and we find that anti-bias contents and keywords referring to certain groups or revealing negative attitudes trigger offensive outputs easier. © 2022 Association for Computational Linguistics.},
	keywords = {Generative model; Language analysis; Language detection; Language model; Offensive languages; Social media platforms; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895}
}

@CONFERENCE{Cai2022,
	author = {Cai, Yi and Zimek, Arthur and Wunder, Gerhard and Ntoutsi, Eirini},
	title = {Power of Explanations: Towards automatic debiasing in hate speech detection},
	year = {2022},
	journal = {Proceedings - 2022 IEEE 9th International Conference on Data Science and Advanced Analytics, DSAA 2022},
	doi = {10.1109/DSAA54385.2022.10032325},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148541043&doi=10.1109%2fDSAA54385.2022.10032325&partnerID=40&md5=920fe72e519f826ed99e45b04e64896e},
	affiliations = {Freie Universität Berlin, Dept. of Math. and Comp. Science, Berlin, Germany; University of Southern Denmark, Dept. of Math. and Comp. Science, Odense, Denmark; Universität der Bundeswehr München, Research Institute Code, Munich, Germany},
	abstract = {Hate speech detection is a common downstream application of natural language processing (NLP) in the real world. In spite of the increasing accuracy, current data-driven approaches could easily learn biases from the imbalanced data distributions originating from humans. The deployment of biased models could further enhance the existing social biases. But unlike handling tabular data, defining and mitigating biases in text classifiers, which deal with unstructured data, are more challenging. A popular solution for improving machine learning fairness in NLP is to conduct the debiasing process with a list of potentially discriminated words given by human annotators. In addition to suffering from the risks of overlooking the biased terms, exhaustively identifying bias with human annotators are unsustainable since discrimination is variable among different datasets and may evolve over time. To this end, we propose an automatic misuse detector (MiD) relying on an explanation method for detecting potential bias. And built upon that, an end-to-end debiasing framework with the proposed staged correction is designed for text classifiers without any external resources required. © 2022 IEEE.},
	author_keywords = {AI fairness; bias detection; bias mitigation; explainable AI; text classification},
	keywords = {Classification (of information); Data handling; Speech recognition; Text processing; AI fairness; Bias detection; Bias mitigation; De-biasing; Explainable AI; Language processing; Natural languages; Speech detection; Text classification; Text classifiers; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 9th IEEE International Conference on Data Science and Advanced Analytics, DSAA 2022; Conference date: 13 October 2022 through 16 October 2022; Conference code: 186596; All Open Access, Green Open Access}
}

@CONFERENCE{Vani2022529,
	author = {Vani, Dikshitha V. and Bharathi, B.},
	title = {Hate Speech and Offensive Content Identification in Multiple Languages using machine learning algorithms},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {529 – 541},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146719911&partnerID=40&md5=06566ef25d92b4bb802ff14eaa8ebe59},
	affiliations = {Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Kalavakkam, 603110, India},
	abstract = {The freedom of expression on social media sites like Twitter and Facebook provides opportunities for people to voice out their opinions and concerns. At the same time, it has also become a tool for immense bullying and hateful comments online. AI tools are methods used to identify such comments automatically . These identification tools are evaluated by continuous experimentation with data sets. The HASOC track (Hate Speech and Offensive Content Identification) is dedicated to developing benchmark data for this purpose. This paper presents the HASOC task for Offensive Language Identification in Marathi. The data set was assembled from Twitter. This task has 3 subtasks. Subtask A is Offensive Language Detection where the goal is to discriminate between offensive and non-offensive posts. In subtask B, only the posts labeled as Offensive (OFF) in subtask A are included and the goal is to predict the type of offense as either Targeted Insult(TIN) or Untargeted (UNT). In subtask C, only posts that are either insults or threats (TIN) are considered in this third layer of annotation and classifies them on the target of offenses as Individual (IND), Group (GRP), and Other (OTH). In this work, our team ssncse_nlp have applied machine learning prediction algorithms - Random forest (RF), Support Vector Machine(SVM), Logistic Regression, and k nearest neighbors (KNN) classifier algorithms along with count vectorized features to the tweets for classification. Finally, the result shows that Random Forest predicts the labels for subtasks A and C more accurately than the other classifier models with a Macro F1 score of 0.9745 and 0.7929 while the Logistic Regression classifier predicts more accurately for subtask B with a Macro F1 of 0.6958. © 2022 Copyright for this paper by its authors.},
	keywords = {Crime; Learning systems; Nearest neighbor search; Random forests; Social networking (online); Support vector machines; Content identifications; Data set; Facebook; Identification tools; Machine learning algorithms; Multiple languages; Offensive languages; Random forests; Social media; Subtask; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}

@CONFERENCE{Salaam20226617,
	author = {Salaam, Cesa and Dernoncourt, Franck and Bui, Trung and Rawat, Danda and Yoon, Seunghyun},
	title = {Offensive Content Detection Via Synthetic Code-Switched Text},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {1},
	pages = {6617 – 6624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165768073&partnerID=40&md5=90f02409dc6644acf910701ca62f2704},
	affiliations = {Howard University, United States; Adobe Research},
	abstract = {The prevalent use of offensive content in social media has become an important reason for concern for online platforms (customer service chat-boxes, social media platforms, etc). Classifying offensive and hate-speech content in online settings is an essential task in many applications that needs to be addressed accordingly. However, online text from online platforms can contain code-switching, a combination of more than one language. The non-availability of labeled code-switched data for low-resourced code-switching combinations adds difficulty to this problem. To overcome this, we release a human-generated dataset containing around 10k samples for testing for three language combinations en-fr, en-es, and en-de1 and a synthetic code-switched dataset containing 30k samples for training2. In this paper, we describe the process for gathering the human-generated data and our algorithm for creating synthetic code-switched offensive content data. We also introduce the results of a keyword classification baseline and a multi-lingual transformer-based classification model. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.},
	keywords = {Computational linguistics; Social networking (online); Statistical tests; Classification models; Code-switching; Content data; Content detection; Customer-service; On-line setting; Online platforms; Social media; Social media platforms; Speech content; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893}
}

@CONFERENCE{Bahaaulddin2022296,
	author = {Bahaaulddin, Ahmed and Sabeeh, Vian and Azeez, Ali Sami},
	title = {Detection of Hate Speech on Twitter for Arabic Iraqi Dialect using Stochastic Gradient Classifier},
	year = {2022},
	journal = {4th International Conference on Current Research in Engineering and Science Applications, ICCRESA 2022},
	pages = {296 – 301},
	doi = {10.1109/ICCRESA57091.2022.10352468},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182599958&doi=10.1109%2fICCRESA57091.2022.10352468&partnerID=40&md5=9ab6c29670fc8ddd6aa1af0f588d2bf8},
	affiliations = {Informatics Department, Technical College of Management, Middle Technical University, Baghdad, Iraq},
	abstract = {People increasingly use social media platforms to communicate and share information worldwide. However, challenges such as verbal misbehaviors and hate messages have been raised and widely disseminated via social media. In the Arabic region, especially in Iraq, Twitter is one of the most prominent social media platforms that has gained popularity. Consequently, an ethical reason behind this research is to build a system that can distinguish Iraqi hate tweets. This work achieved three contributions. First, a dataset of Iraqi tweets has been collected and annotated; this is the first dataset for hate speech in the Iraqi dialect. Second, an algorithm for distinguishing Arabic tweets from other oriental tweets that use the same Arabic glyph was proposed to represent a new addition to the preprocessing steps for the Arabic NLP area. This algorithm was tested and showed efficiency in detecting Urdu about (0.91), Persian (0.73), and Arabic (0.98). Third, the Iraqi hate speech classifier was built using two types of text features depending on the stochastic gradient classifier. The classifier was compared with various machine learning algorithms like SVM logistic regression. The proposed system with stochastic gradient classifier was more efficient than other classifiers achieving precision and recall of 0.80. © 2022 IEEE.},
	author_keywords = {Hate speech; Iraqi hate speech dataset; Machine learning; Natural language processing},
	keywords = {Classification (of information); Learning algorithms; Logistic regression; Natural language processing systems; Social networking (online); Support vector machines; Hate speech; Iraqi hate speech dataset; Language processing; Machine-learning; Misbehaviour; Natural language processing; Natural languages; Social media; Social media platforms; Stochastic gradient; Stochastic systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th International Conference on Current Research in Engineering and Science Applications, ICCRESA 2022; Conference date: 20 December 2022 through 21 December 2022; Conference code: 195835}
}

@CONFERENCE{Chhabra2022,
	author = {Chhabra, Anusha and Vishwakarma, Dinesh Kumar},
	title = {Fuzzy and Machine learning Classifiers for Hate Content Detection: A Comparative Analysis},
	year = {2022},
	journal = {AIST 2022 - 4th International Conference on Artificial Intelligence and Speech Technology},
	doi = {10.1109/AIST55798.2022.10064822},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151283212&doi=10.1109%2fAIST55798.2022.10064822&partnerID=40&md5=9903901747e106ff9f02fcdf4db70836},
	affiliations = {Biometric Research Laboratory Delhi Technological University, Department of Information Technology, Delhi, 110042, India},
	abstract = {Hate content on social media is currently one of the most significant risks, where the victim is either a single individual or a group of people. In the current scenario, online web platforms are one of the most prominent ways to contribute to an individual's opinions and thoughts. Free sharing of ideas on an event or situation also bulks on the web. Information sharing is sometimes a bane for society if primarily used platforms are utilized with some lousy intention to spread hatred for intentionally creating chaos/ confusion among the public. Users take this as an opportunity to spread hate to get some monetary benefits, the detection of which is of paramount importance. This article includes various fuzzy pattern classifiers, including both the top-down and bottom-up algorithms for identifying the hate contents on multiple datasets, compared to the baseline results obtained from diverse machine learning or deep learning classifiers. Moreover, the result shows that fuzzy logic classifiers give decent results when classification is done on hate speech datasets. © 2022 IEEE.},
	author_keywords = {Deep Learning; Fuzzy logic; Hate Speech; Machine Learning},
	keywords = {Classification (of information); Computer circuits; Deep learning; Learning systems; 'current; Comparative analyzes; Content detection; Deep learning; Fuzzy learning; Fuzzy-Logic; Hate speech; Learning classifiers; Machine-learning; Social media; Fuzzy logic},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 4th International Conference on Artificial Intelligence and Speech Technology, AIST 2022; Conference date: 9 December 2022 through 10 December 2022; Conference code: 187320}
}

@CONFERENCE{Mishra2022252,
	author = {Mishra, Varun and Tripathi, Monika},
	title = {Detecting Toxic Comments Using Convolutional Neural Network Approach},
	year = {2022},
	journal = {Proceedings - 2022 14th IEEE International Conference on Computational Intelligence and Communication Networks, CICN 2022},
	pages = {252 – 255},
	doi = {10.1109/CICN56167.2022.10008301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146833054&doi=10.1109%2fCICN56167.2022.10008301&partnerID=40&md5=cc5bee5f250c9ba6e4a54f8ebbaefbc4},
	affiliations = {Shri Krishna University, Dept. of Computer Science & Engineering, Madhya Pradesh, Chhatarpur, India},
	abstract = {In the most significant issue now plaguing social networking platforms and online communities is toxicity identification. Therefore, it is necessary to create an automatic hazardous identification system to block and restrict individual from certain online environments. We introduce multichannel Convolutional Neural Network (CNN) approach in this paper for the detection of toxic comments in a multi-label context. With the help of pre-trained word embeddings, the suggested model produces word vectors. Also, to model input words with long-term dependency, this hybrid model extracts local characteristics using a variety of filters and kernel sizes. Then, to forecast multi-label categories, we integrate numerous channels with three layers as fully linked, normalization, and an output layer. The results of the experiments show that the suggested model performs where we are presenting the fresh modeling CNN approach to detect the toxicity of textual content present on the social media platforms and we categorized the toxicity into positive and negative impact on our society.  © 2022 IEEE.},
	author_keywords = {CNN; Deep learning; Sentiment Analysis; Toxicity},
	keywords = {Convolution; Convolutional neural networks; Deep learning; Social networking (online); Toxicity; Community IS; Convolutional neural network; Deep learning; Multi channel; Multi-labels; On-line communities; Online environments; Sentiment analysis; Social-networking; Toxicity identification; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th IEEE International Conference on Computational Intelligence and Communication Networks, CICN 2022; Conference date: 4 December 2022 through 6 December 2022; Conference code: 186000}
}

@CONFERENCE{Oikawa2022581,
	author = {Oikawa, Yuto and Nakayama, Yuki and Murakami, Koji},
	title = {A Stacking-based Efficient Method for Toxic Language Detection on Live Streaming Chat},
	year = {2022},
	journal = {EMNLP 2022 - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track},
	pages = {581 – 588},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152891593&partnerID=40&md5=4df777d488bfed74b19222bf29de9802},
	affiliations = {Graduate School of Engineering, Kitami Institute of Technology; Rakuten Institute of Technology, Rakuten Group Inc.},
	abstract = {In a live streaming chat on a video streaming service, it is crucial to filter out toxic comments with online processing to prevent users from reading comments in real-time. However, recent toxic language detection methods rely on deep learning methods, which can not be scalable considering inference speed. Also, these methods do not consider constraints of computational resources expected depending on a deployed system (e.g., no GPU resource). This paper presents an efficient method for toxic language detection that is aware of real-world scenarios. Our proposed architecture is based on partial stacking that feeds initial results with low confidence to meta-classifier. Experimental results show that our method achieves a much faster inference speed than BERT-based models with comparable performance. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Learning systems; Video streaming; Computational resources; Deployed systems; Detection methods; Language detection; Learning methods; Live streaming; Online processing; Real- time; Stackings; Video streaming services; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 187661}
}

@ARTICLE{Alkomah2022,
	author = {Alkomah, Fatimah and Ma, Xiaogang},
	title = {A Literature Review of Textual Hate Speech Detection Methods and Datasets},
	year = {2022},
	journal = {Information (Switzerland)},
	volume = {13},
	number = {6},
	doi = {10.3390/info13060273},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131355502&doi=10.3390%2finfo13060273&partnerID=40&md5=519593a383b193769ee2607ee464989c},
	affiliations = {Department of Computer Science, University of Idaho, Moscow, 83844-1010, ID, United States; Department of Information Systems, Princess Nourah bint Abdulrahman University, Riyadh, 11671, Saudi Arabia},
	abstract = {Online toxic discourses could result in conflicts between groups or harm to online communities. Hate speech is complex and multifaceted harmful or offensive content targeting individuals or groups. Existing literature reviews have generally focused on a particular category of hate speech, and to the best of our knowledge, no review has been dedicated to hate speech datasets. This paper systematically reviews textual hate speech detection systems and highlights their primary datasets, textual features, and machine learning models. The results of this literature review are integrated with content analysis, resulting in several themes for 138 relevant papers. This study shows several approaches that do not provide consistent results in various hate speech categories. The most dominant sets of methods combine more than one deep learning model. Moreover, the analysis of several hate speech datasets shows that many datasets are small in size and are not reliable for various tasks of hate speech detection. Therefore, this study provides the research community with insights and empirical evidence on the intrinsic properties of hate speech and helps communities identify topics for future work. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {hate speech datasets; hate speech detection; hate speech methods; literature review},
	keywords = {Deep learning; Speech recognition; Content analysis; Detection methods; Detection system; Hate speech dataset; Hate speech detection; Hate speech method; Literature reviews; Machine learning models; Speech detection; Textual features; Speech},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 87; All Open Access, Gold Open Access}
}

@CONFERENCE{Gongane2022,
	author = {Gongane, Vaishali U. and Munot, Mousami V. and Anuse, Alwin},
	title = {Feature Representation Techniques for Hate Speech Detection on Social Media: A Comparative Study},
	year = {2022},
	journal = {2022 International Conference on Signal and Information Processing, IConSIP 2022},
	doi = {10.1109/ICoNSIP49665.2022.10007458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146917908&doi=10.1109%2fICoNSIP49665.2022.10007458&partnerID=40&md5=abe7a8942fc9013479b476826c29001c},
	affiliations = {Pune Institute of Computer Technology, SPPU, Dept. of E&tc SCTR's, Pune, India; PVG'sCOET&GKPIOM, Pune, India; School of Ece, Dr. Vishwanath Karad MIT-WPU, Pune, India},
	abstract = {Past decade has shown an overwhelming use of social media. Inspite of multi-fold benefits of using social media platforms, it is being misused due to increasing prevalence of inappropriate content in form of hate speech and abusive language shared on these platforms. Hate speech content is one such form of content that has shown dramatic increase in recent years. Automated techniques like AI and NLP have reported significant performance in detection of hate speech content. In order to extract the textual properties from online content that help in the detection of hate speech, feature extraction and representation using NLP are essential. There is an increasing trend in academia and industry to the use of pretrained neural network language models for hate speech and offensive content detection. This paper presents the performance of important feature extraction techniques: TD-IDF, GloVe, FastText and BERT for binary classification and multiclass classification of hate speech with Convolutional Neural Network (CNN) architecture as the base network for all the techniques.  © 2022 IEEE.},
	author_keywords = {BERT; FastText; GloVe; Hate Speech; TF-IDF},
	keywords = {Convolutional neural networks; Extraction; Natural language processing systems; Social networking (online); Speech recognition; BERT; Fasttext; Feature representation; Glove; Hate speech; Performance; Representation techniques; Social media; Speech content; TF-IDF; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Signal and Information Processing, IConSIP 2022; Conference date: 26 August 2022 through 27 August 2022; Conference code: 185996}
}

@CONFERENCE{Madhura2022,
	author = {Madhura, G.K. and Parameshachari, B.D. and Pareek, Piyush Kumar},
	title = {Hate Speech Detection using CSO based Polynomial Network using Twitter},
	year = {2022},
	journal = {4th International Conference on Emerging Research in Electronics, Computer Science and Technology, ICERECT 2022},
	doi = {10.1109/ICERECT56837.2022.10059728},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150679470&doi=10.1109%2fICERECT56837.2022.10059728&partnerID=40&md5=0f5c50a857636091bf8eb02faad5cc91},
	affiliations = {Nitte Meenakshi Institute of Technology, Department of Artificial Intelligence and Machine Learning, Bengaluru, India; Nitte Meenakshi Institute of Technology, Department of Electronics and Communications Engineering, Bengaluru, India},
	abstract = {The power of social media as a catalyst for societal transformation is now unrivalled. What happens in one part of the world has repercussions in other parts of the world. This is because the vast quantities of data produced by these platforms may be instantly disseminated to any part of the globe. To make cyber space as welcoming and productive as feasible for all users, developers of these platforms must overcome several obstacles. However, provocative speech and hate speech have emerged as major problems in recent years. The scale of this issue is so large that it cannot be solved by coordinated teamwork alone, no matter how hard people try. Actually, there is a need for the development of an automated approach that can identify and eliminate nasty and insulting remarks before they can do any damage. This paper offers a novel Deep Learning-based Hate Speech Detection Scheme (DL-HSDS) to identify hate speech in Twitter data. Even though there are a lot of HSDS methods available, many of them suffer from insufficient feature learning and poor dataset management, both of which negatively impact attack detection precision. Therefore, to improve detection accuracy, the suggested module integrates the Cuckoo Search Optimization algorithm (CSO) with the (SDPN); CSO picks the optimum features in the datasets, and SDPN categorises the data as hate or normal. The suggested model, which employs the tweet text with CSO to imprisonment the tweets' outperforms the previous models. © 2022 IEEE.},
	author_keywords = {Cuckoo Search Optimization; Hate Speech Finding System; Social-Media; Stacked-Deep Polynomial Network; Twitter data},
	keywords = {Feature extraction; Optimization; Social networking (online); Space platforms; Speech recognition; Cuckoo search optimization; Cuckoo searches; Hate speech finding system; Optimization algorithms; Polynomial networks; Search optimization; Social media; Speech detection; Stacked-deep polynomial network; Twitter data; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th International Conference on Emerging Research in Electronics, Computer Science and Technology, ICERECT 2022; Conference date: 26 December 2022 through 27 December 2022; Conference code: 187203}
}

@CONFERENCE{Kumari2022575,
	author = {Kumari, Kirti and Singh, Jyoti Prakash},
	title = {Machine Learning Approach for Hate Speech and Offensive Content Identification in English and Indo Aryan Code-Mixed Languages},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3395},
	pages = {575 – 583},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146727514&partnerID=40&md5=4805416e0d9d39e88f459fcd7c2cd9ea},
	affiliations = {Indian Institute of Information Technology Ranchi, Jharkhand, Ranchi, India; National Institute of Technology Patna, Bihar, Patna, India},
	abstract = {In current times, social media is the most widely used platform, and everyone has the right to express their speculations, ideas and thoughts. In such a case, it is often seen that hate speech and offensive contents are spreading like wildfire, making a detrimental impact on the world. It is important to identify and eradicate such offensive content from social media. This paper is a contribution to the Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC) 2022 shared task by the AI_ML_IIITRanchi team. We experimented with machine learning models to detect hate speech and offensive content in all three code-mixed languages English, German and Marathi as provided. Our experimental results show that a Logistic Regression, Support Vector Machine and Random Forest classifier can achieve good results for multilingual hate speech and offensive content identification. Overall, our team participated on all the tasks and ranked 3rd,5thand7th on Marathi C, Marathi B and Marathi A tasks respectively. Our team ranked 8th and 9th on ICHCL-Multiclass and ICHCL-Binary class shared tasks, respectively. © 2022 Copyright for this paper by its authors.},
	author_keywords = {HASOC; Logistic Regression; Machine Learning; Random Forest; Support Vector Machine},
	keywords = {Decision trees; Learning systems; Random forests; Social networking (online); Support vector regression; 'current; Content identifications; HASOC; Logistics regressions; Machine learning approaches; Machine learning models; Machine-learning; Random forests; Social media; Support vectors machine; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783}
}@ARTICLE{Isaac2022125,
	author = {Isaac, Akileng and Kumar, Raju and Bhat, Aruna},
	title = {Hate Speech Detection Using Machine Learning Techniques},
	year = {2022},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {840},
	pages = {125 – 135},
	doi = {10.1007/978-981-16-9012-9_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128668796&doi=10.1007%2f978-981-16-9012-9_11&partnerID=40&md5=c90002e053b4b3bbd3bfef3c5543d4e4},
	affiliations = {Delhi Technological University, Delhi, India},
	abstract = {Hate speech is an issue to most governments and the public’s concern due to the increased emergence of different social media applications and the increasing use of such media to disseminate hate speech to individuals or groups of persons, communities, or race. Therefore, without detection and hate speech analysis, it is impossible to believe that there is not any malicious information on social media. This paper strives to provide a survey of hate speech detection using different approaches and their comparisons while focusing on aspects like machine learning models, different features put to use, and datasets. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Clustering; Deep learning; Hate speech; Performance measures; Supervised learning; Unsupervised learning},
	keywords = {Deep learning; Social networking (online); Speech recognition; Supervised learning; Unsupervised learning; Clusterings; Community OR; Deep learning; Hate speech; Machine learning models; Machine learning techniques; Media application; Performance measure; Social media; Speech detection; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd International Conference on Sustainable Advanced Computing, ICSAC 2021; Conference date: 5 March 2021 through 6 March 2021; Conference code: 276099}
}

@CONFERENCE{Anjum2022,
	author = {Anjum and Katarya, Rahul},
	title = {Exploring Bioinspired Feature Engineering Technique for Online Hate Speech Detection},
	year = {2022},
	journal = {2022 International Conference for Advancement in Technology, ICONAT 2022},
	doi = {10.1109/ICONAT53423.2022.9726098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127607226&doi=10.1109%2fICONAT53423.2022.9726098&partnerID=40&md5=f368bc04aa1f8f19de1261e66e2a7351},
	affiliations = {Computer Science and Engineering, Delhi Technological University, New Delhi, India},
	abstract = {The spreading of hate speech and toxicity on social media and other online platforms has increased severely in the past decade. In the current scenario also, when the whole world is suffering with outspread of COVID-19 online hate speech spreading more than before. The spread of such hate can jeopardize the mental and physical health of many people and is thus necessary to stop its spread on online social media. This paper aims to explore bioinspired algorithms like PSO and GA to detect online hate speech on social media and other online platforms. We explore the hybrid feature selection approach to select valuable and meaningful features from the hate speech dataset to classify between hate and not hate posts efficiently. Our experiments indicate the random behavior of Particle Swarm Optimization and Genetic Algorithm and the decrease in accuracy when applied individually to the experiments. The proposed hybrid approach gives the comparative results as TF-IDF when applied with the baseline machine learning models.  © 2022 IEEE.},
	author_keywords = {Genetic Algorithm (GA); Machine Learning; Natural Language Processing; Online Hate Speech (OHS); Particle Swarm Optimization (PSO)},
	keywords = {Classification (of information); E-learning; Feature extraction; Learning algorithms; Machine learning; Natural language processing systems; Particle swarm optimization (PSO); Social networking (online); Speech; Speech recognition; Feature engineerings; Genetic algorithm; Machine-learning; Online hate speech; Online platforms; Optimization and genetic algorithms; Particle swarm genetic algorithms; Particle swarm optimization; Particle swarm optimization algorithm; Social media; Genetic algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 International Conference for Advancement in Technology, ICONAT 2022; Conference date: 21 January 2022 through 22 January 2022; Conference code: 177711}
}

@ARTICLE{Dhanya2022687,
	author = {Dhanya, L.K. and Balakrishnan, Kannan},
	title = {Comparative Performance of Machine Learning Algorithms in Detecting Offensive Speech in Malayalam-English Code-Mixed Data},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {427},
	pages = {687 – 696},
	doi = {10.1007/978-981-19-1018-0_59},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136101913&doi=10.1007%2f978-981-19-1018-0_59&partnerID=40&md5=cad6260f4afe8c9186691c677d58ec29},
	affiliations = {Department of Computer Applications, Cochin University of Science and Technology, Kerala, Thrikkakara, India},
	abstract = {Offensive speech identification in social media communication has risen to the top of the priority list for avoiding confrontations and curtailing unwanted behaviour. Hate speech identification becomes difficult in a context, where multilingual speakers fluctuate between various languages, making algorithms built for monolingual corpora inadequate. We intend to undertake a comparative analysis of hate speech in a code-mixed social media text as part of our research. We created a standard Malayalam-English code-mixed dataset that may be utilised to detect hate speech and abuse in this article. We used five machine learning algorithms: support vector machine, logistic regression, K-nearest neighbour, random forest and XGBoost in this study and tuned all the models with hyper-parameters. The study finishes by analysing these five models using different performance metrics and then calculating the various parameters to find the optimum model. XGBoost achieved good results with 80% accuracy and with high precision, recall and F1-score. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Grid search; KNN; Logistic regression; Machine learning; Offensive speech; Random forest; SMOTE; SVM; XGBoost},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International Conference on Advances in Distributed Computing and Machine Learning, ICADCML 2022; Conference date: 15 January 2022 through 16 January 2022; Conference code: 281419}
}

@ARTICLE{Hong-Phuc Vo2022315,
	author = {Hong-Phuc Vo, Hanh and Nguyen, Huy Hoang and Do, Trong-Hop},
	title = {Online Hate Speech Detection on Vietnamese Social Media Texts In Streaming Data},
	year = {2022},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {124},
	pages = {315 – 325},
	doi = {10.1007/978-3-030-97610-1_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130907281&doi=10.1007%2f978-3-030-97610-1_25&partnerID=40&md5=f64896f405a282b4bbe3238121c389af},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {This paper proposes a online hate speech detection system for streaming social media text. A combination of novel preprocessing techniques and state-of-the-art transfer learning model is proposed for social media hate speech detection. The experiment was conducted using the ViHSD dataset. The effectiveness of the proposed preprocessing method is verified as the proposed model achieves a significant improvement over the existing works on ViHDS dataset. An online hate speech detection system that detects and processes online hate speech in real-time was built to consolidate the effectiveness of the proposed system. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Hate speech detection; Natural language processing; Social network text; Streaming data; Transfer learning},
	keywords = {Data transfer; Deep learning; E-learning; Media streaming; Natural language processing systems; Speech; Speech recognition; Deep learning; Detection system; Hate speech detection; Pre-processing techniques; Social media; Social network text; Speech detection; Streaming data; Transfer learning; Vietnamese; Social networking (online)},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{McMillan-Major202211,
	author = {McMillan-Major, Angelina and Paullada, Amandalynne and Jernite, Yacine},
	title = {An Interactive Exploratory Tool for the Task of Hate Speech Detection},
	year = {2022},
	journal = {HCI+NLP 2022 - 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing, Proceedings of the Workshop},
	pages = {11 – 20},
	doi = {10.18653/v1/2022.hcinlp-1.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137542908&doi=10.18653%2fv1%2f2022.hcinlp-1.2&partnerID=40&md5=548bff5ae4cdc9ae3c89a3843fa17b46},
	affiliations = {Department of Linguistics, University of Washington, Seattle, United States; Department of Biomedical Informatics & Medical Education, University of Washington, Seattle, United States; Hugging Face},
	abstract = {With the growth of Automatic Content Moderation (ACM) on widely used social media platforms, transparency into the design of moderation technology and policy is necessary for online communities to advocate for themselves when harms occur. In this work, we describe a suite of interactive modules to support the exploration of various aspects of this technology, and particularly of those components that rely on English models and datasets for hate speech detection, a subtask within ACM. We intend for this demo to support the various stakeholders of ACM in investigating the definitions and decisions that underpin current technologies such that those with technical knowledge and those with contextual knowledge may both better understand existing systems. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Automatic content; Contextual knowledge; Current technology; Existing systems; On-line communities; Social media platforms; Speech detection; Subtask; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing, HCI+NLP 2022; Conference date: 15 July 2022; Conference code: 182130; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Agrawal2022182,
	author = {Agrawal, Tanmay and Chakravarthy, V. Deeban},
	title = {Cyberbullying Detection and Hate Speech Identification using Machine Learning Techniques},
	year = {2022},
	journal = {Proceedings - 2022 2nd International Conference on Interdisciplinary Cyber Physical Systems, ICPS 2022},
	pages = {182 – 187},
	doi = {10.1109/ICPS55917.2022.00041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142852702&doi=10.1109%2fICPS55917.2022.00041&partnerID=40&md5=518d79c1b17493dfdafd1a1c98a862fc},
	affiliations = {SRM Institute of Science and Technology, Computer Science and Engineering, Chennai, India; SRM Institute of Science and Technology, Dept. of Computer Science and Engineering, Chennai, India},
	abstract = {Bullying has been prevalent since the beginning of time, It's just the ways of bullying that have changed over the years, from physical bullying to cyberbullying. According to Williard (2004), there are eight types of cyberbullying such as harassment, denigration, impersonation, etc. It's been around 2 decades since social media sites came into the picture, but there haven't been a lot of effective measures to curb social bullying and it has become one of the alarming issues in recent times.Our paper presents an analytical review of cyberbullying detection approaches and assesses methods to recognize hate speech on social media. We aim to apply traditional supervised classification methods as well as some novel ensemble machine learning techniques using a manually annotated open-source dataset for this purpose. This paper does a comparative study of various Supervised algorithms, including standard, as well as ensemble methods. The evaluations of the result based upon the scores obtained by accuracy shows that Ensemble supervised methods have the potential to perform better than traditional supervised methods.  © 2022 IEEE.},
	author_keywords = {Cyberbullying; Ensemble; Hate Speech; Machine Learning; Natural Language Processing; Super vised},
	keywords = {Classification (of information); Computer crime; Natural language processing systems; Social networking (online); Speech recognition; Supervised learning; Cyber bullying; Ensemble; Hate speech; Language processing; Machine learning techniques; Machine-learning; Natural language processing; Natural languages; Social media; Super vised; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2nd International Conference on Interdisciplinary Cyber Physical Systems, ICPS 2022; Conference date: 9 May 2022 through 10 May 2022; Conference code: 184272}
}

@ARTICLE{Markov20223,
	author = {Markov, Ilia and Gevers, Ine and Daelemans, Walter},
	title = {An Ensemble Approach for Dutch Cross-Domain Hate Speech Detection},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13286 LNCS},
	pages = {3 – 15},
	doi = {10.1007/978-3-031-08473-7_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133021806&doi=10.1007%2f978-3-031-08473-7_1&partnerID=40&md5=73354d9b583d7efb2ad0b42c0cb3f57c},
	affiliations = {CLTL, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; CLiPS, University of Antwerp, Antwerp, Belgium},
	abstract = {Over the past years, the amount of online hate speech has been growing steadily. Among multiple approaches to automatically detect hateful content online, ensemble learning is considered one of the best strategies, as shown by several studies on English and other languages. In this paper, we evaluate state-of-the-art approaches for Dutch hate speech detection both under in-domain and cross-domain hate speech detection conditions, and introduce a new ensemble approach with additional features for detecting hateful content in Dutch social media. The ensemble consists of the gradient boosting classifier that incorporates state-of-the-art transformer-based pre-trained language models for Dutch (i.e., BERTje and RobBERT), a robust SVM approach, and additional input information such as the number of emotion-conveying and hateful words, the number of personal pronouns, and the length of the message. The ensemble significantly outperforms all the individual models both in the in-domain and cross-domain hate speech detection settings. We perform an in-depth error analysis focusing on the explicit and implicit hate speech instances, providing various insights into open challenges in Dutch hate speech detection and directions for future research. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Cross-domain; Dutch; Ensemble; Hate speech},
	keywords = {Conveying; Speech recognition; Condition; Cross-domain; Dutch; Ensemble; Ensemble approaches; Ensemble learning; Hate speech; Social media; Speech detection; State-of-the-art approach; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 27th International Conference on Applications of Natural Language to Information Systems, NLDB 2022; Conference date: 15 June 2022 through 17 June 2022; Conference code: 279519}
}

@CONFERENCE{Sokolova2022497,
	author = {Sokolova, Zuzana and Stas, Jan and Hladek, Daniel},
	title = {An Introduction to Detection of Hate Speech and Offensive Language in Slovak},
	year = {2022},
	journal = {Proceedings - International Conference on Advanced Computer Information Technologies, ACIT},
	pages = {497 – 501},
	doi = {10.1109/ACIT54803.2022.9913104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141164517&doi=10.1109%2fACIT54803.2022.9913104&partnerID=40&md5=da6b9aacc71bf43eb19a77073a6b9f83},
	affiliations = {Technical University of Košice, Faculty of Electrical Engineering and Informatics, Department of Electronics and Multimedia Communications, Košice, Slovakia},
	abstract = {The paper introduces a very current topic in the field of natural language processing oriented to the automatic detection of hate speech and offensive language performed in the Slovak language. In this work, we describe the creation and processing database of short texts composed of posts and comments written in Slovak and published on social media. The proposed approach is based on sentiment analysis and implementing a tool for detecting hate speech using a convolutional neural network with elements of a recursive neural network, applied to a created database of comments. We achieved 61.32% detection accuracy only on a small set of training data balanced in the number of positive, neutral, and negative sentiments. © 2022 IEEE.},
	author_keywords = {hate speech; natural language processing; neural networks; offensive language; sentiment analysis},
	keywords = {Convolutional neural networks; Speech recognition; 'current; Automatic Detection; Hate speech; Language processing; Natural language processing; Natural languages; Neural-networks; Offensive languages; Sentiment analysis; Slovak languages; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 12th International Conference on Advanced Computer Information Technologies, ACIT 2022; Conference date: 26 September 2022 through 28 September 2022; Conference code: 183484}
}

@ARTICLE{Kwan-Loo202286339,
	author = {Kwan-Loo, Kevin B. and Ortiz-Bayliss, Jose C. and Conant-Pablos, Santiago E. and Terashima-Marin, Hugo and Rad, P.},
	title = {Detection of Violent Behavior Using Neural Networks and Pose Estimation},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {86339 – 86352},
	doi = {10.1109/ACCESS.2022.3198985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136736532&doi=10.1109%2fACCESS.2022.3198985&partnerID=40&md5=8d03b888e336146bed63bb2bd42bca5f},
	affiliations = {School of Engineering and Sciences, Tecnológico de Monterrey, Monterrey, 64849, Mexico; Department of Computer Science, The University of Texas at San Antonio, San Antonio, 78249, TX, United States},
	abstract = {Regarding safety and security, felonies and crimes with physical violence remain a significant problem worldwide. Some solutions for pedestrian safety are guards, police car patrolling, sensors, and security cameras. Nonetheless, these methods react only when the crime takes place. In the worst cases, the damage may be irreversible when it has already occurred. Therefore, numerous methods based on Artificial Intelligence have been proposed to solve this problem. Many approaches to detect violent behavior and action recognition rely on 3D convolutional neural networks (3D-CNNs), spatio-temporal models, long short-term memory networks, pose estimation, among other implementations. However, these approaches work in a limited fashion and have not been adapted to uncontrolled environments. Thus, a significant contribution from this work is the development of an innovative solution model capable of detecting violent behavior. This approach focuses on pedestrian detection, tracking, pose estimation, and neural networks to predict pedestrian behavior in video frames. Our proposal uses a time window frame to extract joint angles, given by the pose estimation algorithm, as features for classifying behavior. Another significant contribution of this work is the creation of a new database, Kranok-NV, with a total of 3,683 normal and violent videos. This database was used to train and test the solution model. For the evaluation, we designed a protocol using 10-fold cross-validation. We obtained an accuracy slightly above 98% on the Kranok-NV database with the implemented solution model. Although the proposed solution model detects violent and normal behavior, it can be easily extended to classify other types of behavior.  © 2022 IEEE.},
	author_keywords = {computer vision; frame buffer; neural networks; pedestrian detection; pose estimation; tracking; Violent behavior},
	keywords = {Behavioral research; Computer vision; Database systems; Feature extraction; Gesture recognition; Network security; Neural networks; Pedestrian safety; Behavioral science; Features extraction; Frame buffer; Neural-networks; Pedestrian detection; Pose-estimation; Security; Tracking; Violent behavior; Cameras},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Kumar2022,
	author = {Kumar, Anuj},
	title = {A Study: Hate Speech and Offensive Language Detection in Textual Data by Using RNN, CNN, LSTM and BERT Model},
	year = {2022},
	journal = {Proceedings - 2022 6th International Conference on Intelligent Computing and Control Systems, ICICCS 2022},
	doi = {10.1109/ICICCS53718.2022.9788347},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133175304&doi=10.1109%2fICICCS53718.2022.9788347&partnerID=40&md5=aa613b36cd253cf855858768ffca8f0a},
	affiliations = {Gla University, Department of Computer Engineering and Applications, Mathura, India},
	abstract = {The issue of offensive speech on social networking platforms is widespread, or like face book and twitter website is dealing with it. Several approaches for intent-based text categorization have been investigated. Each technique has advantages and disadvantages depending on the type of goal, the dimension of the facts collection, the highest reach of content, and so on. Various ways for detecting dislike and incitement to hatred have been published in the literature. The primary objective of paper is to give a approximate investigation of several method for detecting hateful content and abusive content. Recurrent neural networks (RNN), convolutional neural networks (CNN), long short-term memory (LSTM), and bidirectional encoder representations from transformers are among the approaches used (BERT). The impact of class weighting methods on the efficacy of deep learning techniques was investigated. Our research shows that the or before BERT model exceed another method including both un weighted and weighted offensive prose allocation. In terms of foul language categorization, the RNN and CNN models beat every alternate methods in both un weighted and weighted cases. It was discovered that the class weighting strategy significantly improved the grading precision of all four hate speech models. © 2022 IEEE.},
	author_keywords = {convolutional neural networks; Deep learning model; hate speech detection; long short-term memory; Recurrent neural networks},
	keywords = {Brain; Convolution; Convolutional neural networks; Deep neural networks; Grading; Learning systems; Speech recognition; Text processing; Convolutional neural network; Deep learning model; Hate speech detection; Language detection; Learning models; Offensive languages; Social-networking; Speech detection; Text categorization; Textual data; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 6th International Conference on Intelligent Computing and Control Systems, ICICCS 2022; Conference date: 25 May 2022 through 27 May 2022; Conference code: 179922}
}

@CONFERENCE{Jemima20221274,
	author = {Jemima, P. Preethy and Majumder, Bishop Raj and Ghosh, Bibek Kumar and Hoda, Farazul},
	title = {Hate Speech Detection using Machine Learning},
	year = {2022},
	journal = {7th International Conference on Communication and Electronics Systems, ICCES 2022 - Proceedings},
	pages = {1274 – 1277},
	doi = {10.1109/ICCES54183.2022.9835776},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136322127&doi=10.1109%2fICCES54183.2022.9835776&partnerID=40&md5=d2184e3cd6350f2da34e3d4e4b72642c},
	affiliations = {Srm Institute of Science and Technology, Ramapuram Campus, Department of Computer Science and Engineering, Tamil Nadu, Chennai, India},
	abstract = {A lot of methods have already been created for the automation of hate speech detection online. There are two elements to this process: identifying the qualities that these terms utilize to target a certain group and classifying textual material as hate or non-hate speech. Due to time restraints, research efforts are initiated on the latter issue in this project. For this reason, detecting hate speech is a more challenging endeavor, as our research of the language used in typical datasets reveals that hate speech lacks distinctive, discriminatory characteristics. Deep neural network topologies are very useful for capturing the meaning of hate speech and are thus proposed as feature extractors. Data from social media sites such as Twitter are used to test the effectiveness of these procedures, and they reveal a 6 percentage point improvement in macro-average F1 or a 9 percent improvement for content that has been labeled as hateful, respectively.  © 2022 IEEE.},
	author_keywords = {ANNs; Back Propagation Neural Network; LSTN; Machine Learning; NLP; Random Forest; RNN; Sentiment Analysis; Text mining},
	keywords = {Backpropagation; Decision trees; Deep neural networks; Learning systems; Random forests; Social networking (online); Speech recognition; ANN; Back-propagation neural networks; Detection online; LSTN; Machine-learning; Random forests; RNN; Sentiment analysis; Speech detection; Text-mining; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 7th International Conference on Communication and Electronics Systems, ICCES 2022; Conference date: 22 June 2022 through 24 June 2022; Conference code: 181470}
}

@CONFERENCE{Chakraborty20221874,
	author = {Chakraborty, Souvic and Dutta, Parag and Roychowdhury, Sumegh and Mukherjee, Animesh},
	title = {CRUSH: Contextually Regularized and User anchored Self-supervised Hate speech Detection},
	year = {2022},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2022 - Findings},
	pages = {1874 – 1886},
	doi = {10.18653/v1/2022.findings-naacl.144},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137364478&doi=10.18653%2fv1%2f2022.findings-naacl.144&partnerID=40&md5=116311d09fe33b540f846054d6c2cd97},
	affiliations = {Indian Institute of Science (IISc), KA, Bangalore, 560012, India; Indian Institute of Technology (IIT), WB, Kharagpur, 721302, India},
	abstract = {The last decade has witnessed a surge in the interaction of people through social networking platforms. While there are several positive aspects of these social platforms, their proliferation has led them to become the breeding ground for cyber-bullying and hate speech. Recent advances in NLP have often been used to mitigate the spread of such hateful content. Since the task of hate speech detection is usually applicable in the context of social networks, we introduce CRUSH, a framework for hate speech detection using User Anchored selfsupervision and contextual regularization. Our proposed approach secures ˜ 1-12% improvement in test set metrics over best performing previous approaches on two types of tasks and multiple popular English language social networking datasets. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.},
	keywords = {Computational linguistics; Natural language processing systems; Breeding grounds; Cyber bullying; English languages; Regularisation; Social-networking; Speech detection; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2022 Findings of the Association for Computational Linguistics: NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182081; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Goel202234,
	author = {Goel, Divyam and Sharma, Raksha},
	title = {Leveraging Dependency Grammar for Fine-Grained Offensive Language Detection using Graph Convolutional Networks},
	year = {2022},
	journal = {SocialNLP 2022 - 10th International Workshop on Natural Language Processing for Social Media, Proceedings of the Workshop},
	pages = {34 – 43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139172849&partnerID=40&md5=240e352747426aefc8f380ae1af5d302},
	affiliations = {Indian Institute of Technology Roorkee, Roorkee, India},
	abstract = {The last few years have witnessed an exponential rise in the propagation of offensive text on social media. Identification of this text with high precision is crucial for the well-being of society. Most of the existing approaches tend to give high toxicity scores to innocuous statements (e.g., “I am a gay man”). These false positives result from over-generalization on the training data where specific terms in the statement may have been used in a pejorative sense (e.g., “gay”). Emphasis on such words alone can lead to discrimination against the classes these systems are designed to protect. In this paper, we address the problem of offensive language detection on Twitter, while also detecting the type and the target of the offense. We propose a novel approach called SyLSTM, which integrates syntactic features in the form of the dependency parse tree of a sentence and semantic features in the form of word embeddings into a deep learning architecture using a Graph Convolutional Network. Results show that the proposed approach significantly outperforms the state-of-the-art BERT model with orders of magnitude fewer number of parameters. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Convolution; Deep learning; Social networking (online); Trees (mathematics); Convolutional networks; Dependency grammar; Exponentials; False positive; Fine grained; High-precision; Language detection; Offensive languages; Social media; Well being; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 10th International Workshop on Natural Language Processing for Social Media, SocialNLP 2022; Conference date: 14 July 2022 through 15 July 2022; Conference code: 182690}
}

@CONFERENCE{Wang2022768,
	author = {Wang, Jianfeng},
	title = {Deep Neural Networks for Detecting Hate Speech},
	year = {2022},
	journal = {2022 IEEE 2nd International Conference on Data Science and Computer Application, ICDSCA 2022},
	pages = {768 – 772},
	doi = {10.1109/ICDSCA56264.2022.9988324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146371073&doi=10.1109%2fICDSCA56264.2022.9988324&partnerID=40&md5=2d04ea1afe5c0095eebf4ecdca852945},
	affiliations = {Delaware State University, Division of Computer Science, Delaware, 19901, United States},
	abstract = {With increased social media activity, hate speech on the Internet has become increasingly prevalent. It is a hazardous and damaging form of internet content that targets a group or individual based on their religion, race, or sexual orientation. As a result, it has garnered increasing attention from researchers. This article will examine current research trends, data sources, and methodologies and recommend future study directions. The subject of hate speech was determined at the start of 2020, and it includes attacks on minorities, religion, women, the general election agenda, and politics. Individuals have experimented with various methodologies and models and discovered several characteristics that fulfill the exclusion requirements. However, these methodologies and features do not imply that they will perform well in detecting hatred. The data collection, selected features, number of categories, and mutually exclusive categories all significantly impact the classification performance of hate speech. © 2022 IEEE.},
	author_keywords = {data source; Internet; Neural Network},
	keywords = {'current; Data methodology; Data-source; Group-based; Individual-based; Internet content; Neural-networks; Research trends; Sexual orientations; Social media; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE International Conference on Data Science and Computer Application, ICDSCA 2022; Conference date: 28 October 2022 through 30 October 2022; Conference code: 185682}
}

@CONFERENCE{Hajibabaee202292,
	author = {Hajibabaee, Parisa and Malekzadeh, Masoud and Ahmadi, Mohsen and Heidari, Maryam and Esmaeilzadeh, Armin and Abdolazimi, Reyhaneh and Jones, James H Jr},
	title = {Offensive Language Detection on Social Media Based on Text Classification},
	year = {2022},
	journal = {2022 IEEE 12th Annual Computing and Communication Workshop and Conference, CCWC 2022},
	pages = {92 – 98},
	doi = {10.1109/CCWC54503.2022.9720804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127706091&doi=10.1109%2fCCWC54503.2022.9720804&partnerID=40&md5=064336b67d72a47b4c6b5ee19418956d},
	affiliations = {University of Massachusetts at Lowell, United States; Arizona State University, United States; George Mason University, United States; University of Nevada Las Vegas, United States; Syracuse University, United States},
	abstract = {There is a concerning rise of offensive language on the content generated by the crowd over various social platforms. Such language might bully or hurt the feelings of an individual or a community. Recently, the research community has investigated and developed different supervised approaches and training datasets to detect or prevent offensive monologues or dialogues automatically. In this study, we propose a model for text classification consisting of modular cleaning phase and tokenizer, three embedding methods, and eight classifiers. Our experiments shows a promising result for detection of offensive language on our dataset obtained from Twitter. Considering hyperparameter optimization, three methods of AdaBoost, SVM and MLP had highest average of F1-score on popular embedding method of TF-IDF. © 2022 IEEE.},
	author_keywords = {Machine learning; Offensive language detection; Social media; Text mining},
	keywords = {Adaptive boosting; Classification (of information); Support vector machines; Text processing; Embedding method; Language detection; Modulars; Offensive language detection; Offensive languages; Research communities; Social media; Text classification; Tokenizer; Training dataset; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42; Conference name: 12th IEEE Annual Computing and Communication Workshop and Conference, CCWC 2022; Conference date: 26 January 2022 through 29 January 2022; Conference code: 177781}
}

@ARTICLE{Mehmood2022187,
	author = {Mehmood, Qasim and Kaleem, Anum and Siddiqi, Imran},
	title = {Islamophobic Hate Speech Detection from Electronic Media Using Deep Learning},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1543 CCIS},
	pages = {187 – 200},
	doi = {10.1007/978-3-031-04112-9_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128899879&doi=10.1007%2f978-3-031-04112-9_14&partnerID=40&md5=33dad11a87f6c4bfa0c5614a3e507413},
	affiliations = {Department of Computer Science, Bahria University, Islamabad, 44000, Pakistan},
	abstract = {Islamophobic hate speech is the indiscriminate negative attitude and behavior towards Muslims and Islam. Speech indicating prejudice against Muslims has negatively impacted the perceptions of Islam. Online platforms like Twitter have carved out policies to stop users from promoting Islamophobic hate speech, however, such content still exists which causes problems for Muslim communities globally. Hence, it becomes pivotal to find solutions to eradicate such speech from social media platforms. This paper presents an effective methodology for Islamophobic hate speech identification in online tweets using deep learning techniques. The proposed technique relies on feature extraction using a one-dimensional Convolutional Neural Network and classification using Long Short-Term Memory network based classifier. The proposed technique is validated on a dataset comprising of 1290 pre-processed online tweets and an accuracy of more than 90% is reported. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Bi-directional Long Short-Term Memory (LSTM); Convolution Neural Networks (CNN); Hate speech; Islamophobia; Word embeddings},
	keywords = {Brain; Convolution; E-learning; Social networking (online); Speech; Speech recognition; Bi-directional; Bi-directional long short-term memory; Convolution neural network; Electronic medium; Embeddings; Hate speech; Islamophobia; Speech detection; Word embedding; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 5th Mediterranean Conference on Pattern Recognition and Artificial Intelligence, MedPRAI 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 276749}
}

@ARTICLE{Mutanga2022331,
	author = {Mutanga, Raymond T and Naicker, Nalindren and Olugbara, Oludayo O},
	title = {Detecting Hate Speech on Twitter Network using Ensemble Machine Learning},
	year = {2022},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {13},
	number = {3},
	pages = {331 – 339},
	doi = {10.14569/IJACSA.2022.0130341},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129835296&doi=10.14569%2fIJACSA.2022.0130341&partnerID=40&md5=733c440a1e83b43d903840921d56f205},
	affiliations = {Department of Information Technology, Durban University of Technology, Durban, South Africa; Department of Information Systems, Durban University of Technology, Durban, South Africa},
	abstract = {Twitter is habitually exploited now-a-days to propagate torrents of hate speeches, misogynistic, and misandry tweets that are written in slang. Machine learning methods have been explored in manifold studies to address the inherent challenges of hate speech detection in online spaces. Nevertheless, language has subtleties that can make it stiff for machines to adequately comprehend and disambiguate the semantics of words that are heavily dependent on the usage context. Deep learning methods have demonstrated promising results for automatic hate speech detection, but it requires a significant volume of training data. Classical machine learning methods suffer from the innate problem of high variance that in turn affects the performance of hate speech detection systems. This study presents a voting ensemble machine learning method that harnesses the strengths of logistic regression, decision trees, and support vector machines for the automatic detection of hate speech in tweets. The method was evaluated against ten widely used machine learning methods on two standard tweet data sets using the famous performance evaluation metrics to achieve an improved average F1-score of 94.2%. © 2022. International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {Classical learning; Deep learning; Ensemble learning; Hate speech; Social media; Twitter network; Voting ensemble},
	keywords = {Decision trees; Deep learning; Logistic regression; Semantics; Speech; Speech recognition; Support vector machines; Classical learning; Deep learning; Ensemble learning; Hate speech; Machine learning methods; Machine-learning; Social media; Speech detection; Twitter network; Voting ensemble; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Jamil2022365,
	author = {Jamil, Raihan and Khan, Mohammad Abdullah Al Nayeem and Anwar, Md Musfique},
	title = {Topic Oriented Hate Speech Detection},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {420 LNNS},
	pages = {365 – 375},
	doi = {10.1007/978-3-030-96305-7_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126372206&doi=10.1007%2f978-3-030-96305-7_34&partnerID=40&md5=91c818eaaa237a22b2fdc7cc98d39826},
	affiliations = {Computer Science and Engineering Department, Jahangirnagar University, Savar, Bangladesh},
	abstract = {Online social media is a very popular platform nowadays where people can easily make virtual connections with each other and can freely express their opinions and interests on various topics over time. The ability to freely express oneself often results in the spread of hate speech in the virtual world. Thus, it is very important to detect automatically hate speech to reduce its spread on social media. Most of the existing research works in this area paid less attention to the topical hate speech detection. In this paper, we addressed topic-oriented hate speech detection using machine learning classifiers. Experimental results on a real dataset demonstrate the efficacy of the proposed model. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Hate speech; Machine learning; Online social media},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st International Conference on Hybrid Intelligent Systems, HIS 2021 and 17th International Conference on Information Assurance and Security, IAS 2021; Conference date: 14 December 2021 through 16 December 2021; Conference code: 274429}
}

@CONFERENCE{Bhat20222128,
	author = {Bhat, Aruna and Adhikari, Surabhi and Jha, Khushi and Sadat, Hazrat Bilal},
	title = {Deep Learning Based Hybrid Word Representation for Detection of Hate Speech},
	year = {2022},
	journal = {2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2022},
	pages = {2128 – 2133},
	doi = {10.1109/ICACITE53722.2022.9823830},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135449061&doi=10.1109%2fICACITE53722.2022.9823830&partnerID=40&md5=8b3d5e35decc33f7ad5df6657a200d22},
	affiliations = {Delhi Technological University, Department of Computer Science and Engineering, India},
	abstract = {In this era of very easy access to information, it has become very easier for anyone to share their ideas, opinions and beliefs. Internet being the most used space for all lets every user share their thoughts with just a click. With a lot of people sharing their ideas and opinions, it is obvious that there can be some dissatisfactions. Internet has witnessed some of the greatest social movements in the history. With smartphones available in every hand, people can join the movement easily and express their opinions. Social movements are drives related to a particular community which gets attention from the entire world. Social media mostly gets polarized into two parts, one in support of the movement and another in opposition of the movement. Machine learning algorithms give us the power to do the analysis of people's sentiment in the internet. Using the power of machine learning and its applications, this paper tries to do the fundamental analysis of which sides the twitter users are leaning to subsequently enable recognizing hate speech. With the help of tweets publicly available, the analysis is done using multiple deep learning algorithms. © 2022 IEEE.},
	author_keywords = {Deep Learning; Machine Learning; Natural Language Understanding; Opinion Mining},
	keywords = {Deep learning; Learning algorithms; Learning systems; Social networking (online); Speech recognition; Deep learning; Machine learning algorithms; Machine-learning; Natural language understanding; Opinion mining; Power; Smart phones; Social media; Social movements; Word representations; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2022; Conference date: 28 April 2022 through 29 April 2022; Conference code: 181064}
}

@CONFERENCE{Panchala20221262,
	author = {Panchala, Geetha Harshini and Sasank, V.V.S. and Adidela, Dory Ratna Harshitha and Yellamma, Pachipala and Ashesh, K. and Prasad, Chitturi},
	title = {HATE SPEECH & OFFENSIVE LANGUAGE DETECTION USING ML &NLP},
	year = {2022},
	journal = {Proceedings - 4th International Conference on Smart Systems and Inventive Technology, ICSSIT 2022},
	pages = {1262 – 1268},
	doi = {10.1109/ICSSIT53264.2022.9716417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127330751&doi=10.1109%2fICSSIT53264.2022.9716417&partnerID=40&md5=26967a160e9b5307653fa1952381d9e3},
	affiliations = {Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, 522502, India},
	abstract = {To restore peace and harmony in this cross-cultural Internet era, it is of utmost importance for every citizen to behave and spread brotherhood. Under the given circumstances of 5G evolution citizens have taken their role onto the internet very seriously thereby most of the netizens spend their time condemning, judging, and trolling other netizens, public figures for that matter. Because of the consequences in an unprejudiced society involving race, gender, or religion, the challenge of automatically detecting hate speech and objectionable language in social media material is critical. However, existing research in this field is mostly focused on several languages, which limits its relevance to certain groups. The use of harsh language on social media platforms, as well as the consequences that this has, has become a serious problem in modern culture. Automatic ways to recognize and deal with this sort of content are necessary due to the large volume of content produced every day. Machine Learning & Natural Language processing has cutting-edge algorithms and classifiers that have benefitted mankind in impossible ways. Hence, our effort in this project is to make use of this impeccable technology to create an efficient system that automatically detects hate speech and offensive language from the Twitter dataset. © 2022 IEEE},
	author_keywords = {Classifiers; English; Hate; Language; Machine Learning; Natural Language Processing; Naïve Bayes; Offensive; Random Forest; Speech; Twitter Data},
	keywords = {5G mobile communication systems; Classification (of information); Decision trees; Natural language processing systems; Random forests; Social networking (online); Speech recognition; English; Hate; Language; Language processing; Machine-learning; Naive bayes; Natural language processing; Natural languages; Offensive; Random forests; Twitter data; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 4th International Conference on Smart Systems and Inventive Technology, ICSSIT 2022; Conference date: 20 January 2022 through 22 January 2022; Conference code: 177665}
}

@CONFERENCE{Putra2022207,
	author = {Putra, Bagas Prakoso and Irawan, Budhi and Setianingsih, Casi and Rahmadani, Annisa and Imanda, Farradita and Fawwas, Izzu Zantya},
	title = {Hate Speech Detection using Convolutional Neural Network Algorithm Based on Image},
	year = {2022},
	journal = {2021 International Seminar on Machine Learning, Optimization, and Data Science, ISMODE 2021},
	pages = {207 – 212},
	doi = {10.1109/ISMODE53584.2022.9742810},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128174775&doi=10.1109%2fISMODE53584.2022.9742810&partnerID=40&md5=5b2222b397b02a775c19025fb2d0f7cf},
	affiliations = {Telkom University, School of Electrical Engineering, Bandung, Indonesia},
	abstract = {Hate speech is words behavior that can cause an attitude of violence and anarchy against other individuals or groups. The internet has become necessary in this day and age, so internet morals need to be considered. However, several parties deviate from using the internet to spread hate speech, such about race, ethnicity, and religion. Nowadays, hate speech detection systems are usually through text but hate speech detection through images tends to be rare. For that reason, this study is aimed to detect whether there is hate speech or not in the selected image. This project uses the Convolutional Neural Network (CNN) algorithm and Deep Learning method to classify the aspect of hate speech contained in an image and recognize any hate speech on the image through the existing text. After this application is developed, the machine learning system can detect some hate speech on an image that contains the text. It achieves about 95.89% accuracy and 94.43% precision. After that, the authors hoped that the authorities could reduce hate speech in the community and follow up more quickly.  © 2022 IEEE.},
	author_keywords = {Convolutional Neural Network (CNN); Deep Learning; Hate Speech; Text Classification},
	keywords = {Character recognition; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Image classification; Learning algorithms; Speech recognition; Text processing; Convolutional neural network; Deep learning; Detection system; Hate speech; Learning methods; Machine learning systems; Neural networks algorithms; Speech detection; Text classification; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 2021 International Seminar on Machine Learning, Optimization, and Data Science, ISMODE 2021; Conference date: 29 January 2022; Conference code: 178272}
}

@CONFERENCE{Sen20224716,
	author = {Sen, Indira and Samory, Mattia and Wagner, Claudia and Augenstein, Isabelle},
	title = {Counterfactually Augmented Data and Unintended Bias: The Case of Sexism and Hate Speech Detection},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {4716 – 4726},
	doi = {10.18653/v1/2022.naacl-main.347},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138414469&doi=10.18653%2fv1%2f2022.naacl-main.347&partnerID=40&md5=263cfc88ebcfa7c35472cc55c1dfcc2d},
	affiliations = {GESIS, Leibniz Institute for the Social Sciences, Germany; RWTH Aachen University, Germany; University of Copenhagen, Denmark},
	abstract = {Counterfactually Augmented Data (CAD) aims to improve out-of-domain generalizability, an indicator of model robustness. The improvement is credited to promoting core features of the construct over spurious artifacts that happen to correlate with it. Yet, over-relying on core features may lead to unintended model bias. Especially, construct-driven CAD-perturbations of core features-may induce models to ignore the context in which core features are used. Here, we test models for sexism and hate speech detection on challenging data: non-hateful and nonsexist usage of identity and gendered terms. On these hard cases, models trained on CAD, especially construct-driven CAD, show higher false positive rates than models trained on the original, unperturbed data. Using a diverse set of CAD-construct-driven and construct-agnostic-reduces such unintended bias. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computer aided design; Core features; Data perturbation; False positive rates; Model bias; Model robustness; Speech detection; Test models; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182070; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{Shibly202259,
	author = {Shibly, F.H.A. and Sharma, Uzzal and Naleer, H.M.M.},
	title = {DETECTING HATE SPEECH THROUGH MACHINE LEARNING},
	year = {2022},
	journal = {Research Notes on Computing and Communication Sciences: Applied Soft Computing: Techniques and Applications},
	pages = {59 – 68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132466814&partnerID=40&md5=2d4d088376b34a4d5fe972e215e56e10},
	affiliations = {Assam Don Bosco University/South Eastern University of Sri Lanka, Sri Lanka; Assam Don Bosco University, Assam, India; South Eastern University of Sri Lanka, Sri Lanka},
	abstract = {Hatred and abusive speeches are identified as huge crime that have been incrementing very recent years, and this has been not only in the specific interaction done face to face but preferably also in the online sharing of information. A considerable number of factors have been contributing to this. There has been a specific study that has well provided a kind of critical overview on the way of detecting such speeches within post or text has been highly evolved over the last few years. However, it has been observed that there are few studies that have been published in detecting hate speech automatically from the perspective of computer science. There is a great way or process with the support of which hate speech can be detected. It has been observed that both the automatic speech recognition and machine learning (ML) have been together complementing each other in the current past, and this has been because both the paradigms are very much deeply ingrained in each other. Therefore, this chapter aims to find out the relationship between hate speech detection and ML and find out the feasible ML algorithms to control hate speeches in social media. It has been observed that there is the implementation of a huge range of several methods of classifying the utilization of the embedding learning for computing all the distances which are semantic in between various parts of the speech which is properly considered to be a specific part of the “othering” narrative. It has also been observed that both the automatic recognition of speech and the ML have been hugely complementing each other in the current past, and this has been just because of the fact that both the paradigms are very much deeply ingrained in each other. © 2022 by Apple Academic Press, Inc.},
	author_keywords = {Hate speech; Long short-term memory; Machine learning; Recurrent neural network; Social media; Worldwide web},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{de Araujo202275,
	author = {de Araujo, Pedro Henrique Luz and Roth, Benjamin},
	title = {Checking HATECHECK: a cross-functional analysis of behaviour-aware learning for hate speech detection},
	year = {2022},
	journal = {NLP-Power 2022 - 1st Workshop on Efficient Benchmarking in NLP, Proceedings of the Workshop},
	pages = {75 – 83},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137704662&partnerID=40&md5=e87a17c6de256e255b4a2593f1ae3ab9},
	affiliations = {University of Vienna, Austria},
	abstract = {Behavioural testing-verifying system capabilities by validating human-designed input-output pairs-is an alternative evaluation method of natural language processing systems proposed to address the shortcomings of the standard approach: computing metrics on held-out data. While behavioural tests capture human prior knowledge and insights, there has been little exploration on how to leverage them for model training and development. With this in mind, we explore behaviour-aware learning by examining several fine-tuning schemes using HATECHECK, a suite of functional tests for hate speech detection systems. To address potential pitfalls of training on data originally intended for evaluation, we train and evaluate models on different configurations of HATECHECK by holding out categories of test cases, which enables us to estimate performance on potentially overlooked system properties. The fine-tuning procedure led to improvements in the classification accuracy of held-out functionalities and identity groups, suggesting that models can potentially generalise to overlooked functionalities. However, performance on held-out functionality classes and i.i.d. hate speech detection data decreased, which indicates that generalisation occurs mostly across functionalities from the same class and that the procedure led to overfitting to the HATECHECK data distribution. © 2022 Association for Computational Linguistics.},
	keywords = {Behavioral research; Classification (of information); Computational linguistics; Knowledge management; Speech recognition; Behavioural tests; Cross-functional; Evaluation methods; Fine tuning; Input-output; Model training; Performance; Prior-knowledge; Speech detection; System capabilities; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 1st Workshop on Efficient Benchmarking in NLP, NLP-Power 2022; Conference date: 26 May 2022; Conference code: 181951}
}

@CONFERENCE{Islam20221349,
	author = {Islam, Mominul and Hossain, Md Sanjid and Akhter, Nasrin},
	title = {Hate Speech Detection Using Machine Learning In Bengali Languages},
	year = {2022},
	journal = {Proceedings - 2022 6th International Conference on Intelligent Computing and Control Systems, ICICCS 2022},
	pages = {1349 – 1354},
	doi = {10.1109/ICICCS53718.2022.9788344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133168885&doi=10.1109%2fICICCS53718.2022.9788344&partnerID=40&md5=3205e56291117e1e0b563befbcf28d21},
	affiliations = {Daffodil International University, Dept. of Cse, Dhaka, Bangladesh},
	abstract = {Hate speech is a common problem in the current time of social media and the internet as it is very easy to be in touch with everything through the internet and social media. Hate speech detection research is not very rare but in terms of Bengali language there are very few works related to hate speech in Bengali language. The proposed research experiment has developed a machine learning based project to detect hate speech from Bengali language data or comments, posts in social media that are in Bengali language. This research work has used 3006 pure Bengali data from social media pages (such as Facebook, YouTube) groups, comment sections of news portals. Further, this research work has categorized them in 0 for non-Hate-Speech and 1 for Hate-Speech to classify the data between non-abusive and abusive data. This research work has used several algorithms to find the best possible result in order to determine whether the sentence is abusive or non-abusive such as Logistic Regression, Naive Bayes, Random Forest, Support Vector Machine, K Nearest Neighbor Classifier. From these algorithms, the best result for detecting non-abusive data is the Random Forest [RF] algorithm, which is 67%. © 2022 IEEE.},
	author_keywords = {Abusive Speech; annotation data; cleaning data; Count Vectorizer; Machine Learning Algorith ms; Term frequency-inverse document frequency [TF-IDF]},
	keywords = {Inverse problems; Logistic regression; Nearest neighbor search; Random forests; Social networking (online); Speech; Support vector machines; Text processing; Abusive speech; Algorith; Annotation data; Cleaning data; Count vectorizer; Machine learning algorith ms; Machine-learning; Term frequency-inverse document frequency; Term frequencyinverse document frequency (TF-IDF); Vectorizer; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 6th International Conference on Intelligent Computing and Control Systems, ICICCS 2022; Conference date: 25 May 2022 through 27 May 2022; Conference code: 179922}
}

@CONFERENCE{Sap20225884,
	author = {Sap, Maarten and Swayamdipta, Swabha and Vianna, Laura and Zhou, Xuhui and Choi, Yejin and Smith, Noah A.},
	title = {Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {5884 – 5906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136328599&partnerID=40&md5=2423b29a8b856764e50364c4c0e5999e},
	affiliations = {Paul G. Allen School of Computer Science, University of Washington, Seattle, WA, United States; Allen Institute for AI, Seattle, WA, United States; Department of Psychology, University of Washington, Seattle, WA, United States; Georgia Institute of Technology, Atlanta, GA, United States},
	abstract = {The perceived toxicity of language can vary based on someone's identity and beliefs, but this variation is often ignored when collecting toxic language datasets, resulting in dataset and model biases. We seek to understand the who, why, and what behind biases in toxicity annotations. In two online studies with demographically and politically diverse participants, we investigate the effect of annotator identities (who) and beliefs (why), drawing from social psychology research about hate speech, free speech, racist beliefs, political leaning, and more. We disentangle what is annotated as toxic by considering posts with three characteristics: anti-Black language, African American English (AAE) dialect, and vulgarity. Our results show strong associations between annotator identity and beliefs and their ratings of toxicity. Notably, more conservative annotators and those who scored highly on our scale for racist beliefs were less likely to rate anti-Black language as toxic, but more likely to rate AAE as toxic. We additionally present a case study illustrating how a popular toxicity detection system's ratings inherently reflect only specific beliefs and perspectives. Our findings call for contextualizing toxicity labels in social variables, which raises immense implications for toxic language annotation and detection. © 2022 Association for Computational Linguistics.},
	keywords = {Social psychology; African American; American English; Case-studies; Detection system; Free speech; Language detection; Model bias; Online studies; Social psychology; Toxicity detection; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 107; Conference name: 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182070}
}

@ARTICLE{Ojo20221007,
	author = {Ojo, Olumide Ebenezer and Ta, Thang-Hoang and Gelbukh, Alexander and Calvo, Hiram and Sidorov, Grigori and Adebanji, Olaronke Oluwayemisi},
	title = {Automatic Hate Speech Detection Using Deep Neural Networks and Word Embedding},
	year = {2022},
	journal = {Computacion y Sistemas},
	volume = {26},
	number = {2},
	pages = {1007 – 1013},
	doi = {10.13053/CyS-26-2-4107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129210092&doi=10.13053%2fCyS-26-2-4107&partnerID=40&md5=78c0364d14874601c6ce8aea5f9fd9b5},
	affiliations = {Instituto Politécnico Nacional, Centro de Investigacion en Computación, Mexico; Dalat University, Lam Dong, Viet Nam},
	abstract = {Hatred spreading through the use of language on social media platforms and in online groups is becoming a well-known phenomenon. By comparing two text representations: bag of words (BoW) and pre-trained word embedding using GloVe, we used a binary classification approach to automatically process user contents to detect hate speech. The Naive Bayes Algorithm (NBA), Logistic Regression Model (LRM), Support Vector Machines (SVM), Random Forest Classifier (RFC) and the one-dimensional Convolutional Neural Networks (1D-CNN) are the models proposed. With a weighted macro-F1 score of 0.66 and a 0.90 accuracy, the performance of the 1D-CNN and GloVe embeddings was best among all the models. © 2022 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {1D-CNN; gloVe; Hate speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Sanoussi2022266,
	author = {Sanoussi, Mahamat Saleh Adoum and Xiaohua, Chen and Agordzo, George K. and Guindo, Mahamed Lamine and Al Omari, Abdullah Mma and Issa, Boukhari Mahamat},
	title = {Detection of Hate Speech Texts Using Machine Learning Algorithm},
	year = {2022},
	journal = {2022 IEEE 12th Annual Computing and Communication Workshop and Conference, CCWC 2022},
	pages = {266 – 273},
	doi = {10.1109/CCWC54503.2022.9720792},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127711157&doi=10.1109%2fCCWC54503.2022.9720792&partnerID=40&md5=ac6408575762c76b0fdecd792b7fedff},
	affiliations = {School of Information Engineering, Huzhou University, Zhejiang, China; School of Mathematics and Big Data, Anhui University of Science and Technology, Anhui, China; College of Biosystems Engineering, Zhejiang University, Hangzhou, China; Abeche Institute of Sciences and Technologies, Department of Electrical Engineering, Abeche, Chad},
	abstract = {Identifying hate speech on social media has become increasingly crucial for society. It has been shown that cyberbul-lying significantly affects the social tranquillity of the Chadian population, mainly in places of conflict. This article aims to detect hate speech for texts written in 'lingua franca', a mix of the local Chadian and French languages. The dataset consists of 14, 000 comments extracted from the most visited Facebook pages and annotated in four categories (hate, offence, insult and neutral) were used for this study. The data were cleaned by Natural Language Processing techniques (NLP) and applied to three word embedding methods such as Word2Vec, Doc2Vec, and Fasttext. Finally, four Machine Learning methods, namely Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbours (KNN), were computed to classify the different categories. The result showed that FastText features representation as input to SVM classifier was the best with 95.4% accuracy for predicting the comment contained insult statement followed by hate statement 93.9%. The result demonstrated our model could be used to detect the hate speech made by Chadians on social media texts. © 2022 IEEE.},
	author_keywords = {Hate speech; Natural language processing; Social media; Text classification; Word embedding},
	keywords = {Classification (of information); Decision trees; Embeddings; Logistic regression; Natural language processing systems; Nearest neighbor search; Speech; Speech recognition; Support vector machines; Text processing; Embedding method; Embeddings; Facebook pages; Hate speech; Language processing techniques; Machine learning algorithms; Machine learning methods; Social media; Text classification; Word embedding; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 12th IEEE Annual Computing and Communication Workshop and Conference, CCWC 2022; Conference date: 26 January 2022 through 29 January 2022; Conference code: 177781}
}

@ARTICLE{Babaeianjelodar2022233,
	author = {Babaeianjelodar, Marzieh and Poorna Prudhvi, Gurram and Lorenz, Stephen and Chen, Keyu and Mondal, Sumona and Dey, Soumyabrata and Kumar, Navin},
	title = {Interpretable and High-Performance Hate and Offensive Speech Detection},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13518 LNCS},
	pages = {233 – 244},
	doi = {10.1007/978-3-031-21707-4_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144390230&doi=10.1007%2f978-3-031-21707-4_18&partnerID=40&md5=d06d016492a48955881e7f332bc27414},
	affiliations = {Yale University, New Haven, 06520, CT, United States; Clarkson University, Potsdam, 13699, NY, United States; Hyderabad, India},
	abstract = {The spread of information through social media platforms can create environments possibly hostile to vulnerable communities and silence certain groups in society. To mitigate such instances, several models have been developed to detect hate and offensive speech. Since detecting hate and offensive speech in social media platforms could incorrectly exclude individuals from social media platforms, which can reduce trust, there is a need to create explainable and interpretable models. Thus, we build an explainable and interpretable high performance model based on the XGBoost algorithm, trained on Twitter data. For unbalanced Twitter data, XGboost outperformed the LSTM, AutoGluon, and ULMFiT models on hate speech detection with an F1 score of 0.75 compared to 0.38 and 0.37, and 0.38 respectively. When we down-sampled the data to three separate classes of approximately 5,000 tweets, XGBoost performed better than LSTM, AutoGluon, and ULMFiT; with F1 scores for hate speech detection of 0.79 vs 0.69, 0.77, and 0.66 respectively. XGBoost also performed better than LSTM, AutoGluon, and ULMFiT in the down-sampled version for offensive speech detection with F1 score of 0.83 vs 0.88, 0.82, and 0.79 respectively. We use Shapley Additive Explanations (SHAP) on our XGBoost models’ outputs to makes it explainable and interpretable compared to LSTM, AutoGluon and ULMFiT that are black-box models. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Hate; Machine learning; Natural language processing; Offensive; Performance; Transparency; XGBoost},
	keywords = {Long short-term memory; Natural language processing systems; Social networking (online); Hate; Language processing; Machine-learning; Natural language processing; Natural languages; Offensive; Performance; Social media platforms; Speech detection; Xgboost; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 24th  International Conference on Human-Computer Interaction,  HCII  2022; Conference date: 26 June 2022 through 1 July 2022; Conference code: 286879}
}

@ARTICLE{De la Peña Sarracén202216,
	author = {De la Peña Sarracén, Gretel Liz and Rosso, Paolo},
	title = {Convolutional Graph Neural Networks for Hate Speech Detection in Data-Poor Settings},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13286 LNCS},
	pages = {16 – 24},
	doi = {10.1007/978-3-031-08473-7_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133005856&doi=10.1007%2f978-3-031-08473-7_2&partnerID=40&md5=d4873de4151c412c8b69a25c69a9a9c2},
	affiliations = {Universitat Politècnica de València, Valencia, Spain; Symanto Research, Valencia, Spain},
	abstract = {Hate speech detection has received a lot of attention in recent years. However, there are still a number of challenges to monitor hateful content in social media, especially in scenarios with few data. In this paper we propose HaGNN, a convolutional graph neural network that is capable of performing an accurate text classification in a supervised way with a small amount of labeled data. Moreover, we propose Similarity Penalty, a novel loss function that considers the similarity among nodes in the graph to improve the final classification. Particularly, our goal is to overcome hate speech detection in data-poor settings. As a result we found that our model is more stable than other state-of-the-art deep learning models with few data in the considered datasets. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Convolutional graph neural networks; Data-poor settings; Hate speech detection},
	keywords = {Classification (of information); Convolution; Convolutional neural networks; Deep learning; Speech recognition; Text processing; Convolutional graph neural network; Data-poor setting; Graph neural networks; Hate speech detection; Labeled data; Loss functions; Social media; Speech detection; State of the art; Text classification; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 27th International Conference on Applications of Natural Language to Information Systems, NLDB 2022; Conference date: 15 June 2022 through 17 June 2022; Conference code: 279519}
}

@CONFERENCE{Krupalija2022,
	author = {Krupalija, Ehlimana and Donko, Dzenana and Supic, Haris},
	title = {Usage of user hate speech index for improving hate speech detection in Twitter posts},
	year = {2022},
	journal = {2022 28th International Conference on Information, Communication and Automation Technologies, ICAT 2022 - Proceedings},
	doi = {10.1109/ICAT54566.2022.9811159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135369842&doi=10.1109%2fICAT54566.2022.9811159&partnerID=40&md5=4dbbadff015dc224c99d736d8810a009},
	affiliations = {University of Sarajevo, Faculty of Electrical Engineering, Sarajevo, Bosnia and Herzegovina},
	abstract = {Social media is an important source of real-world data for sentiment analysis. Hate speech detection models can be trained on data from Twitter and then utilized for content filtering and removal of posts which contain hate speech. This work proposes a new algorithm for calculating user hate speech index based on user post history. Three available datasets were merged for the purpose of acquiring Twitter posts which contained hate speech. Text preprocessing and tokenization was performed, as well as outlier removal and class balancing. The proposed algorithm was used for determining hate speech index of users who posted tweets from the dataset. The preprocessed dataset was used for training and testing multiple machine learning models: k-means clustering without and with principal component analysis, naïve Bayes, decision tree and random forest. Four different feature subsets of the dataset were used for model training and testing. Anomaly detection, data transformation and parameter tuning were used in an attempt to improve classification accuracy. The highest F1 measure was achieved by training the model using a combination of user hate speech index and other user features. The results show that the usage of user hate speech index, with or without other user features, improves the accuracy of hate speech detection.  © 2022 IEEE.},
	author_keywords = {data mining; hate speech detection; natural language processing; sentiment analysis; Twitter data analysis},
	keywords = {Anomaly detection; Balancing; Data mining; Internet of things; K-means clustering; Learning algorithms; Metadata; Principal component analysis; Sentiment analysis; Social networking (online); Speech recognition; Statistical tests; Well testing; Hate speech detection; Language processing; Natural language processing; Natural languages; Sentiment analysis; Speech detection; Training and testing; Twitter data analyse; Twitter posts; User feature; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 28th International Conference on Information, Communication and Automation Technologies, ICAT 2022; Conference date: 16 June 2022 through 18 June 2022; Conference code: 180657}
}

@CONFERENCE{Tanyel20221,
	author = {Tanyel, Toygar and Alkurdi, Besher and Ayvaz, Serkan},
	title = {Linguistic-based Data Augmentation Approach for Offensive Language Detection},
	year = {2022},
	journal = {Proceedings - 7th International Conference on Computer Science and Engineering, UBMK 2022},
	pages = {1 – 6},
	doi = {10.1109/UBMK55850.2022.9919562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141878868&doi=10.1109%2fUBMK55850.2022.9919562&partnerID=40&md5=70973ec44d6fba3a38b6adb0f0770a8b},
	affiliations = {Yildiz Technical University, Department of Computer Engineering, Istanbul, Turkey},
	abstract = {The massive amount of data generated by social media possess a great deal of toxic content that lead to serious content filtering problems including hate speech, cyberbullying and insulting. Offensive content even without profanity may result in psychological and physical harms to, particularly children and sensitive people. As of 2022, Turkey houses 7th largest Twitter community among all countries in terms of the active user size exceeding 16 million users, which represents a high diversity of people considering its population. That said, there is a growing need for a comprehensive and high-quality dataset in Turkish that can be utilized in development of NLP models for robust detection of offensive language usage in social media. Related studies in literature have mostly focused on small, synthetic and label-imbalanced datasets. Machine learning models trained on such datasets tend to favor majority class for accuracy and possess generalizability issues. However, it is challenging to create an unbiased dataset containing hate speech without offensive words, and build an accurate detection model to identify the actual hate speech Tweets. The models may lack sufficient context due to the absence of swear words. Therefore, we propose a data augmentation approach based on data mining methods utilizing the linguistic features of Turkish that can help enhance the generalizability of machine learning models without further human interaction. Furthermore, we evaluated the impact of our comprehensive dataset in detection of offensive language in social media. The NLP models training using the augmented dataset improved the macro average detection accuracy by 7.60% in comparison to the baseline approach.  © 2022 IEEE.},
	author_keywords = {contextual models; cyberbullying; data mining; hate speech; linguistics; offensive language; pre-processing; Social media},
	keywords = {Computer crime; Data mining; Machine learning; Natural language processing systems; Social networking (online); Speech recognition; Contextual modeling; Cyber bullying; Data augmentation; Hate speech; Language detection; Machine learning models; Offensive languages; Pre-processing; Social media; Turkishs; Linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 7th International Conference on Computer Science and Engineering, UBMK 2022; Conference date: 14 September 2022 through 16 September 2022; Conference code: 183844}
}

@ARTICLE{Kammakomati2022873,
	author = {Kammakomati, Mehant and Tarun Kumar, P.V. and Radhika, K.},
	title = {Comparison of Machine Learning Algorithms for Hate and Offensive Speech Detection},
	year = {2022},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {116},
	pages = {873 – 881},
	doi = {10.1007/978-981-16-9605-3_61},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127140312&doi=10.1007%2f978-981-16-9605-3_61&partnerID=40&md5=9ac97ac7f25ccc1e71a0d3f047f9352b},
	affiliations = {National Institute of Technology, Andhra Pradesh, Tadepalligudem, India; Chaitany Bharathi Institute of Technology, Telangana, Gandipet, India},
	abstract = {Hate speech is not uncommon and is likely practiced almost on every networking platform. In recent times, due to exponential increase in Internet users and events such as the unprecedented pandemic and lockdown, it showed increased usage of social platforms for communicating thoughts, opinions, and ideas. Hate speech has a strong impact on people’s lives and is one of the reasons for suicidal events. There is certainly a strong need to make progress toward the mitigation of hate speech. Detection is the primary step to eradicate hate speech. In the following paper, the comparative analysis of different machine learning algorithms to detect hate speech was shown. Data from the Twitter social platform was considered. From the analysis, it was found that the long short-term memory method is a highly performant machine learning algorithm. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Classification; Hate speech; Machine learning; Natural language processing},
	keywords = {Learning algorithms; Natural language processing systems; Speech; Speech recognition; Comparative analyzes; Exponential increase; Hate speech; Internet users; Machine learning algorithms; Speech detection; Machine learning},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Velankar20221,
	author = {Velankar, Abhishek and Patil, Hrushikesh and Joshi, Raviraj},
	title = {L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and BERT models},
	year = {2022},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {29},
	number = {12},
	pages = {1 – 9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144959723&partnerID=40&md5=9562c9fc97aeb2e6d31e2e3a8bfdde19},
	affiliations = {Pune Institute of Computer Technology, Pune, India; Indian Institute of Technology Madras, Chennai, India; L3Cube, Pune, India},
	abstract = {Social media platforms are used by a large number of people prominently to express their thoughts and opinions. However, these platforms have contributed to a substantial amount of hateful and abusive content as well. Therefore, it is important to curb the spread of hate speech on these platforms. In India, Marathi is one of the most popular languages used by a wide audience. In this work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in Marathi. The dataset is curated from Twitter and annotated manually. Our dataset consists of over 25000 distinct tweets labeled into four major classes i.e hate, offensive, profane, and not. We present the approaches used for collecting and annotating the data and the challenges faced during the process. Finally, we present baseline classification results using deep learning models based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that mono-lingual models perform better than their multilingual counterparts. The MahaBERT model provides the best results on L3CubeMahaHate Corpus. The data and models are available at https://github.com/l3cubepune/MarathiNLP . © 2022 MMMPIE. All Rights Reserved.},
	author_keywords = {BERT; Convolutional Neural Networks; FastText; Hate Speech Detection; Long Short Term Memory; Natural Language Processing},
	keywords = {Convolutional neural networks; Natural language processing systems; Social networking (online); Speech recognition; BERT; Convolutional neural network; Fasttext; Hate speech detection; Language processing; Natural language processing; Natural languages; Number of peoples; Social media platforms; Speech detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 3rd Workshop on Threat, Aggression and Cyberbullying, TRAC 2022 at 29th International Conference on Computational Linguistics. COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 192733}
}

@CONFERENCE{Ramponi20223027,
	author = {Ramponi, Alan and Tonelli, Sara},
	title = {Features or Spurious Artifacts? Data-centric Baselines for Fair and Robust Hate Speech Detection},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {3027 – 3040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137577068&partnerID=40&md5=3637bb04cf991ac9ba3ef126924e1996},
	affiliations = {Fondazione Bruno Kessler, Trento, Italy},
	abstract = {Avoiding to rely on dataset artifacts to predict hate speech is at the cornerstone of robust and fair hate speech detection. In this paper we critically analyze lexical biases in hate speech detection via a cross-platform study, disentangling various types of spurious and authentic artifacts and analyzing their impact on out-of-distribution fairness and robustness. We experiment with existing approaches and propose simple yet surprisingly effective data-centric baselines. Our results on English data across four platforms show that distinct spurious artifacts require different treatments to ultimately attain both robustness and fairness in hate speech detection. To encourage research in this direction, we release all baseline models and the code to compute artifacts, pointing it out as a complementary and necessary addition to the data statements practice. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Baseline models; Cross-platform; Data centric; Data statement; Different treatments; Lexical bias; Simple++; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182070}
}

@ARTICLE{Lai2022149,
	author = {Lai, Mirko and Stranisci, Marco Antonio and Bosco, Cristina and Damiano, Rossana and Patti, Viviana},
	title = {Analysing Moral Beliefs for Detecting Hate Speech Spreaders on Twitter},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13390 LNCS},
	pages = {149 – 161},
	doi = {10.1007/978-3-031-13643-6_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137987095&doi=10.1007%2f978-3-031-13643-6_12&partnerID=40&md5=f519e41cf7daad98a96d441d2c88e9ca},
	affiliations = {Dipartimento di Informatica, Università degli Studi di Torino, Turin, Italy},
	abstract = {The Hate and Morality (HaMor) submission for the Profiling Hate Speech Spreaders on Twitter task at PAN 2021 ranked as the 19th position - over 67 participating teams - according to the averaged accuracy value of 73 % over the two languages - English (62 % ) and Spanish (84 % ). The method proposed four types of features for inferring users attitudes just from the text in their messages: HS detection, users morality, named entities, and communicative behaviour. In this paper, since the test set is now available, we were able to analyse false negative and false positive prediction with the aim of shed more light on the hate speech spreading phenomena. Furthermore, we fine-tuned the features based on users morality and named entities showing that semantic resources could help in facing Hate Speech Spreaders detection on Twitter. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Hate Speech; Moral Foundation Theory; Twitter},
	keywords = {Feature extraction; Social networking (online); Speech recognition; Spreaders; False negatives; False positive; Feature-based; Hate speech; Moral foundation theory; Named entities; Participating teams; Test sets; Twitter; User attitudes; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 13th International Conference of the Cross-Language Evaluation Forum for European Languages, CLEF 2022; Conference date: 5 September 2022 through 8 September 2022; Conference code: 282409}
}

@CONFERENCE{Sabry2022,
	author = {Sabry, Sana Sabah and Adewumi, Tosin and Abid, Nosheen and Kovacs, Gyorgy and Liwicki, Foteini and Liwicki, Marcus},
	title = {HaT5: Hate Language Identification using Text-to-Text Transfer Transformer},
	year = {2022},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	volume = {2022-July},
	doi = {10.1109/IJCNN55064.2022.9892696},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140754070&doi=10.1109%2fIJCNN55064.2022.9892696&partnerID=40&md5=2e5f4775107c7d50937c3d3266f5d3a7},
	affiliations = {Luleå University of Technology, Department of Computer Science, Electrical and Space Engineering, Luleå, Sweden},
	abstract = {We investigate the performance of a state-of-the-art (SoTA) architecture T5 (available on the SuperGLUE) and compare it with 3 other previous SoTA architectures across 5 different tasks from 2 relatively diverse datasets. The datasets are diverse in terms of the number and types of tasks they have. To improve performance, we augment the training data by using a new autoregressive conversational AI model checkpoint. We achieve near-SoTA results on a couple of the tasks - macro F1 scores of 81.66% for task A of the OLID 2019 dataset and 82.54% for task A of the hate speech and offensive content (HASOC) 2021 dataset, where SoTA are 82.9% and 83.05%, respectively. We perform error analysis and explain why one of the models (Bi-LSTM) makes the predictions it does by using a publicly available algorithm: Integrated Gradient (IG). This is because explainable artificial intelligence (XAI) is essential for earning the trust of users. The main contributions of this work are the implementation method of T5, which is discussed; the data augmentation, which brought performance improvements; and the revelation on the shortcomings of the HASOC 2021 dataset. The revelation shows the difficulties of poor data annotation by using a small set of examples where the T5 model made the correct predictions, even when the ground truth of the test set were incorrect (in our opinion). We also provide our model checkpoints on the HuggingFace hub11https://huggingface.co/sana-ngu/HaT5_augmentation https://huggingface.co/sana-ngu/HaT5. © 2022 IEEE.},
	author_keywords = {Data Augmentation; Hate Speech; T5; Transformer},
	keywords = {Auto-regressive; Data augmentation; Hate speech; Improve performance; Language identification; Performance; State of the art; T5; Training data; Transformer; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2022 International Joint Conference on Neural Networks, IJCNN 2022; Conference date: 18 July 2022 through 23 July 2022; Conference code: 183333; All Open Access, Green Open Access}
}

@CONFERENCE{Ludwig202229,
	author = {Ludwig, Florian and Dolos, Klara and Zesch, Torsten and Hobley, Eleanor},
	title = {Improving Generalization of Hate Speech Detection Systems to Novel Target Groups via Domain Adaptation},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {29 – 39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139104474&partnerID=40&md5=899cb6b0180770a31a0e087527d8493c},
	affiliations = {ZITiS, Zamdorfer Str. 88, München, 81677, Germany; FernUniversität in Hagen, Universitätsstraße 47, Hagen, 58097, Germany},
	abstract = {Despite recent advances in machine learning based hate speech detection, classifiers still struggle with generalizing knowledge to out-of-domain data samples. In this paper, we investigate the generalization capabilities of deep learning models to different target groups of hate speech under clean experimental settings. Furthermore, we assess the efficacy of three different strategies of unsupervised domain adaptation to improve these capabilities. Given the diversity of hate and its rapid dynamics in the online world (e.g. the evolution of new target groups like virologists during the COVID-19 pandemic), robustly detecting hate aimed at newly identified target groups is a highly relevant research question. We show that naively trained models suffer from a target group specific bias, which can be reduced via domain adaptation. We were able to achieve a relative improvement of the F1-score between 5.8% and 10.7% for out-of-domain target groups of hate speech compared to baseline approaches by utilizing domain adaptation. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; COVID-19; Deep learning; Data sample; Detection system; Domain adaptation; Generalisation; Generalization capability; Learning models; Machine-learning; Research questions; Speech detection; Target group; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714}
}

@ARTICLE{Balouchzahi20226995,
	author = {Balouchzahi, Fazlourrahman and Shashirekha, Hosahalli Lakshmaiah and Sidorov, Grigori and Gelbukh, Alexander},
	title = {A comparative study of syllables and character level N-grams for Dravidian multi-script and code-mixed offensive language identification},
	year = {2022},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {43},
	number = {6},
	pages = {6995 – 7005},
	doi = {10.3233/JIFS-212872},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145658866&doi=10.3233%2fJIFS-212872&partnerID=40&md5=7c47b9f93f8c453c2bacde0dc0008c84},
	affiliations = {Instituto Politécnico Nacional, Centro de Investigación en Computación, CDMX, Mexico; Department of Computer Science, Mangalore University Mangalore, India},
	abstract = {Curfews and lockdowns around the world in the Covid-19 era have increased the usage of the internet drastically and accordingly the amount of data shared on social media. In addition to using social media for sharing useful information, some miscreants are using the power of social media to spread hate speech and offensive content. Filtering the offensive language content manually is a laborious task due to the huge volume of data. Further, rapid developments in hardware and software technology have provided opportunities for users to post their comments not only in English but also in their native language scripts. However, based on the ease of Roman script usage, social media users specifically in multilingual countries like India, prefer to comment in code-mixed and multi-script texts. The typical systems that are employed to process and analyze monolingual texts are usually not appropriate for these kinds of texts. Further, as these texts do not adhere to the rules and regulations of any language to frame the words and sentences, the complexity of analyzing such texts increases. The novelty of the present study is to address the Offensive Language Identification (OLI) task in code-mixed and multi-script texts, this paper proposes to use relevant syllable and character n-grams features to train Machine Learning (ML) classifiers. The performance of the proposed models is evaluated on three Dravidian language pairs, namely: Malayalam-English, Tamil-English, and Kannada-English. The performances of ML classifiers prove the effectiveness of syllable and character n-grams features for code-mixed and multi-script texts analysis.  © 2022 - IOS Press. All rights reserved.},
	author_keywords = {character n-grams; Code-mixed; multi-script; offensive language identification; syllable},
	keywords = {Computational linguistics; Information use; Natural language processing systems; Software engineering; Character n-gram; Code-mixed; Language identification; Machine-learning; Multi-script; N-grams; Offensive language identification; Offensive languages; Social media; Syllable; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Zhang2022,
	author = {Zhang, Errui},
	title = {Deep learning for hate speech detection},
	year = {2022},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {12163},
	doi = {10.1117/12.2628010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131822717&doi=10.1117%2f12.2628010&partnerID=40&md5=e27b0525ee013ff651e6ba578e49f23c},
	affiliations = {College of Engineering and Computer Science, Australia National University, Australia},
	abstract = {With the rapid growth of the Internet, more and more people use online social media. Hence, hate speech becomes rampant in social media, and it is important to classify the hate speech and control it before it spreads. With the introduction and the development of deep learning, hate speech detection becomes practice. Many studies utilize data from social platforms such as Twitter and Facebook together with machine learning or deep learning technologies to detect and recognize hate speech. However, there are not enough reviews about this area. Hence, this paper aims to provide a review of using machine learning and deep learning for hate speech detection.  © COPYRIGHT SPIE.},
	author_keywords = {deep learning; hate speech detection},
	keywords = {Deep learning; Speech; Speech recognition; Deep learning; Facebook; Hate speech detection; Learning technology; Online social medias; Rapid growth; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Conference on Statistics, Applied Mathematics, and Computing Science, CSAMCS 2021; Conference date: 26 November 2021 through 28 November 2021; Conference code: 179701}
}

@CONFERENCE{Mishra2022398,
	author = {Mishra, Varun and Tripathi, Monika},
	title = {A Toxic Content Detection Technique in Sentimental Analysis with Convolution Neural Networks},
	year = {2022},
	journal = {Proceedings - 2022 IEEE 11th International Conference on Communication Systems and Network Technologies, CSNT 2022},
	pages = {398 – 402},
	doi = {10.1109/CSNT54456.2022.9787588},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133140887&doi=10.1109%2fCSNT54456.2022.9787588&partnerID=40&md5=f52d517c950095aba284219f0cc3f54c},
	affiliations = {Shri Krishna University, Dept. of Computer Science and Engineering, Madhya Pradesh, Chhatarpur, India},
	abstract = {In the recent time, the usage of various social media platforms has drastically increased which involves the positive or negative impact on human lives. One of the aspects is directly associated with comment/opinion which individual user/person passes through different social networking sites. This paper provides the discussion on different approaches to analyze classification and modelling techniques for detecting toxic comments using convolution neural networks (CNN). It also specifies algorithm based on outlier detection on given data stream that can evaluate the posted material on social platforms and check its positive and negative impact on the society.  © 2022 IEEE.},
	author_keywords = {Convolution Neural Networks; Outlier Detection Techniques; Sentiment Analysis; Toxic/Non-toxic Comment Classification},
	keywords = {Anomaly detection; Convolution; Data handling; Social networking (online); Statistics; Content detection; Convolution neural network; Human lives; Non-toxic; Outlier Detection; Outlier detection technique; Sentiment analysis; Social media platforms; Social-networking; Toxic/non-toxic comment classification; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 11th IEEE International Conference on Communication Systems and Network Technologies, CSNT 2022; Conference date: 23 April 2022 through 24 April 2022; Conference code: 179894}
}

@CONFERENCE{Lavanya2022489,
	author = {Lavanya, S.K. and Navaneethakrishnan, Subalalitha Chinnaudayar},
	title = {Building Tamil Text Dataset on LGBTQIA and Offensive Language Detection using Multilingual BERT},
	year = {2022},
	journal = {5th International Conference on Inventive Computation Technologies, ICICT 2022 - Proceedings},
	pages = {489 – 496},
	doi = {10.1109/ICICT54344.2022.9850904},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137368979&doi=10.1109%2fICICT54344.2022.9850904&partnerID=40&md5=2a3c3c7145e81b806f63446c26542a46},
	affiliations = {Srm Institute of Science and Technology, Computational Intelligence, Chennai, India; Srm Institute of Science and Technology, Computing Technologies, Chennai, India},
	abstract = {Lesbian, Gay, Bisexual, Transgender and Queer or Questioning (LGBTQ) community worldwide undergo depression, mental health problems and develop suicidal thoughts, due to non-acceptance by the society. This primarily stems from the lack of awareness and connection with the LGBTQ community. This paper aims to collect tweets and classifies them as offensive or non-offensive using manual and automated methods. The tweets are in Tamil (a classical Indian language), which is limited in terms of data and research. The presented dataset is annotated by two annotators and validated by a Cohen's kappa metric score of 0.97. A finetuned Multilingual BERT (mBERT) Transformer model along with baseline models of Naive Bayes and Long Short-Term Memory detect offensive and non-offensive texts using the benchmark dataset, with the mBERT model performing the best, scoring a F-score of 93% for Non-Offensive class and 70% for Offensive class We also discuss preliminary findings from the dataset, which can be investigated further for specific research directions in the future.  © 2022 IEEE.},
	author_keywords = {Bisexual; Gay; Lesbian; Long Short Term Memory; Multilingual BERT; Naive Bayes; sentiment analysis; Tamil Dataset; Transgender and Queer or Questioning},
	keywords = {Brain; Long short-term memory; Bisexual; Gay; Language detection; Lesbian; Multilingual BERT; Naive bayes; Offensive languages; Sentiment analysis; Tamil dataset; Transgender and queer or questioning; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 5th International Conference on Inventive Computation Technologies, ICICT 2022; Conference date: 20 July 2022 through 22 July 2022; Conference code: 182062}
}

@ARTICLE{Cahyana2022147,
	author = {Cahyana, Nur Heri and Saifullah, Shoffan and Fauziah, Yuli and Aribowo, Agus Sasmito and Drezewski, Rafal},
	title = {Semi-supervised Text Annotation for Hate Speech Detection using K-Nearest Neighbors and Term Frequency-Inverse Document Frequency},
	year = {2022},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {13},
	number = {10},
	pages = {147 – 151},
	doi = {10.14569/IJACSA.2022.0131020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141787597&doi=10.14569%2fIJACSA.2022.0131020&partnerID=40&md5=00ddf1ef9e92ae7b74a79471f320258c},
	affiliations = {Department of Informatics, Universitas Pembangunan Nasional Veteran Yogyakarta Yogyakarta, Indonesia; Department of Information Systems, Universitas Pembangunan Nasional Veteran Yogyakarta Yogyakarta, Indonesia; Faculty of Information and Communication Technology, Universiti Teknikal Malaysia Melaka, Malaysia; Institute of Computer Science, AGH University of Science and Technology, Cracow, Poland},
	abstract = {Sentiment analysis can detect hate speech using the Natural Language Processing (NLP) concept. This process requires annotation of the text in the labeling. However, when carried out by people, this process must use experts in the field of hate speech, so there is no subjectivity. In addition, if processed by humans, it will take a long time and allow errors in the annotation process for extensive data. To solve this problem, we propose an automatic annotation process with the concept of semi-supervised learning using the K-Nearest Neighbor algorithm. This process requires feature extraction of term frequency-inverse document frequency (TF-IDF) to obtain optimal results. KNN and TF-IDF were able to annotate and increase the accuracy of < 2% from the initial iteration of 57.25% to 59.68% in detecting hate speech. This process can annotate the initial dataset of 13169 with the distribution of 80:20 of training and testing data. There are 2370 labeled datasets; for testing, there are 1317 unannotated data; after preprocessing, there are 9482. The final results of the KNN and TF-IDF annotation processes have a length of 11235 for annotated data. © 2022, International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {K-nn; Natural language processing; Semi-supervised learning; Text annotation; Tf-idf},
	keywords = {Inverse problems; Iterative methods; Learning algorithms; Motion compensation; Nearest neighbor search; Speech recognition; Statistical tests; Supervised learning; K-nn; Language processing; Natural language processing; Natural languages; Semi-supervised; Semi-supervised learning; Speech detection; Term frequencyinverse document frequency (TF-IDF); Text annotations; Tf-idf; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@CONFERENCE{Sanya2022380,
	author = {Sanya, Almira Diva and Suadaa, Lya Hulliyyatus},
	title = {Handling Imbalanced Dataset on Hate Speech Detection in Indonesian Online News Comments},
	year = {2022},
	journal = {2022 10th International Conference on Information and Communication Technology, ICoICT 2022},
	pages = {380 – 385},
	doi = {10.1109/ICoICT55009.2022.9914883},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141572354&doi=10.1109%2fICoICT55009.2022.9914883&partnerID=40&md5=0b098d6efe58c5c414ef9f5adc688519},
	affiliations = {Politeknik Statistika Stis, Department of Computational Statistics, Jakarta, Indonesia},
	abstract = {In the current technological era, people can get information quickly, up to date, and in large quantities by accessing online news. A comment column is usually provided as a feature in the online news to express criticism, suggestions, and opinions on certain news. This convenience is a form of freedom of expression for everyone. However, it increases the opportunity for users to express their hate in the comment column. The rise of posts containing hate speech is a problem that needs to be addressed by automatic hate speech detection. Naturally, there is an imbalance between the number of comments that include hate speech and those that do not. Therefore, in this study, the detection of Indonesian hate speech posts in the comments was carried out under several imbalanced conditions. Models used in this study are the SVM model, SVM with various resampling methods, fine-tuned IndoBERT, and fine-tuned mBERT. Based on the results, an imbalanced state can reduce the performance of SVM and the fine-tuned models. Even under an extreme imbalanced condition, the fine-tuned IndoBERT can capture the sentence contexts better than SVM. Then, applying oversampling strategies to SVM can improve the performance of SVM under imbalanced settings. The combination of SVM and SMOTE models perform the best in handling imbalanced problem.  © 2022 IEEE.},
	author_keywords = {Hate Speech Detection; Imbalanced Dataset; Indonesian NLP},
	keywords = {Support vector machines; 'current; Condition; Hate speech detection; Imbalanced dataset; Indonesian NLP; Online news; Performance; Resampling method; Speech detection; SVM model; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 10th International Conference on Information and Communication Technology, ICoICT 2022; Conference date: 2 August 2022 through 3 August 2022; Conference code: 183706}
}

@CONFERENCE{Yadav2022,
	author = {Yadav, Ankit and Chandel, Shubham and Chatufale, Sushant and Bandhakavi, Anil},
	title = {LAHM: Large Annotated Dataset for Multi-Domain and Multilingual Hate Speech Identification},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134346487&partnerID=40&md5=c3e28f75453e752f1d1fce19d1d0fca8},
	affiliations = {Logically.ai, Brookfoot Mills, Brookfoot Industrial Estate, Brighouse, HD6 2RW, United Kingdom},
	abstract = {Current research on hate speech analysis is typically oriented towards monolingual and single classification tasks. In this paper, we present a new multilingual hate speech analysis dataset for English, Hindi, Arabic, French, German and Spanish languages for multiple domains across hate speech - Abuse, Racism, Sexism, Religious Hate and Extremism. To the best of our knowledge, this paper is the first to address the problem of identifying various types of hate speech in these five wide domains in these six languages. In this work, we describe how we created the dataset, created annotations at high level and low level for different domains and how we use it to test the current state-of-the-art multilingual and multitask learning approaches. We evaluate our dataset in various monolingual, cross-lingual and machine translation classification settings and compare it against open source English datasets that we aggregated and merged for this task. Then we discuss how this approach can be used to create large scale hate-speech datasets and how to leverage our annotations in order to improve hate speech detection and classification in general. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)},
	author_keywords = {abuse; cross-lingual; extremism; few shot learning; hate speech; multi-domain; multilingual; racism; religious hate; sexism; zero shot learning},
	keywords = {Classification (of information); Computational linguistics; Large dataset; Speech recognition; Statistical tests; Abuse; Cross-lingual; Extremism; Few shot learning; Hate speech; Multi-domains; Multilingual; Racism; Religious hate; Sexism; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st Workshop on Multimodal Fact-Checking and Hate Speech Detection, DE-FACTIFY 2022; Conference date: 27 February 2022; Conference code: 180770}
}

@ARTICLE{Kovács202287,
	author = {Kovács, György and Alonso, Pedro and Saini, Rajkumar and Liwicki, Marcus},
	title = {Leveraging external resources for offensive content detection in social media},
	year = {2022},
	journal = {AI Communications},
	volume = {35},
	number = {2},
	pages = {87 – 109},
	doi = {10.3233/AIC-210138},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135231173&doi=10.3233%2fAIC-210138&partnerID=40&md5=6bbc238304f631dcecbd3e897c552199},
	affiliations = {Department of Computer Science Electrical and Space Engineering, Luleå University of Technology, Norrbotten, Sweden},
	abstract = {Hate speech is a burning issue of today's society that cuts across numerous strategic areas, including human rights protection, refugee protection, and the fight against racism and discrimination. The gravity of the subject is further demonstrated by António Guterres, the United Nations Secretary-General, calling it 'a menace to democratic values, social stability, and peace'. One central platform for the spread of hate speech is the Internet and social media in particular. Thus, automatic detection of hateful and offensive content on these platforms is a crucial challenge that would strongly contribute to an equal and sustainable society when overcome. One significant difficulty in meeting this challenge is collecting sufficient labeled data. In our work, we examine how various resources can be leveraged to circumvent this difficulty. We carry out extensive experiments to exploit various data sources using different machine learning models, including state-of-the-art transformers. We have found that using our proposed methods, one can attain state-of-the-art performance detecting hate speech on Twitter (outperforming the winner of both the HASOC 2019 and HASOC 2020 competitions). It is observed that in general, adding more data improves the performance or does not decrease it. Even when using good language models and knowledge transfer mechanisms, the best results were attained using data from one or two additional data sets.  © 2022-IOS Press. All rights reserved.},
	author_keywords = {deep language processing; Hateful and offensive language; RoBERTa; transfer learning; vocabulary augmentation},
	keywords = {Deep learning; Knowledge management; Learning systems; Transfer learning; Content detection; Deep language processing; External resources; Hateful and offensive language; Language processing; Offensive languages; RoBERTa; Social media; Transfer learning; Vocabulary augmentation; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Debele2022102,
	author = {Debele, Abreham Gebremedin and Woldeyohannis, Michael Melese},
	title = {Multimodal Amharic Hate Speech Detection Using Deep Learning},
	year = {2022},
	journal = {2022 International Conference on Information and Communication Technology for Development for Africa, ICT4DA 2022},
	pages = {102 – 107},
	doi = {10.1109/ICT4DA56482.2022.9971436},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145439504&doi=10.1109%2fICT4DA56482.2022.9971436&partnerID=40&md5=179ca2ec34064e174c00a8d15c3b1cca},
	affiliations = {University of Gondar, Information Systems Department, Gondar, Ethiopia; Addis Ababa University, School of Information Science, Addis Ababa, Ethiopia},
	abstract = {Social media has become a tool of online communication used for discussions, information sharing, and the creation of online content on social networks. Hate speech is one of the detrimental or harmful information spread on social media. Discrimination against individuals results from hate speech. Human rights are also violated by it. As a result, several studies have been attempting to identify hate speech. However, while the majority of studies focus on identifying hate speech in textual data, it is also distributed through films. Amharic is also one of the under-resourced languages that benefits from hate speech detection, so this is another positive. This work seeks to apply a multi-modal, which is a mix of the acoustic and textual elements using a deep learning technique, to address the issue of Amharic hate speech on social media In the beginning, we gathered 1,459 extracted audios from YouTube videos, ranging in length from 30 seconds to 140 minutes. A five-minute audio speech employing silent segmentation techniques follows this. From these, we have a collection of 6497 audios from one to five minutes after the audio segmenting and filtering. Each Audio is annotated by a domain expert for the purpose of performing tests. Then, for our research, we use the Google Speech-to-Text API to transcribe audio speech into text scripts. The features were then extracted, with textual features extracted using word2vec and acoustic features extracted using Mel-Frequency Cepstral Coefficient (MFCC). As a result, this study makes use of four deep learning algorithms: LSTM, BILSTM, GRU, and BIGRU. The results of the multi-modal experiment demonstrate that the multi-modal model with BILSTM outperforms the other experiment for detecting Amharic hate speech with an accuracy of 88.15%. Furthermore, we are working to extend the Amharic hate speech detection taking the video in to account addition to the text and audio.  © 2022 IEEE.},
	author_keywords = {Amharic language; deep learning; Hate speech; MFCC; Multimodal Learning; Social media; Word2vec},
	keywords = {Learning algorithms; Learning systems; Long short-term memory; Social networking (online); Speech communication; Amharic language; Deep learning; Hate speech; Mel frequency cepstral co-efficient; Mel-frequency cepstral coefficients; Multi-modal; Multi-modal learning; Social media; Speech detection; Word2vec; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2022 International Conference on Information and Communication Technology for Development for Africa, ICT4DA 2022; Conference date: 28 November 2022 through 30 November 2022; Conference code: 184982}
}

@CONFERENCE{Kurrek2022131,
	author = {Kurrek, Jana and Saleem, Haji Mohammad and Ruths, Derek},
	title = {Enriching Abusive Language Detection with Community Context},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {131 – 142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139171785&partnerID=40&md5=cbe9c4b304747748ac9d74894a80afeb},
	affiliations = {McGill University, School of Computer Science, Canada},
	abstract = {Uses of pejorative expressions can be benign or actively empowering. When models for abuse detection misclassify these expressions as derogatory, they inadvertently censor productive conversations held by marginalized groups. One way to engage with non-dominant perspectives is to add context around conversations. Previous research has leveraged user- and thread-level features, but it often neglects the spaces within which productive conversations take place. Our paper highlights how community context can improve classification outcomes in abusive language detection. We make two main contributions to this end. First, we demonstrate that online communities cluster by the nature of their support towards victims of abuse. Second, we establish how community context improves accuracy and reduces the false positive rates of state-of-the-art abusive language classifiers. These findings suggest a promising direction for context-aware models in abusive language research. © 2022 Association for Computational Linguistics.},
	keywords = {Context-aware models; False positive rates; Language detection; On-line communities; State of the art; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714}
}

@ARTICLE{Vo2022299,
	author = {Vo, Hanh Hong-Phuc and Nguyen, Huy Hoang and Do, Trong-Hop},
	title = {Analysis of the Effects of Stop-word Removal in Hate Speech Detection Problem for Vietnamese Social Network Data},
	year = {2022},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {148},
	pages = {299 – 309},
	doi = {10.1007/978-3-031-15063-0_28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136815533&doi=10.1007%2f978-3-031-15063-0_28&partnerID=40&md5=ea6241cac482197b48241c57b928d1ed},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University Ho Chi Minh City, Ho Chi Minh City, Viet Nam},
	abstract = {The usefulness of removing the stop-word in detecting Vietnamese hate speech on social media has yet to be determined. In this study, statistical hypothesis testing is used to evaluate the effect of stop-word removal in hate speech detection using two datasets, the ViHSD dataset and the HSD dataset of VLSP-HSD, six models, including traditional machine learning models, deep neural learning models, transformer models, and two methods of stop-word selection, word frequency and word form. The results indicate stop-word removal is bad effective in hate speech detection problem on Vietnamese. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Hate speech detection; Machine learning; Natural language processing; Social network text; Statistical test; Stop-word},
	keywords = {Learning algorithms; Learning systems; Natural language processing systems; Speech recognition; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Social network text; Speech detection; Stop word; Vietnamese; Word removals; Statistical tests},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chong2022,
	author = {Chong, Wei Jiek and Chua, Hui Na and Gan, May Fen},
	title = {Comparing Zero-Shot Text Classification and Rule-Based Matching in Identifying Cyberbullying Behaviors on Social Media},
	year = {2022},
	journal = {4th IEEE International Conference on Artificial Intelligence in Engineering and Technology, IICAIET 2022},
	doi = {10.1109/IICAIET55139.2022.9936821},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142231610&doi=10.1109%2fIICAIET55139.2022.9936821&partnerID=40&md5=6c4800922ec3d65eceb5d98838270761},
	affiliations = {Sunway University, Department of Computing and Information Systems, Selangor, Sunway City, Malaysia},
	abstract = {The incidences of cyberbullying have skyrocketed due to the continuous expansion of social media users. Therefore, proactive efforts are necessary to address cyberbullying, including countermeasures for handling the various cyberbullying behaviors. Nevertheless, due to the large volume of social media texts being generated persistently, it is challenging to identify cyberbullying behaviors in a social text and not scalable in using the manual approach of human annotation. Most previous studies adopt the human annotation approach to determine whether a text is a cyberbully or non-cyberbully. Therefore, this paper aims to experiment with approaches that can improve the efficiency of recognizing the different cyberbullying behaviors through textual data using zero-shot classification and rule-based matching, and compare how they perform in classifying cyberbullying behaviors. This study uses techniques such as topic modelling, zero-shot text classification, and information extraction with rule-based matching to identify and classify the cyberbully behaviors underlying a cyberbully comment. The human annotation approach serves as the benchmark to compare the performance of both models in identifying cyberbullying behaviors. Our results show that zero-shot classification performed better accuracy in categorizing cyberbullying behaviors. Among the behaviors, the zero-shot model we generated presents a better accuracy rate in recognizing the flaming behavior, but it achieves a lower accuracy rate in identifying the other cyberbully behaviors.  © 2022 IEEE.},
	author_keywords = {cyberbullying detection; data mining; rule-based matching; social media data analytics; text classification; topic modeling; zero-shot classification},
	keywords = {Benchmarking; Classification (of information); Computer crime; Data mining; Social networking (online); Text processing; Cyber bullying; Cyberbullying detection; Data analytics; Matchings; Rule based; Rule-based matching; Shot classification; Social media datum; Social medium data analytic; Text classification; Topic Modeling; Zero-shot classification; Data Analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 4th IEEE International Conference on Artificial Intelligence in Engineering and Technology, IICAIET 2022; Conference date: 13 September 2022 through 15 September 2022; Conference code: 184212}
}

@CONFERENCE{Zhuang2022,
	author = {Zhuang, Yan and Zhang, Yanru},
	title = {Yet at Memotion 2.0 2022: Hate Speech Detection Combining BiLSTM and Fully Connected Layers},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128341017&partnerID=40&md5=b4882a33ff00fc14d14684754b23d318},
	affiliations = {University of Electronic Science and Technology of China, China; Shenzhen Institute for Advanced Study, UESTC, China},
	abstract = {People are increasingly willing to send emojis rather than plain text to express themselves. However, emoticons with bad feelings such as hatred are more subtle and harder to detect than text. The'Memotion 2.0' task of the'DE-FACTIFY' workshop aims to detect the hate speech in internet memes. In this paper, we present our approach for solving this task. The GloVe is applied to get the text embedding matrix and pre-trained VGG-16 is used to get the image representation. Instead of attention mechanism, we combine the bidirectional Long Short Term Memory (LSTM) and fully connected layers to promote the feature interactions. Compared to text-only models, our model showed better performance and helped us increase the baseline (43.4%) by 7.4%, which finally ranked 3rd in'Sentiment Analysis' task. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)},
	author_keywords = {Hate Speech Detection; Meme Classification; Multimodality},
	keywords = {Image representation; Sentiment analysis; Speech recognition; Attention mechanisms; Embedding matrices; Feature interactions; Hate speech detection; Image representations; Meme classification; Multi-modality; Performance; Plain text; Speech detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 1st Workshop on Multimodal Fact-Checking and Hate Speech Detection, DE-FACTIFY 2022; Conference date: 27 February 2022; Conference code: 180770}
}

@ARTICLE{Nath2022347,
	author = {Nath, Nilanjan and George, Jossy P. and Kesan, Athishay and Rodrigues, Andrea},
	title = {An Efficient Deep Learning-Based Hybrid Architecture for Hate Speech Detection in Social Media},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {462},
	pages = {347 – 355},
	doi = {10.1007/978-981-19-2211-4_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135007967&doi=10.1007%2f978-981-19-2211-4_30&partnerID=40&md5=13972f303d79c8e87bb7e04c29d9b447},
	affiliations = {CHRIST (Deemed to be University), Bengaluru, India},
	abstract = {Social media has become an integral part of life as users are spending a significant amount of time networking online. Two primary reasons for its increasing popularity are ease of access and freedom of speech. People can express themselves without worrying about consequences. Due to lack of restriction, however, cases of cyberbullying and hate speeches are increasing on social media. Twitter and Facebook receive over a million posts daily, and manual filtration of this enormous number is a tedious task. This paper proposes a deep learning-based hybrid architecture (CNN + LSTM) to identify hate speeches by using Stanford’s GloVe, which is a pre-trained word embedding. The model has been tested under different parameters and compared with several state-of-the-art models. The proposed framework has outperformed existing models and has also achieved the best accuracy. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {CNN; Detection; Hate speech; Hybrid model; LSTM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: International Conference on Data Science, Computation, and Security, IDSCS 2022; Conference date: 11 February 2022 through 12 February 2022; Conference code: 280239}
}

@CONFERENCE{Sachdeva2022231,
	author = {Sachdeva, Pratik S. and Barreto, Renata and von Vacano, Claudia and Kennedy, Chris J.},
	title = {Targeted Identity Group Prediction in Hate Speech Corpora},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {231 – 244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139161100&partnerID=40&md5=2abeae35122a3c9371576b310757343c},
	affiliations = {D-Lab, University of California, Berkeley, United States; School of Law, University of California, Berkeley, United States; Center for Precision Psychiatry, Harvard Medical School, United States},
	abstract = {The past decade has seen an abundance of work seeking to detect, characterize, and measure online hate speech. A related, but less studied problem, is the specification of identity groups targeted by that hate speech. Predictive accuracy on this task can supplement additional analyses beyond hate speech detection, motivating its study. Using the Measuring Hate Speech corpus, which provided annotations for targeted identity groups on roughly 50,000 social media comments, we create neural network models to perform multi-label binary prediction of identity groups targeted by a social media comment. Specifically, we study 8 broad identity groups and 12 identity sub-groups within race and gender identity. We find that these networks exhibited good predictive performance, achieving ROC AUCs of greater than 0.9 and PR AUCs of greater than 0.7 on several identity groups. At the same time, we find performance suffered on identity groups less represented in the dataset. We validate model performance on the HateCheck and Gab Hate Corpora, finding that predictive performance generalizes in most settings. We additionally examine the performance of the model on comments targeting multiple identity groups. Lastly, we discuss issues with a standardized conceptualization of a “target” in hate speech corpora, and its relation to intersectionality. Our results demonstrate the feasibility of simultaneously detecting a broad range of targeted groups in social media comments, and offer suggestions for future work on modeling and dataset annotation for this task. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Neural network models; Social networking (online); Modeling performance; Multi-labels; Neural network model; Performance; Predictive accuracy; Predictive performance; Social media; Speech corpora; Speech detection; Sub-groups; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714}
}

@CONFERENCE{Balkır20222672,
	author = {Balkır, Esma and Nejadgholi, Isar and Fraser, Kathleen C. and Kiritchenko, Svetlana},
	title = {Necessity and Sufficiency for Explaining Text Classifiers: A Case Study in Hate Speech Detection},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {2672 – 2686},
	doi = {10.18653/v1/2022.naacl-main.192},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132150240&doi=10.18653%2fv1%2f2022.naacl-main.192&partnerID=40&md5=25725a8a8b7d49cb5021c3cdb01dc2bb},
	affiliations = {National Research Council Canada, Ottawa, Canada},
	abstract = {We present a novel feature attribution method for explaining text classifiers, and analyze it in the context of hate speech detection. Although feature attribution models usually provide a single importance score for each token, we instead provide two complementary and theoretically-grounded scores - necessity and sufficiency -resulting in more informative explanations. We propose a transparent method that calculates these values by generating explicit perturbations of the input text, allowing the importance scores themselves to be explainable. We employ our method to explain the predictions of different hate speech detection models on the same set of curated examples from a test suite, and show that different values of necessity and sufficiency for identity terms correspond to different kinds of false positive errors, exposing sources of classifier bias against marginalized groups. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Text processing; Case-studies; Detection models; False positive; Speech detection; Text analysis; Text classifiers; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182070; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Röttger2022154,
	author = {Röttger, Paul and Seelawi, Haitham and Nozza, Debora and Talat, Zeerak and Vidgen, Bertie},
	title = {MULTILINGUAL HATECHECK: Functional Tests for Multilingual Hate Speech Detection Models},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {154 – 169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139124792&partnerID=40&md5=f891095ef66d69dae53e2ff78de305bd},
	affiliations = {Rewire, United Kingdom; University of Oxford, United Kingdom; Bocconi University, Italy; Simon Fraser University, Canada},
	abstract = {Hate speech detection models are typically evaluated on held-out test sets. However, this risks painting an incomplete and potentially misleading picture of model performance because of increasingly well-documented systematic gaps and biases in hate speech datasets. To enable more targeted diagnostic insights, recent research has thus introduced functional tests for hate speech detection models. However, these tests currently only exist for English-language content, which means that they cannot support the development of more effective models in other languages spoken by billions across the world. To help address this issue, we introduce MULTILINGUAL HATECHECK (MHC), a suite of functional tests for multilingual hate speech detection models. MHC covers 34 functionalities across ten languages, which is more languages than any other hate speech dataset. To illustrate MHC’s utility, we train and test a high-performing multilingual hate speech detection model, and reveal critical model weaknesses for monolingual and cross-lingual applications. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Cross-lingual; Detection models; English languages; Functional test; Language content; Modeling performance; Recent researches; Speech detection; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714}
}

@CONFERENCE{Veerasamy20221681,
	author = {Veerasamy, Sevagen and Khare, Yash and Ramesh, Abhijit and Adarsh, S. and Singh, Pranjal and Anjali, T.},
	title = {Hate Speech Detection using mono BERT model in custom Content-Management-System},
	year = {2022},
	journal = {Proceedings - 4th International Conference on Smart Systems and Inventive Technology, ICSSIT 2022},
	pages = {1681 – 1686},
	doi = {10.1109/ICSSIT53264.2022.9716428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127363741&doi=10.1109%2fICSSIT53264.2022.9716428&partnerID=40&md5=5b73d31fa9ebc09b5259093222729c3a},
	affiliations = {Amrita Vishwa Vidyapeetham, Amritapuri, India},
	abstract = {Detecting hate speech is more or less natural from the point of view of a human being. Slurs and hateful symbols usually represent attacks on a person's opinion, race or religion. Being in the 21st century and the emergence of E-content has only provided a means of distributing hate speech to more people for a quarter of the effort. It is not hard to find hateful content while scrolling through out social media feed or online forums. On the other side of the coin, the rapid distribution of hate speech online means that there is a standardised way of creating and publishing content through platforms (Forums, blogs, social media, etc...) With the right set of tool, this standardised means can be targeted and fitted with the appropriate means to prevent the spread of such information. Here an open-source content management system is developed for creating and managing content with integrated hate speech detection using the state-of-the-art mono BERT model. In contrast to older language models, which relied on the previous token to predict the next one, BERT is specialized for predicting the next and previous tokens simultaneously. This makes it appropriate for tasks such as hate-speech detection. The model was trained on a combined dataset of Hatebase Twitter and StormFront. This project is mostly targeted to hindering the spread of hateful content in the form of blogs, forum responses and so on. © 2022 IEEE},
	author_keywords = {BERT; Content Management System; Dehatebert-mono-english; Hate Speech; Natural Language Processing},
	keywords = {Knowledge engineering; Open systems; Social networking (online); Speech; Speech recognition; BERT; Content management system; Dehatebert-mono-english; E-content; Hate speech; Human being; Online forums; Social media; Speech detection; State of the art; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 4th International Conference on Smart Systems and Inventive Technology, ICSSIT 2022; Conference date: 20 January 2022 through 22 January 2022; Conference code: 177665}
}

@ARTICLE{Omar2022228,
	author = {Omar, Abdulfattah and Hashem, Mohamed Elarabawy},
	title = {An Evaluation of the Automatic Detection of Hate Speech in Social Media Networks},
	year = {2022},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {13},
	number = {2},
	pages = {228 – 233},
	doi = {10.14569/IJACSA.2022.0130228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126829546&doi=10.14569%2fIJACSA.2022.0130228&partnerID=40&md5=7c2b41363041ee4939dd81f7e90f42ef},
	affiliations = {Department of English, College of Science & Humanities Prince Sattam Bin Abdulaziz University, Saudi Arabia; Faculty of Arts, Port Said University, Egypt; Department of English, College of Science and Arts in Tabarjal, Jouf University, Saudi Arabia; Al-Azhar University, Cairo, Egypt},
	abstract = {Numerous approaches have been developed over recent years to detect hate speech on social media networks. Nevertheless, a great deal of what is generally recognized as hate speech cannot yet be detected. There remain many challenges to assuring the effectiveness and reliability of automatic detection systems in different languages, including Arabic. Social media platforms and networks such as Facebook continue to encounter difficulties regarding the automatic detection of hate speech in Arabic content. Given the importance of developing reliable artificial intelligence and automatic detection systems that can reduce the problems and crimes associated with the spread of hate speech on social media platforms, this study is concerned with evaluating the performance of the automatic detection and tracking of hate speech in Arabic content on Facebook. As an example, the study evaluates the period in October 2020 that came to be known as France’s cartoon controversy. Two different corpora were designed. The first corpus comprised 347 posts deleted by Facebook, now known as Meta. The second corpus was composed of 1,856 posts that were randomly selected using the hashtag إلا رسول الله (except the Prophet of Allah). The results indicate that there is a considerable amount of hate speech taken from or influenced by the Islamic religious discourse, but that automatic detection systems are unable to address the peculiar linguistic features of Arabic. There is also a lack of clarity in defining what constitutes “hate speech”. The study suggests that social media networks, including Facebook, need to adopt more reliable automatic detection systems that consider the linguistic properties of Arabic. Political thinkers and religious scholars should be involved in defining what constitutes hate speech in Arabic. © 2022, (IJACSA) International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {Artificial intelligence; Automatic detection; Facebook; Hate speech; Islamic discourse; Social media networks},
	keywords = {Artificial intelligence; Linguistics; Speech; Speech recognition; Automatic Detection; Automatic detection systems; Automatic tracking; Detection and tracking; Facebook; Hate speech; Islamic discourse; Performance; Social media networks; Social media platforms; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Ibrahim2022175,
	author = {Ibrahim, Muhammad Amien and Arifin, Samsul and Gusti Agung Anom Yudistira, I. and Nariswari, Rinda and Abdillah, Abdul Azis and Murnaka, Nerru Pranuta and Prasetyo, Puguh Wahyu},
	title = {An Explainable AI Model for Hate Speech Detection on Indonesian Twitter},
	year = {2022},
	journal = {CommIT Journal},
	volume = {16},
	number = {2},
	pages = {175 – 182},
	doi = {10.21512/commit.v16i2.8343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137943157&doi=10.21512%2fcommit.v16i2.8343&partnerID=40&md5=90fe95107dbadc8e5c5865a7cc1df38d},
	affiliations = {Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia; Statistics Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia; Department of Mechanical Engineering, Politeknik Negeri Jakarta, Depok, 16425, Indonesia; Department of Mathematics Education, STKIP Surya, Tangerang, 15334, Indonesia; Mathematics Education Department, Universitas Ahmad Dahlan Daerah Istimewa, Yogyakarta, 55166, Indonesia},
	abstract = {To avoid citizen disputes, hate speech on social media, such as Twitter, must be automatically detected. The current research in Indonesian Twitter focuses on developing better hate speech detection models. However, there is limited study on the explainability aspects of hate speech detection. The research aims to explain issues that previous researchers have not detailed and attempt to answer the shortcomings of previous researchers. There are 13,169 tweets in the dataset with labels like "hate speech" and "abusive language". The dataset also provides binary labels on whether hate speech is directed to individual, group, religion, race, physical disability, and gender. In the research, classification is performed by using traditional machine learning models, and the predictions are evaluated using an Explainable AI model, such as Local Interpretable Model-Agnostic Explanations (LIME), to allow users to comprehend why a tweet is regarded as a hateful message. Moreover, models that perform well in classification perceive incorrect words as contributing to hate speech. As a result, such models are unsuitable for deployment in the real world. In the investigation, the combination of XGBoost and logical LIME explanations produces the most logical results. The use of the Explainable AI model highlights the importance of choosing the ideal model while maintaining users trust in the deployed model. © 2022 CommIT Journal. All rights reserved.},
	author_keywords = {Artificial Intelligence Model; Hate Speech; Indonesian Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{Alsagheer202275,
	author = {Alsagheer, Dana and Mansourifar, Hadi and Dehshibi, Mohammad Mahdi and Shi, Weidong},
	title = {Detecting Hate Speech Against Athletes in Social Media},
	year = {2022},
	journal = {2022 International Conference on Intelligent Data Science Technologies and Applications, IDSTA 2022},
	pages = {75 – 81},
	doi = {10.1109/IDSTA55301.2022.9923132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141482435&doi=10.1109%2fIDSTA55301.2022.9923132&partnerID=40&md5=8c780920dbf30f23ebbcda5340fae185},
	affiliations = {University of Houston, Computer Science Department, Houston, United States; Universidad Carlos Iii de Madrid, Department of Computer Science, Madrid, Spain},
	abstract = {When English clubs and the game's governing bodies and organizations turned off their Facebook, Twitter, and Instagram accounts from April 30 to May 1, 2021, the fight against online racism regained a new momentum. However, the Tokyo Olympics revealed new aspects of online bullying that athletes may face during major sporting events. Despite the significant effort put into online hate speech detection research in general, hate speech detection against athletes requires a separate investigation. We show in this paper that abusive language directed at athletes is more varied and difficult to detect. We began with the introduction of the collected data from online comments aimed at three athletes competing in the Tokyo Olympics 2020. Followed by conducting an extensive classification experiments of the collected data to demonstrate its diversity in comparison to other hate speech datasets. This was done to demonstrate that Active Learning outperforms Supervised Learning in hate speech detection against athletes.  © 2022 IEEE.},
	author_keywords = {Active Learning; Hate Speech Detection; Social Media},
	keywords = {Artificial intelligence; Social networking (online); Speech recognition; Active Learning; Facebook; Governing bodies; Hate speech detection; Olympics; Social media; Speech detection; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International Conference on Intelligent Data Science Technologies and Applications, IDSTA 2022; Conference date: 5 September 2022 through 7 September 2022; Conference code: 183740}
}

@ARTICLE{Swain2022335,
	author = {Swain, Manswini and Biswal, Manish and Raj, Priya and Kumar, Abhinav and Mishra, Debahuti},
	title = {Hate and Offensive Language Identification from Social Media: A Machine Learning Approach},
	year = {2022},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {860},
	pages = {335 – 342},
	doi = {10.1007/978-981-16-9488-2_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132914898&doi=10.1007%2f978-981-16-9488-2_30&partnerID=40&md5=99ccb108e133efa2635763fd8057ac3f},
	affiliations = {Department of Computer Science and Engineering, Siksha ‘O’ Anusandhan (Deemed to be University), Odisha, Bhubaneswar, India},
	abstract = {Social media has evolved into a valuable tool for disseminating information while also ensuring that everyone on the site has complete freedom of expression. This ability of social media to openly express oneself to the world has resulted in major issues such as hate speech, cyberbullying, aggression, and general profanity, all of which harm society's well-being. It's critical to pay attention to these issues as it has a significant impact on an individual's life and, in some situations, be suicidal, negatively impacting the victim's mental health. Our key aim is that our approach will automate and quicken the detection of offensive content that has been posted, making it easier to take appropriate steps and moderate these offenses. In this work, we have implemented several popular machine learning classifiers with character N-gram TF-IDF features. Along with this, we have also proposed dense neural network (DNN) and convolutional neural network (CNN) models for the identification of hate speech. In the case of DNN, character N-gram TF-IDF features wherein CNN, word embedding features are used. In the extensive experiments, we found AdaBoost classifiers performed best with the weighted F1-score of 0.86 in the identification of hate speech. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Abusive language; Classification; CNN; Deep learning; Hate speech; Machine learning},
	keywords = {Computational linguistics; Convolutional neural networks; Deep learning; Information dissemination; Learning systems; Social networking (online); Speech recognition; Abusive language; Convolutional neural network; Deep learning; Hate speech; Language identification; Machine-learning; N-grams; Neural-networks; Offensive languages; Social media; Adaptive boosting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Electronic Systems and Intelligent Computing, ESIC 2021; Conference date: 5 November 2021 through 6 November 2021; Conference code: 278829}
}

@ARTICLE{Mandal2022247,
	author = {Mandal, Prasanta and Senapati, Apurbalal and Nag, Amitava},
	title = {Hate-Speech Detection in News Articles: In the Context of West Bengal Assembly Election 2021},
	year = {2022},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {888},
	pages = {247 – 256},
	doi = {10.1007/978-981-19-1520-8_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137604664&doi=10.1007%2f978-981-19-1520-8_19&partnerID=40&md5=cb18c17534c0c5656052bf33d0a6c0ab},
	affiliations = {Department of Computer Science and Engineering, Govt. College of Engineering and Textile Technology, 12, William Carey Road, West Bengal, Hooghly, Serampore, 712201, India; Department of Computer Science and Engineering, Central Institute of Technology Kokrajhar, Assam, Kokrajhar, 783370, India},
	abstract = {A hate speech represents an expression or phrase of offensive language. The intention behind the usage of hate speech is to abuse, dehumanize, disparage, or harass a person or a group of persons based on their race, color, gender, religion, caste, ethnicity, disability, language, belief, nationality, or other factors. Hate speech is also used to express violence, harm, or hatred against the targeted people. Nowadays, the amount of hate speech is overgrowing in social media, online newspapers, etc. It becomes very difficult to moderate the data containing hate speeches manually, as it is a tedious and time-consuming task. Therefore, an automated hate-speech detection technique is very essential. Numerous works have been done to develop the technique or tool for automatic detection of hate speeches in Twitter, Facebook, and other social media data. This paper studies hate speeches on political news articles in the context of the West Bengal Legislative Assembly Election 2021. In the computational aspect, this task is carried out in three phases. First, a political news corpus has been created, and next from that corpus a key word/phrase-based hate-speech identifier is developed. A semi-automated approach has been used to find out the set of hate-speech-related key words/phrases. Finally, the system’s performance is evaluated, and the results are investigated. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Election; Hate speech; News article; West Bengal},
	keywords = {Social networking (online); Speech recognition; Election; Hate speech; Key words; News articles; Offensive languages; Online newspaper; Political news; Social media; Speech detection; West Bengal; Automation},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kanclerz202237,
	author = {Kanclerz, Kamil and Gruza, Marcin and Karanowski, Konrad and Bielaniewcz, Julita and Miłkowski, Piotr and Kocon, Jan and Kazienko, Przemysław},
	title = {What if Ground Truth is Subjective? Personalized Deep Neural Hate Speech Detection},
	year = {2022},
	journal = {1st Workshop on Perspectivist Approaches to Disagreement in NLP, NLPerspectives 2022 as part of Language Resources and Evaluation Conference, LREC 2022 Workshop},
	pages = {37 – 45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145873216&partnerID=40&md5=b5e2a461483e1c0de35b94c83d725ea5},
	affiliations = {Department of Artificial Intelligence, Wrocław University of Science and Technology, Wrocław, Poland},
	abstract = {A unified gold standard commonly exploited in natural language processing (NLP) tasks requires high inter-annotator agreement. However, there are many subjective problems that should respect users’ individual points of view. Therefore, in this paper, we evaluate three different personalized methods for the task of hate speech detection. Our user-centered techniques are compared to the generalizing baseline approach. We conduct our experiments on three datasets including single-task and multi-task hate speech detection. For validation purposes, we introduce a new data split strategy, which prevents data leakage between training and testing. To better understand the behavior of the model for individual users, we carried out personalized ablation studies. Our experiments revealed that all models leveraging user preferences in any case provide significantly better results than most frequently used generalized approaches. This supports our general observation that personalized models should always be considered in all subjective NLP tasks, including hate speech detection. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.},
	author_keywords = {hate speech; human bias; human representation; NLP; offensive content; subjective NLP tasks},
	keywords = {Natural language processing systems; User interfaces; Hate speech; Human bias; Human representation; Language processing; Natural language processing; Natural languages; Offensive content; Subjective natural language processing task; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 1st Workshop on Perspectivist Approaches to Disagreement in NLP, NLPerspectives 2022; Conference date: 20 June 2022; Conference code: 184375}
}

@CONFERENCE{Hoang2022,
	author = {Hoang, Suong N. and Nguyen, Binh and Nguyen, Nam P. and Luu, Son T. and Phan, Hieu T. and Nguyen, Hien D.},
	title = {Enhanced Task-based Knowledge for Lexicon-based Approach in Vietnamese Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - International Conference on Knowledge and Systems Engineering, KSE},
	volume = {2022-October},
	doi = {10.1109/KSE56063.2022.9953615},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146197948&doi=10.1109%2fKSE56063.2022.9953615&partnerID=40&md5=38a57b83f2870398478ee74bca64e863},
	affiliations = {Vietnam National University, Ho Chi Minh City, Viet Nam; Olli Technology, Ho Chi Minh City, Viet Nam; University of Science, Ho Chi Minh City, Viet Nam; University of Information Technology, Ho Chi Minh City, Viet Nam},
	abstract = {The explosion of free-text content on social media has brought the exponential propagation of hate speech. The definition of hate speech is well-defined in the community guidelines of many popular platforms such as Facebook, Tiktok, and Twitter, where any communication judges towards the minor, protected groups are considered hateful content. This paper first points out the sophisticated word-play of malicious users in a Vietnamese Hate Speech (VHS) Dataset. The Center Loss in the training process to disambiguate the task-based sentence embedding is proposed for improving generalizations of the model. Moreover, a task-based lexical attention pooling is also proposed to highlight lexicon-level information and then combined into sentence embedding. The experimental results show that the proposed method improves the F1 score in the ViHSD dataset, while the training time and inference speed are insignificantly changed.  © 2022 IEEE.},
	author_keywords = {BERT; hate speech detection; slot attention; text classification; transformer},
	keywords = {Classification (of information); Social networking (online); Speech communication; Speech recognition; Text processing; BERT; Embeddings; Hate speech detection; Lexicon-based; Slot attention; Speech detection; Task-based; Text classification; Transformer; Vietnamese; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Conference on Knowledge and Systems Engineering, KSE 2022; Conference date: 19 October 2022 through 21 October 2022; Conference code: 184621}
}

@ARTICLE{Xu202293,
	author = {Xu, Depeng and Yuan, Shuhan and Wang, Yueyang and Nwude, Angela Uchechukwu and Zhang, Lu and Zajicek, Anna and Wu, Xintao},
	title = {Coded Hate Speech Detection via Contextual Information},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13280 LNAI},
	pages = {93 – 105},
	doi = {10.1007/978-3-031-05933-9_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130351459&doi=10.1007%2f978-3-031-05933-9_8&partnerID=40&md5=6650946861a19ce06141819473a2565c},
	affiliations = {University of Arkansas, Fayetteville, 72701, AR, United States; Utah State University, Logan, 84322, UT, United States; Paycom Software, Inc., Oklahoma City, 73142, OK, United States},
	abstract = {Hate speech on online social media seriously affects the experience of common users. Many online social media platforms deploy automatic hate speech detection programs to filter out hateful content. To evade detection, coded words have been used to represent the targeted groups in hate speech. For example, on Twitter, “Google” is used to indicate African-Americans, and “Skittles” is used to indicate Muslim. As a result, it would be difficult to determine whether a hateful text including “Google” targets African-Americans or the search engine. In this paper, we develop a coded hate speech detection framework, called CODE, to detect hate speech by judging whether coded words like Google or Skittles are used in the coded meaning or not. Based on a proposed two-layer structure, CODE is able to detect the hateful texts with observed coded words as well as newly emerged coded words. Experimental results on a Twitter dataset show the effectiveness of our approach. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Coded hate speech; Few-shot learning},
	keywords = {Search engines; Speech; Speech recognition; African American; Coded hate speech; Contextual information; Detection framework; Few-shot learning; Google+; Online social medias; Social media platforms; Speech detection; Two-layer structures; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 26th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2022; Conference date: 16 May 2022 through 19 May 2022; Conference code: 277699}
}

@ARTICLE{Sharmila2022105366,
	author = {Sharmila, P. and Anbananthen, Kalaiarasi Sonai Muthu and Chelliah, Deisy and Parthasarathy, Sudhaman and Kannan, Subarmaniam},
	title = {PDHS: Pattern-Based Deep Hate Speech Detection with Improved Tweet Representation},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {105366 – 105376},
	doi = {10.1109/ACCESS.2022.3210177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139414778&doi=10.1109%2fACCESS.2022.3210177&partnerID=40&md5=6b87be686629f24bbb92cb010bd2e9e1},
	affiliations = {Thiagarajar College of Engineering, Tamil Nadu, Madurai, 625015, India; Multimedia University, Faculty of Information Science and Technology, Melaka, 75450, Malaysia},
	abstract = {Automatic hate speech identification in unstructured Twitter is significantly more difficult to analyze, posing a significant challenge. Existing models heavily depend on feature engineering, which increases the time complexity of detecting hate speech. This work aims to classify and detect hate speech using a linguistic pattern-based approach as pre-trained transformer language models. As a result, a novel Pattern-based Deep Hate Speech (PDHS) detection model was proposed to detect the presence of hate speech using a cross-attention encoder with a dual-level attention mechanism. Instead of concatenating the features, our model computes dot product attention for better representation by reducing the irrelevant features. The first level of Attention is extracting aspect terms using predefined parts-of-speech tagging. The second level of Attention is extracting the sentiment polarity to form a pattern. Our proposed model trains the extracted patterns with term frequency, parts-of-speech tag, and Sentiment Scores. The experimental results on Twitter Dataset can learn effective features to enhance the performance with minimum training time and attained 88%F1Score.  © 2013 IEEE.},
	author_keywords = {Attention mechanism; BERT; hate speech; natural language processing; sequence modeling; transformer},
	keywords = {Blogs; Computational linguistics; Modeling languages; Natural language processing systems; Social networking (online); Speech recognition; Attention mechanisms; BERT; Computational modelling; Features extraction; Hate speech; Language processing; Medium; Natural language processing; Natural languages; Sequence models; Transformer; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{Munasinghe2022,
	author = {Munasinghe, Sidath and Thayasivam, Uthayasanker},
	title = {A Deep Learning Ensemble Hate Speech Detection Approach for Sinhala Tweets},
	year = {2022},
	journal = {MERCon 2022 - Moratuwa Engineering Research Conference, Proceedings},
	doi = {10.1109/MERCon55799.2022.9906232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141170667&doi=10.1109%2fMERCon55799.2022.9906232&partnerID=40&md5=db020106a2862f91473e8913c32479f0},
	affiliations = {University of Moratuwa, Department of Computer Science and Engineering, Sri Lanka},
	abstract = {We live in an era where social media platforms play a key role in society. These platforms support most of the native languages and this has enabled people to express their opinions conveniently. Also, it is very common to observe that people express very hateful opinions on social media platforms as well. Several studies have been carried out in this area for the Sinhala language with traditional machine learning models and none of them have shown promising results. Further, current approaches are far behind the latest techniques carried out in high-resource languages. Hence this study presents a deep learning-based approach for hate speech detection which has shown outstanding results for other languages. Moreover, a deep learning ensemble was constructed from these models to evaluate performance improvements. These models were trained and tested on a newly created dataset using the Twitter API. Moreover, the model generalizability was further tested by applying it to a completely new dataset. As per the results, it can be observed that the proposing approach has outperformed the traditional machine learning models and is well generalized. Finally, the experimentation with extra features also reveals that there is a positive impact on the performance using extra features. © 2022 IEEE.},
	author_keywords = {Deep learning; Ensemble; Hate speech; NLP; Sinhala},
	keywords = {Learning systems; Social networking (online); Speech recognition; Deep learning; Detection approach; Ensemble; Hate speech; Machine learning models; Native language; Performance; Sinhalum; Social media platforms; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 8th International Multidisciplinary Moratuwa Engineering Research Conference, MERCon 2022; Conference date: 27 July 2022 through 29 July 2022; Conference code: 183432}
}

@CONFERENCE{Hüsünbeyi202232,
	author = {Hüsünbeyi, Zehra Melce and Akar, Didar and Özgür, Arzucan},
	title = {Identifying Hate Speech using Neural Networks and Discourse Analysis Techniques},
	year = {2022},
	journal = {Proceedings of the Language Resources and Evaluation Conference, LREC 2022 Workshop on Language Technology and Resources for a Fair, Inclusive, and Safe Society, LATERAISSE 2022},
	pages = {32 – 41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145883815&partnerID=40&md5=63c0a53b7711eec4cbc97e8fb74b5fa7},
	affiliations = {Department of Computer Engineering, Department of Linguistics, Bogaziçi University, Turkey},
	abstract = {Discriminatory language, in particular hate speech, is a global problem posing a grave threat to democracy and human rights. Yet, it is not always easy to identify, as it is rarely explicit. In order to detect hate speech, we developed Hierarchical Attention Network (HAN) based and Bidirectional Encoder Representations from Transformer (BERT) based deep learning models to capture the changing discursive cues and understand the context around the discourse. In addition, we designed linguistic features using critical discourse analysis techniques and integrated them to the these neural network models. We studied the compatibility of our model with the hate speech detection problem by comparing it with traditional machine learning models, as well as a Convolution Neural Network (CNN) based model, a Convolutional Neural Network-Gated Recurrent Unit (CNN-GRU) based model which reached significant performance results for hate speech detection. Our results on a manually annotated corpus of print media in Turkish show that the proposed approach is effective for hate speech detection. We believe that the feature sets created for the Turkish language will encourage new studies in the quantitative analysis of hate speech. © European Language Resources Association (ELRA).},
	author_keywords = {bert; deep learning; hierarchical attention network; linguistic features},
	keywords = {Convolution; Neural network models; Recurrent neural networks; Analysis techniques; Bert; Deep learning; Discourse analysis; Global problems; Hierarchical attention network; Human rights; Linguistic features; Neural network analysis; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 1st Workshop on Language Technology and Resources for a Fair, Inclusive, and Safe Society, LATERAISSE 2022; Conference date: 25 June 2022; Conference code: 184372}
}

@CONFERENCE{Nozza2022252,
	author = {Nozza, Debora and Bianchi, Federico and Attanasio, Giuseppe},
	title = {HATE-ITA: Hate Speech Detection in Italian Social Media Text},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {252 – 260},
	doi = {10.18653/v1/2022.woah-1.24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138299698&doi=10.18653%2fv1%2f2022.woah-1.24&partnerID=40&md5=e6e88a9444dae5bace5886585bc136f5},
	affiliations = {Bocconi University, Via Sarfatti 25, Milan, Italy},
	abstract = {Online hate speech is a dangerous phenomenon that can (and should) be promptly counteracted properly. While Natural Language Processing has been successfully used for the purpose, many of the research efforts are directed toward the English language. This choice severely limits the classification power in non-English languages. In this paper, we test several learning frameworks for identifying hate speech in Italian text. We release HATE-ITA, a set of multilanguage models trained on a large set of English data and available Italian datasets. HATE-ITA performs better than mono-lingual models and seems to adapt well also on language-specific slurs. We believe our findings will encourage research in other mid-to-low resource communities and provide a valuable benchmarking tool for the Italian community. © 2022 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Social networking (online); Speech recognition; Classification power; English languages; Language processing; Learning frameworks; Multilanguages; Natural languages; Non-English languages; Research efforts; Social media; Speech detection; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Lu202279,
	author = {Lu, Christina and Jurgens, David},
	title = {The subtle language of exclusion: Identifying the Toxic Speech of Trans-exclusionary Radical Feminists},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {79 – 91},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139157182&partnerID=40&md5=c459407e7f827069913bcce50d4aa6d4},
	affiliations = {Dartmouth College, United States; University of Michigan, United States},
	abstract = {Toxic language can take many forms, from explicit hate speech to more subtle microaggressions. Within this space, models identifying transphobic language have largely focused on overt forms. However, a more pernicious and subtle source of transphobic comments comes in the form of statements made by Trans-exclusionary Radical Feminists (TERFs); these statements often appear seemingly-positive and promote women’s causes and issues, while simultaneously denying the inclusion of transgender women as women. Here, we introduce two models to mitigate this antisocial behavior. The first model identifies TERF users in social media, recognizing that these users are a main source of transphobic material that enters mainstream discussion and whom other users may not desire to engage with in good faith. The second model tackles the harder task of recognizing the masked rhetoric of TERF messages and introduces a new dataset to support this task. Finally, we discuss the ethics of deploying these models to mitigate the harm of this language, arguing for a balanced approach that allows for restorative interactions. © 2022 Association for Computational Linguistics.},
	keywords = {Antisocial behavior; Good faith; Hard task; Social media; Space models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714}
}

@CONFERENCE{Pasupa2022,
	author = {Pasupa, Kitsuchart and Karnbanjob, Werasut and Aksornsiri, Massakorn},
	title = {Hate Speech Detection in Thai Social Media with Ordinal-Imbalanced Text Classification},
	year = {2022},
	journal = {2022 19th International Joint Conference on Computer Science and Software Engineering, JCSSE 2022},
	doi = {10.1109/JCSSE54890.2022.9836312},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136202488&doi=10.1109%2fJCSSE54890.2022.9836312&partnerID=40&md5=caac73d7ce37b5c240950ebfe558d9e2},
	affiliations = {King Mongkut's Institute of Technology Ladkrabang, Faculty of Information Technology, Bangkok, 10520, Thailand},
	abstract = {Cyberbullying has become a serious problem in Thai social media. For example, some Thai people posted hate speeches on Myanmar workers in Thailand during the COVID-19 pandemic, which might elevate hate crime. It is imperative and urgent to detect cyberbullying on Thai social media. The task is a text classification problem. Moreover, hate speeches contain the order of severity levels, but many pieces of work did not consider this point in the model. Therefore, we developed a Thai hate-speech classification method with various loss functions to detect such hate speeches accurately. We evaluated them on a corpus of ordinal-imbalanced Thai text. The evaluated outcomes indicated that the best-in terms of $F$1 -score-model was the model with a loss function of a hybrid between an Ordinal regression loss function and Pearson correlation coefficients (common in similarity function). It yielded an average F1-score of 78.38 %-0.88 % significantly higher than the score achieved by a conventional loss function-and an average mean squared error of 0.2478-5.49 % relative improvement. Thus, the proposed hybrid loss function improved the efficiency of the model.  © 2022 IEEE.},
	author_keywords = {Deep Learning; Hybrid Loss Function; Imbalanced Data; Natural Language Processing; Text Classification},
	keywords = {Computer crime; Correlation methods; COVID-19; Data handling; Deep learning; Learning algorithms; Mean square error; Natural language processing systems; Social networking (online); Text processing; Cyber bullying; Deep learning; Hybrid loss function; Imbalanced data; Language processing; Loss functions; Natural language processing; Natural languages; Social media; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 19th International Joint Conference on Computer Science and Software Engineering, JCSSE 2022; Conference date: 22 June 2022 through 25 June 2022; Conference code: 181472}
}

@CONFERENCE{Huang2022216,
	author = {Huang, Yen-Hao and Harryyanto, Kevin and Tsai, Che-Wei and Pornvattanavichai, Ratana and Chen, Yi-Shin},
	title = {Graph Knowledge Transfer for Offensive Language Identification with Graph Neural Networks},
	year = {2022},
	journal = {Proceedings - 2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science, IRI 2022},
	pages = {216 – 221},
	doi = {10.1109/IRI54793.2022.00056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139084567&doi=10.1109%2fIRI54793.2022.00056&partnerID=40&md5=1fcb4457f12b1049a93349d06b1ebdc7},
	affiliations = {Institute of Information Systems and Applications, National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Department of Computer Science, Hsinchu, Taiwan},
	abstract = {Identifying offensive language (OL) has become ever more important with the rise of online social media (OSM). Most works on OL identification have applied sequential models to learn offensive semantics. In a different light, recent popular graph neural networks (GNNs) model text in a word graph and learn local word-level usages for each document. This work aims to explore text GNNs on learning OL usages in a non-sequential view yet there are two barriers: (1) Similar to sequential models, GNNs also suffer from the out-of-vocabulary (OOV) issue due to the informal usages of OSM texts. (2) Lacking of appropriate edge weights derived from short content to the word graph. Motivated by the rich resources of OSM, this work leverages existing OL corpus to build a global reference graph and proposes a graph knowledge transfer mechanism (GKtran) to tackle the limited extent of learning from short texts. To embed OL knowledge, GKtran infers edge weights from a reference graph and transfers weights to each document's word graph. Edges that connect OOV words are assigned weights through weight propagation. Thus, each document graph is fully weighted for graph classification. Experimental results show that the additional information from training or external data transferred by GKtran effectively improves OL identification with graphs.  © 2022 IEEE.},
	author_keywords = {graph; Graph neural network; Knowledge transfer; Natural language processing; offensive identification},
	keywords = {Backpropagation; Computer software maintenance; Graph theory; Information retrieval systems; Knowledge graph; Knowledge management; Natural language processing systems; Semantics; Social networking (online); Graph; Graph neural networks; Knowledge transfer; Language identification; Language processing; Natural language processing; Natural languages; Offensive identification; Offensive languages; Online social medias; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 23rd IEEE International Conference on Information Reuse and Integration for Data Science, IRI 2022; Conference date: 9 August 2022 through 11 August 2022; Conference code: 182632}
}

@CONFERENCE{Remon2022169,
	author = {Remon, Nasif Istiak and Tuli, Nafisa Hasan and Akash, Ranit Debnath},
	title = {Bengali Hate Speech Detection in Public Facebook Pages},
	year = {2022},
	journal = {2022 International Conference on Innovations in Science, Engineering and Technology, ICISET 2022},
	pages = {169 – 173},
	doi = {10.1109/ICISET54810.2022.9775900},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131737416&doi=10.1109%2fICISET54810.2022.9775900&partnerID=40&md5=5a649822edb887c9ae803e94b9d933f6},
	affiliations = {Metropolitan University, Department of Cse, Sylhet, Bangladesh},
	abstract = {Hate speech is a form of negative communication intended to harm people and communities. Hate speech is quite common in the real world, and it has reached alarming proportions on social media as well. These days our lives have become increasingly reliant on social media platforms, such as Facebook. This is due to the rapid advancement of technology and communication. In Bangladesh, the number of people using social media platforms is also rapidly increasing. In English, detecting hate speech on social media is a difficult task. Comparatively, Bengali is a complicated language with few datasets available. As a result, detection of Bengali hate speech becomes even more challenging. In this paper, we present a new dataset of 10,133 user comments. We have collected them from the comment section of various public Facebook pages. We explore the performance of various machine learning and deep learning models in detecting hate speech. Bengali pre-trained word embeddings from fastText are used to train the models. We are especially interested in Convolutional Neural Network (CNN). To our knowledge it was never used for hate speech detection in binary classification. Another goal of this research is to create a new and large dataset, which will facilitate further research of Bengali Hate Speech Detection. All machine learning and deep learning models performed very well from our experiments. But, Support Vector Machine (SVM) is the one that performed the best among them.  © 2022 IEEE.},
	author_keywords = {Bengali Hate Speech Detection; Bengali Text Classification; Deep Learning.; fastText; Machine Learning; Natural Language Processing (NLP); Word Embedding},
	keywords = {Classification (of information); Convolutional neural networks; Deep learning; Embeddings; Large dataset; Natural language processing systems; Social networking (online); Speech communication; Speech recognition; Support vector machines; Text processing; Transfer learning; Bengali hate speech detection; Bengali text classification; Bengalis; Deep learning.; Embeddings; Fasttext; Machine-learning; Natural language processing; Speech detection; Text classification; Word embedding; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 2022 International Conference on Innovations in Science, Engineering and Technology, ICISET 2022; Conference date: 25 February 2022 through 28 February 2022; Conference code: 179492}
}

@CONFERENCE{Alhejaili202286,
	author = {Alhejaili, Ruba M. and Yafooz, Wael M. S. and Alsaeedi, Abdullah A.},
	title = {Hate Speech and Abusive Laungage Detection in Twitter and Challenges: Review},
	year = {2022},
	journal = {Proceedings of International Conference on Computational Intelligence and Sustainable Engineering Solution, CISES 2022},
	pages = {86 – 94},
	doi = {10.1109/CISES54857.2022.9844317},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137169780&doi=10.1109%2fCISES54857.2022.9844317&partnerID=40&md5=09033aff77bf536c00a1988b9454caf4},
	affiliations = {Taibah University, College of Computer Science, Department of Computer Science and Engineering, Madinah, Saudi Arabia},
	abstract = {The web' content is increasing every day, especially on social media, where all users can express their opinions freely and without restrictions. Accordingly, many negative activities emerged, such as abusive language, racism, and hate speech. Hate speech or abusive language is a manifestation of negative social media that requires tools to detect it. This work provides a comprehensive view of the concepts of abusive language and hate speech. The methods used for detection will also be presented. The paper also reviews previous studies in this field. Finally, the paper recalls the challenges facing the detection of abusive language or hate speech.  © 2022 IEEE.},
	author_keywords = {Classification; Hate Speech; Natural Language; Processing; Social Networks; Text Mining},
	keywords = {Natural language processing systems; Speech recognition; Text processing; Hate speech; Natural languages; Processing; Social media; Social network; Text-mining; Web content; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 1st International Conference on Computational Intelligence and Sustainable Engineering Solution, CISES 2022; Conference date: 20 May 2022 through 21 May 2022; Conference code: 182033}
}

@CONFERENCE{Deepasree Varma2022,
	author = {Deepasree Varma, P. and Vinod, P. and Nandakumar, M. and Akshay, K. and Madhu, Akhil},
	title = {Hate Speech detection in English and Malayalam Code-Mixed Text using BERT embedding},
	year = {2022},
	journal = {Proceedings of International Conference on Computing, Communication, Security and Intelligent Systems, IC3SIS 2022},
	doi = {10.1109/IC3SIS54991.2022.9885339},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139132581&doi=10.1109%2fIC3SIS54991.2022.9885339&partnerID=40&md5=e49bcb00051ef40ec33669cf59d7017d},
	affiliations = {Scms School of Engineering and Technology, Department of Computer Application, Cochin, India; Cochin University of Science and Technology, Department of Computer Application, India; Christ College of Engineering Irinjalakkuda, Department of Electrical and Electronics Engineering, India; SCMS College of Engineering and Technology Karukkutty, Department of Computer Application, Ernakulam, India},
	abstract = {Hate speech detection is a very popular research area for past few years. Hate speech is given various definition by various researchers. In this paper we try to analyse the use of BERT embedding in hate speech detection in low resource language like Malayalam. The crucial challenge faced by researchers in this area are that most non-English languages are represented in code-mixed form in Social media. Here we work with transformer-based models to classify tweets as hate or non-hate content. Hence this is a novel approach that uses BERT in non-English text. © 2022 IEEE.},
	author_keywords = {BERT; Codemix; hate speech; social media},
	keywords = {Codes (symbols); Social networking (online); Speech recognition; BERT; Codemix; Embeddings; Hate speech; Low resource languages; Malayalams; Non-English languages; Research areas; Social media; Speech detection; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 International Conference on Computing, Communication, Security and Intelligent Systems, IC3SIS 2022; Conference date: 23 June 2022 through 25 June 2022; Conference code: 182792}
}

@ARTICLE{Wang202244337,
	author = {Wang, Chih-Chien and Day, Min-Yuh and Wu, Chun-Lian},
	title = {Political Hate Speech Detection and Lexicon Building: A Study in Taiwan},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {44337 – 44346},
	doi = {10.1109/ACCESS.2022.3160712},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127068481&doi=10.1109%2fACCESS.2022.3160712&partnerID=40&md5=ba8f0fcbebbe41ddd16baaab3d1dff75},
	affiliations = {Graduate Institute Of Information Management, National Taipei University, New Taipei City, 23741, Taiwan},
	abstract = {There is the minimal restriction to users' speech in cyberspace. The Internet provides a space where people can freely present their speech, which puts a Utopian sense of freedom of speech into practice. However, the appearance of hate speech is a significant side effect of online freedom of speech. Some users use hate speech to attack others, making the attacked targets uncomfortable. The proliferation of hate speech poses severe challenges to cyber society. Users may hope that social media platforms and online communities promote anti-hate speech. However, hate speech detection is still a developing technology that requires system developers to create a method to detect unacceptable hate speech while maintaining the online freedom of speech environment. No excellence detection approach has yet been proposed, although some literature has focused on it. The current study proposes an approach to build a political hate speech lexicon and train artificial intelligence classifiers to detect hate speech. Our academic and practical contributions include the collection of a Chinese hate speech dataset, creating a Chinese hate speech lexicon, and developing both a deep learning-based and a lexicon-based approach to detect Chinese hate speech. Although we focus on Chinese hate speech detection, our proposed hate speech detection system and hate speech lexicon development approach can also be used for other languages. © 2013 IEEE.},
	author_keywords = {BERT; Bidirectional encoder representations from transformersc; Deep learning; Hate speech; Lexicon; N-gram; Natural language processing; TF-IDF},
	keywords = {Deep learning; Natural language processing systems; Signal encoding; Social networking (online); BERT; Bidirectional encoder representation from transformersc; Deep learning; Hate speech; Language processing; Lexicon; N-grams; Natural language processing; Natural languages; TF-IDF; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access}
}

@CONFERENCE{Me Chit2022119,
	author = {Me Chit, Khin Me and Chan Myae Win Shein, Yi Yi and Yan, Wai and Khine, Aye Hninn},
	title = {SIREN! Detecting Burmese Hate Speech Comments on Social Media},
	year = {2022},
	journal = {KST 2022 - 2022 14th International Conference on Knowledge and Smart Technology},
	pages = {119 – 124},
	doi = {10.1109/KST53302.2022.9729075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127970301&doi=10.1109%2fKST53302.2022.9729075&partnerID=40&md5=56fec3daa26c11a2ef56cfe8cadcf7a1},
	affiliations = {Koe Koe Tech Foundation Inc, Department of Artificial Intelligence, New York, United States},
	abstract = {Hate Speech on Social Media is definitely an evolving threat for every nation, especially for countries like Myanmar. Lack of media and digital literacy is playing a huge role in making people insult to each other or misallocating their stresses to others without physical encounter. Moreover, disingenuous politicians fuel online hate speech campaigns backstage of the elections by targeting different religions in the regard of heretics and using racialism. To emphasize this matter, we scraped over 16,000 social media comments from the most popular social media platform in Myanmar and performed hate-speech research using those samples. With the precise definition of a hate speech labelling guideline, annotation on the sample dataset was done systematically and efficiently. Experiments and evaluations were conducted using different linear and non-linear deep-learning classification models. Performances of the models are at the peak in Logistic Regression among linear models with 0.8974 AUC score and XLM-RoBERTa among deep learning models with 0.8958 AUC score on the test dataset. We observed that it is more advantageous to use linear models on our dataset since they achieved comparable results to the deep learning models and have much lower computational cost.  © 2022 IEEE.},
	author_keywords = {deep learning; hate speech; machine learning; natural language processing; social media analysis; text classification},
	keywords = {Classification (of information); Deep learning; Learning algorithms; Logistic regression; Natural language processing systems; Speech; Speech recognition; Statistical tests; Text processing; Burmese; Deep learning; Digital literacies; Hate speech; Learning models; Linear modeling; Myanmars; Social media; Social media analysis; Social media platforms; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Conference on Knowledge and Smart Technology, KST 2022; Conference date: 26 January 2022 through 29 January 2022; Conference code: 177713}
}

@ARTICLE{Alaoui2022,
	author = {Alaoui, Safae Sossi and Farhaoui, Yousef and Aksasse, Brahim},
	title = {Hate Speech Detection Using Text Mining and Machine Learning},
	year = {2022},
	journal = {International Journal of Decision Support System Technology},
	volume = {14},
	number = {1},
	doi = {10.4018/IJDSST.286680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135933532&doi=10.4018%2fIJDSST.286680&partnerID=40&md5=51d32c968a2e704fcbaeac2e589fe963},
	affiliations = {Faculty of Sciences and Techniques, Moulay Ismail University of Meknes, Morocco, Morocco},
	abstract = {Automatic hate speech detection on social media is becoming an outstanding concern in modern countries. Indeed, hate speech towards people brings about violent acts and social chaos; hence, law prohibits it, and it engenders moral and legal implications. It is crucial that we can precisely categorize hate speech and not hate speech automatically. This allows us to identify easily real people who represent a threat for our society. In this paper, the authors applied a complete text mining process and naïve bayes machine learning classification algorithm to two different data sets (tweets_Num1 and tweets_Num2) taken from Twitter to better classify tweets. The results obtained demonstrate that the model performed well regarding different metrics based on the confusion matrix including the accuracy metric, which achieved 87. 23% on the first dataset and 93. 06% on the second. Copyright © 2022, IGI Global.},
	author_keywords = {Hate Speech; Machine Learning; Naïve Bayes; Sentiment Analysis; Text Mining},
	keywords = {Classification (of information); Data mining; Machine learning; Social networking (online); Speech recognition; Hate speech; Legal implications; Machine learning classification; Machine-learning; Mining process; Naive bayes; Sentiment analysis; Social media; Speech detection; Text-mining; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33}
}

@ARTICLE{Gangurde2022100,
	author = {Gangurde, Akshaya and Mankar, Purva and Chaudhari, Deptii and Pawar, Ambika},
	title = {A Systematic Bibliometric Analysis of Hate Speech Detection on Social Media Sites},
	year = {2022},
	journal = {Journal of Scientometric Research},
	volume = {11},
	number = {1},
	pages = {100 – 111},
	doi = {10.5530/jscires.11.1.10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132101577&doi=10.5530%2fjscires.11.1.10&partnerID=40&md5=29b41c9fa6df824d6dd173e54700d628},
	affiliations = {Symbiosis Institute of Technology, Symbiosis International University (Deemed University), Maharashtra, Pune, India; Hope Foundation's International Institute of Information Technology, Maharashtra, Pune, India},
	abstract = {With the increasing availability of internet facilities for everyone across the globe, the internet plays an integral part in modern communication. People have the ease of contacting others and sharing thoughts and ideas quickly. This has raised an enormous amount of spread of Hate Speech on Online Social Media Sites. This paper aims to provide systematic bibliometric analysis and mappings of existing literature for Hate Speech Detection and to identify the existence of Hate speech-related research. Bibliometric Analysis of Machine Learning and Deep Learning articles in Hate, hostile, and abusive speech is considered. This is accomplished using the SCOPUS database, with tools like VOSViewer, Biblioshiny, and ScienceScape. Explored parameters consist of the document type, most active countries, top journals, relevant affiliations, trending topics, etc. It is observed that the current literature on hate speech is concentrated on a specific philosophy. An unexpected need to rectify this situation was evident from this bibliometric analysis due to recent occurrences of hate speech in the digital world.  © The Author(s). 2022.},
	author_keywords = {Hate Speech; Hostile Speech; Machine Learning; Natural Language Processing; Scopus; Social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kumar20221561,
	author = {Kumar, Kgssv Akhil and Kanisha, B.},
	title = {Analysis of Multiple Toxicities Using ML Algorithms to Detect Toxic Comments},
	year = {2022},
	journal = {2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2022},
	pages = {1561 – 1566},
	doi = {10.1109/ICACITE53722.2022.9823822},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135462383&doi=10.1109%2fICACITE53722.2022.9823822&partnerID=40&md5=3317e7126359d79469feda3cc3d2365d},
	affiliations = {SRM Institute of Science and Technology, India},
	abstract = {Toxic Comment Classification is a classification problem that needs to be addressed these days. People can expresstheir thoughts on the internet via social media platforms. Hence itis important to set up some guidelines, which address the kind of information that is allowed to be posted. Hence The study of comments and their classification is necessary. The main aim of the following project is to understand whether the followingcomment falls under the toxic or nontoxic category by using multiple machine learning techniques. The following study uses 6 different traits, with the help of □ vectorization a dictionary will be created out of known vocabulary(Dataset) to train the ML model. Since Multiple Traits are presentthe ML model has to get trained multiple times against each trait.This helps us to identify, which algorithm performs best in identifying multiple types of toxicities. It was identified that the Random Forest algorithm performed well against all types of traitswhich gave us a good accuracy of 85% with a precision of 91%. During the preliminary research, it was concluded that most of theresearch which was revolving around the topic was limited to Demographic/local Languages. We tried identifying a classifier for the English language. © 2022 IEEE.},
	author_keywords = {Decision Tree; K nearest Neighbors; logistic regression; Machine Learning; Naïve Bayes; Random Forest; Toxic Comments},
	keywords = {Logistic regression; Machine learning; Nearest neighbor search; Random forests; Toxicity; K near neighbor; Logistics regressions; Machine learning techniques; Machine-learning; Multiple machine; Naive bayes; Nearest-neighbour; Random forests; Social media platforms; Toxic comment; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2nd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2022; Conference date: 28 April 2022 through 29 April 2022; Conference code: 181064}
}

@ARTICLE{Elbasani2022677,
	author = {Elbasani, Ermal and Kim, Jeong-Dong},
	title = {AMR-CNN: Abstract Meaning Representation with Convolution Neural Network for Toxic Content Detection},
	year = {2022},
	journal = {Journal of Web Engineering},
	volume = {21},
	number = {3},
	pages = {677 – 692},
	doi = {10.13052/jwe1540-9589.2135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126470139&doi=10.13052%2fjwe1540-9589.2135&partnerID=40&md5=383e290015655e458fe86ced4516b151},
	affiliations = {Department of Computer Science and Engineering, Sun Moon University, Asan, 31460, South Korea; Genome-based BioIT Convergence Institute, Sun Moon University, Asan, 31460, South Korea},
	abstract = {Recognizing the offensive, abusive, and profanity of multimedia content on the web has been a challenge to keep the web environment for user s freedom of speech. As profanity filtering function has been developed and applied in text, audio, and video context in platforms such as social media, entertainment, and education, the number of methods to trick the web-based application also has been increased and became a new issue to be solved. Compared to commonly developed toxic content detection systems that use lexicon and keyword-based detection, this work tries to embrace a different approach by the meaning of the sentence. Meaning representation is a way to grasp the meaning of linguistic input. This work proposed a data-driven approach utilizing Abstract meaning Representation to extract the meaning of the online text content into a convolutional neural network to detect level profanity. This work implements the proposed model in two kinds of datasets from the Offensive Language Identification Dataset and other datasets from the Offensive Hate dataset merged with the Twitter Sentiment Analysis dataset. The results indicate that the proposed model performs effectively, and can achieve a satisfactory accuracy in recognizing the level of online text content toxicity. © 2022 River Publishers. All rights reserved.},
	author_keywords = {datacenter carbon footprint computation.; Datacenter design; energy efficiency of datacenter; energy efficient metrics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Bronze Open Access}
}

@CONFERENCE{Nejadgholi20225517,
	author = {Nejadgholi, Isar and Fraser, Kathleen C. and Kiritchenko, Svetlana},
	title = {Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors},
	year = {2022},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {5517 – 5529},
	doi = {10.18653/v1/2022.acl-long.378},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141590493&doi=10.18653%2fv1%2f2022.acl-long.378&partnerID=40&md5=72623ba0b1da01045638e13f9ca0c308},
	affiliations = {National Research Council Canada, Ottawa, Canada},
	abstract = {Robustness of machine learning models on ever-changing real-world data is critical, especially for applications affecting human well-being such as content moderation. New kinds of abusive language continually emerge in online discussions in response to current events (e.g., COVID-19), and the deployed abuse detection systems should be updated regularly to remain accurate. In this paper, we show that general abusive language classifiers tend to be fairly reliable in detecting out-of-domain explicitly abusive utterances but fail to detect new types of more subtle, implicit abuse. Next, we propose an interpretability technique, based on the Testing Concept Activation Vector (TCAV) method from computer vision, to quantify the sensitivity of a trained model to the human-defined concepts of explicit and implicit abusive language, and use that to explain the generalizability of the model on new data, in this case, COVID-related anti-Asian hate speech. Extending this technique, we introduce a novel metric, Degree of Explicitness, for a single instance and show that the new metric is beneficial in suggesting out-of-domain unlabeled examples to effectively enrich the training data with informative, implicitly abusive texts. © 2022 Association for Computational Linguistics.},
	keywords = {Chemical activation; Computational linguistics; Online systems; Activation vectors; Current events; Detection system; Interpretability; Language detection; Machine learning models; Online discussions; Real-world; Vector method; Well being; COVID-19},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181737; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Müller2022581,
	author = {Müller, Kilian},
	title = {Elicitation of Requirements for a NLP-Model Store for Abusive Language Detection},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1582 CCIS},
	pages = {581 – 588},
	doi = {10.1007/978-3-031-06391-6_72},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133179454&doi=10.1007%2f978-3-031-06391-6_72&partnerID=40&md5=76d2ae0a34f4421eb49b3f740ec01f4d},
	affiliations = {Department for Information Systems, University of Muenster, Leonardo-Campus 3, Münster, 48149, Germany},
	abstract = {While in social media users most commonly interact with each other without a guiding entity, the discussion space of newspaper platforms is moderated by community managers, who invest considerable amounts of time and effort in keeping comment sections clean. To reduce this effort and allow community managers again to more freely interact with their users, automated comment moderation systems (ACMS) be be utilized. However, most newspapers do not have the expertise to create, update, and maintain machine learning (ML)-models. Thus, they are forced to rely on proprietary off-the-shelf solutions. However, if they want to keep their sovereignty over their data and systems, they would need access to models which could be integrated within their current moderation or content management systems. One option could be a platform for newspapers and data scientists where the data scientists could sell their pre-trained models and where newspapers could hire data scientists to create tailor-made models for them. In order to identify the requirements, community managers have for such systems, we conducted a series of semi-structured interviews with community managers of newspapers of varying size (from local to national). Furthermore, the information was enriched by the participation in multiple workshops on content moderation. We were able to elicit five major technical requirements necessary to create the described design artifact. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Abusive language; Comment moderation; Model store},
	keywords = {Managers; Newsprint; Space platforms; 'current; Abusive language; Comment moderation; Content management system; Language detection; Machine learning models; Model store; Semi structured interviews; Social media; Tailor made models; Information management},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 24th International Conference on Human-Computer Interaction, HCI International, HCII 2022; Conference date: 26 June 2022 through 1 July 2022; Conference code: 279199}
}

@CONFERENCE{Nayak20221179,
	author = {Nayak, Ajay and Agrawal, Anupam},
	title = {Detection of hate speech in Social media memes: A comparative Analysis},
	year = {2022},
	journal = {Proceedings of the 2022 3rd International Conference on Intelligent Computing, Instrumentation and Control Technologies: Computational Intelligence for Smart Systems, ICICICT 2022},
	pages = {1179 – 1185},
	doi = {10.1109/ICICICT54557.2022.9917633},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141377149&doi=10.1109%2fICICICT54557.2022.9917633&partnerID=40&md5=a50f158df65c9246b33a5705ab93fb88},
	affiliations = {Indian Institute of Information Technology, Department of Information Technology, Prayagraj, Allahabad, India},
	abstract = {This work projects light upon the challenges of hate speech detection in memes and demonstrates the various machine learning model to automatically detect hate in the internet memes. Memes are the visual content shared on the social media in the form of combination of picture and some textual phrases to depict light humour or jokes. However, some images in the form of memes can also be used to convey misinformation and hate, so their early automatic detection is necessary to stop the hate spreading to wide range of users or population which may cause unrest and harm to human life and property. In this paper, the hateful meme dataset by Facebook AI has been used to test the various unimodal and a multimodal approach to baseline performance for these models and highlight the challenges these hate memes pose to the community.  © 2022 IEEE.},
	author_keywords = {hate speech detection; multimodal; social media memes; unimodal},
	keywords = {Social networking (online); Speech recognition; Automatic Detection; Comparative analyzes; Hate speech detection; Machine learning models; Multi-modal; Social media; Social medium meme; Speech detection; Unimodal; Visual content; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International Conference on Intelligent Computing, Instrumentation and Control Technologies, ICICICT 2022; Conference date: 11 August 2022 through 12 August 2022; Conference code: 183655}
}

@ARTICLE{Alkomah2022860,
	author = {Alkomah, Fatimah and Salati, Sanaz and Ma, Xiaogang},
	title = {A New Hate Speech Detection System based on Textual and Psychological Features},
	year = {2022},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {13},
	number = {8},
	pages = {860 – 869},
	doi = {10.14569/IJACSA.2022.01308100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137159530&doi=10.14569%2fIJACSA.2022.01308100&partnerID=40&md5=e13ea00b57c8bf80fd77e2cb57c9a3ed},
	affiliations = {Department of Computer Science, University of Idaho, Moscow, ID, United States},
	abstract = {Hate speech often spreads on social media and harms individuals and the community. Machine learning models have been proposed to detect hate speech in social media; however, several issues presently limit the performance of current approaches. One challenge is the issue of having diverse comprehensions of hate speech constructs which will lead to many speech categories and different interpretations. In addition, certain language-specific features, and short text issues, such as Twitter, exacerbate the problem. Moreover, current machine learning approaches lack universality due to small datasets and the adoption of a few features of hateful speech. This paper develops and builds new feature sets based on frequencies of textual tokens and psychological characteristics. Then, the study evaluates several machine learning methods over a large dataset. Results showed that the Random Forest and BERT methods are the most valuable for detecting hate speech content. Furthermore, the most dominant features that are helpful for hate speech detection methods combine psychological features and Term-Frequency Inverse Document-Frequency (TFIDF) features. Therefore, the proposed approach could identify hate speech on social media platforms like Twitter. © 2022, International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {Hate speech classification; Hate speech detection; Hate speech features; Hate speech methods},
	keywords = {Feature extraction; Large dataset; Social networking (online); Speech recognition; Text processing; 'current; Hate speech classification; Hate speech detection; Hate speech feature; Hate speech method; Psychological features; Social media; Speech classification; Speech detection; Speech features; Decision trees},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Gémes2022,
	author = {Gémes, Kinga and Kovács, Ádám and Recski, Gábor},
	title = {Offensive text detection across languages and datasets using rule-based and hybrid methods},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3318},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146252334&partnerID=40&md5=f14c84b98aeb14364503d3190fed6bf9},
	affiliations = {TU Wien, Favoritenstraße 9-11., Vienna, 1040, Austria; Budapest University of Technology and Economics, Műegyetem rkp. 3., Budapest, H-1111, Hungary},
	abstract = {We investigate the potential of rule-based systems for the task of offensive text detection in English and German, and demonstrate their effectiveness in low-resource settings, as an alternative or addition to transfer learning across tasks and languages. Task definitions and annotation guidelines used by existing datasets show great variety, hence state-of-the-art machine learning models do not transfer well across datasets or languages. Furthermore, such systems lack explainability and pose a critical risk of unintended bias. We present simple rule systems based on semantic graphs for classifying offensive text in two languages and provide both quantitative and qualitative comparison of their performance with deep learning models on 5 datasets across multiple languages and shared tasks. © 2022 Copyright for this paper by its authors.},
	author_keywords = {human in the loop learning; offensive text; rule-based methods},
	keywords = {Classification (of information); Learning systems; Semantics; Transfer learning; Human in the loop learning; Human-in-the-loop; Hybrid method; Low-resource settings; Offensive text; Rule-based method; Rules based systems; State of the art; Text detection; Transfer learning; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 International Conference on Information and Knowledge Management Workshops, CIKM-WS 2022; Conference date: 17 October 2022 through 21 October 2022; Conference code: 185910}
}

@ARTICLE{Althobaiti2022972,
	author = {Althobaiti, Maha Jarallah},
	title = {BERT-based Approach to Arabic Hate Speech and Offensive Language Detection in Twitter: Exploiting Emojis and Sentiment Analysis},
	year = {2022},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {13},
	number = {5},
	pages = {972 – 980},
	doi = {10.14569/IJACSA.2022.01305109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131416204&doi=10.14569%2fIJACSA.2022.01305109&partnerID=40&md5=456fcb3ace247d878aac7d01e2ce5b66},
	affiliations = {Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, 21944, Saudi Arabia},
	abstract = {The user-generated content on the internet including that on social media may contain offensive language and hate speech which negatively affect the mental health of the whole internet society and may lead to hate crimes. Intelligent models for automatic detection of offensive language and hate speech have attracted significant attention recently. In this paper, we propose an automatic method for detecting offensive language and fine-grained hate speech from Arabic tweets. We compare between BERT and two conventional machine learning techniques (SVM, logistic regression).We also investigate the use of sentiment analysis and emojis descriptions as appending features along with the textual content of the tweets. The experiments shows that BERT-based model gives the best results, surpassing the best benchmark systems in the literature, on all three tasks: (a) offensive language detection with 84.3% F1-score, (b) hate speech detection with 81.8% F1-score, and (c) fine-grained hatespeech recognition (e.g., race, religion, social class, etc.) with 45.1% F1-score. The use of sentiment analysis slightly improves the performance of the models when detecting offensive language and hate speech but has no positive effect on the performance of the models when recognising the type of the hate speech. The use of textual emoji description as features can improve or deteriorate the performance of the models depending on the size of the examples per class and whether the emojis are considered among distinctive features between classes or not. © 2022. International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {Bert; Deep learning; Emoji; Hate speech detection; Offensive language detection; Sentiment analysis; Transformer-based model},
	keywords = {C (programming language); Deep learning; Logistic regression; Sentiment analysis; Social networking (online); Speech recognition; Bert; Deep learning; Emoji; Hate speech detection; Language detection; Offensive language detection; Offensive languages; Sentiment analysis; Speech detection; Transformer-based model; Speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Gold Open Access}
}

@ARTICLE{Tripathy202295,
	author = {Tripathy, Arpita and Goyal, Anshika and Tyagi, Urvashi and Tanwar, Poonam},
	title = {Detecting Twitter Hate Speech Using Sentiment Analysis},
	year = {2022},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {875},
	pages = {95 – 105},
	doi = {10.1007/978-981-19-0284-0_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128976896&doi=10.1007%2f978-981-19-0284-0_8&partnerID=40&md5=134e71624acb6167a35ed511f1ccb17c},
	affiliations = {Department of CSE, MRIIRS, Faridabad, India; Faculty, CSE, FET, MRIIRS, Faridabad, India},
	abstract = {In current era due to the rapid increase in the consumption of the Internet by people of different cultural backgrounds, malicious content on the Internet has become an endless problem. In the automatic detection of malicious text content, distinguishing between hate speech and profanity will be a major issue. The police investigating strategies for positive or negative emotions in the text. Companies use it extensively to perceive emotions in social data, measure overall reputation, and understand customers. For example, if you use sentiment analysis to mechanically analyze more than 4000 reviews related to your products, you can more easily determine whether customers are satisfied with your customer service and pricing plans. The Twitter information set is usually used for comparative analysis of the model. Information science provides useful data based on large amounts of complex information or big data. Information science/engineering combines different fields of statistics and computer science to interpret information for decision-making purposes. The purpose of this article is to provide the method for detecting twitter the speech using Support vector machine and Machine Learning algorithm. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Machine learning (ML); Sentiment analysis; Support vector machine (SVM)},
	keywords = {Behavioral research; Decision making; Learning algorithms; Sales; Sentiment analysis; Social networking (online); Speech recognition; 'current; Automatic Detection; Cultural backgrounds; Customer-service; Machine learning; Sentiment analysis; Social datum; Support vector machine; Support vectors machine; Text content; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Emerging Technologies for Computing, Communications, and Smart Cities, ETCCS 2021; Conference date: 21 August 2021 through 22 August 2021; Conference code: 277079}
}

@CONFERENCE{Arango2022122,
	author = {Arango, Aymé and Pérez, Jorge and Poblete, Bárbara and Proust, Valentina and Saldaña, Magdalena},
	title = {Multilingual Resources for Offensive Language Detection},
	year = {2022},
	journal = {WOAH 2022 - 6th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {122 – 130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139110961&partnerID=40&md5=cc1f7293ca0ed3921c11b1b7635f38d4},
	affiliations = {Departament of Computer Science, University of Chile, Chile; Communication Faculty, Pontifical Catholic University of Chile, Chile; Millennium Institute of Data Foundation, Santiago, Chile},
	abstract = {Most of the published approaches and resources for offensive language and hate speech detection are tailored for the English language. In consequence, cross-lingual and cross-cultural perspectives lack some essential resources. The lack of diversity of the datasets in Spanish is notable. Variations throughout Spanish-speaking countries make existing datasets not enough to encompass the task in the different Spanish variants. We manually annotated 9834 tweets from Chile to enrich the existing Spanish resources with different words and new targets of hate that have not been considered in previous studies. We conducted several cross-dataset evaluation experiments of the models published in the literature using our Chilean dataset and two others in English and Spanish. We propose a comparative framework for quickly conducting comparative experiments using different previously published models. In addition, we set up a Codalab competition for further comparison of new models in a standard scenario, that is, data partitions and evaluation metrics. All resources can be accessed through a centralized repository for researchers to get a complete picture of the progress on the multilingual hate speech and offensive language detection task. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Comparative experiments; Cross-dataset evaluation; Cross-lingual; Data evaluation; Data partition; English languages; Evaluation experiments; Language detection; Offensive languages; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 6th Workshop on Online Abuse and Harms, WOAH 2022; Conference date: 14 July 2022; Conference code: 182714}
}

@CONFERENCE{Du2022,
	author = {Du, Chengxuan and Weng, Xin},
	title = {Deep neural network approaches in hate speech detection},
	year = {2022},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {12163},
	doi = {10.1117/12.2628169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131788071&doi=10.1117%2f12.2628169&partnerID=40&md5=71272ba0f4975944675cba9917aa0984},
	affiliations = {Computer Science, Penn State University, State College, 16801, United States; Computer Science, Trent University, Peterborough, K9L 0G2, ON, Canada},
	abstract = {Over the past decade, the number of automated communication and posts on social media platforms has made it much easier to generate and spread hate speech in tandem with the related social implications. Social media companies have experienced intense pressure to address the issue and help minimize incidences of hate speech on their platforms. In this regard, machine language processing techniques such as natural language processing can help detect online hate speech. Natural language processing is a branch of machine language that enables one to understand human speech, analyze, manipulate it, and potentially understand language generated by humans. Other deep learning techniques that could help explore this subject and improve hate speech detection, such as convolutional neural network, recurrent neural network, and graph neural network, will be explored in this paper.  © COPYRIGHT SPIE.},
	author_keywords = {Deep Learning; Hate Speech; Neural Network; Offensive Language},
	keywords = {Deep neural networks; Graph neural networks; Natural language processing systems; Recurrent neural networks; Social networking (online); Speech communication; Speech recognition; Deep learning; Hate speech; Machine languages; Media companies; Neural-networks; Offensive languages; Social implication; Social media; Social media platforms; Speech detection; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Conference on Statistics, Applied Mathematics, and Computing Science, CSAMCS 2021; Conference date: 26 November 2021 through 28 November 2021; Conference code: 179701}
}

@CONFERENCE{Trandaba20222883,
	author = {Trandaba, Diana and Gifu, Daniela and Adrian, Plescu},
	title = {Detecting Offensive Language in Romanian Social Media},
	year = {2022},
	journal = {Procedia Computer Science},
	volume = {207},
	pages = {2883 – 2890},
	doi = {10.1016/j.procs.2022.09.346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143355854&doi=10.1016%2fj.procs.2022.09.346&partnerID=40&md5=ab6c8787902881f883f7203edcfaf43d},
	affiliations = {Faculty of Computer Science, Alexandru Ioan Cuza University, General Berthelot, 16, Iasi, 700483, Romania; Institute of Computer Science, Romanian Academy, Iasi Branch, Bulevardul Carol I, 8, 700505, Romania},
	abstract = {Due to an exponential increase in the use of Internet by persons from different countries and educational backgrounds, the offensive online language detection has become a significant task facing natural language processing. Considering the major negative impact of this type of content in the case of youngers, detecting online toxic language to protect users' online safety becomes an urgent issue. The project has two main goals: (1) developing an annotated corpus of offensive content for Romanian language and (2) testing various machine learning algorithms to identify a best approach. The proposed methods achieve results with a few percentages more than the accuracy of the current SoTA. © 2022 The Authors. Published by Elsevier B.V.},
	author_keywords = {machine learning; offensive language; social media; toxic comments},
	keywords = {Learning algorithms; Natural language processing systems; Social networking (online); Exponential increase; Language detection; Language processing; Machine-learning; Natural languages; Offensive languages; Online languages; Romanians; Social media; Toxic comment; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 26th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2022; Conference date: 7 September 2022 through 9 September 2022; Conference code: 184401; All Open Access, Gold Open Access}
}

@CONFERENCE{Bose2022372,
	author = {Bose, Tulika and Aletras, Nikolaos and Illina, Irina and Fohr, Dominique},
	title = {Dynamically Refined Regularization for Improving Cross-corpora Hate Speech Detection},
	year = {2022},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {372 – 382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142217053&partnerID=40&md5=6a5f3922ec406e617ad125e0055a0d61},
	affiliations = {Universite de Lorraine, CNRS, Inria, LORIA, Nancy, F-54000, France; University of Sheffield, United Kingdom},
	abstract = {Hate speech classifiers exhibit substantial performance degradation when evaluated on datasets different from the source. This is due to learning spurious correlations between words that are not necessarily relevant to hateful language, and hate speech labels from the training corpus. Previous work has attempted to mitigate this problem by regularizing specific terms from pre-defined static dictionaries. While this has been demonstrated to improve the generalizability of classifiers, the coverage of such methods is limited and the dictionaries require regular manual updates from human experts. In this paper, we propose to automatically identify and reduce spurious correlations using attribution methods with dynamic refinement of the list of terms that need to be regularized during training. Our approach is flexible and improves the cross-corpora performance over previous work independently and in combination with pre-defined dictionaries.. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Dynamic refinement; Human expert; Performance; Performance degradation; Regularisation; Speech detection; Training corpus; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181734}
}

@ARTICLE{Shannaq202275018,
	author = {Shannaq, Fatima and Hammo, Bassam and Faris, Hossam and Castillo-Valdivieso, Pedro A.},
	title = {Offensive Language Detection in Arabic Social Networks Using Evolutionary-Based Classifiers Learned From Fine-Tuned Embeddings},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {75018 – 75039},
	doi = {10.1109/ACCESS.2022.3190960},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135249168&doi=10.1109%2fACCESS.2022.3190960&partnerID=40&md5=e0914b5b1017106174faaa99f7fea7f2},
	affiliations = {The University of Jordan, King Abdullah Ii School of Information Technology, Amman, 11942, Jordan; Princess Sumaya University for Technology, King Hussein School of Computing Sciences, Amman, 11941, Jordan; ETSIIT-CITIC, University of Granada, Department of Computer Architecture and Technology, Granada, 18011, Spain},
	abstract = {Social networks facilitate communication between people from all over the world. Unfortunately, the excessive use of social networks leads to the rise of antisocial behaviors such as the spread of online offensive language, cyberbullying (CB), and hate speech (HS). Therefore, abusive\offensive and hate detection become a crucial part of cyberharassment. Manual detection of cyberharassment is cumbersome, slow, and not even feasible in rapidly growing data. In this study, we addressed the challenges of automatic detection of the offensive tweets in the Arabic language. The main contribution of this study is to design and implement an intelligent prediction system encompassing a two-stage optimization approach to identify and classify the offensive from the non-offensive text. In the first stage, the proposed approach fine-tuned the pre-trained word embedding models by training them for several epochs on the training dataset. The embeddings of the vocabularies in the new dataset are trained and added to the old embeddings. While in the second stage, it employed a hybrid approach of two classifiers, namely XGBoost and SVM, and a genetic algorithm (GA) to mitigate the drawback of the classifiers in finding the optimal hyperparameter values to run the proposed approach. We tested the proposed approach on Arabic Cyberbullying Corpus (ArCybC), which contains tweets collected from four Twitter domains: gaming, sports, news, and celebrities. The ArCybC dataset has four categories: sexual, racial, intelligence, and appearance. The proposed approach produced superior results, in which the SVM algorithm with the Aravec SkipGram word embedding model achieved an accuracy rate of 88.2% and an F1-score rate of 87.8%.  © 2013 IEEE.},
	author_keywords = {Arabic harassment dataset; deep learning; evolutionary algorithm; fine-tuned word embedding; hate speech; offensive language; optimization},
	keywords = {Computer crime; Deep learning; Genetic algorithms; Social networking (online); Speech communication; Speech recognition; Arabic harassment dataset; Deep learning; Embeddings; Fine-tuned word embedding; Hate speech; Offensive languages; Optimisations; Social networking (online); Support vectors machine; Support vector machines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Salehgohari2022243,
	author = {Salehgohari, Ali and Mirhosseini, Mina and Tabrizchi, Hamed and Koczy, Annamaria Varkonyi},
	title = {Abusive Language Detection on Social Media using Bidirectional Long-Short Term Memory},
	year = {2022},
	journal = {INES 2022 - 26th IEEE International Conference on Intelligent Engineering Systems 2022, Proceedings},
	pages = {243 – 247},
	doi = {10.1109/INES56734.2022.9922628},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141886549&doi=10.1109%2fINES56734.2022.9922628&partnerID=40&md5=9fb909483153e04ab9833a194713f033},
	affiliations = {Shahid Bahonar University of Kerman, Department of Computer Science, Kerman, Iran; Graduate University of Advanced Technology, Department of Energy Management and Optimisation, Kerman, Iran; University of Tabriz, Faculty of Mathematics Statistics and Computer Science, Department of Computer Science, Tabriz, Iran; J. Selye University, Department of Mathematics and Informatics, Komarno, Slovakia},
	abstract = {Social media has allowed anybody to share their opinions and engage with the general public, but it has also become a platform for harsh language, cruel conduct, personal assaults, and cyberbullying. However, determining whether a comment or a post is violent or not remains difficult and time-consuming, and most social media businesses are always seeking better ways to do so. This may be automated to assist in detecting nasty comments, promote user safety, preserve websites, and enhance online dialogue. The toxic comment dataset is utilized in this research to train a deep learning model that categorizes comments into the following categories: severe toxic, toxic, threat, obscene, insult, and identity hatred. To categorize comments, use a bidirectional long short-Term memory cell (Bi-LSTM).  © 2022 IEEE.},
	author_keywords = {Abusive Language Detection; Bidirectional LSTM; deep learning; Social media},
	keywords = {Brain; Social networking (online); Abusive language detection; Bidirectional LSTM; Cyber bullying; Deep learning; General publics; Language detection; Learning models; Media business; Online dialog; Social media; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 26th IEEE International Conference on Intelligent Engineering Systems, INES 2022; Conference date: 12 August 2022 through 15 August 2022; Conference code: 183801}
}

@ARTICLE{Santana2022177,
	author = {Santana, Brenda Salenave and Vanin, Aline Aver and Wives, Leandro Krug},
	title = {Sexist Hate Speech: Identifying Potential Online Verbal Violence Instances},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13208 LNAI},
	pages = {177 – 187},
	doi = {10.1007/978-3-030-98305-5_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127111087&doi=10.1007%2f978-3-030-98305-5_17&partnerID=40&md5=8b06c5617e7bd18e1a58786cdcceefb9},
	affiliations = {Postgraduate Program in Computing, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Department of Education and Humanities, Federal University of Health Sciences of Porto Alegre, Porto Alegre, Brazil},
	abstract = {Online communication provides space for content dissemination and opinion sharing. However, the limit between opinion and offense might be exceeded, characterizing hate speech. Moreover, its automatic detection is challenging, and approaches focused on the Portuguese language are scarce. This paper proposes an interface between linguistic concepts and computational interventions to support hate speech detection. We applied a Natural Language Processing pipeline involving topic modeling and semantic role labeling, allowing a semi-automatic identification of hate speech. We also discuss how such speech qualifies as a type of verbal violence widespread on social networks to reinforce a sexist stereotype. Finally, we use Twitter data to analyze information that resulted in virtual attacks against a specific person. As an achievement, this work validates the use of linguistic features to annotate data either as hate speech or not. It also proposes using fallacies as a potential additional feature to identify potential intolerant discourses. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Hate speech; Linguistic features; Natural Language Processing},
	keywords = {Automation; Modeling languages; Semantics; Speech; Speech recognition; Automatic Detection; Content dissemination; Hate speech; Linguistic features; On-line communication; Portuguese languages; Semantic role labeling; Semi-automatics; Speech detection; Topic Modeling; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on the Computational Processing of Portuguese, PROPOR 2022; Conference date: 21 March 2022 through 23 March 2022; Conference code: 275209}
}

@CONFERENCE{Perera2022131,
	author = {Perera, Suresha and Perera, Indika and Ahangama, Supunmali},
	title = {The effects of Social Media User Behavioural Factors on Hate Speech Detection},
	year = {2022},
	journal = {ICARC 2022 - 2nd International Conference on Advanced Research in Computing: Towards a Digitally Empowered Society},
	pages = {131 – 136},
	doi = {10.1109/ICARC54489.2022.9753942},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128965910&doi=10.1109%2fICARC54489.2022.9753942&partnerID=40&md5=f6694849bc9c94fd914ea4aaf1e98729},
	affiliations = {University of Moratuwa, Department of Computer Science and Engineering, Katubedda, Sri Lanka; University of Moratuwa, Department of Information Technology, Katubedda, Sri Lanka},
	abstract = {Social networking sites have grown in popularity, and many people have incorporated them into their daily routines. Most importantly, these platforms allow people to freely express themselves. However, the enforcement of threatening behaviours leading to societal risks is also prominent with the provisions of hate posts on social networking sites. Although there are rules and regulations to safeguard the community, the necessity to reduce the exposure of such hate posts in the user's timeline in every possible way is encouraged. Facebook users communicate through three behaviors: reactions, comments, and shares where those have an individual psychological inference towards the social emotion of a post as a significant proportion of natural behaviours of the user are deemed to be manifested by what is posted and how they have reacted to them. Thus, this proposed model identifies the social media behavioural factors which positively support hate and non-hate posts using the Binary Logistic Regression Statistical Model in a multilingual context. The experiment shows that social media behavioural factors such as "angry", "haha", "sad", and the number of shares positively support hate posts and can be applied as a parameter to reduce the engagement of hate posts as well to use them for detecting hate content which is a challenging task even the state-of-the-art models struggle with. Experimentally, this study shows that incorporating social media behavioural factors significantly improves classification performance by obtaining 88% accuracy when compared to similar methods. Finally, the results also showed that the developed system is good enough to classify hate speech detection methods providing a solution to the challenge of natural language processing for low-resourced languages. © 2022 IEEE.},
	author_keywords = {hate speech; post engagement; reactions; social networks},
	keywords = {Behavioral research; Natural language processing systems; Speech; Speech recognition; Behavioral factors; Daily routines; Hate speech; Post engagement; Reaction; Rules and regulations; Social media; Social network; Societal risks; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Advanced Research in Computing, ICARC 2022; Conference date: 23 February 2022 through 24 February 2022; Conference code: 178785}
}

@CONFERENCE{Thapa20221,
	author = {Thapa, Surendrabikram and Shah, Aditya and Jafri, Farhan Ahmad and Naseem, Usman and Razzak, Imran},
	title = {A Multi-Modal Dataset for Hate Speech Detection on Social Media: Case-study of Russia-Ukraine Conflict},
	year = {2022},
	journal = {CASE 2022 - 5th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, Proceedings of the Workshop},
	pages = {1 – 6},
	doi = {10.18653/v1/2022.case-1.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143439410&doi=10.18653%2fv1%2f2022.case-1.1&partnerID=40&md5=b9e20d3a8303f19281ba56aa256d0124},
	affiliations = {Department of Computer Science, Virginia Tech, United States; Department of Computer Science, Jamia Millia Islamia, India; School of Computer Science, The University of Sydney, Australia; School of Computer Science and Engineering, University of New South Wales, Australia},
	abstract = {Hate speech consists of types of content (e.g. text, audio, image) that express derogatory sentiments and hate against certain people or groups of individuals. The internet, particularly social media and microblogging sites, have become an increasingly popular platform for expressing ideas and opinions. Hate speech is prevalent in both offline and online media. A substantial proportion of this kind of content is presented in different modalities (e.g. text, image, video). Taking into account that hate speech spreads quickly during political events, we present a novel multimodal dataset composed of 5680 text-image pairs of tweets data related to the Russia-Ukraine war and annotated with a binary class:”hate” or”no-hate” The baseline results show that multimodal resources are relevant to leverage the hateful information from different types of data. The baselines and dataset provided in this paper may boost researchers in direction of multimodal hate speech, mainly during serious conflicts such as war contexts. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Audio images; Case-studies; Microblogging; Multi-modal; Multi-modal dataset; Popular platform; Social media; Speech detection; Text images; Ukraine; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; Conference name: 5th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2022; Conference date: 7 December 2022 through 8 December 2022; Conference code: 187667; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Shawkat2022213,
	author = {Shawkat, Nabil and Simpson, Jesse and Saquer, Jamil},
	title = {Evaluation of Different ML and Text Processing Techniques for Hate Speech Detection},
	year = {2022},
	journal = {Proceedings - 2022 4th International Conference on Data Intelligence and Security, ICDIS 2022},
	pages = {213 – 219},
	doi = {10.1109/ICDIS55630.2022.00040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146487170&doi=10.1109%2fICDIS55630.2022.00040&partnerID=40&md5=0a234de5a09c2e1e4e5976b6c3c0dbf6},
	affiliations = {Missouri State University, Department of Computer Science, Springfield, MO, United States},
	abstract = {Social media has become a domain that involves a lot of cyberbullying and hate speech. Some users feel entitled to engage in abusive conversations by sending abusive messages, tweets, or photos to other users. It is critical to detect hate speech and prevent innocent users from becoming victims of cyberbullying. In this paper, we investigate the applicability and performance of a variety of machine learning techniques with the help of text processing techniques in the pursuit of a reliable system for identifying hate speech. We evaluate Naïve Bayes, Support Vector Machines, Decision Trees, Random Forests, Logistic Regression, and K Nearest Neighbors on three different datasets. We used Term Frequency-Inverse Document Frequency (TF-IDF), unigram, bigram, trigram, combination of unigram and bigram, and combination of unigram, bigram, and trigram for the text corpus read by the machine learning techniques to see which approach gives better results. Additionally, since the datasets are unbalanced, we under-sampled and over-sampled the data and investigated the results. Our results show that on all three datasets over-sampling the minority class and using a combination of unigram, bigram, and trigram gave the best results with Random Forests achieving the highest F1-score of at least 0.96 on the three datasets. This was followed by SVM and Logistic Regression, which achieved F1-scores of at least 0.939.  © 2022 IEEE.},
	author_keywords = {abusive words; cyberbullying; hate speech; machine learning; social media},
	keywords = {Computer crime; Decision trees; Learning systems; Logistic regression; Nearest neighbor search; Social networking (online); Speech recognition; Support vector machines; Abusive word; Bigrams; Cyber bullying; Hate speech; Machine learning techniques; Machine-learning; Processing technique; Social media; Text-processing; Tri grams; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Data Intelligence and Security, ICDIS 2022; Conference date: 24 August 2022 through 26 August 2022; Conference code: 185433}
}

@CONFERENCE{Husain2022196,
	author = {Husain, Fatemah and Uzuner, Ozlem},
	title = {Transfer Learning Across Arabic Dialects for Offensive Language Detection},
	year = {2022},
	journal = {2022 International Conference on Asian Language Processing, IALP 2022},
	pages = {196 – 205},
	doi = {10.1109/IALP57159.2022.9961263},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143969863&doi=10.1109%2fIALP57159.2022.9961263&partnerID=40&md5=e4bfb918ce54773a7f26358665fc9941},
	affiliations = {Kuwait University, Sabah AlSalem University City, Dept. of Information Science, Kuwait; George Mason University, Dept. of Information Sciences and Technology, Fairfax, United States},
	abstract = {The Arabic language is spoken by a wide range of countries across Asia, however, it is a low-resource language that has a minimal number of linguistic resources. Moreover, the large spread of Arabic speakers spans several countries and cultures, which creates a complex variation in its dialectal form. This variation makes it very challenging to analyze online Arabic content, particularly for offensive language detection. We propose a transfer learning approach for dialectal Arabic offensives language detection based on the BERT model. The results demonstrate the effectiveness of the proposed system in improving the performance of some Arabic dialects, such as the Tunisian and the Egyptian. © 2022 IEEE.},
	author_keywords = {Arabic dialects; BERT customization; BERT model; Offensive language detection; text classification},
	keywords = {Text processing; Transfer learning; Arabic dialects; Arabic languages; BERT customization; BERT model; Customisation; Language detection; Offensive language detection; Offensive languages; Text classification; Transfer learning; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2022 International Conference on Asian Language Processing, IALP 2022; Conference date: 27 October 2022 through 28 October 2022; Conference code: 184807}
}

@CONFERENCE{Hartvigsen20223309,
	author = {Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece},
	title = {TOXIGEN: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection},
	year = {2022},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {3309 – 3326},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142367052&partnerID=40&md5=f69624e0da0a929fa31df326fe2f39b2},
	affiliations = {Massachusetts Institute of Technology, United States; University of Washington, United States; Microsoft Research, United States; Allen Institute for AI, United States; Carnegie Mellon University, United States; Microsoft, United States},
	abstract = {Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create TOXIGEN, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model (Brown et al., 2020). Controlling machine generation in this way allows TOXIGEN to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of TOXIGEN and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that TOXIGEN can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset. © 2022 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Large dataset; Natural language processing systems; Online systems; Speech recognition; Decoding methods; Demographic groups; Detection system; Language detection; Language model; Large machines; Large-scales; Minority groups; Over reliance; Speech detection; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 117; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181737}
}

@CONFERENCE{Thi202290,
	author = {Thi, Tham Nguyen and Do, Trong-Hop},
	title = {Lexicon-enhanced hate speech detection on Vietnamese social network data},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Cybernetics and Computational Intelligence, CyberneticsCom 2022},
	pages = {90 – 95},
	doi = {10.1109/CyberneticsCom55287.2022.9865524},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138434914&doi=10.1109%2fCyberneticsCom55287.2022.9865524&partnerID=40&md5=197b949ff1b9e881ff93894ec6d3a1e9},
	affiliations = {University of Information Technology, Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {This paper applies two lexicon enhancement methods, that are lexica feature extraction and retrofitting to improve the accuracy of hate speech detection problem on Vietnamese social network data. The experiments were conducted on multiple datasets to achieve the statistical significance of the experimental results. The results show that the use of retrofitting lexicon enhancement improves the accuracy of hate speech detection. This paper also introduces a dictionary consisting of hateful words that can be used for lexicon enhancement for hate speech detection on Vietnamese social network data.  © 2022 IEEE.},
	author_keywords = {Hate speech; Sematic; Sentiment},
	keywords = {Feature extraction; Speech recognition; Detection problems; Features extraction; Hate speech; Multiple data sets; Network data; Sematic; Sentiment; Speech detection; Statistical significance; Vietnamese; Retrofitting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th IEEE International Conference on Cybernetics and Computational Intelligence, CyberneticsCom 2022; Conference date: 16 June 2022 through 18 June 2022; Conference code: 182420}
}@ARTICLE{Naseem202135239,
	author = {Naseem, Usman and Razzak, Imran and Eklund, Peter W.},
	title = {A survey of pre-processing techniques to improve short-text quality: a case study on hate speech detection on twitter},
	year = {2021},
	journal = {Multimedia Tools and Applications},
	volume = {80},
	number = {28-29},
	pages = {35239 – 35266},
	doi = {10.1007/s11042-020-10082-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095113639&doi=10.1007%2fs11042-020-10082-6&partnerID=40&md5=a4a026deacac8ff88e62a19fbb51fee6},
	affiliations = {University of Sydney, Sydney, Australia; Deakin University, Geelong, Australia},
	abstract = {Pre-processing plays an essential role in disambiguating the meaning of short-texts, not only in applications that classify short-texts but also for clustering and anomaly detection. Pre-processing can have a considerable impact on overall system performance; however, it is less explored in the literature in comparison to feature extraction and classification. This paper analyzes twelve different pre-processing techniques on three pre-classified Twitter datasets on hate speech and observes their impact on the classification tasks they support. It also proposes a systematic approach to text pre-processing to apply different pre-processing techniques in order to retain features without information loss. In this paper, two different word-level feature extraction models are used, and the performance of the proposed package is compared with state-of-the-art methods. To validate gains in performance, both traditional and deep learning classifiers are used. The experimental results suggest that some pre-processing techniques impact negatively on performance, and these are identified, along with the best performing combination of pre-processing techniques. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Machine learning; Natural language processing; Text pre-processing; Tweet classification},
	keywords = {Anomaly detection; Deep learning; Extraction; Feature extraction; Social networking (online); Classification tasks; Feature extraction and classification; Information loss; Learning classifiers; Pre-processing; Short texts; Speech detection; State-of-the-art methods; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 76}
}

@CONFERENCE{Mohtaj2021173,
	author = {Mohtaj, Salar and Schmitt, Vera and Möller, Sebastian},
	title = {A Feature Extraction based Model for Hate Speech Identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {173 – 181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134232527&partnerID=40&md5=c5ec0b5b55135a5985e6e505d84a646e},
	affiliations = {Quality and Usability Lab., Technische Universität Berlin, Berlin, Germany; German Research Centre for Artificial Intelligence (DFKI), Projektbüro Berlin, Berlin, Germany},
	abstract = {The detection of hate speech online has become an important task, as offensive language such as hurtful, obscene and insulting content can harm marginalized people or groups. This paper presents TU Berlin team experiments and results on the task 1A and 1B of the shared task on hate speech and offensive content identification in Indo-European languages 2021. The success of different Natural Language Processing models is evaluated for the respective subtasks throughout the competition. We tested different models based on recurrent neural networks in word and character levels and transfer learning approaches based on Bert on the provided dataset by the competition. Among the tested models that have been used for the experiments, the transfer learning-based models achieved the best results in both subtasks. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Bert; English; Hate speech detection; LSTM; Offensive Content Identification},
	keywords = {Feature extraction; Learning systems; Long short-term memory; Natural language processing systems; Bert; Content identifications; English; Features extraction; Hate speech detection; LSTM; Offensive content identification; Speech detection; Subtask; Transfer learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Zhao2021286,
	author = {Zhao, Qingqing and Xiao, Yue and Long, Yunfei},
	title = {Multi-task CNN for Abusive Language Detection},
	year = {2021},
	journal = {2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning, PRML 2021},
	pages = {286 – 291},
	doi = {10.1109/PRML52754.2021.9520387},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115385279&doi=10.1109%2fPRML52754.2021.9520387&partnerID=40&md5=5d718e62f94a01476e43a1ca1ef8ae77},
	affiliations = {Institute of Linguistics, Chinese Academy of Social Sciences, Beijing, China; University of Edinburgh, School of Informatics, Scotland, United Kingdom; University of Essex, School of Computer Science and Electronic Engineering, Colchester, United Kingdom},
	abstract = {Abusive language detection serves to ensure a compelling user experience via high-quality content. Different sub-categories of abusive language are closely related, with most aggressive comments containing personal attacks and toxic content and vice versa. We set a multi-task learning framework to detect different types of abusive content in a mental health forum to address this feature. Each classification task is treated as a subclass in a multi-class classification problem, with shared knowledge used for three related tasks: attack, aggression, and toxicity. Experimental results on three sub-types of Wikipedia abusive language datasets show that our framework can improve the net F1-score by 7.1%, 5.6%, and 2.7% in the attack, aggressive, and toxicity detection. Our experiments identified multi tasking framework act as an effective method in abusive language detection.  © 2021 IEEE.},
	author_keywords = {datasets; gaze detection; multi-task learning; Natural language processing; neural networks; text classification},
	keywords = {Classification (of information); Learning systems; Natural language processing systems; Toxicity; Classification tasks; Dataset; Gaze detection; High quality; Language detection; Mental health; Multi tasks; Neural-networks; Quality content; Users' experiences; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2nd IEEE International Conference on Pattern Recognition and Machine Learning, PRML 2021; Conference date: 16 July 2021 through 18 July 2021; Conference code: 171487}
}

@CONFERENCE{Ratan2021459,
	author = {Ratan, Shyam and Sinha, Sonal and Singh, Siddharth},
	title = {SVM for Hate Speech and Offensive Content Detection},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {459 – 466},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134230187&partnerID=40&md5=faf1eb58e8f4c6b0edb9cfe2f854d4ee},
	affiliations = {Department of Linguistics, Dr. Bhimrao Ambedkar University, India; Centre for Transdisciplinary Studies, Dr. Bhimrao Ambedkar University, India},
	abstract = {This paper presents the system description of S_cube, which was submitted at the FIRE Shared Task 2021 on Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC). Our team submitted a system for Subtask 1 in two languages - English and Hindi, which has two different segments Subtask 1A and 1B for both languages. We experimented with the classic machine learning using Support Vector Machine (SVM). We discuss the system and its results with main findings for hate speech and offensive content identification in this paper. Our model achieves an F1 Score of 0.7563 at English Subtask 1A while the performance is worse for Hindi Subtask 1B (0.7195 F1). © 2021 Copyright for this paper by its authors.},
	author_keywords = {English; Hate Speech; Hindi; Offensive Language; SVM},
	keywords = {Fires; Speech recognition; Content detection; Content identifications; English; European languages; Hate speech; Hindi; Offensive languages; Subtask; Support vectors machine; System description; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Araque202248,
	author = {Araque, Oscar and Iglesias, Carlos A.},
	title = {An Ensemble Method for Radicalization and Hate Speech Detection Online Empowered by Sentic Computing},
	year = {2022},
	journal = {Cognitive Computation},
	volume = {14},
	number = {1},
	pages = {48 – 61},
	doi = {10.1007/s12559-021-09845-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101092143&doi=10.1007%2fs12559-021-09845-6&partnerID=40&md5=0582386c7bed32c6cabd9b33dd2e901c},
	affiliations = {Intelligent Systems Group, Universidad Politécnica de Madrid, Madrid, 28040, Spain},
	abstract = {The dramatic growth of the Web has motivated researchers to extract knowledge from enormous repositories and to exploit the knowledge in myriad applications. In this study, we focus on natural language processing (NLP) and, more concretely, the emerging field of affective computing to explore the automation of understanding human emotions from texts. This paper continues previous efforts to utilize and adapt affective techniques into different areas to gain new insights. This paper proposes two novel feature extraction methods that use the previous sentic computing resources AffectiveSpace and SenticNet. These methods are efficient approaches for extracting affect-aware representations from text. In addition, this paper presents a machine learning framework using an ensemble of different features to improve the overall classification performance. Following the description of this approach, we also study the effects of known feature extraction methods such as TF-IDF and SIMilarity-based sentiment projectiON (SIMON). We perform a thorough evaluation of the proposed features across five different datasets that cover radicalization and hate speech detection tasks. To compare the different approaches fairly, we conducted a statistical test that ranks the studied methods. The obtained results indicate that combining affect-aware features with the studied textual representations effectively improves performance. We also propose a criterion considering both classification performance and computational complexity to select among the different methods. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.},
	author_keywords = {Affective computing; Hate speech detection; Machine learning; Natural language processing; Radicalization detection; Sentic computing},
	keywords = {Extraction; Natural language processing systems; Speech recognition; Turing machines; Affective Computing; Classification performance; Feature extraction methods; Myriad applications; NAtural language processing; Sentic Computing; Speech detection; Textual representation; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@CONFERENCE{Rajalakshmi2021467,
	author = {Rajalakshmi, Ratnavel and Mattins, Faerie and Srivarshan, S. and Reddy, L. Preethi and Kumar, Anand M.},
	title = {Hate Speech and Offensive Content Identification in Hindi and Marathi Language Tweets using Ensemble Techniques},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {467 – 479},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134261408&partnerID=40&md5=4b8422c29260521068cfd1c8f9e08542},
	affiliations = {School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; Department of Information Technology, National Institute of Technology Karnataka (NITK), Surathkal, India},
	abstract = {Hate Speech is described as any form of speech in which speakers attempt to ridicule, humiliate, or inculcate hatred in someone else’s minds based on characteristics such as religion, the colour of skin, race, or sexual preference. In recent years, social networking sites have been a major source of excessive amounts of hate speech. If unaddressed, these might cause anxiety and despair in the affected individuals or groups. As a result, the above-mentioned social networks utilize an assortment of algorithms to identify such hate speech. Detecting Hate Speech in English texts has been one of the hottest topics in recent years, with multiple types of research being published. However, in regional and indigenous languages, hate speech detection is a recent area with not much research being conducted. It is difficult to perform hate speech detection using data in regional languages due to a lack of large enough training data and a lack of resources about that domain. The HASOC [1] 2021 Hate Speech Detection Task solves one of the problems. It provides a dataset containing Tweet data in English, Hindi [2] and Marathi [3] languages. There were two subtasks as part of the main task. The subtask was to classify the hate speech and offensive texts in the Hindi and Marathi tweet dataset as Hate Speech (HATE), Offensive (OFFN) or Profane (PRF). This work compares the performance of different models on both subtasks and provides a conclusion on the best performing model. The Random Forest Classifier reports the most remarkable accuracy on the first subtask with a macro F1 score of 75.19% and 73.12% on the Marathi and Hindi tweet datasets. The XGBoost algorithm is the best performing algorithm on the second subtask with a 46.5% macro F1 score. Overall any of these models can get satisfactory results when dealing with hate speech detection in regional language. This work has been submitted to the FIRE2021 shared task, Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC-2021) by team DLRG. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Hate speech detection; Machine learning; Majority voting; Multilingual tweets; Random forest; XGBoost},
	keywords = {Classification (of information); Machine learning; Random forests; Social networking (online); Speech recognition; Content identifications; F1 scores; Hate speech detection; Machine-learning; Majority voting; Multilingual tweet; Random forests; Speech detection; Subtask; Xgboost; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Kalaivani202192,
	author = {Kalaivani, Adaikkan and Thenmozhi, Durairaj},
	title = {Multilingual Hate speech and Offensive language detection in English, Hindi, and Marathi languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {92 – 103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134238074&partnerID=40&md5=6881c453c2ee3b6929610e0f2e98ac36},
	affiliations = {Department of Information and Communication Engineering, Anna University, Chennai, India; Research Centre, Department of CSE, Sri Sivasubramaniya Nadar College of Engineering, Kalavakkam, TamilNadu, India; Department of CSE, Sri Sivasubramaniya Nadar College of Engineering, Kalavakkam, TamilNadu, India},
	abstract = {Hate speech and offensive language are phenomena that spread with the rising popularity of social media forums. Automatic detection of such content is crucial for predicting conflicts among social communities and blocking inappropriate content from social media forums. This paper aims to describe our team SSN_NLP_MLRG submission to HASOC 2021: Hate speech and offensive language detection in English and Indo-Aryan language, where we explore different models to perform the subtask1 includes subtask A: To detect the comments is Hate speech and offensive (HOF) or NOT and subtask B: To classify the HOF comments into profanity (PRFN), Hate speech (HATE), Offensive (OFFN) in English, Hindi language and subtask A in Marathi language. The experiments cover different learning techniques that include machine learning, transfer learning, and Multilingual pre-trained models. Our best models are Roberta for English subtask A, BERT for English subtask B, and MBERT for the Hindi subtask A, Hindi subtask B, and Marathi subtask A. Our team achieved the macro-averaged F1 scores of 0.7919, 0.7320, 0.8223, 0.6242, and 0.5110 in the English subtask A, Hindi subtask A, Marathi subtask A, English subtask B, and Hindi subtask B, respectively. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-Mixed language; Language modeling; Low-resource language; Machine learning; Transfer learning},
	keywords = {Codes (symbols); Computational linguistics; Learning systems; Modeling languages; Social networking (online); Speech recognition; Code-mixed language; Language detection; Language model; Low resource languages; Machine-learning; Marathi languages; Offensive languages; Social media; Subtask; Transfer learning; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Plaza-Del-Arco2021183,
	author = {Plaza-Del-Arco, Flor Miriam and Casavantes, Marco and Escalante, Hugo Jair and Martín-Valdivia, M. Teresa and Montejo-Ráez, Arturo and Montes-Y-Gómez, Manuel and Jarquín-Vásquez, Horacio and Villaseñor-Pineda, Luis},
	title = {Overview of MeOffendEs at IberLEF 2021: Offensive Language Detection in Spanish Variants; [Resumen de la tarea MeOffendEs en IberLEF 2021: Detección de lenguaje ofensivo en las variantes del español]},
	year = {2021},
	journal = {Procesamiento del Lenguaje Natural},
	volume = {67},
	pages = {183 – 194},
	doi = {10.26342/2021-67-16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121784842&doi=10.26342%2f2021-67-16&partnerID=40&md5=99b63719b135f2ee2ebf1d3a955cc3d0},
	affiliations = {Universidad de Jaén, Campus Las Lagunillas, Jaén, 23071, Spain; Laboratorio de Tecnologías del Lenguaje (INAOE), Mexico; Centre de Recherche GRAMMATICA (EA 4521), Université d’Artois, France},
	abstract = {This paper is an overview of MeOffendES 2021, organized at IberLEF 2021 and co-located with the 37th International Conference of the Spanish Society for Natural Language Processing (SEPLN 2021). The main purpose of MeOffendEs is to promote research on the detection of offensive language in Spanish variants. The shared task involve four subtasks, the first two correspond to the identification of offensive language categories in generic Spanish texts from different social media platforms, while subtasks 3 and 4 are related to the identification of offensive language targeting the Mexican variant of Spanish. Two annotated datasets on offensive language have been released to the Natural Language Processing community. MeOffendes attracted a large number of participants: a total of 69 signed up to participate in the task, 12 submitted official runs on the test data, and 10 submitted system description papers. Corpora and results are available at the shared task website at https://competitions.codalab.org/competitions/28679. © 2021 Sociedad Española para el Procesamiento del Lenguaje Natural},
	author_keywords = {clasificación de textos; detección de lenguaje ofensivo; MeOffendEs; procesamiento del lenguaje natural},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Singh20211,
	author = {Singh, Sumer and Li, Sheng},
	title = {Exploiting Auxiliary Data for Offensive Language Detection with Bidirectional Transformers},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {1 – 5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138737499&partnerID=40&md5=485905ccb7d763a9b34117d91b86a030},
	affiliations = {University of Georgia, Athens, GA, United States},
	abstract = {Offensive language detection (OLD) has received increasing attention due to its societal impact. Recent work shows that bidirectional transformer based methods obtain impressive performance on OLD. However, such methods usually rely on large-scale well-labeled OLD datasets for model training. To address the issue of data/label scarcity in OLD, in this paper, we propose a simple yet effective domain adaptation approach to train bidirectional transformers. Our approach introduces domain adaptation (DA) training procedures to ALBERT, such that it can effectively exploit auxiliary data from source domains to improve the OLD performance in a target domain. Experimental results on benchmark datasets show that our approach, ALBERT (DA), obtains the state-of-the-art performance in most cases. Particularly, our approach significantly benefits underrepresented and under-performing classes, with a significant improvement over ALBERT.  © 2021 Association for Computational Linguistics.},
	keywords = {Benchmarking; Auxiliary data; Data labels; Domain adaptation; Language detection; Large-scales; Model training; Offensive languages; Performance; Simple++; Societal impacts; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference date: 6 August 2021; Conference code: 182536}
}

@CONFERENCE{Banerjee202132,
	author = {Banerjee, Somnath and Sarkar, Maulindu and Agrawal, Nancy and Saha, Punyajoy and Das, Mithun},
	title = {Exploring Transformer Based Models to Identify Hate Speech and Offensive Content in English and Indo-Aryan Languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {32 – 43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134263389&partnerID=40&md5=369f6c2ca58a307f3f54d9c2ab6d59ed},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology, West Bengal, Kharagpur, India; Department of Electrical Engineering, Indian Institute of Technology, West Bengal, Kharagpur, India},
	abstract = {Hate speech is considered to be one of the major issues currently plaguing online social media. Repeated and repetitive exposure to hate speech has been shown to create physiological effects on the target users. Thus, hate speech, in all its forms, should be addressed on these platforms in order to maintain good health. In this paper, we explored several Transformer based machine learning models for the detection of hate speech and offensive content in English and Indo-Aryan languages at FIRE 2021. We explore several models such as mBERT, XLMR-large, XLMR-base by team name "Super Mario". Our models came 2nd position in Code-Mixed Data set (Macro F1: 0.7107), 2nd position in Hindi two-class classification (Macro F1: 0.7797), 4tℎ in English four-class category (Macro F1: 0.8006) and 12tℎ in English two-class category (Macro F1: 0.6447). We have made our code public 1 © 2021 Copyright for this paper by its authors.},
	author_keywords = {classification; Hate speech; Hindi; low resource languages; Marathi; offensive speech},
	keywords = {Codes (symbols); Fires; Social networking (online); Speech; Data set; Hate speech; Hindi; Low resource languages; Machine learning models; Marathi; Mixed data; Offensive speech; Online social medias; Physiological effects; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Calderón2021,
	author = {Calderón, Fernando H. and Balani, Namrita and Taylor, Jherez and Peignon, Melvyn and Huang, Yen-Hao and Chen, Yi-Shin},
	title = {Linguistic patterns for code word resilient hate speech identification},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {23},
	doi = {10.3390/s21237859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119666904&doi=10.3390%2fs21237859&partnerID=40&md5=fe17c6680980c0357fa65865af838176},
	affiliations = {Institute of Information Systems and Applications, National Tsing Hua University, East District, Guang Fu Rd. Sec. 2, No. 101, Hsinchu City, 300, Taiwan; Social Networks and Human-Centered Computing, Taiwan International Graduate Program, Institute of Information Sciences, Academia Sinica, 128, Academia Road, Sec. 2, Nankang, Taipei, 115, Taiwan},
	abstract = {The permanent transition to online activity has brought with it a surge in hate speech discourse. This has prompted increased calls for automatic detection methods, most of which currently rely on a dictionary of hate speech words, and supervised classification. This approach often falls short when dealing with newer words and phrases produced by online extremist communities. These code words are used with the aim of evading automatic detection by systems. Code words are frequently used and have benign meanings in regular discourse, for instance, “skypes, googles, bing, yahoos” are all examples of words that have a hidden hate speech meaning. Such overlap presents a challenge to the traditional keyword approach of collecting data that is specific to hate speech. In this work, we first introduced a word embedding model that learns the hidden hate speech meaning of words. With this insight on code words, we developed a classifier that leverages linguistic patterns to reduce the impact of individual words. The proposed method was evaluated across three different datasets to test its generalizability. The empirical results show that the linguistic patterns approach outperforms the baselines and enables further analysis on hate speech expressions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Hate speech; Linguistic patterns; Social media},
	keywords = {Hate; Language; Learning; Linguistics; Speech; Classification (of information); Codes (symbols); Linguistics; Speech; Speech recognition; Automatic Detection; Automatic detection method; Code-words; Hate speech; Linguistic patterns; Online activities; Social media; Speech identification; Supervised classification; Word classification; hate; language; learning; linguistics; speech; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Abebaw2022603,
	author = {Abebaw, Zeleke and Rauber, Andreas and Atnafu, Solomon},
	title = {Multi-channel Convolutional Neural Network for Hate Speech Detection in Social Media},
	year = {2022},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {411 LNICST},
	pages = {603 – 618},
	doi = {10.1007/978-3-030-93709-6_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122597719&doi=10.1007%2f978-3-030-93709-6_41&partnerID=40&md5=b31cb25d5db88c0a8467badc44ce21a8},
	affiliations = {IT Doctoral Program, Addis Ababa University, Addis Ababa, Ethiopia; Institute of Information Systems Engineering, Technical University of Vienna, Vienna, Austria; Department of Computer Science, Addis Ababa University, Addis Ababa, Ethiopia},
	abstract = {As online social media content continues to grow, so does the spread of hate speech. Hate speech has devastating consequences unless it is detected and monitored early. Recently, deep neural network-based hate speech detection models, particularly conventional single-channel Convolutional Neural Network (CNN), have achieved remarkable performance. However, the effectiveness of the models depends on the type of language they are trained on and the training data size. We argue that the effectiveness of the models could further be enhanced if we use multi-channel CNN models even for under-resourced languages that have limited training data size. This is because the single-channel CNN might fail to consider the potential effect of multiple channels to generate better features, which is not well investigated for hate speech detection. Therefore, in this work, we explore the use of multi-channel CNN to extract better features from different channels in an end-to-end manner on top of a word2vec embedding layer. Tested on a new small-scale Amharic hate speech dataset containing 2000 annotated social media comments, the experimental results show that the proposed multi-channel CNN model outperforms the single-channel CNN models but underperform from the baseline Support Vector Machine (SVM) with an average F-score of 81.3%, 78.2%, and 92.5% respectively. The finding of the study implies that the proposed MC-CNN model can be used as an alternative solution for hate speech detection using a deep learning approach when dataset scarcity is an issue. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
	author_keywords = {Amharic hate speech detection; Convolutional neural network; Deep learning; Multi-channel; Single-channel; Social media; Word embedding},
	keywords = {Convolution; Convolutional neural networks; Deep neural networks; Embeddings; Speech; Speech recognition; Support vector machines; Amharic hate speech detection; Convolutional neural network; Deep learning; Embeddings; Multi channel; Neural network model; Single channels; Social media; Speech detection; Word embedding; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 9th EAI International Conference on Advancement of Science and Technology, ICAST 2021; Conference date: 27 August 2021 through 29 August 2021; Conference code: 270629}
}

@ARTICLE{Karayiğit2021,
	author = {Karayiğit, Habibe and İnan Acı, Çiğdem and Akdağlı, Ali},
	title = {Detecting abusive Instagram comments in Turkish using convolutional Neural network and machine learning methods},
	year = {2021},
	journal = {Expert Systems with Applications},
	volume = {174},
	doi = {10.1016/j.eswa.2021.114802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102407683&doi=10.1016%2fj.eswa.2021.114802&partnerID=40&md5=2ed9307ea71ba21fe399f47181f267b1},
	affiliations = {Department of Electrical and Electronics Engineering, Mersin University, 33343, Turkey; Department of Computer Engineering, Mersin University, 33343, Turkey},
	abstract = {Instagram is a free photo-sharing platform where each user has a profile and can upload photos for followers to view, like, and comment. Abusive comments on images can be humiliating and harmful to those who share photos. Developing a comment filter in languages other than English is difficult and time-consuming. This paper proposes a dataset called Abusive Turkish Comments (ATC) to detect abusive Instagram comments in Turkish. It is composed of a large number of Instagram comments posted to tabloid and sports accounts (i.e., 10,528 abusive and 19,826 not-abusive). It is the first public dataset dedicated to detecting abusive Turkish messages, as far as we know. The sentiment annotation has been done in sentence-level by assigning polarity to each comment. The performance of the abusive message detection models was evaluated using several performance metrics: Convolutional Neural Network (CNN), five well-known classifiers (i.e., Naive Bayes, Support Vector Machine, Decision Tree, Random Forest, and Logistic Regression), and two reweighted classifiers (i.e., Adaptive Boosting (AdaBoost), eXtreme Gradient Boosting (XGBoost)) were compared in terms of F1-score, precision, and recall. The results showed that the best performance (i.e., Micro-averaged F1-score: 0.974, Macro-averaged F1-score: 0.973, Kappa-value: 0.946) was yielded by the CNN model on the oversampled ATC dataset. The abusive message detection model proposed in this study can contribute to the development of Turkish comment filters on Instagram. Different model combinations are considered to select the best model that gives better recognition accuracy. © 2021 Elsevier Ltd},
	author_keywords = {Abusive comment; Classification; Dataset; Hate speech; Instagram; Social media},
	keywords = {Adaptive boosting; Classifiers; Convolution; Decision trees; Neural networks; Support vector machines; Abusive comment; Convolutional neural network; Dataset; F1 scores; Hate speech; Instagram; Message detection; Performance; Social media; Turkishs; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36}
}

@ARTICLE{Kumar2021,
	author = {Kumar, Ritesh and Lahiri, Bornini and Ojha, Atul Kr.},
	title = {Aggressive and Offensive Language Identification in Hindi, Bangla, and English: A Comparative Study},
	year = {2021},
	journal = {SN Computer Science},
	volume = {2},
	number = {1},
	doi = {10.1007/s42979-020-00414-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121918271&doi=10.1007%2fs42979-020-00414-6&partnerID=40&md5=bf3640fadb84bf9718eb58903306d4b6},
	affiliations = {Department of Linguistics, K. M. Institute of Hindi and Linguistics, Dr. Bhimrao Ambedkar University, Agra, India; Department of Humanities and Social Sciences, Indian Institute of Technology, Kharagpur, India; Panlingua Language Processing LLP, New Delhi, India; DSI, NUIG, Galway, Ireland},
	abstract = {In the present paper, we carry out a comparative study between offensive and aggressive language and attempt to understand their inter-relationship. To carry out this study, we develop classifiers for offensive and aggressive language identification in Hindi, Bangla, and English using the datasets released for the languages as part of the two shared tasks: hate speech and offensive content identification in Indo-European languages (HASOC) and aggression and misogyny identification task at TRAC-2. The HASOC dataset is annotated with the information about offensive language and TRAC-2 dataset is annotated with the information about aggressive language. We experiment with SVM as well as BERT and its different derivatives such as ALBERT and DistilBERT for developing the classifiers. The best classifiers achieve an impressive F-score in between 0.70 and 0.80 for different tasks. We use these classifiers to cross-annotate the two datasets, and look at the co-occurrence of different sub-categories of aggression and offense. The study shows that even though aggression and offense significantly overlaps, but still one does not entail the other. © 2021, Springer Nature Singapore Pte Ltd.},
	author_keywords = {Aggression; Bangla; BERT; Comparison; English; HASOC; Hindi; Offensive language; TRAC},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@CONFERENCE{Refaee2021244,
	author = {Refaee, Eshrag A.},
	title = {A Data-oriented Approach for Detecting offensive Language in Arabic Tweets},
	year = {2021},
	journal = {Proceedings - 2021 International Conference on Software Engineering and Computer Systems and 4th International Conference on Computational Science and Information Management, ICSECS-ICOCSIM 2021},
	pages = {244 – 248},
	doi = {10.1109/ICSECS52883.2021.00051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116169703&doi=10.1109%2fICSECS52883.2021.00051&partnerID=40&md5=3690e9319796c8b7d5b5a00a87e35bda},
	affiliations = {Jazan University, College of Computer Sciences and Information Technology, Jazan, Saudi Arabia},
	abstract = {The growing popularity of social media (SM) platforms has made these platforms a crucial part of modern societies. Users from different cultures, backgrounds, demographics get aboard in an increasing manner to express their views, stances, and opinions on a varied range of topics. Since users on SM can easily hide their real identity, a closer look at daily posts on social medial platforms shows that users do not seem to reflect only their stances and views, but also, they get an opportunity for revealing their behaviors, which could be negative towards the others. Although only a small population of SM users can show negative behavior towards other individuals, groups, and society in general, the impact could be catastrophic. This has resulted in the emerge of terms like cyberbullying, online extremism/hatred/threatening, online trolling, online political-polarity discourse. To ensure safe social networking, the domain of automatic detection of offensive/hatred language has lately grown notably. This work focuses on utilizing a publicly available dataset of Arabic tweets labeled for offensive/non-offensive language. Unlike previous work which focuses merely on developing and tuning machine learning models to be as accurate as possible on the benchmark dataset used, we turn to focus on the characteristics of the offensive language used in SM. The purpose is to have an in-depth look into the dataset to disclose what seems to be hidden patterns in offensive language expressed daily online. Our findings reveal the benefit of using larger training dataset that covers a wide range of offensive language patterns to build robust machine learning classifiers with a better ability to generalize well on highly sparse data used in SM.  © 2021 IEEE.},
	author_keywords = {Arabic NLP; classification; machine learning; offensive language; twitter},
	keywords = {Classification (of information); Machine learning; Arabic NLP; Automatic Detection; Benchmark datasets; Cyber bullying; Machine learning models; Offensive languages; Small population; Social media; Social media platforms; Social-networking; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th International Conference on Software Engineering and Computer Systems and 4th International Conference on Computational Science and Information Management, ICSECS-ICOCSIM 2021; Conference date: 24 August 2021 through 26 August 2021; Conference code: 171807}
}

@ARTICLE{Bashar2021,
	author = {Bashar, Md Abul and Nayak, Richi and Luong, Khanh and Balasubramaniam, Thirunavukarasu},
	title = {Progressive domain adaptation for detecting hate speech on social media with small training set and its application to COVID-19 concerned posts},
	year = {2021},
	journal = {Social Network Analysis and Mining},
	volume = {11},
	number = {1},
	doi = {10.1007/s13278-021-00780-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111540068&doi=10.1007%2fs13278-021-00780-w&partnerID=40&md5=b1a67d0e242c191096fd1862a02c6503},
	affiliations = {School of Computer Science and Centre for Data Science, Queensland University of Technology, 2 George St, Brisbane City, 4000, QLD, Australia},
	abstract = {In this world of information and experience era, microblogging sites have been commonly used to express people feelings including fear, panic, hate and abuse. Monitoring and control of abuse on social media, especially during pandemics such as COVID-19, can help in keeping the public sentiment and morale positive. Developing the fear and hate detection methods based on machine learning requires labelled data. However, obtaining the labelled data in suddenly changed circumstances as a pandemic is expensive and acquiring them in a short time is impractical. Related labelled hate data from other domains or previous incidents may be available. However, the predictive accuracy of these hate detection models decreases significantly if the data distribution of the target domain, where the prediction will be applied, is different. To address this problem, we propose a novel concept of unsupervised progressive domain adaptation based on a deep-learning language model generated through multiple text datasets. We showcase the efficacy of the proposed method in hate speech and fear detection on the tweets collection during COVID-19 where the labelled information is unavailable. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Domain adaptation; Fear prediction; Hate speech; Small dataset; Text mining},
	keywords = {Deep learning; Learning systems; Social networking (online); Data distribution; Detection methods; Detection models; Domain adaptation; Learning languages; Monitoring and control; Predictive accuracy; Public sentiments; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Sharma2022,
	author = {Sharma, Arushi and Kabra, Anubha and Jain, Minni},
	title = {Ceasing hate with MoH: Hate Speech Detection in Hindi–English code-switched language},
	year = {2022},
	journal = {Information Processing and Management},
	volume = {59},
	number = {1},
	doi = {10.1016/j.ipm.2021.102760},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118884761&doi=10.1016%2fj.ipm.2021.102760&partnerID=40&md5=060b1c07021c367f73a6e4a92ce3c6e2},
	affiliations = {Optum Global Advantage, India; Adobe Inc., India; Delhi Technological University, India},
	abstract = {Warning: This manuscript may contain upsetting language. Social media has become a bedrock for people to voice their opinions worldwide. Due to the greater sense of freedom with the anonymity feature, it is possible to disregard social etiquette online and attack others without facing severe consequences, inevitably propagating hate speech. The current measures to sift the online content and offset the hatred spread do not go far enough. One factor contributing to this is the prevalence of regional languages in social media and the paucity of language flexible hate speech detectors. The proposed work focuses on analyzing hate speech in Hindi–English code-switched language. Our method explores transformation techniques to capture precise text representation. To contain the structure of data and yet use it with existing algorithms, we developed ‘MoH’ or (Map Only Hindi), which means ‘Love’ in Hindi. ‘MoH’ pipeline which consists of language identification, Roman to Devanagari Hindi transliteration using a knowledge base of Roman Hindi words, and finally employs the fine-tuned Multilingual Bert, and MuRIL language models. We conducted several quantitative experiment studies on three datasets, and evaluated performance using Precision, Recall and F1 metrics. The first experiment studies ‘MoH’ mapped text's performance with classical machine learning models and shows an average increase of 13% in F1 scores. The second compares the proposed work's scores with those of the baseline models and shows a rise in performance by 6%. Finally, the third compares the proposed ‘MoH’ technique with various data simulations using the existing transliteration library. Here, ‘MoH’ outperforms the rest by 15%. Our results demonstrate a significant improvement in the state-of-the-art scores on all three datasets. © 2021 Elsevier Ltd},
	author_keywords = {And machine learning; Bert; Cyber hate; Data simulations; MuRIL; Social media; Text classification; Transfer learning},
	keywords = {Classification (of information); Codes (symbols); Computational linguistics; Knowledge based systems; Machine learning; Natural language processing systems; Speech; Speech recognition; Text processing; And machine learning; Bert; Cybe hate; Data simulation; Experiment study; MuRIL; Performance; Social media; Text classification; Transfer learning; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46}
}

@ARTICLE{Aldjanabi2021,
	author = {Aldjanabi, Wassen and Dahou, Abdelghani and Al-Qaness, Mohammed A. A. and Elaziz, Mohamed Abd and Helmi, Ahmed Mohamed and Damaševičius, Robertas},
	title = {Arabic offensive and hate speech detection using a cross-corpora multi-task learning model},
	year = {2021},
	journal = {Informatics},
	volume = {8},
	number = {4},
	doi = {10.3390/informatics8040069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117290498&doi=10.3390%2finformatics8040069&partnerID=40&md5=2bd3afc7e1abb941cdab0d7d73107130},
	affiliations = {Department of Mathematics and Computer Science, Faculty of Science and Technology, University of Ahmed DRAIA, Adrar, 01000, Algeria; LDDI Laboratory, Faculty of Science and Technology, University of Ahmed DRAIA, Adrar, 01000, Algeria; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, 430079, China; Department of Mathematics, Faculty of Science, Zagazig University, Zagazig, 44519, Egypt; Department of Computer and Systems Engineering, Faculty of Engineering, Zagazig University, Zagazig, 44519, Egypt; Faculty of Applied Mathematics, Silesian University of Technology, Gliwice, 44-100, Poland},
	abstract = {As social media platforms offer a medium for opinion expression, social phenomena such as hatred, offensive language, racism, and all forms of verbal violence have increased spectacularly. These behaviors do not affect specific countries, groups, or communities only, extending beyond these areas into people’s everyday lives. This study investigates offensive and hate speech on Arab social media to build an accurate offensive and hate speech detection system. More precisely, we develop a classification system for determining offensive and hate speech using a multi-task learning (MTL) model built on top of a pre-trained Arabic language model. We train the MTL model on the same task using cross-corpora representing a variation in the offensive and hate context to learn global and dataset-specific contextual representations. The developed MTL model showed a significant performance and outperformed existing models in the literature on three out of four datasets for Arabic offensive and hate speech detection tasks. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Arabic language model; Contextual representations; Hate speech; Multi-task learning; Offensive lan-guage},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; All Open Access, Gold Open Access}
}

@CONFERENCE{Wilkens2021357,
	author = {Wilkens, Rodrigo and Ognibene, Dimitri},
	title = {biCourage: ngram and syntax GCNs for Hate Speech detection},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {357 – 366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134256208&partnerID=40&md5=eb52425b5b6cf8418a2b799a232fe2fc},
	affiliations = {University of Milano-Bicocca, Italy; University of Essex, United Kingdom},
	abstract = {Hate Speech identification is a challenging task given the world knowledge required. Moreover, it is even more complex in the social media context due to language and media specificities. Despite these challenges, advances in this task may help improving collective well-being on social media. In this context, the biCourage team participated in the English version of Task 1 of HASOC 2021, a shared task for “Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages”. Our participation in this campaign aimed to examine the suitability of Graph Convolutional Neural Networks (GCN), due to their capability to integrate flexible contextual priors, as a computationally effective solution compared to more computationally expensive and relatively data-hungry methods, such as fine-tuning. Specifically, we explored and combined two text-to-graph strategies based on different language modelling objectives, comparing them with fine-tuned Bert. We submitted the results of several deep learning architectures, comprised of different arrangements of GCNs and transformer architectures. Our team achieved the best results in both subtasks using the GCNs based architectures combining two text-to-graph strategies ranked in 21st and 20th positions in Subtasks 1A and 1B. Assessing the models’ prediction, we identify complementary capabilities in the text-to-graph strategies that further research on their combination can explore. Moreover, the proposed GCN model is 3.85 times faster than fine-tuned Bert in training speed and still outperforms it by 2.3% and 5.41% on the F1 score of Subtasks 1A and 1B, respectively. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Bert fine-tuning; biCourage; graph convolutional network; hate speech; text-to-graph},
	keywords = {Computational linguistics; Convolution; Convolutional neural networks; Graph neural networks; Modeling languages; Network architecture; Neural network models; Social networking (online); Speech recognition; Bert fine-tuning; Bicourage; Convolutional networks; Convolutional neural network; Fine tuning; Graph convolutional network; Hate speech; Social media; Subtask; Text-to-graph; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Mozafari202214880,
	author = {Mozafari, Marzieh and Farahbakhsh, Reza and Crespi, Noel},
	title = {Cross-Lingual Few-Shot Hate Speech and Offensive Language Detection Using Meta Learning},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {14880 – 14896},
	doi = {10.1109/ACCESS.2022.3147588},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124105666&doi=10.1109%2fACCESS.2022.3147588&partnerID=40&md5=6db17b2a6c8b881dcd77678014374c17},
	affiliations = {CNRS Lab UMR5157, Institut Polytechnique de Paris, Palaiseau, 91764, France},
	abstract = {Automatic detection of abusive online content such as hate speech, offensive language, threats, etc. has become prevalent in social media, with multiple efforts dedicated to detecting this phenomenon in English. However, detecting hatred and abuse in low-resource languages is a non-trivial challenge. The lack of sufficient labeled data in low-resource languages and inconsistent generalization ability of transformer-based multilingual pre-trained language models for typologically diverse languages make these models inefficient in some cases. We propose a meta learning-based approach to study the problem of few-shot hate speech and offensive language detection in low-resource languages that will allow hateful or offensive content to be predicted by only observing a few labeled data items in a specific target language. We investigate the feasibility of applying a meta learning approach in cross-lingual few-shot hate speech detection by leveraging two meta learning models based on optimization-based and metric-based (MAML and Proto-MAML) methods. To the best of our knowledge, this is the first effort of this kind. To evaluate the performance of our approach, we consider hate speech and offensive language detection as two separate tasks and make two diverse collections of different publicly available datasets comprising 15 datasets across 8 languages for hate speech and 6 datasets across 6 languages for offensive language. Our experiments show that meta learning-based models outperform transfer learning-based models in a majority of cases, and that Proto-MAML is the best performing model, as it can quickly generalize and adapt to new languages with only a few labeled data points (generally, 16 samples per class yields an effective performance) to identify hateful or offensive content. © 2013 IEEE.},
	author_keywords = {cross-lingual classification; few-shot learning; Hate speech; meta learning; offensive language; transfer learning; XLM-RoBERTa},
	keywords = {Speech recognition; Cross-lingual; Cross-lingual classification; Few-shot learning; Hate speech; Language detection; Low resource languages; Metalearning; Offensive languages; Transfer learning; XLM-RoBERTa; Speech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Gold Open Access}
}

@ARTICLE{Le-Hong2021,
	author = {Le-Hong, Phuong},
	title = {Diacritics generation and application in hate speech detection on Vietnamese social networks},
	year = {2021},
	journal = {Knowledge-Based Systems},
	volume = {233},
	doi = {10.1016/j.knosys.2021.107504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115945453&doi=10.1016%2fj.knosys.2021.107504&partnerID=40&md5=865ad96dc9dbe15c9bcf0db15990ea5f},
	affiliations = {Vietnam National University, Hanoi, Viet Nam},
	abstract = {One of the challenging problems in text processing is diacritics generation where one needs to generate diacritic marks for non-accented text. With an ever increasing amount of informal text without accents such as short text messages, emails or blog posts on social media, a software system which is capable of generating diacritic marks accurately is very useful and necessary in many situations. This paper presents an approach to improve the accuracy of diacritics generation for Vietnamese text. We propose two novel deep learning models which leverage a plausible conceptual representation for the phonetic structure of Vietnamese syllables. Experimental results on real-world datasets show that our models achieve a significant improvement as compared to the state-of-the-art methods for diacritics generation. We also demonstrate that the proposed models can be applied efficiently to improve the accuracy of hate speech detection on Vietnamese social networks. © 2021 Elsevier B.V.},
	author_keywords = {Diacritics generation; Hate speech detection; Recurrent neural networks; Sentiment analysis; Text; Transformers; Vietnamese},
	keywords = {Recurrent neural networks; Social networking (online); Speech recognition; Diacritic generation; Hate speech detection; Sentiment analysis; Short text messages; Social media; Speech detection; Text; Text-processing; Transformer; Vietnamese; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Rahul20211112,
	author = {Rahul and Gupta, Vasu and Sehra, Vibhu and Vardhan, Yashaswi Raj},
	title = {Hindi-English Code Mixed Hate Speech Detection using Character Level Embeddings},
	year = {2021},
	journal = {Proceedings - 5th International Conference on Computing Methodologies and Communication, ICCMC 2021},
	pages = {1112 – 1118},
	doi = {10.1109/ICCMC51019.2021.9418261},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106044008&doi=10.1109%2fICCMC51019.2021.9418261&partnerID=40&md5=be35afc48a0f87f1b252bb2109ccd1a9},
	affiliations = {Delhi Technological University, Department of Computer Science and Engineering, New Delhi, India},
	abstract = {Hinglish is a portmanteau word for 'Hindi' and 'English', and refers to the informal "language"predominantly used in the South-Asian (Indian) Sub-Continent, a blend of the two languages it derives its name from. It considerably differs from the English language in grammar, syntax, punctuations, phonetics and accent, as well as in sentiments.As it is more convenient to use English for certain technical words, sports events, scientific phenomena, and other things, mixed usage of English and regional languages has gained considerable prominence in day-to-day conversations and Social Media. This research aims to create an independent and self-sufficing model that classifies Hingish texts as Hate Speech, Abusive or Non-Offensive.The prevalent use of code-mixed language in the subcontinent, the sensitive nature of hate speeches, and the need of a self-sufficient model for Hinglish, together serve as the motivation for this research.We have used character level embeddings for Hinglish Language which has the potential to most efficiently extract the context from Hinglish sentences given the level of variation in syntax and semantics of the code-mixed (a language that is a combination of two or more languages) language. Later we trained various deep learning classifier models. Hybridisation of GRU with Attention Model performed best among more than 12 models experimented with. The use of Character Level Embeddings, GRU, and attention layer are novel to Hate Speech Detection in Hinglish Code-Mixed Language. © 2021 IEEE.},
	author_keywords = {Character-level Embeddings; Code-Switched; Deep Learning; Hate Speech; Hinglish Sentiment Analysis; Sequential Models},
	keywords = {Deep learning; Embeddings; Semantics; Speech recognition; Syntactics; Attention model; Character level; English languages; Hybridisation; Learning classifiers; Speech detection; Sports events; Sub-continents; Context sensitive languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 5th International Conference on Computing Methodologies and Communication, ICCMC 2021; Conference date: 8 April 2021 through 10 April 2021; Conference code: 168766}
}

@ARTICLE{Husain2021,
	author = {Husain, Fatemah and Uzuner, Ozlem},
	title = {A Survey of Offensive Language Detection for the Arabic Language},
	year = {2021},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {20},
	number = {1},
	doi = {10.1145/3421504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104179281&doi=10.1145%2f3421504&partnerID=40&md5=b7ee20ace4551e9921727efb306d15db},
	affiliations = {Information Science Department, College of Life Sciences, Sabah AlSalem University City (Alshadadiya), Kuwait University, P.O. Box 5969, Safat, 13060, Kuwait; George Mason University, 4400 University Drive, 5359 Nguyen Engineering Building, Ffx, MSN: 1G8, Fairfax, VA22030, United States},
	abstract = {The use of offensive language in user-generated content is a serious problem that needs to be addressed with the latest technology. The field of Natural Language Processing (NLP) can support the automatic detection of offensive language. In this survey, we review previous NLP studies that cover Arabic offensive language detection. This survey investigates the state-of-The-Art in offensive language detection for the Arabic language, providing a structured overview of previous approaches, including core techniques, tools, resources, methods, and main features used. This work also discusses the limitations and gaps of the previous studies. Findings from this survey emphasize the importance of investing further effort in detecting Arabic offensive language, including the development of benchmark resources and the invention of novel preprocessing and feature extraction techniques. © 2021 ACM.},
	author_keywords = {Arabic language; deep learning; literature review; machine learning; natural language processing; Offensive language},
	keywords = {Natural language processing systems; Surveys; Arabic languages; Automatic Detection; Feature extraction techniques; Latest technology; NAtural language processing; Offensive languages; State of the art; User-generated content; Feature extraction},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49}
}

@CONFERENCE{Kalra2021200,
	author = {Kalra, Sakshi and Inani, Kalit Naresh and Sharma, Yashvardhan and Chauhan, Gajendra Singh},
	title = {Applying Transfer Learning using BERT-based models for Hate Speech Detection},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {200 – 208},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134241805&partnerID=40&md5=59188e3b7d9402de12e52d8de0edf084},
	affiliations = {Department of Computer Science and Information Systems, Birla Institute of Technology and Science, Pilani Campus, Rajasthan, Pilani, India; Department of Humanities and Social Sciences, Birla Institute of Technology and Science, Pilani Campus, Rajasthan, Pilani, India},
	abstract = {Hateful and Offensive speech is rising along with social media. This issue has motivated researchers to devise novel approaches which perform better than the traditional algorithms. This paper presents the methods adopted by the BITS Pilani team for Subtask 1A of the Hate Speech and Offensive Content Identification in English and Indo-Aryan Language task proposed by the Forum of Information Retrieval Evaluation in 2021. We have used data augmentation to make the models generalize better. We have experimented with different feature extraction techniques along with machine learning algorithms. But, fine-tuning the pre-trained BERT-based models using transfer learning gave us the best results for all the given languages on the test set. We got the highest Macro-F1 of 0.7993 for the English Language, 0.7612 for the Hindi Language, and 0.8306 for the Marathi Language using the pre-trained BERT-based models. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT-variants; HASOC; hate speech; label classification; offensive language detection},
	keywords = {Speech recognition; Transfer learning; BERT-variant; HASOC; Hate speech; Label classification; Language detection; Offensive language detection; Offensive languages; Social media; Speech detection; Transfer learning; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Khan2021688,
	author = {Khan, Haseeb and Yu, Frances and Sinha, Amar and Gokhale, Swapna S.},
	title = {A parsimonious and practical approach to detecting offensive speech},
	year = {2021},
	journal = {Proceedings - IEEE 2021 International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2021},
	pages = {688 – 695},
	doi = {10.1109/ICCCIS51004.2021.9397140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104618123&doi=10.1109%2fICCCIS51004.2021.9397140&partnerID=40&md5=53565bf663da3dd0c9f45ca31e2c0218},
	affiliations = {Univ. of Connecticut, Computer Science and Engg, Storrs, 06269, CT, United States},
	abstract = {With the proliferation of hateful and offensive speech on social media platforms such as Twitter, machine learning approaches to detect such toxic content have gained prominence. Despite these advances, real-time detection of such speech, while it is being shared on these platforms, remains a challenge for two reasons. First, these approaches train complex models on a plethora of features, which calls into question their computational efficiency for real-time deployment. Moreover, they require sizeable, manually annotated data sets from the same context, and annotating large data sets is extremely time-consuming, error-prone and cumbersome. This paper proposes a parsimonious and practical approach for the detection of offensive speech that alleviates these challenges. The approach is parsimonious because through a comprehensive evaluation of commonly used machine learning models (Logistic Regression, Random Forest, Neural Networks) on two public domain data sets it demonstrates that a simple Logistic Regression model trained on unigrams with frequency counts can detect hate speech with high accuracy of over 90%. It is practical because it demonstrates how an existing labeled training data set can be used to train models that can detect offensive content from a completely unknown data set with moderate accuracy. Based on these findings, the paper offers guidance on the characteristics that may be desirable in benchmark training data sets for offensive speech detection. © 2021 IEEE.},
	author_keywords = {Detection.; Machine Learning; Offensive speech},
	keywords = {Computational efficiency; Decision trees; Intelligent systems; Logistic regression; Machine learning; Social networking (online); Speech; Comprehensive evaluation; Labeled training data; Machine learning approaches; Machine learning models; Real-time detection; Simple logistic regressions; Social media platforms; Training data sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 2021 IEEE International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2021; Conference date: 19 February 2021 through 20 February 2021; Conference code: 168396}
}

@ARTICLE{Plaza-del-Arco2021,
	author = {Plaza-del-Arco, Flor Miriam and Molina-González, M. Dolores and Ureña-López, L. Alfonso and Martín-Valdivia, M. Teresa},
	title = {Comparing pre-trained language models for Spanish hate speech detection},
	year = {2021},
	journal = {Expert Systems with Applications},
	volume = {166},
	doi = {10.1016/j.eswa.2020.114120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092734154&doi=10.1016%2fj.eswa.2020.114120&partnerID=40&md5=efeedf6d54122a29370d8d4611ba1a4b},
	affiliations = {Department of Computer Science, Advanced Studies Center in Information and Communication Technologies (CEATIC), Universidad de Jaén Campus Las Lagunillas, Jaén, E-23071, Spain},
	abstract = {Nowadays, due to the great uncontrolled content posted daily on the Web, there has also been a huge increase in the dissemination of hate speech worldwide. Social media, blogs and community forums are examples where people are freely allowed to communicate. However, freedom of expression is not always respectful since offensive or insulting language is sometimes used. Social media companies often rely on users and content moderators to report on this type of content. Nevertheless, due to the large amount of content generated every day on the Web, automatic systems based on Natural Language Processing techniques are required for identifying abusive language online. To date, most of the systems developed to combat this problem are mainly focused on English content, but this issue is a worldwide concern and therefore other languages such as Spanish are involved. In this paper, we address the task of Spanish hate speech identification on social media and provide a deeper understanding of the capabilities of new techniques based on machine learning. In particular, we compare the performance of Deep Learning methods with recently pre-trained language models based on Transfer Learning as well as with traditional machine learning models. Our main contribution is the achievement of promising results in Spanish by applying multilingual and monolingual pre-trained language models such as BERT, XLM and BETO. © 2020 Elsevier Ltd},
	author_keywords = {BERT; BETO; Hate speech; Natural language processing; Text classification; Transfer learning},
	keywords = {Computational linguistics; Deep learning; Natural language processing systems; Online systems; Social networking (online); Speech recognition; Transfer learning; Automatic systems; Language model; Large amounts; Learning methods; Machine learning models; NAtural language processing; Speech detection; Speech identification; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 112}
}

@CONFERENCE{Jadhav2021338,
	author = {Jadhav, Ishali and Kanade, Aditi and Waghmare, Vishesh and Chaudhari, Deptii},
	title = {Hate and Offensive Speech Detection in Hindi Twitter Corpus},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {338 – 348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134235650&partnerID=40&md5=e96ed9d5d1abdc0e670ad57bd5937c1b},
	affiliations = {Hope Foundation's International Institute of Information Technology, Pune, India},
	abstract = {Nowadays, social media sites like Twitter and Facebook emerge as user-friendly and accessible sources for people to express their voice. Everybody, irrespective of their age group, uses these sites to share every moment of their life, making these sites flooded with data. This has led to many positive outcomes. At the same time, it has brought risks and harms as these sites set no restrictions. The volume of hate speech is not manageable by humans. As part of the HASOC-2021 shared task on information retrieval, we, Team Ignite, address the problem of hate speech identification in the Hindi corpus. Subtask A aims to identify binary hate or non-hate speech. This work was further extended with subtask B to determine the result of subtask A into three categories: profane, offensive, and hate. Hence, this paper compares the performance of three feature engineering techniques and four machine learning algorithms to evaluate their performance on a publicly available dataset with two distinct classes. With these two classes of hate and non-hate, we create a baseline model and improve model performance scores using various optimization techniques. Moreover, the output of different comparisons can be used further for text classification techniques. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Hate speech detection; machine learning; natural language processing; social media text; text classification},
	keywords = {Classification (of information); Learning algorithms; Natural language processing systems; Social networking (online); Speech recognition; Text processing; Hate speech detection; Language processing; Machine-learning; Natural language processing; Natural languages; Social media; Social medium text; Speech detection; Subtask; Text classification; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Cheriyan2021254,
	author = {Cheriyan, Jithin and Savarimuthu, Bastin Tony Roy and Cranefield, Stephen},
	title = {Towards offensive language detection and reduction in four software engineering communities},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {254 – 259},
	doi = {10.1145/3463274.3463805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108907678&doi=10.1145%2f3463274.3463805&partnerID=40&md5=bb9bb3a0f2f75941f2e6e4f3eff67263},
	affiliations = {University of Otago, Department of Information Science, Dunedin, New Zealand},
	abstract = {Software Engineering (SE) communities such as Stack Overflow have become unwelcoming, particularly through members' use of offensive language. Research has shown that offensive language drives users away from active engagement within these platforms. This work aims to explore this issue more broadly by investigating the nature of offensive language in comments posted by users in four prominent SE platforms - GitHub, Gitter, Slack and Stack Overflow (SO). It proposes an approach to detect and classify offensive language in SE communities by adopting natural language processing and deep learning techniques. Further, a Conflict Reduction System (CRS), which identifies offence and then suggests what changes could be made to minimize offence has been proposed. Beyond showing the prevalence of offensive language in over 1 million comments from four different communities which ranges from 0.07% to 0.43%, our results show promise in successful detection and classification of such language. The CRS system has the potential to drastically reduce manual moderation efforts to detect and reduce offence in SE communities.  © 2021 ACM.},
	author_keywords = {Conflict reduction; Offensive language detection; SE platforms},
	keywords = {Crime; Deep learning; Natural language processing systems; Cr-S system; Engineering community; Learning techniques; NAtural language processing; Offensive languages; Reduction systems; Stack overflow; Software engineering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 25th Evaluation and Assessment in Software Engineering Conference, EASE 2021; Conference date: 21 June 2021 through 24 June 2021; Conference code: 169627; All Open Access, Green Open Access}
}

@CONFERENCE{Jahan2021262,
	author = {Jahan, Md Saroar and Beddiar, Djamila Romaissa and Oussalah, Mourad and Arhab, Nabil and Bounab, Yazid},
	title = {Hate and Offensive language detection using BERT for English Subtask A},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {262 – 272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134265105&partnerID=40&md5=554f565daa3d9c2218b65bbd39af8df5},
	affiliations = {University of Oulu, Faculty of Information Tech., CMVS, PO Box 4500, Oulu, 90014, Finland},
	abstract = {This paper presents the results and main findings of the HASOC-2021 Hate/Offensive Language Identification Subtask A. The work consisted of fine-tuning pre-trained transformer networks such as BERT and an ensemble of different models, including CNN and BERT. We have used the HASOC-2021 English 3.8k annotated twitter dataset. We compare current pre-trained transformer networks with and without Masked-Language-Modelling (MLM) fine-tuning on their performance for offensive language detection. Among different BERT MLM fine-tuned BERT-base, BERT-large, and ALBERT outperformed other models; however, BERT and CNN ensemble classifier that applies majority voting outperformed other models, achieving 85.1% F1 score on both hate/non-hate labels. Our final submission achieved 77.0 F1 in the HASOC-2021 competition. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT fine-tuning; BERT performance comparison; Hate speech; Offensive language identification},
	keywords = {Computational linguistics; Natural language processing systems; BERT fine-tuning; BERT performance comparison; Fine tuning; Hate speech; Language detection; Language identification; Offensive language identification; Offensive languages; Performance comparison; Subtask; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Niraula202167,
	author = {Niraula, Nobal B. and Dulal, Saurab and Koirala, Diwa},
	title = {Offensive Language Detection in Nepali Social Media},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {67 – 75},
	doi = {10.18653/v1/2021.woah-1.7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138745619&doi=10.18653%2fv1%2f2021.woah-1.7&partnerID=40&md5=7d5ece5d80e9da6448011524dc450d5e},
	affiliations = {Nowa Lab, Madison, AL, United States; The University of Memphis, Memphis, TN, United States},
	abstract = {Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassments. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.  © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Social networking (online); Data set; Language detection; Low resource languages; Offensive languages; Resource-Rich; Sexual harassment; Social media; Supervised machine learning; Supervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference date: 6 August 2021; Conference code: 182536; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kumari2021643,
	author = {Kumari, Jyoti and Kumar, Abhinav},
	title = {Offensive Language Identification on Multilingual Code Mixing Text},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {643 – 650},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134265106&partnerID=40&md5=5c56b896b4cebc09a94c54c8ba5b177f},
	affiliations = {Department of Computer Science & Engineering, National Institute of Technology Patna, Patna, India; Department of Computer Science & Engineering, Siksha ’O’ Anusandhan Deemed to be University, Bhubaneswar, India},
	abstract = {Hate and offensive language identification from social media platforms have been an active area of research for the researchers. As the user-generated social media posts contain several grammatical errors, spelling mistakes, and non-standard abbreviations, the identification of hate and offensive posts have become a challenging task. In non-native English-speaking countries, social media texts are often code mixed or script mixed/switched, making it considerably more difficult. This work proposes ensemble-based models for the identification of offensive language from Tamil script-mixed, Tamil code-mixed, and Malayalam code-mixed social media posts. The use of character n-gram TF-IDF features with the ensemble-based model have shown promising results with weighted F1-scores of 0.83 for Tamil script-mixed, 0.67 for Tamil code-mixed, and 0.77 for Malayalam code-mixed social media posts. The code for the proposed models is available at https://github.com/Abhinavkmr/Dravidian-hate-speech.git. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-mixed; Dravidian language; Hate speech; Social media},
	keywords = {HTTP; Natural language processing systems; Active area; Code-mixed; Code-mixing; Dravidian language; Hate speech; Language identification; Malayalams; Offensive languages; Social media; Social media platforms; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Dhanya2021,
	author = {Dhanya, L K and Balakrishnan, Kannan},
	title = {Hate speech Detection in Asian Languages:A Survey},
	year = {2021},
	journal = {ICCISc 2021 - 2021 International Conference on Communication, Control and Information Sciences, Proceedings},
	doi = {10.1109/ICCISc52257.2021.9484922},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113322817&doi=10.1109%2fICCISc52257.2021.9484922&partnerID=40&md5=1a6372b7600a3741ad95e5da3cf08be6},
	affiliations = {Mar Baselious College of Engineering and Technology, Department of Computer Science and Engineering, Kerala, India; Cochin University of Science and Technology, Department of Computer Applications, Kerala, India},
	abstract = {In this study, we present a language-based survey of hate speech detection in Asian languages. The motivation of this survey is to encourage the development of an automated hate speech detection system for Malayalam. Any message from social media spreading negativity in the society related to sex, caste, religion, politics, race etc. can be called a hateful message. This kind of text is very challenging to detect. Here we have taken only language-specific studies for hate speech detection and analyzed the approaches used in each work. We have used three parameters in this paper to analyze the overall scenario of this problem among Asian languages. This study tries to identify the best classification algorithm for this task and also find the relation between classification approach, type and size of dataset and accuracy. So this survey will become the foundation of future studies in this area and will help to understand the challenges also.  © 2021 IEEE.},
	author_keywords = {Asian languages; Hate speech; machine learning},
	keywords = {Classification (of information); Surveys; Asian languages; Classification algorithm; Classification approach; Malayalams; Social media; Speech detection; Three parameters; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 2021 International Conference on Communication, Control and Information Sciences, ICCISc 2021; Conference date: 16 June 2021 through 18 June 2021; Conference code: 171177}
}

@ARTICLE{Chiril2022322,
	author = {Chiril, Patricia and Pamungkas, Endang Wahyu and Benamara, Farah and Moriceau, Véronique and Patti, Viviana},
	title = {Emotionally Informed Hate Speech Detection: A Multi-target Perspective},
	year = {2022},
	journal = {Cognitive Computation},
	volume = {14},
	number = {1},
	pages = {322 – 352},
	doi = {10.1007/s12559-021-09862-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106513940&doi=10.1007%2fs12559-021-09862-5&partnerID=40&md5=62e89e3a6a86b8e4373da011c0c2ca2e},
	affiliations = {IRIT, Université de Toulouse, Université Toulouse III - UPS, Toulouse, France; Dipartimento di Informatica, University of Turin, Turin, Italy},
	abstract = {Hate Speech and harassment are widespread in online communication, due to users' freedom and anonymity and the lack of regulation provided by social media platforms. Hate speech is topically focused (misogyny, sexism, racism, xenophobia, homophobia, etc.), and each specific manifestation of hate speech targets different vulnerable groups based on characteristics such as gender (misogyny, sexism), ethnicity, race, religion (xenophobia, racism, Islamophobia), sexual orientation (homophobia), and so on. Most automatic hate speech detection approaches cast the problem into a binary classification task without addressing either the topical focus or the target-oriented nature of hate speech. In this paper, we propose to tackle, for the first time, hate speech detection from a multi-target perspective. We leverage manually annotated datasets, to investigate the problem of transferring knowledge from different datasets with different topical focuses and targets. Our contribution is threefold: (1) we explore the ability of hate speech detection models to capture common properties from topic-generic datasets and transfer this knowledge to recognize specific manifestations of hate speech; (2) we experiment with the development of models to detect both topics (racism, xenophobia, sexism, misogyny) and hate speech targets, going beyond standard binary classification, to investigate how to detect hate speech at a finer level of granularity and how to transfer knowledge across different topics and targets; and (3) we study the impact of affective knowledge encoded in sentic computing resources (SenticNet, EmoSenticNet) and in semantically structured hate lexicons (HurtLex) in determining specific manifestations of hate speech. We experimented with different neural models including multitask approaches. Our study shows that: (1) training a model on a combination of several (training sets from several) topic-specific datasets is more effective than training a model on a topic-generic dataset; (2) the multi-task approach outperforms a single-task model when detecting both the hatefulness of a tweet and its topical focus in the context of a multi-label classification approach; and (3) the models incorporating EmoSenticNet emotions, the first level emotions of SenticNet, a blend of SenticNet and EmoSenticNet emotions or affective features based on Hurtlex, obtained the best results. Our results demonstrate that multi-target hate speech detection from existing datasets is feasible, which is a first step towards hate speech detection for a specific topic/target when dedicated annotated data are missing. Moreover, we prove that domain-independent affective knowledge, injected into our models, helps finer-grained hate speech detection. © 2021, The Author(s).},
	author_keywords = {Affective resources; Hate speech detection; Hate speech targets; Multi-task learning; Social media},
	keywords = {Classification (of information); Knowledge management; Speech; Speech communication; Annotated datasets; Binary classification; Domain independents; Multi label classification; On-line communication; Sexual orientations; Social media platforms; Vulnerable groups; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Miok2022353,
	author = {Miok, Kristian and Škrlj, Blaž and Zaharie, Daniela and Robnik-Šikonja, Marko},
	title = {To BAN or Not to BAN: Bayesian Attention Networks for Reliable Hate Speech Detection},
	year = {2022},
	journal = {Cognitive Computation},
	volume = {14},
	number = {1},
	pages = {353 – 371},
	doi = {10.1007/s12559-021-09826-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099930740&doi=10.1007%2fs12559-021-09826-9&partnerID=40&md5=807821af54932d3ef37782293fc95826},
	affiliations = {Computer Science Department, West University of Timisoara, Bulevardul Vasile Pârvan 4, Timisoara, 300223, Romania; Jozef Stefan International Postgraduate School, Jozef Stefan Institute, Jamova 39, Ljubljana, 1000, Slovenia; Faculty of Computer and Information Science, University of Ljubljana, Večna pot 113, Ljubljana, 1000, Slovenia},
	abstract = {Hate speech is an important problem in the management of user-generated content. To remove offensive content or ban misbehaving users, content moderators need reliable hate speech detectors. Recently, deep neural networks based on the transformer architecture, such as the (multilingual) BERT model, have achieved superior performance in many natural language classification tasks, including hate speech detection. So far, these methods have not been able to quantify their output in terms of reliability. We propose a Bayesian method using Monte Carlo dropout within the attention layers of the transformer models to provide well-calibrated reliability estimates. We evaluate and visualize the results of the proposed approach on hate speech detection problems in several languages. Additionally, we test whether affective dimensions can enhance the information extracted by the BERT model in hate speech classification. Our experiments show that Monte Carlo dropout provides a viable mechanism for reliability estimation in transformer networks. Used within the BERT model, it offers state-of-the-art classification performance and can detect less trusted predictions. © 2021, The Author(s).},
	author_keywords = {Bayesian BERT; Model calibration; Monte Carlo dropout; Prediction uncertainty; Reliability estimation; Sentic Computing; Transformer neural networks},
	keywords = {Bayesian networks; Classification (of information); Deep neural networks; Monte Carlo methods; Reliability; Speech; Classification performance; Classification tasks; Natural languages; Reliability estimates; Reliability estimation; Speech classification; Transformer models; User-generated content; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mishra2021,
	author = {Mishra, Sudhanshu and Prasad, Shivangi and Mishra, Shubhanshu},
	title = {Exploring Multi-Task Multi-Lingual Learning of Transformer Models for Hate Speech and Offensive Speech Identification in Social Media},
	year = {2021},
	journal = {SN Computer Science},
	volume = {2},
	number = {2},
	doi = {10.1007/s42979-021-00455-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118379369&doi=10.1007%2fs42979-021-00455-5&partnerID=40&md5=9d44790b92918b9932db142dab561d7b},
	affiliations = {Indian Institute of Technology Kanpur, Kanpur, India; University of Illinois at Urbana-Champaign, Champaign, United States},
	abstract = {Hate Speech has become a major content moderation issue for online social media platforms. Given the volume and velocity of online content production, it is impossible to manually moderate hate speech related content on any platform. In this paper we utilize a multi-task and multi-lingual approach based on recently proposed Transformer Neural Networks to solve three sub-tasks for hate speech. These sub-tasks were part of the 2019 shared task on hate speech and offensive content (HASOC) identification in Indo-European languages. We expand on our submission to that competition by utilizing multi-task models which are trained using three approaches, (a) multi-task learning with separate task heads, (b) back-translation, and (c) multi-lingual training. Finally, we investigate the performance of various models and identify instances where the Transformer based models perform differently and better. We show that it is possible to to utilize different combined approaches to obtain models that can generalize easily on different languages and tasks, while trading off slight accuracy (in some cases) for a much reduced inference time compute cost. We open source an updated version of our HASOC 2019 code with the new improvements at https://github.com/socialmediaie/MTML_HateSpeech. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. part of Springer Nature.},
	author_keywords = {BERT; Deep learning; Hate speech; Language models; Machine learning; Multi-lingual; Multi-Task learning; Natural language processing; Neural networks; Offensive content; Open source; Social media; Transformer models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access}
}

@CONFERENCE{Alakrot2021244,
	author = {Alakrot, Azalden and Fraifer, Muftah and Nikolov, Nikola S.},
	title = {Machine Learning Approach to Detection of Offensive Language in Online Communication in Arabic},
	year = {2021},
	journal = {2021 IEEE 1st International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering, MI-STA 2021 - Proceedings},
	pages = {244 – 249},
	doi = {10.1109/MI-STA52233.2021.9464402},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113667658&doi=10.1109%2fMI-STA52233.2021.9464402&partnerID=40&md5=1e37f32127b1871dbb7ddca68dc1ae3d},
	affiliations = {The College of Medical Technology, Department of Information Technology, Yefren, Libyan Arab Jamahiriya; The College of Industrial Technologies-CIT, Department of Electronic Engineering, Misurata, Libyan Arab Jamahiriya; University of Limerick, Dep. of Computer Science and Information System, Limerick, Ireland},
	abstract = {This paper presents the results of several machine learning experiments, conducted with a dataset of YouTube comments in Arabic. The experiments aim at studying the impact of various text preprocessing, feature-extraction and feature-selection techniques on the accuracy of a document classifier for detection of offensive language in online communication in Arabic. Regarding data pre-processing, our experiments focus on filtering out noisy characters and normalising inconsistencies present in casual online writing in Arabic. The combined effect of these data preprocessing techniques and a few feature-extraction and feature-selection methods is then evaluated by training document classifiers. Our results give evidence that it is possible to train a classifier for the detection of offensive language on Arabic social media with reasonable overall accuracy of 0.84, and precision, recall and F1-score of 0.89, 0.76 and 0.81, respectively. © 2021 IEEE.},
	author_keywords = {Feature Selection; Logistic Regression; Machine Learning; Offensive Language; Support Vector Machine; SVM},
	keywords = {Automation; Data handling; E-learning; Extraction; Machine learning; Process control; Data preprocessing technique; Feature selection methods; Machine learning approaches; Offensive languages; On-line communication; Selection techniques; Text preprocessing; Training documents; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 1st IEEE International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering, MI-STA 2021; Conference date: 25 May 2021 through 27 May 2021; Conference code: 171040}
}

@ARTICLE{Chaudhry2022195,
	author = {Chaudhry, Prateek and Lease, Matthew},
	title = {You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate Speech Detection},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13193 LNCS},
	pages = {195 – 203},
	doi = {10.1007/978-3-030-96960-8_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126236283&doi=10.1007%2f978-3-030-96960-8_13&partnerID=40&md5=688a33f3f40c4964360adad9291255dc},
	affiliations = {University of Texas at Austin, Austin, United States},
	abstract = {Hate speech detection research has predominantly focused on purely content-based methods, without exploiting other contextual data. We briefly critique pros and cons of this task formulation. We then investigate profiling users by their past utterances as an informative prior to better predict whether new utterances constitute hate speech. To evaluate this, we augment three Twitter hate speech datasets with additional timeline data, then embed this additional context into a strong baseline model. Promising results suggest merit for further investigation. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Classification; Hate speech; Modeling; Profiles; Twitter},
	keywords = {Speech; Speech recognition; User profile; Baseline models; Content-based methods; Hate speech; Informative Priors; Modeling; Profile; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 17th International Conference on Information for a Better World: Shaping the Global Future, iConference 2022; Conference date: 28 February 2022 through 4 March 2022; Conference code: 273989; All Open Access, Green Open Access}
}

@CONFERENCE{Agustian2021508,
	author = {Agustian, Surya and Saputra, Reski and Fadhilah, Aidil},
	title = {“Feature Selection” with Pretrained-BERT for Hate Speech and Offensive Content Identification in English and Hindi Languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {508 – 516},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134256747&partnerID=40&md5=51de2cc2960334e548d0d42726f9a483},
	affiliations = {UIN Sultan Syarif Kasim, Jl. H.R. Soeberantas km 11.5 Panam, Riau, Pekanbaru, Indonesia},
	abstract = {The intensive use of social media has led people to express non-formal spoken language, in interactions with others on the internet through text posts. Often, people spill out their annoyance without concern about the use of hate speech, profanity, and abusive language, when is meant to attack and even oppress someone. HASOC 2021 is a shared task that aims to identify hate and abusive content in tweets. In this event, we proposed BERT (and FastText) based transfer learning approach to solve this classification problem. The results obtained by our team UINSUSKA, for English task 1A and 1B, and Hindi task 1A are in the rank 8, 5 and 12 respectively. As for the Hindi task 1B, due to time constraints, our team could not have enough time to develop experiments with BERT, and was ranked 18th for the result using FastText. © 2021 Copyright for this paper by its authors.},
	author_keywords = {abusive content; BERT; FastText; Hate speech; profane words; transfer learning},
	keywords = {Abusive content; BERT; Content identifications; Fasttext; Features selection; Hate speech; Profane word; Social media; Spoken languages; Transfer learning; Hazardous materials spills},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Ranasinghe2021,
	author = {Ranasinghe, Tharindu and Zampieri, Marcos},
	title = {An evaluation of multilingual offensive language identification methods for the languages of India},
	year = {2021},
	journal = {Information (Switzerland)},
	volume = {12},
	number = {8},
	doi = {10.3390/info12080306},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112436523&doi=10.3390%2finfo12080306&partnerID=40&md5=ffa69111cbf83c526a8cf34d38b29228},
	affiliations = {Research Group in Computational Linguistics, University of Wolverhampton, Wolverhampton, WV1 1LY, United Kingdom; Language Technology Group, Rochester Institute of Technology, Rochester, 14623, NY, United States},
	abstract = {The pervasiveness of offensive content in social media has become an important reason for concern for online platforms. With the aim of improving online safety, a large number of studies applying computational models to identify such content have been published in the last few years, with promising results. The majority of these studies, however, deal with high-resource languages such as English due to the availability of datasets in these languages. Recent work has addressed offensive language identification from a low-resource perspective, exploring data augmentation strategies and trying to take advantage of existing multilingual pretrained models to cope with data scarcity in low-resource scenarios. In this work, we revisit the problem of low-resource offensive language identification by evaluating the performance of multilingual transformers in offensive language identification for languages spoken in India. We investigate languages from different families such as Indo-Aryan (e.g., Bengali, Hindi, and Urdu) and Dravidian (e.g., Tamil, Malayalam, and Kannada), creating important new technology for these languages. The results show that multilingual offensive language identification models perform better than monolingual models and that cross-lingual transformers show strong zero-shot and few-shot performance across languages. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Deep learning; Multilingual learning; Offensive language identification},
	keywords = {Computational model; Cross-lingual; Data augmentation; Data scarcity; Malayalams; Offensive languages; Online platforms; Social media; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Pamungkas2021,
	author = {Pamungkas, Endang Wahyu and Basile, Valerio and Patti, Viviana},
	title = {A joint learning approach with knowledge injection for zero-shot cross-lingual hate speech detection},
	year = {2021},
	journal = {Information Processing and Management},
	volume = {58},
	number = {4},
	doi = {10.1016/j.ipm.2021.102544},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101695666&doi=10.1016%2fj.ipm.2021.102544&partnerID=40&md5=18082c8c4b91413d84e772ff0a681ef8},
	affiliations = {Department of Computer Science, University of Turin, Italy},
	abstract = {Hate speech is an increasingly important societal issue in the era of digital communication. Hateful expressions often make use of figurative language and, although they represent, in some sense, the dark side of language, they are also often prime examples of creative use of language. While hate speech is a global phenomenon, current studies on automatic hate speech detection are typically framed in a monolingual setting. In this work, we explore hate speech detection in low-resource languages by transferring knowledge from a resource-rich language, English, in a zero-shot learning fashion. We experiment with traditional and recent neural architectures, and propose two joint-learning models, using different multilingual language representations to transfer knowledge between pairs of languages. We also evaluate the impact of additional knowledge in our experiment, by incorporating information from a multilingual lexicon of abusive words. The results show that our joint-learning models achieve the best performance on most languages. However, a simple approach that uses machine translation and a pre-trained English language model achieves a robust performance. In contrast, Multilingual BERT fails to obtain a good performance in cross-lingual hate speech detection. We also experimentally found that the external knowledge from a multilingual abusive lexicon is able to improve the models’ performance, specifically in detecting the positive class. The results of our experimental evaluation highlight a number of challenges and issues in this particular task. One of the main challenges is related to the issue of current benchmarks for hate speech detection, in particular how bias related to the topical focus in the datasets influences the classification performance. The insufficient ability of current multilingual language models to transfer knowledge between languages in the specific hate speech detection task also remain an open problem. However, our experimental evaluation and our qualitative analysis show how the explicit integration of linguistic knowledge from a structured abusive language lexicon helps to alleviate this issue. © 2021 Elsevier Ltd},
	author_keywords = {Cross-lingual classification; Hate speech detection; Social media; Transfer learning; Zero-shot learning},
	keywords = {Benchmarking; Classification (of information); Computational linguistics; Computer aided language translation; Digital communication systems; Learning systems; Speech; Speech communication; Classification performance; Digital communications; Experimental evaluation; Linguistic knowledge; Low resource languages; Machine translations; Multilingual lexicons; Qualitative analysis; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68}
}

@ARTICLE{Pandey2022457,
	author = {Pandey, Yogesh and Sharma, Monika and Siddiqui, Mohammad Kashaf and Yadav, Sudeept Singh},
	title = {Hate Speech Detection Model Using Bag of Words and Naïve Bayes},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {318},
	pages = {457 – 470},
	doi = {10.1007/978-981-16-5689-7_40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125226805&doi=10.1007%2f978-981-16-5689-7_40&partnerID=40&md5=22fe388898f59d0d019181f616395cd6},
	affiliations = {SCSE, Galgotias University, Greater Noida, India},
	abstract = {In this era of increasing hate and intolerance among the people, especially among those who interact with each other over the Web, there is a dire need of some technological innovation that would cater to this situation. The said hate and clash of opinions among the people often comes out in the form of hate speech in texts and in pictures. To counter this situation, we have come up with a hate speech detection model which would be able to detect and identify hateful and provocative content in a textual data, which is published on various social media websites, viz. Twitter, Facebook, and Instagram. The sole idea behind the making of this model is to be able to prevent every individual from spreading as well as witnessing hate-speech on different digital-platforms. We have developed a text classifier using basic principles of natural language processing. This has been achieved by the use of the bag of words model for feature extraction purposes, followed by various text filtering processes, and ultimately feeding this data to a naïve-Bayes classifier, and hence training the same to work autonomously to classify textual data depending upon the sentiments indicated by them, i.e. whether they imply negative aspects over a certain matter/topic or positive. As a result of this experiment, we were able to successfully classify all the data taken by us with a cumulative accuracy of 99.7% upon the test data set. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Bag of Words; Digital-platforms; Hate-speech; Naïve-Bayes},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 3rd International Conference on Data and Information Sciences, ICDIS 2021; Conference date: 14 May 2021 through 15 May 2021; Conference code: 272109}
}

@CONFERENCE{Chebbi2021,
	author = {Chebbi, Safa and Sekkate, Sara and Jebara, Sofia Ben and Adib, Abdellah},
	title = {On the use of MFCC and SWT-based features for offensive speech detection in social media},
	year = {2021},
	journal = {2021 International Conference on INnovations in Intelligent SysTems and Applications, INISTA 2021 - Proceedings},
	doi = {10.1109/INISTA52262.2021.9548341},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116635892&doi=10.1109%2fINISTA52262.2021.9548341&partnerID=40&md5=7641480e2291b4cf88595354089abced},
	affiliations = {University of Carthage, Sup'Com, LR11TIC01, COSIM Research Lab, Tunisia; University of HassanII, FSTM, LIM Research Lab, Morocco},
	abstract = {Research on psychological comfort and serenity in social media becomes a necessity because of the excess of negative waves generated by the users. In this paper, we aim to distinguish between offensive and ordinary speech based on machine learning classification techniques. For this purpose, the VAM emotional audio database has been restructured and adjusted to the context of offensive speech detection. Besides, a feature fusion based on Mel Frequency Cepstral Coefficients (MFCCs) as well as Stationary Wavelet Transform (SWT) has been employed and K-nearest neighbors (KNN) algorithm has been used as a classification tool. Results show that the considered feature set has relatively great power in recognizing suspicious behavior, reaching 96.2% as the highest accuracy rate. © 2021 IEEE.},
	author_keywords = {Arousal dimension; Emotional wheel; Feature selection; MFCC; Offensive speech; Speech analysis; SWT; Valence dimension},
	keywords = {Feature extraction; Learning systems; Nearest neighbor search; Social networking (online); Speech recognition; Wavelet transforms; Arousal dimension; Emotional wheel; Features selection; Mel frequency cepstral co-efficient; Mel-frequency cepstral coefficients; Offensive speech; Social media; Speech detection; Stationary wavelet transforms; Valence dimension; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Conference on INnovations in Intelligent SysTems and Applications, INISTA 2021; Conference date: 25 August 2021 through 27 August 2021; Conference code: 172175}
}

@ARTICLE{Uyheng2021121,
	author = {Uyheng, Joshua and Carley, Kathleen M.},
	title = {An Identity-Based Framework for Generalizable Hate Speech Detection},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12720 LNCS},
	pages = {121 – 130},
	doi = {10.1007/978-3-030-80387-2_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134663881&doi=10.1007%2f978-3-030-80387-2_12&partnerID=40&md5=573a469f6ba1e4be702116567524fdda},
	affiliations = {CASOS Center, Institute for Software Research, Carnegie Mellon University, Pittsburgh, 15213, PA, United States},
	abstract = {This paper explores the viability of leveraging an identity-based framework for generalizable hate speech detection. Across a corpus of seven benchmark datasets, we find that hate speech consistently features higher levels of abusive and identity terms, robust to social media platforms of origin and multiple languages. Using only lexical counts of abusives, identities, and other psycholinguistic features, heuristic and machine learning models achieve high precision and weighted F1 scores in hate speech prediction, with performance on a three-language dataset comparable to recent state-of-the-art multilingual models. Cross-dataset predictions further reveal that our proposed identity-based models map hate and non-hate categories with each other in a conceptually coherent fashion across diverse classification schemes. Our findings suggest that conceptualizing hate speech through an identity lens offers a generalizable, interpretable, and socio-theoretically robust framework for computational modelling of online conflict and toxicity. © Springer Nature Switzerland AG 2021.},
	author_keywords = {Hate speech; Identities; Machine learning; Social media},
	keywords = {Classification (of information); Social networking (online); Speech recognition; Benchmark datasets; Feature learning; Hate speech; Identity; Identity-based; Machine-learning; Multiple languages; Social media; Social media platforms; Speech detection; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 14th International Conference on Social, Cultural, and Behavioral Modeling, SBP-BRiMS 2021; Conference date: 6 July 2021 through 9 July 2021; Conference code: 262289}
}

@CONFERENCE{Xu2021154,
	author = {Xu, Yifan and Ning, Hui and Sun, Yutong},
	title = {Hate Speech and Offensive Content Identification Based on Self-Attention},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {154 – 160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134252781&partnerID=40&md5=695e42388063372e862181aad18fdc49},
	affiliations = {Harbin Engineering University, Harbin, China; Heilongjiang Institute of Technology, Harbin, China},
	abstract = {With the development of the Internet, more and more people use the social medias to share their daily life. However, there are various problems existing in the online community. One of these problems is that some people would like to post hate speech and offensive contents. How to identify hate speech and offensive contents is a serious problem. “Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages” is a track which is committed to solve this problem. We used three different models consisting of SVM, CNN and BERT to do experiments about English texts. Among them, BERT has the best performance. Our team called QQQ get a Macro-averaged F1 score of 0.7374. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT; Hate speech; Self-Attention},
	keywords = {Speech recognition; BERT; Content identifications; Daily lives; F1 scores; Hate speech; On-line communities; Performance; Self-attention; Social media; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Ritu20211725,
	author = {Ritu, Sumaiya Salim and Mondal, Joysurya and Mia, Md. Moinu and Marouf, Ahmed Al},
	title = {Bangla Abusive Language Detection using Machine Learning on Radio Message Gateway},
	year = {2021},
	journal = {Proceedings of the 6th International Conference on Communication and Electronics Systems, ICCES 2021},
	pages = {1725 – 1729},
	doi = {10.1109/ICCES51350.2021.9489131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113783145&doi=10.1109%2fICCES51350.2021.9489131&partnerID=40&md5=b149acfe5370cb0d0be73df26cb0d36d},
	affiliations = {Daffodil International University, Department of Computer Science and Engineering, Dhaka, Bangladesh},
	abstract = {In the era of modern technology, machine learning and natural language processing has been adopted to be applied in several application areas. Natural language processing consists of diversified techniques such as text classification, text summarization, named entity recognition, sentiment analysis. Text classification is considered to be the area of research where the text gets segmented into different category sentences or paragraphs from a single text genre. This paper presents a mechanism for detecting Bangla abusive language from a realtime radio message gateway. Online radio stations nowadays accept communications and voices of their target audience from web-based applications or social media platforms, such as Facebook or Twitter pages. This paper has created a dataset with more than 45000 Bangla sentences, which are labeled as abusive and non-abusive. Sample online radio message gateway has been been introduced and machine learning algorithms such as multinomial naive bias (MNB), logistic regression (LR), and random forest (RF) classifiers are utilized to predict the abusive languages. One of the significant prospects of this work would be applied during live radio programs where listeners try to communicate by sending live messages. Our proposed mechanism can check and map the live messages with the dataset and segregate the positive comments or messages only, by filtering the abusive comments. Among the applied classifiers, it has been found that the random forest classifier has performed better than the other two classifiers by leveraging approximately 76% accuracy. © 2021 IEEE.},
	author_keywords = {Bangla Abusive Words; Communication Gateway; Machine Learning; Radio Message; Random Forest},
	keywords = {Character recognition; Decision trees; Logistic regression; Radio broadcasting; Radio stations; Random forests; Sentiment analysis; Social networking (online); Taxonomies; Language detection; Modern technologies; Named entity recognition; NAtural language processing; Random forest classifier; Social media platforms; Text classification; Web-based applications; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 6th IEEE International Conference on Communication and Electronics Systems, ICCES 2021; Conference date: 8 July 2021 through 10 July 2021; Conference code: 170997}
}

@ARTICLE{Song20211667,
	author = {Song, Guizhe and Huang, Degen and Zhang, Yanping},
	title = {A hybrid model for monolingual and multilingual toxic comment detection},
	year = {2021},
	journal = {Tehnicki Vjesnik},
	volume = {28},
	number = {5},
	pages = {1667 – 1673},
	doi = {10.17559/TV-20210325125414},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113710025&doi=10.17559%2fTV-20210325125414&partnerID=40&md5=1a1282e1dc23f36f00b9f23608e2691c},
	affiliations = {Dalian University of Technology, School of Computer Science and Technology, No. 2 Linggong Road, Ganjingzi District, Liaoning Province, Dalian City, 116024, China; Gonzaga University, Department of Computer Science, 502 East Boone Avenue, Spokane, 99258-0102, WA, Canada},
	abstract = {Social media provides a public and convenient platform for people to communicate. However, it is also open to hateful behavior and toxic comments. Social networks, like Facebook, Twitter, and many others, have been working on developing effective toxic comment detection methods to provide better service. Monolingual language model focuses on a single-language and provides high accuracy in detection. Multilingual language model provides better generalization performance. In order to improve the effectiveness of detecting toxic comments in multiple languages, we propose a hybrid model, which fuses monolingual model and multilingual model. We use labeled data to fine-tune the monolingual pre-trained model. We use masked language modeling to semi-supervise the fine-tuning of multilingual pre-trained model on unlabeled data and then use labeled data to fine-tune the model. Through this way, we can fully utilize the large amount of unlabeled data; reduce dependence on labeled comment data; and improve the effectiveness of detection. We also design several comparative experiments. The results demonstrate the effectiveness and advantage of our proposed model, especially compared to the XLM-RoBERTa multilingual fine-tuning model. © 2021, Strojarski Facultet. All rights reserved.},
	author_keywords = {Masked language modelling; Model fusion; Toxic commenting; XLM-RoBERTa},
	keywords = {Computational linguistics; Labeled data; Social networking (online); Comparative experiments; Detection methods; Generalization performance; High-accuracy; Language model; Large amounts; Multiple languages; Unlabeled data; Modeling languages},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Jarquin-Vasquez2021103,
	author = {Jarquin-Vasquez, Horacio and Escalante, Hugo Jair and Montes-Y-Gomez, Manuel},
	title = {Self-Contextualized Attention for Abusive Language Identification},
	year = {2021},
	journal = {SocialNLP 2021 - 9th International Workshop on Natural Language Processing for Social Media, Proceedings of the Workshop},
	pages = {103 – 112},
	doi = {10.18653/v1/2021.socialnlp-1.9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138491897&doi=10.18653%2fv1%2f2021.socialnlp-1.9&partnerID=40&md5=d92e2ce8e71c56caeb20fc72f942f721},
	affiliations = {Instituto Nacional de Astrofísica, Optica y Electronica (INAOE), Luis Enrique Erro #1, Sta Maria Tonanzintla, San Andres Cholula, Pue., 72840, Mexico},
	abstract = {The use of attention mechanisms in deep learning approaches has become popular in natural language processing due to its outstanding performance. The use of these mechanisms allows one managing the importance of the elements of a sequence in accordance to their context, however, this importance has been observed independently between the pairs of elements of a sequence (self-attention) and between the application domain of a sequence (contextual attention), leading to the loss of relevant information and limiting the representation of the sequences. To tackle these particular issues we propose the self-contextualized attention mechanism, which trades off the previous limitations, by considering the internal and contextual relationships between the elements of a sequence. The proposed mechanism was evaluated in four standard collections for the abusive language identification task achieving encouraging results. It outperformed the current attention mechanisms and showed a competitive performance with respect to state-of-the-art approaches. © SocialNLP 2021 Natural Language Processing for Social Media},
	keywords = {Deep learning; Social networking (online); Applications domains; Attention mechanisms; Contextual relationships; Internal relationships; Language identification; Language processing; Learning approach; Natural languages; Performance; Trade off; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 9th International Workshop on Natural Language Processing for Social Media, SocialNLP 2021; Conference date: 10 June 2021; Conference code: 182490; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Toktarova20212054,
	author = {Toktarova, Aigerim and Beissenova, Gulbakhram and Nurtas, Marat and Kozhabekova, Pernekul and Azhibekova, Zhanar and Makhanova, Zlikha and Tulegenova, Bibigul and Rakhymbek, Nazira and Baishemirov, Zharasbek},
	title = {Automatic offensive language detection in online user generated contents},
	year = {2021},
	journal = {Journal of Theoretical and Applied Information Technology},
	volume = {99},
	number = {9},
	pages = {2054 – 2067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107034533&partnerID=40&md5=ff26e339bf79542414b8b6da487c194f},
	affiliations = {Khoja Akhmet Yassawi International Kazakh-Turkish University, Turkistan, Kazakhstan; M.Auezov South Kazakhstan University, Shymkent, Kazakhstan; University of Friendship of People’s Academician A. Kuatbekov, Shymkent, Kazakhstan; International Information Technology University, Almaty, Kazakhstan; Kazakh-Britain Technical University, Almaty, Kazakhstan; Asfendiyarov Kazakh National Medical University, Almaty, Kazakhstan; Abai Kazakh National Pedagogical University, Almaty, Kazakhstan; RSE Institute of Information and Computational Technology CS MES RK, Almaty, Kazakhstan},
	abstract = {Profanity on the pages of social networking networks is growing the number of problems social networking has. Easy and automated steps are necessary to control the amount of content that is generated on a daily basis. There is a significant research question concerning language instruction rather than the implementation methods. We are creating a dataset of internet users in Kazakhstan where they use social networks and the media to share their opinions. According to this report, it is the first time anybody has ever done a study focused on complaints from multiple social networks. We have classified our index in a variety of respects, one of which is to use derogatory terms. Furthermore, our results will not only explore the roots of offensive language, but will also present concepts that help in differentiating such types of offensive language, such as offensive language and cyberbullying. We use machine learning approaches to access the data sets we can use for the automated study of offensive language on social media. The results show that recognizing offensive language on social networks is a task that can be solved automatically and produces excellent results. © 2021 Little Lion Scientific.},
	author_keywords = {Classification; Detection; Hate speech; Machine learning; Natural language processing; Offensive language; Social media; Social networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kovács2021,
	author = {Kovács, György and Alonso, Pedro and Saini, Rajkumar},
	title = {Challenges of Hate Speech Detection in Social Media: Data Scarcity, and Leveraging External Resources},
	year = {2021},
	journal = {SN Computer Science},
	volume = {2},
	number = {2},
	doi = {10.1007/s42979-021-00457-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122607484&doi=10.1007%2fs42979-021-00457-3&partnerID=40&md5=f5d39efdfeff00c78d9c038a03ce080a},
	affiliations = {Luleå University of Technology, Aurorum 1, Luleå, 971 87, Sweden},
	abstract = {The detection of hate speech in social media is a crucial task. The uncontrolled spread of hate has the potential to gravely damage our society, and severely harm marginalized people or groups. A major arena for spreading hate speech online is social media. This significantly contributes to the difficulty of automatic detection, as social media posts include paralinguistic signals (e.g. emoticons, and hashtags), and their linguistic content contains plenty of poorly written text. Another difficulty is presented by the context-dependent nature of the task, and the lack of consensus on what constitutes as hate speech, which makes the task difficult even for humans. This makes the task of creating large labeled corpora difficult, and resource consuming. The problem posed by ungrammatical text has been largely mitigated by the recent emergence of deep neural network (DNN) architectures that have the capacity to efficiently learn various features. For this reason, we proposed a deep natural language processing (NLP) model—combining convolutional and recurrent layers—for the automatic detection of hate speech in social media data. We have applied our model on the HASOC2019 corpus, and attained a macro F1 score of 0.63 in hate speech detection on the test set of HASOC. The capacity of DNNs for efficient learning, however, also means an increased risk of overfitting. Particularly, with limited training data available (as was the case for HASOC). For this reason, we investigated different methods for expanding resources used. We have explored various opportunities, such as leveraging unlabeled data, similarly labeled corpora, as well as the use of novel models. Our results showed that by doing so, it was possible to significantly increase the classification score attained. © 2021, The Author(s).},
	author_keywords = {BERT; Deep language processing; Hate speech; Transfer learning; Vocabulary augmentation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 84; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bindra2022703,
	author = {Bindra, Mahin and Sharma, Bhavya and Bansal, Nipun},
	title = {Detecting Hate Speech and Offensive Language Using Transformer Techniques},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {373},
	pages = {703 – 715},
	doi = {10.1007/978-981-16-8721-1_65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126217775&doi=10.1007%2f978-981-16-8721-1_65&partnerID=40&md5=d6445a837145ff3f1fc6c89da6b25883},
	affiliations = {Department of Computer Science, Delhi Technological University, New Delhi, India},
	abstract = {Social media has become part of our everyday lives, and it has its pros and cons. Hate speech online is a new-born problem in our modern society that is growing at a steady pace, using the weaknesses of cohesive regimes that spill over several social media platforms. Due to the inconsistent and large size of social media, the detection of hate content has become a major concern to avoid conflicts and prevent unwanted activities. Hence, it is crucial to devise an automated system to detect the same. There have been many studies in the field of Artificial Intelligence to detect hate speech. Nonetheless, the efficiency of the models has not been up to the mark. In this study, we compare two different state-of-the-art models. The first is BERT-CNN model based on transformer, and the second is an LSTM model based on attention. Both these models work on a publicly available dataset containing messages categorized into different hate emotions. This study shows that the BERT-CNN model exhibits the highest accuracy, while outperforming the other. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Attention; Convolutional neural network; Hate speech; Natural language processing; Transformers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th International Conference on Microelectronics and Telecommunication Engineering, ICMETE 2021; Conference date: ; Conference code: 274209}
}

@ARTICLE{da Silva2021,
	author = {da Silva, Daniela America and Louro, Henrique Duarte Borges and Goncalves, Gildarcio Sousa and Marques, Johnny Cardoso and Dias, Luiz Alberto Vieira and da Cunha, Adilson Marques and Tasinaffo, Paulo Marcelo},
	title = {Could a conversational ai identify offensive language?†},
	year = {2021},
	journal = {Information (Switzerland)},
	volume = {12},
	number = {10},
	doi = {10.3390/info12100418},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117762535&doi=10.3390%2finfo12100418&partnerID=40&md5=ad36849cde8e51a4218a897a52ba9500},
	affiliations = {Electronic and Computer Engineering Program, Informatics, Brazilian Aeronautics Institute of Technology, ITA, Sao Jose dos Campos, 12228-900, Brazil},
	abstract = {In recent years, we have seen a wide use of Artificial Intelligence (AI) applications in the Internet and everywhere. Natural Language Processing and Machine Learning are important sub-fields of AI that have made Chatbots and Conversational AI applications possible. Those algorithms are built based on historical data in order to create language models, however historical data could be intrinsically discriminatory. This article investigates whether a Conversational AI could identify offensive language and it will show how large language models often produce quite a bit of unethical behavior because of bias in the historical data. Our low-level proof-of-concept will present the challenges to detect offensive language in social media and it will discuss some steps to propitiate strong results in the detection of offensive language and unethical behavior using a Conversational AI. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {AI ethics; Dictionary; Fairness; Natural language; Offensive},
	keywords = {Artificial intelligence; Computational linguistics; Natural language processing systems; Artificial intelligence ethic; Chatbots; Fairness; Historical data; Language model; Machine-learning; Natural languages; Offensive; Offensive languages; Sub fields; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@CONFERENCE{Bouazizi2021165,
	author = {Bouazizi, Mondher and Niida, Natsuho and Ohtsuki, Tomoaki},
	title = {All-in-One Hate Speech Detectors May not be what You Want},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {165 – 170},
	doi = {10.1145/3451471.3451498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112532542&doi=10.1145%2f3451471.3451498&partnerID=40&md5=3d19d92c23e23d4f1b08ea2fbb175bb1},
	affiliations = {Faculty of Science of Technology, Keio University Yokohama, Kanagawa, Japan},
	abstract = {The detection of Hate speech has been an increasingly active research topic. The results reported by the state-of-the-art systems to automatically detect hateful contents achieved almost perfect performance on common data sets. However, "hate speech"is a very subjective term, and people with different backgrounds have different levels of tolerance to what constitutes hate. In this paper, we show the limitations of having a single classifier handling the problem of hate speech detection. We then propose to build classifiers customized for different people, instead of a single classifier. The main obstacle towards achieving such a goal is the scarcity of data. Therefore, we use transfer learning to overcome this issue and use very limited amount of annotated data to build these customized classifiers. In a first stage, we build a classifier on a large data set which classifies tweets into 3 classes: hate, offensive, clean, and which we refer to as the general classifier. In the second stage, we asked 3 annotators with different backgrounds to re-annotate a small sub-set of tweets (600 tweets) from the original one. We refer to this newly created data set as "the customized data set."We then fine-tune the general classifier on the customized data set and build the customized classifier for each annotator. The accuracy of classification of corresponding customized data set got 0.08, 0.06 and 0.11 higher than the general classifier. The result shows that it is possible to start with a general classifier, and adjusted it to each individual despite the very limited amount of the training data for him/her. © 2021 ACM.},
	author_keywords = {Deep Learning; Hate Speech Detection; Transfer Learning; Twitter},
	keywords = {Information management; Software engineering; Speech recognition; Transfer learning; Accuracy of classifications; Common datum; Data set; Large datasets; Research topics; Speech detection; State-of-the-art system; Training data; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th International Conference on Software Engineering and Information Management, ICSIM 2021; Conference date: 16 January 2021 through 18 January 2021; Conference code: 170192}
}

@CONFERENCE{Gajbhiye2021379,
	author = {Gajbhiye, Disha and Deshpande, Swapnil and Ghante, Prerna and Kale, Abhijeet and Chaudhari, Deptii},
	title = {Machine Learning Models for Hate Speech Identification in Marathi Language},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {379 – 386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134260045&partnerID=40&md5=707d7d6fe530baaa2312461b55dbfc59},
	affiliations = {Hope Foundation’s International Institute of Information Technology, Hinjawadi, Pune, India},
	abstract = {Hate speech content has become a significant issue in today’s world. Hate speech detection is an automated task of detecting textual content that contains discriminatory language regarding a person or group based on who they are, their race, gender, caste, etc. In this paper, we discuss the models submitted by our team, Mind Benders, for Marathi subtask A, for "Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC)" at Forum for Information Retrieval Evaluation. A training and test dataset in Marathi language containing 1874 and 625 tweets, respectively, were shared by the HASOC organizers. Using these datasets, we propose an approach to automatically classify the tweets into two categories: "NOT" (Non-Hate-Offensive) and "HOF" (Hate and Offensive). The classification models developed are applied to the test dataset. They are experimented with to predict the categories of respective test data. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Logistic Regression; Random Forest Classifier; Text Classification; TF-IDF Vectorizer},
	keywords = {Classification (of information); Information retrieval; Logistic regression; Machine learning; Random forests; Speech recognition; Statistical tests; Text processing; Logistics regressions; Machine learning models; Marathi languages; Random forest classifier; Speech content; Speech detection; Speech identification; Text classification; TF-IDF vectorizer; Vectorizer; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Parihar20211302,
	author = {Parihar, Anil Singh and Thapa, Surendrabikram and Mishra, Sushruti},
	title = {Hate Speech Detection Using Natural Language Processing: Applications and Challenges},
	year = {2021},
	journal = {Proceedings of the 5th International Conference on Trends in Electronics and Informatics, ICOEI 2021},
	pages = {1302 – 1308},
	doi = {10.1109/ICOEI51242.2021.9452882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113448674&doi=10.1109%2fICOEI51242.2021.9452882&partnerID=40&md5=275826c122bee792efd48f6977f82ee3},
	affiliations = {Machine Learning Research Lab, Delhi Technological University, Department of Cse, India; Delhi Technological University, Department of Software Engineering, India},
	abstract = {The internet has become a common platform for everyone to share their ideas and opinions. The user has freedom to post whatever he/she likes in social networking and blogging sites. However, sometimes the content when directed towards certain group of individuals with an intention to incite hate or discrimination, causes a turmoil in the society. Such content is known as hate speech. Hate speech can be a serious problem to peace and harmony in the society. There are instances where hate speech have led to social unrest and extremism. Thus, hate speech in the internet needs to be monitored. In this paper, we discuss the relevant works done in the field of hate speech detection. Different types of hate speech like racism, sexism, religious hate speech, etc. and the various methods proposed to tackle them are discussed. Further, we identify the challenges and propose the solutions to challenges in hate speech detection in the public internet sphere.  © 2021 IEEE.},
	author_keywords = {Deep Learning; Hate Speech; Machine Learning; Natural Language Processing; Racism; Sexism},
	keywords = {Natural language processing systems; Speech; Blogging; Common platform; Internet needs; NAtural language processing; Public internet; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; Conference name: 5th International Conference on Trends in Electronics and Informatics, ICOEI 2021; Conference date: 3 June 2021 through 5 June 2021; Conference code: 170931}
}

@CONFERENCE{Mahibha2021705,
	author = {Mahibha, C. Jerin and Kayalvizhi, Sampath and Thenmozhi, Durairaj and Arunima, Sundar},
	title = {Offensive Language Identification using Machine Learning and Deep Learning Techniques},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {705 – 713},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134227017&partnerID=40&md5=1bb28ae4a5a12acc4e8273f281dfde18},
	affiliations = {Meenakshi Sundararajan Engineering College, Chennai, India; Sri Sivasubramaniya Nadar College of Engineering, Kalavakkam, India},
	abstract = {Offensive Language is the use of abusive, rude or insulting language that upsets or embarrasses people towards whom it is been spoken. This paper aims to identify whether the given text is offensive or not using deep learning models. The proposed model uses a bidirectional dual-encoder with Additive Margin Softmax to perform the classification task. The performance of the model is also compared with a machine learning model and a recurrent model. When a cross lingual sentence embedding space transformer model was applied on the Tamil dataset provided by HASOC @ FIRE 2021 for Task 1, it was able to classify the offensive and non offensive data with a F1 score of 0.865 which brought our team to the top of the leaderboard score. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Classification; Code-mixed data; Deep Learning; Encoding; Offensive; Recurrent Network; Transformer},
	keywords = {Deep learning; Learning systems; Network coding; Code-mixed data; Deep learning; Encodings; Language identification; Machine-learning; Mixed data; Offensive; Offensive languages; Recurrent networks; Transformer; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Ranasinghe2022,
	author = {Ranasinghe, Tharindu and Zampieri, Marcos},
	title = {Multilingual Offensive Language Identification for Low-resource Languages},
	year = {2022},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {21},
	number = {1},
	doi = {10.1145/3457610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124261725&doi=10.1145%2f3457610&partnerID=40&md5=7cf2c1d828c3b14c5458b9563f0bf82f},
	affiliations = {University of Wolverhampton, Wulfruna Street, Wolverhampton, WV1 1LY, United Kingdom; Rochester Institute of Technology, 92 Lomb Memorial Drive, Rochester, 14620, NY, United States},
	abstract = {Offensive content is pervasive in social media and a reason for concern to companies and government organizations. Several studies have been recently published investigating methods to detect the various forms of such content (e.g., hate speech, cyberbullying, and cyberaggression). The clear majority of these studies deal with English partially because most annotated datasets available contain English data. In this article, we take advantage of available English datasets by applying cross-lingual contextual word embeddings and transfer learning to make predictions in low-resource languages. We project predictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi, Spanish, and Turkish. We report results of 0.8415 F1 macro for Bengali in TRAC-2 shared task [23], 0.8532 F1 macro for Danish and 0.8701 F1 macro for Greek in OffensEval 2020 [58], 0.8568 F1 macro for Hindi in HASOC 2019 shared task [27], and 0.7513 F1 macro for Spanish in in SemEval-2019 Task 5 (HatEval) [7], showing that our approach compares favorably to the best systems submitted to recent shared tasks on these three languages. Additionally, we report competitive performance on Arabic and Turkish using the training and development sets of OffensEval 2020 shared task. The results for all languages confirm the robustness of cross-lingual contextual embeddings and transfer learning for this task.  © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {cross-lingual embeddings; low-resource languages; Offensive language identification},
	keywords = {Computer crime; Natural language processing systems; Bengalis; Cross-lingual; Cross-lingual embedding; Embeddings; Language identification; Low resource languages; Offensive language identification; Offensive languages; Transfer learning; Turkishs; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Green Open Access}
}

@ARTICLE{Cécillon2021,
	author = {Cécillon, Noé and Labatut, Vincent and Dufour, Richard and Linarès, Georges},
	title = {Graph Embeddings for Abusive Language Detection},
	year = {2021},
	journal = {SN Computer Science},
	volume = {2},
	number = {1},
	doi = {10.1007/s42979-020-00413-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106077400&doi=10.1007%2fs42979-020-00413-7&partnerID=40&md5=950017e68aed3aa18b90fcb3cb9c873b},
	affiliations = {Laboratoire Informatique d’Avignon-LIA EA 4128, Avignon Université, Avignon, France},
	abstract = {Abusive behaviors are common on online social networks. The increasing frequency of anti-social behaviors forces the hosts of online platforms to find new solutions to address this problem. Automating the moderation process has thus received a lot of interest in the past few years. Various methods have been proposed, most based on the exchanged content, and one relying on the structure and dynamics of the conversation. It has the advantage of being language-independent, however it leverages a hand-crafted set of topological measures which are computationally expensive and not necessarily suitable to all situations. In the present paper, we propose to use recent graph embedding approaches to automatically learn representations of conversational graphs depicting message exchanges. We compare two categories: node vs. whole-graph embeddings. We experiment with a total of 8 approaches and apply them to a dataset of online messages. We also study more precisely which aspects of the graph structure are leveraged by each approach. Our study shows that the representation produced by certain embeddings captures the information conveyed by specific topological measures, but misses out other aspects. © 2021, Springer Nature Singapore Pte Ltd.},
	author_keywords = {Automatic abuse detection; Conversational graph; Graph embedding; Online conversations; Social networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Sharma2021,
	author = {Sharma, Mayukh and Kandasamy, Ilanthenral and Kandasamy, Vasantha},
	title = {Deep Learning for predicting neutralities in Offensive Language Identification Dataset[Formula presented]},
	year = {2021},
	journal = {Expert Systems with Applications},
	volume = {185},
	doi = {10.1016/j.eswa.2021.115458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111953518&doi=10.1016%2fj.eswa.2021.115458&partnerID=40&md5=9839a13a11a45c78e99f033d78c8fed0},
	affiliations = {School of Computer Science and Engineering, VIT, Vellore, 632014, Tamil Nadu, India},
	abstract = {Deep learning is advancing rapidly; it has aided in solving problems that were thought impossible. Natural language understanding is one such task that has evolved with the advancement of deep learning systems. There have been several sentiment analysis attempts, but they aim to classify it as a single emotion. Human emotion in natural language is generally a complex combination of emotions, which may be indeterminate or neutral at times. Neutrosophy is a branch of philosophy that identifies neutralities and uses membership functions (positive, negative, neutral) to quantify a sample into Single Valued Neutrosophic Set (SVNS) values. Our work aims to combine the power of deep learning with SVNS to represent a sample's sentiment into membership functions of SVNS. We have worked on the Offensive Language Identification Dataset (OLID). Combining the power of state-of-the-art neural network techniques with neutrosophy allowed us to quantify the sentiments and identify the transition phase between positive and negative ones. We used the transition phase to capture neutral samples, which is beneficial if we want to obtain purely positive/negative samples. We performed experiments using Bi-directional Long Short Term Memory (BiLSTM) with attention, Bidirectional Encoder Representations from Transformers (BERT), A Lite BERT (ALBERT), A Robustly Optimised BERT Approach (RoBERTa), and MPNet. Our SVNS model performed equivalent to state-of-the-art neural network models on the OLID dataset. Here, we propose a novel framework that can integrate with any neural network model and quantify sentiments using SVNS. © 2021 Elsevier Ltd},
	author_keywords = {ALBERT; BERT; BiLSTM; MPNet; Neutrosophy; OLID; RoBERTa; Sentiment analysis; SVNS},
	keywords = {Deep learning; Membership functions; Neural networks; A lite BERT; Bi-directional long short term memory; Bidirectional encoder representation from transformer; MPNet; Neutrosophic sets; Neutrosophy; Offensive language identification dataset; Robustly optimized BERT approach; Sentiment analysis; Single valued neutrosophic set; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Malik20211254,
	author = {Malik, Pranav and Aggrawal, Aditi and Vishwakarma, Dinesh K.},
	title = {Toxic Speech Detection using Traditional Machine Learning Models and BERT and fastText Embedding with Deep Neural Networks},
	year = {2021},
	journal = {Proceedings - 5th International Conference on Computing Methodologies and Communication, ICCMC 2021},
	pages = {1254 – 1259},
	doi = {10.1109/ICCMC51019.2021.9418395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106019234&doi=10.1109%2fICCMC51019.2021.9418395&partnerID=40&md5=03186c81b925fcb5901b99d7461ee42d},
	affiliations = {Delhi Technological University, Department of Information Technology, Delhi, India},
	abstract = {The introduction of social media brought about a revolution in the world of digitalization and communication. These platforms were initially developed with a purpose of connecting people across the global boundaries while allowing them to express their views and opinions and learn from others' ideas. With the incoming of the pandemic, the usage of these sites has risen significantly be it by the businesses, educational institutions, students or general public. The increasing ubiquity of social media platforms like Twitter and Facebook has been an issue of major concern since a long time. Along with providing a way for enhanced communication, these platforms also allow internet users to voice their opinions which get circulated among the masses within seconds. Moreover, given the different backgrounds, believes, ethnicity and cultures that the users on these platforms come from, many of them tend to use mean, aggressive and hateful content during their discussions with people not hailing from a background similar to theirs. The amount of hate speech and offensive content has been increasing exponentially. Terms like "profane", "hate", and "offensive"are used interchangeably, and hence these have been classified under a broader category of "Toxic"content. A major part of our dataset focuses on conversations prevailing among the youth. After the preprocessing of this dataset using NLP and embeddings (Bert and fastText), a bunch of Machine Learning (LR, SVM, DT, RF, XGBoost) and Deep Learning algorithms (CNN, MLP, LSTM) have been performed, with CNN giving the best results. © 2021 IEEE.},
	author_keywords = {classification; deep learning; facebook; hate speech; natural language processing; offensive; toxic; twitter},
	keywords = {Deep neural networks; Embeddings; Learning algorithms; Learning systems; Long short-term memory; Social networking (online); Support vector machines; Educational institutions; Facebook; General publics; Internet users; Machine learning models; Social media; Social media platforms; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; Conference name: 5th International Conference on Computing Methodologies and Communication, ICCMC 2021; Conference date: 8 April 2021 through 10 April 2021; Conference code: 168766}
}

@CONFERENCE{Kannan2021209,
	author = {Kannan, Sudharsana and Mitrović, Jelena},
	title = {Hatespeech and Offensive Content Detection in Hindi Language using C-BiGRU},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {209 – 216},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134258283&partnerID=40&md5=8ef352ada23a7a8b67fc701e1f1fa394},
	affiliations = {Faculty of Computer Science and Mathematics, CAROLL Research Group, University of Passau, Germany},
	abstract = {In this paper, we present our submission from the team CAROLL_Passau for subtask 1A of the HASOC 2021 workshop. Our presented model, C-BiGRU, is composed of a Convolutional Neural Network (CNN) together with a bidirectional Recurrent Neural Network (RNN). We utilized word embeddings to allow our model to apprehend the correlation between words in the text. The structure of our model enables it to capture the contextual information along with the long-term dependencies in the text in order to perform binary classification on offensive text. We evaluated our model on the test data provided by the HASOC organizers. Our model achieved a macro F1 score of 75.04%, accuracy of 77.48%, precision and recall with the scores of 74.63% and 75.60% respectively. © 2021 Copyright for this paper by its authors.},
	author_keywords = {C-BiGRU; Embeddings; Hate speech; Hindi; Offensive language},
	keywords = {C (programming language); Classification (of information); Convolutional neural networks; Recurrent neural networks; Text processing; Bidirectional recurrent neural networks; C-BiGRU; Content detection; Contextual information; Convolutional neural network; Embeddings; Hate speech; Hindi; Offensive languages; Subtask; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Kompally2021,
	author = {Kompally, Pranav and Sethuraman, Sibi Chakkaravarthy and Walczak, Steven and Johnson, Samuel and Cruz, Meenalosini Vimal},
	title = {Malang: A decentralized deep learning approach for detecting abusive textual content},
	year = {2021},
	journal = {Applied Sciences (Switzerland)},
	volume = {11},
	number = {18},
	doi = {10.3390/app11188701},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115293019&doi=10.3390%2fapp11188701&partnerID=40&md5=8dca9a3f3609027e35cf77f73695a795},
	affiliations = {School of Computer Science and Engineering & Artificial Intelligence and Robotics Research Center, VIT-AP University, Amaravati, Andhra Pradesh, 522237, India; School of Information & Florida Center for Cybersecurity, University of South Florida, Tampa, 33620, FL, United States; School of Business, VIT-AP University, Amaravati, Andhra Pradesh, 522237, India; Department of Information Technology, Georgia Southern University, Statesboro, 30458, GA, United States},
	abstract = {Cyberbullying is a growing and significant problem in today’s workplace. Existing automated cyberbullying detection solutions rely on machine learning and deep learning techniques. It is proven that the deep learning-based approaches produce better accuracy for text-based classification than other existing approaches. A novel decentralized deep learning approach called MaLang is developed to detect abusive textual content. MaLang is deployed at two levels in a network: (1) the System Level and (2) the Cloud Level, to tackle the usage of toxic or abusive content on any messaging application within a company’s networks. The system-level module consists of a simple deep learning model called CASE that reads the user’s messaging data and classifies them into abusive and non-abusive categories, without sending any raw or readable data to the cloud. Identified abusive messages are sent to the cloud module with a unique identifier to keep user profiles hidden. The cloud module, called KIPP, utilizes deep learning to determine the probability of a message containing different categories of toxic content, such as: ‘Toxic’, ‘Insult’, ‘Threat’, or ‘Hate Speech’. MaLang achieves a 98.2% classification accuracy that outperforms other current cyberbullying detection systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Abusive text; Cyber-harassment; Cyberbullying; Decentralization; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{Kumar2021,
	author = {Kumar, Ashwini and Tyagi, Vishu and Das, Sanjoy},
	title = {Deep Learning for Hate Speech Detection in social media},
	year = {2021},
	journal = {2021 IEEE 4th International Conference on Computing, Power and Communication Technologies, GUCON 2021},
	doi = {10.1109/GUCON50781.2021.9573687},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119092192&doi=10.1109%2fGUCON50781.2021.9573687&partnerID=40&md5=7a5f7fa141ce605e6d973b637c894323},
	affiliations = {Graphic Era Deemed to Be University, Department of CSE, Dehradun, India; Indira Gandhi National Tribal University, RCM, Department of Computer Science, Imphal, India},
	abstract = {In recent years, many people on the internet write and post abusive language on online social media platforms such as Twitter, Facebook, etc. Detection of hate speech is very difficult to solve manually, especially in social media. Thus, we need to be automatic detection of hate speech in social media. We have used a benchmark dataset of approximately 25 thousand annotated tweets and proposed a model based on deep learning methods. We also compare the performance of our deep learning methods to the traditional machine learning classifier in terms of F1 Score and Accuracy. The results obtained through the proposed method is very promising. © 2021 IEEE.},
	author_keywords = {Deep Learning; Hate Speech; Social Media; Twitter},
	keywords = {Deep learning; Speech recognition; Automatic Detection; Benchmark datasets; Deep learning; Facebook; Hate speech; Learning methods; Online social medias; Social media; Social media platforms; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th IEEE International Conference on Computing, Power and Communication Technologies, GUCON 2021; Conference date: 24 September 2021 through 26 September 2021; Conference code: 173402}
}

@CONFERENCE{Moon2021446,
	author = {Moon, Jihye and Nguyen, Hieu and Pines, Bradshaw and Gokhale, Swapna S.},
	title = {Detecting offensive content on social media during anti-lockdown protests in Michigan},
	year = {2021},
	journal = {Proceedings - 2021 IEEE 45th Annual Computers, Software, and Applications Conference, COMPSAC 2021},
	pages = {446 – 451},
	doi = {10.1109/COMPSAC51774.2021.00068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115885787&doi=10.1109%2fCOMPSAC51774.2021.00068&partnerID=40&md5=7232928d2d5386b282386c547d959126},
	affiliations = {Dept. of Biomedical Engg, Univ. of Connecticut, Storrs, 06269, CT, United States; Dept. of Computer Science and Engg, Univ. of Connecticut, Storrs, 06269, CT, United States},
	abstract = {Hateful and offensive speech on online social media platforms has been exacerbated by the turbulent and chaotic circumstances brought on by the coronavirus pandemic. A particularly contentious issue was lockdown orders issued by state governments designed to keep citizens safe by controlling the spread of the virus. To compel the government to relax these orders and restore normalcy, anti-lockdown protests were organized in many states. The economic, ideological, political, and health concerns related to the lockdowns and the associated protests were debated vigorously on social media platforms, many times using offensive content. Detecting such insulting and humiliating content is especially important during tumultuous times, when tensions are high, because such expressions online can quickly precipitate violence in the physical world. This paper presents an approach to detect hateful and offensive content from Twitter feeds collected after anti-lockdown protests in Lansing, Michigan. These tweets were labeled using a comprehensive definition of what constitutes offensive content based on its potential to trigger and incite people. Linguistic and auxiliary features were extracted from these labeled tweets. These features were further processed through feature selection and dimensionality reduction techniques. The preprocessed feature set was used to train machine learning models, which detect offensive content with an accuracy of around 84%. Our approach demonstrates the feasibility of identifying and tagging offensive content in politically motivated situations, even when such speech is dominated by contextual and circumstantial information. It can thus be used to mitigate the damage caused by widespread dissemination of offensive content. © 2021 IEEE.},
	keywords = {Application programs; Dimensionality reduction; Social networking (online); Coronaviruses; Dimensionality reduction techniques; Health concerns; Machine learning models; Online social medias; Physical world; Social media platforms; State governments; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 45th IEEE Annual Computers, Software, and Applications Conference, COMPSAC 2021; Conference date: 12 July 2021 through 16 July 2021; Conference code: 171654}
}

@CONFERENCE{Kumar2021104,
	author = {Kumar, Ritesh and Gupta, Vishesh and Pamula, Rajendra},
	title = {Hate Speech and Offensive Content Identification in English Tweets},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {104 – 109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134273441&partnerID=40&md5=7211705a4ea89209ff39c004553ac465},
	affiliations = {Department of Computer Science and Engineering, National Institute of Technology, Jamshedpur, India; Department of Computer Science and Engineering, Indian Institute of Technology (Indian School of Mines), Dhanbad, India},
	abstract = {Hate speech is a prevalent practice that society has to struggle with everyday. The freedom of speech and ease of anonymity granted by social media has also resulted in incitement to hatred. This presents the need for automatic detection of hate speeches or tweets on social media. In this paper, we have presented the machine learning models that can detect hate Speech and offensive content. Specifically, we described the model submitted for the shared task on hate Speech and offensive content identification in English Tweets at HASOC 2021 and our team name is Vishesh Gupta.The problem concentrates on hate speech detection in English language. The challenge is divided into two tasks of different granularity: (1) coarse-grained binary classification in which participating system are required to classify tweets into two class, namely: Hate and Offensive (HOF) and Non-Hate and offensive (NOT). (2) to predict one of the three types of hate speeches present. Overall, our performance is good but it needs some improvement, our scores are encouraging enough to work for better results in future. © 2021 Copyright for this paper by its authors.},
	author_keywords = {GRU; Ktrain; Logistic regression; LSTM; Random Forest; TFIDF; XGBoost},
	keywords = {Long short-term memory; Random forests; Social networking (online); Speech recognition; Content identifications; Freedom of speech; GRU; Ktrain; Logistics regressions; LSTM; Random forests; Social media; TFIDF; Xgboost; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Suresh202158,
	author = {Suresh, Gautham Vadakkekara and Chakravarthi, Bharathi Raja and McCrae, John Philip},
	title = {Meta-Learning for Offensive Language Detection in Code-Mixed Texts},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {58 – 66},
	doi = {10.1145/3503162.3503167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124339638&doi=10.1145%2f3503162.3503167&partnerID=40&md5=a6f45ce3fbc1741967910517bfe17260},
	affiliations = {Insight SFI Research Centre for Data Analytics, National University of Ireland Galway, Ireland},
	abstract = {This research investigates the application of Model-Agnostic Meta-Learning (MAML) and ProtoMAML to identify offensive code-mixed text content on social media in Tamil-English and Malayalam-English code-mixed texts. We follow a two-step strategy: The XLM-RoBERTa (XLM-R) model is trained using the meta-learning algorithms on a variety of tasks having code-mixed data, monolingual data in the same language as the target language and related tasks in other languages. The model is then fine-tuned on target tasks to identify offensive language in Malayalam-English and Tamil-English code-mixed texts. Our results show that meta-learning improves the performance of models significantly in low-resource (few-shot learning) tasks1. We also introduce a weighted data sampling approach which helps the model converge better in the meta-training phase compared to traditional methods.  © 2021 ACM.},
	author_keywords = {Code-mixing; Deep Learning; Dravidian Languages; Malayalam; Meta Learning; Tamil},
	keywords = {Codes (symbols); Deep learning; Code-mixing; Deep learning; Dravidian language; Language detection; Malayalams; Metalearning; Offensive languages; Social media; Tamil; Text content; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 13th Annual Meeting of the Forum for Information Retrieval Evaluation, FIRE 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 176677; All Open Access, Bronze Open Access}
}

@ARTICLE{Shah2022265,
	author = {Shah, Vipul and Bhole, Amey and Udmale, Sandeep S. and Sambhe, Vijay},
	title = {A Deep Multi-kernel Uniform Capsule Approach for Hate Speech Detection},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13145 LNCS},
	pages = {265 – 271},
	doi = {10.1007/978-3-030-94876-4_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124274512&doi=10.1007%2f978-3-030-94876-4_19&partnerID=40&md5=e0cf9fed1eda403be8657a97db7ed25c},
	affiliations = {Department of Computer Engineering and Information Technology, Veermata Jijabai Technological Institute (VJTI), Maharashtra, Mumbai, 400019, India; Faculty of Science and Engineering, University of Groningen, Bernoulliborg, Nijenborgh 9, Groningen, 9747AG, Netherlands},
	abstract = {Hate Speech is an expression that expresses hatred towards people of a specific ethnic group or nationality and incites hatred. Even though many countries have anti-hate speech legislation, hate speech can spread in the native language on social media platforms, resulting in violent riots and protests that spiral out of control and result in anti-social events. Hence, hate speech has caused a crucial social issue. Thus, various intelligent mechanisms have been employed to classify hate speech, depending on the category. A deep learning model has certain limitations for providing n-gram features for text classification of the native language. As a result, in this paper, the Multi-kernel uniform capsule network for multilingual languages is proposed. The proposed method employs a Multi-kernel uniform capsule network to improve feature selection performance by utilizing the capsule network routing algorithm. The experiments were carried out on political, COVID-19 and vaccination, lockdown, and multilingual dataset. The experimental results demonstrate that the proposed methods achieve adequate results when compared with other machine learning models for hate speech detection. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Capsule network; COVID-19; Hate speech; Lockdown; Multilingual; US election; Vaccination},
	keywords = {Classification (of information); Deep learning; Locks (fasteners); Speech recognition; Text processing; Vaccines; Capsule network; COVID-19; Ethnic groups; Hate speech; Lockdown; Multi-kernel; Native language; Social media platforms; Speech detection; US election; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 18th International Conference on Distributed Computing and Intelligent Technology, ICDCIT 2022; Conference date: 19 January 2022 through 23 January 2022; Conference code: 271479}
}

@CONFERENCE{Deepakindresh2021396,
	author = {Deepakindresh, N. and Rohan, AviReddy and Ambalavanan, Aakash and Selvamani, B. Radhika},
	title = {Hate Speech Detection using LIME guided Ensemble Method and DistilBERT},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {396 – 411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134256483&partnerID=40&md5=48d620071c799dc34afff0e11a0bbe29},
	affiliations = {Vellore Institute of Technology, Chennai, India; Center for Advanced Data Science, Vellore Institute of Technology, Chennai, India},
	abstract = {Hate Speech classification has crucial applications in the social media domain. We describe the performance of our classifiers in the Hate Speech and Offensive Content Identification Track (HASOC) of FIRE 2021 conference. The dataset provided is for Indo-European Languages. We chose English tweets and developed two main classifiers as part of HASOC Track 1, which had two Subtasks 1A and 1B. Subtask 1A is a binary Hate Speech identification task, and Subtask 1B is multi grained classification of hate, profane, offensive and neutral content. Our team”Beware Haters” studied Support Vector Machine, Random Forest, Logistic Regression, Bidirectional Long Short Term Memory Model and an Ensemble of the listed models for the Subtask 1A and the highest Macro F1 score we achieved was 0.7722 by our Ensemble model which combined the advantages of SVM, Logistic Regression and Random Forest. We used a model interpretation tool LIME, before integrating the models in a weighted Ensemble approach. For Subtask 1B, we obtained better results using a DistilBERT model that achieved a Macro F1 score of 0.6311. We have compared the performance of the basic DistilBERT Model with a fine tuned version. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT; DistilBERT; Ensemble; Hate Speech Identification; LIME; Logistic Regression; LSTM; Random Forest; SVM; TF-IDF},
	keywords = {Decision trees; Fires; Logistic regression; Long short-term memory; Random forests; Speech recognition; Support vector machines; BERT; Distilbert; Ensemble; Hate speech identification; Logistics regressions; LSTM; Random forests; Speech identification; SVM; TF-IDF; Lime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Benhur2021659,
	author = {Benhur, Sean and Sivanraju, Kanchana},
	title = {Pretrained Transformers for Offensive Language Identification in Tanglish},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {659 – 666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134255310&partnerID=40&md5=04901c9a71cd6b4eab074e9164c2e80a},
	affiliations = {PSG College of Arts and Science, Civil Aerodrome Post, Coimbatore, India},
	abstract = {This paper describes the system submitted to Dravidian-Codemix-HASOC2021: Hate Speech and Offensive Language Identification in Dravidian Languages (Tamil-English and Malayalam-English). This task aims to identify offensive content in code-mixed comments/posts in Dravidian Languages collected from social media. Our approach utilizes pooling the last layers of pretrained transformer multilingual BERT for this task which helped us achieve rank nine on the leaderboard with a weighted average score of 0.61 for the Tamil-English dataset in subtask B. After the task deadline, we sampled the dataset uniformly and used the MuRIL pretrained model, which helped us achieve a weighted average score of 0.67, the top score in the leaderboard. Furthermore, our approach to utilizing the pretrained models helps reuse our models for the same task with a different dataset. Our code and models are available in GitHub. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT; Hate Speech; Offensive Content; Transformer},
	keywords = {Computational linguistics; Learning algorithms; Statistical methods; BERT; Hate speech; Language identification; Malayalams; Offensive content; Offensive languages; Social media; Subtask; Transformer; Weighted averages; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Bhimani2021,
	author = {Bhimani, Darsh and Bheda, Rutvi and Dharamshi, Femin and Nikumbh, Deepti and Abhyankar, Priyanka},
	title = {Identification of Hate Speech using Natural Language Processing and Machine Learning},
	year = {2021},
	journal = {2021 2nd Global Conference for Advancement in Technology, GCAT 2021},
	doi = {10.1109/GCAT52182.2021.9587652},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119474705&doi=10.1109%2fGCAT52182.2021.9587652&partnerID=40&md5=41ca484e657bb26f07a7a21622b9ee9a},
	affiliations = {Shah and Anchor Kutchhi Engineering College, Computer Engineering, Mumbai, India; Shah and Anchor Kutchhi Engineering College, Mumbai, India},
	abstract = {From the past decade, social media has gained a lot of momentum both in a positive way as well as in a negative way. With this rapid increase of networking through social platforms and websites, people are able to communicate with each other directly with no cultural or economic gap. While there have been many benefits of social media but there are no less negative impacts on the society. One such problem that has arised since the past few years is the hate speech. Hate speech is basically the use of offensive and hostile language happening on the social media. It may refer to any individual or a certain group of people with the same interests. In this paper, we have introduced our way of dealing with this hate speech and minimizing it to a large extent. People convey their hatred and anger straightaway on social media which would hurt the feelings of other people. It would affect their caste, creed, religion, race and would have a very negative impact on them. Some comments might not be intentional to anyone but would be counted as hate speech due the foul language used. We have dived deep into natural language processing to eliminate hate speech and used various machine learning models to decide which one to use as per its accuracy. © 2021 IEEE.},
	author_keywords = {Hate Speech; Machine Learning; Natural Language Processing; Social Media},
	keywords = {Learning algorithms; Machine learning; Social networking (online); Speech; Hate speech; Machine learning models; Machine-learning; Social media; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2nd Global Conference for Advancement in Technology, GCAT 2021; Conference date: 1 October 2021 through 3 October 2021; Conference code: 173912}
}

@ARTICLE{Canossa2021,
	author = {Canossa, Alessandro and Salimov, Dmitry and Azadvar, Ahmad and Harteveld, Casper and Yannakakis, Georgios},
	title = {For Honor, for Toxicity: Detecting Toxic Behavior through Gameplay},
	year = {2021},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {5},
	number = {CHIPLAY},
	doi = {10.1145/3474680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117078671&doi=10.1145%2f3474680&partnerID=40&md5=844880e409c48ea212f6b9cb9cf9d454},
	affiliations = {The Royal Danish Academy, Copenhagen, Denmark; Ubisoft Blue Byte, Düsseldorf, Germany; A Ubisoft Studio, Malmo, Sweden; Northeastern University, Boston, MA, United States; University of Malta, Msida, Malta},
	abstract = {Is it possible to detect toxicity in games just by observing in-game behavior? If so, what are the behavioral factors that will help machine learning to discover the unknown relationship between gameplay and toxic behavior? In this initial study, we examine whether it is possible to predict toxicity in the MOBA gameFor Honor by observing in-game behavior for players that have been labeled as toxic (i.e. players that have been sanctioned by Ubisoft community managers). We test our hypothesis of detecting toxicity through gameplay with a dataset of almost 1,800 sanctioned players, and comparing these sanctioned players with unsanctioned players. Sanctioned players are defined by their toxic action type (offensive behavior vs. unfair advantage) and degree of severity (warned vs. banned). Our findings, based on supervised learning with random forests, suggest that it is not only possible to behaviorally distinguish sanctioned from unsanctioned players based on selected features of gameplay; it is also possible to predict both the sanction severity (warned vs. banned) and the sanction type (offensive behavior vs. unfair advantage). In particular, all random forest models predict toxicity, its severity, and type, with an accuracy of at least 82%, on average, on unseen players. This research shows that observing in-game behavior can support the work of community managers in moderating and possibly containing the burden of toxic behavior.  © 2021 ACM.},
	author_keywords = {labeled dataset; machine learning; random forest; toxicity; video games},
	keywords = {Decision trees; Forecasting; Human computer interaction; Interactive computer graphics; Managers; Statistical tests; Behavioral factors; Gameplay; Labeled dataset; Random forest modeling; Random forests; Toxic action; Ubisoft; Video-games; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@CONFERENCE{Nene2021273,
	author = {Nene, Mayuresh and North, Kai and Ranasinghe, Tharindu and Zampieri, Marcos},
	title = {Transformer Models for Offensive Language Identification in Marathi},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {273 – 282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134261032&partnerID=40&md5=49ca6ed1af1c9bb17933eca60a104d07},
	affiliations = {Rochester Institute of Technology, United States; University of Wolverhampton, United Kingdom},
	abstract = {This paper describes the WLV-RIT entry to the Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC) shared task of 2021. The HASOC 2021 organizers provided participants with annotated datasets containing social media posts of English, Hindi and Marathi. We participated in Marathi Subtask 1A: identifying hateful, offensive and profane content. In our methodology, we take advantage of available data from high resource languages by applying cross-lingual transformer-based models and transfer learning to make predictions to Marathi data. Our system achieved a macro F1 score of 0.91 for the test set and it ranked 1st place out of 25 systems. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Marathi; offensive language identification; transformers},
	keywords = {Computational linguistics; Machine learning; Annotated datasets; Content identifications; Language identification; Marathi; Offensive language identification; Offensive languages; Social media; Subtask; Transformer; Transformer modeling; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Beddiar2021,
	author = {Beddiar, Djamila Romaissa and Jahan, Md Saroar and Oussalah, Mourad},
	title = {Data expansion using back translation and paraphrasing for hate speech detection},
	year = {2021},
	journal = {Online Social Networks and Media},
	volume = {24},
	doi = {10.1016/j.osnem.2021.100153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108402271&doi=10.1016%2fj.osnem.2021.100153&partnerID=40&md5=2d0c48d617876647d0f58553ff1e03f6},
	affiliations = {Center for Machine Vision and Signal Analysis, University of Oulu, Finland},
	abstract = {With proliferation of user generated contents in social media platforms, establishing mechanisms to automatically identify toxic and abusive content becomes a prime concern for regulators, researchers, and society. Keeping the balance between freedom of speech and respecting each other dignity is a major concern of social media platform regulators. Although, automatic detection of offensive content using deep learning approaches seems to provide encouraging results, training deep learning-based models requires large amounts of high-quality labeled data, which is often missing. In this regard, we present in this paper a new deep learning-based method that fuses a Back Translation method, and a Paraphrasing technique for data augmentation. Our pipeline investigates different word-embedding-based architectures for classification of hate speech. The back translation technique relies on an encoder–decoder architecture pre-trained on a large corpus and mostly used for machine translation. In addition, paraphrasing exploits the transformer model and the mixture of experts to generate diverse paraphrases. Finally, LSTM, and CNN are compared to seek enhanced classification results. We evaluate our proposal on five publicly available datasets; namely, AskFm corpus, Formspring dataset, Warner and Waseem dataset, Olid, and Wikipedia toxic comments dataset. The performance of the proposal together with comparison to some related state-of-art results demonstrate the effectiveness and soundness of our proposal. © 2021 The Authors},
	author_keywords = {Back translation; Cyberbullying detection; Encoder–decoder; Hate speech; NLP transformers; Paraphrasing},
	keywords = {Computer aided language translation; Deep learning; Learning systems; Social networking (online); Classification results; Decoder architecture; Learning Based Models; Learning-based methods; Machine translations; Social media platforms; Transformer modeling; User-generated content; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 67; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Jiang2021217,
	author = {Jiang, Aiqi and Zubiaga, Arkaitz},
	title = {Cross-lingual Capsule Network for Hate Speech Detection in Social Media},
	year = {2021},
	journal = {HT 2021 - Proceedings of the 32nd ACM Conference on Hypertext and Social Media},
	pages = {217 – 223},
	doi = {10.1145/3465336.3475102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114800198&doi=10.1145%2f3465336.3475102&partnerID=40&md5=30873492989840fe44bbe707fefb65b7},
	affiliations = {Queen Mary University of London, London, United Kingdom},
	abstract = {Most hate speech detection research focuses on a single language, generally English, which limits their generalisability to other languages. In this paper we investigate the cross-lingual hate speech detection task, tackling the problem by adapting the hate speech resources from one language to another. We propose a cross-lingual capsule network learning model coupled with extra domain-specific lexical semantics for hate speech (CCNL-Ex). Our model achieves state-of-The-Art performance on benchmark datasets from AMI@Evalita2018 and AMI@Ibereval2018 involving three languages: English, Spanish and Italian, outperforming state-of-The-Art baselines on all six language pairs.  © 2021 ACM.},
	author_keywords = {capsule network; cross-lingual learning; hate speech detection; social media},
	keywords = {Benchmarking; Hypertext systems; Semantics; Social networking (online); Speech; Benchmark datasets; Domain specific; Lexical semantics; Network learning; Speech detection; Speech resources; State of the art; State-of-the-art performance; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 32nd ACM Conference on Hypertext and Social Media, HT 2021; Conference date: 30 August 2021 through 2 September 2021; Conference code: 171621; All Open Access, Green Open Access}
}

@ARTICLE{Perifanos2021,
	author = {Perifanos, Konstantinos and Goutsos, Dionysis},
	title = {Multimodal hate speech detection in greek social media},
	year = {2021},
	journal = {Multimodal Technologies and Interaction},
	volume = {5},
	number = {7},
	doi = {10.3390/mti5070034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109262735&doi=10.3390%2fmti5070034&partnerID=40&md5=755b5cdf46ddbdb1aba1e4d9e161d7f8},
	affiliations = {National and Kapodistrian, University of Athens, Athens, 10679, Greece},
	abstract = {Hateful and abusive speech presents a major challenge for all online social media platforms. Recent advances in Natural Language Processing and Natural Language Understanding allow for more accurate detection of hate speech in textual streams. This study presents a new multimodal approach to hate speech detection by combining Computer Vision and Natural Language processing models for abusive context detection. Our study focuses on Twitter messages and, more specifically, on hateful, xenophobic, and racist speech in Greek aimed at refugees and migrants. In our approach, we combine transfer learning and fine-tuning of Bidirectional Encoder Representations from Transformers (BERT) and Residual Neural Networks (Resnet). Our contribution includes the development of a new dataset for hate speech classification, consisting of tweet IDs, along with the code to obtain their visual appearance, as they would have been rendered in a web browser. We have also released a pre-trained Language Model trained on Greek tweets, which has been used in our experiments. We report a consistently high level of accuracy (accuracy score = 0.970, f1-score = 0.947 in our best model) in racist and xenophobic speech detection. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Deep learning; Hate speech; Multimodal machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Gold Open Access}
}

@CONFERENCE{Maity2021182,
	author = {Maity, Krishanu and Kumar, Abhishek and Saha, Sriparna},
	title = {Attention Based BERT-FastText model for Hate Speech and Offensive Content Identification in English and Hindi Languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {182 – 190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134253723&partnerID=40&md5=fe7b8dbae3324de1d02b838118805fd4},
	affiliations = {Indian Institute of Technology, Patna, India},
	abstract = {This paper describes our model submitted for HASOC-2021 as the IIT_Patna team for hate and offensive content identification in English and Hindi languages. A deep learning model, namely BERT+FastTextGRU, has been developed based on BERT and FastText, followed by GRU with attention. Our proposed model uses a BiGRU-based deep neural network to extract textual features, followed by an Attention layer to focus on the most important phrase of the text. The BERT language model and FastText embedding have been employed to examine the effectiveness of joint embedding representation compared to a single one. We have set up some baselines by varying the RNN architecture (LSTM/GRU) and the word vector representation approach (BERT/FastText). Our model outperforms all the baselines with the highest accuracy values of 76.32% for subtask-1A (EN), 56.73% for subtask-1B (EN), 69.17% for subtask-1A (HI) and 40.45% for subtask-1B (HI). © 2021 Copyright for this paper by its authors.},
	author_keywords = {Attention; BERT; FastText; Hate Speech; Offensive Content},
	keywords = {Computational linguistics; Deep neural networks; Information retrieval; Long short-term memory; Multilayer neural networks; Attention; BERT; Content identifications; Embeddings; Fasttext; Hate speech; Learning models; Model use; Offensive content; Subtask; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Priya2021636,
	author = {Priya, Anu and Kumar, Abhinav},
	title = {Hate and Offensive content identification from Dravidian social media posts: A deep learning approach},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {636 – 642},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134231776&partnerID=40&md5=75c712bdf0b5267947a7477ae49f812b},
	affiliations = {Central University of Punjab, Punjab, Bathinda, India; Department of Computer Science & Engineering, Siksha ’O’ Anusandhan Deemed to be University, Bhubaneswar, India},
	abstract = {Identifying hate and offensive content in social media posts is one of the most challenging tasks for Natural Language Processing. The usage of non-standard acronyms, misspellings, poor grammar, and multilingualism in social media posts makes detecting hate and offensive language much more difficult. This work proposes a deep neural network-based model for the identification of offensive social media posts from Tamil script-mixed, Tamil code-mixed, and Malayalam code-mixed messages. The combination of one to six-gram character-level Term-Frequency Inverse Document Frequency (TF-IDF) features with a four-layered deep neural network model performed better than the other combinations of character-level n-gram TF-IDF features. For Tamil script-mixed, Tamil code-mixed, and Malayalam code-mixed social media postings, the suggested model attained weighted F1-scores of 0.84, 0.65, and 0.71, respectively. The code for the proposed models is available at https://github.com/Abhinavkmr/Hate-Speech-Identification-Dravidian-Language.git. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Deep learning; Hate speech; Offensive language; Social media},
	keywords = {Codes (symbols); Computational linguistics; Deep neural networks; Multilayer neural networks; Natural language processing systems; Network coding; Network layers; Social networking (online); Text processing; Character level; Content identifications; Deep learning; Frequency features; Hate speech; Learning approach; Malayalams; Offensive languages; Social media; Term frequencyinverse document frequency (TF-IDF); Neural network models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Khan2021,
	author = {Khan, Muhammad Moin and Shahzad, Khurram and Malik, Muhammad Kamran},
	title = {Hate Speech Detection in Roman Urdu},
	year = {2021},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {20},
	number = {1},
	doi = {10.1145/3414524},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104203945&doi=10.1145%2f3414524&partnerID=40&md5=a20133c96e6eb223947a3be0e6f340a9},
	affiliations = {Punjab University College of Information Technology, University of the Punjab, Lahore, Pakistan},
	abstract = {Hate speech is a specific type of controversial content that is widely legislated as a crime that must be identified and blocked. However, due to the sheer volume and velocity of the Twitter data stream, hate speech detection cannot be performed manually. To address this issue, several studies have been conducted for hate speech detection in European languages, whereas little attention has been paid to low-resource South Asian languages, making the social media vulnerable for millions of users. In particular, to the best of our knowledge, no study has been conducted for hate speech detection in Roman Urdu text, which is widely used in the sub-continent. In this study, we have scrapped more than 90,000 tweets and manually parsed them to identify 5,000 Roman Urdu tweets. Subsequently, we have employed an iterative approach to develop guidelines and used them for generating the Hate Speech Roman Urdu 2020 corpus. The tweets in the this corpus are classified at three levels: Neutral-Hostile, Simple-Complex, and Offensive-Hate speech. As another contribution, we have used five supervised learning techniques, including a deep learning technique, to evaluate and compare their effectiveness for hate speech detection. The results show that Logistic Regression outperformed all other techniques, including deep learning techniques for the two levels of classification, by achieved an F1 score of 0.906 for distinguishing between Neutral-Hostile tweets, and 0.756 for distinguishing between Offensive-Hate speech tweets. © 2021 ACM.},
	author_keywords = {Hate speech detection; Low-resource languages; Roman Urdu; South Asian Languages},
	keywords = {Data streams; Deep learning; Iterative methods; Learning systems; Logistic regression; Social networking (online); Speech; Supervised learning; European languages; F1 scores; Iterative approach; Learning techniques; Social media; South Asian languages; Speech detection; Sub-continents; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44; All Open Access, Green Open Access}
}

@ARTICLE{Boulouard2022147,
	author = {Boulouard, Zakaria and Ouaissa, Mariya and Ouaissa, Mariyam},
	title = {Machine Learning for Hate Speech Detection in Arabic Social Media},
	year = {2022},
	journal = {EAI/Springer Innovations in Communication and Computing},
	pages = {147 – 162},
	doi = {10.1007/978-3-030-77185-0_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125896502&doi=10.1007%2f978-3-030-77185-0_10&partnerID=40&md5=9fdad8d7cf2a062ec211684a47dd39a7},
	affiliations = {Faculty of Sciences and Techniques Mohammedia, Hassan II University, Casablanca, Morocco; Moulay Ismail University, Meknes, Morocco},
	abstract = {(WARNING: This paper may contain some offensive words) Over the past few years, abusive language and cyberbullying have known a great increase on social media in general. This phenomenon has encouraged efforts to propose solutions able to detect and prohibit such behavior. Most of these solutions are dedicated to English, but the ones that can handle Arabic are, to the best of our knowledge, rare. Many reasons lie behind this situation including the informality and ambiguity of the Arabic dialects, as well as the use of Arabic/Arabizi combinations. In this paper, we will use a collection of Arabic YouTube comments that are annotated as either “hateful” or “inoffensive” to compare the ability of five machine learning algorithms to perform correct classification on hateful Arabic comments. The algorithms are Logistic Regression, Naïve Bayes, Random Forests, Support Vector Machines, and Long Short-Term Memory. The performance metrics are Accuracy, F1-Score, Precision, and Recall. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Accuracy; Artificial Intelligence; F1-Score; Hate speech detection; Logistic Regression; Long Short-Term Memory; Machine learning; Natural Language Processing; Naïve Bayes; Precision; Random Forests; Recall; Social media; Support Vector Machines},
	keywords = {Brain; Decision trees; Long short-term memory; Natural language processing systems; Random forests; Regression analysis; Speech recognition; Support vector machines; Accuracy; F1 scores; Hate speech detection; Logistics regressions; Naive bayes; Precision; Random forests; Recall; Social media; Speech detection; Support vectors machine; Social networking (online)},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Nagar20223,
	author = {Nagar, Seema and Gupta, Sameer and Bahushruth, C.S. and Barbhuiya, Ferdous Ahmed and Dey, Kuntal},
	title = {Hate Speech Detection on Social Media Using Graph Convolutional Networks},
	year = {2022},
	journal = {Studies in Computational Intelligence},
	volume = {1016},
	pages = {3 – 14},
	doi = {10.1007/978-3-030-93413-2_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122525056&doi=10.1007%2f978-3-030-93413-2_1&partnerID=40&md5=b84d67f67fe9ebabbb2aedd1165098f4},
	affiliations = {Institute of Information Technology, Guwahati, Guwahati, India; National Institute of Technology, Kurukshetra, Kurukshetra, India; Manipal University, Jaipur, India},
	abstract = {Detection of hateful content on Twitter has become the need of the hour. Hate detection is challenging primarily due to the subjective definition of “hateful”. In the absence of context, text content alone is often not sufficient to detect hate. In this paper, we propose a framework that combines content with context, to detect hate. The framework takes into account (a) textual features of the content and (b) unified features of the author to detect hateful content. We use a Variational Graph Auto-encoder (VGAE) to jointly learn the unified features of authors using a social network, content produced by the authors, and their profile information. To accommodate emerging and future language models, we develop a flexible framework that incorporates any text encoder as a plug-in to obtain the textual features of the content. We empirically demonstrate the performance and utility of the framework on two diverse datasets from Twitter. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Graph convolutional network; Hate speech detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 10th International Conference on Complex Networks and Their Applications, COMPLEX NETWORKS 2021; Conference date: 30 November 2021 through 2 December 2021; Conference code: 270439}
}

@ARTICLE{Mohapatra2021,
	author = {Mohapatra, Sudhir Kumar and Prasad, Srinivas and Bebarta, Dwiti Krishna and Das, Tapan Kumar and Srinivasan, Kathiravan and Hu, Yuh-Chung},
	title = {Automatic hate speech detection in english-odia code mixed social media data using machine learning techniques},
	year = {2021},
	journal = {Applied Sciences (Switzerland)},
	volume = {11},
	number = {18},
	doi = {10.3390/app11188575},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115204765&doi=10.3390%2fapp11188575&partnerID=40&md5=6bb13ebb7a58066c41cd5df79075a555},
	affiliations = {Faculty of Emerging Technologies, Sri Sri University, Cuttack, 754006, India; Department of Computer Science and Engineering, GITAM University, Visakhapatnam, 530045, India; Department of Information Technology, Gayatri Vidya Parishad College of Engineering for Women, Vishakhapatnam, 530048, India; School of Information Technology and Engineering, Vellore Institute of Technology, Vellore, 632014, India; School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, 632014, India; Department of Mechanical and Electromechanical Engineering, National Ilan University, Yilan, 26047, Taiwan},
	abstract = {Hate speech on social media may spread quickly through online users and subsequently, may even escalate into local vile violence and heinous crimes. This paper proposes a hate speech detection model by means of machine learning and text mining feature extraction techniques. In this study, the authors collected the hate speech of English-Odia code mixed data from a Facebook public page and manually organized them into three classes. In order to build binary and ternary datasets, the data are further converted into binary classes. The modeling of hate speech employs the combination of a machine learning algorithm and features extraction. Support vector machine (SVM), naïve Bayes (NB) and random forest (RF) models were trained using the whole dataset, with the extracted feature based on word unigram, bigram, trigram, combined n-grams, term frequency-inverse document frequency (TF-IDF), combined n-grams weighted by TF-IDF and word2vec for both the datasets. Using the two datasets, we developed two kinds of models with each feature—binary models and ternary models. The models based on SVM with word2vec achieved better performance than the NB and RF models for both the binary and ternary categories. The result reveals that the ternary models achieved less confusion between hate and non-hate speech than the binary models. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {English-Odia; Feature extraction; Hate speech; Machine learning; Social media; TF-IDF},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Gold Open Access}
}

@ARTICLE{Aljarah2021483,
	author = {Aljarah, Ibrahim and Habib, Maria and Hijazi, Neveen and Faris, Hossam and Qaddoura, Raneem and Hammo, Bassam and Abushariah, Mohammad and Alfawareh, Mohammad},
	title = {Intelligent detection of hate speech in Arabic social network: A machine learning approach},
	year = {2021},
	journal = {Journal of Information Science},
	volume = {47},
	number = {4},
	pages = {483 – 501},
	doi = {10.1177/0165551520917651},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084999430&doi=10.1177%2f0165551520917651&partnerID=40&md5=0307b6a2aa089c8de8ba1070f59e2eb9},
	affiliations = {The University of Jordan, Jordan; Philadelphia University, Jordan},
	abstract = {Nowadays, cyber hate speech is increasingly growing, which forms a serious problem worldwide by threatening the cohesion of civil societies. Hate speech relates to using expressions or phrases that are violent, offensive or insulting for a person or a minority of people. In particular, in the Arab region, the number of Arab social media users is growing rapidly, which is accompanied with high increasing rate of cyber hate speech. This drew our attention to aspire healthy online environments that are free of hatred and discrimination. Therefore, this article aims to detect cyber hate speech based on Arabic context over Twitter platform, by applying Natural Language Processing (NLP) techniques, and machine learning methods. The article considers a set of tweets related to racism, journalism, sports orientation, terrorism and Islam. Several types of features and emotions are extracted and arranged in 15 different combinations of data. The processed dataset is experimented using Support Vector Machine (SVM), Naive Bayes (NB), Decision Tree (DT) and Random Forest (RF), in which RF with the feature set of Term Frequency-Inverse Document Frequency (TF-IDF) and profile-related features achieves the best results. Furthermore, a feature importance analysis is conducted based on RF classifier in order to quantify the predictive ability of features in regard to the hate class. © The Author(s) 2020.},
	author_keywords = {Hate speech; machine learning; text vectorization; Twitter},
	keywords = {Decision trees; Natural language processing systems; Social networking (online); Speech; Speech recognition; Support vector machines; Text processing; Importance analysis; Intelligent detection; Machine learning approaches; Machine learning methods; NAtural language processing; Online environments; Predictive abilities; Term frequencyinverse document frequency (TF-IDF); Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 72}
}

@CONFERENCE{Pariyani20211146,
	author = {Pariyani, Bhavesh and Shah, Krish and Shah, Meet and Vyas, Tarjni and Degadwala, Sheshang},
	title = {Hate speech detection in twitter using natural language processing},
	year = {2021},
	journal = {Proceedings of the 3rd International Conference on Intelligent Communication Technologies and Virtual Mobile Networks, ICICV 2021},
	pages = {1146 – 1152},
	doi = {10.1109/ICICV50876.2021.9388496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104434698&doi=10.1109%2fICICV50876.2021.9388496&partnerID=40&md5=fc9a8c8b0a452a1bef9506ac1e995826},
	affiliations = {Nirma University, Data Science, Ahmedabad, Gujarat, 380060, India; Sigma Institute of Engineering, Department Computer Engineering},
	abstract = {Twitter's central goal is to enable everybody to make and share thoughts and data, and to communicate their suppositions and convictions without boundaries. Twitter's job is to serve the public discussion, which requires portrayal of a different scope of points of view. Yet, it does not advance viciousness against or straightforwardly assault or undermine others based on race, nationality, public cause, rank, sexual direction, age, inability, or genuine illness. Hate Speech can hurt a person or a community. So, it is not appropriate to use hate speech. Now, due to increase in social media usage, hate speech is very commonly used on these platforms. So, it is not possible to identify hate speeches manually. So, it is essnetial to develop an automated hate speech detection model and this resaech work shows different approaches of Natural Language Processing for classification of Hate Speech through Machine Learning Algorithms. © 2021 IEEE.},
	author_keywords = {Bag of Words); Hate Speech; Logistic Regression; Random Forest; SVM; Tf-Idf},
	keywords = {Cellular radio systems; Learning algorithms; Machine learning; Mobile telecommunication systems; Natural language processing systems; Social networking (online); Speech; Wireless networks; NAtural language processing; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; Conference name: 3rd International Conference on Intelligent Communication Technologies and Virtual Mobile Networks, ICICV 2021; Conference date: 4 February 2021 through 6 February 2021; Conference code: 168213}
}

@ARTICLE{Isaac2022561,
	author = {Isaac, Akileng and Bhat, Aruna},
	title = {A Conceptual Enhancement of LSTM Using Knowledge Distillation for Hate Speech Detection},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {286},
	pages = {561 – 570},
	doi = {10.1007/978-981-16-4016-2_53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118979205&doi=10.1007%2f978-981-16-4016-2_53&partnerID=40&md5=b46e662a857b5c46191b3e6ea3cf0cbb},
	affiliations = {Delhi Technological University, New Delhi, India},
	abstract = {Hate speech is by no means always on the rise due to the high rate of remote service usage such as communication, online studies, meeting, dating, etc. With the recent outbreak of COVID-19, there has been an increase in the number of users on different social media platforms. This increase in number has brought about an increase in issues such as hate speech, among others. This paper aims to provide a detailed process of improving LSTM used for hate speech detection using knowledge distillation. The knowledge transfer is done from the more extensive network (teacher) to the smaller student network. The teacher has trained for five entire epochs to output accuracy of 76.8%, the student network trained from the teacher network for three whole epochs attained an accuracy of 82.6%. Another student model cloned and trained from scratch for three entire epochs instead of the teacher network achieves an accuracy of 75.4%. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Deep learning; Hate speech; Knowledge distillation; LSTM; Performance measures; RNN; Student model; Teacher model},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 5th International Conference on Smart Trends in Computing and Communications, SmartCom 2021; Conference date: 15 April 2021 through 16 April 2021; Conference code: 267489}
}

@ARTICLE{Wullach202148,
	author = {Wullach, Tomer and Adler, Amir and Minkov, Einat},
	title = {Towards Hate Speech Detection at Large via Deep Generative Modeling},
	year = {2021},
	journal = {IEEE Internet Computing},
	volume = {25},
	number = {2},
	pages = {48 – 57},
	doi = {10.1109/MIC.2020.3033161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096147798&doi=10.1109%2fMIC.2020.3033161&partnerID=40&md5=12cf7e20cd49d2c647a66860db079039},
	affiliations = {University of Haifa, Haifa, Israel; Braude College of Engineering, Karmiel, Israel; Massachusetts Institute of Technology, Cambridge, MA, United States},
	abstract = {Hate speech detection is a critical problem in social media, being often accused for enabling the spread of hatred and igniting violence. Hate speech detection requires overwhelming computing resources for online monitoring as well as thousands of human experts for daily screening of suspected posts or tweets. Recently, deep learning (DL)-based solutions have been proposed for hate speech detection, using modest-sized datasets of few thousands of sequences. While these methods perform well on the specific datasets, their ability to generalize to new hate speech sequences is limited. Being a data-driven approach, it is known that DL surpasses other methods whenever scale-up in trainset size and diversity is achieved. Therefore, we first present a dataset of 1 million hate and nonhate sequences, produced by a deep generative model. We further utilize the generated data to train a well-studied DL detector, demonstrating significant performance improvements across five hate speech datasets. © 1997-2012 IEEE.},
	keywords = {Deep learning; Speech; Computing resource; Critical problems; Data-driven approach; Generative model; Online monitoring; Social media; Speech detection; Speech sequences; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; All Open Access, Green Open Access}
}

@CONFERENCE{Rahul20211800,
	author = {Rahul and Gupta, Vasu and Sehra, Vibhu and Vardhan, Yashaswi Raj},
	title = {Ensemble based hinglish hate speech detection},
	year = {2021},
	journal = {Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021},
	pages = {1800 – 1806},
	doi = {10.1109/ICICCS51141.2021.9432352},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107598004&doi=10.1109%2fICICCS51141.2021.9432352&partnerID=40&md5=7d3092125464b047d4fa46a1c523d756},
	affiliations = {Delhi Technological University, Dept. of Computer Science and Engineering, New Delhi, India},
	abstract = {The mixing of multiple languages in speech or text is termed as the phenomenon of code-mixing. The easier access of internet to a larger population, fluent in various regional languages and the more convenient usage of ubiquitous languages like English for technical terms, sports related words, scientific concepts, etc. has led to an increasing presence of code-mixed content on the world wide web, especially socializing and microblogging platforms like of Facebook, twitter, Instagram, etc. The code-mixing of Hindi, the predominant language of South Asia, with English is colloquially referred to as 'Hinglish', a portmanteau resulting from the names of these two languages. Hinglish is considerably different from its parent languages in syntax, phonetics, grammar and even usage of punctuations. The accent and sentiments are drawn from Hindi, the vocabulary is comprised of varying English (Roman) transliteration of Hindi words, certain English terms. The proposed research work aims to build a self-sufficient model, independent of models meant for English language, which can classify code-mixed posts or tweets, or any other text material for that matter, into the categories: Non-Offensive, Abusive and Hate-Inducing. Our work proposes two ensemble models. The first consisting of some basic machine learning models, first experimented individually experimented with, then as an ensemble. The other ensemble is made by stacking some deep learning models. The aim was to combine the learning of models as weak learners into one for getting better results.  © 2021 IEEE.},
	author_keywords = {Code-Mixed; Ensemble; Hate-Speech; Hinglish; Natural Language Processing},
	keywords = {Control systems; Deep learning; Intelligent computing; Mixing; Social networking (online); English languages; Ensemble models; Learning models; Machine learning models; Micro-blogging platforms; Multiple languages; Speech detection; Technical terms; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021; Conference date: 6 May 2021 through 8 May 2021; Conference code: 169144}
}

@CONFERENCE{Abdul Aziz2021,
	author = {Abdul Aziz, Noor Azeera and Aizaini Maarof, Mohd and Zainal, Anazida},
	title = {Hate Speech and Offensive Language Detection: A New Feature Set with Filter-Embedded Combining Feature Selection},
	year = {2021},
	journal = {2021 3rd International Cyber Resilience Conference, CRC 2021},
	doi = {10.1109/CRC50527.2021.9392486},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104524534&doi=10.1109%2fCRC50527.2021.9392486&partnerID=40&md5=779856c81808e75fa5945fb164edd66d},
	affiliations = {Universiti Teknologi Malaysia, School of Computing, Faculty of Engineering, Johor, Malaysia},
	abstract = {Social media has changed the world and play an important role in people lives. Social media platforms like Twitter, Facebook and YouTube create a new dimension of communication by providing channels to express and exchange ideas freely. Although the evolution brings numerous benefits, the dynamic environment and the allowable of anonymous posts could expose the uglier side of humanity. Irresponsible people would abuse the freedom of speech by aggressively express opinion or idea that incites hatred. This study performs hate speech and offensive language detection. The problem of this task is there is no clear boundary between hate speech and offensive language. In this study, a selected new features set is proposed for detecting hate speech and offensive language. Using Twitter dataset, the experiments are performed by considering the combination of word n-gram and enhanced syntactic n-gram. To reduce the feature set, filter-embedded combining feature selection is used. The experimental results indicate that the combination of word n-gram and enhanced syntactic n-gram with feature selection to classify the data into three classes: hate speech, offensive language or neither could give good performance. The result reaches 91% for accuracy and the averages of precision, recall and F1. © 2021 IEEE.},
	author_keywords = {feature selection; hate speech; machine learning; offensive language; syntactic n-gram; Twitter; word n-gram},
	keywords = {Computational linguistics; Social networking (online); Speech; Speech recognition; Syntactics; Dynamic environments; Features sets; Freedom of speech; New dimensions; Offensive languages; Social media; Social media platforms; Word n-grams; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 3rd International Cyber Resilience Conference, CRC 2021; Conference date: 29 January 2021 through 31 January 2021; Conference code: 168321}
}

@CONFERENCE{Halevy2021,
	author = {Halevy, Matan and Harris, Camille and Bruckman, Amy and Yang, Diyi and Howard, Ayanna},
	title = {Mitigating Racial Biases in Toxic Language Detection with an Equity-Based Ensemble Framework},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3465416.3483299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119280696&doi=10.1145%2f3465416.3483299&partnerID=40&md5=08975f25725985aa58581d1e63f5ddc5},
	affiliations = {Georgia Institute of Technology, United States; Ohio State University, United States},
	abstract = {Recent research has demonstrated how racial biases against users who write African American English exists in popular toxic language datasets. While previous work has focused on a single fairness criteria, we propose to use additional descriptive fairness metrics to better understand the source of these biases. We demonstrate that different benchmark classifiers, as well as two in-process bias-remediation techniques, propagate racial biases even in a larger corpus. We then propose a novel ensemble-framework that uses a specialized classifier that is fine-tuned to the African American English dialect. We show that our proposed framework substantially reduces the racial biases that the model learns from these datasets. We demonstrate how the ensemble framework improves fairness metrics across all sample datasets with minimal impact on the classification performance, and provide empirical evidence for its ability to unlearn the annotation biases towards authors who use African American English. ∗∗Please note that this work may contain examples of offensive words and phrases.  © 2021 ACM.},
	author_keywords = {AI fairness; bias mitigation; hate speech detection; moderation},
	keywords = {Remediation; Speech recognition; African American; AI fairness; American English; Bias mitigation; Hate speech detection; Language detection; Moderation; Racial bias; Recent researches; Speech detection; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, EAAMO 2021; Conference date: 5 October 2021 through 9 October 2021; Conference code: 173501; All Open Access, Green Open Access}
}

@CONFERENCE{Sultan2021197,
	author = {Sultan, Daniyar and Mussiraliyeva, Shynar and Toktarova, Aigerim and Nurtas, Marat and Iztayev, Zhalgasbek and Zhaidakbaeva, Lyazzat and Shaimerdenova, Lazzat and Akhmetova, Oxana and Omarov, Batyrkhan},
	title = {Cyberbullying and Hate Speech Detection on Kazakh-Language Social Networks},
	year = {2021},
	journal = {Proceedings - 2021 7th IEEE International Conference on Big Data Security on Cloud, IEEE International Conference on High Performance and Smart Computing, and IEEE International Conference on Intelligent Data and Security, BigDataSecurity/HPSC/IDS 2021},
	pages = {197 – 201},
	doi = {10.1109/BigDataSecurityHPSCIDS52275.2021.00045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113740261&doi=10.1109%2fBigDataSecurityHPSCIDS52275.2021.00045&partnerID=40&md5=3f83314e8e9d760cfb035b784847da84},
	affiliations = {Al-Farabi Kazkah National University, Faculty of Information Systems, Almaty, Kazakhstan; A. Yassawi International Kazakh-Turkish University, Turkistan, Kazakhstan; International Information Technology University, Kazakh-British Technical University, Almaty, Kazakhstan; M.Auezov South Kazakhstan University, Shymkent, Kazakhstan},
	abstract = {Currently, there is a growing number of online bullying, attacks, and propaganda of prohibited materials over the Internet. The main means of exchanging information, selecting and promoting personnel for such structures is the Internet, namely web resources, social networks and e-mail. In this regard, the task of identifying, identifying communication topics, connections, as well as monitoring behavior and predicting threats emanating from individual users, groups and network communities that generate and distribute information of a bullying network on the Internet. The article is devoted to the research and data mining related to the topic of detecting bullying on the Internet. The study examines the development of the data set aimed to train the machine learning algorithms in the Kazakh language and marking them as con-sist of bullying phrasesor not.  © 2021 IEEE.},
	author_keywords = {Classification; Cyberbullying; Detection; Machine Learning; Social Networks; SocialMedia},
	keywords = {Big data; Learning algorithms; Machine learning; Security of data; Social networking (online); Cyber bullying; Data set; Monitoring behaviors; Network communities; Speech detection; Web resources; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th IEEE International Conference on Big Data Security on Cloud, 7th IEEE International Conference on High Performance and Smart Computing, and 6th IEEE International Conference on Intelligent Data and Security, BigDataSecurity/HPSC/IDS 2021; Conference date: 15 May 2021 through 17 May 2021; Conference code: 171032}
}

@CONFERENCE{Satapara202120,
	author = {Satapara, Shrey and Modha, Sandip and Mandl, Thomas and Madhu, Hiren and Majumder, Prasenjit},
	title = {Overview of the HASOC Subtrack at FIRE 2021: Conversational Hate Speech Detection in Code-mixed language},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {20 – 31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134225786&partnerID=40&md5=75bcbc5b10e4c7fea026d31b9fc02c1e},
	affiliations = {DA-IICT, Gandhinagar, India; LDRP-ITR, Gandhinagar, India; University of Hildesheim, Germany; Indian Institute of Science, Bangalore, India},
	abstract = {This paper presents an overview of the newly developed subtask offered at the Forum for Information Retrieval (FIRE’21) conference on detecting contextual hate in social media conversational dialogue. Identification of Conversational Hate-Speech in Code-Mixed Languages (ICHCL) is offered as subtask-2 of the HASOC-English and Indo-Aryan Languages subtrack under the HASOC main track. The objective of the ICHCL subtask is to filter posts that are normal on a standalone basis but might be judged as hate, profane and offensive posts if we consider the context. This subtask focused on the binary classification of such contextual posts. The dataset is sampled from Twitter. Around 7000 code-mixed posts in English and Hindi were downloaded and annotated with an annotation platform developed for this task. A total of 15 teams from across the world has participated and submitted 50 runs for this track. The Macro F1 score is used as the primary metric for the evaluation. The best-performing team has reported a macro-f1 score of around 0.74. The task shows that considering the context can improve the performance of classification methods. ICHCL can contribute to identifying the best methods for this task. © 2021 Copyright for this paper by its authors.},
	author_keywords = {context; Hate Speech; NLP; social media},
	keywords = {Codes (symbols); Information retrieval; Social networking (online); Speech recognition; Binary classification; Classification methods; Context; F1 scores; Hate speech; Performance; Social media; Speech detection; Subtask; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Anand2021432,
	author = {Anand, Anirudh and Golecha, Jeet and Bharathi, B. and Jayaraman, Bhuvana and Mirnalinee, T.T.},
	title = {Machine Learning based hate speech identification for English and Indo-Aryan languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {432 – 438},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134233203&partnerID=40&md5=9848a198b4d870bcc34fe63eb51da7bf},
	affiliations = {Department of CSE, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, India},
	abstract = {Social media platforms pave way for the public to express their opinions. These opinions are mostly on the events and happenings across the world. These comments are most often unbiased and cross the individual boundaries that cause hurt to the people involved. Some comments are intentionally delivered through these platforms with the purpose of offending the party concerned. An automatic technique is needed to identify offensive comments to prevent unwanted consequences. Our work is a part of Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages, where the offensive public opinions on social media platforms are to identified. We have devised a system that uses both machine learning and deep learning techniques to detect the offensive comments. Random Forest has obtained 78% macro F1 score, in Hindi Recurrent Neural Network performed well with 73% and Support vector machine with 75% macro F1 score. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Indo-Aryan Languages; Machine learning; Offensive comments; Text classification},
	keywords = {Classification (of information); Decision trees; Learning systems; Social networking (online); Support vector machines; Text processing; Automatic technique; Content identifications; Deep learning; F1 scores; Indo-aryan language; Machine-learning; Offensive comment; Social media platforms; Speech identification; Text classification; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Kalaivani2021667,
	author = {Kalaivani, Adaikkan and Thenmozhi, Durairaj and Aravindan, Chandrabose},
	title = {TOLD: Tamil Offensive Language Detection in Code-Mixed Social Media Comments using MBERT with Features based Selection},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {667 – 679},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134239273&partnerID=40&md5=39651a0d1ce8fbace1ae15690601c7c3},
	affiliations = {Department of Information and Communication Engineering, Anna University, Chennai, India; Research Centre, Department of CSE, Sri Sivasubramaniya Nadar College of Engineering, Kalavakkam, TamilNadu, India; Department of CSE, Sri Sivasubramaniya Nadar College of Engineering, Kalavakkam, TamilNadu, India; Department of Information Technology, Sri Sivasubramaniya Nadar College of Engineering, Kalavakkam, TamilNadu, India},
	abstract = {The immense growth in social media forums does increase the spread of offensive language. We detect and examine the challenges faced by automatic approaches for offensive language detection in the Tamil-English language. Among these difficulties are subtleties in code-mixed Tamil language, identifying what constitutes offensive, and handling the imbalanced data under the low resource language. This paper presents our work in the shared task of HASOC-Dravidian-CodeMix-FIRE 2021, where we explore different machine learning algorithms, deep learning techniques, and transfer learning models. We also explore various feature extraction techniques and utilize offensive features to perform this task. Our team SSN_NLP_MLRG has participated in task1 and classifies the code-mixed Tamil textual content into offensive or not-offensive. Our team best model is Multilingual BERT, and submission had a macro F1-score 0.84 of task1 of Tamil code-mixed language. Our team achieved the 3rd rank on the final test results in task1 for the Tamil code-mixed language. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-Mixed language; Dravidian language; Language modeling; Transfer learning; Transformers},
	keywords = {Codes (symbols); Data handling; Deep learning; Feature extraction; Learning algorithms; Learning systems; Social networking (online); Automatic approaches; Code-mixed language; Dravidian language; Feature-based; Language detection; Language model; Offensive languages; Social media; Transfer learning; Transformer; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Chakravarthi2021589,
	author = {Chakravarthi, Bharathi Raja and Kumaresan, Prasanna Kumar and Sakuntharaj, Ratnasingam and Madasamy, Anand Kumar and Thavareesan, Sajeetha and Premjith, B. and Sreelakshmi, K. and Navaneethakrishnan, Subalalitha Chinnaudayar and McCrae, John P. and Mandl, Thomas},
	title = {Overview of the HASOC-DravidianCodeMix Shared Task on Offensive Language Detection in Tamil and Malayalam},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {589 – 602},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134230210&partnerID=40&md5=de8c29ba1832a3a8654053e71a282ce3},
	affiliations = {Insight Centre for Data Analytics, National University of Ireland, Galway, Ireland; Indian Institute of Information Technology and Management, Kerala, India; Eastern University, Sri Lanka; National Institute of Technology Karnataka, Surathkal, Karnataka, India; Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; SRM Institute of Science and Technology, Tamil Nadu, Chennai, India; University of Hildesheim, Germany},
	abstract = {We present the results of HASOC-Dravidian-CodeMix shared task1 held at FIRE 2021, a track on offensive language identification for Dravidian languages in Code-Mixed Text in this paper. This paper will detail the task, its organisation, and the submitted systems. The identification of offensive language was viewed as a classification task. For this, 16 teams participated in identifying offensive language from Tamil-English code mixed data, 11 teams for Malayalam-English code mixed data and 14 teams for Tamil data. The teams detected offensive language using various machine learning and deep learning classification models. This paper has analysed those benchmark systems to find out how well they accommodate a code-mixed scenario in Dravidian languages, focusing on Tamil and Malayalam. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-mixing; Dravidian languages; Kannada; Malayalam; Sentiment analysis; Tamil},
	keywords = {Deep learning; Learning systems; Code-mixing; Dravidian language; Kannada; Language detection; Language identification; Malayalams; Mixed data; Offensive languages; Sentiment analysis; Tamil; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Shekhar2021,
	author = {Shekhar, Shubhanshu and Akanksha and Saini, Aman},
	title = {Utilizing Topic Modelling to Identify Abusive Comments on YouTube},
	year = {2021},
	journal = {2021 International Conference on Intelligent Technologies, CONIT 2021},
	doi = {10.1109/CONIT51480.2021.9498368},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114879292&doi=10.1109%2fCONIT51480.2021.9498368&partnerID=40&md5=da641b58d73a2f1180c2beec040d7e3a},
	affiliations = {Delhi Technological University, Department of Computer Engineering, New Delhi, India},
	abstract = {Online video platforms such as YouTube was once regarded as a haven for entertainment, educational, and promotional purposes. Now they have become a breeding ground for spreading toxic behavior, radicalizing content, and political propaganda. We have used YouTube data API v3 to scrape several data related to youtube videos like videos URL, description, view count, and comment information like commenters, comments, and replies. We investigated some hot topics which are prone to abusive comments. For example, bullies are highly existent in racial, teenage lifestyle and appearance, LGBTQ topics, or targeted mainly towards women and girls. We randomly selected a couple of videos from these YouTube channels and used them to research and analyze this project. We have used LDA (latent Dirichlet allocation) to identify dominant topics in a particular uploader's comment section. We have also used the TextBlob library of python for determining the polarity and subjectivity of comments for each uploader. © 2021 IEEE.},
	author_keywords = {Abusive Comments; LDA (Latent Dirichlet Allocation); Polarity and Subjectivity; TextBlob; YouTube},
	keywords = {Breeding grounds; Hot topics; LDA (latent Dirichlet allocation); Online video; YouTube; Statistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 International Conference on Intelligent Technologies, CONIT 2021; Conference date: 25 June 2021 through 27 June 2021; Conference code: 171211}
}

@CONFERENCE{Marpaung2021186,
	author = {Marpaung, Angela and Rismala, Rita and Nurrahmi, Hani},
	title = {Hate Speech Detection in Indonesian Twitter Texts using Bidirectional Gated Recurrent Unit},
	year = {2021},
	journal = {KST 2021 - 2021 13th International Conference Knowledge and Smart Technology},
	pages = {186 – 190},
	doi = {10.1109/KST51265.2021.9415760},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105887430&doi=10.1109%2fKST51265.2021.9415760&partnerID=40&md5=5f6f525eee7d085a948457fd2749ec40},
	affiliations = {School of Computing, Telkom University, Bandung, Indonesia},
	abstract = {As the number of social media users rises, the probability of hate speech spread in social media also rises indirectly. Hate speech has become one of most common cases found on social media. The spread of hate speech can lead to a riot that might cause conflict, group extermination, and even human casualties. Some of the latest controversies in Indonesia related to hate speech was the hate speech uttered to the government that led to polemic and even demonstration in the country. Along with this, it is important to detect hate speech to avoid conflict to happen. As the spread of hate speech in social media increases, it requires significant human efforts and is costly to detect manually. Therefore, this experiment is built to detect hate speech detection in Indonesian twitter texts using several conventional machine learning and deep learning based, BiGRU, with various features. The machine learning approaches being used are SVM and RFDT, while deep learning based methods used are BiGRU and pre-Trained IndoBERT with BiGRU. Several methods used are Word2vec and fastText. The experiment shows that BiGRU method with IndoBERT and no stop word removal achieves the best performance with 84.77% accuracy. BiGRU has advantages on storing important information from text, thus making a better result than conventional machine learning algorithm. © 2021 IEEE.},
	author_keywords = {BiGRU; fastText; hate speech; text classification; Word2vec},
	keywords = {Deep learning; Learning systems; Social networking (online); Speech; Speech recognition; Conventional machines; Indonesia; Learning-based methods; Machine learning approaches; Social media; Speech detection; Stop word; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 13th International Conference Knowledge and Smart Technology, KST 2021; Conference date: 21 January 2021 through 24 January 2021; Conference code: 168764}
}

@CONFERENCE{Kumaresan202116,
	author = {Kumaresan, Prasanna Kumar and Premjith and Sakuntharaj, Ratnasingam and Thavareesan, Sajeetha and Navaneethakrishnan, Subalalitha and Madasamy, Anand Kumar and Chakravarthi, Bharathi Raja and McCrae, John P.},
	title = {Findings of Shared Task on Offensive Language Identification in Tamil and Malayalam},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {16 – 18},
	doi = {10.1145/3503162.3503179},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124354689&doi=10.1145%2f3503162.3503179&partnerID=40&md5=72487732a2e73de4bd0e778aae5fa460},
	affiliations = {Indian Institute of Information Technology and Management - Kerala, India; Amrita Vishwa Vidyapeetham, India; Eastern University, Sri Lanka; SRM Institute of Science and Technology, India; National Institute of Technology Karnataka Surathkal, India; Insight SFI Research Centre for Data Analytics, National University of Ireland Galway, Ireland},
	abstract = {We present the results of HASOC-Dravidian-CodeMix shared task1 held at FIRE 2021, a track on offensive language identification for Dravidian languages in Code-Mixed Text in this paper. This paper will detail the task, its organisation, and the submitted systems. The identification of offensive language was viewed as a classification task. For this, 16 teams participated in identifying offensive language from Tamil-English code mixed data, 11 teams for Malayalam-English code mixed data and 14 teams for Tamil data. The teams detected offensive language using various machine learning and deep learning classification models. This paper has analysed those benchmark systems to find out how well they accommodate a code-mixed scenario in Dravidian languages, focusing on Tamil and Malayalam.  © 2021 Owner/Author.},
	author_keywords = {datasets; deep learning; evaluation; Hate speech},
	keywords = {Codes (symbols); Deep learning; Fires; Classification models; Classification tasks; Dataset; Deep learning; Evaluation; Hate speech; Language identification; Malayalams; Mixed data; Offensive languages; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; Conference name: 13th Annual Meeting of the Forum for Information Retrieval Evaluation, FIRE 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 176677}
}

@CONFERENCE{Zeng2021254,
	author = {Zeng, Jun and Xu, Li and Wu, Hao},
	title = {ALBERT for Hate Speech and Offensive Content Identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {254 – 261},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134263999&partnerID=40&md5=0d012729ce1b603bf21b49c5e12adc2f},
	affiliations = {School of Information Science and Engineering, Yunnan University, Kunming, China},
	abstract = {This paper describes our system in Subtask 1A of HASOC 2021, and our team name is JZ2021. Subtask 1A focuses on hate speech and offensive language recognition for English and Hindi. Now, the detection of hate speech and offensive content on the Internet has received widespread attention. These comments have caused a lot of trouble to people, and the identification of the comments are very meaningful. With the development of deep learning, many pre-trained deep neural network models are used for text classification tasks. However, some pre-trained models contain a large number of parameters, although they perform well. In HASOC 2021 task, we use a model called ALBERT. It improves the BERT model and effectively reduces the number of parameters of the model. We chose ALBERT-large, which gets great results in the task. Our system achieves the Macro F1 score of 83.75%. © 2021 Copyright for this paper by its authors.},
	author_keywords = {ALBERT; BERT; HASOC 2021; Hate Speech; Offensive Content},
	keywords = {Classification (of information); Neural network models; Speech recognition; Text processing; ALBERT; BERT; Content identifications; HASOC 2021; Hate speech; Language recognition; Neural network model; Offensive content; Offensive languages; Subtask; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Mandl20211,
	author = {Mandl, Thomas and Modha, Sandip and Shahi, Gautam Kishore and Madhu, Hiren and Satapara, Shrey and Majumder, Prasenjit and Schäfer, Johannes and Ranasinghe, Tharindu and Zampieri, Marcos and Nandini, Durgesh and Jaiswal, Amit Kumar},
	title = {Overview of the HASOC Subtrack at FIRE 2021: Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {1 – 19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134237889&partnerID=40&md5=3857bc3ff7da97cc8c143bb7df273a88},
	affiliations = {University of Hildesheim, Germany; LDRP-ITR, Gandhinagar, India; University of Duisburg-Essen, Germany; Indian Institute of Science, Bangalore, India; DA-IICT, Gandhinagar, India; University of Wolverhampton, United Kingdom; Rochester Institute of Technology, United States; University of Bamberg, Germany; University of Bedfordshire, United Kingdom; University of Leeds, United Kingdom},
	abstract = {The widespread of offensive content online such as hate speech poses a growing societal problem. AI tools are necessary for supporting the moderation process at online platforms. For the evaluation of these identification tools, continuous experimentation with data sets in different languages are necessary. The HASOC track (Hate Speech and Offensive Content Identification) is dedicated to develop benchmark data for this purpose. This paper presents the HASOC subtrack for English, Hindi, and Marathi. The data set was assembled from Twitter. This subtrack has two sub-tasks. Task A is a binary classification problem (Hate and Not Offensive) offered for all three languages. Task B is a fine-grained classification problem for three classes (HATE) Hate speech, OFFENSIVE and PROFANITY offered for English and Hindi. Overall, 652 runs were submitted by 65 teams. The performance of the best classification algorithms for task A are F1 measures 0.91, 0.78 and 0.83 for Marathi, Hindi and English, respectively. This overview presents the tasks and the data development as well as the detailed results. The systems submitted to the competition applied a variety of technologies. The best performing algorithms were mainly variants of transformer architectures. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Evaluation; Hate Speech; Machine Learning; Multilingual Text Classification; Offensive Language; Social Media},
	keywords = {Classification (of information); Deep learning; Fires; Social networking (online); Text processing; Content identifications; Deep learning; Evaluation; Hate speech; Machine-learning; Multilingual text classification; Multilingual texts; Offensive languages; Social media; Text classification; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Modha20211,
	author = {Modha, Sandip and Mandl, Thomas and Shahi, Gautam Kishore and Madhu, Hiren and Satapara, Shrey and Ranasinghe, Tharindu and Zampieri, Marcos},
	title = {Overview of the HASOC Subtrack at FIRE 2021: Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages and Conversational Hate Speech},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {1 – 3},
	doi = {10.1145/3503162.3503176},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124344402&doi=10.1145%2f3503162.3503176&partnerID=40&md5=76fcac9b114d9c88cc1ea94a0b4bcd7a},
	affiliations = {LDRP-ITR, India; University of Hildesheim, Germany; University of Duisburg-Essen, Germany; Indian Institute of Science, India; DA-IICT, India; University of Wolverhampton, United Kingdom; Rochester Institute of Technology, United States},
	abstract = {The HASOC track is dedicated to the evaluation of technology for finding Offensive Language and Hate Speech. HASOC is creating a multilingual data corpus mainly for English and under-resourced languages(Hindi and Marathi). This paper presents one HASOC subtrack with two tasks. In 2021, we organized the classification task for English, Hindi, and Marathi. The first task consists of two classification tasks; Subtask 1A consists of a binary and fine-grained classification into offensive and non-offensive tweets. Subtask 1B asks to classify the tweets into Hate, Profane and offensive. Task 2 consists of identifying tweets given additional context in the form of the preceding conversion. During the shared task, 65 teams have submitted 652 runs. This overview paper briefly presents the task descriptions, the data and the results obtained from the participant's submission.  © 2021 Owner/Author.},
	author_keywords = {hate speech; Multilingual Datasets; social media; Under-resourced language},
	keywords = {Fires; Information retrieval; Classification tasks; Content identifications; Evaluation of technology; Fine grained; Hate speech; Multilingual dataset; Offensive languages; Social media; Subtask; Under-resourced languages; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; Conference name: 13th Annual Meeting of the Forum for Information Retrieval Evaluation, FIRE 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 176677; All Open Access, Green Open Access}
}

@CONFERENCE{Chaitaya2021696,
	author = {Chaitaya, B.S.N.V. and Karri, Anjali},
	title = {Transformer Ensemble System for Detection of Offensive Content in Dravidian Languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {696 – 704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134248137&partnerID=40&md5=4903ab670cc511e54faf268aa7443717},
	affiliations = {Indian Institute of Information Technology, SriCity, India},
	abstract = {Hate speech is a form of oral, written or physical activity that criticizes or uses derogatory language in correspondence to a person or a community discriminating their identity factors. Hate speech or the use of offensive language can endanger democratic principles and societal stability. The growing usage of social media is also increasing the number of people being affected by hate speech. Online hate speech moderation has been significantly increasing, especially through social media platforms like Facebook, Twitter, YouTube, and Instagram. It is high time to take appropriate actions to curb the intensifying online hate speech by supporting the detection of hate speech or offensive language texts in social media. The work presented to Hate Speech and Offensive Content Identification in Dravidian-CodeMix (HASOC) 2021, a joint assignment under Forum for Information Retrieval Evaluation (FIRE) 2021, is described in this paper. In this paper, we proposed an ensemble system of transformer models (mBERT, DistilBERT and MuRIL) to achieve the task of identifying social media code-mixed comments/posts in Dravidian Languages (Malayalam-English and Tamil-English) as offensive or not-offensive texts. The motivation behind this was to use the power of transformers in combination with ensembling to enhance the prediction quality. For sub-task 2, the proposed ensemble method received 3rd and 6th positions in Malayalam and Tamil languages, respectively. The code is publicly available at https://github.com/chaitnayabasava/HSU_TransEmb. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT Transformers; CodeMix; Ensemble; Hate speech; Offensive Language},
	keywords = {Codes (symbols); Speech recognition; BERT transformer; Codemix; Ensemble; Ensemble systems; Hate speech; Malayalams; Number of peoples; Offensive languages; Physical activity; Social media; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Khan20227881,
	author = {Khan, Shakir and Kamal, Ashraf and Fazil, Mohd and Alshara, Mohammed Ali and Sejwal, Vineet Kumar and Alotaibi, Reemiah Muneer and Baig, Abdul Rauf and Alqahtani, Salihah},
	title = {HCovBi-Caps: Hate Speech Detection Using Convolutional and Bi-Directional Gated Recurrent Unit With Capsule Network},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {7881 – 7894},
	doi = {10.1109/ACCESS.2022.3143799},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123281956&doi=10.1109%2fACCESS.2022.3143799&partnerID=40&md5=ffdd62313b2d70fbb4d4f8b9b3818402},
	affiliations = {Imam Mohammad Ibn Saud Islamic University, College of Computer and Information Sciences, Riyadh, 11564, Saudi Arabia; ACL Digital, Bengaluru, 560029, India; Qatar University, Department of Computer Engineering, Qatar; Jamia Millia Islamia, Department of Computer Science, New Delhi, 110025, India},
	abstract = {Adversaries and anti-social elements have exploited the rapid proliferation of computing technology and online social media in the form of novel security threats, such as fake profiles, hate speech, social bots, and rumors. The hate speech problem on online social networks (OSNs) is also widespread. The existing literature has machine learning approaches for hate speech detection on OSNs. However, the effectiveness of contextual information at different orientations is understudied. This study presents a novel Convolutional, BiGRU, and Capsule network-based deep learning model, HCovBi-Caps, to classify the hate speech. The proposed model is evaluated over two Twitter-based benchmark datasets – DS1(balanced) and DS2(unbalanced) with the best performance of 0.90, 0.80, and 0.84 respectively considering precision, recall, and f-score over unbalanced dataset. In terms of training and validation accuracy, the proposed model shows the best performance of 0.93 and 0.90, respectively, over the unbalanced dataset. In comparative evaluation, HCovBi-Caps demonstrates a significantly better performance than state-of-the-art approaches. In addition, HCovBi-Caps shows comparatively better performance over the unbalanced dataset. We also investigate the impact of different hyperparameters on the efficacy of HCovBi-Caps to ascertain the selection of their values. We observed that a higher value of routing iterations adversely affects the model performance, whereas a higher value of capsule dimension improves the performance. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/},
	author_keywords = {Blogs; Context modeling; Deep learning; Hate speech; Logic gates; Logistics; Social networking (online)},
	keywords = {Benchmarking; Convolution; Deep learning; Fake detection; Network layers; Speech; Speech recognition; Bi-directional; BiGRU; Capsule network; Convolutional layer; Deep learning; Hate speech detection; Performance; Speech detection; Twitter data analyse; Unbalanced datasets; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 56; All Open Access, Gold Open Access}
}@ARTICLE{Ashraf2021,
	author = {Ashraf, Noman and Zubiaga, Arkaitz and Gelbukh, Alexander},
	title = {Abusive language detection in youtube comments leveraging replies as conversational context},
	year = {2021},
	journal = {PeerJ Computer Science},
	volume = {7},
	doi = {10.7717/peerj-cs.742},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124363956&doi=10.7717%2fpeerj-cs.742&partnerID=40&md5=7beb59a96bd432f26a4238fa61730f8e},
	affiliations = {Instituto Politécnico Nacional, CIC, Mexico City, Mexico; Queen Mary University of London, London, United Kingdom},
	abstract = {Nowadays, social media experience an increase in hostility, which leads to many people suffering from online abusive behavior and harassment. We introduce a new publicly available annotated dataset for abusive language detection in short texts. The dataset includes comments from YouTube, along with contextual information: replies, video, video title, and the original description. The comments in the dataset are labeled as abusive or not and are classified by topic: politics, religion, and other. In particular, we discuss our refined annotation guidelines for such classification. We report a number of strong baselines on this dataset for the tasks of abusive language detection and topic classification, using a number of classifiers and text representations. We show that taking into account the conversational context, namely, replies, greatly improves the classification results as compared with using only linguistic features of the comments. We also study how the classification accuracy depends on the topic of the comment. © Copyright 2021. Ashraf et al.},
	author_keywords = {Abusive language detection; Context aware abusive language detection; Corpus; Deep learning; Natural language processing; YouTube},
	keywords = {Classification (of information); Deep learning; Natural language processing systems; Text processing; Abusive language detection; Annotated datasets; Context aware abusive language detection; Context-Aware; Corpus; Deep learning; Language detection; Social media; YouTube; Linguistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Bhatia2021419,
	author = {Bhatia, Mehar and Bhotia, Tenzin Singhay and Agarwal, Akshat and Ramesh, Prakash and Gupta, Shubham and Shridhar, Kumar and Laumann, Felix and Dash, Ayushman},
	title = {One to Rule Them All: Towards Joint Indic Language Hate Speech Detection},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {419 – 431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134205301&partnerID=40&md5=fbe4d0ac19ddd33ae43b92c259c13036},
	affiliations = {NeuralSpace, London, United Kingdom},
	abstract = {This paper is a contribution to the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) 2021 shared task. Social media today is a hotbed of toxic and hateful conversations, in various languages. Recent news reports have shown that current models struggle to automatically identify hate posted in minority languages. Therefore, efficiently curbing hate speech is a critical challenge and problem of interest. Our team, ‘NeuralSpace’ presents a multilingual architecture using state-of-the-art transformer language models to jointly learn hate and offensive speech detection across three languages namely, English, Hindi, and Marathi. On the provided testing corpora, we achieve Macro F1 scores of 0.7996, 0.7748, 0.8651 for sub-task 1A and 0.6268, 0.5603 during the fine-grained classification of sub-task 1B. These results show the efficacy of exploiting a multilingual training scheme. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Hate Speech; Indic Languages; Low Resource; Multilingual Language Models; Social Media},
	keywords = {Social networking (online); Speech recognition; Content identifications; European languages; Hate speech; Indic language; Language model; Low resource; Multilingual language model; Social media; Speech detection; Subtask; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Salim2021193,
	author = {Salim, Calvin Erico Rudy and Suhartono, Derwin},
	title = {Long short-term memory for hate speech and abusive language detection on Indonesian YouTube comment section},
	year = {2021},
	journal = {2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},
	pages = {193 – 200},
	doi = {10.18178/wcse.2021.06.029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114196740&doi=10.18178%2fwcse.2021.06.029&partnerID=40&md5=7ec57532951fce39506a12efb7f49983},
	affiliations = {Computer Science Department, BINUS Graduate Program, Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia},
	abstract = {Hate speech is one of the most challenging problem internet is facing today. With increasing numbers of users online, hate speech also rise and takes time to be classified manually particularly in languages other than English. This research examines hate speech detection problem in form of Bahasa Indonesia. Millions of comments and text posts are added to various social media and discussion platforms. Manual classification in all of the internet as hate speech and offensive language is a near impossible and time-consuming task. This research uses Long Short-Term Memory (LSTM) and Bidirectional Long Short Term Memory (Bi-LSTM) for the method of classifying hate speech and abusive language. The final accuracy is 88,44% by using 200 neurons with Bi-LSTM method. Most common challenges are different languages, out of vocabulary words, long range dependencies, and sarcasm. © 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021. All Rights Reserved.},
	author_keywords = {Hate speech; Machine learning; Natural language processing},
	keywords = {Brain; Speech; Speech recognition; Language detection; Long-range dependencies; Manual classification; Offensive languages; Out of vocabulary words; Social media; Speech detection; Time-consuming tasks; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021; Conference date: 19 June 2021 through 21 June 2021; Conference code: 171371; All Open Access, Bronze Open Access}
}

@CONFERENCE{Bestgen202182,
	author = {Bestgen, Yves},
	title = {A simple language-agnostic yet strong baseline system for hate speech and offensive content identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {82 – 91},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134196341&partnerID=40&md5=cb6dad34e08dc4fc9b14fb89725f984d},
	affiliations = {Laboratoire D’Analyse Statistique des Textes - Statistical Analysis of Text Laboratory (LAST - SATLab), Université Catholique de Louvain, 10 place Cardinal Mercier, Louvain-la-Neuve, 1348, Belgium},
	abstract = {For automatically identifying hate speech and offensive content in tweets, a system based on a classical supervised algorithm only fed with character n-grams, and thus completely language-agnostic, is proposed by the SATLab team. After its optimization in terms of the feature weighting and the classifier parameters, it reached, in the multilingual HASOC 2021 challenge, a medium performance level in English, the language for which it is easy to develop deep learning approaches relying on many external linguistic resources, but a far better level for the two less resourced language, Hindi and Marathi. It ended even first when performances are averaged over the three tasks in these languages. These performances suggest that it is an interesting reference level to evaluate the benefits of using more complex approaches such as deep learning or taking into account complementary resources. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Character n-grams; gradient boosting decision tree; logistic regression; low-resource languages},
	keywords = {Computational linguistics; Deep learning; Baseline systems; Character n-gram; Content identifications; Gradient boosting; Gradient boosting decision tree; Logistics regressions; Low resource languages; N-grams; Performance; Simple++; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Hossain Junaid2021347,
	author = {Hossain Junaid, Mohd. Istiaq and Hossain, Faisal and Rahman, Rashedur M.},
	title = {Bangla Hate Speech Detection in Videos Using Machine Learning},
	year = {2021},
	journal = {2021 IEEE 12th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2021},
	pages = {347 – 351},
	doi = {10.1109/UEMCON53757.2021.9666550},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125188019&doi=10.1109%2fUEMCON53757.2021.9666550&partnerID=40&md5=3d5e098964b7aacdbfea056db1e05f26},
	affiliations = {North South University, Department of Electrical and Computer Engineering, Plot-15, Block-B, Bashundhara, Dhaka, 1229, Bangladesh},
	abstract = {Due to the internet and social media advance, people now communicate their ideas and opinions on many topics freely through several channels. However, because of its ethnicity, religion, genders, etc., this freedom of expression is exploited to direct hate to individuals or groups of people. The increase in hate speech led to disputes and cyberbullying, which drove many companies to find ideal solutions to this problem. The strategy we have taken is to use machine learning classification methods to classify videos. We have generated our dataset and tested it with several training models in this paper, utilizing the spoken material of the videos from YouTube. We experimented with some of the machine learning models along with some deep learning techniques. Our experiments concluded that the logistic regression and deep learning GRU model bring out the best accuracy on the current dataset.  © 2021 IEEE.},
	author_keywords = {Artificial Neural Networks (ANNs); Deep Learning (DL); Gate recurrent unit (GRU); Long short-term memory (LSTM); Natural Language Processing (NLP)},
	keywords = {Convolutional neural networks; Learning algorithms; Natural language processing systems; Artificial neural network; Cyber bullying; Deep learning; Gate recurrent unit; Internet media; Long short-term memory; Machine-learning; Natural language processing; Social media; Speech detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 12th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2021; Conference date: 1 December 2021 through 4 December 2021; Conference code: 176321}
}

@CONFERENCE{Özberk2021517,
	author = {Özberk, Anil and Çiçekli, Ilyas},
	title = {Offensive Language Detection in Turkish Tweets with Bert Models},
	year = {2021},
	journal = {Proceedings - 6th International Conference on Computer Science and Engineering, UBMK 2021},
	pages = {517 – 521},
	doi = {10.1109/UBMK52708.2021.9559000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125857712&doi=10.1109%2fUBMK52708.2021.9559000&partnerID=40&md5=128daab036d1a1c0bd41e6f9e967ab3a},
	affiliations = {Department of Computer Engineering, Hacettepe University, Ankara, Turkey},
	abstract = {As the insulting statements increase on the online platform, these negative statements create a reaction and disturb the peace of society. Offensive language detection research has been increased in recent years. This paper explores the effects of the usage of BERT models and fine-tuning techniques on offensive language detection on Turkish tweets. We emphasize the pre-trained model importance on the performance of a downstream task and the importance of the used BERT model. © 2021 IEEE},
	author_keywords = {BERT; Natural language processing; Offensive language detection},
	keywords = {BERT; Down-stream; Fine tuning; Language detection; Model tuning; Offensive language detection; Offensive languages; Online platforms; Performance; Turkishs; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 6th International Conference on Computer Science and Engineering, UBMK 2021; Conference date: 15 September 2021 through 17 September 2021; Conference code: 176826}
}

@CONFERENCE{Velankar2021239,
	author = {Velankar, Abhishek and Patil, Hrushikesh and Gore, Amol and Salunke, Shubham and Joshi, Raviraj},
	title = {Hate and Offensive Speech Detection in Hindi and Marathi},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {239 – 247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133703471&partnerID=40&md5=0a9f12a86daf6af8ebf237f61e523698},
	affiliations = {Pune Institute of Computer Technology, Maharashtra, Pune, India; Indian Institute of Technology Madras, Tamilnadu, Chennai, India},
	abstract = {Sentiment analysis is the most basic NLP task to determine the polarity of text data. There has been a significant amount of work in the area of multilingual text as well. Still hate and offensive speech detection faces a challenge due to inadequate availability of data, especially for Indian languages like Hindi and Marathi. In this work, we consider hate and offensive speech detection in Hindi and Marathi texts. The problem is formulated as a text classification task using the state of the art deep learning approaches. We explore different deep learning architectures like CNN, LSTM, and variations of BERT like multilingual BERT, IndicBERT, and monolingual RoBERTa. The basic models based on CNN and LSTM are augmented with fast text word embeddings. We use the HASOC 2021 Hindi and Marathi hate speech datasets to compare these algorithms. The Marathi dataset consists of binary labels and the Hindi dataset consists of binary as well as more-fine grained labels. We show that the transformer-based models perform the best and even the basic models along with FastText embeddings give a competitive performance. Moreover, with normal hyper-parameter tuning, the basic models perform better than BERT-based models on the fine-grained Hindi dataset. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT; Convolutional Neural Networks; FastText; Hate Speech Detection; Long Short Term Memory; Natural Language Processing},
	keywords = {Classification (of information); Convolutional neural networks; Long short-term memory; Sentiment analysis; Speech recognition; BERT; Convolutional neural network; Embeddings; Fasttext; Fine grained; Hate speech detection; Language processing; Natural language processing; Natural languages; Speech detection; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Mullah202188364,
	author = {Mullah, Nanlir Sallau and Zainon, Wan Mohd Nazmee Wan},
	title = {Advances in Machine Learning Algorithms for Hate Speech Detection in Social Media: A Review},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {88364 – 88376},
	doi = {10.1109/ACCESS.2021.3089515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117607230&doi=10.1109%2fACCESS.2021.3089515&partnerID=40&md5=082d44c1592f60eb61d44fa4ce0c6317},
	affiliations = {School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Federal College of Education Pankshin, PMB1027 Pankshin, Plateau State, Nigeria},
	abstract = {The aim of this paper is to review machine learning (ML) algorithms and techniques for hate speech detection in social media (SM). Hate speech problem is normally model as a text classification task. In this study, we examined the basic baseline components of hate speech classification using ML algorithms. There are five basic baseline components - data collection and exploration, feature extraction, dimensionality reduction, classifier selection and training, and model evaluation, were reviewed. There have been improvements in ML algorithms that were employed for hate speech detection over time. New datasets and different performance metrics have been proposed in the literature. To keep the researchers informed regarding these trends in the automatic detection of hate speech, it calls for a comprehensive and an updated state-of-the-art. The contributions of this study are three-fold. First to equip the readers with the necessary information on the critical steps involved in hate speech detection using ML algorithms. Secondly, the weaknesses and strengths of each method is critically evaluated to guide researchers in the algorithm choice dilemma. Lastly, some research gaps and open challenges were identified. The different variants of ML techniques were reviewed which include classical ML, ensemble approach and deep learning methods. Researchers and professionals alike will benefit immensely from this study.  © 2013 IEEE.},
	author_keywords = {Cyber hate; Deep learning; Ensemble technique; Machine learning; Social media networks; Text classification},
	keywords = {Classification (of information); Deep learning; Feature extraction; Learning algorithms; Social networking (online); Speech recognition; Text processing; Cybe hate; Deep learning; Ensemble techniques; Machine learning algorithms; Machine learning techniques; Social media; Social media networks; Speech classification; Speech detection; Text classification; Speech},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68}
}

@CONFERENCE{Kyrollos20212496,
	author = {Kyrollos, Daniel G. and Green, James R.},
	title = {MetaHate: A Meta-Model for Hate Speech Detection},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
	pages = {2496 – 2502},
	doi = {10.1109/BigData52589.2021.9672023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125329969&doi=10.1109%2fBigData52589.2021.9672023&partnerID=40&md5=3625992f06f467226ede5cc3996c621c},
	affiliations = {Systems and Computer Engineering, Carleton University, Ottawa, Canada},
	abstract = {We present MetaHate, a NLP meta-model for detecting hatefulness in tweets by combining predictors for hate, emotion, sentiment, and offensiveness. We evaluate this model with the TweetEval benchmark for hate speech detection. MetaHate improves the baseline TweetEval RoBERTa based model on the TweetEval benchmark. Optimizing the decision threshold for the macro-averaged F1-score, MetaHate achieves a F1-score of 0.70, while the TweetEval RoBERTa-Twitter Retrained Hate model achieves a F1-score of 0.63. This improvement on one of the most difficult tasks on the TweetEval benchmark was achieved with no additional training data and negligible computational time and cost. MetaHate demonstrates the utility of leveraging predictions from language models trained for various tasks to improve performance on a single task. © 2021 IEEE.},
	keywords = {Computational costs; Computational time; Decision threshold; F1 scores; Improve performance; Language model; Meta model; Metamodeling; Speech detection; Training data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 IEEE International Conference on Big Data, Big Data 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 176404}
}

@CONFERENCE{Plaza-Del-Arco2021580,
	author = {Plaza-Del-Arco, Flor Miriam and Molina-González, M. Dolores and Urena-López, L. Alfonso and Martín-Valdivia, M. Teresa},
	title = {Sinai at iberlef-2021 detoxis task: Exploring features as tasks in a multi-task learning approach to detecting toxic comments},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2943},
	pages = {580 – 590},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115322778&partnerID=40&md5=45a7583dd9e9a29201703ea62d2c86a1},
	affiliations = {Department of Computer Science, Advanced Studies Center in Ict (CEATIC), Universidad de Jaen, Campus Las Lagunillas, Jaen, 23071, Spain},
	abstract = {This paper describes the participation of the SINAI research group at DETOXIS (DEtection of TOxicity in comments In Spanish) shared task at IberLEF 2021. The proposed system follows a Multitask Learning approach where multiple tasks related to toxic comments identification are learned in parallel while using a shared representation. Specifically, we use the dataset features provided by the organizers as tasks along with the combination of polarity classification, emotion classification and offensive language detection tasks to explore if they help in the identification of toxic comments. Our proposal ranked first in both DETOXIS subtasks, toxicity detection and toxicity level detection. © 2021 CEUR-WS. All rights reserved.},
	author_keywords = {BERT; Multi-Task Learning; Sentiment Analysis; Toxic Features},
	keywords = {Classification (of information); Feature extraction; Learning systems; Sentiment analysis; BERT; Emotion classification; Learning approach; Multiple tasks; Multitask learning; Polarity classification; Research groups; Sentiment analysis; Shared representations; Toxic feature; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2021 Iberian Languages Evaluation Forum, IberLEF 2021; Conference date: 21 September 2021; Conference code: 171720}
}

@CONFERENCE{Bölücü202144,
	author = {Bölücü, Necva and Canbay, Pelin},
	title = {Hate Speech and Offensive Content Identification with Graph Convolutional Networks},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {44 – 51},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134220654&partnerID=40&md5=079a9112e0cdcaa277832ff9fd4c689f},
	affiliations = {Department of Computer Engineering, Hacettepe University, Ankara, Turkey; Department of Computer Engineering, Sutcu Imam University, Kahramanmaras, Turkey},
	abstract = {Social media is a widespread platform and has a huge impact on society. There is a massive amount of data that plays an important role in expressing ideas, thoughts, emotions, etc. Identifying hate speech and offensive content on social media has gained attention recently. This is also the goal of the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) 2021 Challenge in both English and Hindi languages. In this paper, we describe the system based on Graph Convolutional Networks (GCN) submitted by our team HUNLP for Subtask 1A and 1B. Our system has achieved a Macro F1-score of 82.15% for English Subtask 1A and ranked 2nd in the leader-board. Moreover, our model has achieved 71.94% and 78.95% for Hindi and Marathi Subtask 1A on the official test set, respectively. Also, we have achieved Macro F1-score of 62.96% for English Subtask 1B. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Graph Convolutional Network; Hate Speech; Social Media},
	keywords = {Convolution; Content identifications; Convolutional networks; European languages; F1 scores; Graph convolutional network; Hate speech; Social media; Subtask; Test sets; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Chuang2021114,
	author = {Chuang, Yung-Sung and Gao, Mingye and Luo, Hongyin and Glass, James and Lee, Hung-Yi and Chen, Yun-Nung and Li, Shang-Wen},
	title = {Mitigating Biases in Toxic Language Detection through Invariant Rationalization},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {114 – 120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127053168&partnerID=40&md5=cc31308eb1d18baa6408bae260c23aa9},
	affiliations = {National Taiwan University, Taiwan; MIT CSAIL, United States; Amazon AI, United States},
	abstract = {Automatic detection of toxic language plays an essential role in protecting social media users, especially minority groups, from verbal abuse. However, biases toward some attributes, including gender, race, and dialect, exist in most training datasets for toxicity detection. The biases make the learned models unfair and can even exacerbate the marginalization of people. Considering that current debiasing methods for general natural language understanding tasks cannot effectively mitigate the biases in the toxicity detectors, we propose to use invariant rationalization (INVRAT), a game-theoretic framework consisting of a rationale generator and predictors, to rule out the spurious correlation of certain syntactic patterns (e.g., identity mentions, dialect) to toxicity labels. We empirically show that our method yields lower false positive rate in both lexical and dialectal attributes than previous debiasing methods.  © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Game theory; Natural language processing systems; 'current; Automatic Detection; De-biasing; Language detection; Marginalization; Minority groups; Rationalisation; Social media; Toxicity detection; Training dataset; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference date: 6 August 2021; Conference code: 182536}
}

@ARTICLE{Madukwe2021273,
	author = {Madukwe, Kosisochukwu Judith and Gao, Xiaoying and Xue, Bing},
	title = {What Emotion Is Hate? Incorporating Emotion Information into the Hate Speech Detection Task},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13032 LNAI},
	pages = {273 – 286},
	doi = {10.1007/978-3-030-89363-7_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119325608&doi=10.1007%2f978-3-030-89363-7_21&partnerID=40&md5=cd3f34448bbbffa2c53064d068445ac0},
	affiliations = {School of Engineering and Computer Science, Victoria University of Wellington, P.O. Box 600, Wellington, 6012, New Zealand},
	abstract = {Finding ethical, platform-independent, computationally efficient methods of adding contextual information to the hate speech detection task is difficult. Methods that rely only on the text for successful classification are of extreme importance. Emotion information extracted from text has been shown to be effective for sentiment analysis and thus we hypothesize that it could have a potential for hate speech. In this study, we propose several methods of introducing emotions into the task of hate speech detection. Using an emotion lexicon, we counter-fitted pre-trained word embeddings (Word2Vec, GloVe, FastText) and also generated a binary and a weighted emotional embedding vector. These were used as features for classification on four publicly available hate speech datasets. Our results and analysis demonstrate that the inclusion of emotion information especially anger, sadness, disgust, fear are helpful for hate speech detection. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Emotion information; Emotion lexicon; Hate speech detection; Natural language processing; Text classification; Word embedding},
	keywords = {Classification (of information); Sentiment analysis; Speech; Speech recognition; Computationally efficient; Detection tasks; Embeddings; Emotion information; Emotion lexicon; Hate speech detection; Platform independent; Speech detection; Text classification; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021; Conference date: 8 November 2021 through 12 November 2021; Conference code: 267459}
}

@CONFERENCE{Khan2021967,
	author = {Khan, Yakoob and Ma, Weicheng and Vosoughi, Soroush},
	title = {Lone Pine at SemEval-2021 Task 5: Fine-Grained Detection of Hate Speech Using BERToxic},
	year = {2021},
	journal = {SemEval 2021 - 15th International Workshop on Semantic Evaluation, Proceedings of the Workshop},
	pages = {967 – 973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125367719&partnerID=40&md5=8411b7979c351362ca09f1aac0406bfd},
	affiliations = {Department of Computer Science, Dartmouth College, United States},
	abstract = {This paper describes our approach to the Toxic Spans Detection problem (SemEval-2021 Task 5). We propose BERToxic, a system that fine-tunes a pre-trained BERT model to locate toxic text spans in a given text and utilizes additional post-processing steps to refine the boundaries. The post-processing steps involve (1) labeling character offsets between consecutive toxic tokens as toxic and (2) assigning a toxic label to words that have at least one token labeled as toxic. Through experiments, we show that these two post-processing steps improve the performance of our model by 4.16% on the test set. We also studied the effects of data augmentation and ensemble modeling strategies on our system. Our system significantly outperformed the provided baseline and achieved an F1-score of 0.683, placing Lone Pine in the 17th place out of 91 teams in the competition. © 2021 Association for Computational Linguistics.},
	keywords = {Speech recognition; Data augmentation; Data ensemble; Detection problems; Ensemble models; Fine grained; Labelings; Performance; Post-processing; Processing steps; Test sets; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 15th International Workshop on Semantic Evaluation, SemEval 2021; Conference date: 5 August 2021 through 6 August 2021; Conference code: 182482}
}

@CONFERENCE{Farooqi202163,
	author = {Farooqi, Zaki Mustafa and Ghosh, Sreyan and Shah, Rajiv Ratn},
	title = {Leveraging Transformers for Hate Speech Detection in Conversational Code-Mixed Tweets},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {63 – 74},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134195085&partnerID=40&md5=161fbea2ffad68ea076a8893e8ef16a0},
	affiliations = {Multimodal Digital Media Analysis Lab., Indraprastha Institute of Information Technology, Delhi, India},
	abstract = {In the current era of the internet, where social media platforms are easily accessible for everyone, people often have to deal with threats, identity attacks, hate, and bullying due to their association with a cast, creed, gender, religion, or even acceptance or rejection of a notion. Existing works in hate speech detection primarily focus on individual comment classification as a sequence labelling task and often fail to consider the context of the conversation. The context of a conversation often plays a substantial role when determining the author’s intent and sentiment behind the tweet. This paper describes the system proposed by team MIDAS-IIITD for HASOC 2021 subtask 2, one of the first shared tasks focusing on detecting hate speech from Hindi-English code-mixed conversations on Twitter. We approach this problem using neural networks, leveraging the transformer’s cross-lingual embeddings and further fine-tuning them for low-resource hate-speech classification in transliterated Hindi text. Our best performing system, a hard voting ensemble of Indic-BERT, XLM-RoBERTa, and Multilingual BERT, achieved a macro F1 score of 0.7253, placing us 1st on the overall leaderboard standings. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-Mixed Languages; Hate Speech; Hindi-English; Offensive Tweets; Transformers},
	keywords = {Codes (symbols); Social networking (online); Text processing; 'current; Code-mixed language; Hate speech; Hindi-english; Offensive tweet; Sequence Labeling; Social media platforms; Speech detection; Subtask; Transformer; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Moy2021929,
	author = {Moy, Tian Xiang and Raheem, Mafas and Logeswaran, Rajasvaran},
	title = {Hate Speech Detection in English and Non-English Languages: A Review of Techniques and Challenges},
	year = {2021},
	journal = {Webology},
	volume = {18},
	number = {Special Issue},
	pages = {929 – 938},
	doi = {10.14704/WEB/V18SI05/WEB18272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119653812&doi=10.14704%2fWEB%2fV18SI05%2fWEB18272&partnerID=40&md5=28cf050e3c64c7fd1265179b0d679d14},
	affiliations = {School of Computing, Asia Pacific University of Technology & Innovation, Kuala Lumpur, Malaysia},
	abstract = {The exponential growth of social media has spurred an increase in the propagation of hate nowadays. Recent evidence shows that hate speech on social media is detrimental to the mental and physical health of individuals. Thus, there is an emerging need for automated hate speech detection. Automated hate speech detection rests on the intersection between Natural Language Processing (NLP) techniques and machine learning models. An introduction of NLP and its utilities, as well as commonly employed features and classification methods in hate speech detection, are discussed. Hate speech detection in non-English languages is needed to tackle this emergent issue in countries where multiple languages are used. Hence, an overview of the current literature on hate speech detection in non-English languages are covered too. Challenges in the field of hate speech detection are explored and the importance of standardized methodologies for building corpora and data sets are emphasized. © 2021},
	author_keywords = {Deep Learning; Hate Speech; Machine Learning; Natural Language Processing; Social Media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Bose2021113,
	author = {Bose, Tulika and Illina, Irina and Fohr, Dominique},
	title = {Unsupervised Domain Adaptation in Cross-corpora Abusive Language Detection},
	year = {2021},
	journal = {SocialNLP 2021 - 9th International Workshop on Natural Language Processing for Social Media, Proceedings of the Workshop},
	pages = {113 – 122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127915814&partnerID=40&md5=bc9d77a8a0e86760c512246c72d23a6a},
	affiliations = {Universite de Lorraine, CNRS, Inria, LORIA, Nancy, F-54000, France},
	abstract = {The state-of-the-art abusive language detection models report great in-corpus performance, but underperform when evaluated on abusive comments that differ from the training scenario. As human annotation involves substantial time and effort, models that can adapt to newly collected comments can prove to be useful. In this paper, we investigate the effectiveness of several Unsupervised Domain Adaptation (UDA) approaches for the task of cross-corpora abusive language detection. In comparison, we adapt a variant of the BERT model, trained on large-scale abusive comments, using Masked Language Model (MLM) fine-tuning. Our evaluation shows that the UDA approaches result in sub-optimal performance, while the MLM fine-tuning does better in the cross-corpora setting. Detailed analysis reveals the limitations of the UDA approaches and emphasizes the need to build efficient adaptation methods for this task. © SocialNLP 2021 Natural Language Processing for Social Media},
	keywords = {Natural language processing systems; Detection models; Domain adaptation; Fine tuning; Human annotations; Language detection; Language model; Large-scales; Performance; State of the art; Training scenario; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 9th International Workshop on Natural Language Processing for Social Media, SocialNLP 2021; Conference date: 10 June 2021; Conference code: 182490}
}

@CONFERENCE{Utami202178,
	author = {Utami, Ema and Rini and Iskandar, Ahmad Fikri and Raharjo, Suwanto},
	title = {Multi-Label Classification of Indonesian Hate Speech Detection Using One-vs-All Method},
	year = {2021},
	journal = {Proceedings - 2021 IEEE 5th International Conference on Information Technology, Information Systems and Electrical Engineering: Applying Data Science and Artificial Intelligence Technologies for Global Challenges During Pandemic Era, ICITISEE 2021},
	pages = {78 – 82},
	doi = {10.1109/ICITISEE53823.2021.9655883},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124514302&doi=10.1109%2fICITISEE53823.2021.9655883&partnerID=40&md5=ee168824520c9be277123a3e53ee536a},
	affiliations = {Universitas Amikom Yogyakarta, Magister Of Informatics Engineering, Yogyakarta, Indonesia; IST AKPRIND, Department Of Informatics Engineering, Yogyakarta, Indonesia},
	abstract = {Hate speech is an act of communication carried out against specific targets, categories, and levels related to abusive language, even though abusive language is not necessarily. Currently, text mining technology is one approach that can overcome hate speech. Conventional Hate speech expressed in Indonesian Language on Twitter tranform single label to multi-label. The novelty of this research to classifying multi-label hate speech in Indonesian Language using One-vsAll (OvA) that testing on several models of machine learning. Multi-Label on hate speech using in this research is Abusive, HS_Weak, HS_Moderate, and HS_Strong, then transform into new label OvA. There are two scenarios of feature extraction: Bag of Word (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF). The experimental results showed that the Artificial Neural Network (ANN) classifier with the One-vs-All method, BoW and Chi-square feature selection got the best accuracy of 86.96%  © 2021 IEEE.},
	author_keywords = {Chi-Square; Classification; Hate Speech; Multi-label; One-vsAll},
	keywords = {Classification (of information); Feature extraction; Inverse problems; Neural networks; Speech communication; Speech recognition; Text processing; Bag of words; Chi-square; Hate speech; Indonesian languages; Mining technology; Multi-labels; One vs alls; One-vsall; Speech detection; Text-mining; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 5th IEEE International Conference on Information Technology, Information Systems and Electrical Engineering, ICITISEE 2021; Conference date: 24 November 2021 through 25 November 2021; Conference code: 176116}
}

@CONFERENCE{Boishakhi20214496,
	author = {Boishakhi, Fariha Tahosin and Shill, Ponkoj Chandra and Alam, Md. Golam Rabiul},
	title = {Multi-modal Hate Speech Detection using Machine Learning},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
	pages = {4496 – 4499},
	doi = {10.1109/BigData52589.2021.9671955},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125325596&doi=10.1109%2fBigData52589.2021.9671955&partnerID=40&md5=d34f4d9cfb3d8a78557dcbc8e0cf3cd2},
	affiliations = {BRAC University, Computer Science and Engineering, Dhaka, Bangladesh},
	abstract = {With the continuous growth of internet users and media content, it is very hard to track down hateful speech in audio and video. Converting video or audio into text does not detect hate speech accurately as human sometimes uses hateful words as humorous or pleasant in sense and also uses different voice tones or show different action in the video. The state-of-the-art hate speech detection models were mostly developed on a single modality. In this research, a combined approach of multi-modal system has been proposed to detect hate speech from video contents by extracting feature images, feature values extracted from the audio, text and used machine learning and Natural language processing. © 2021 IEEE.},
	author_keywords = {Audio hate Speech; Hate Speech detection; Machine Learning; Multi-modal Hate Speech detection; Video hate Speech},
	keywords = {Learning algorithms; Machine learning; Natural language processing systems; Speech recognition; Audio hate speech; Hate speech detection; Internet media; Internet users; Machine-learning; Multi-modal; Multi-modal hate speech detection; Speech detection; Video hate speech; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 2021 IEEE International Conference on Big Data, Big Data 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 176404; All Open Access, Green Open Access}
}

@ARTICLE{Duong2021138,
	author = {Duong, Phuc H. and Chung, Cuong C. and Vo, Loc T. and Nguyen, Hien T. and Ngo, Dat},
	title = {Detecting Hate Speech Contents Using Embedding Models},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13116 LNCS},
	pages = {138 – 146},
	doi = {10.1007/978-3-030-91434-9_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121866066&doi=10.1007%2f978-3-030-91434-9_13&partnerID=40&md5=2288748e233731e67a8a5ae6aa2b7469},
	affiliations = {Artificial Intelligence Laboratory, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Viet Nam; Department of Economic Mathematics, Banking University of Ho Chi Minh City, Ho Chi Minh City, Viet Nam; NewAI Research, Ho Chi Minh City, Viet Nam},
	abstract = {The rise of hate speech contents on social network platforms has recently become a topic of interest. There have been a lot of studies to develop systems that can automatically detect hate speech contents. In this paper, we propose a knowledge-rich solution to hate speech detection by incorporating hate speech embeddings to generate a more accurate representation of the given text. To obtain the hate speech embeddings, we construct a hate speech dictionary in a semi-supervised fashion. We conduct experiments on two popular datasets, which show that the combination of word embeddings and hate speech embeddings can produce promising results when compared with the methods that employ large-scale pre-trained language models. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Hate speech detection; Natural language processing},
	keywords = {Deep learning; Large dataset; Natural language processing systems; Speech; Speech recognition; Deep learning; Embeddings; Hate speech detection; Language model; Large-scales; Network platforms; Semi-supervised; Speech content; Speech detection; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 10th International Conference on Computational Data and Social Networks, CSoNet 2021; Conference date: 15 November 2021 through 17 November 2021; Conference code: 270069}
}

@CONFERENCE{Caparrós-Laiz202175,
	author = {Caparrós-Laiz, Camilo and García-Díaz, José Antonio and Valencia-García, Rafael},
	title = {Detecting Hate Speech on English and Indo-Aryan Languages with BERT and Ensemble learning},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {75 – 81},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134221570&partnerID=40&md5=186aecd53b8a1bdd71c9be107d561bc8},
	affiliations = {Facultad de Informática, Universidad de Murcia, Campus de Espinardo, Murcia, 30100, Spain},
	abstract = {The increasing use of social media platforms is making possible the communication between people around the world, including those with conflicting ideologies and cultures. However, some people use offensive language instead of having a polite conversation either because of little education or with the intention of intoxicating the debate. In this paper we analyze the results achieved by the UMUTeam of applying BERT models, either separate or combined with other popular models, for the HASOC’2021 shared-task for identifying offensive language in English, Hindi and Marathi. Our bests results are achieved with BERT for English classification subtask (1A), in which we reached a macro F1-score of 80.13%, and with ensemble learning for the rest of the subtasks, reaching macro F1-scores of 62.89% in English (subtask 1B), 75.20% and 51.67% in Hindi (subtasks 1A and 1B, respectively), and 84.23% in Marathi. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Deep-learning; Feature engineering; Hate-speech detection; Low-resource languages; Transformers},
	keywords = {Speech recognition; Deep-learning; Ensemble learning; F1 scores; Feature engineerings; Hate-speech detection; Low resource languages; Offensive languages; Speech detection; Subtask; Transformer; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Razdan2021,
	author = {Razdan, Aditya and Shridevi, S.},
	title = {Hate Speech Detection using ML algorithms},
	year = {2021},
	journal = {Proceedings - 2021 1st IEEE International Conference on Artificial Intelligence and Machine Vision, AIMV 2021},
	doi = {10.1109/AIMV53313.2021.9670987},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125008230&doi=10.1109%2fAIMV53313.2021.9670987&partnerID=40&md5=1cee80de50fb04185a1cef46fc15175a},
	affiliations = {Vellore Institute of Technology, School of Computer Science and Engineering, Chennai, India},
	abstract = {Social media is a growing platform where different users share their ideas and sentiments towards different topics because users spend a lot of time expressing their thoughts and views. There are various researches going on in detecting the sentiments of the user's comments but the main sentiment factor remain undiagnosed. In this paper, the aim is to detect hate speeches. The dataset was preprocessed and cleaned and cleaned text was explored to get a better understanding. Salient features were extracted from the data to train our model and to identify the hate sentiments of tweets. The vector model is created using genism to learn the relationship between words and based on that sentence are labeled. Stop words and port stemmer are used to filter unwanted data to build the vocabulary using CountVectorizer before it is used for model building. Using various machine algorithms, comparative study is done to check the performance of algorithms and promising results are attained.  © 2021 IEEE.},
	author_keywords = {a bag of words; evaluation metric; model; NLP; sentiment analysis},
	keywords = {Sentiment analysis; Speech recognition; A bag of word; Bag of words; Evaluation metrics; Learn+; Salient features; Sentiment analysis; Social media; Speech detection; Stop word; Vector-modeling; Information retrieval},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 1st IEEE International Conference on Artificial Intelligence and Machine Vision, AIMV 2021; Conference date: 24 September 2021 through 26 September 2021; Conference code: 176354}
}

@CONFERENCE{Balouchzahi2021603,
	author = {Balouchzahi, F. and Bashang, S. and Sidorov, G. and Shashirekha, H.L.},
	title = {CoMaTa OLI-Code-mixed Malayalam and Tamil Offensive Language Identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {603 – 614},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124358266&partnerID=40&md5=f8242be9767e11d84bfab7aa6344949e},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico; Canara Bank School of Management Studies, Bangalore University, India; Department of Computer Science, Mangalore University, Mangalore, India},
	abstract = {Offensive Language Identification (OLI) in code-mixed under-resourced Dravidian languages is a challenging task due to the complex characteristics of code-mixed text and scarcity of digital resources and tools to process these languages. This paper describes the strategy proposed by our team MUCIC for the’Dravidian-CodeMix-HASOC2021’ shared task which includes two tasks: Task 1 and Task 2, with the aim of classifying a given social media post/comment into one of two predefined categories: Offensive (OFF) and Not-Offensive (NOT) in both the tasks. While Task 1 aims at identifying Hate Speech (HS) contents in Tamil language in native script, Task 2 focuses on identifying HS contents in Tamil-English (Ta-En) and Malayalam-English (Ma-En) code-mixed texts in Roman script. Training the Machine Learning (ML) classifiers using the most frequent char and word n-grams, the proposed methodology secured 2nd, 1st, and 2nd ranks for Tamil, and Ta-En and Ma-En code-mixed texts with average weighted F1-scores of 0.852, 0.678, and 0.762 respectively. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-mixed; Dravidian languages; HASOC; Machine Learning; n-grams},
	keywords = {Computational linguistics; Learning algorithms; Natural language processing systems; Code-mixed; Dravidian language; HASOC; Identification codes; Language identification; Machine-learning; Malayalams; N-grams; Offensive languages; Speech content; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Sreelakshmi2021233,
	author = {Sreelakshmi, K. and Premjith, B. and Soman, K.P.},
	title = {Transformer based offensive language identification in spanish?},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2943},
	pages = {233 – 239},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115331593&partnerID=40&md5=b00d0bafa13d78a2c181ff9763137dcb},
	affiliations = {Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India},
	abstract = {This paper presents the work done for the shared task on Me- OffendEs@IberLEF 2021 Non-contextual binary classification for Mexican Spanish. We implemented two deep neural network architectures such as a network containing a Bi-LSTM, LSTM, fully connected layer and another with a Bi-LSTM and LSTM stack. In addition to that we also implemented a BERT classifier. Among the three models the BERT exhibited better training performance, and we submitted the predictions based on the same. BERT performed well compared to other languages as it has pretrained embeddings that are trained on huge corpus of multiple languages. © 2021 CEUR-WS. All rights reserved.},
	author_keywords = {Bidirectional Encoder Representations from Transformers; Bidirectional Long Short-Term Memory; Long short-term memory},
	keywords = {Brain; Deep neural networks; Multilayer neural networks; Natural language processing systems; Network architecture; Signal encoding; Bidirectional encoder representation from transformer; Bidirectional long short-term memory; Binary classification; Embeddings; Language identification; Neural network architecture; Offensive languages; Performance; Prediction-based; Three models; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 Iberian Languages Evaluation Forum, IberLEF 2021; Conference date: 21 September 2021; Conference code: 171720}
}

@CONFERENCE{Excell202155,
	author = {Excell, Elizabeth and Moubayed, Noura Al},
	title = {Towards Equal Gender Representation in the Annotations of Toxic Language Detection},
	year = {2021},
	journal = {GeBNLP 2021 - 3rd Workshop on Gender Bias in Natural Language Processing, Proceedings},
	pages = {55 – 65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123737061&partnerID=40&md5=8391e697b99295ac4157e80ea5932df8},
	affiliations = {Department of Computer Science, Durham University, Durham, United Kingdom},
	abstract = {Classifiers tend to propagate biases present in the data on which they are trained. Hence, it is important to understand how the demographic identities of the annotators of comments affect the fairness of the resulting model. In this paper, we focus on the differences in the ways men and women annotate comments for toxicity, investigating how these differences result in models that amplify the opinions of male annotators. We find that the BERT model associates toxic comments containing offensive words with male annotators, causing the model to predict 67.7% of toxic comments as having been annotated by men. We show that this disparity between gender predictions can be mitigated by removing offensive words and highly toxic comments from the training data. We then apply the learned associations between gender and language to toxic language classifiers, finding that models trained exclusively on female-annotated data perform 1.8% better than those trained solely on male-annotated data, and that training models on data after removing all offensive words reduces bias in the model by 55.5% while increasing the sensitivity by 0.4%.  ©2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Gender predictions; Language detection; Training data; Training model; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 3rd Workshop on Gender Bias in Natural Language Processing, GeBNLP 2021; Conference date: 5 August 2021; Conference code: 175261}
}

@CONFERENCE{Huang2021346,
	author = {Huang, Xi and Xu, Minxuan},
	title = {An Inter and Intra Transformer for Hate Speech Detection},
	year = {2021},
	journal = {2021 3rd International Academic Exchange Conference on Science and Technology Innovation, IAECST 2021},
	pages = {346 – 349},
	doi = {10.1109/IAECST54258.2021.9695652},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126999557&doi=10.1109%2fIAECST54258.2021.9695652&partnerID=40&md5=0f6e7cc3f8dc36f1d47c63811e526a46},
	affiliations = {University of Toronto, Computer Science, Toronto, M5S 1A1, Canada; Arts and Sciences the Ohio State University, Ohio, 43201, United States},
	abstract = {Hate speech is prevalent in the Internet environment, under circumstances of anonymity and physical distance on the Web. Hate speech detection has also had an increasing trend of development. In recent years, successful hate speech detection models have been developed, such as using CNN, LSTM, but they lack a sufficient amount of discriminative power. In order to tackle the task of hate speech detection, this paper introduces the use of center loss - known for its applications in image understanding - on top of the basis of the Transformer architecture. Our model can become more discriminative with the help of the center loss application. We performed experiments to validate the performance of our proposal using a hate speech detection dataset of manually labeled Wikipedia comments. Our experiments show that this method can outperform previous architectures for hate speech detection with an accuracy of 94.08% and an F1-score of 68.46% on the hate speech detection dataset.  © 2021 IEEE.},
	author_keywords = {Attention mechanism; deep neural network; hate speech; natural language processing},
	keywords = {Long short-term memory; Natural language processing systems; Network architecture; Speech; Speech recognition; Attention mechanisms; Detection models; Discriminative power; F1 scores; Hate speech; Internet environment; ITS applications; Performance; Speech detection; Wikipedia; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 3rd International Academic Exchange Conference on Science and Technology Innovation, IAECST 2021; Conference date: 10 December 2021 through 12 December 2021; Conference code: 177076}
}

@CONFERENCE{Alsafari2021863,
	author = {Alsafari, Safa and Sadaoui, Samira},
	title = {Semi-Supervised Self-Learning for Arabic Hate Speech Detection},
	year = {2021},
	journal = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
	pages = {863 – 868},
	doi = {10.1109/SMC52423.2021.9659134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124282969&doi=10.1109%2fSMC52423.2021.9659134&partnerID=40&md5=a7916f690bbfc8713ac23586ad4ca14f},
	affiliations = {University of Regina, Department of Computer Science, Regina, Canada},
	abstract = {One key for improving hate speech detection performance is to have a textual training corpus that is vast and confidently labeled. This paper develops a semi-supervised learning approach with self-training to benefit from the abundant amount of social media content and develop a robust hate speech classifier for future predictions. The classifier is self-trained iteratively using the most confident pseudo labels obtained from a large-scale unlabelled Twitter corpus. We demonstrate our approach's efficacy and the high quality of the produced supervised hate speech dataset through experiments.  © 2021 IEEE.},
	author_keywords = {Deep Learning; Hate Speech; Self Learning; Semi-supervised Learning; Text Vectorization; Twitter; Word Embedding},
	keywords = {Deep learning; Speech; Speech recognition; Deep learning; Embeddings; Hate speech; Self-learning; Semi-supervised; Semi-supervised learning; Speech detection; Text vectorization; Vectorization; Word embedding; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 2021 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2021; Conference date: 17 October 2021 through 20 October 2021; Conference code: 176213}
}

@CONFERENCE{Vo2021,
	author = {Vo, Hanh Hong-Phuc and Trung Tran, Hieu and Luu, Son T.},
	title = {Automatically Detecting Cyberbullying Comments on Online Game Forums},
	year = {2021},
	journal = {Proceedings - 2021 RIVF International Conference on Computing and Communication Technologies, RIVF 2021},
	doi = {10.1109/RIVF51545.2021.9642116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124104668&doi=10.1109%2fRIVF51545.2021.9642116&partnerID=40&md5=c30241dd3138cbd35ef351cdfe1adec6},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {Online game forums are popular to most of game players. They use it to communicate and discuss the strategy of the game, or even to make friends. However, game forums also contain abusive and harassment speech, disturbing and threatening players. Therefore, it is necessary to automatically detect and remove cyberbullying comments to keep the game forum clean and friendly. We use the Cyberbullying dataset collected from World of Warcraft (WoW) and League of Legends (LoL) forums and train classification models to automatically detect whether a comment of a player is abusive or not. The result obtains 82.69% of macro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the Toxic-BERT model on the Cyberbullying dataset. © 2021 IEEE.},
	author_keywords = {Bert; Cyberbullying; Deep neural network; Game forums; Machine learning; Text classification},
	keywords = {Classification (of information); Computer crime; Social networking (online); Text processing; Bert; Classification models; Cyber bullying; F1 scores; Game forum; Game players; On-line games; Text classification; World of Warcraft; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 15th RIVF International Conference on Computing and Communication Technologies, RIVF 2021; Conference date: 2 December 2021 through 4 December 2021; Conference code: 175722; All Open Access, Green Open Access}
}

@CONFERENCE{Yu2021319,
	author = {Yu, Wentao and Boenninghoff, Benedikt and Kolossa, Dorothea},
	title = {Hybrid Representation Fusion for Twitter Hate Speech Identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {319 – 329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134196362&partnerID=40&md5=98179331eed2c9160ddd02df6db0fe81},
	affiliations = {Institute of Communication Acoustics, Ruhr University, Bochum, Germany},
	abstract = {The amount and impact of hate speech on social media is already alarming, causing harm for individuals and societies, yet it still keeps increasing. It has been reported that hate speech is strongly related to hate crimes and suicide rates. To stop hate speech on social media, online automatic approaches for hate speech detection in text have thus been drawing wide attention in the last decade. In this work, we take up the HASOC-21 shared tasks, which focus on hate speech and offensive content identification in English. Two subtasks are addressed—one to identify the presence of any form of hate, offensive and profane content in a post, the other to discriminate between these three types of problematic content. We propose a hybrid representation fusion (HRF) structure, using both TF-IDF and BERTweet-based representations. Specifically, a Convolutional-BiLSTM (CBLSTM) network is used to extract semantic information from the BERTweet embeddings. Finally, we use the cosine similarity between different types of features as a reliability measure. We compare the performance between the proposed model with and without cosine similarity as an additional reliability measure. The former could reduce the standard deviation of the macro f1 score in a 10-fold cross-validation by over 27.27% for subtask A and 22.22% for subtask B, respectively. In the HASOC-21 ranking, our approach achieved an 80.13% macro F1 score for subtask A and 64.82% for subtask B on the official HASOC-21 test set. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERTweet; CBLSTM; Cosine Similarity; Feature Fusion; Hate Speech; TF-IDF},
	keywords = {Social networking (online); Speech recognition; Bertweet; Convolutional-BiLSTM; Cosine similarity; Features fusions; Hate speech; Hybrid representations; Reliability measure; Social media; Subtask; TF-IDF; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Ashok Kumar2021158,
	author = {Ashok Kumar, P.M. and Varalakshmi, K.},
	title = {Hate Speech Detection using Text and Image Tweets Based on Bi-directional Long Short-Term Memory},
	year = {2021},
	journal = {Proceedings of IEEE International Conference on Disruptive Technologies for Multi-Disciplinary Research and Applications, CENTCON 2021},
	pages = {158 – 162},
	doi = {10.1109/CENTCON52345.2021.9688115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126828426&doi=10.1109%2fCENTCON52345.2021.9688115&partnerID=40&md5=8c71006063f9b4a44aa682823326a8a3},
	affiliations = {K L Deemed to Be University, Dept. of Computer Science and Engineering, Andhra Pradesh, India; K L H Deemed to Be University, Dept. of Computer Science and Engineering, Telangana, India},
	abstract = {Due to the obvious exponential growth in the usage of the internet by individuals of all ethnicities and educational backgrounds, dangerous internet media has become a serious concern in today's society. In the automated identification of hazardous text material, distinguishing between offensive speech and offensive language is a major problem. Most of the current approaches revolve around TF-IDF feature extraction, followed by the traditional classification techniques like Support Vector Machines (SVM), Decision Trees etc., As a result, there is a scope of improvement in the Accuracy of Emotion Detection and long training times. Most of the works considered only tweet data only. But in this work, we would like to include image characters and image components also. We propose a technique in this study for automatically classifying tweets on Twitter into two categories: Hate speech, Offensive speech and non-hate speech. A training and testing step are included in the suggested technique. Traditional Tweet preparation procedures such as removing Twitter handles, URLs, punctuation, stop words, and stemming were used. In both testing and training, we pad each tweet to its maximum length based on the vocabulary. This padding can have an impact on how the network works and can have a significant impact on performance and accuracy. The normalized characteristics are supplied into Bi-directional Long Short-Term Memory, which learns bidirectional long-term relationships between time steps in a time series or sequential twitter data. In comparison research, we compare the models utilizing each of these approaches. We used the Kaggle data set to predict Hate, offensive and Neutral Messages. After conducting many tests, we discovered that the suggested technique outperforms state-of-the-art algorithms by more than 90 percent.  © 2021 IEEE.},
	author_keywords = {Bi-directional Long Short-Term Memory (Bi-LSTM); Hate Speech; Tweet; Tweet image; Tweet-pre-processing},
	keywords = {Brain; Decision trees; Social networking (online); Speech; Speech recognition; Support vector machines; Bi-directional; Bi-directional long short-term memory; Exponential growth; Hate speech; Internet media; Pre-processing; Speech detection; Tweet; Tweet image; Tweet-pre-processing; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2021 IEEE International Conference on Disruptive Technologies for Multi-Disciplinary Research and Applications, CENTCON 2021; Conference date: 19 November 2021 through 21 November 2021; Conference code: 176947}
}

@CONFERENCE{Sevani2021,
	author = {Sevani, Nina and Soenandi, Iwan A. and Adianto and Wijaya, Jeremy},
	title = {Detection of Hate Speech by Employing Support Vector Machine with Word2Vec Model},
	year = {2021},
	journal = {7th International Conference on Electrical, Electronics and Information Engineering: Technological Breakthrough for Greater New Life, ICEEIE 2021},
	doi = {10.1109/ICEEIE52663.2021.9616721},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123589771&doi=10.1109%2fICEEIE52663.2021.9616721&partnerID=40&md5=7bc9a11c1d5ac4c4e8b98de8a7ceb46e},
	affiliations = {Krida Wacana Christian University, Informatics Department, Jakarta, Indonesia},
	abstract = {Social media can be seen as one prominent assimilation of technology into human life interaction. Its presence is now likely inseparable to us and its usage, whether individually or communally, evidently has been impactful by means of news spread-both positive and negative ones. As a highlight, Indonesia records more than 3, 640 hate speech cases from 2018 to this day. This issue has been the main drive of our research. We aim to produce a model for hate speech detection posted on a social media platform. The data was obtained from github-a hosting provider, consisting of tweets. Word2vec was employed as the method for feature extraction while support vector machine (SVM) with RBF as kernel function was used for data classification. The model was built and tested with a 70:30 ratio of data training and testing, in which we achieved the highest accuracy level of 85% with the settings of gamma =0.1 and C-value =10. The accuracy dropped to 69.7% when the model was tested with different datasets. With the development of hate speech detection models, we are optimistic towards a better society where social media users are less prone to negatively-intended information spread. © 2021 IEEE.},
	author_keywords = {Hate speech; Social media; Support vector machine; Tweets; Word2vec},
	keywords = {Digital storage; Social networking (online); Speech; Speech recognition; Hate speech; Human lives; Indonesia; Main drive; Social media; Social media platforms; Speech detection; Support vectors machine; Tweet; Word2vec; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 7th International Conference on Electrical, Electronics and Information Engineering, ICEEIE 2021; Conference date: 2 October 2021; Conference code: 175061}
}

@CONFERENCE{Biradar2021680,
	author = {Biradar, Shankar and Saumya, Sunil and Chauhan, Arun},
	title = {mBERT based model for identification of offensive content in south Indian languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {680 – 687},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124338180&partnerID=40&md5=7abfcae56ce85d9f9a2965678c34628c},
	affiliations = {Indian Institute of Information Technology, Dharwad Graphic Era University, Dehradun, India},
	abstract = {In recent years, there has been a lot of focus on offensive content. The amount of offensive content generated by social media is increasing at an alarming rate. It created a greater need to address this issue than ever before. To address these issues, the organizers of “Dravidian-Code Mixed HASOC-2021” have created two challenges. Task 1 involves identifying offensive content in Malayalam data, whereas Task 2 includes Malayalam and Tamil Code Mixed Sentences. Our team participated in Task 2. We used multilingual BERT to extract features in our proposed model, and we used two different classifiers, Support Vector Machine (SVM) and Deep Neural Network (DNN), on the extracted features. In addition, we used the proposed data to evaluate the performance of a monolingual BERT classifier. Our best performing model monolingual Bert received a weighted F1 score of 0.70 for Malayalam data, ranking fifth; we also received a weighted F1 score of 0.573 for Tamil Code Mixed data, ranking twelfth. © 2021 Copyright for this paper by its authors.},
	author_keywords = {CodeMixed; mBERT; Offensive; SVM},
	keywords = {Codes (symbols); Support vector machines; Codemixed; Data rankings; F1 scores; Indian languages; Malayalams; MBERT; Offensive; Performance; Social media; Support vectors machine; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Raza2021774,
	author = {Raza, Muhammad Owais and Khan, Qaisar and Soomro, Ghulam Muhammad},
	title = {Urdu Abusive Language Detection using Machine Learning},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {774 – 783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134211002&partnerID=40&md5=1ec7ad3e97f77638f7b1ae82af3fca3c},
	affiliations = {Mehran University of Engineering and Technology, Indus Hwy, Sindh, Jamshoro, 76062, Pakistan; Sunway University, 5 Jalan University, Bandar Sunway, Selangor, Petaling Jaya, 47500, Malaysia; Mehran University Institute of Science, Technology and Development, Indus Hwy, Sindh, Jamshoro, 76062, Pakistan},
	abstract = {The growing popularity of user-generated material on social media has increased the quantity of offensive language used online. The tendency of user-generated material on social media is growing, giving rise to offensive language on these platforms. The offensive language negatively impacts individuals and affects society as a whole, which is why it is a dire need of time to identify vulgar remarks in languages used online. 'Urdu' is one of the many languages used on the internet that faces the same issue. Manually labeling the text as abusive on social media platforms is unattainable due to the production of a large amount of daily content. Therefore, automation (machine learning) is used to create the solution. This study uses machine learning algorithms, namely logistic regression, bagging algorithms, decision trees, and artificial neural networks (ANN), to detect abuse in the text. The F1 score is used as the primary metric, along with accuracy, precision, recall, and AUC-ROC, to measure the performance. Based on the evaluation, the bagging and logistic regression perform equally with an 83% F1 score. However, logistic regression is better for this use case because it is computationally less expensive and requires less effort than the bagging classifier. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Logistic Regression; Machine Learning; NLP; Python; Urdu Abuse Detection},
	keywords = {Decision trees; High level languages; Learning algorithms; Logistic regression; Machine learning; Neural networks; Social networking (online); F1 scores; Labelings; Language detection; Logistics regressions; Machine-learning; Offensive languages; Social media; Social media platforms; Urdu abuse detection; User-generated; Python},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Manerba202134,
	author = {Manerba, Marta Marchiori and Guidotti, Riccardo},
	title = {FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems},
	year = {2021},
	journal = {Proceedings - 2021 IEEE 3rd International Conference on Cognitive Machine Intelligence, CogMI 2021},
	pages = {34 – 43},
	doi = {10.1109/CogMI52975.2021.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128851102&doi=10.1109%2fCogMI52975.2021.00014&partnerID=40&md5=a6ed84678ca52d693dc5b695c08dae76},
	affiliations = {University of Pisa, Pisa, Italy},
	abstract = {At every stage of a supervised learning process, harmful biases can arise and be inadvertently introduced, ul-timately leading to marginalization, discrimination, and abuse towards minorities. This phenomenon becomes particularly im-pactful in the sensitive real-world context of abusive language detection systems, where non-discrimination is difficult to assess. In addition, given the opaqueness of their internal behavior, the dynamics leading a model to a certain decision are often not clear nor accountable, and significant problems of trust could emerge. A robust value-oriented evaluation of models' fairness is therefore necessary. In this paper, we present FairShades, a model-agnostic approach for auditing the outcomes of abusive language detection systems. Combining explainability and fairness evaluation, Fair-Shades can identify unintended biases and sensitive categories towards which models are most discriminative. This objective is pursued through the auditing of meaningful counterfactuals generated within CheckList framework. We conduct several ex-periments on BERT-based models to demonstrate our proposal's novelty and effectiveness for unmasking biases.  © 2021 IEEE.},
	author_keywords = {Abusive Language Detection; Algorithmic Bias; Explainability; Fairness in ML},
	keywords = {Abusive language detection; Algorithmic bias; Algorithmics; Detection system; Explainability; Fairness evaluation; Fairness in ML; Language detection; Marginalization; Real-world; Algorithmic languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 3rd IEEE International Conference on Cognitive Machine Intelligence, CogMI 2021; Conference date: 13 December 2021 through 15 December 2021; Conference code: 178716}
}

@ARTICLE{Aman2021438,
	author = {Aman, Aayush and Krishna, Gopal and Anand, Tushar and Lal, Anubhaw},
	title = {Identification of Offensive Content in Memes},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {290},
	pages = {438 – 445},
	doi = {10.1007/978-981-16-4486-3_49},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115101242&doi=10.1007%2f978-981-16-4486-3_49&partnerID=40&md5=aff8c85c0f2b8d57321735093d8507e4},
	affiliations = {Netaji Subhas Institute of Technology, Patna, India},
	abstract = {Social media is an interactive platform for communication that facilitates the creation or sharing of information, ideas, or other forms of expression among people. With the increased usage of such platforms, automatic detection of multimodal content should be mandatory and so the main focus should be on memes. A meme can be briefly described as an image or video depicting thoughts or ideas of people as well as to express culturally-relevant ideas. Although, memes mostly are captioned photos intended to elicit humor. Since memes are multimodal in nature, posting of irrelevant memes that spread hatred, trolling, cyberbullying is increasing day by day. Awful speech, aggression is explored as single modalities such as text or image. However, combining both the modalities text and image to detect whether it is offensive content or not is a difficult task. Though with the use of a multimodal approach this issue can be dealt with up-to a certain extent. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Classification; Memes; Modalities; Multimodal data; Offensive content},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: International Conference on Data Science, Computation, and Security, IDSCS 2021; Conference date: 16 April 2021 through 17 April 2021; Conference code: 264549}
}

@CONFERENCE{Dandi202117,
	author = {Dandi and Johan, Monika Evelin},
	title = {Detecting Hate Speech on Memes using FixEfficientNet-L2},
	year = {2021},
	journal = {Proceedings of 2021 6th International Conference on New Media Studies, CONMEDIA 2021},
	pages = {17 – 21},
	doi = {10.1109/CONMEDIA53104.2021.9617177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123633688&doi=10.1109%2fCONMEDIA53104.2021.9617177&partnerID=40&md5=3956c3415ee4123d302ad8085e3827dd},
	affiliations = {Information System, Universitas Multimedia Nusantara, Tangerang, Indonesia},
	abstract = {In Indonesia, there were 3,325 cases of hate speech spreading in 2017, based on the popularity of memes and the number of hate speech cases. There are studies that have investigated this topic and get an accuracy of 50-52%. This study will create an image classification model using the FixEfficientNet-L2 architecture with the aim of being able to identify memes that contain hate speech and memes that do not contain hate speech. hate speech. Our research had used a dataset provided by the Facebook AI team, totaling 9,540 data of meme image, and will be divided into three parts of training, validation, and data testing. Our model will use 15 different configurations on the train and test image size. Previously, preprocessing stages were carried out on the data so that the data could be studied by the model. The highest accuracy results obtained from the FixEfficientNet-L2 model with several different configurations in classifying memes are 54.8% for validation and 63% for testing, the accuracy has increased from previous studies of 2% for validation and 10% for testing.  © 2021 IEEE.},
	author_keywords = {Convolutional Neural Network; FixEfficientNet-L2; hate speech; Image Classification; Meme},
	keywords = {Convolutional neural networks; Image classification; Speech recognition; Statistical tests; Classification models; Convolutional neural network; Data testing; Facebook; Fixefficientnet-l2; Hate speech; Images classification; Indonesia; Meme; Validation testing; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 6th International Conference on New Media Studies, CONMEDIA 2021; Conference date: 12 October 2021 through 13 October 2021; Conference code: 175063}
}

@CONFERENCE{Silva2021,
	author = {Silva, Evangeli and Nandathilaka, Maheshi and Dalugoda, Sandupa and Amarasinghe, Thanu and Ahangama, Supunmali and Weerasuriya, G. Thilini},
	title = {Machine Learning-Based Automated Tool to Detect Sinhala Hate Speech in Images},
	year = {2021},
	journal = {Proceedings of 6th International Conference on Information Technology Research: Digital Resilience and Reinvention, ICITR 2021},
	doi = {10.1109/ICITR54349.2021.9657453},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124802744&doi=10.1109%2fICITR54349.2021.9657453&partnerID=40&md5=d8697cd7687ad7d97d9e0fb7abaa6c41},
	affiliations = {Faculty of Information Technology, University of Moratuwa, Moratuwa, Sri Lanka},
	abstract = {Social media platforms have emerged rapidly with technological advancements. Facebook, the most widely used social media platform has been the primary reason for the spread of hatred in Sri Lanka in the recent past. When a post with Sinhala hate content is reported on Facebook, it is translated to the English language before the review of the moderators. In most instances, the translated content has a different context compared to the original post. This results in concluding that the reported post does not violate the established policies and guidelines concerning hate content. Hence, an effective approach needs to be in place to address the aforementioned problem. This research project proposes a solution through an automated tool that is capable of detecting hate content presented in Sinhala phrases extracted from Facebook posts/memes. The tool accepts an image that contains Sinhala texts, extracts the text using a Convolutional Neural Network (CNN) model, preprocesses the text using Natural Language Processing (NLP) techniques, analyzes the preprocessed text to identify hate intensity level and finally classifies the text into four main domains named Political, Race, Religion and Gender using a text classification model.  © 2021 IEEE.},
	author_keywords = {Convolutional Neural Network; Facebook; Hate content; Natural Language Processing; Sinhala language; Text classifier model},
	keywords = {Convolution; Convolutional neural networks; Image classification; Learning algorithms; Machine learning; Natural language processing systems; Social networking (online); Text processing; Translation (languages); Automated tools; Classifier models; Convolutional neural network; Facebook; Hate content; Machine-learning; Sinhalum language; Social media platforms; Text classifier model; Text classifiers; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th International Conference on Information Technology Research, ICITR 2021; Conference date: 1 December 2021 through 3 December 2021; Conference code: 176147}
}

@CONFERENCE{Saraiva20211261,
	author = {Saraiva, Ghivvago D. and Anchiêta, Rafael T. and Neto, Francisco A.R. and Moura, Raimundo S.},
	title = {A Semi-Supervised Approach to Detect Toxic Comments},
	year = {2021},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1261 – 1267},
	doi = {10.26615/978-954-452-072-4_142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123579712&doi=10.26615%2f978-954-452-072-4_142&partnerID=40&md5=264d9ffeed750878ffd041082dd501b2},
	affiliations = {Federal University of Piauí, Brazil; Federal Institute of Piauí, Brazil},
	abstract = {Toxic comments contain forms of non-acceptable language targeted towards groups or individuals. These types of comments become a serious concern for government organizations, online communities, and social media platforms. Although there are some approaches to handle non-acceptable language, most of them focus on supervised learning and the English language. In this paper, we deal with toxic comment detection as a semi-supervised strategy over a heterogeneous graph. We evaluate the approach on a toxic dataset of the Portuguese language, outperforming several graph-based methods and achieving competitive results compared to transformer architectures. © 2021 Incoma Ltd. All rights reserved.},
	keywords = {Social networking (online); English languages; Government organizations; Graph-based methods; Heterogeneous graph; Portuguese languages; Semi-supervised; Social media platforms; Graphic methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: International Conference on Recent Advances in Natural Language Processing: Deep Learning for Natural Language Processing Methods and Applications, RANLP 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 176177; All Open Access, Bronze Open Access}
}

@ARTICLE{Maity2021440,
	author = {Maity, Krishanu and Saha, Sriparna},
	title = {A Multi-task Model for Sentiment Aided Cyberbullying Detection in Code-Mixed Indian Languages},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13111 LNCS},
	pages = {440 – 451},
	doi = {10.1007/978-3-030-92273-3_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121925598&doi=10.1007%2f978-3-030-92273-3_36&partnerID=40&md5=c8bccd77a23087bce886b5bb71bf4efd},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology, Patna, India},
	abstract = {With the expansion of digital sphere and advancement of technology, cyberbullying has become increasingly common, especially among teenagers. In this work, we have created a benchmark Hindi-English code-mixed corpus called BullySent, annotated with bully and sentiment labels for investigating how sentiment label information helps to identify cyberbully in a better way. For a vast portion of India, both of these languages constitute the primary means of communication, and language mixing is common in everyday speech. A multi-task framework called MT-BERT+VecMap based on two different embedding schemes for the efficient representations of code-mixed data, has been developed. Our proposed multi-task framework outperforms all the single-task baselines with the highest accuracy values of 81.12(+/−1.65)% and 77.46(+/−0.99)% for the cyberbully detection task and sentiment analysis task, respectively. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Code-Mixed (Hindi+English); Cyberbullying; Deep multi-task learning; MuRIL BERT; VecMap},
	keywords = {Codes (symbols); Deep learning; Sentiment analysis; Speech communication; Code-mixed (hindi+english); Cyber bullying; Cyberbully; Deep multi-task learning; Indian languages; Label information; Multi tasks; Multi-task model; MuRIL BERT; Vecmap; Computer crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 28th International Conference on Neural Information Processing, ICONIP 2021; Conference date: 8 December 2021 through 12 December 2021; Conference code: 269629}
}

@ARTICLE{Kumar2021670,
	author = {Kumar, Gunjan and Singh, Jyoti Prakash and Kumar, Abhinav},
	title = {A Deep Multi-modal Neural Network for the Identification of Hate Speech from Social Media},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	pages = {670 – 680},
	doi = {10.1007/978-3-030-85447-8_55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115148306&doi=10.1007%2f978-3-030-85447-8_55&partnerID=40&md5=68098a6aedcc8fb5e0b891d7fd3e941d},
	affiliations = {National Institute of Technology Patna, Patna, India; Department of Computer Science & Engineering, Siksha ‘O’ Anusandhan Deemed to be University, Bhubaneswar, India},
	abstract = {Hate speech can be particularized as an intentional and chronic act to harm a single person or a group of individuals. This act can be performed via social networking websites such as Twitter, YouTube, Facebook, and more. Most of the existing approaches for finding hate speech are concentrated on either textual or visual information of the posted social media contents. In this work, a multi-modal system is proposed that uses textual as well as the visual contents of the social media post to classify it into Racist, Sexist, Homophobic, Religion-based hate, Other hate and No hate classes. The proposed multi-modal system uses a convolutional neural network-based model to process text and a pre-trained VGG-16 network to process imagery contents. The performance of the proposed model is tested with the benchmark dataset and it achieved significant performance in classifying social media posts into six different hate classes. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {Hate-speech; Multi-modal; Twitter images},
	keywords = {Benchmarking; Classification (of information); Convolutional neural networks; Deep neural networks; Electronic commerce; Benchmark datasets; Facebook; Multi-modal neural networks; Multimodal system; Social media; Visual content; Visual information; YouTube; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}

@CONFERENCE{Celli2021,
	author = {Celli, Fabio and Lai, Mirko and Duzha, Armend and Bosco, Cristina and Patti, Viviana},
	title = {Policycorpus XL: An Italian corpus for the detection of hate speech against politics},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121248469&partnerID=40&md5=9cb08868914b9376548c287248c220be},
	affiliations = {Research and Development, Gruppo Maggioli, Italy; Dept. of Informatics, University of Turin, Italy},
	abstract = {In this paper we describe the largest corpus annotated with hate speech in the political domain in Italian. Policycorpus XL has 7000 tweets, manually annotated, and a presence of hate labels above 40%, while in other corpora of the same type is usually below 30%. Here we describe the collection of data and test some baseline with simple classification algorithms, obtaining promising results. We suggest that the high amount of hate labels boosts the performance of classifiers, and we plan to release the dataset in a future evaluation campaign. © 2021 for this paper by its author. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Classification algorithm; Large corpora; Performance of classifier; Simple++; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 8th Italian Conference on Computational Linguistics, CLiC-it 2021; Conference date: 26 January 2022 through 28 January 2022; Conference code: 175403}
}

@CONFERENCE{Reimann2021159,
	author = {Reimann, Sebastian and Dakota, Daniel},
	title = {Examining the effects of preprocessing on the detection of offensive language in German tweets},
	year = {2021},
	journal = {KONVENS 2021 - Proceedings of the 17th Conference on Natural Language Processing},
	pages = {159 – 169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119409965&partnerID=40&md5=229175a3e96350f7bb14b15b69a91c5e},
	affiliations = {Uppsala University, Department of Linguistics, Sweden},
	abstract = {Preprocessing is essential for creating more effective features and reducing noise in classification, especially in user-generated data (e.g. Twitter). How each individual preprocessing decision changes an individual classifier’s behavior is not universal. We perform a series of ablation experiments in which we examine how classifiers behave based on individual preprocessing steps when detecting offensive language in German. While preprocessing decisions for traditional classifier approaches are not as varied, we note that pre-trained BERT models are far more sensitive to each decision and do not behave identically to each other. We find that the cause of much variation between classifiers has to do with the interactions specific preprocessing steps have on the overall vocabulary distributions, and, in the case of BERT models, how this interacts with the WordPiece tokenization. © 2021 KONVENS 2021 - Proceedings of the 17th Conference on Natural Language Processing. All Rights Reserved.},
	keywords = {Ablation experiments; Individual classifiers; Offensive languages; Pre-processing step; Reducing noise; Tokenization; User-generated},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 17th Conference on Natural Language Processing, KONVENS 2021; Conference date: 6 September 2021 through 9 September 2021; Conference code: 173594}
}

@CONFERENCE{Jada2021625,
	author = {Jada, Pawan Kalyan and Yasaswini, Konthala and Puranik, Karthik and Sampath, Anbukkarasi and Thangasamy, Sathiyaraj and Thamburaj, Kingston Pal},
	title = {Analyzing Social Media Content for Detection of Offensive Text},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {625 – 635},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134205639&partnerID=40&md5=89419c5e7b00a04ae258e1ad6c493a97},
	affiliations = {Indian Institute of Information Technology, Tiruchirappalli, India; Kongu Engineering College, Tamil Nadu, Erode, India; Sri Krishna Adithya College of Arts and Science, Coimbatore, India; Sultan Idris Education University, Tanjong Malim, Perak, Malaysia},
	abstract = {To tackle the conundrum of detecting offensive comments/posts which are considerably informal, unstructured, miswritten and code-mixed, we introduce two inventive methods in this research paper. Offensive comments/posts on the social media platforms, can affect an individual, a group or underage alike. In order to classify comments/posts in two popular Dravidian languages, Tamil and Malayalam, as a part of the HASOC - DravidianCodeMix FIRE 2021 shared task, we employ two Transformer-based prototypes which successfully stood in the top 8 for all the tasks. The codes for our approach can be viewed and utilized1 © 2021 Copyright for this paper by its authors.},
	author_keywords = {Sequence classification; Transformers; Translation; Transliteration},
	keywords = {Codes (symbols); Fires; Text processing; Malayalams; Media content; Research papers; Sequence classification; Social media; Social media platforms; Transformer; Translation; Transliteration; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Liyanage2021225,
	author = {Liyanage, Oshadhi and Jayakumar, Krishnakripa},
	title = {Hate Speech Detection in Sinhala-English Code-Mixed Language},
	year = {2021},
	journal = {21st International Conference on Advances in ICT for Emerging Regions, ICter 2021 - Proceedings},
	pages = {225 – 230},
	doi = {10.1109/ICter53630.2021.9774816},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130815018&doi=10.1109%2fICter53630.2021.9774816&partnerID=40&md5=cf2249e482846b697ac67d263e9d5e32},
	affiliations = {Informatics Institute of Technology, Department of Computing, Colombo, Sri Lanka},
	abstract = {With the steady increase of user-generated content on the internet, the amount of hate content on the internet is also being rapidly increased. Social media sites, review forums, microblogging sites encourage users to convey their thoughts with minimum restrictions. This leads to expressing hate towards others who do not believe their beliefs. This study focuses on identifying hate speech texts that are written in Sinhala-English code-mixed language (Singlish) which is mostly used by Sri Lankans on the internet. Due to the unavailability of Sinhala-English code-mixed datasets, the dataset was created using comments on YouTube and Facebook. In this research, eight machine learning algorithms and three ensemble approaches were evaluated to detect hate speech in Singlish. Furthermore, their accuracy, precision, recall, and f1-score were evaluated. Afterwards, based on the performance of the considered algorithms, Support Vector Machine (SVM), Multinominal Naïve Bayes (MNB), AdaBoost Classifier, and Logistic Regression classifiers were used to develop ensemble learning-based solutions. In terms of ensemble learning approaches, soft voting, hard voting, and stacking were evaluated. The hard voting approach outperformed other baseline algorithms and ensemble approaches with 84% accuracy and f1-score. © 2021 IEEE.},
	author_keywords = {Ensemble Learning; Hard Voting; Hate Speech detection; Sinhala-English Code-Mixed Language},
	keywords = {Adaptive boosting; Codes (symbols); Logistic regression; Speech recognition; Support vector machines; Ensemble approaches; Ensemble learning; F1 scores; Hard voting; Hate speech detection; Microblogging; Sinhalum-english code-mixed language; Social media; Speech detection; User-generated; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 21st International Conference on Advances in ICT for Emerging Regions, ICter 2021; Conference date: 2 December 2021 through 3 December 2021; Conference code: 179346}
}

@CONFERENCE{Kumar2021546,
	author = {Kumar, Ashwini and Tyagi, Vishu and Das, Sanjoy},
	title = {Detection of Offensive Language in Social Networks Using LSTM and BERT Model},
	year = {2021},
	journal = {2021 IEEE 6th International Conference on Computing, Communication and Automation, ICCCA 2021},
	pages = {546 – 548},
	doi = {10.1109/ICCCA52192.2021.9666342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124793860&doi=10.1109%2fICCCA52192.2021.9666342&partnerID=40&md5=de78ce33b6705693353d54b5e0be5331},
	affiliations = {Graphic Era Deemed to Be University, Department of Cse, Dehradun, India},
	abstract = {The uses of offensive languages on social media's like Instagram, Facebook, Twitter, etc. are increased tremendously. Nowadays, huge growth in the number of social media users are seen. Peoples are knowingly or unknowingly flooded the social media platforms with offensive posts. This become very challenging task to detect offensive posts. Manually solving this problem is not feasible, therefore automatic detection of offensive language is needed. Our objective of the work is to detect offensive language with the highest accuracy. The Davidson dataset is used for experiments with annotated tweets and implemented based on LSTM and BERT methods. The proposed deep learning methods is compared with other known machine learning classifier. Overall, result analysis is show that proposed deep learning method is outperforming others.  © 2021 IEEE.},
	author_keywords = {BERT; LSTM; Offensive Language; Social Media},
	keywords = {Long short-term memory; Automatic Detection; BERT; Davidson; Facebook; High-accuracy; Learning methods; LSTM; Offensive languages; Social media; Social media platforms; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th IEEE International Conference on Computing, Communication and Automation, ICCCA 2021; Conference date: 17 December 2021 through 19 December 2021; Conference code: 176300}
}

@CONFERENCE{Bhawal2021615,
	author = {Bhawal, Snehaan and Roy, Pradeep Kumar and Kumar, Abhinav},
	title = {Hate Speech and Offensive Language Identification on Multilingual code-mixed Text using BERT},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {615 – 624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124360194&partnerID=40&md5=b7341c87fb0726d1a3e55231f2ade068},
	affiliations = {Kalinga Institute of Industrial Technology, Odisha, India; Indian Institute of Information Technology, Gujarat, Surat, India; Siksha ‘O’ Anusandhan Deemed to be University, Odisha, Bhubaneswar, India},
	abstract = {Hate Speech and Offensive Content detection in social media has been an active field of research for the last couple of years. For the majority of the world consisting of non-native English speakers, most of the time unofficial messages are written in code-mixed language in a combination of words in a native language with English text. The current study focuses on using Machine and Deep learning techniques for detection of Hate Speech and Offensive content in a Malayalam and Tamil code-mixed text collected from social media. The study showed that Deep learning models perform better than the machine learning models, specifically the implementation of BERT based transfer learning models performed best. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT; Deep Learning; Hate Speech; Machine Learning; Multilingual Text},
	keywords = {Codes (symbols); Learning systems; Social networking (online); Speech recognition; BERT; Content detection; Deep learning; Hate speech; Language identification; Learning models; Machine-learning; Multilingual texts; Offensive languages; Social media; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Fahim20211582,
	author = {Fahim, Md and Gokhale, Swapna S.},
	title = {Detecting Offensive Content on Twitter during Proud Boys Riots},
	year = {2021},
	journal = {Proceedings - 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021},
	pages = {1582 – 1587},
	doi = {10.1109/ICMLA52953.2021.00253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125862318&doi=10.1109%2fICMLA52953.2021.00253&partnerID=40&md5=8a02a977833143601bebf78252e746e1},
	affiliations = {Univ. of Connecticut, Computer Science Engg., Storrs, 06269, CT, United States},
	abstract = {Hateful and offensive speech on online social media platforms has seen a rise in the recent years. Often used to convey humor through sarcasm or to emphasize a point, offensive speech may also be employed to insult, deride and mock alternate points of view. In turbulent and chaotic circumstances, insults and mockery can lead to violence and unrest, and hence, such speech must be identified and tagged to limit its damage. This paper presents an application of machine learning to detect hateful and offensive content from Twitter feeds shared after the protests by Proud Boys, an extremist, ideological and violent hate group. A comprehensive coding guide, consolidating definitions of what constitutes offensive content based on the potential to trigger and incite people is developed and used to label the tweets. Linguistic, auxiliary and social features extracted from these labeled tweets were used to train machine learning classifiers, which detect offensive content with an accuracy of about 92%. An analysis of the importance scores reveals that offensiveness is pre-dominantly a function of words and their combinations, rather than meta features such as punctuations and quotes. This observation can form the foundation of pre-trained classifiers that can be deployed to automatically detect offensive speech in new and unforeseen circumstances. © 2021 IEEE.},
	author_keywords = {Classification; Machine Learning; Offensive Speech; Proud Boys; Social Media},
	keywords = {Classification (of information); Machine learning; Speech; Chaotics; Content-based; Machine-learning; Metafeature; Offensive speech; Online social medias; Proud boy; Social media; Social media platforms; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021; Conference date: 13 December 2021 through 16 December 2021; Conference code: 176595}
}

@CONFERENCE{HaCohen-Kerner2021501,
	author = {HaCohen-Kerner, Yaakov and Uzan, Moshe},
	title = {Detecting Offensive Language in English, Hindi, and Marathi using Classical Supervised Machine Learning Methods and Word/Char N-grams},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {501 – 507},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134221157&partnerID=40&md5=1c002699cd9f50ed444223b333f4e4b3},
	affiliations = {Computer Science Department, Jerusalem College of Technology, Jerusalem, 9116001, Israel; Computer Science Department, Bar Ilan University, Ramat-Gan, 5290002, Israel},
	abstract = {In this paper, we describe our submissions for the HASOC 2021 contest. We tackled subtask 1A that addresses the problem of hate speech and offensive language identification in three languages: English, Hindi, and Marathi. We developed different models using six classical supervised machine learning methods: support vector classifier, binary support vector classifier, random forest, ada-boost classifier, multi-layer perceptron, and logistic regression. Our best submission was a model we built for offensive language identification in Marathi using random forest. This model was ranked in 6th place out of 25 teams. Our result is lower by only 0.0059 than the result of the team that was ranked in 3rd place. Our ML models were applied on various combinations of character and/or word n-gram features from uni-gram to 8-gram. © 2021 Copyright for this paper by the Forum for Information Retrieval Evaluation, December 13-17, 2021, India.},
	author_keywords = {Hate Speech; offensive language; supervised machine learning; word/char n-grams},
	keywords = {Adaptive boosting; Computational linguistics; Information retrieval; Logistic regression; Natural language processing systems; Random forests; Speech recognition; Supervised learning; Hate speech; Language identification; Machine learning methods; N-grams; Offensive languages; Random forests; Subtask; Supervised machine learning; Support vector classifiers; Word/char n-gram; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Motlogelwa2021248,
	author = {Motlogelwa, Nkwebi Peace and Thuma, Edwin and Mudongo, Monkgigi and Leburu-Dingalo, Tebo and Mosweunyane, Gontlafetse},
	title = {Leveraging Text Generated from Emojis for Hate Speech and Offensive Content Identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {248 – 253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134197445&partnerID=40&md5=9853262fdb4c2c6ac6ce2715dce3e8ae},
	affiliations = {Department of Computer Science, University of Botswana, Botswana},
	abstract = {In this paper, team University of Botswana Computer Science (UBCS) investigate whether enriching social media data with text generated from emojis can help in the identification of Hate Speech and Offensive Content. In particular, we build three different binary text classifiers that can detect Hate and Offensive content (HOF) or Not Hate-Offensive content (NOT) on data sampled from Twitter. In building our first classifier, we used pre-processed text from twitter only without emojis. In the second classifier, we enrich our preprocessed text from Twitter with text generated from emojis within the Tweets. Our result suggests that enriching Tweets with text generated from emojis within the Tweets improves the classification accuracy of our hate and offensive content classier. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Binary Classification; Emojis; fastText; Hate Speech},
	keywords = {Concentration (process); Social networking (online); Text processing; Binary classification; Classification accuracy; Content identifications; Emojis; Fasttext; Hate speech; In-buildings; Social media datum; Text classifiers; University of Botswana; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@ARTICLE{Rajput202167,
	author = {Rajput, Gaurav and Punn, Narinder Singh and Sonbhadra, Sanjay Kumar and Agarwal, Sonali},
	title = {Hate Speech Detection Using Static BERT Embeddings},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13147 LNCS},
	pages = {67 – 77},
	doi = {10.1007/978-3-030-93620-4_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122573596&doi=10.1007%2f978-3-030-93620-4_6&partnerID=40&md5=09565e4f176e1f77d16275ddbcec18c6},
	affiliations = {Indian Institute of Information Technology, Allahabad, Uttar Pradesh, Prayagraj, 211015, India},
	abstract = {With increasing popularity of social media platforms hate speech is emerging as a major concern, where it expresses abusive speech that targets specific group characteristics, such as gender, religion or ethnicity to spread violence. Earlier people use to verbally deliver hate speeches but now with the expansion of technology, some people are deliberately using social media platforms to spread hate by posting, sharing, commenting, etc. Whether it is Christchurch mosque shootings or hate crimes against Asians in west, it has been observed that the convicts are very much influenced from hate text present online. Even though AI systems are in place to flag such text but one of the key challenges is to reduce the false positive rate (marking non hate as hate), so that these systems can detect hate speech without undermining the freedom of expression. In this paper, we use ETHOS hate speech detection dataset and analyze the performance of hate speech detection classifier by replacing or integrating the word embeddings (fastText (FT), GloVe (GV) or FT + GV) with static BERT embeddings (BE). With the extensive experimental trails it is observed that the neural network performed better with static BE compared to using FT, GV or FT + GV as word embeddings. In comparison to fine-tuned BERT, one metric that significantly improved is specificity. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {BERT; BERT embeddings; Hate speech detection; Word embeddings},
	keywords = {Classification (of information); Social networking (online); Speech; Speech recognition; AI systems; BERT; BERT embedding; Embeddings; False positive rates; Hate speech detection; Social media platforms; Speech detection; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 9th International Conference on Big Data Analytics, BDA 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 270559}
}

@CONFERENCE{Davani202192,
	author = {Davani, Aida Mostafazadeh and Omrani, Ali and Kennedy, Brendan and Atari, Mohammad and Ren, Xiang and Dehghani, Morteza},
	title = {Improving Counterfactual Generation for Fair Hate Speech Detection},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {92 – 101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127872564&partnerID=40&md5=981475cb00a22f0836102d298eca4067},
	affiliations = {University of Southern California, United States},
	abstract = {Bias mitigation approaches reduce models' dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. In hate speech detection, however, equalizing model predictions may ignore important differences among targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs. Our method evaluates the similarity in sentence likelihoods (via pretrained language models) among counterfactuals, to treat SGTs equally only within interchangeable contexts. By applying logit pairing to equalize outcomes on the restricted set of counterfactuals for each instance, we improve fairness metrics while preserving model performance on hate speech detection.  © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Counterfactuals; Language model; Model prediction; Modeling performance; Sensitive features; Social groups; Specific languages; Speech detection; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference date: 6 August 2021; Conference code: 182536}
}

@ARTICLE{Venturott2021778,
	author = {Venturott, Lígia Iunes and Ciarelli, Patrick Marques},
	title = {Application of Data Augmentation Techniques for Hate Speech Detection with Deep Learning},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12981 LNAI},
	pages = {778 – 787},
	doi = {10.1007/978-3-030-86230-5_61},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115441545&doi=10.1007%2f978-3-030-86230-5_61&partnerID=40&md5=8244cfc26817cf2857a2fefe7986d187},
	affiliations = {Universidade Federal do Espírito Santo, Vitória, Brazil},
	abstract = {In the past decade, there has been a great increase in the usage of social media, and with it also an increase on dissemination of online hate-speech. Some of the most advanced techniques for online hate-speech detection are based on deep learning. Unfortunately, this kind of technique requires a large amount of labeled data, which is not so easy to find. One way of trying to overcome this problem is with the use of data augmentation techniques. The present paper explores data augmentation in order to improve the performance of deep neural networks on the task of hate speech detection on a small dataset in Portuguese. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Data augmentation; Deep learning; Hate-speech},
	keywords = {Deep neural networks; Speech recognition; Augmentation techniques; Data augmentation; Deep learning; Hate-speech; Labeled data; Large amounts; Performance; Small data set; Social media; Speech detection; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th EPIA Conference on Artificial Intelligence, EPIA 2021; Conference date: 7 September 2021 through 9 September 2021; Conference code: 265179}
}

@CONFERENCE{Jain2021,
	author = {Jain, Naman and Hegde, Ashish and Jain, Aryan and Joshi, Aditya and Madake, Jyoti},
	title = {Pseudo-conventional Approach for Cyberbullying and Hate-speech detection},
	year = {2021},
	journal = {2021 7th IEEE International Conference on Advances in Computing, Communication and Control, ICAC3 2021},
	doi = {10.1109/ICAC353642.2021.9697140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126450104&doi=10.1109%2fICAC353642.2021.9697140&partnerID=40&md5=0835541a75900727674f41dbe5f3a206},
	affiliations = {Vishwakarma Institute of Technology (VIT), Department of Electronics and Telecommunication Engineering (EnTC), Pune, India},
	abstract = {Cyberbullying is an upsetting web misconduct with alarming results. It shows up in various structures, and in a large portion of the informal communities, it could be found in various textual or image formats. Detection of such episodes requires shrewd frameworks. In this paper we have compared various approaches that were and are still being used to detect cyberbullying. An approach with multiple ML Algorithms and DL model has been proposed and tested by us for the cause.  © 2021 IEEE.},
	author_keywords = {BERT models; Cyberbullying Detection; Machine Learning; Mental Health; NLP; Online Bullying},
	keywords = {E-learning; Machine learning; BERT model; Conventional approach; Cyber bullying; Cyberbullying detection; Image format; Machine-learning; Mental health; Online bullying; Speech detection; Textual format; Computer crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 7th IEEE International Conference on Advances in Computing, Communication and Control, ICAC3 2021; Conference date: 3 December 2021 through 4 December 2021; Conference code: 177083}
}

@CONFERENCE{Kavatagi2021,
	author = {Kavatagi, Sanjana and Rachh, Rashmi},
	title = {A Context Aware Embedding for the Detection of Hate Speech in Social Media Networks},
	year = {2021},
	journal = {2021 International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2021},
	doi = {10.1109/SMARTGENCON51891.2021.9645877},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124005207&doi=10.1109%2fSMARTGENCON51891.2021.9645877&partnerID=40&md5=3c131ae03e138d9aae2ace7cc0942d6a},
	affiliations = {AITM, Belagavi, India; VTU, Belagavi, India},
	abstract = {Proliferation of social media platforms in recent past has resulted into upsurge in the number of users. Advent of these sites have paved way for the users to easily express share and communicate. In such a scenario, it is imperative to analyze the content and identify nasty content so as to avoid unpleasant situations. Machine learning techniques are extensively used for this purpose. In this paper, we propose a language model for the identification of hate speech in twitter data. Distil-BERT, a context aware embedding model along with Support Vector Machine (SVM) for the classification of hate speech has been used. SVM with a 10-fold cross validation and linear kernel has been found to provide better accuracy as compared to existing models. Results show that accuracy is improved with the use of context aware embedding model. © 2021 IEEE.},
	author_keywords = {Cross validation; Distil-BERT; hate speech; Support vector machine},
	keywords = {Embeddings; Social networking (online); Speech recognition; Context-Aware; Cross validation; Distill-BERT; Embeddings; Hate speech; Language model; Machine learning techniques; Social media networks; Social media platforms; Support vectors machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2021 International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2021; Conference date: 29 October 2021 through 30 October 2021; Conference code: 175751}
}

@CONFERENCE{Naidu2021908,
	author = {Naidu, T Akhilesh and Kumar, Shailender},
	title = {Hate Speech Detection Using Multi-Channel Convolutional Neural Network},
	year = {2021},
	journal = {Proceedings - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021},
	pages = {908 – 912},
	doi = {10.1109/ICAC3N53548.2021.9725696},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126988871&doi=10.1109%2fICAC3N53548.2021.9725696&partnerID=40&md5=b57af2cfee7a88596191e7169f782462},
	affiliations = {Delhi Technological University, Delhi, India},
	abstract = {As we are used to seeing the Internet as a mode of availability that is available at our doorstep, it is no wonder that we have access to a number of online stages. Increasing their use brings both advantages and disadvantages. One of such disadvantages is hate speech. Hate speech is a subject of worry for online media stages. With powerfully expanding datasets manual mediation of posts is very inconceivable or will be tedious. Hate speech detection should be an automated task to distinguish hate speech from the provided input. In this work, we have implemented a deep learning model multi-channel convolutional neural network (MCCNN). The model consists of 3 channels of Convolutional Neural Network. Each channel is merged and connected to a fully connected layer from where the final output is obtained. We have compared our model with a single-channel convolution neural network and results have shown that MCCNN outperformed simple CNN. The accuracy and F1-score achieved by our model are 95.49 and 93.93 for dataset D1 and for dataset D2 97.85% and 95.74% respectively.  © 2021 IEEE.},
	author_keywords = {CNN; Glove; Hate-speech; MCCNN; Word Embedding},
	keywords = {Convolution; Deep learning; Speech; Speech recognition; CNN; Convolutional neural network; Embeddings; Glove; Hate-speech; Multi channel; Multi-channel convolutional neural network; Online medium; Speech detection; Word embedding; Convolutional neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 177627}
}

@CONFERENCE{Lin2021967,
	author = {Lin, Ken-Yu and Lee, Roy Ka-Wei and Gao, Wei and Peng, Wen-Chih},
	title = {Early Prediction of Hate Speech Propagation},
	year = {2021},
	journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
	volume = {2021-December},
	pages = {967 – 974},
	doi = {10.1109/ICDMW53433.2021.00126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125343273&doi=10.1109%2fICDMW53433.2021.00126&partnerID=40&md5=a4f53bf4c63f8c22ccd3fa884a47e3ab},
	affiliations = {National Chiao Tung University; Singapore University of Design and Technology, Singapore; Singapore Management University, Singapore},
	abstract = {Online hate speech has disrupted the social connectedness in online communities and raises public safety concerns in our societies. Motivated by this rising issue, researchers have developed many machine learning and deep learning methods to detect hate speech in social media automatically. However, most of the existing automated solutions have focused on detecting hate speech in a single post, neglecting the network and information propagation effects of social media platforms. Ideally, the content moderators would want to identify the hateful posts and monitor posts and threads that are likely to induce hate. This paper aims to address this research gap by defining a new problem of early hate speech propagation prediction. We also propose HEAR, which is a deep learning model that utilizes a post's semantic, propagation structure, and temporal features to predict hateful propagation in social media. Through extensive experiments on two publicly available large Twitter datasets, we demonstrate HEAR's ability to outperform the state-of-the-art baselines in the early prediction of hateful propagation task. Specifically, with just 15 minutes of observation on a post's propagation, HEAR outperforms the best baselines by more than 10% (F1 score) in predicting the eventual amount of hateful posts it will induce. © 2021 IEEE.},
	author_keywords = {early detection; hate speech; social media mining},
	keywords = {Deep learning; Forecasting; Information dissemination; Large dataset; Semantics; Social networking (online); Speech recognition; Automated solutions; Early detection; Early prediction; Hate speech; Information propagation; Learning methods; Public safety; Safety concerns; Social media; Social media minings; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 21st IEEE International Conference on Data Mining Workshops, ICDMW 2021; Conference date: 7 December 2021 through 10 December 2021; Conference code: 176562}
}

@CONFERENCE{Markov2021149,
	author = {Markov, Ilia and Ljubešić, Nikola and Fišer, Darja and Daelemans, Walter},
	title = {Exploring Stylometric and Emotion-Based Features for Multilingual Cross-Domain Hate Speech Detection},
	year = {2021},
	journal = {WASSA 2021 - Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, Proceedings of the 11th Workshop},
	pages = {149 – 159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115666850&partnerID=40&md5=5cc2a0cc302ba6cb97828b2bbe5b21f2},
	affiliations = {CLIPS Research Center, University of Antwerp, Belgium; Dept. of Language Technologies, Jožef Stefan Institute, Slovenia; Faculty of Arts, University of Ljubljana, Slovenia},
	abstract = {In this paper, we describe experiments designed to evaluate the impact of stylometric and emotion-based features on hate speech detection: the task of classifying textual content into hate or non-hate speech classes. Our experiments are conducted for three languages – English, Slovene, and Dutch – both in in-domain and cross-domain setups, and aim to investigate hate speech using features that model two linguistic phenomena: the writing style of hateful social media content operationalized as function word usage on the one hand, and emotion expression in hateful messages on the other hand. The results of experiments with features that model different combinations of these phenomena support our hypothesis that stylometric and emotion-based features are robust indicators of hate speech. Their contribution remains persistent with respect to domain and language variation. We show that the combination of features that model the targeted phenomena outperforms words and character n-gram features under cross-domain conditions, and provides a significant boost to deep learning models, which currently obtain the best results, when combined with them in an ensemble. © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Feature extraction; Speech recognition; Cross-domain; Emotion expression; Function words; Linguistic phenomena; Media content; Social media; Speech detection; Stylometrics; Textual content; Writing style; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39; Conference name: 11th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA 2021; Conference date: 19 April 2021; Conference code: 182534}
}

@CONFERENCE{Kumar2021439,
	author = {Kumar, Abhinav and Roy, Pradeep Kumar and Saumya, Sunil},
	title = {An Ensemble Approach for Hate and Offensive Language Identification in English and Indo-Aryan Languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {439 – 445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134210656&partnerID=40&md5=fd7b005f661940f377e8e786f4ba6b18},
	affiliations = {Department of Computer Science & Engineering, Siksha ’O’ Anusandhan Deemed to be University, Bhubaneswar, India; Department of Computer Science & Engineering, Indian Institute of Information Technology, Gujarat, Surat, India; Department of Computer Science & Engineering, Indian Institute of Information Technology, Dharwad, India},
	abstract = {The freedom to upload and the lack of effective social media monitoring have resulted in a slew of societal issues such as cyberbullying, offensive content, and hate speech. Due to this, identifying hate and abusive language on social media is one of the trendiest research topics these days. This work proposes an ensemble-based model for detecting hate and offensive language in English and Hindi social media postings, which combines a support vector machine, logistic regression, random forest, gradient boosting, and Adaboost classifiers. The use of word-level n-gram features performed significantly well in the English dataset, with macro F1-scores of 0.79 and 0.59 for two different tasks, while character-level n-gram features performed significantly well in the Hindi dataset, with macro F1-scores of 0.75 and 0.47 for two different tasks. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Deep learning; Ensemble learning; Hate speech; Machine learning; Offensive content},
	keywords = {Adaptive boosting; Computational linguistics; Deep learning; Learning systems; Random forests; Social networking (online); Support vector machines; Deep learning; Ensemble approaches; Ensemble learning; Hate speech; Language identification; Machine-learning; N-grams; Offensive content; Offensive languages; Social media; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Chanda2021446,
	author = {Chanda, Supriya and Ujjwal, S. and Das, Shayak and Pal, Sukomal},
	title = {Fine-tuning Pre-Trained Transformer based model for Hate Speech and Offensive Content Identification in English, Indo-Aryan and Code-Mixed (English-Hindi) languages},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {446 – 458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134217848&partnerID=40&md5=8c5c156a8ba01189b40b284e19a46f13},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology (BHU), Varanasi, 221005, India},
	abstract = {Hate Speech and Offensive Content Identification is one of the most challenging problem in the natural language processing field, being imposed by the rising presence of this phenomenon in online social media. This paper describes our Transformer-based solutions for identifying offensive language on Twitter in three languages (i.e., English, Hindi, and Marathi) and one code mixed (English-Hindi) language, which was employed in Subtask 1A, Subtask 1B and Subtask 2 of the HASOC 2021 shared task. Finally, the highest-scoring models were used for our submissions in the competition, which ranked our IRLab@IITBHU team 16th of 56, 18th of 37, 13th of 34, 7th of 24, 12th of 25 and 6th of 16 for English Subtask 1A, English Subtask 1B, Hindi Subtask 1A, Hindi Subtask 1B, Marathi Subtask 1A, and English-Hindi Code-Mix Subtask 2 respectively. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-Mixed; Hate Speech; Hindi; Marathi; Multilingual BERT; Offensive Language; Orcid; Social Media},
	keywords = {Learning algorithms; Machine learning; Social networking (online); Code-mixed; Content identifications; Hate speech; Hindi; Marathi; Multilingual BERT; Offensive languages; Orcid; Social media; Subtask; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Mou2021687,
	author = {Mou, Guanyi and Lee, Kyumin},
	title = {An Effective, Robust and Fairness-aware Hate Speech Detection Framework},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
	pages = {687 – 697},
	doi = {10.1109/BigData52589.2021.9672022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125309379&doi=10.1109%2fBigData52589.2021.9672022&partnerID=40&md5=fc50b3064ddae6a563ed839a3ce612ab},
	affiliations = {Worcester Polytechnic Institute, Worcester, 01605, MA, United States},
	abstract = {With the widespread online social networks, hate speeches are spreading faster and causing more damage than ever before. Existing hate speech detection methods have limitations in several aspects, such as handling data insufficiency, estimating model uncertainty, improving robustness against malicious attacks, and handling unintended bias (i.e., fairness). There is an urgent need for accurate, robust, and fair hate speech classification in online social networks. To bridge the gap, we design a data-augmented, fairness addressed, and uncertainty estimated novel framework. As parts of the framework, we propose Bidirectional Quaternion-Quasi-LSTM layers to balance effectiveness and efficiency. To build a generalized model, we combine five datasets collected from three platforms. Experiment results show that our model outperforms eight state-of-the-art methods under both no attack scenario and various attack scenarios, indicating the effectiveness and robustness of our model. We share our code along with combined dataset for better future research. © 2021 IEEE.},
	author_keywords = {fairness; hate speech detection; robustness},
	keywords = {Bridges; Data handling; Long short-term memory; Speech recognition; Uncertainty analysis; Attacks scenarios; Detection framework; Detection methods; Fairness; Hate speech detection; Malicious attack; Modeling uncertainties; Robustness; Speech classification; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 IEEE International Conference on Big Data, Big Data 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 176404}
}

@ARTICLE{Firmino2021170,
	author = {Firmino, Anderson Almeida and de Baptista, Cláudio Souza and de Paiva, Anselmo Cardoso},
	title = {Using Cross Lingual Learning for Detecting Hate Speech in Portuguese},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12924 LNCS},
	pages = {170 – 175},
	doi = {10.1007/978-3-030-86475-0_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115216569&doi=10.1007%2f978-3-030-86475-0_17&partnerID=40&md5=e87e36f3f5673b503a15ee2148e797e8},
	affiliations = {Information Systems Laboratory, Federal University of Campina Grande, Campina Grande, Paraiba, Brazil; Applied Computing Center, Federal University of Maranhão, Maranhão, Brazil},
	abstract = {Social media growth all around the world brought benefits and challenges to society. One problem that must be highlighted is hate speech proliferation on the Internet. This article proposes a technique to hate speech detection in texts, which uses a Cross-Lingual Learning classifier. In our experiments, we used a public dataset in Portuguese and achieved one of the greatest F1 Scores within our state-of-the-art. Besides, this work is the first one to perform a cross-lingual learning task for hate speech detection using a corpus in Portuguese. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Cross-Lingual Learning; Deep learning; Hate speech detection; Social media},
	keywords = {Expert systems; Cross-lingual; F1 scores; Learning classifiers; Learning tasks; Public dataset; Social media; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 32nd International Conference on Database and Expert Systems Applications, DEXA 2021; Conference date: 27 September 2021 through 30 September 2021; Conference code: 264559}
}

@CONFERENCE{Faal2021,
	author = {Faal, Farshid and Schmitt, Ketra and Yu, Jia Yuan},
	title = {Protecting marginalized communities by mitigating discrimination in toxic language detection},
	year = {2021},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2021-October},
	doi = {10.1109/ISTAS52410.2021.9629201},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123175125&doi=10.1109%2fISTAS52410.2021.9629201&partnerID=40&md5=8e6a88cfcc1baf51b37342f4b1007081},
	affiliations = {Concordia University, Institute for Information System Engineering, Montreal, QC, Canada; Concordia University, Centre for Engineering in Society, Montreal, QC, Canada},
	abstract = {As the harms of online toxic language become more apparent, countering online toxic behavior is an essential application of natural language processing. The first step in managing toxic language risk is identification, but algorithmic approaches have themselves demonstrated bias. Texts containing some demographic identity terms such as gay or Black are more likely to be labeled as toxic in existing toxic language detection datasets. In many machine learning models introduced for toxic language detection, non-toxic comments containing minority and marginalized community-specific identity terms were given unreasonably high toxicity scores. To address the challenge of bias in toxic language detection, we propose a two-step training approach. A pretrained language model with a multitask learning objective will mitigate biases in the toxicity classifier prediction. Experiments demonstrate that jointly training the pretrained language model with a multitask objective can effectively mitigate the impacts of unintended biases and is more robust to model bias towards commonly-attacked identity groups presented in datasets without significantly hurting the model's generalizability.  © 2021 IEEE.},
	keywords = {Computational linguistics; Learning algorithms; Learning systems; Natural language processing systems; Algorithmic approach; Language detection; Language model; Machine learning models; Model bias; Non-toxic; Two-step training; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 IEEE International Symposium on Society and Technology, ISTAS 2021; Conference date: 28 October 2021 through 31 October 2021; Conference code: 175401}
}

@ARTICLE{Rodríguez202177,
	author = {Rodríguez, Sebastián E. and Allende-Cid, Héctor and Allende, Héctor},
	title = {Detecting Hate Speech in Cross-Lingual and Multi-lingual Settings Using Language Agnostic Representations},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12702 LNCS},
	pages = {77 – 87},
	doi = {10.1007/978-3-030-93420-0_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124311246&doi=10.1007%2f978-3-030-93420-0_8&partnerID=40&md5=db6cdbd0dade0f867bbc047807915b7e},
	affiliations = {Departamento de Informática, Universidad Técnica Federico Santa María, Valparaíso, Chile; Escuela de Ingeniería Informática, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile},
	abstract = {The automatic detection of hate speech is a blooming field in the natural language processing community. In recent years there have been efforts in detecting hate speech in multiple languages, using models trained on multiple languages at the same time. Furthermore, there is special interest in the capabilities of language agnostic features to represent text in hate speech detection. This is because models can be trained in multiple languages, and then the capabilities of the model and representation can be tested on a unseen language. In this work we focused on detecting hate speech in mono-lingual, multi-lingual and cross-lingual settings. For this we used a pre-trained language model called Language Agnostic BERT Sentence Embeddings (LabSE), both for feature extraction and as an end to end classification model. We tested different models such as Support Vector Machines and Tree-based models, and representations in particular bag of words, bag of characters, and sentence embeddings extracted from Multi-lingual BERT. The dataset used was the SemEval 2019 task 5 data set, which covers hate speech against immigrants and women in English and Spanish. The results show that the usage of LabSE as feature extraction improves the performance on both languages in a mono-lingual setting, and in a cross-lingual setting. Moreover, LabSE as an end to end classification model performs better than the reported by the authors of SemEval 2019 task 5 data set for the Spanish language. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Hate speech detection; Multi-lingual language models; Natural Language Processing},
	keywords = {Classification (of information); Computational linguistics; Embeddings; Extraction; Feature extraction; Information retrieval; Natural language processing systems; Speech recognition; Support vector machines; Classification models; Cross-lingual settings; Embeddings; End to end; Features extraction; Hate speech detection; Language model; Multi-lingual language model; Multiple languages; Speech detection; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 25th Iberoamerican Congress on Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications, CIARP 2021; Conference date: 10 May 2021 through 13 May 2021; Conference code: 271399}
}

@CONFERENCE{Aroyehun2021313,
	author = {Aroyehun, Segun Taofeek and Gelbukh, Alexander},
	title = {Evaluation of intermediate pre-training for the detection of offensive language},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2943},
	pages = {313 – 320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115318768&partnerID=40&md5=420d5c8830a1bac7f731cfb0481b8922},
	affiliations = {Cic, Instituto Politecnico Nacional, Mexico City, Mexico},
	abstract = {This paper presents an evaluation of intermediate pretraining for the task of offensive language identification. We leverage recent advances in multilingual contextual representation and fine-tuning of pre-trained language models. We compare the performance of a pretrained language model adapted for the social media domain and another that was further trained on multilingual sentiment analysis data. We found that the intermediate pre-training steps prior to fine-tuning on the target task yield performance gains. The best submissions by our team, NLP-CIC, achieved first and second place on the non-contextual Spanish (Subtask 1) and Mexican Spanish (Subtask 3) subtasks of the MeOffendEs-IberLEF 2021 shared task respectively. © 2021 CEUR-WS. All rights reserved.},
	author_keywords = {Mexican Spanish; Offensive Language Identification; Sentiment Analysis; Social Media; Spanish; XLM-RoBERTa},
	keywords = {Computational linguistics; Social networking (online); Language identification; Mexican spanish; Offensive language identification; Offensive languages; Pre-training; Sentiment analysis; Social media; Spanish; Subtask; XLM-RoBERTa; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2021 Iberian Languages Evaluation Forum, IberLEF 2021; Conference date: 21 September 2021; Conference code: 171720}
}

@CONFERENCE{Li2021233,
	author = {Li, Mingqi and Liao, Song and Okpala, Ebuka and Tong, Max and Costello, Matthew and Cheng, Long and Hu, Hongxin and Luo, Feng},
	title = {COVID-HateBERT: A Pre-trained Language Model for COVID-19 related Hate Speech Detection},
	year = {2021},
	journal = {Proceedings - 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021},
	pages = {233 – 238},
	doi = {10.1109/ICMLA52953.2021.00043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125875873&doi=10.1109%2fICMLA52953.2021.00043&partnerID=40&md5=a0f1568564a6c6250c562bfde53c7ea8},
	affiliations = {Clemson University, School of Computing, Clemson, United States; Clemson University, Department of Sociology, Clemson, United States; University at Buffalo, Department of Computer Science and Engineering, Buffalo, United States; Intern from Christ Church Episcopal School, Greenville, SC, United States},
	abstract = {With the dramatic growth of hate speech on social media during the COVID-19 pandemic, there is an urgent need to detect various hate speech effectively. Existing methods only achieve high performance when the training and testing data come from the same data distribution. The models trained on the traditional hateful dataset cannot fit well on COVID-19 related dataset. Meanwhile, manually annotating the hate speech dataset for supervised learning is time-consuming. Here, we propose COVID-HateBERT, a pre-trained language model to detect hate speech on English Tweets to address this problem. We collect 200M English tweets based on COVID-19 related hateful keywords and hashtags. Then, we use a classifier to extract the 1.27M potential hateful tweets to re-train BERT-base. We evaluate our COVID-HateBERT on four benchmark datasets. The COVID-HateBERT achieves a 14.8%-23.8% higher macro average F1 score on traditional hate speech detection comparing to baseline methods and a 2.6%-6.73% higher macro average F1 score on COVID-19 related hate speech detection comparing to classifiers using BERT and BERTweet, which shows that COVID-HateBERT can generalize well on different datasets. © 2021 IEEE.},
	author_keywords = {BERT; COVID-19; Hate speech detection; Language model},
	keywords = {Classification (of information); Computational linguistics; Speech recognition; BERT; COVID-19; F1 scores; Hate speech detection; Language model; Performance; Social media; Speech detection; Training and testing; Training data; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021; Conference date: 13 December 2021 through 16 December 2021; Conference code: 176595}
}

@CONFERENCE{Zhou20217158,
	author = {Zhou, Xianbing and Yang, Yong and Fan, Xiaochao and Ren, Ge and Song, Yunfeng and Diao, Yufeng and Yang, Liang and Lin, Hongfei},
	title = {Hate speech detection based on sentiment knowledge sharing},
	year = {2021},
	journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
	pages = {7158 – 7166},
	doi = {10.18653/v1/2021.acl-long.556},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118946615&doi=10.18653%2fv1%2f2021.acl-long.556&partnerID=40&md5=a3daaa8c26fad41a918a98769e02afda},
	affiliations = {School of Computer Science and Technology, Xinjiang Normal University, China; Department of Computer Science and Technology, Dalian University of Technology, China},
	abstract = {The wanton spread of hate speech on the internet brings great harm to society and families. It is urgent to establish and improve automatic detection and active avoidance mechanisms for hate speech. While there exist methods for hate speech detection, they stereotype words and hence suffer from inherently biased training. In other words, getting more affective features from other affective resources will significantly affect the performance of hate speech detection. In this paper, we propose a hate speech detection framework based on sentiment knowledge sharing. While extracting the affective features of the target sentence itself, we make better use of the sentiment features from external resources, and finally fuse features from different feature extraction units to detect hate speech. Experimental results on two public datasets demonstrate the effectiveness of our model. © 2021 Association for Computational Linguistics},
	keywords = {Computational linguistics; Knowledge management; Speech recognition; Automatic Detection; Detection framework; External resources; Features extraction; Knowledge-sharing; Performance; Public dataset; Sentiment features; Speech detection; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Varughese202172,
	author = {Varughese, Aparna Susan and Fathima Swaliha, T.M. and Irfan, Nargis and Rehannara Beegum, T.},
	title = {A review on hate speech detection using natural language processing},
	year = {2021},
	journal = {12th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2021},
	volume = {2021-August},
	pages = {72 – 76},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118164363&partnerID=40&md5=89d85e19cfe9f34c8eb869a0867e8dc1},
	affiliations = {TKM College of Engineering, Kerala, Kollam, India},
	abstract = {With increased use of social media among various users, there has been a prominent surge in hate speech content in the online platforms. This paper provides a review on how natural language processing is being used to combat this surge. The paper discusses the resources like tools and datasets that are currently available. The features and various methods of detection are explored. The most targeted groups of people are also identified. The languages which have been covered under hate speech detection are also discussed. The challenges that are faced are reviewed. © Grenze Scientific Society, 2021},
	author_keywords = {Classifiers; Hate speech; Languages; Natural language processing},
	keywords = {Medical applications; Speech recognition; Hate speech; Language; Language processing; Natural language processing; Natural languages; Online platforms; Social media; Speech content; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2021; Conference date: 27 August 2021 through 28 August 2021; Conference code: 172116}
}

@CONFERENCE{Mosca202191,
	author = {Mosca, Edoardo and Wich, Maximilian and Groh, Georg},
	title = {Understanding and Interpreting the Impact of User Context in Hate Speech Detection},
	year = {2021},
	journal = {SocialNLP 2021 - 9th International Workshop on Natural Language Processing for Social Media, Proceedings of the Workshop},
	pages = {91 – 102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115673658&partnerID=40&md5=dd6246211919780850a2f3860ac2b0a8},
	affiliations = {TU Munich, Department of Informatics, Germany},
	abstract = {As hate speech spreads on social media and online communities, research continues to work on its automatic detection. Recently, recognition performance has been increasing thanks to advances in deep learning and the integration of user features. This work investigates the effects that such features can have on a detection model. Unlike previous research, we show that simple performance comparison does not expose the full impact of including contextualand user information. By leveraging explainability techniques, we show (1) that user features play a role in the model's decision and (2) how they affect the feature space learned by the model. Besides revealing that-and also illustrating why-user features are the reason for performance gains, we show how such techniques can be combined to better understand the model and to detect unintended bias. © SocialNLP 2021 Natural Language Processing for Social Media},
	keywords = {Deep learning; Feature extraction; Social networking (online); Speech recognition; Automatic Detection; Community researches; Detection models; On-line communities; Performance; Simple++; Social media; Speech detection; User context; User feature; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; Conference name: 9th International Workshop on Natural Language Processing for Social Media, SocialNLP 2021; Conference date: 10 June 2021; Conference code: 182490}
}

@CONFERENCE{Markov202117,
	author = {Markov, Ilia and Daelemans, Walter},
	title = {Improving Cross-Domain Hate Speech Detection by Reducing the False Positive Rate},
	year = {2021},
	journal = {NLP4IF 2021 - NLP for Internet Freedom: Censorship, Disinformation, and Propaganda, Proceedings of the 4th Workshop},
	pages = {17 – 22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119210707&partnerID=40&md5=f696177421d5a7e2d9c22bbad427cd3c},
	affiliations = {CLIPS Research Center, University of Antwerp, Belgium},
	abstract = {Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allowed to push the state-of-the-art results. One of the challenges of such automated approaches – namely recent deep learning models – is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention. We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble. The improvement is mainly due to a reduction of the false positive rate. © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Deep learning; Learning systems; Automated approach; Blockings; Cross-domain; False positive; False positive rates; False-accusation; Learning models; Social media; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 4th Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda, NLP4IF 2021; Conference date: 6 June 2021; Conference code: 182171}
}

@ARTICLE{Durães2021290,
	author = {Durães, Dalila and Santos, Flávio and Marcondes, Francisco S. and Lange, Sascha and Machado, José},
	title = {Comparison of Transfer Learning Behaviour in Violence Detection with Different Public Datasets},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12981 LNAI},
	pages = {290 – 298},
	doi = {10.1007/978-3-030-86230-5_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115443718&doi=10.1007%2f978-3-030-86230-5_23&partnerID=40&md5=258a2451e74014f8e5df8c461bf232a0},
	affiliations = {Centre Algoritmi, University of Minho, Braga, 4710-057, Portugal; Bosch Car Multimedia, Braga, 4705-820, Portugal},
	abstract = {The detection and recognition of violence have been area of interest to research, mainly in surveillance, Human-Computer Interaction and information retrieval for video based on content. The primary purpose of detecting and recognizing violence is to automatically and in real-time recognize violence. Hence, it is a crucial area and object of several studies, as it will enable systems to have the necessary means to contain violence automatically. In this sense, pre-trained models are used to solve general problems of recognition of violent activity. These models were pre-trained with datasets from: hockey fight; movies; violence in real surveillance; and fighting in real situations. From this pre-training models, general patterns are extracted that are very important to detect violent behaviour in videos. Our approach uses a state-of-the-art pre-trained violence detection model in general activity recognition tasks and then tweaks it for violence detection inside a car. For this, we created our dataset with videos inside the car to apply in this study. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Inside car; Video recognition; Violence detection},
	keywords = {Deep learning; Human computer interaction; Area of interest; Deep learning; Inside car; Learning behavior; Pre-training; Public dataset; Real situation; Real- time; Video recognition; Violence detections; Security systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 20th EPIA Conference on Artificial Intelligence, EPIA 2021; Conference date: 7 September 2021 through 9 September 2021; Conference code: 265179}
}

@CONFERENCE{Manerba202181,
	author = {Manerba, Marta Marchiori and Tonelli, Sara},
	title = {Fine-Grained Fairness Analysis of Abusive Language Detection Systems with CheckList},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {81 – 91},
	doi = {10.18653/v1/2021.woah-1.9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128818261&doi=10.18653%2fv1%2f2021.woah-1.9&partnerID=40&md5=a18c03373e43497c989e493a8f3d41d6},
	affiliations = {Department of Philology, Literature and Linguistics, University of Pisa, Italy; Fondazione Bruno Kessler, Trento, Italy},
	abstract = {Current abusive language detection systems have demonstrated unintended bias towards sensitive features such as nationality or gender. This is a crucial issue, which may harm minorities and underrepresented groups if such systems were integrated in real-world applications. In this paper, we create ad hoc tests through the CheckList tool (Ribeiro et al., 2020) to detect biases within abusive language classifiers for English. We compare the behaviour of two BERT-based models, one trained on a generic abusive language dataset and the other on a dataset for misogyny detection. Our evaluation shows that, although BERT-based classifiers achieve high accuracy levels on a variety of natural language processing tasks, they perform very poorly as regards fairness and bias, in particular on samples involving implicit stereotypes, expressions of hate towards minorities and protected attributes such as race or sexual orientation. We release both the notebooks implemented to extend the Fairness tests and the synthetic datasets usable to evaluate systems bias independently of CheckList.  © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; 'current; Accuracy level; Detection system; Fine grained; High-accuracy; Language detection; Minority groups; Real-world; Sensitive features; Under-represented groups; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference date: 6 August 2021; Conference code: 182536; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hegde2021132,
	author = {Hegde, Asha and Anusha, Mudoor Devadas and Shashirekha, Hosahalli Lakshmaiah},
	title = {Ensemble Based Machine Learning Models for Hate Speech and Offensive Content Identification},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {132 – 141},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134208439&partnerID=40&md5=a6ce2a86622d8508a585eae7ae6a80c2},
	affiliations = {Department of Computer Science, Mangalore University, Mangalore, India},
	abstract = {The rapid growth of internet and mobile technology has accelerated the spread of Hate Speech and Offensive Content (HASOC) to a larger extent. Identifying HASOC is a real challenge as the social media content may contain code-mixed text in two or more languages. Hence, filtering HASOC on social media to curb its further spread and the damage it is going to create is the need of the day. Automated tools are required to filter HASOC as doing it manually is labour intensive and error prone. In this paper, we, team MUM, describe the models submitted to the HASOC in English and Indo-Aryan Languages 2021 shared task in Forum for Information Retrieval Evaluation (FIRE) 2021. The shared task consists of Subtasks 1A and 1B for English, Hindi and Marathi languages and Subtask 2 for code-mixed text in English-Hindi language pair. The proposed models are devised as ensemble of three Machine Learning (ML) classifiers, namely: Random Forest (RF), Multi-Layer Perceptron (MLP) and Gradient Boosting (GB). These ensemble models are trained using a combination of the Term Frequency — Inverse Document Frequency (TF-IDF) of different features like word uni-gram, character n-grams, Hashtag vectors (HastagVec) followed by using the pre-trained embeddings: word2Vec and Emo2Vec. The proposed approaches obtained 43rd, 23rd, 18th, 10th, and 15th rank for English, Hindi and Marathi Subtask 1A and Subtask 1B respectively (Marathi language does not have Subtask 1B) and 11th rank in Subtask 2 for code-mixed English-Hindi tweets. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-mixing; Emoji2vec; Ensemble; HashTag; Voting Classifier},
	keywords = {Adaptive boosting; Codes (symbols); Machine learning; Random forests; Social networking (online); Text processing; Code-mixing; Content identifications; Emoji2vec; Ensemble; Hashtags; Machine learning models; Marathi languages; Social media; Subtask; Voting classifiers; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{García-Díaz2021329,
	author = {García-Díaz, José Antonio and Jiménez-Zafra, Salud María and Valencia-García, Rafael},
	title = {Umuteam at meoffendes 2021: Ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2943},
	pages = {329 – 345},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115341638&partnerID=40&md5=4e19504f4fa59f16d65929b3b23e3ec2},
	affiliations = {Facultad de Informatica, Universidad de Murcia, Campus de Espinardo, 30100, Spain; Computer Science Department, Sinai, Ceatic, Universidad de Jaen, 23071, Spain},
	abstract = {This paper presents the participation of the UMUTeam in the MeOffendEs shared task at IberLEF 2021. This task involves the identiffcation and categorisation of offensiveness in Spanish comments from different social networks (YouTube, Instagram and Twitter), and Mexican Spanish tweets. Specifically, four subtasks were proposed: The first one on multi-class classification of offensiveness types, the second one also concerning multi-class classification but with contextual information, the third one on a binary classification of texts as offensives or non-offensives, and the last one also regarding a binary classification but with metadata. Subtasks 1 and 2 focus on generic Spanish, and subtasks 3 and 4 on Mexican Spanish. We have participated in the four subtasks with the aim of promoting the automatic identification of offensiveness in Spanish variants. Our proposal for solving these subtasks is based on the combination of linguistic features (including fine-grained negation features) and embeddings using transformers and ensemble learning. We ranked in second place in subtask 1 with a micro-averaged F1-score of 87.8289%, first in subtask 2 with a micro-averaged F1-score of 87.8289%, fifth in subtask 3 with a macro-averaged F1-score of 67.0588%, and first in subtask 4 with a macro-averaged F1-score of 66.9449%. © 2021 CEUR-WS. All rights reserved.},
	author_keywords = {Ensemble learning; Feature Engineering; Natural Language Processing; Negation processing Transformers; Offensiveness},
	keywords = {Automation; Classification (of information); Classifiers; Learning systems; Linguistics; Binary classification; Ensemble learning; F1 scores; Feature engineerings; Fine grained; Linguistic features; Negation processing transformer; Offensive languages; Offensiveness; Subtask; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 Iberian Languages Evaluation Forum, IberLEF 2021; Conference date: 21 September 2021; Conference code: 171720}
}

@CONFERENCE{Barkhashree20211933,
	author = {Barkhashree and Dhaliwal, Parneeta},
	title = {Comprehensive Exploration of Machine Learning based models in Digital Forensics - A plunge into Hate Speech Detection},
	year = {2021},
	journal = {Proceedings - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021},
	pages = {1933 – 1938},
	doi = {10.1109/ICAC3N53548.2021.9725393},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126996522&doi=10.1109%2fICAC3N53548.2021.9725393&partnerID=40&md5=ca16849f02879fa7ff7127e9854ac17c},
	affiliations = {Manav Rachna University, Dept. of Comp. Sc. and Technology, Haryana, India},
	abstract = {From the prime state of distress to the gigantic flood of hatred thriving online, the humanity seems to be poignant. Social media is endemic with hate speech. Moreover, online along with offline hate events are rising at a high pace. This, eventually, makes a call to develop automatic hate speech detection systems. The present study aims to endow with a thorough relative analysis of machine learning algorithms in this regard. The methodologies are investigated with respect to their potencies and limitations for better understanding. The paper also imparts the milieu information about hate speech followed by the challenges faced by researchers while developing the appropriate models. This paper will act as a guide for future researchers of this domain by showing them the path for selecting most suitable machine learning based models.  © 2021 IEEE.},
	author_keywords = {CNN; deep learning; fuzzy; hate speech detection; machine learning; RNN; social media},
	keywords = {Deep learning; Digital forensics; E-learning; Learning algorithms; Speech; Speech recognition; CNN; Deep learning; Fuzzy; Hate speech detection; Learning Based Models; Machine-learning; Prime state; RNN; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 177627}
}

@CONFERENCE{Bose202151,
	author = {Bose, Tulika and Illina, Irina and Fohr, Dominique},
	title = {Generalisability of Topic Models in Cross-corpora Abusive Language Detection},
	year = {2021},
	journal = {NLP4IF 2021 - NLP for Internet Freedom: Censorship, Disinformation, and Propaganda, Proceedings of the 4th Workshop},
	pages = {51 – 56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128049331&partnerID=40&md5=b493338c44e1bba47ec27793ebadbe2e},
	affiliations = {Université de Lorraine, CNRS, Inria, LORIA, Nancy, F-54000, France},
	abstract = {Rapidly changing social media content calls for robust and generalisable abuse detection models. However, the state-of-the-art supervised models display degraded performance when they are evaluated on abusive comments that differ from the training corpus. We investigate if the performance of supervised models for cross-corpora abuse detection can be improved by incorporating additional information from topic models, as the latter can infer the latent topic mixtures from unseen samples. In particular, we combine topical information with representations from a model tuned for classifying abusive comments. Our performance analysis reveals that topic models are able to capture abuse-related topics that can transfer across corpora, and result in improved generalisability. © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Degraded performance; Detection models; Language detection; Media content; Performances analysis; Social media; State of the art; Topic Modeling; Training corpus; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 4th Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda, NLP4IF 2021; Conference date: 6 June 2021; Conference code: 182171}
}

@CONFERENCE{Kanessa202142,
	author = {Kanessa, Lata Guta and Tulu, Solomon Gizaw},
	title = {Automatic Hate and Offensive speech detection framework from social media: The case of Afaan Oromoo language},
	year = {2021},
	journal = {2021 International Conference on Information and Communication Technology for Development for Africa, ICT4DA 2021},
	pages = {42 – 47},
	doi = {10.1109/ICT4DA53266.2021.9672232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125351841&doi=10.1109%2fICT4DA53266.2021.9672232&partnerID=40&md5=e6217d01d7f71acb50ac41e3a570a7e0},
	affiliations = {Dilla University, Department of Computer Science, Dilla, Ethiopia; Addis Ababa University, Department of Computer Science, Addis Ababa, Ethiopia},
	abstract = {The easily accessibility of different online platform allows every individuals people to express their ideas and share experiences easily without any restriction because of freedom of speech. Since social media don't have general framework to identify hate and neutral speech this results anonymity. However, the propagation of hate speech on social media distresses the society in many aspects, such as affecting the mental health of targeted audiences, affects social interaction and distraction of properties. This research proposed the SVM with TF-IDF, N-gram, and W2vec feature extraction to construct dataset which is binary classifier to detect hate speech for Afaan Oromoo language. To construct dataset for this study first we crawl data from Facebook posts and comments by using Face pager and scrap storm API. After we collect we labeled the collected data to two class hate and neutral class. The general objective of this research is to design a framework which classify hate and neutral speech. Furthermore, when we compare the results of different Machine Learning algorithms. The experiment is evaluated based on accuracy, F-score, recall and precision measurements. The framework based on SVM with n-gram combination with TF-IDF achieve 96% in all metrics. © 2021 IEEE.},
	author_keywords = {Afaan Oromoo; Detection; Feature extraction; Hate speech; Machine learning; SVM},
	keywords = {Classification (of information); Computational linguistics; Extraction; Learning algorithms; Social networking (online); Speech; Speech recognition; Support vector machines; Afaan oromoo; Detection; Detection framework; Features extraction; Hate speech; N-grams; Online platforms; Social media; Speech detection; SVM; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 3rd International Conference on Information and Communication Technology for Development for Africa, ICT4DA 2021; Conference date: 22 November 2021 through 24 November 2021; Conference code: 176421}
}

@CONFERENCE{Alsafari2021,
	author = {Alsafari, Safa and Sadaoui, Samira},
	title = {Ensemble-based Semi-Supervised Learning for Hate Speech Detection},
	year = {2021},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {34},
	doi = {10.32473/flairs.v34i1.128427},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124278144&doi=10.32473%2fflairs.v34i1.128427&partnerID=40&md5=4ac50c5f31d74f32fe4743867d04dc2f},
	affiliations = {Department of Computer Science, University of Regina, 3737 Wascana Pkwy, Regina, Canada},
	abstract = {Large and accurately labeled textual corpora are vital to developing efficient hate speech classifiers. This paper introduces an ensemble-based semi-supervised learning approach to leverage the availability of abundant social media content. Starting with a reliable hate speech dataset, we train and test diverse classifiers that are then used to label a corpus of one million tweets. Next, we investigate several strategies to select the most confident labels from the obtained pseudo labels. We assess these strategies by re-training all the classifiers with the seed dataset augmented with the trusted pseudo-labeled data. Finally, we demonstrate that our approach improves classification performance over supervised hate speech classification methods. © 2021by the authors. All rights reserved.},
	author_keywords = {Confidence Threshold; Deep Learning; Hate Speech Classification; Pseudo Label Selection; SemiSupervised Learning},
	keywords = {Classification (of information); Learning algorithms; Speech; Speech recognition; Statistical tests; Supervised learning; Confidence threshold; Deep learning; Hate speech classification; Labeled data; Media content; Pseudo label selection; Semi-supervised learning; Social media; Speech classification; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 34th International Florida Artificial Intelligence Research Society Conference, FLAIRS-34 2021; Conference date: 16 May 2021 through 19 May 2021; Conference code: 277879; All Open Access, Bronze Open Access}
}

@CONFERENCE{Mankar2021110,
	author = {Mankar, Purva and Gangurde, Akshaya and Chaudhari, Deptii and Pawar, Ambika},
	title = {Machine Learning Models for Hate Speech and Offensive Language Identification for Indo-Aryan Language: Hindi},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {110 – 120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121768579&partnerID=40&md5=6b4149662387986548af3a028b2c1794},
	affiliations = {Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Hope Foundation’s International Institute of Information Technology, Pune, India},
	abstract = {Automated recognition and detection of Hate Speech and Offensive language on different Online Social Networks, mainly Twitter, presents a challenge to the community of Artificial Intelligence and Machine Learning. Unfortunately, sometimes these ideas communicated via the internet are intended to promote or incite hatred or humiliation of an individual, community, or even organizations. The HASOC shared task is to attempt to automatically detect abusive language on Twitter in English and Indo-Aryan Languages like Hindi. To participate in this task and provide our input, we Team Data Pirates presented several machine learning models for Hindi Subtasks. The datasets provided allowed the development and testing of supervised machine learning techniques. The top 2 performing models for sub-task A were Naïve Bayes and Logistic Regression with the same Macro F1 score of 0.7394. The top 2 performing models for sub-task B were Logistic Regression and CatBoost, with Macro F1 scores of 0.4828 and 0.4709, respectively. This overview intends to provide detailed understandings and to analyze the outcomes. © 2021 Copyright for this paper by its authors.},
	author_keywords = {CatBoost; HASOC; Hate Speech; Logistic Regression; Machine Learning; Text Classification; TF-IDF},
	keywords = {Classification (of information); Learning systems; Regression analysis; Speech recognition; Supervised learning; Text processing; Catboost; HASOC; Hate speech; Logistics regressions; Machine learning models; Machine-learning; Offensive languages; Subtask; Text classification; TF-IDF; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Long2021868,
	author = {Long, HollyLopez and O'Neil, Alexandra and Kbler, Sandra},
	title = {On the Interaction between Annotation Quality and Classifier Performance in Abusive Language Detection},
	year = {2021},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {868 – 875},
	doi = {10.26615/978-954-452-072-4_099},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123592970&doi=10.26615%2f978-954-452-072-4_099&partnerID=40&md5=25578da4a69d4391a3861c21b94fecf8},
	affiliations = {Indiana University, Bloomington, IN, United States},
	abstract = {Abusive language detection has become an important tool for the cultivation of safe online platforms. We investigate the interaction of annotation quality and classifier performance. We use a new, fine-grained annotation scheme that allows us to distinguish between abusive language and colloquial uses of profanity that are not meant to harm. Our results show a tendency of crowd workers to overuse the abusive class, which creates an unrealistic class balance and affects classification accuracy. We also investigate different methods of distinguishing between explicit and implicit abuse and show lexicon-based approaches either over- or under-estimate the proportion of explicit abuse in data sets. © 2021 Incoma Ltd. All rights reserved.},
	keywords = {Annotation scheme; Classification accuracy; Classifier performance; Data set; Fine grained; Language detection; Lexicon-based; Online platforms; Quality performance; Workers'},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: International Conference on Recent Advances in Natural Language Processing: Deep Learning for Natural Language Processing Methods and Applications, RANLP 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 176177; All Open Access, Bronze Open Access}
}

@CONFERENCE{Mercan2021,
	author = {Mercan, Vildan and Jamil, Akhtar and Hameed, Alaa Ali and Magsi, Irfan Ahmed and Bazai, Sibghatullah and Shah, Syed Attique},
	title = {Hate Speech and Offensive Language Detection from Social Media},
	year = {2021},
	journal = {2021 International Conference on Computing, Electronic and Electrical Engineering, ICE Cube 2021 - Proceedings},
	doi = {10.1109/ICECube53880.2021.9628255},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123788929&doi=10.1109%2fICECube53880.2021.9628255&partnerID=40&md5=b07a039fc3c52f2110aa7bd9e78c0bff},
	affiliations = {Istanbul Sabahattin Zaim University, Department of Computer Engineering, Istanbul, Turkey; National University of Computer and Emerging Sciences, Department of Computer Science, Islamabad, Pakistan; BUITEMS, Department of Information Technology, Quetta, Pakistan; BUITEMS, Department of Computer Engineering, Quetta, Pakistan; BUITEMS, Department of Computer Science, Quetta, Pakistan},
	abstract = {In recent years, the advent of social media platforms has led users to freely express their opinions on various subjects, including politics, society, health, education, finance, and even business-related issues. However, this widespread usage of social media has also increased the risk of its misuse by some groups resulting in spreading hate speeches or offensive language. This paper investigates machine learning methods for hate speech classification and compared its results with advanced deep learning models to evaluate its efficiency. The data from Twitter, a popular microblogging social media platform for sharing short digital content, was used for experiments in this study. Each tweet was labeled into one of three categories: hate speech, offensive, neutral. Four machine learning methods were investigated: logistic regression (LR), random forest (RF), naive Bayes (NB), and support vector machine (SVM). The results were compared with two deep learning-based models: recurrent neural networks (RNN) and bidirectional encoder representations (BERT). The overall results indicated that both machine learning and deep learning models were effective for hate speech recognition. The highest overall accuracy was obtained using BERT (87.78%), while SVM produced the best (84.66%) among traditional classifiers.  © 2021 IEEE.},
	author_keywords = {deep learning; hate speech recognition; machine learning; social media analysis; text analytics},
	keywords = {Character recognition; Convolutional neural networks; Decision trees; Logistic regression; Recurrent neural networks; Speech; Speech recognition; Support vector machines; Deep learning; Hate speech recognition; Learning models; Machine learning methods; Offensive languages; Social media; Social media analysis; Social media platforms; Support vectors machine; Text analytics; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 2021 International Conference on Computing, Electronic and Electrical Engineering, ICE Cube 2021; Conference date: 26 November 2021 through 27 November 2021; Conference code: 175387}
}

@CONFERENCE{Biradar20212470,
	author = {Biradar, Shankar and Saumya, Sunil and Chauhan, Arun},
	title = {Hate or Non-hate: Translation based hate speech identification in Code-Mixed Hinglish data set},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
	pages = {2470 – 2475},
	doi = {10.1109/BigData52589.2021.9671526},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125302345&doi=10.1109%2fBigData52589.2021.9671526&partnerID=40&md5=18f638dbddf746f804cc941c063346d0},
	affiliations = {Indian Institute of Information Technology Dharwad, Dept of Computer Science and Engineering, Dharwad, India; Graphic Era University, Dept of Computer Science and Engineering, Dehradun, India},
	abstract = {Hate speech identification in social media has emerged as a highly debated research topic in computational linguistics. Understanding linguistic phenomena in low-resource languages, in particular, remains a major problem in natural language processing. Code-mixing is a common phenomenon in social media writing, particularly in multilingual societies such as India. Traditional deep learning techniques trained on monolingual data will not perform well on code-mixed data, and training new models are challenging due to a lack of resources. Converting multilingual data into monolingual is an important solution to this challenge. TIF-DNN, a Transformer-based Interpretation and Feature Extraction Model is proposed in this work for hate speech identification. We used the IndicNLP and Englishtohindi libraries for transliteration and translation, respectively, and mBERT for feature extraction in our suggested model. Later, we compared our findings to various baseline and existing models. © 2021 IEEE.},
	author_keywords = {deep learning; hate speech; mBERT; Trans-former},
	keywords = {Deep learning; Extraction; Feature extraction; Linguistics; Natural language processing systems; Speech recognition; Translation (languages); Data set; Deep learning; Features extraction; Hate speech; Linguistic phenomena; MBERT; Research topics; Social media; Speech identification; Trans-former; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 2021 IEEE International Conference on Big Data, Big Data 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 176404}
}

@CONFERENCE{Prabhu Ram2021976,
	author = {Prabhu Ram, N. and Meeradevi, T. and Vinod, Vibin Mammen and Gothainayaki, A. and Anusha, S. and Agalya, T.},
	title = {COMPARATIVE ANALYSIS FOR OFFENSIVE LANGUAGE IDENTIFICATION OF TAMIL TEXT USING SVM AND LOGISTIC CLASSIFIER},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {976 – 983},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134205692&partnerID=40&md5=bb9a1b956164998cd7983956351b455e},
	affiliations = {Electronics and Communication Engineering, Kongu Engineering College, TamilNadu, Erode, India},
	abstract = {Social media like Twitter, Facebook, YouTube provide an opportunity of the fastest communication between people. The social media texts are largely filled with code-mixed comments/post and reactions and its content may be filled with offensive language or non-offensive language. It is necessary to classify the YouTube comments/post and reactions as offensive label and non-offensive label. As the offensive comments/post is very sensational to something or someone to react in the society, Government has responsibility to identify it in the social media, before it reaches a larger audience. In India, multi-lingual practices use code mixed comments/post in social media, which leads to difficulty in offensive text classification automatically. The Dravidian code mixed data set is used to train the machine learning model to classify the label as offensive language or non-offensive language. The text data set is transformed into numerical data based on relative occurrence in the available datasets of training and testing using TFIDF method. However, the imbalanced dataset may be biased to a particular class of label, and hence it is turned into balanced dataset using SMOTE method. It is trained on SVM classifier and Logistic Classifier. The F1 score is analsyed and it is observed that balanced dataset predictions are better than unbalanced dataset predictions. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Logistic classifier; Machine Learning; Multilingual; NLP; SMOTE; SVM; TFIDF},
	keywords = {Learning algorithms; Learning systems; Numerical methods; Social networking (online); Statistical tests; Support vector machines; Text processing; Data set; Logistic classifier; Machine-learning; Multilingual; Offensive languages; SMOTE; Social media; SVM; TFIDF; YouTube; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Abdou20211415,
	author = {Abdou, Aziz L. Ngou Njikam and Tagne, Elie Fute},
	title = {A Sentiment Analysis Approach for Abusive Content Detection using Improved Dataset},
	year = {2021},
	journal = {Proceedings - 2021 International Conference on Computational Science and Computational Intelligence, CSCI 2021},
	pages = {1415 – 1420},
	doi = {10.1109/CSCI54926.2021.00283},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133934239&doi=10.1109%2fCSCI54926.2021.00283&partnerID=40&md5=62942e1d3f440e3d7587b37c00f29992},
	affiliations = {Nanjing University of Science and Technology, Nanjing, China; University of Dschang, University of Buea, Faculty of Science, Faculty of Engineeering and Technology, Buea, Cameroon},
	abstract = {The rapid growth of information and communications technologies has led to the generation of enormous amount of information daily. Consequently, there has been an increased interest in effective data processing. The nature of the information is varied and can in some cases include users' emotions and opinions. Faced with this situation, the need of proposing social media monitoring and content filtering is a major asset for the community. The specific case of abusive content is becoming more relevant these recent years leading to the proposition of many models which unfortunately suffer from the unbalanced nature of the dataset used. We propose a sentiment analysis approach which classifies social media posts according to three categories: hate, abusive and neutral. The approach is based on a constructed dataset which reduces unbalancing and improves classification results. © 2021 IEEE.},
	author_keywords = {Abusive Content; Hate Content; Sentiment Analysis; social media; Unbalanced Dataset},
	keywords = {Classification (of information); Data handling; Social networking (online); Abusive content; Amount of information; Analysis approach; Content detection; Hate content; Information and Communication Technologies; Rapid growth; Sentiment analysis; Social media; Unbalanced datasets; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Conference on Computational Science and Computational Intelligence, CSCI 2021; Conference date: 15 December 2021 through 17 December 2021; Conference code: 180282}
}

@CONFERENCE{Liu20211727,
	author = {Liu, Huan and Chang, Jun and Zhang, Li and Huang, Bin},
	title = {CSI-Based Violent Behavior Detection Method},
	year = {2021},
	journal = {2021 7th International Conference on Computer and Communications, ICCC 2021},
	pages = {1727 – 1732},
	doi = {10.1109/ICCC54389.2021.9674343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125359954&doi=10.1109%2fICCC54389.2021.9674343&partnerID=40&md5=1896d14b0ee2a82dfa13b215a409ad80},
	affiliations = {Dept. School of Information Science and Engineering, Yunnan University, Kunming, China},
	abstract = {People are deeply saddened by the endless incidents of domestic violence and school violence. However, the existing real-time monitoring methods of violence have some shortcomings, such as high deployment cost, exposure of privacy and so on. In order to solve the above problems, a violence detection method based on channel state information (CSI) is proposed. Firstly, uses wavelet denoising and smoothing filtering to suppress the noise of signal, and then calculates the sliding variance to extract the existence of activities. Secondly, in order to make full use of the effective information in CSI, combine image domain, time domain, and frequency domain features, and finally put the three-domain features into the support vector machine(SVM) for behavior classification. The experimental results show that the average recognition accuracy of classifying 10 kinds of behaviors (daily and violent behavior) in darkroom and laboratory scenes can achieve 97.3% and 92.7% respectively.  © 2021 IEEE.},
	author_keywords = {channel state information; multi-domain features; ray-level co-occurrence matrix; support vector machine; vehavior recognition; wavelet denoising},
	keywords = {Channel state information; Classification (of information); Frequency domain analysis; Time domain analysis; Wavelet analysis; Channel-state information; Cooccurrence matrixes (COM); Detection methods; Domain feature; Multi-domain features; Ray-level co-occurrence matrix; Support vectors machine; Vehavior recognition; Violent behavior; Wavelet denoising; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th International Conference on Computer and Communications, ICCC 2021; Conference date: 10 December 2021 through 13 December 2021; Conference code: 176466}
}

@CONFERENCE{Vargas20211438,
	author = {Vargas, Francielle and Góes, Fabiana and Carvalho, Isabelle and Benevenuto, Fabrício and Pardo, Thiago A.S.},
	title = {Contextual-Lexicon Approach for Abusive Language Detection},
	year = {2021},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1438 – 1447},
	doi = {10.26615/978-954-452-072-4_161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123599240&doi=10.26615%2f978-954-452-072-4_161&partnerID=40&md5=423e20f534b9ea27a0fdb6d2c7ad8cbc},
	affiliations = {Institute of Mathematical and Computer Sciences, University of São Paulo, Brazil; Ribeirão Preto Medical School, University of São Paulo, Brazil; Computer Science Department, Federal University of Minas Gerais, Brazil},
	abstract = {Since a lexicon-based approach is more elegant scientifically, explaining the solution components and being easier to generalize to other applications, this paper provides a new approach for offensive language and hate speech detection on social media, which embodies a lexicon of implicit and explicit offensive and swearing expressions annotated with contextual information. Due to the severity of the social media abusive comments in Brazil, and the lack of research in Portuguese, Brazilian Portuguese is the language used to validate the models. Nevertheless, our method may be applied to any other language. The conducted experiments show the effectiveness of the proposed approach, outperforming the current baseline methods for the Portuguese language. © 2021 Incoma Ltd. All rights reserved.},
	keywords = {'current; Baseline methods; Contextual information; Language detection; Lexicon-based; New approaches; Offensive languages; Social media; Solution components; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: International Conference on Recent Advances in Natural Language Processing: Deep Learning for Natural Language Processing Methods and Applications, RANLP 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 176177; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Aljero2021115115,
	author = {Aljero, Mona Khalifa A. and Dimililer, Nazife},
	title = {Genetic Programming Approach to Detect Hate Speech in Social Media},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {115115 – 115125},
	doi = {10.1109/ACCESS.2021.3104535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113936232&doi=10.1109%2fACCESS.2021.3104535&partnerID=40&md5=6a9ad8939ccb9b3304477403a472dafd},
	affiliations = {Department of Applied Mathematics and Computer Sciences, Eastern Mediterranean University Famagusta, North Cyprus, 99628, Turkey; Faculty of Information Technology, Eastern Mediterranean University Famagusta, North Cyprus, 99628, Turkey},
	abstract = {Social media sites, which became central to our everyday lives, enable users to freely express their opinions, feelings, and ideas due to a certain level of depersonalization and anonymity they provide. If there is no control, these platforms may be used to propagate hate speech. In fact, in recent years, hate speech has increased on social media. Therefore, there is a need to monitor and prevent hate speech on these platforms. However, manual control is not feasible due to the high traffic of content production on social media sites. Moreover, the language used and the length of the messages provide a challenge when using classical machine learning approaches as prediction methods. This paper presents a genetic programming (GP) model for detecting hate speech where each chromosome represents a classifier employing a universal sentence encoder as a feature. A novel mutation technique that affects only the feature values in combination with the standard one-point mutation technique improved the performance of the GP model by enriching the offspring pool with alternative solutions. The proposed GP model outperformed all state-of-the-art systems for the four publicly available hate speech datasets.  © 2013 IEEE.},
	author_keywords = {Classification algorithms; genetic programming; machine learning; prediction methods},
	keywords = {Chromosomes; Genetic algorithms; Genetic programming; Social networking (online); Speech; Alternative solutions; Content production; Feature values; Machine learning approaches; Novel mutations; Point mutations; Prediction methods; State-of-the-art system; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@CONFERENCE{Jahan2021226,
	author = {Jahan, Md Saroar and Oussalah, Mourad and Mim, Jhuma kabir and Islam, Mominul},
	title = {Offensive Language Identification Using Hindi-English Code-Mixed Tweets, and Code-Mixed Data Augmentation},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {226 – 238},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134223366&partnerID=40&md5=128cc5a02563c13b5d377ae61ea0544b},
	affiliations = {University of Oulu, Faculty of Information Tech., CMVS, PO Box 4500, Oulu, 90014, Finland; LUT Univerity, Dept of Computational Engineering, Lappeenranta, 53850, Finland; Daffodil International University, Dhaka, 1207, Bangladesh},
	abstract = {The Code-mixed text classification is challenging due to the lack of code-mixed labeled datasets and the non-existence of pre-trained models. This paper presents the HASOC-2021 offensive language identification results and main findings on code-mixed (Hindi-English) Subtask2. In this work, we have proposed a new method of code-mixed data augmentation using synonym replacement of Hindi and English words using WordNet, and phonetics conversion of Hinglish (Hindi-English) words. We used a 5.7k pre-annotated HASOC-2021 code-mixed dataset for training and data augmentation. The proposal’s feasibility was tested with a Logistic Regression (LR) used as a baseline, Convolutional Neural Network (CNN), and BERT with and without data augmentation. The research outcomes were promising and yields almost 3% increase of classifier accuracy and F1 scores as compared to baseline. Our official submission showed a 66.56% F1 score and ranked 8th position in the competition. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Code-mixed Data Augmentation; Code-mixed Hindi-Englsih; Offensive language identification},
	keywords = {Computational linguistics; Convolutional neural networks; Logistic regression; Natural language processing systems; Text processing; Code-mixed data augmentation; Code-mixed hindi-englsih; Data augmentation; English word; F1 scores; Language identification; Mixed data; Offensive language identification; Offensive languages; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Caselli202117,
	author = {Caselli, Tommaso and Basile, Valerio and Mitrović, Jelena and Granitzer, Michael},
	title = {HateBERT: Retraining BERT for Abusive Language Detection in English},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {17 – 25},
	doi = {10.18653/v1/2021.woah-1.3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133916841&doi=10.18653%2fv1%2f2021.woah-1.3&partnerID=40&md5=1e302a8257b84d377d54366cad07a08c},
	affiliations = {University of Groningen, Netherlands; University of Turin, Italy; University of Passau, Germany},
	abstract = {We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.  © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Speech recognition; Detection tasks; Language detection; Language model; Large-scale datasets; Speech detection; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 137; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference date: 6 August 2021; Conference code: 182536; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Aquino2021661,
	author = {Aquino, Michael and Ortiz, Yasiris and Rashid, Arif and Tumlin, Anne M. and Artan, N. Sertac and Dong, Ziqian and Gu, Huanying},
	title = {Toxic Comment Detection: Analyzing the Combination of Text and Emojis},
	year = {2021},
	journal = {Proceedings - 2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems, MASS 2021},
	pages = {661 – 662},
	doi = {10.1109/MASS52906.2021.00097},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123955277&doi=10.1109%2fMASS52906.2021.00097&partnerID=40&md5=6bf370042c225b7e05484bf24991e405},
	affiliations = {New York Institute Of Technology, Department Of Electrical And Computer Engineering, New York, 10023, NY, United States; New York Institute Of Technology, Department Of Computer Science, New York, 10023, NY, United States; The City College Of New York, Department Of Computer Science, United States; University Of South Carolina, Department Of Computer Science And Engineering, United States},
	abstract = {Detection of toxicity in online commentary is a growing branch of Natural Language Processing (NLP). Most research in the area rely only on text-based toxic comment detection. We propose a machine learning approach for detecting the toxicity of a comment by analyzing both the text and the emojis within the comment. Our approach utilizes word embeddings derived from GloVe and emoji2vec to train a bidirectional Long Short Term Memory (biLSTM) model. We also create a new labeled dataset with comments with text and emojis. The accuracy score of our model on preliminary data is 0.911. © 2021 IEEE.},
	author_keywords = {Emojis.; Natural language processing (NLP); Toxic comments},
	keywords = {Learning algorithms; Toxicity; Embeddings; Emojis.; Labeled dataset; Machine learning approaches; Memory modeling; Natural language processing; Toxic comment; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 18th IEEE International Conference on Mobile Ad Hoc and Smart Systems, MASS 2021; Conference date: 4 October 2021 through 7 October 2021; Conference code: 175553}
}

@CONFERENCE{Putri2021461,
	author = {Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},
	title = {Abusive language and hate speech detection for Javanese and Sundanese languages in tweets: Dataset and preliminary study},
	year = {2021},
	journal = {2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},
	pages = {461 – 465},
	doi = {10.18178/wcse.2021.02.011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114203618&doi=10.18178%2fwcse.2021.02.011&partnerID=40&md5=8a597b8d3cd3381f0e169cc599a8bfb6},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Depok, 16424, Indonesia},
	abstract = {Indonesia’s demography as an archipelago with lots of tribes and local languages added variances in their communication style. Every region in Indonesia has its own distinct culture, accents, and languages. The demographical condition can influence the characteristic of the language used in social media, such as Twitter. It can be found that Indonesian uses their own local language for communicating and expressing their mind in tweets. Nowadays, research about identifying hate speech and abusive language has become an attractive and developing topic. Moreover, the research related to Indonesian local languages still rarely encountered. This paper analyzes the use of machine learning approaches such as Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) in detecting hate speech and abusive language in Sundanese and Javanese as Indonesian local languages. The classifiers were used with the several term weightings features, such as word n-grams and char n-grams. The experiments are evaluated using the F-measure. It achieves over 60 % for both local languages. © 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021. All Rights Reserved.},
	author_keywords = {Abusive; Hate speech; Indonesian local language; Javanese; Sundanese; Twitter},
	keywords = {Decision trees; Demography; Population statistics; Social networking (online); Speech recognition; Support vector machines; Communication styles; F measure; Indonesia; Local language; Machine learning approaches; Social media; Speech detection; Word n-grams; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021; Conference date: 19 June 2021 through 21 June 2021; Conference code: 171371; All Open Access, Bronze Open Access}
}

@CONFERENCE{Shome20214524,
	author = {Shome, Debaditya and Kar, T.},
	title = {ConOffense: Multi-modal multitask Contrastive learning for offensive content identification},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
	pages = {4524 – 4529},
	doi = {10.1109/BigData52589.2021.9671427},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125316860&doi=10.1109%2fBigData52589.2021.9671427&partnerID=40&md5=ae635e5a737520d26faa433471711582},
	affiliations = {KIIT University, School of Electronics Engineering, Odisha, India},
	abstract = {Hateful or offensive content has been increasingly common on social media platforms in recent years, and the problem is now widespread. There is a pressing need for effective automatic solutions for detecting such content, especially due to the gigantic size of social media data. Although significant progress has been made in the automated identification of offensive content, most of the focus has been on only using textual information. It can be easily noticed that with the rise in visual information shared on these platforms, it is quite common to have hateful content on images rather than in the associated text. Due to this, present day unimodal text-based methods won't be able to cope up with the multimodal hateful content. In this paper, we propose a novel multimodal neural network powered by contrastive learning for identifying offensive posts on social media utilizing both visual and textual information. We design the text and visual encoders with a lightweight architecture to make the solution efficient for real world use. Evaluation on the MMHS150K dataset shows state-of-the-art performance of 82.6 percent test accuracy, making an improvement of approximately +14.1 percent accuracy over the previous best performing benchmark model on the dataset. © 2021 IEEE.},
	author_keywords = {Contrastive learning; Multimodal learning; Offensive content identification; Representation learning; Social media},
	keywords = {Benchmarking; Computer vision; Statistical tests; Content identifications; Contrastive learning; Multi-modal; Multi-modal learning; Offensive content identification; Representation learning; Social media; Social media platforms; Textual information; Visual information; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 IEEE International Conference on Big Data, Big Data 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 176404}
}

@CONFERENCE{Sazzed2021125,
	author = {Sazzed, Salim},
	title = {Abusive content detection in transliterated Bengali-English social media corpus},
	year = {2021},
	journal = {Computational Approaches to Linguistic Code-Switching, CALCS 2021 - Proceedings of the 5th Workshop},
	pages = {125 – 130},
	doi = {10.26615/978-954-452-056-4_016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119440378&doi=10.26615%2f978-954-452-056-4_016&partnerID=40&md5=9d0e22a40898935c1df7cf81235074d9},
	affiliations = {Old Dominion University, Norfolk, VA, United States},
	abstract = {Abusive text detection in low-resource languages such as Bengali is a challenging task due to the inadequacy of resources and tools. The ubiquity of transliterated Bengali comments in social media makes the task even more involved as monolingual approaches cannot capture them. Unfortunately, no transliterated Bengali corpus is publicly available yet for abusive content analysis. Therefore, in this paper, we introduce an annotated corpus of 3000 transliterated Bengali comments categorized into two classes, abusive and non-abusive, 1500 comments for each. For baseline evaluations, we employ several supervised machine learning (ML) and deep learning-based classifiers. We find support vector machine (SVM) classifier shows the highest efficacy for identifying abusive content. We make the annotated corpus publicly available for the researchers to aid abusive content detection in Bengali social media data. © 2021 Association for Computational Linguistics.},
	keywords = {Deep learning; Learning algorithms; Support vector machines; Bengalis; Content analysis; Content detection; Low resource languages; Social media; Social media datum; Supervised machine learning; Support vector machine classifiers; Text detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 5th Workshop on Computational Approaches to Linguistic Code-Switching, CALCS 2021; Conference date: 11 June 2021; Conference code: 175246; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Romero2021533,
	author = {Romero, Sergio Esteban and Kleinlein, Ricardo and Luna-Jiménez, Cristina and Montero, Juan Manuel and Fernández-Martínez, Fernando},
	title = {Gth-upm at detoxis-iberlef 2021: Automatic detection of toxic comments in social networks},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2943},
	pages = {533 – 546},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115289638&partnerID=40&md5=bf575f93044f9213dde5bc76c2d8cbad},
	affiliations = {Speech Technology Group, Center for Information Processing and Telecommunications, E.T.S.I. de Telecomunicacion, Universidad Politecnica de Madrid, Av. Complutense No 30, Madrid, 28040, Spain},
	abstract = {Sadly, the presence of toxic messages on social networks, whether in the form of stereotypes, sarcasm, mockery, insult, inappropriate language, aggressiveness, intolerance, or typical of hate speech against immigrants and / or women, among others, is relatively frequent. This presence should not be ignored by the scientific community, since it is their responsibility to develop tools and systems that allow their automatic detection and elimination. In this paper, we present an exploratory analysis in which different deep learning (DL) models for the detection of toxic expressions have been evaluated on the DETOXISIberLEF 2021 challenge using the official release of the NewsCom-TOX corpus. Particularly, we compare traditional RNN and state-of-the-art transformer models. Our experiments confirmed that optimum performance can be obtained from transformer models. Specifically, top performance was achieved by fine tuning a BETO model (the pre-trained BERT model for the Spanish language from the Universidad de Chile) for the toxicity detection tasks. Another contribution of this analysis is the validation of the proposed method for adding task-specific vocabulary (new tokens) that could help to effectively extend the original vocabulary of the pre-trained models. © 2021 CEUR-WS. All rights reserved.},
	author_keywords = {Attention; Classification task; Recurrent networks; Social networks; Toxicity detection; Transfer learning; Transformer models},
	keywords = {Natural language processing systems; Toxicity; Attention; Automatic Detection; Classification tasks; Exploratory analysis; Recurrent networks; Scientific community; Social network; Toxicity detection; Transfer learning; Transformer modeling; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 Iberian Languages Evaluation Forum, IberLEF 2021; Conference date: 21 September 2021; Conference code: 171720}
}

@CONFERENCE{Karim2021,
	author = {Karim, Md Rezaul and Dey, Sumon Kanti and Islam, Tanhim and Sarker, Sagor and Menon, Mehadi Hasan and Hossain, Kabir and Hossain, Md Azam and Decker, Stefan},
	title = {DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language},
	year = {2021},
	journal = {2021 IEEE 8th International Conference on Data Science and Advanced Analytics, DSAA 2021},
	doi = {10.1109/DSAA53316.2021.9564230},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126091003&doi=10.1109%2fDSAA53316.2021.9564230&partnerID=40&md5=93a8950f1ecf8a73df2b40007341f7c6},
	affiliations = {Fraunhofer Institute for Applied Information Technology FIT, Germany; Computer Science 5 - Information Systems and Databases, RWTH Aachen University, Germany; Noakhali Science and Technology University, Noakhali, Bangladesh; Begum Rokeya University, Rangpur, Bangladesh; The University of Alabama, Tuscaloosa, United States; Islamic University of Technology, Gazipur, Bangladesh},
	abstract = {In this paper, we propose an explainable approach for hate speech detection from the under-resourced Bengali language, which we called DeepHateExplainer. In our approach, Bengali texts are first comprehensively preprocessed, before classifying them into political, personal, geopolitical, and religious hates using a neural ensemble method of transformer-based neural architectures (i.e., monolingual Bangla BERT-base, multilingual BERT-cased/uncased, and XLM-RoBERTa). Subsequently, important (most and least) terms are identified using sensitivity analysis and layer-wise relevance propagation (LRP), before providing human-interpretable explanations1. Finally, we compute comprehensiveness and sufficiency scores to measure the quality of explanations w.r.t faithfulness. Evaluations against machine learning (linear and tree-based models) and neural networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines yield F1-scores of 78%, 91%, 89%, and 84%, for political, personal, geopolitical, and religious hates, respectively, outperforming both ML and DNN baselines2 © 2021 IEEE.},
	author_keywords = {Bengali; Embeddings; Hate speech detection; Interpretability; Transformers; Under-resourced language},
	keywords = {Backpropagation; Embeddings; Long short-term memory; Speech recognition; Bengali language; Bengalis; Embeddings; Hate speech detection; Interpretability; Neural ensembles; Speech detection; Transformer; Under-resourced; Under-resourced languages; Sensitivity analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 59; Conference name: 8th IEEE International Conference on Data Science and Advanced Analytics, DSAA 2021; Conference date: 6 October 2021 through 9 October 2021; Conference code: 176932; All Open Access, Green Open Access}
}

@CONFERENCE{Mitra2021349,
	author = {Mitra, Arka and Sankhala, Priyanshu},
	title = {Multilingual Hate Speech and Offensive Content Detection using Modified Cross-entropy Loss},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {349 – 356},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134216842&partnerID=40&md5=52acd67f19192f0f791c21bd263e79b7},
	affiliations = {Indian Institute of Technology, Kharagpur, India; National Institute of Technology, Raipur, India},
	abstract = {The number of increased social media users has led to a lot of people misusing these platforms to spread offensive content and use hate speech. Manual tracking the vast amount of posts is impractical so it is necessary to devise automated methods to identify them quickly. Large language models are trained on a lot of data and they also make use of contextual embeddings. We fine-tune the large language models to help in our task. The data is also quite unbalanced; so we used a modified cross-entropy loss to tackle the issue. We observed that using a model which is fine-tuned in hindi corpora performs better. Our team (HNLP) achieved the macro F1-scores of 0.808, 0.639 in English Subtask A and English Subtask B respectively. For Hindi Subtask A, Hindi Subtask B our team achieved macro F1-scores of 0.737, 0.443 respectively in HASOC 2021. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Deep-learning; Hate speech detection; Text classification; Transfer learning},
	keywords = {Classification (of information); Computational linguistics; Deep learning; Speech recognition; Text processing; Transfer learning; Cross entropy; Deep-learning; Entropy loss; F1 scores; Hate speech detection; Language model; Speech detection; Subtask; Text classification; Transfer learning; Entropy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}

@CONFERENCE{Gong202114804,
	author = {Gong, Hongyu and Valido, Alberto and Ingram, Katherine M. and Fanti, Giulia and Bhat, Suma and Espelage, Dorothy L.},
	title = {Abusive Language Detection in Heterogeneous Contexts: Dataset Collection and the Role of Supervised Attention},
	year = {2021},
	journal = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
	volume = {17A},
	pages = {14804 – 14812},
	doi = {10.1609/aaai.v35i17.17738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129841182&doi=10.1609%2faaai.v35i17.17738&partnerID=40&md5=3b9411572ae0b235e8ee11bd961ae876},
	affiliations = {University of Illinois at Urbana-Champaign, United States; University of North Carolina at Chapel Hill, United States; Carnegie Mellon University, United States},
	abstract = {Abusive language is a massive problem in online social platforms. Existing abusive language detection techniques are particularly ill-suited to comments containing heterogeneous abusive language patterns, i.e., both abusive and non-abusive parts. This is due in part to the lack of datasets that explicitly annotate heterogeneity in abusive language. We tackle this challenge by providing an annotated dataset of abusive language in over 11,000 comments from YouTube. We account for heterogeneity in this dataset by separately annotating both the comment as a whole and the individual sentences that comprise each comment. We then propose an algorithm that uses a supervised attention mechanism to detect and categorize abusive content using multi-task learning. We empirically demonstrate the challenges of using traditional techniques on heterogeneous content and the comparative gains in performance of the proposed approach over state-of-the-art methods. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Annotated datasets; Attention mechanisms; Language detection; Language patterns; Multitask learning; Performance; State-of-the-art methods; Traditional techniques; YouTube},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 35th AAAI Conference on Artificial Intelligence, AAAI 2021; Conference date: 2 February 2021 through 9 February 2021; Conference code: 176953; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mansourifar2021341,
	author = {Mansourifar, Hadi and Alsagheer, Dana and Fathi, Reza and Shi, Weidong and Ni, Lan and Huang, Yan},
	title = {Hate Speech Detection in Clubhouse},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1525 CCIS},
	pages = {341 – 351},
	doi = {10.1007/978-3-030-93733-1_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126193882&doi=10.1007%2f978-3-030-93733-1_24&partnerID=40&md5=9faf5414358b57d3e8cef7701b0d2d02},
	affiliations = {Computer Science Department, University of Houston, Houston, 77004, TX, United States; Valenti School of Communication, University of Houston, Houston, 77004, TX, United States},
	abstract = {With the rise of voice chat rooms, a gigantic resource of data can be exposed to the research community for natural language processing tasks. Moderators in voice chat rooms actively monitor the discussions and remove the participants with offensive language. However, it makes the hate speech detection even more difficult since some participants try to find creative ways to articulate hate speech. This makes the hate speech detection challenging in new social media like Clubhouse. To the best of our knowledge, all the hate speech datasets have been collected from text resources like Twitter. In this paper, we take the first step to collect a significant dataset from Clubhouse as the rising star in social media industry. We analyze the collected instances from statistical point of view using the Google Perspective Scores. Our experiments show that, the Perspective Scores can outperform Bag of Words and Word2Vec as high level text features. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Clubhouse; Counter hate speech; Social computing},
	keywords = {Natural language processing systems; Social networking (online); Speech recognition; Chat rooms; Counter hate speech; Creatives; Exposed to; Media industry; Offensive languages; Research communities; Social media; Speech detection; Voice chat; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 21st European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2021; Conference date: 13 September 2021 through 17 September 2021; Conference code: 273779}
}

@CONFERENCE{Akhilesh Naidu2021,
	author = {Akhilesh Naidu, T. and Kumar, Shailender},
	title = {Impact of Deep Learning Models on Hate Speech Detection},
	year = {2021},
	journal = {2021 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021},
	doi = {10.1109/ICCCNT51525.2021.9579608},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126205119&doi=10.1109%2fICCCNT51525.2021.9579608&partnerID=40&md5=44ad9b8cff7e48ae16082c6731afef9f},
	affiliations = {Department of Computer Science Engineering, Delhi Technological Univesity, New Delhi, India},
	abstract = {Internet one of the mediums of connectivity that is available at the doorstep, with access to the internet one gets access to many web-based platforms. An increase in the use of these platforms gives us some benefits as well as some drawbacks. One of such drawbacks is hate speech. Hate speech is a topic of concern for social media platforms. With dynamically increasing datasets manual intervention of posts is quite impossible or will be time-consuming. Hate speech detection is an automated task to detect hate speech from the input. In this paper, we have compared some deep learning models like Convolution Neural Network (CNN), Recurrence Neural Network (RNN), Long Gated Recurrent Unit (GRU), and Long-Short Term Memory. The datasets used here are publicly available. The result of our analysis shows us that GRU performed better than other basic deep learning models. The model achieved an accuracy of 92.60% with an F1 score of 81.84% for dataset (D1) and the respective values for dataset (D2) are 96.15% and 83.06%. © 2021 IEEE.},
	author_keywords = {CNN; GRU; LSTM; RNN; SVM},
	keywords = {Long short-term memory; Speech recognition; Support vector machines; Convolution neural network; Gated recurrent unit; Learning models; LSTM; Neural-networks; Recurrence neural network; Social media platforms; Speech detection; SVM; Web based platform; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021; Conference date: 6 July 2021 through 8 July 2021; Conference code: 177114}
}

@CONFERENCE{Yadav2021,
	author = {Yadav, Yogesh and Bajaj, Parth and Gupta, Rohan Kumar and Sinha, Rohit},
	title = {A Comparative Study of Deep Learning Methods for Hate Speech and Offensive Language Detection in Textual Data},
	year = {2021},
	journal = {Proceedings of the 2021 IEEE 18th India Council International Conference, INDICON 2021},
	doi = {10.1109/INDICON52576.2021.9691704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126397191&doi=10.1109%2fINDICON52576.2021.9691704&partnerID=40&md5=52a81185fb6b9b8b23e11a54022130bf},
	affiliations = {Indian Institute of Technology Guwahati, Department of Electronics and Electrical Engineering, Guwahati, 781039, India},
	abstract = {The problem of hate speech on social network sites is very prevalent which is being faced by every major social media platform. Several methods have been explored for the purpose of intent-based text classification. Each method has its own pros and cons concerning the type of intent, size of data set, the maximum length of text, etc. Several approaches have been presented in the literature for the hate and offensive speech detection. The main objective of this work is to present a comparative study among select deep learning methods for hate speech and offensive language detection. These methods include recurrent neural network (RNN), convolutional neural network (CNN), long shortterm memory (LSTM) and bidirectional encoder representations from transformer (BERT). We have investigated the effect of class weighting technique on the performance of the deep learning methods. Our study finds that the pre-trained BERT model outperforms the other explored models in case of both unweighted and weighted hate speech classification. For offensive language classification, RNN and CNN model outperforms all other models in case of unweighted and weighted respectively. It came out that, the class weighting technique has considerably boost the classification performance of all four models for hate speech. © 2021 IEEE.},
	author_keywords = {Deep learning models; Hate speech; NLP; Offensive language; Word2Vec},
	keywords = {Classification (of information); Convolutional neural networks; Long short-term memory; Speech recognition; Text processing; Comparatives studies; Convolutional neural network; Deep learning model; Hate speech; Language detection; Learning methods; Learning models; Offensive languages; Weighting techniques; Word2vec; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 18th IEEE India Council International Conference, INDICON 2021; Conference date: 19 December 2021 through 21 December 2021; Conference code: 176863}
}

@CONFERENCE{Nayak2021217,
	author = {Nayak, Ravindra and Joshi, Raviraj},
	title = {Contextual Hate Speech Detection in Code Mixed Text using Transformer Based Approaches},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3159},
	pages = {217 – 225},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133654236&partnerID=40&md5=e658732ecd76888a0dc01d953fa6485c},
	affiliations = {Sri Jayachamarajendra College of Engineering, Mysore, India; Indian Institute of Technology Madras, Chennai, India},
	abstract = {In the recent past, social media platforms have helped people in connecting and communicating to a wider audience. But this has also led to a drastic increase in cyberbullying. It is essential to detect and curb hate speech to keep the sanity of social media platforms. Also, code mixed text containing more than one language is frequently used on these platforms. We, therefore, propose automated techniques for hate speech detection in code mixed text from scraped Twitter. We specifically focus on code mixed English-Hindi text and transformer-based approaches. While regular approaches analyze the text independently, we also make use of content text in the form of parent tweets. We try to evaluate the performances of multilingual BERT and Indic-BERT in single-encoder and dual-encoder settings. The first approach is to concatenate the target text and context text using a separator token and get a single representation from the BERT model. The second approach encodes the two texts independently using a dual BERT encoder and the corresponding representations are averaged. We show that the dual-encoder approach using independent representations yields better performance. We also employ simple ensemble methods to further improve the performance. We describe the systems built by our team r1_2021 for HASOC 2021 Subtask 2 and the subsequent set of experiments. © 2021 Copyright for this paper by its authors.},
	author_keywords = {BERT; Code Mixed; Context-aware; Deep Learning; Hate Speech Detection; Hinglish; Indic; Multilingual; Social Media},
	keywords = {Codes (symbols); Deep learning; Signal encoding; Social networking (online); BERT; Code mixed; Context-Aware; Deep learning; Hate speech detection; Hinglish; Indic; Multilingual; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 13th Forum for Information Retrieval Evaluation, FIRE-WN 2021; Conference date: 13 December 2021 through 17 December 2021; Conference code: 180530}
}@CONFERENCE{Cervero20211883,
	author = {Cervero, Riccardo},
	title = {Use of lexical and psycho-emotional information to detect Hate Speech Spreaders on Twitter},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {1883 – 1891},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113431759&partnerID=40&md5=27b53be7ee18f79f4192e7c7c5991f0b},
	affiliations = {Università degli Studi di Milano-Bicocca (UNIMIB), Milan, Italy},
	abstract = {This notebook summarises the participation at the "Profiling Hate Speech Spreaders on Twitter" shared task [1] at PAN at CLEF 2021 [2], and describes the proposed method for the goal of binary classification into hate speech spreaders and non spreaders. This method consists in an ensemble method inspired by Buda-Bolonyai's previous work - based on the separate training of different baselines and the subsequent definition of a meta-model for the final prediction - has been proposed for both the English and Spanish corpora, with the introduction of more in-depth features relating to the personality traits of the users and the psychological and emotional dimensions detectable from the text they published. The aforementioned system achieved an accuracy result of 0.7 for the English-writing users' dataset and 0.8 for the Spanish-writing users' dataset (with a final average result of 0.75). © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Hate speech detection; Personality traits; Psycho-linguistic patterns; Sentiment analysis},
	keywords = {Social networking (online); Binary classification; Depth features; Emotional dimensions; Emotional information; English writings; Ensemble methods; Personality traits; Spanish corpora; Spreaders},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Zualkernan2020284,
	author = {Zualkernan, Imran A. and Towheed, Mohammed},
	title = {Computational Offloading for CNN-based Toxic Comment Detection on a Smartwatch},
	year = {2020},
	journal = {2020 5th International Conference on Fog and Mobile Edge Computing, FMEC 2020},
	pages = {284 – 288},
	doi = {10.1109/FMEC49853.2020.9144770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094678533&doi=10.1109%2fFMEC49853.2020.9144770&partnerID=40&md5=69d1e96bf1d9644f0064915bd3cff3c6},
	affiliations = {American University of Sharjah, Department of Computer Science and Engineering, Sharjah, United Arab Emirates},
	abstract = {Smartwatches are an important enabler of the Social Internet of Things (SIoT). However, a successful transition to SIoT will require negotiating challenges specific to social networks. One current challenge for social networks is the detection and removal of toxic comments like insults, threats, or sexually explicit language. Many proposed techniques for detecting toxic comments use deep neural networks. Like Siri, a smartwatch can use a remote service to detect toxic comments, or alternatively run the neural network on the edge to detect such comments. This paper presents the results of an experiment comparing the tradeoffs in memory consumption, CPU load and response time between running a toxic text detection CNN on a Samsung S3 smartwatch, or running the CNN remotely using computational offloading. Sentences were processed either periodically or by using a Poisson distribution with periods of between 0.25 and 4 minutes. The results were that there was little difference in battery depletion between running the CNN locally on the watch or remotely running the CNN. However, using WIFI for offloading resulted in much better (< 1 second) response time than running the CNN on the watch (1-2 seconds). This suggests that computational offloading is a preferred solution in this instance. © 2020 IEEE.},
	author_keywords = {CNN; computational offloading; SIoT; smartwatch; social internet of things; toxic comment detection},
	keywords = {Deep neural networks; Edge computing; Poisson distribution; Social networking (online); Watches; Wearable computers; Memory consumption; Preferred solutions; Remote services; Samsung; Text detection; Neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Fog and Mobile Edge Computing, FMEC 2020; Conference date: 20 April 2020 through 23 April 2020; Conference code: 161963}
}

@CONFERENCE{Putri2020,
	author = {Putri, T.T.A. and Sriadhi, S. and Sari, R.D. and Rahmadani, R. and Hutahaean, H.D.},
	title = {A comparison of classification algorithms for hate speech detection},
	year = {2020},
	journal = {IOP Conference Series: Materials Science and Engineering},
	volume = {830},
	number = {3},
	doi = {10.1088/1757-899X/830/3/032006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086319206&doi=10.1088%2f1757-899X%2f830%2f3%2f032006&partnerID=40&md5=58cad6eeddfa9e49ac0d3c5c078f80e9},
	affiliations = {PTIK-FT, Universitas Negeri Medan, Indonesia},
	abstract = {Freedom of opinion through social media is frequently affect a negative impact that spreads hatred. This study aims to automatically detect Indonesian tweets that contain hate speech on Twitter social media. The data used amounted to 4,002 tweets related to politics, religion, ethnicity and race in Indonesia. The application model uses classification methods with machine learning algorithms such as Naïve Bayes, Multi Level Perceptron, AdaBoost Classifier, Decision Tree and Support Vector Machine. The study also compared the performance of the model using SMOTE to overcome imbalanced data. The results show that the Multinomial Naive Bayes algorithm produces the best model with the highest recall value of 93.2% which has an accuracy value of 71.2% for the classification of hate speech. Therefore, the Multinomial Naïve Bayes algorithm without SMOTE is recommended as the model to detect hate speech on social media. © Published under licence by IOP Publishing Ltd.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 3rd International Conference on Innovation in Engineering and Vocational Education 2019, ICIEVE 2019; Conference date: 26 November 2019; Conference code: 160463; All Open Access, Bronze Open Access}
}

@CONFERENCE{Mou20201145,
	author = {Mou, Guanyi and Ye, Pengyi and Lee, Kyumin},
	title = {SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection},
	year = {2020},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {1145 – 1154},
	doi = {10.1145/3340531.3411990},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095864199&doi=10.1145%2f3340531.3411990&partnerID=40&md5=94a83a4bc5ba631c7c6093fe91a2cb5a},
	affiliations = {Worcester Polytechnic Institute, Worcester, United States},
	abstract = {Hate speech detection on online social networks has become one of the emerging hot topics in recent years. With the broad spread and fast propagation speed across online social networks, hate speech makes significant impacts on society by increasing prejudice and hurting people. Therefore, there are aroused attention and concern from both industry and academia. In this paper, we address the hate speech problem and propose a novel hate speech detection framework called SWE2, which only relies on the content of messages and automatically identifies hate speech. In particular, our framework exploits both word-level semantic information and sub-word knowledge. It is intuitively persuasive and also practically performs well under a situation with/without character-level adversarial attack. Experimental results show that our proposed model achieves 0.975 accuracy and 0.953 macro F1, outperforming 7 state-of-the-art baselines under no adversarial attack. Our model robustly and significantly performed well under extreme adversarial attack (manipulation of 50% messages), achieving 0.967 accuracy and 0.934 macro F1. © 2020 ACM.},
	author_keywords = {hate speech detection; online social networks},
	keywords = {Knowledge management; Semantics; Social networking (online); Speech; Character level; Content of messages; Hot topics; On-line social networks; Propagation speed; Semantic information; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 29th ACM International Conference on Information and Knowledge Management, CIKM 2020; Conference date: 19 October 2020 through 23 October 2020; Conference code: 164320}
}

@CONFERENCE{Banerjee202021,
	author = {Banerjee, Shubhanker and Raja Chakravarthi, Bharathi and McCrae, John P.},
	title = {Comparison of Pretrained Embeddings to Identify Hate Speech in Indian Code-Mixed Text},
	year = {2020},
	journal = {Proceedings - IEEE 2020 2nd International Conference on Advances in Computing, Communication Control and Networking, ICACCCN 2020},
	pages = {21 – 25},
	doi = {10.1109/ICACCCN51052.2020.9362731},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098437105&doi=10.1109%2fICACCCN51052.2020.9362731&partnerID=40&md5=1fe421ff5a48ee2fa62144a3d688005e},
	affiliations = {JIIT, Electronics and Communication Engineering, Noida, India; National University of Ireland, Insight SFI Research Centre for Data Analytics, Galway, Ireland; Insight SFI Research Centre for da NUIG, Galway, Ireland},
	abstract = {Two or more languages used in the same sentence is known as the code-mixed text. The phenomenon is abundant in social media due to multilingualism. It poses a considerable challenge for classic NLP tools trained on monolingual corpora. Automatic hate speech detection in code-mixed text becomes even more challenging due to non-standard variations in the spelling, grammar and writing in foreign scripts. Pre-Trained models provide word embedding trained on massive monolingual corpora, which are now ubiquitous forms of word representation to classifying text. In this paper, we compare pretrained models and create an ensemble model for code-mixed data of hate speech classification task on Hindi-English data. We have also experimented with using word embedding for CNN networks and showed that XLNet performs better for hate speech detection in code-mixed text. © 2020 IEEE.},
	author_keywords = {code switching; dataset; natural language processing},
	keywords = {Classification (of information); Embeddings; CNN network; Ensemble modeling; Multilingualism; Social media; Speech classification; Speech detection; Standard variation; Word representations; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; Conference name: 2nd IEEE International Conference on Advances in Computing, Communication Control and Networking, ICACCCN 2020; Conference date: 18 December 2020 through 19 December 2020; Conference code: 167621}
}

@CONFERENCE{Samarasinghe202065,
	author = {Samarasinghe, S.W.A.M.D. and Meegama, R.G.N. and Punchimudiyanse, M.},
	title = {Machine learning approach for the detection of hate speech in sinhala unicode text},
	year = {2020},
	journal = {20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020 - Proceedings},
	pages = {65 – 70},
	doi = {10.1109/ICTer51097.2020.9325493},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100482795&doi=10.1109%2fICTer51097.2020.9325493&partnerID=40&md5=8b00700d85e49918873862d8a2847786},
	affiliations = {University of Sri Jayewardenepura, Apple Research and Development Centre, Department of Computer Science, !!!Faculty of Applied Sciences, Nugegoda, Sri Lanka; The Open University of Sri Lanka, Faculty of Natural Sciences, Department of Mathematics and Computer Science, Nawala, Sri Lanka},
	abstract = {Hate speech published online platforms has become a critical issue in Sri Lanka since this has caused conflicts between different ethnic groups. One of the main barriers to stop this crime is the lack of resources to detect online hate content in Sinhala automatically. Due to the vast amount of content published on online platforms every minute, an automatic method must be implemented in order to solve this issue.As a solution, we suggest a deep learning mechanism that utilizes two convolution neural networks (CNNs) which will first classify a given text corpus as hateful or not. Then, if the text corpus contains hate content text, it will again be classified according to its hate level which can be used by authorities to make decisions. In order to convert the text data into numerical vectors, we have used FastText word embedding in this study.Results indicate an accuracy of 83% and 60% for hate speech classification and hate level classifications, respectively. © 2020 IEEE.},
	author_keywords = {Convolutional Neural Networks; N-Gram; Sinhala hate speech; Word Embedding},
	keywords = {Data handling; Deep learning; Learning systems; Automatic method; Convolution neural network; Critical issues; Ethnic groups; Learning mechanism; Machine learning approaches; Online platforms; Speech classification; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 166665}
}

@CONFERENCE{Muhammad2020,
	author = {Muhammad, Iqbal Zulfikar and Nasrun, Muhammad and Setianingsih, Casi},
	title = {Hate Speech Detection using Global Vector and Deep Belief Network Algorithm},
	year = {2020},
	journal = {2020 1st International Conference on Big Data Analytics and Practices, IBDAP 2020},
	doi = {10.1109/IBDAP50342.2020.9245467},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097328929&doi=10.1109%2fIBDAP50342.2020.9245467&partnerID=40&md5=5336f8a4bbaa761dc427c9e80cb3e633},
	affiliations = {Telkom University, School of Electrical Engineering, Bandung, Indonesia},
	abstract = {Hate speeches are words, behaviors, and actions prohibited because they lead to acts that trigger violence and anarchist attitudes towards other individuals or groups. Since the 2014 presidential election, the term 'hater' has been widely known, marking people with a tendency to practice speech utterances in certain people and groups. Thus, the internet's ethics need to be emphasized, considering that the internet is a necessity for today's society. Nevertheless, more and more users are also many parties who abuse the internet to spread information about speech utterances such as ethnicity, race, and religion. In this project, a system will be created to detect hate speech in the form of tweets on twitter. The author's method is the Deep Belief Network method by weighing the Global Vector feature to increase accuracy before classification. The making of this system is expected to be able to find out and detect hate speech from the text previously in the form of tweets. By using the Deep Belief Network method, the results of this study were obtained with an accuracy =86,00%, precision =82,00%, recall =89,13% and Fl-Score =85,42%. After doing this research, it is expected that the computer can find out and classify the existence of hate speech in the text. © 2020 IEEE.},
	author_keywords = {Deep Belief Network (DBN); Global Vector; Hate speech},
	keywords = {Advanced Analytics; Big data; Speech; Deep belief networks; Presidential election; Speech detection; Speech utterance; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 1st International Conference on Big Data Analytics and Practices, IBDAP 2020; Conference date: 25 September 2020 through 26 September 2020; Conference code: 164855}
}

@CONFERENCE{Martín-Del-Campo-Rodríguez20212060,
	author = {Martín-Del-Campo-Rodríguez, Carolina and Sidorov, Grigori and Batyrshin, Ildar},
	title = {Hate speech detection on Twitter},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {2060 – 2063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113517612&partnerID=40&md5=17cac55111776614e6eff81945f2eca9},
	affiliations = {Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Juan de Dios Bátiz Avenue, Mexico City, 07738, Mexico},
	abstract = {With the use of social networks, the automatic detection of hate speech has become of great importance to prevent people, being protected by anonymity, from feeling free to discriminate against different groups. This document describes two approaches taken to detect hate speech by author: the first based on the individual processing of tweets by the author, which establishes a threshold of hate tweets to identify hate speech; the second based in the concatenation of tweets by author for processing. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Deep neural network; Hate speech; SVM; Twitter},
	keywords = {Automatic Detection; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@ARTICLE{Kanan202195,
	author = {Kanan, Tarek and Kanaan, Ghassan G. and Al-Shalabi, Riyad and Aldaaja, Amal},
	title = {Offensive language detection in social networks for arabic language using clustering techniques},
	year = {2021},
	journal = {International Journal of Advances in Soft Computing and its Applications},
	volume = {13},
	number = {2},
	pages = {95 – 111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111557293&partnerID=40&md5=2a0349f9b5c88f8ee0e12710b3c08531},
	affiliations = {Computer Science Department, AlZaytoonah University, Amman, Jordan; International Center for Scientific Research and Studies, Amman, Jordan},
	abstract = {With the advent of social networks, the users have obtained a golden opportunity to express their opinions using text and multimedia. However, some users abused these platforms by introducing acts such as Cyber-Bullying and Cyber-Harassment. Despite the various negative health and social effects, the works proposed toward the detection of these acts are still limited, especially in non-English languages. In Arabic, few works studied this phenomenon. These works had limited datasets. As the number of available training datasets are limited, it is still hard to train classifiers to detect these acts. Therefore, clustering has posed as an alternative solution to tackle this difficulty. In this work, we propose the use of clustering to detect Cyber-Bullying and Cyber-Harassment. We adopted various clustering algorithms including K-Means and Expectation Maximization (EM). Moreover, we used various natural language processing (NLP) tools for this objective. The results illustrate that the training time of K-Means is significantly smaller than that of EM in all the conducted experiments. As for the accuracy, the two clustering methods showed different performance based on the variance in the used NLP settings. © Al-Zaytoonah University of Jordan (ZUJ).},
	author_keywords = {Arabic Text; Clustering; Machine Learning; Natural language Processing; Social Media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Zampieri2021156,
	author = {Zampieri, Nicolas and Illina, Irina and Fohr, Dominique},
	title = {Multiword Expression Features for Automatic Hate Speech Detection},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12801 LNCS},
	pages = {156 – 164},
	doi = {10.1007/978-3-030-80599-9_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111447243&doi=10.1007%2f978-3-030-80599-9_14&partnerID=40&md5=088098209c48e90fb429ca98082d3651},
	affiliations = {University of Lorraine, CNRS, INRIA, Loria, Nancy, 54000, France},
	abstract = {The task of automatically detecting hate speech in social media is gaining more and more attention. Given the enormous volume of content posted daily, human monitoring of hate speech is unfeasible. In this work, we propose new word-level features for automatic hate speech detection (HSD): multiword expressions (MWEs). MWEs are lexical units greater than a word that have idiomatic and compositional meanings. We propose to integrate MWE features in a deep neural network-based HSD framework. Our baseline HSD system relies on Universal Sentence Encoder (USE). To incorporate MWE features, we create a three-branch deep neural network: one branch for USE, one for MWE categories, and one for MWE embeddings. We conduct experiments on two hate speech tweet corpora with different MWE categories and with two types of MWE embeddings, word2vec and BERT. Our experiments demonstrate that the proposed HSD system with MWE features significantly outperforms the baseline system in terms of macro-F1. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Hate speech detection; Social media},
	keywords = {Deep neural networks; Embeddings; Feature extraction; Information systems; Information use; Neural networks; Speech; Speech recognition; Baseline systems; Human monitoring; Lexical unit; Multi-word expressions; Social media; Speech detection; Three-branch; Word level; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 26th International Conference on Applications of Natural Language to Information Systems, NLDB 2021; Conference date: 23 June 2021 through 25 June 2021; Conference code: 261479}
}

@ARTICLE{Ayo2020485,
	author = {Ayo, Femi Emmanuel and Folorunso, Olusegun and Ibharalu, Friday Thomas and Osinuga, Idowu Ademola},
	title = {Hate speech detection in Twitter using hybrid embeddings and improved cuckoo search-based neural networks},
	year = {2020},
	journal = {International Journal of Intelligent Computing and Cybernetics},
	volume = {13},
	number = {4},
	pages = {485 – 525},
	doi = {10.1108/IJICC-06-2020-0061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094808685&doi=10.1108%2fIJICC-06-2020-0061&partnerID=40&md5=39d7b0f6ef5353dfd011ad5585a6ad45},
	affiliations = {Computer Science, College of Natural and Applied Sciences, McPherson University, Seriki Sotayo, Nigeria; Computer Science, College of Natural Sciences, Federal University of Agriculture Abeokuta, Abeokuta, Nigeria; Computer Science, Federal University of Agriculture Abeokuta, Abeokuta, Nigeria; Mathematics, Federal University of Agriculture Abeokuta, Abeokuta, Nigeria},
	abstract = {Purpose: Hate speech is an expression of intense hatred. Twitter has become a popular analytical tool for the prediction and monitoring of abusive behaviors. Hate speech detection with social media data has witnessed special research attention in recent studies, hence, the need to design a generic metadata architecture and efficient feature extraction technique to enhance hate speech detection. Design/methodology/approach: This study proposes a hybrid embeddings enhanced with a topic inference method and an improved cuckoo search neural network for hate speech detection in Twitter data. The proposed method uses a hybrid embeddings technique that includes Term Frequency-Inverse Document Frequency (TF-IDF) for word-level feature extraction and Long Short Term Memory (LSTM) which is a variant of recurrent neural networks architecture for sentence-level feature extraction. The extracted features from the hybrid embeddings then serve as input into the improved cuckoo search neural network for the prediction of a tweet as hate speech, offensive language or neither. Findings: The proposed method showed better results when tested on the collected Twitter datasets compared to other related methods. In order to validate the performances of the proposed method, t-test and post hoc multiple comparisons were used to compare the significance and means of the proposed method with other related methods for hate speech detection. Furthermore, Paired Sample t-Test was also conducted to validate the performances of the proposed method with other related methods. Research limitations/implications: Finally, the evaluation results showed that the proposed method outperforms other related methods with mean F1-score of 91.3. Originality/value: The main novelty of this study is the use of an automatic topic spotting measure based on naïve Bayes model to improve features representation. © 2020, Emerald Publishing Limited.},
	author_keywords = {Cuckoo search; Embeddings; Hate speech detection; Neural networks; Twitter},
	keywords = {Bayesian networks; Embeddings; Extraction; Feature extraction; Inverse problems; Network architecture; Optimization; Social networking (online); Speech; Speech recognition; Text processing; Design/methodology/approach; Feature extraction techniques; Metadata architecture; Multiple comparison; Neural networks architecture; Offensive languages; Paired-sample t-test; Term frequencyinverse document frequency (TF-IDF); Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@CONFERENCE{Gupta2020,
	author = {Gupta, Shailja and Lakra, Sachin and Kaur, Manpreet},
	title = {Study on BERT Model for Hate Speech Detection},
	year = {2020},
	journal = {Proceedings of the 4th International Conference on Electronics, Communication and Aerospace Technology, ICECA 2020},
	doi = {10.1109/ICECA49313.2020.9297560},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099583618&doi=10.1109%2fICECA49313.2020.9297560&partnerID=40&md5=71783897abea9eeadc8ecc98547b6f0b},
	affiliations = {Manav Rachna University, Department of Computer Science and Technology, Faridabad, India},
	abstract = {The last decade has witnessed a massive rise in the problem of hate speech due to revolutionary growth in online content. Urgent countermeasures are being taken by government bodies, social websites, multinational companies, research communities to solve the problem of hate speech detection, which is a text classification problem, by the development of automated methods of hate speech detection. A lot of manual effort and time is dedicated to find the solution for the problem of detecting hate speech from online content, but the authors of the paper feel that there is a lot of scope to improve the accuracy of the existing automated methods of hate speech detection. The authors observed that recently, transfer learning models have exhibited good results in the area of text classification for question-answering, summarization, and nextword prediction, but these learning models have not been used for the problem of hate speech detection to date. The authors of the article anticipate that these networks may give better results in another task of text classification, i.e., hate speech detection. Therefore, this article proposes a novel method of hate speech detection based on the concept of attention networks using the BERT attention model. © 2020 IEEE.},
	author_keywords = {attention networks; neural networks; pre-trained models; Transfer learning; transformers},
	keywords = {Classification (of information); Natural language processing systems; Speech; Text processing; Transfer learning; Attention model; Automated methods; Multi-national companies; On-line contents; Question Answering; Research communities; Speech detection; Text classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 4th International Conference on Electronics, Communication and Aerospace Technology, ICECA 2020; Conference date: 5 November 2020 through 7 November 2020; Conference code: 166221}
}

@ARTICLE{Plaza-Del-Arco2021112478,
	author = {Plaza-Del-Arco, Flor Miriam and Molina-Gonzalez, M. Dolores and Urena-Lopez, L. Alfonso and Martin-Valdivia, Maria Teresa},
	title = {A multi-task learning approach to hate speech detection leveraging sentiment analysis},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {112478 – 112489},
	doi = {10.1109/ACCESS.2021.3103697},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113222108&doi=10.1109%2fACCESS.2021.3103697&partnerID=40&md5=3f71678bc89f0c602e044d6712bae97f},
	affiliations = {Department of Computer Science, Advanced Studies Center in Information and Communication Technologies (CEATIC), Universidad de Jaén, Jaén, 23071, Spain},
	abstract = {The rise of social media platforms has significantly changed the way our world communicates, and part of those changes includes a rise in inappropriate behaviors, such as the use of aggressive and hateful language online. Detecting such content is crucial to filtering or blocking inappropriate content on the Web. However, due to the huge amount of data posted every day, automatic methods are essential for identifying this type of content. Seeking to address this issue, the Natural Language Processing community is increasingly involved in testing a wide range of techniques for hate speech detection. While achieving promising results, these techniques consider hate speech detection as the sole optimization objective, without involving other related tasks such as polarity and emotion classification that are strongly linked to offensive behavior. In this paper, we propose the first Multi-task approach that leverages the shared affective knowledge to detect hate speech in Spanish tweets, using a well-known Transformer-based model. Our results show that the combination of both polarity and emotional knowledge helps to detect hate speech more accurately across datasets.  © 2013 IEEE.},
	author_keywords = {multi-task learning; Natural language processing; offensive language; sentiment analysis; Spanish hate speech},
	keywords = {Multi-task learning; Sentiment analysis; Speech; Automatic method; Community IS; Emotion classification; NAtural language processing; Social media platforms; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 73; All Open Access, Gold Open Access}
}

@CONFERENCE{Sahana2020297,
	author = {Sahana, B.S. and Sandhya, G. and Tanuja, R.S. and Ellur, Sushma and Ajina, A.},
	title = {Towards a Safer Conversation Space: Detection of Toxic Content in Social Media (Student Consortium)},
	year = {2020},
	journal = {Proceedings - 2020 IEEE 6th International Conference on Multimedia Big Data, BigMM 2020},
	pages = {297 – 301},
	doi = {10.1109/BigMM50055.2020.00052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097221609&doi=10.1109%2fBigMM50055.2020.00052&partnerID=40&md5=3f1e0d16db245322dcf50a955322044a},
	affiliations = {Sir M Visvesvaraya Institute of Technology, Department of Computer Science and Engineering, Bengaluru, Karnataka, India},
	abstract = {With content on social media turning increasingly toxic, it has attracted intensive research in the Natural Language Processing domain to detect aggression, hate, profanity, insult, cyberbullying and other personal attacks. Unlike most of the work in toxic content detection where the nature of toxicity is determined, we treat the detection of toxic content as a binary classification task. Here, we have explored Support Vector Machine, Boosting and deep neural networks for classification. We have trained the model on twitter datasets. With a goal of better predictive performance, our approach uses a majority voting ensemble to aggregate the predictions of individual classifiers. © 2020 IEEE.},
	author_keywords = {classifier ensemble; social media; Text classification; Toxic content detection},
	keywords = {Big data; Deep neural networks; Natural language processing systems; Support vector machines; Binary classification; Content detection; Cyber bullying; Individual classifiers; Intensive research; NAtural language processing; Predictive performance; Social media; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 6th IEEE International Conference on Multimedia Big Data, BigMM 2020; Conference date: 24 September 2020 through 26 September 2020; Conference code: 164212}
}

@ARTICLE{Mossie2020,
	author = {Mossie, Zewdie and Wang, Jenq-Haur},
	title = {Vulnerable community identification using hate speech detection on social media},
	year = {2020},
	journal = {Information Processing and Management},
	volume = {57},
	number = {3},
	doi = {10.1016/j.ipm.2019.102087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069630089&doi=10.1016%2fj.ipm.2019.102087&partnerID=40&md5=f4b1e0b832e0b630e14ea5f703c9c07b},
	affiliations = {International Graduate Program of Electrical Engineering and Computer Science, National Taipei University of Technology, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taipei University of Technology, Taipei, Taiwan},
	abstract = {With the rapid development in mobile computing and Web technologies, online hate speech has been increasingly spread in social network platforms since it's easy to post any opinions. Previous studies confirm that exposure to online hate speech has serious offline consequences to historically deprived communities. Thus, research on automated hate speech detection has attracted much attention. However, the role of social networks in identifying hate-related vulnerable community is not well investigated. Hate speech can affect all population groups, but some are more vulnerable to its impact than others. For example, for ethnic groups whose languages have few computational resources, it is a challenge to automatically collect and process online texts, not to mention automatic hate speech detection on social media. In this paper, we propose a hate speech detection approach to identify hatred against vulnerable minority groups on social media. Firstly, in Spark distributed processing framework, posts are automatically collected and pre-processed, and features are extracted using word n-grams and word embedding techniques such as Word2Vec. Secondly, deep learning algorithms for classification such as Gated Recurrent Unit (GRU), a variety of Recurrent Neural Networks (RNNs), are used for hate speech detection. Finally, hate words are clustered with methods such as Word2Vec to predict the potential target ethnic group for hatred. In our experiments, we use Amharic language in Ethiopia as an example. Since there was no publicly available dataset for Amharic texts, we crawled Facebook pages to prepare the corpus. Since data annotation could be biased by culture, we recruit annotators from different cultural backgrounds and achieved better inter-annotator agreement. In our experimental results, feature extraction using word embedding techniques such as Word2Vec performs better in both classical and deep learning-based classification algorithms for hate speech detection, among which GRU achieves the best result. Our proposed approach can successfully identify the Tigre ethnic group as the highly vulnerable community in terms of hatred compared with Amhara and Oromo. As a result, hatred vulnerable group identification is vital to protect them by applying automatic hate speech detection model to remove contents that aggravate psychological harm and physical conflicts. This can also encourage the way towards the development of policies, strategies, and tools to empower and protect vulnerable communities. © 2019 Elsevier Ltd},
	author_keywords = {Amharic text processing; Data annotation; Hate speech detection; Spark distributed framework; Vulnerable community identification},
	keywords = {Data handling; Deep learning; Distributed computer systems; Embeddings; Feature extraction; Learning algorithms; Recurrent neural networks; Social networking (online); Social sciences computing; Speech; Text processing; Classification algorithm; Computational resources; Data annotation; Distributed framework; Distributed processing frameworks; Recurrent neural network (RNNs); Speech detection; Vulnerable communities; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 135}
}

@CONFERENCE{Melton20201015,
	author = {Melton, Joshua and Bagavathi, Arunkumar and Krishnan, Siddharth},
	title = {DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection},
	year = {2020},
	journal = {Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020},
	pages = {1015 – 1022},
	doi = {10.1109/ICMLA51294.2020.00165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102505150&doi=10.1109%2fICMLA51294.2020.00165&partnerID=40&md5=08dfae69deaa8e7a2b4fbc5528580028},
	affiliations = {University of North Carolina at Charlotte, Department of Computer Science, United States; Oklahoma State University, Department of Computer Science, United States},
	abstract = {Online hate speech on social media has become a fast-growing problem in recent times. Nefarious groups have developed large content delivery networks across several mainstream (Twitter and Facebook) and fringe outlets (Gab, 4chan, 8chan, etc.) to deliver cascades of hate messages directed both at individuals and communities. Thus addressing these issues has become a top priority for large-scale social media outlets. Three key challenges in automated detection and classification of hateful content are the lack of clearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc - and the lack of baseline models for fringe outlets such as Gab. In this work, we propose a novel framework with three major contributions. (a) We engineer an ensemble of deep learning models that combines the strengths of state-of-the-art approaches, (b) we incorporate a tuning factor into this framework that leverages transfer learning to conduct automated hate speech classification on unlabeled datasets, like Gab, and (c) we develop a weak supervised learning methodology that allows our framework to train on unlabeled data. Our ensemble models achieve an 83% hate recall on the HON dataset, surpassing the performance of the state of the art deep models. We demonstrate that weak supervised training in combination with classifier tuning significantly increases model performance on unlabeled data from Gab, achieving a hate recall of 67%. © 2020 IEEE.},
	author_keywords = {ensemble classifier; hate speech detection; transfer learning; weak supervision},
	keywords = {Classification (of information); Learning systems; Social networking (online); Supervised learning; Transfer learning; Automated detection and classification; Content delivery network; Model performance; Speech classification; Speech detection; State of the art; State-of-the-art approach; Supervised trainings; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020; Conference date: 14 December 2020 through 17 December 2020; Conference code: 167387; All Open Access, Green Open Access}
}

@CONFERENCE{Hu2020171,
	author = {Hu, Ruijia and Dorris, Wyatt and Vishwamitra, Nishant and Luo, Feng and Costello, Matthew},
	title = {On the Impact of Word Representation in Hate Speech and Offensive Language Detection and Explanation},
	year = {2020},
	journal = {CODASPY 2020 - Proceedings of the 10th ACM Conference on Data and Application Security and Privacy},
	pages = {171 – 173},
	doi = {10.1145/3374664.3379535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083381561&doi=10.1145%2f3374664.3379535&partnerID=40&md5=76c079aff815dcce9ec2f1d9e389f413},
	affiliations = {Clemson University, Clemson, SC, United States; Clemson University, D.W. Daniel High School, Clemson, SC, United States},
	abstract = {Online hate speech and offensive language have been widely recognized as critical social problems. To defend against this problem, several recent works have emerged that focus on the detection and explanation of hate speech and offensive language using machine learning approaches. Although these approaches are quite effective in the detection and explanation of hate speech and offensive language samples, they do not explore the impact of the representation of such samples. In this work, we introduce a novel, pronunciation-based representation of hate speech and offensive language samples to enable its detection with high accuracy. To demonstrate the effectiveness of our pronunciation-based representation, we extend an existing hate-speech and offensive language defense model based on deep Long Short-term Memory (LSTM) neural networks by using our pronunciation-based representation of hate speech and offensive language samples to train this model. Our work finds that the pronunciation-based presentation significantly reduces noise in the datasets and enhances the overall performance of the existing model. © 2020 ACM.},
	author_keywords = {explanation; hate speech detection; natural language processing; offensive language detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 10th ACM Conference on Data and Application Security and Privacy, CODASPY 2020; Conference date: 16 March 2020 through 18 March 2020; Conference code: 158440}
}

@CONFERENCE{Anwar20211808,
	author = {Anwar, Talha},
	title = {Identify hate speech spreaders on twitter using transformer embeddings features and AutoML classifiers},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {1808 – 1812},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113476959&partnerID=40&md5=6fd34615f0ff90cbc9da0225e1158ed6},
	affiliations = {Independent Researcher},
	abstract = {Hate speech against other communities, religions and countries is getting more common on social media. There is a need to control the spread of hate and offensive language on social media. Most studies identify whether a sentence is a hatred or not. This paper deals with the identification of whether a user spreads hate on Twitter or not by analyzing hundreds of tweets from the user. Feature embeddings of hundreds of tweets of a user are extracted using different transformers techniques such as BERT, BERTTweet, and RoBERTa for the English language and BETO for the Spanish language. An AutoML classifier is used to classify these embedding features. An accuracy of 75% and 85% is achieved using five-fold cross-validation and Accuracy of 72% and 82% is obtained for gold standard test data for English and Spanish, respectively. This paper secured 4th position in PAN competition. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {AutoML; Hate speech; Transformers; Twitter},
	keywords = {Embeddings; Social networking (online); Cross validation; English languages; Gold standards; Offensive languages; Social media; Spanish language; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Singh2020301,
	author = {Singh, Oyesh Mann and Timilsina, Sandesh and Bal, Bal Krishna and Joshi, Anupam},
	title = {Aspect Based Abusive Sentiment Detection in Nepali Social Media Texts},
	year = {2020},
	journal = {Proceedings of the 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020},
	pages = {301 – 308},
	doi = {10.1109/ASONAM49781.2020.9381292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103694651&doi=10.1109%2fASONAM49781.2020.9381292&partnerID=40&md5=7e680f9e8da7f13db82c56437ecd8c3e},
	affiliations = {University of Maryland, Baltimore County (UMBC), Department of Computer Science and Electrical Engineering, Baltimore, MD, United States; Information and Language Processing Research Lab (ILPRL), Kathmandu University, Department of Computer Science and Engineering, Kathmandu, Nepal},
	abstract = {With the increase in internet access and the ease of writing comments in the Nepali language, fine-grained sentiment analysis of social media comments is becoming more and more pertinent. There are a number of benchmarked datasets for high-resource languages (English, French, and German) in specific domains like restaurants, hotels or electronic goods but not in low-resource languages like Nepali. In this paper, we present our work to create a dataset for the targeted aspect-based sentiment analysis in the social media domain, set up a dataset benchmark and evaluate using various machine learning models. The dataset comprises of code-mixed and code-switched comments extracted from Nepali YouTube videos. We present convincing baselines using a multilingual BERT model for the Aspect Term Extraction task and BiLSTM model for the Sentiment Classification Task achieving 57.978% and 81.60% F1 score respectively. © 2020 IEEE.},
	author_keywords = {abusive sentiment analysis; aspect based; natural language processing; Nepali; social media; YouTube},
	keywords = {Social networking (online); Electronic goods; Internet access; Low resource languages; Machine learning models; Sentiment classification; Social media; Term extraction; Writing comments; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020; Conference date: 7 December 2020 through 10 December 2020; Conference code: 168050; All Open Access, Green Open Access}
}

@ARTICLE{Nguyen2021572,
	author = {Nguyen, Luan Thanh and Van Nguyen, Kiet and Nguyen, Ngan Luu-Thuy},
	title = {Constructive and Toxic Speech Detection for Open-Domain Social Media Comments in Vietnamese},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12798 LNAI},
	pages = {572 – 583},
	doi = {10.1007/978-3-030-79457-6_49},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112690248&doi=10.1007%2f978-3-030-79457-6_49&partnerID=40&md5=202b04f9739b4a6419b68628d4fc0116},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {The rise of social media has led to the increasing of comments on online forums. However, there still exists invalid comments which are not informative for users. Moreover, those comments are also quite toxic and harmful to people. In this paper, we create a dataset for constructive and toxic speech detection, named UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset) with 10,000 human-annotated comments. For these tasks, we propose a system for constructive and toxic speech detection with the state-of-the-art transfer learning model in Vietnamese NLP as PhoBERT. With this system, we obtain F1-scores of 78.59% and 59.40% for classifying constructive and toxic comments, respectively. Besides, we implement various baseline models as traditional Machine Learning and Deep Neural Network-Based models to evaluate the dataset. With the results, we can solve several tasks on the online discussions and develop the framework for identifying constructiveness and toxicity of Vietnamese social media comments automatically. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Constructive speech detection; Deep learning; Machine learning; Toxic speech detection; Transfer learning},
	keywords = {Deep learning; Deep neural networks; Intelligent systems; Learning systems; Social networking (online); Transfer learning; Baseline models; F1 scores; Online discussions; Online forums; Social media; Speech detection; State of the art; Vietnamese; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021; Conference date: 26 July 2021 through 29 July 2021; Conference code: 262819}
}

@ARTICLE{Shruthi202097,
	author = {Shruthi, P. and Anil Kumar, K.M.},
	title = {Novel approach for generating hybrid features set to effectively identify hate speech},
	year = {2020},
	journal = {Inteligencia Artificial},
	volume = {23},
	number = {66},
	pages = {97 – 111},
	doi = {10.4114/intartif.vol23iss66pp97-111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100479493&doi=10.4114%2fintartif.vol23iss66pp97-111&partnerID=40&md5=c04a44d5f6f99446bf9733a90a0e2abc},
	affiliations = {Department Of Computer Science and Engineering, JSS Science and Technology University, Mysuru, Karnataka, India},
	abstract = {Automating hate speech or inappropriate text detection in social media and other internet platforms is gaining a lot of interest and becoming a valuable research topic for both industry and academia in recent years. It is more important for applications to identify the disruptive contents, understand sentiment analysis, identify cyber bullying, detect flames, threats, hatred towards people or particular communities or groups etc. Text classification is a very challenging task due to the nature and complexities with languages, especially its context, micro words, emojis, typo error and sarcasm present in the text. In this paper, we have proposed a model with a novel approach for generating hybrid features for an effective feature representation to classify hate speech. We have combined features learned from deep learning methods with the semantic features like word n-grams and tweets specific syntactic features to form hybrid feature sets. We have also improvised preprocessing steps to reduce the number of missing embeddings to increase the vocabulary for efficient feature learning. We have experimented with the various neural networks for feature learning and machine learning models with hybrid features for classification. Our work delivers hybrid features and appropriate preprocessing techniques for an efficient classification of the standard dataset of 16k annotated hate speech tweets. The combination of Long Short Term Memory (LSTM) trained on Random Embeddings for deep learning features extraction and Logistic Regression (LR) as a classifier with the hybrid features is found to be the best model and it outperforms the state of the art reported in the literature. © IBERAMIA and the authors.},
	author_keywords = {Cyber-bullying; Deep Learning; Deep Learning Features; Hate Speech; Hybrid Features},
	keywords = {Deep learning; Embeddings; Learning systems; Logistic regression; Long short-term memory; Semantics; Sentiment analysis; Speech recognition; Feature representation; Features extraction; Machine learning models; Pre-processing step; Preprocessing techniques; Semantic features; Syntactic features; Text classification; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Katona20212025,
	author = {Katona, Eszter and Buda, Jakab and Bolonyai, Flora},
	title = {Using N-grams and statistical features to identify Hate Speech Spreaders on Twitter},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {2025 – 2034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113499778&partnerID=40&md5=283d88e05b0167a51253e6ca1312c0d2},
	abstract = {In this notebook, we summarize our work process of preparing a software for the PAN 2021 Profiling Hate Speech Spreaders on Twitter task. Our final software was a stacking ensemble classifier of different machine learning models; a mixture of models using word n-grams as features and models based on statistical features extracted from the Twitter feeds. Our software uploaded to the TIRA platform achieved an accuracy of 70% in English and 79% in Spanish. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Hate speech recognition; Text classification},
	keywords = {Spreaders; Ensemble classifiers; Machine learning models; N-grams; Statistical features; Word n-grams; Work process; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Rini2020,
	author = {Rini and Utami, Ema and Hartanto, Anggit Dwi},
	title = {Systematic Literature Review of Hate Speech Detection with Text Mining},
	year = {2020},
	journal = {2020 2nd International Conference on Cybernetics and Intelligent System, ICORIS 2020},
	doi = {10.1109/ICORIS50180.2020.9320755},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100397402&doi=10.1109%2fICORIS50180.2020.9320755&partnerID=40&md5=5c7c222d21080ada22036e3c5b4f2812},
	affiliations = {Universitas Amikom Yogyakarta, Magister of Informatics Engineering, Yogyakarta, Indonesia; Universitas Amikom Yogyakarta, Faculty of Computer Science, Yogyakarta, Indonesia},
	abstract = {Along with the increasing activity on social media, hate speech is getting out of control. Hate speech detection can be done by utilizing text mining technology. There have been many hate speech detection studies conducted. To identify and analyze research trends, data sources, methods and features used in hate speech detection, this systematic literature review was created. Until early 2020, the topics of hate speech were found, including hate speech against minorities, religion, women, the general election agenda, and politics. Sources of data that are widely used to be used as datasets come from twitter. Hate speech is not only classified into HS (hate speech) and Non-HS (non-hate speech) but can be further classified into racism, sexism, offensive, abusive, threats of violence and others. Of the 38 studies that meet inclusion and exclusion, there are 26 algorithms and 28 features that have been used to detect hate speech. However, these methods and features do not necessarily guarantee a good hate detection performance. Hate speech classification performance is also influenced by the dataset, the features chosen, the number of classes and mutually exclusive classes. © 2020 IEEE.},
	author_keywords = {classification; hate speech; systematic literature review; text mining},
	keywords = {Classification (of information); Feature extraction; Intelligent systems; Social networking (online); Speech; Text mining; Detection performance; General Elections; Inclusion and exclusions; Number of class; Research trends; Speech classification; Speech detection; Systematic literature review; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 2nd International Conference on Cybernetics and Intelligent System, ICORIS 2020; Conference date: 27 October 2020 through 28 October 2020; Conference code: 166662}
}

@ARTICLE{Al-Makhadmeh2020501,
	author = {Al-Makhadmeh, Zafer and Tolba, Amr},
	title = {Automatic hate speech detection using killer natural language processing optimizing ensemble deep learning approach},
	year = {2020},
	journal = {Computing},
	volume = {102},
	number = {2},
	pages = {501 – 522},
	doi = {10.1007/s00607-019-00745-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070080575&doi=10.1007%2fs00607-019-00745-0&partnerID=40&md5=225c044cf7ed57d5f08b5e36403127c4},
	affiliations = {Computer Science Department, Community College, King Saud University, Riyadh, 11437, Saudi Arabia; Mathematics and Computer Science Department, Faculty of Science, Menoufia University, Shebin-El-Kom, 32511, Egypt},
	abstract = {Over the last decade, the increased use of social media has led to an increase in hateful activities in social networks. Hate speech is one of the most dangerous of these activities, so users have to protect themselves from these activities from YouTube, Facebook, Twitter etc. This paper introduces a method for using a hybrid of natural language processing and with machine learning technique to predict hate speech from social media websites. After hate speech is collected, steaming, token splitting, character removal and inflection elimination is performed before performing hate speech recognition process. After that collected data is examined using a killer natural language processing optimization ensemble deep learning approach (KNLPEDNN). This method detects hate speech on social media websites using an effective learning process that classifies the text into neutral, offensive and hate language. The performance of the system is then evaluated using overall accuracy, f-score, precision and recall metrics. The system attained minimum deviations mean square error − 0.019, Cross Entropy Loss − 0.015 and Logarithmic loss L-0.0238 and 98.71% accuracy. © 2019, Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Facebook; Hate speech; Killer natural language processing optimizing ensemble deep learning approach; Social media; Twitter; YouTube},
	keywords = {Learning algorithms; Mean square error; Natural language processing systems; Social networking (online); Speech; Speech recognition; Facebook; Learning approach; Social media; Twitter; YouTube; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 83}
}

@ARTICLE{Singh20211,
	author = {Singh, Ashwin and Ray, Rudraroop},
	title = {Identifying Offensive Content in Social Media Posts},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1402 CCIS},
	pages = {1 – 8},
	doi = {10.1007/978-3-030-73696-5_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104713808&doi=10.1007%2f978-3-030-73696-5_1&partnerID=40&md5=8203746d20d7622aa46a584fcf4c310a},
	affiliations = {Indraprastha Institute of Information Technology, Delhi, India},
	abstract = {The identification of offensive language on social media has been a widely studied problem in recent years owing to the volume of data generated by these platforms and its consequences. In this paper, we present the results of our experiments on the OLID dataset from the OffensEval shared from SemEval 2019. We use both traditional machine learning methods and state of the art transformer models like BERT to set a baseline for our experiments. Following this, we propose the use of fine-tuning Distilled Bert using both OLID and an additional hate speech and offensive language dataset. Then, we evaluate our model on the test set, yielding a macro f1 score of 78.8. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Machine learning; Offensive language; Social media},
	keywords = {Artificial intelligence; Social networking (online); F1 scores; Fine tuning; Machine learning methods; Offensive languages; Social media; State of the art; Test sets; Transformer models; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situation, CONSTRAINT 2021 co-located with 35th AAAI Conference on Artificial Intelligence, AAAI 2021; Conference date: 8 February 2021 through 8 February 2021; Conference code: 257659}
}

@ARTICLE{Guellil2020295,
	author = {Guellil, Imane and Adeel, Ahsan and Azouaou, Faical and Chennoufi, Sara and Maafi, Hanene and Hamitouche, Thinhinane},
	title = {Detecting hate speech against politicians in Arabic community on social media},
	year = {2020},
	journal = {International Journal of Web Information Systems},
	volume = {16},
	number = {3},
	pages = {295 – 313},
	doi = {10.1108/IJWIS-08-2019-0036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088931657&doi=10.1108%2fIJWIS-08-2019-0036&partnerID=40&md5=303acdc22ffbec1e02765ae22741d0ec},
	affiliations = {Laboratoire des Méthodes de Conception des Systèmes, Ecole Nationale Supérieure d’Informatique, Algiers, Algeria; School of Mathematics and Computer Science, University of Wolverhampton, Wolverhampton, United Kingdom; Laboratoire des Méthodes de Conception des Systèmes, Ecole Nationale Supérieure d’Informatique, Algiers, Algeria; Laboratoire des Méthodes de Conception des Systémes, Ecole Nationale Supèrieure d'Informatique, Alger, Algeria; School of Engineering and Applied Science (EAS), Aston University, Birmingham, United Kingdom; Folding Space, Birmingham, United Kingdom},
	abstract = {Purpose: This paper aims to propose an approach for hate speech detection against politicians in Arabic community on social media (e.g. Youtube). In the literature, similar works have been presented for other languages such as English. However, to the best of the authors’ knowledge, not much work has been conducted in the Arabic language. Design/methodology/approach: This approach uses both classical algorithms of classification and deep learning algorithms. For the classical algorithms, the authors use Gaussian NB (GNB), Logistic Regression (LR), Random Forest (RF), SGD Classifier (SGD) and Linear SVC (LSVC). For the deep learning classification, four different algorithms (convolutional neural network (CNN), multilayer perceptron (MLP), long- or short-term memory (LSTM) and bi-directional long- or short-term memory (Bi-LSTM) are applied. For extracting features, the authors use both Word2vec and FastText with their two implementations, namely, Skip Gram (SG) and Continuous Bag of Word (CBOW). Findings: Simulation results demonstrate the best performance of LSVC, BiLSTM and MLP achieving an accuracy up to 91%, when it is associated to SG model. The results are also shown that the classification that has been done on balanced corpus are more accurate than those done on unbalanced corpus. Originality/value: The principal originality of this paper is to construct a new hate speech corpus (Arabic_fr_en) which was annotated by three different annotators. This corpus contains the three languages used by Arabic people being Arabic, French and English. For Arabic, the corpus contains both script Arabic and Arabizi (i.e. Arabic words written with Latin letters). Another originality is to rely on both shallow and deep leaning classification by using different model for extraction features such as Word2vec and FastText with their two implementation SG and CBOW. © 2020, Emerald Publishing Limited.},
	author_keywords = {Arabic hate speech},
	keywords = {Brain; Convolutional neural networks; Decision trees; Deep learning; Logistic regression; Long short-term memory; Multilayer neural networks; Social networking (online); Speech recognition; Arabic languages; Design/methodology/approach; Extracting features; Multi layer perceptron; Short term memory; Speech corpora; Speech detection; Unbalanced corpora; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Puertas20212118,
	author = {Puertas, Edwin and Martinez-Santos, Juan Carlos},
	title = {Phonetic detection for Hate Speech Spreaders on Twitter},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {2118 – 2125},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113524538&partnerID=40&md5=23d035bd746a0d3697b64e3b53d2ecee},
	affiliations = {Universidad Tecnológica de Bolívar, Cartagena, Colombia},
	abstract = {Nowadays, hate messages have become the object of study on social media. Efficient and effective detection of hate profiles requires various scientific disciplines, such as computational linguistics and sociology. Here, we illustrate how we used lexical and phonetic features to determine if the author spreads hate speech. This article presents a novel strategy for the characterization of the Twitter profile based on the generation of lexical and phonetic user features that serve as input to a set of classifiers. The results are part of our participation in the PAN 2021 in the CLEF in the task of Profiling Hate Speech Spreaders on Twitter. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Feature extraction; Hate speech spreader; Phonetic feature; Phonetic syllable},
	keywords = {Social networking (online); Sociology; Spreaders; Novel strategies; Phonetic features; Scientific discipline; Social media; User feature; Linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Wiegand2021369,
	author = {Wiegand, Michael and Ruppenhofer, Josef},
	title = {Exploiting emojis for abusive language detection},
	year = {2021},
	journal = {EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {369 – 380},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107312740&partnerID=40&md5=58ad83ff6c8d13eb23d51d6b77858308},
	affiliations = {Digital Age Research Center (D!ARC), Alpen-Adria-Universität Klagenfurt, Klagenfurt, AT-9020, Austria; Leibniz Institute for German Language, Mannheim, D-68161, Germany},
	abstract = {We propose to use abusive emojis, such as the middle finger or face vomiting, as a proxy for learning a lexicon of abusive words. Since it represents extralinguistic information, a single emoji can co-occur with different forms of explicitly abusive utterances. We show that our approach generates a lexicon that offers the same performance in cross-domain classification of abusive microposts as the most advanced lexicon induction method. Such an approach, in contrast, is dependent on manually annotated seed words and expensive lexical resources for bootstrapping (e.g. WordNet). We demonstrate that the same emojis can also be effectively used in languages other than English. Finally, we also show that emojis can be exploited for classifying mentions of ambiguous words, such as fuck and bitch, into generally abusive and just profane usages. © 2021 Association for Computational Linguistics},
	keywords = {Computational linguistics; Cross-domain; Induction method; Language detection; Lexical resources; Seed words; Wordnet; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 16th Conference of the European Chapter of the Associationfor Computational Linguistics, EACL 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169023}
}

@BOOK{Ghosal2020200,
	author = {Ghosal, Sayani and Jain, Amita},
	title = {Research journey of hate content detection from cyberspace},
	year = {2020},
	journal = {Natural Language Processing for Global and Local Business},
	pages = {200 – 225},
	doi = {10.4018/978-1-7998-4240-8.ch009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137604737&doi=10.4018%2f978-1-7998-4240-8.ch009&partnerID=40&md5=22f3e6c2a43de9f9e3e88e94db04557c},
	affiliations = {Guru Gobind Singh Indraprastha University, Ambedkar Institute of Advanced Communication Technologies and Research, New Delhi, India; Deptt of CSE, Ambedkar Institute of Advanced Communication Technology and Research, Delhi, India},
	abstract = {Hate content detection is the most prospective and challenging research area under the natural language processing domain. Hate speech abuse individuals or groups of people based on religion, caste, language, or sex. Enormous growth of digital media and cyberspace has encouraged researchers to work on hatred speech detection. A commonly acceptable automatic hate detection system is required to stop flowing hate-motivated data. Anonymous hate content is affecting the young generation and adults on social networking sites. Through numerous studies and review papers, the chapter identifies the need for artificial intelligence (AI) in hate speech research. The chapter explores the current state-of-the-art and prospects of AI in natural language processing (NLP) and machine learning algorithms. The chapter aims to identify the most successful methods or techniques for hate speech detection to date. Revolution in this research helps social media to provide a healthy environment for everyone. © 2021, IGI Global.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Hadj Ameur2021232,
	author = {Hadj Ameur, Mohamed Seghir and Aliane, Hassina},
	title = {AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News & Hate Speech Detection Dataset},
	year = {2021},
	journal = {Procedia CIRP},
	volume = {189},
	pages = {232 – 241},
	doi = {10.1016/j.procs.2021.05.086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112862297&doi=10.1016%2fj.procs.2021.05.086&partnerID=40&md5=1ad5ba18bb37d1e282a93c0ea4cf1006},
	affiliations = {Research and Development in Digital Humanities Division, Research Centre on Scientific and Technical Information (CERIST), Algiers, Algeria},
	abstract = {Along with the COVID-19 pandemic, an "infodemic" of false and misleading information has emerged and has complicated the COVID-19 response efforts. Social networking sites such as Facebook and Twitter have contributed largely to the spread of rumors, conspiracy theories, hate, xenophobia, racism, and prejudice. To combat the spread of fake news, researchers around the world have and are still making considerable efforts to build and share COVID-19 related research articles, models, and datasets. This paper releases "AraCOVID19-MFH"1a manually annotated multi-label Arabic COVID-19 fake news and hate speech detection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10 different labels. The labels have been designed to consider some aspects relevant to the fact-checking task, such as the tweet's check worthiness, positivity/negativity, and factuality. To confirm our annotated dataset's practical utility, we used it to train and evaluate several classification models and reported the obtained results. Though the dataset is mainly designed for fake news detection, it can also be used for hate speech detection, opinion/news classification, dialect identification, and many other tasks. © 2021 Elsevier B.V.. All rights reserved.},
	author_keywords = {Annotated Dataset; Arabic COVID-19 Multi-label Dataset; Arabic Language; Fake News Detection; Hate Speech Detection; Misinformation; Social Media},
	keywords = {Classification (of information); Speech recognition; Annotated datasets; Arabic COVID-19 multi-label dataset; Arabic languages; Elsevier; Fake news detection; Hate speech detection; Misinformation; Multi-labels; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 52; Conference name: 5th International Conference on Artificial Intelligence in Computational Linguistics, ACLing 2021; Conference date: 4 June 2021 through 5 June 2021; Conference code: 170461; All Open Access, Gold Open Access}
}

@ARTICLE{Corazza2020,
	author = {Corazza, Michele and Menini, Stefano and Cabrio, Elena and Tonelli, Sara and Villata, Serena},
	title = {A Multilingual Evaluation for Online Hate Speech Detection},
	year = {2020},
	journal = {ACM Transactions on Internet Technology},
	volume = {20},
	number = {2},
	doi = {10.1145/3377323},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085511143&doi=10.1145%2f3377323&partnerID=40&md5=9fd844a649a6dc7caeaf40ccb17bf6e1},
	affiliations = {Università di Bologna, Bologna, Italy; Fondazione Bruno Kessler, Trento, Italy; Université Cote D'Azur, Inria, CNRS, I3S, France},
	abstract = {The increasing popularity of social media platforms such as Twitter and Facebook has led to a rise in the presence of hate and aggressive speech on these platforms. Despite the number of approaches recently proposed in the Natural Language Processing research area for detecting these forms of abusive language, the issue of identifying hate speech at scale is still an unsolved problem. In this article, we propose a robust neural architecture that is shown to perform in a satisfactory way across different languages; namely, English, Italian, and German. We address an extensive analysis of the obtained experimental results over the three languages to gain a better understanding of the contribution of the different components employed in the system, both from the architecture point of view (i.e., Long Short Term Memory, Gated Recurrent Unit, and bidirectional Long Short Term Memory) and from the feature selection point of view (i.e., ngrams, social network-specific features, emotion lexica, emojis, word embeddings). To address such in-depth analysis, we use three freely available datasets for hate speech detection on social media in English, Italian, and German. © 2020 ACM.},
	author_keywords = {Hate speech detection; multilingual data; social media; text classification},
	keywords = {Brain; Long short-term memory; Memory architecture; Natural language processing systems; Network architecture; Social networking (online); Facebook; In-depth analysis; NAtural language processing; Neural architectures; Social media; Social media platforms; Speech detection; Unsolved problems; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 130; All Open Access, Green Open Access}
}

@ARTICLE{Baydogan2021110047,
	author = {Baydogan, Cem and Alatas, Bilal},
	title = {Metaheuristic Ant Lion and Moth Flame Optimization-Based Novel Approach for Automatic Detection of Hate Speech in Online Social Networks},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {110047 – 110062},
	doi = {10.1109/ACCESS.2021.3102277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112664735&doi=10.1109%2fACCESS.2021.3102277&partnerID=40&md5=d45ca1ad90a5aa80ff550a8168824b4c},
	affiliations = {Department of Software Engineering, Faculty of Technology, Firat University, Elâziǧ, 23119, Turkey; Department of Software Engineering, Faculty of Engineering, Firat University, Elâziǧ, 23119, Turkey},
	abstract = {In the online social networks, blogs, microblogs, social bookmarking services and sharing sites, and various web forum pages; the sharing of knowledge, opinions, ideas, etc. are spreading very quickly. This situation brings very dangerous problems in social networks. One of these problems is hate speech detection (HSD) problem which is covering issues such as insults, swearing, humiliation, discrimination, exclusion, detest, abhor, blast, damn, and intolerance. These can be reactions to a person, a group, an organization, an order, or an event. Although few machine learning methods have been used in the literature to solve this important problem in online social media, the performance of the HSD models in terms of many metrics needs to be increased. In this study, an automatic HSD system based on metaheuristic methodology was proposed for better results in this new and important problem. In the proposed optimization approach, Ant Lion Optimization (ALO) algorithm and Moth Flame Optimization (MFO) algorithm were designed for the HSD problem. This is the first attempt to use optimization algorithms as solution search strategies for automatic HSD. An efficient representation scheme and flexible fitness function were designed for this purpose. Many metrics can easily be embedded into the designed fitness function in order to be simultaneously optimized. Firstly, the basic natural language processing (NLP) steps were carried out. Feature extraction was performed using Bag of Words (BoW), Term Frequency (TF), and document vector (Word2Vec). Then, the performances of the proposed novel approaches were analyzed in detail on the three different real-world data. The obtained results were also checked against eight popular supervised machine learning algorithms, Social Spider Optimization (SSO) algorithm, and state-of-the-art Tunicate Swarm Algorithm (TSA). Considering the evaluation criteria for three sets of experiments, it was observed that the accuracy, sensitivity, precision, and f-score results of the ALO and MFO algorithms were superior to machine learning methods. As a result of the experimental studies, the highest accuracy value was 92.1% for ALO, while this value was 90.7% for MFO. Other numerical values obtained in the study were given in the experiments and results section with tables and graphics in detail. Due to the promising results of the proposed approaches, they are anticipated to be used in the solution of many social media and networking problems.  © 2013 IEEE.},
	author_keywords = {Hate speech detection; metaheuristic optimization; natural language processing; social network analysis; text mining},
	keywords = {Learning systems; Natural language processing systems; Optimization; Social networking (online); Speech recognition; Supervised learning; Machine learning methods; NAtural language processing; On-line social networks; Online social medias; Optimization algorithms; Optimization approach; Representation schemes; Supervised machine learning; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Gold Open Access}
}

@CONFERENCE{Mandl202029,
	author = {Mandl, Thomas and Modha, Sandip and Anand Kumar, M. and Chakravarthi, Bharathi Raja},
	title = {Overview of the HASOC Track at FIRE 2020: Hate Speech and Offensive Language Identification in Tamil, Malayalam, Hindi, English and German},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {29 – 32},
	doi = {10.1145/3441501.3441517},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100373048&doi=10.1145%2f3441501.3441517&partnerID=40&md5=9bc36d4482f01749c160d110fa1e2297},
	affiliations = {University of Hildesheim, Germany; LDRP Institute of Technology and Research, India; National Institute of Technology Karnataka, India; National University of Ireland, Ireland},
	abstract = {This paper presents the HASOC track and its two parts. HASOC is dedicated to evaluate technology for finding Offensive Language and Hate Speech. HASOC is creating test collections for languages with few resources and English for comparison. The first track within HASOC has continued work from 2019 and provided a testbed of Twitter posts for Hindi, German and English. The second track within HASOC has created test resources for Tamil and Malayalam in native and Latin script. Posts were extracted mainly from Youtube and Twitter. Both tracks have attracted much interest and over 40 research groups have participated as well as described their approaches in papers. In this overview, we present the tasks, the data and the main results.  © 2020 ACM.},
	author_keywords = {datasets; deep learning; evaluation; Hate speech},
	keywords = {Information retrieval; Malayalams; Offensive languages; Research groups; Test Collection; Twitter posts; YouTube; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 160; Conference name: 12th Annual Meeting of the Forum for Information Retrieval Evaluation, FIRE 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 166515}
}

@CONFERENCE{Dubey2020,
	author = {Dubey, Krishna and Nair, Rahul and Khan, Mohd. Usman and Shaikh, Prof. Sanober},
	title = {Toxic Comment Detection using LSTM},
	year = {2020},
	journal = {Proceedings of 2020 3rd International Conference on Advances in Electronics, Computers and Communications, ICAECC 2020},
	doi = {10.1109/ICAECC50550.2020.9339521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101112686&doi=10.1109%2fICAECC50550.2020.9339521&partnerID=40&md5=21bc50902e1d9c409924d688f99fa5c9},
	affiliations = {Thadomal Shahani Engineering College, Department of Information Technology, Mumbai, India},
	abstract = {While online communication media acts as a platform for people to connect, collaborate and discuss, overcoming the barriers for communication, some take it as a medium to direct hateful and abusive comments that may prejudice an individual's emotional and mental well being. Explosion of online communication makes it virtually impossible for filtering out the hateful tweets manually, and hence there is a need for a method to filter out the hate-speech and make social media cleaner and safer to use. The paper aims to achieve the same by text mining and making use of deep learning models constructed using LSTM neural networks that can near accurately identify and classify hate-speech and filter it out for us. The model that we have developed is able to classify given comments as toxic or nontoxic with 94.49% precision, 92.79% recall and 94.94% Accuracy score. © 2020 IEEE.},
	author_keywords = {Artificial Neural Networks; Hate Speech; LSTM; NLP; Word Embedding},
	keywords = {Deep learning; Filtration; Speech communication; Text mining; And filters; Learning models; On-line communication; Social media; Well being; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; Conference name: 3rd International Conference on Advances in Electronics, Computers and Communications, ICAECC 2020; Conference date: 11 December 2020 through 12 December 2020; Conference code: 166990}
}

@CONFERENCE{Dukić20211910,
	author = {Dukić, David and Kržić, Ana Sović},
	title = {Detection of Hate Speech Spreaders with BERT},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {1910 – 1919},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113425101&partnerID=40&md5=7a24febb805d2733a8a0f3d0158f7b1e},
	affiliations = {University of Zagreb, Faculty of Electrical Engineering and Computing, Unska 3, Zagreb, 10000, Croatia},
	abstract = {As social media grows, more and more users are disseminating hate speech through their posts. This often comes as a consequence of feeling a false security and anonymity in virtual environment. To stop hate speech spreaders, researchers started developing machine learning systems that automatically detect spreaders of hate speech based on the contents of their posts. This paper describes one such system which was trained on a corpus of English Twitter posts with a goal to predict if author of the given posts spreads hate speech or not. The features were crafted using fine-tuned BERT contextualized embeddings summed over the last 12 hidden states corresponding to the classification token, concatenated with the three binary variables called indicators. Binary variables were indicating whether hashtag, retweet or url were present in author's tweet posts, respectively. Feature vectors were then fed into a Logistic Regression classifier. Described model achieved 75% of accuracy score on the test set. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT; Fine-tuning; Indicators; Logistic regression},
	keywords = {Learning systems; Logistic regression; Social networking (online); Speech; Spreaders; Binary variables; Feature vectors; Hidden state; Logistic regression classifier; Social media; Test sets; Twitter posts; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Lee2021,
	author = {Lee, Kyuhan and Ram, Sudha},
	title = {PERSONA: Personality-based deep learning for detecting hate speech},
	year = {2021},
	journal = {International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103453577&partnerID=40&md5=2f0b0a5611f06fbb8a6b340e061d76a6},
	affiliations = {University of Arizona, McClelland Hall 107, 1130 E. Helen St, Tucson, AZ, United States; University of Arizona, McClelland Hall 430J, 1130 E. Helen St, Tucson, AZ, United States},
	abstract = {Hate speech in an online environment has detrimental impacts on the wellbeing of individuals, online communities, and social network platforms. Consequently, the automated detection of hate speech has become a significant issue for various stakeholders. While previous studies have proposed many approaches for this issue, we find an important research gap that they have neglected a plethora of studies from psychology investigating the relationship between personality and hate. To fill the gap, we adopt a text-mining approach which fully automates the process of personality inference. Based its results, we build a personality-based deep learning model for detecting online hate speech (i.e., PERSONA). We validated our model with two real-world cases. The results show that our model significantly outperforms state-of-the-art baselines including a method proposed by Google. Our study paves the way for future research by incorporating psychological aspects into the design of a deep-learning model for hate speech detection. © ICIS 2020. All rights reserved.},
	author_keywords = {Deep learning; Online hate speech; Personality; Text mining},
	keywords = {Blending; E-learning; Information systems; Information use; Learning systems; Speech; Speech recognition; Text mining; Automated detection; Learning models; Network platforms; On-line communities; Online environments; Psychological Aspects; Speech detection; State of the art; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2020 International Conference on Information Systems - Making Digital Inclusive: Blending the Local and the Global, ICIS 2020; Conference date: 13 December 2020 through 16 December 2020; Conference code: 167844}
}

@ARTICLE{Haapoja2020,
	author = {Haapoja, Jesse and Laaksonen, Salla-Maaria and Lampinen, Airi},
	title = {Gaming Algorithmic Hate-Speech Detection: Stakes, Parties, and Moves},
	year = {2020},
	journal = {Social Media and Society},
	volume = {6},
	number = {2},
	doi = {10.1177/2056305120924778},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087059042&doi=10.1177%2f2056305120924778&partnerID=40&md5=4a5f9e73a84e1948be5fb97eeccb12cb},
	affiliations = {Aalto University, Finland; University of Helsinki, Finland; Stockholm University, Sweden},
	abstract = {A recent strand of research considers how algorithmic systems are gamed in everyday encounters. We add to this literature with a study that uses the game metaphor to examine a project where different organizations came together to create and deploy a machine learning model to detect hate speech from political candidates’ social media messages during the Finnish 2017 municipal election. Using interviews and forum discussions as our primary research material, we illustrate how the unfolding game is played out on different levels in a multi-stakeholder situation, what roles different participants have in the game, and how strategies of gaming the model revolve around controlling the information available to it. We discuss strategies that different stakeholders planned or used to resist the model, and show how the game is not only played against the model itself, but also with those who have created it and those who oppose it. Our findings illustrate that while “gaming the system” is an important part of gaming with algorithms, these games have other levels where humans play against each other, rather than against technology. We also draw attention to how deploying a hate-speech detection algorithm can be understood as an effort to not only detect but also preempt unwanted behavior. © The Author(s) 2020.},
	author_keywords = {algorithmic systems; elections; game metaphor; hate-speech; social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jain2021251,
	author = {Jain, Minni and Goel, Puneet and Singla, Puneet and Tehlan, Rahul},
	title = {Comparison of various word embeddings for hate-speech detection},
	year = {2021},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {54},
	pages = {251 – 265},
	doi = {10.1007/978-981-15-8335-3_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101187743&doi=10.1007%2f978-981-15-8335-3_21&partnerID=40&md5=6349fdfaf4737164a932ae1538b8dedf},
	affiliations = {Department of Computer Engineering, Delhi Technological University, New Delhi, 110042, India},
	abstract = {Word Embedding plays a crucial role in natural language processing, and other related domains. The vast variety of language modelling and feature learning techniques often concludes in a quandary. The motivation behind this work was to produce comparative analysis among these methods and finally use them to flag hate-speech on social media. The progress in these word embedding techniques has led to remarkable results by incorporating various natural language applications. Understanding the different context of polysemous words is one of the features that evolved over time with these word embedding models. A systematic review on varying word embedding methodologies has been performed in this paper. Various experimental metrics have been used and detailed analysis has been done on each word embedding model. It is shown that analysis involves various aspects of the model like dealing with multi-sense words, and rarely occurring words, etc., and finally a coherent analysis report is presented. The various models under analysis are—Word2Vec (Skip-Gram, CBOW), GloVe, Fast-Text and ELMo. These models are then put to a real-life application in the form of Hate Speech detection of twitter data, and their individual capacities and accuracies are compared. Through this paper we show how ELMo uses different word embeddings for polysemous words to capture the context. We show how Hate speech can be better detected by ELMo because such speech requires better understanding of context of words for segregation from normal speech/text. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2021.},
	author_keywords = {CBOW; Elmo; Fast-text; GloVe; Hate-speech detection; Skip-gram; Word embedding; Word2Vec},
	keywords = {Embeddings; Modeling languages; Natural language processing systems; Social networking (online); Speech; Speech recognition; Coherent analysis; Comparative analysis; Embedding technique; Language modelling; Natural language applications; NAtural language processing; Real-life applications; Systematic Review; Learning systems},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Kapil2020,
	author = {Kapil, Prashant and Ekbal, Asif},
	title = {A deep neural network based multi-task learning approach to hate speech detection},
	year = {2020},
	journal = {Knowledge-Based Systems},
	volume = {210},
	doi = {10.1016/j.knosys.2020.106458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092410226&doi=10.1016%2fj.knosys.2020.106458&partnerID=40&md5=cff1f077c881354a60c901badce34a44},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Patna, Bihar, India},
	abstract = {With the advent of the internet and numerous social media platforms, citizens now have enormous opportunities to express and share their opinions on various societal and political issues. This phenomenal growth of the internet, social media networks, and messaging platforms provide plenty of opportunities for building intelligent systems, but these are also being heavily misused by certain groups who often disseminate offensive, racial, and hate speeches. Hence, detecting hate speech at the right time plays a crucial role as its spread might affect social fabrics. In recent times, although a few benchmark datasets have emerged for hate speech detection, these are limited in volume and also do not follow any uniform annotation schema. In this paper, a deep multi-task learning (MTL) framework is proposed to leverage useful information from multiple related classification tasks in order to improve the performance of the individual task. The proposed multi-task model is based on the shared-private scheme that assigns shared and private layers to capture the shared-features and task-specific features from five classification tasks. Experiments1 on the 5 datasets show that the proposed framework attains encouraging performance in terms of macro-F1 and weighted-F1. © 2020 Elsevier B.V.},
	author_keywords = {Hate speech detection; Macro-F1; Multi-task learning; Shared features; Task specific features; Weighted-F1},
	keywords = {Classification (of information); Deep neural networks; Intelligent systems; Learning systems; Multi-task learning; Neural networks; Social networking (online); Speech recognition; Benchmark datasets; Building intelligent systems; Classification tasks; Multi-task model; Political issues; Social media networks; Social media platforms; Speech detection; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 115}
}

@CONFERENCE{Zhou20213143,
	author = {Zhou, Xuhui and Sap, Maarten and Swayamdipta, Swabha and Smith, Noah A. and Choi, Yejin},
	title = {Challenges in automated debiasing for toxic language detection},
	year = {2021},
	journal = {EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {3143 – 3155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106070565&partnerID=40&md5=2b93cc3b0a1b670935a75c95eabb26cd},
	affiliations = {Department of Linguistics, University of Washington, United States; Paul G. Allen School of Computer Science and Engineering, University of Washington, United States; Allen Institute for Artificial Intelligence},
	abstract = {Biased associations have been a challenge in the development of classifiers for detecting toxic language, hindering both fairness and accuracy. As potential solutions, we investigate recently introduced debiasing methods for text classification datasets and models, as applied to toxic language detection. Our focus is on lexical (e.g., swear words, slurs, identity mentions) and dialectal markers (specifically African American English). Our comprehensive experiments establish that existing methods are limited in their ability to prevent biased behavior in current toxicity detectors. We then propose an automatic, dialect-aware data correction method, as a proof-of-concept study. Despite the use of synthetic labels, this method reduces dialectal associations with toxicity. Overall, our findings show that debiasing a model trained on biased toxic language data is not as effective as simply relabeling the data to remove existing biases. © 2021 Association for Computational Linguistics},
	keywords = {Computational linguistics; Text processing; Toxicity; African American; Data correction methods; De-biasing; Language detection; Proof of concept; Relabeling; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 70; Conference name: 16th Conference of the European Chapter of the Associationfor Computational Linguistics, EACL 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169023}
}

@CONFERENCE{Höllig20211976,
	author = {Höllig, Julian and Lee, Yeong Su and Seemann, Nina and Geierhos, Michaela},
	title = {Effective detection of Hate Speech Spreaders on Twitter},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {1976 – 1986},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113486496&partnerID=40&md5=95f0f3f48d4d37ad4666acc5b94b9fd7},
	affiliations = {Research Institute CODE, Bundeswehr University Munich, Neubiberg, Germany},
	abstract = {In this paper, we summarize our participation in the task of “Profiling Hate Speech Spreaders on Twitter” at the PAN@CLEF Conference 2021. Our models obtained an average accuracy of 76% (79% for Spanish and 73% for English). For English, we used a Linear Support Vector Machine with tf-idf features on noun chunk level, while for Spanish we used a Ridge Classifier with simple counts on noun chunk level. Both classifiers were fed with additional features obtained from a Convolutional Neural Network. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Author profiling; Hate speech; Noun chunks},
	keywords = {Convolutional neural networks; Social networking (online); Support vector machines; Linear Support Vector Machines; Spreaders},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Putra2020413,
	author = {Putra, I. Gede Manggala and Nurjanah, Dade},
	title = {Hate speech detection in Indonesian language instagram},
	year = {2020},
	journal = {2020 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2020},
	pages = {413 – 420},
	doi = {10.1109/ICACSIS51025.2020.9263084},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099773410&doi=10.1109%2fICACSIS51025.2020.9263084&partnerID=40&md5=3c28ff1786a4035bd814525ba9796450},
	affiliations = {Telkom University, Informatics Engineering, Bandung, Indonesia},
	abstract = {Hate speech is a form of communication which contains hatred by doing things, such as inciting, insulting, disparaging, or demeaning a person or group. Hate speech issues in Indonesia often have linkages to politics. In 2018 and 2019, for example, the hate speech relates to the local leader and presidential elections. The hate speech actors commonly use social networks, such as Instagram, to spread their hatred words. About 60% of hate speech is found in the comments of the posts and it will be a real threat if not quickly detected. Our study aims to detect hate speech in Instagram comments. We propose the use of a word2vec method with skip-gram models and a modified TextCNN to learn and detect hate speech texts. Furthermore, random oversampling, random under sampling, and class weight was used to solve imbalanced dataset problems. The results show that the best accuracy, in term of F-score, is 93.70%, gained from a combination of word2vec skip-gram with window size 15, a modified TextCNN, and random oversampling methods. © 2020 IEEE.},
	author_keywords = {Hate speech comments; Imbalance dataset; Instagram; TextCNN; Word2vec},
	keywords = {Information systems; Information use; Speech; Speech communication; Gram models; Imbalanced dataset problems; Indonesian languages; Over sampling; Presidential election; Random under samplings; Speech detection; Use social networks; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 12th International Conference on Advanced Computer Science and Information Systems, ICACSIS 2020; Conference date: 17 October 2020 through 18 October 2020; Conference code: 165350}
}

@ARTICLE{Sharma2021731,
	author = {Sharma, Ravindra and Ansari, Irshad Ahmad},
	title = {Detection of Toxic Content to Improve Online Platforms},
	year = {2021},
	journal = {Lecture Notes in Mechanical Engineering},
	pages = {731 – 739},
	doi = {10.1007/978-981-16-0942-8_70},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112654887&doi=10.1007%2f978-981-16-0942-8_70&partnerID=40&md5=a9d1a9fc9c688ae1ef3c7db420026c30},
	affiliations = {Department of Electronics and Communication Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing Jabalpur India, Jabalpur, India},
	abstract = {With the fast expansion of textual data available online, text classification becomes an important task to maintain the data available in a systematic manner. One application of text classification is handling online toxic and unwanted content. Toxic content spreads hate, and therefore, timely detection is a prime requirement. Manual screening of toxic content over the online platform is not a feasible solution as the amount of data inflow remains very high. Quora is an online platform which empowers people to learn from each other’s knowledge by asking questions and sharing useful insights for the same. A key challenge for them is to weed out such insincere questions, i.e., questions based on false premise, spreading hatred, flat statements, etc. Word2vec and TF-IDF are two approaches widely used for text classification problem. Preprocessing steps are performed to ensure better classification. Both the approaches (word2vec and TF-IDF) are implemented in this study, and results are compared. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Logistic regression; Support vector machine; Text classification; TF-IDF; Word2vec},
	keywords = {Classification (of information); Text processing; Feasible solution; Learn+; Logistics regressions; Online platforms; Pre-processing step; Support vectors machine; Text classification; Textual data; TF-IDF; Word2vec; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Congress on Advances in Materials Science and Engineering, CAMSE 2020; Conference date: 25 December 2020 through 27 December 2020; Conference code: 261809}
}

@ARTICLE{Romero-Vega2021312,
	author = {Romero-Vega, Raúl R. and Cumbicus-Pineda, Oscar M. and López-Lapo, Ruperto A. and Neyra-Romero, Lisset A.},
	title = {Detecting Xenophobic Hate Speech in Spanish Tweets Against Venezuelan Immigrants in Ecuador Using Natural Language Processing},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1388 CCIS},
	pages = {312 – 326},
	doi = {10.1007/978-3-030-71503-8_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107390264&doi=10.1007%2f978-3-030-71503-8_24&partnerID=40&md5=46137825b35968b6d45e16cb9eb3d6ba},
	affiliations = {Facultad de Energía, CIS, Universidad Nacional de Loja, Ave. Pío Jaramillo Alvarado, La Argelia, Loja, Ecuador; Departamento de Ciencias de la Computacion y Electronica, Universidad Tecnica Particular de Loja, San Cayetano Alto, Loja, Ecuador},
	abstract = {In recent reports, Ecuador and Venezuela are located as the countries with the worst social indicators, showing ethnic and racial discrimination between both countries, one possible cause is a large number of Venezuelan immigrants in Ecuador. The present work has the goal of determining the existence of xenophobic content from a set of tweets collected around Venezuelan immigrants in Ecuador, using the diverse phases of the Knowledge Discovery in Text (KDT) methodology. Identifying xenophobia by mean of Natural Language Processing (NLP) is not an easy task; nonetheless, with the use of techniques as Synthetic Minority Oversampling (SMOTE) and Crowdsourcing it is possible to make it. The feelings classification: xenophobic, offensive and other are possible thanks to executing of three supervised classification algorithms: Logistic Regression, Support Vector Machines (SVM) and Naive Bayes. As a result of the execution of the three algorithms, SVM algorithm obtains a better performance with an F1-score of 98%. On the other hand, of the 100% of data analysed, it is determinate that there exist a 5.76% of xenophobic sentiments, 31.23% of offensive emotions and 63% contains other feelings. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Hate speech; Natural Language Processing; Sentiment analysis; SMOTE; Xenophobia},
	keywords = {Logistic regression; Support vector machines; Support vector regression; Knowledge discovery in texts; Naive bayes; NAtural language processing; Over sampling; Racial discriminations; Social indicators; Supervised classification; SVM algorithm; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2nd International Conference on Applied Technologies, ICAT 2020; Conference date: 2 December 2020 through 4 December 2020; Conference code: 257279}
}

@CONFERENCE{Pham202037,
	author = {Pham, Quang Huu and Anh Nguyen, Viet and Doan, Linh Bao and Tran, Ngoc N. and Thanh, Ta Minh},
	title = {From Universal Language Model to Downstream Task: Improving RoBERTa-Based Vietnamese Hate Speech Detection},
	year = {2020},
	journal = {Proceedings - 2020 12th International Conference on Knowledge and Systems Engineering, KSE 2020},
	pages = {37 – 42},
	doi = {10.1109/KSE50997.2020.9287406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099535946&doi=10.1109%2fKSE50997.2020.9287406&partnerID=40&md5=011f34df6b8c38cb943fce462c895b7e},
	affiliations = {Sun Asterisk Inc, RD Lab; Le Quy Don Technical University, 236 Hoang Quoc Viet, Bac Tu Liem, Ha Noi, Viet Nam},
	abstract = {Natural language processing (NLP) is a fast-growing field of artificial intelligence. Since the Transformer [32] was introduced by Google in 2017, a large number of language models such as BERT, GPT, and ELMo have been inspired by this architecture. These models were trained on huge datasets and achieved state-of-the-art results on natural language understanding. However, fine-tuning a pre-trained language model on much smaller datasets for downstream tasks requires a carefully-designed pipeline to mitigate problems of the datasets such as lack of training data and imbalanced data. In this paper, we propose a pipeline to adapt the general-purpose RoBERTa language model to a specific text classification task: Vietnamese Hate Speech Detection. We first tune the PhoBERT1[9] on our dataset by re-training the model on the Masked Language Model (MLM) task; then, we employ its encoder for text classification. In order to preserve pre-trained weights while learning new feature representations, we further utilize different training techniques: Layer freezing, block-wise learning rate, and label smoothing. Our experiments proved that our proposed pipeline boosts the performance significantly, achieving a new state-of-the-art on Vietnamese Hate Speech Detection (HSD) campaign2 with 0.7221 F1 score. © 2020 IEEE.},
	author_keywords = {Hate Speech Detection (HSD); Natural Language Processing; RoBERTa; Text Classification; Text Mining},
	keywords = {Artificial intelligence; Computational linguistics; Natural language processing systems; Pipelines; Speech recognition; Systems engineering; Text processing; Feature representation; Imbalanced data; NAtural language processing; Natural language understanding; Speech detection; State of the art; Text classification; Training techniques; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 12th International Conference on Knowledge and Systems Engineering, KSE 2020; Conference date: 12 November 2020 through 14 November 2020; Conference code: 165870; All Open Access, Green Open Access}
}

@CONFERENCE{Uzan20212178,
	author = {Uzan, Moshe and HaCohen-Kerner, Yaakov},
	title = {Detecting Hate Speech Spreaders on Twitter using LSTM and BERT in English and Spanish},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {2178 – 2185},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113542448&partnerID=40&md5=30979c136f47882cfb93403b5a87881a},
	affiliations = {Computer Science Department, Bar Ilan University, Ramat-Gan, 5290002, Israel; Computer Science Department, Jerusalem College of Technology (Lev Academic Center), Jerusalem, 9116001, Israel},
	abstract = {In this paper, we describe our submissions for PAN at CLEF 2021 contest. We tackled the subtask “Profiling Hate Speech Spreaders on Twitter”. We developed different models for English and Spanish languages, using classic machine learning methods like Support Vector Classifier, Multi-Layer Perceptron, Logistic Regression, Random Forest, Ada-Boost Classifier and K-Neighbors Classifier to more recent deep learning methods like BERT and Bidirectional LSTM. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Ada-boost classifier; Author profiling; BERT; English; Hate speech; Logistic regression; LSTM; MLP; Random forest; Spanish; SVM; Twitter},
	keywords = {Decision trees; Deep learning; Logistic regression; Long short-term memory; Multilayer neural networks; Social networking (online); Spreaders; Support vector regression; Ada boost classifiers; K-neighbors; Learning methods; Machine learning methods; Multi layer perceptron; Spanish language; Subtask; Support vector classifiers; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@ARTICLE{Alsafari2020,
	author = {Alsafari, Safa and Sadaoui, Samira and Mouhoub, Malek},
	title = {Hate and offensive speech detection on Arabic social media},
	year = {2020},
	journal = {Online Social Networks and Media},
	volume = {19},
	doi = {10.1016/j.osnem.2020.100096},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090877620&doi=10.1016%2fj.osnem.2020.100096&partnerID=40&md5=5f7f939523ae39a91324a2c734a3e134},
	affiliations = {University of Regina, Regina, Canada; University of Jeddah, Jeddah, Saudi Arabia},
	abstract = {We are witnessing an increasing proliferation of hate speech on social media targeting individuals for their protected characteristics. Our study aims to devise an effective Arabic hate and offensive speech detection framework to address this serious issue. First, we built a reliable Arabic textual corpus by crawling data from Twitter using four robust extraction strategies that we implement based on four types of hate: religion, ethnicity, nationality, and gender. Next, we label the corpus based on a three-hierarchical annotation scheme in which we verify the inter annotation agreement to ensure ground truth at each level. Based on machine and deep learning techniques, we develop numerous two-class, three-class, and six-class classification models that we combine with a variety of feature extraction techniques, such as contextual word embeddings. Finally, we conduct an intensive experiment to assess the performance of the different learned models and to examine the misclassification errors. The performance results are very encouraging compared to prior hate and offensive speech studies carried out on Arabic and other languages. © 2020 Elsevier B.V.},
	author_keywords = {Arabic corpus; Data annotation; Data extraction; Deep learning; Feature extraction; Hate speech; Multi-class classification; Social media},
	keywords = {Deep learning; Extraction; Learning systems; Social networking (online); Annotation scheme; Classification models; Contextual words; Feature extraction techniques; Ground truth; Learning techniques; Misclassification error; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69}
}

@CONFERENCE{De Souza2020,
	author = {De Souza, Gabriel Araujo and Da Costa-Abreu, Marjory},
	title = {Automatic offensive language detection from Twitter data using machine learning and feature selection of metadata},
	year = {2020},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN48605.2020.9207652},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093820738&doi=10.1109%2fIJCNN48605.2020.9207652&partnerID=40&md5=41e3c1c606ca22525abfbe2792f9317b},
	affiliations = {Federal University of Rio Grande Do Norte (UFRN), Natal, Brazil; Sheffield Hallam University, Sheffield, United Kingdom},
	abstract = {The popularity of social networks has only increased in recent years. In theory, the use of social media was proposed so we could share our views online, keep in contact with loved ones or share good moments of life. However, the reality is not so perfect, so you have people sharing hate speech-related messages, or using it to bully specific individuals, for instance, or even creating robots where their only goal is to target specific situations or people. Identifying who wrote such text is not easy and there are several possible ways of doing it, such as using natural language processing or machine learning algorithms that can investigate and perform predictions using the meta-data associated with it. In this work, we present an initial investigation of which are the best machine learning techniques to detect offensive language in tweets. After an analysis of the current trend in the literature about the recent text classification techniques, we have selected Linear SVM and Naive Bayes algorithms for our initial tests. For the preprocessing of data, we have used different techniques for attribute selection that will be justified in the literature section. After our experiments, we have obtained 92% of accuracy and 95% of recall to detect offensive language with Naive Bayes and 90% of accuracy and 92% of recall with Linear SVM. From our understanding, these results overcome our related literature and are a good indicator of the importance of the data description approach we have used. © 2020 IEEE.},
	author_keywords = {Attribute Selection; Linear SVM; Naive Bayes; Offensive Language Detection; Twitter},
	keywords = {Classification (of information); Classifiers; Learning systems; Metadata; Natural language processing systems; Neural networks; Social networking (online); Support vector machines; Text processing; Attribute selection; Machine learning techniques; Naive-Bayes algorithm; NAtural language processing; Offensive languages; Pre-processing of data; Social media; Text classification; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 2020 International Joint Conference on Neural Networks, IJCNN 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 163566; All Open Access, Green Open Access}
}

@CONFERENCE{Atoum2020292,
	author = {Atoum, Jalal Omer},
	title = {Cyberbullying Detection through Sentiment Analysis},
	year = {2020},
	journal = {Proceedings - 2020 International Conference on Computational Science and Computational Intelligence, CSCI 2020},
	pages = {292 – 297},
	doi = {10.1109/CSCI51800.2020.00056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113412844&doi=10.1109%2fCSCI51800.2020.00056&partnerID=40&md5=e63a1538f05d7e59a4bc45ab4483801e},
	affiliations = {East Central University, Department of Mathematics and Computer Science, Ada, OK, United States},
	abstract = {In recent years with the widespread of social media platforms across the globe especially among young people, cyberbullying and aggression have become a serious and annoying problem that communities must deal with. Such platforms provide various ways for bullies to attack and threaten others in their communities. Various techniques and methodologies have been used or proposed to combat cyberbullying through early detection and alerts to discover and/or protect victims from such attacks. Machine learning (ML) techniques have been widely used to detect some language patterns that are exploited by bullies to attack their victims. Also. Sentiment Analysis (SA) of social media content has become one of the growing areas of research in machine learning. SA provides the ability to detect cyberbullying in real-time. SA provides the ability to detect cyberbullying in real-time. This paper proposes a SA model for identifying cyberbullying s in Twitter social media. Support Vector Machines (SVM) and Naïve Bayes (NB) are used in this model as supervised machine learning classification tools. The results of the experiments conducted on this model showed encouraging outcomes when a higher n-grams language model is applied on such s in comparison with similar previous research. Also, the results showed that SVM classifiers have better performance measures than NB classifiers on such tweets.  © 2020 IEEE.},
	author_keywords = {Cyberbullying; machine learning; sentiment analysis; social media},
	keywords = {Barium compounds; Computer crime; Intelligent computing; Sentiment analysis; Social networking (online); Sodium compounds; Support vector machines; Cyber bullying; Language model; Language patterns; Performance measure; Social media platforms; Supervised machine learning; SVM classifiers; Young peoples; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; Conference name: 2020 International Conference on Computational Science and Computational Intelligence, CSCI 2020; Conference date: 16 December 2020 through 18 December 2020; Conference code: 170944}
}

@ARTICLE{Vadesara2021225,
	author = {Vadesara, Abhilasha and Tanna, Purna and Joshi, Hardik},
	title = {Hate Speech Detection: A Bird’s-Eye View},
	year = {2021},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {52},
	pages = {225 – 231},
	doi = {10.1007/978-981-15-4474-3_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087016986&doi=10.1007%2f978-981-15-4474-3_26&partnerID=40&md5=3b27c9a77a036f6f98cb47e2869bec58},
	affiliations = {GLS University, Ahmedabad, India; Deparment of Computer Science, GLS University, Ahmedabad, India},
	abstract = {In recent years, a lot of data is being poured on social media. Due to the penetration of social media among people, a lot of people have started posting their sentiments, ideas, etc., on social media. These posts can be facts or personal emotions. In this paper, we introduce the concept of hate speech and discuss how it differs from non-hate speeches. The concept of hate speech is very old; however, posting them on social media needs special attention. We have reviewed several techniques and approaches to identify hate speech from textual data with a focus on micro-blogs. Since the notion of hate speech is quite personal, we feel that better IR systems are required to identify hate speech and delete build the systems that are capable to delete the content automatically from social media. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2021},
	author_keywords = {Evaluation metrics; Hate speech; Machine learning; Text mining},
	keywords = {Social networking (online); Speech; Ir systems; Social media; Speech detection; Textual data; Speech recognition},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Madukwe20202821,
	author = {Madukwe, Kosisochukwu Judith and Gao, Xiaoying and Xue, Bing},
	title = {A GA-Based Approach to Fine-Tuning BERT for Hate Speech Detection},
	year = {2020},
	journal = {2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020},
	pages = {2821 – 2828},
	doi = {10.1109/SSCI47803.2020.9308419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099710292&doi=10.1109%2fSSCI47803.2020.9308419&partnerID=40&md5=f5d4bd5e2f1f3818e9ae7a8f8a1b0837},
	affiliations = {Victoria University of Wellington, School of Engineering and Computer Science, Wellington, 6140, New Zealand},
	abstract = {There exists a high level of variance in the finetuning of contextual word embedding models like Bi-directional Encoder Representation for Transformers (BERT). Such variance can be introduced by various factors, such as the BERT encoder layers, the fine-tuning architecture or the hyperparameter settings. Each architectural design choice leads to different results for a specific task. Hence, we are interested in reducing this variance given some settings. This study illustrates the use of a Genetic Algorithm (GA) to search, select and design a (near-) optimal fine-tuned BERT architecture for a hate speech detection task. We propose an appropriate encoding scheme for this task which represents the possible solutions in a way that supports a less time-consuming search for the global optima. Each encoding for a single solution represents both the BERT architecture and the fine-tuning architecture for a robust search. The automatic search provided by the GA, helps to reduce the time and cost involved in manual trial and error design methods. The experiments show that the resulting architectural design and hyperparameter settings are good choices for the hate speech detection task. Our method, although validated only on hate speech detection tasks, can easily be extended and generalized to other text classification tasks.  © 2020 IEEE.},
	keywords = {Architectural design; Classification (of information); Encoding (symbols); Genetic algorithms; Intelligent computing; Signal encoding; Text processing; Automatic searches; Bi-directional; Contextual words; Encoding schemes; Hyper-parameter; Speech detection; Text classification; Trial and error; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020; Conference date: 1 December 2020 through 4 December 2020; Conference code: 166370}
}

@CONFERENCE{Ahammed2020317,
	author = {Ahammed, Shovon and Rahman, Mostafizur and Niloy, Mahedi Hasan and Chowdhury, S. M. Mazharul Hoque},
	title = {Implementation of Machine Learning to Detect Hate Speech in Bangla Language},
	year = {2020},
	journal = {Proceedings of the 2019 8th International Conference on System Modeling and Advancement in Research Trends, SMART 2019},
	pages = {317 – 320},
	doi = {10.1109/SMART46866.2019.9117214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094828373&doi=10.1109%2fSMART46866.2019.9117214&partnerID=40&md5=b57276cec7c6691e25ad85a31999d3be},
	affiliations = {Daffodil International University, Department of CSE, Dhaka, Bangladesh},
	abstract = {Hate speech is a crime in all countries. Hate speech can be for women, religions, countries, cultures. The big problem for hate speech is that it entices the evil people. Moreover, it inspires them to spread hatred in the society. Bangla is one of the topmost spoken languages in the world. But hate speech detection in Bangla language is rare. Our purpose is to detect hate speech in Bangla language. To perform the task, we were in need of the Bangla datasets. But the Bangla dataset is not available. So, we have collected data from Facebook. Collecting data from the social site is very hectic. The data contain mixed languages, grammatical mistakes. So, we made a team to collect the data. Another team was to process the data. And finally, we labeled the data as hate speech or not. The team members had enough knowledge about hate speech. They were neutral towards the data. Our data contain hate speech against women, community, culture, ethnicity, race, sex, disability. Machine Learning approach is ideal for our work. We have used the SVM and Naïve Bayes algorithm for our work and got a maximum accuracy of 72%. © 2019 IEEE.},
	author_keywords = {Hate Speech; Machine Learning; Naïve Bayes; Supervised Learning; SVM},
	keywords = {Data acquisition; Learning systems; Speech; Support vector machines; Bayes algorithms; Facebook; Machine learning approaches; Maximum accuracies; Social sites; Speech detection; Spoken languages; Team members; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; Conference name: 8th International Conference on System Modeling and Advancement in Research Trends, SMART 2019; Conference date: 22 November 2019 through 23 November 2019; Conference code: 161182}
}

@CONFERENCE{Alsafari2020526,
	author = {Alsafari, Safa and Sadaoui, Samira and Mouhoub, Malek},
	title = {Deep Learning Ensembles for Hate Speech Detection},
	year = {2020},
	journal = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
	volume = {2020-November},
	pages = {526 – 531},
	doi = {10.1109/ICTAI50040.2020.00087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098751471&doi=10.1109%2fICTAI50040.2020.00087&partnerID=40&md5=69ff66984542a47338098ee211d5231a},
	affiliations = {University of Regina, Dept. of Computer Science, Regina, Canada},
	abstract = {Our study explores offensive and hate speech detection for the Arabic language, as previous studies are minimal. Based on two-class, three-class, and six-class Arabic-Twitter datasets, we develop single and ensemble CNN and BiLSTM classifiers that we train with non-contextual (Fasttext-SkipGram) and contextual (Multilingual Bert and AraBert) word-embedding models. For each hate/offensive classification task, we conduct a battery of experiments to evaluate the performance of single and ensemble classifiers on testing datasets. The average-based ensemble approach was found to be the best performing, as it returned F-scores of 91%, 84%, and 80% for two-class, three-class and six-class prediction tasks, respectively. We also perform an error analysis of the best ensemble model for each task. © 2020 IEEE.},
	author_keywords = {BiLSTM; CNN; Ensemble Models; Error Analysis; Hate and Offensive Speech; Word Embedding},
	keywords = {Bismuth compounds; Classification (of information); Speech recognition; Arabic languages; Class prediction; Classification tasks; Ensemble approaches; Ensemble classifiers; Ensemble modeling; F-score; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: 32nd IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2020; Conference date: 9 November 2020 through 11 November 2020; Conference code: 166093}
}

@CONFERENCE{Istaiteh202095,
	author = {Istaiteh, Othman and Al-Omoush, Razan and Tedmori, Sara},
	title = {Racist and Sexist Hate Speech Detection: Literature Review},
	year = {2020},
	journal = {2020 International Conference on Intelligent Data Science Technologies and Applications, IDSTA 2020},
	pages = {95 – 99},
	doi = {10.1109/IDSTA50958.2020.9264052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098646677&doi=10.1109%2fIDSTA50958.2020.9264052&partnerID=40&md5=c81fd4055a10d83b6259326adef3910e},
	affiliations = {Princess Sumaya University for Technology, Dept. Computer Science, Amman, Jordan},
	abstract = {Hate speech has always existed; yet, the widespread use of the Internet and social media platforms has led to the exponential rise and spread of hate speech creating a pressing need to make social media platforms a safe place for minority groups, while preserving the freedom of speech. Sexist and racist hate speech are two common forms of hate speech in social media platforms and for which researchers have introduced many detection models. This paper aims to provide a survey of sexist and racist hate speech detection approaches with a focus on three different aspects; namely, available datasets, features exploited, and machine learning models.  © 2020 IEEE.},
	author_keywords = {Deep Learning; Hate Speech Detection; NLP; Sentiment Analysis},
	keywords = {Deep learning; Sentiment analysis; Social networking (online); Speech recognition; Deep learning; Exponentials; Hate speech detection; Internet media; Literature reviews; Pressung; Safer places; Sentiment analysis; Social media platforms; Speech detection; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 1st International Conference on Intelligent Data Science Technologies and Applications, IDSTA 2020; Conference date: 19 October 2020 through 22 October 2020; Conference code: 165494}
}

@CONFERENCE{Tontodimamma2021367,
	author = {Tontodimamma, Alice and del Gobbo, Emiliano and Russo, Vanessa and Sarra, Annalina and Fontanella, Lara},
	title = {Facebook Debate on Sea Watch 3 Case: Detecting Offensive Language Through Automatic Topic Mining Techniques},
	year = {2021},
	journal = {Studies in Classification, Data Analysis, and Knowledge Organization},
	pages = {367 – 378},
	doi = {10.1007/978-3-030-51222-4_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097656019&doi=10.1007%2f978-3-030-51222-4_29&partnerID=40&md5=fdbbf3d5c6c4c5b8c81d31b21481b4a3},
	affiliations = {Department of Neuroscience & Imaging, University G.d’Annunzio of Chieti-Pescara, Pescara, Italy; Department of Legal and Social Sciences, University G.d’Annunzio of Chieti-Pescara, Pescara, Italy},
	abstract = {Over the years, there has been growing concern about the disproportionate use of hate speech on social media platforms. In this paper, we present a text analysis for detecting abusive language in Italian messages on Facebook, surrounding the debate over the migrant-rescue ship, Sea Watch 3, and its captain Carola Rackete. The study data consists of more than 130,000 posts retrieved from two pages relating to Matteo Salvini, the leader of the Italian Lega political party, and from the official Facebook pages of five Italian newspapers. To explore the presence of offensive and hatred expressions in the corpus and to establish to what extent social users’ language differs, depending on the type of Facebook pages analysed, we ran a topic model based on Latent Dirichlet Allocation. We have complemented this approach with tools from semantic network analysis. © 2021, Springer Nature Switzerland AG.},
	keywords = {Data Science; Knowledge representation; Semantics; Statistics; Watches; Facebook pages; Latent Dirichlet allocation; Offensive languages; Political parties; Semantic network analysis; Social media platforms; Text analysis; Topic Modeling; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd International Conference on Data Science and Social Research, 2019; Conference date: 4 February 2019 through 5 February 2019; Conference code: 252359}
}

@CONFERENCE{Srivastava202047,
	author = {Srivastava, Naman Deep and Sakshi and Sharma, Yashvardhan},
	title = {Combating Online Hate: A Comparative Study on Identification of Hate Speech and Offensive Content in Social Media Text},
	year = {2020},
	journal = {2020 IEEE Recent Advances in Intelligent Computational Systems, RAICS 2020},
	pages = {47 – 52},
	doi = {10.1109/RAICS51191.2020.9332469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101426579&doi=10.1109%2fRAICS51191.2020.9332469&partnerID=40&md5=8190ea691dfe98487f336d0117d8b830},
	affiliations = {BITS Pilani, Department of CSIS, Pilani, India},
	abstract = {This paper addresses the important issue of rising hate and offensive comments against individuals or communities on social media. Such behaviour has become pervasive in social media where people are easily able to vent out their hatred and reach out to a large number of people, which they may not consider in the physical world. One of the most effective solution for tackling this enigmatic problem is the use of computational techniques to identify such hateful and offensive content and to take action against it. The current work focuses on detecting hate speech and offensive content in Indo-European languages keeping English on the frontline since it is the most widely used language on the Internet. The datasets used for the experiment are obtained from CrowdFlower and FIRE-2019 task on Identifying Hate Speech and Offensive Content in Social Media Text (HASOC). The paper provides a comparative analysis and explores the effectiveness of the TF-IDF approach and various word embedding-based approaches for the classification task on both the datasets. The evaluation measures are accuracy, precision, recall and F1-score. © 2020 IEEE.},
	author_keywords = {BERT; FastText; GloVe; Hate speech; LASER; Logistic Regression; Machine learning; Offensive language; Support Vector Machines; Text classification; TF-IDF; Word embeddings; Word2Vec},
	keywords = {Classification (of information); Intelligent computing; Social networking (online); Classification tasks; Comparative analysis; Comparative studies; Computational technique; Effective solution; European languages; Evaluation measures; Number of peoples; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2020 IEEE Recent Advances in Intelligent Computational Systems, RAICS 2020; Conference date: 3 December 2020 through 5 December 2020; Conference code: 166841}
}

@ARTICLE{Ngan202115,
	author = {Ngan, Chun-Kit and Bhuva, Kashyap},
	title = {A Framework and Decision Algorithm to Determine the Best Feature Extraction Technique for Supporting Machine Learning-Based Hate Speech Detection},
	year = {2021},
	journal = {Studies in Computational Intelligence},
	volume = {985},
	pages = {15 – 28},
	doi = {10.1007/978-3-030-79474-3_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111408507&doi=10.1007%2f978-3-030-79474-3_2&partnerID=40&md5=272b1bb8ceea6e771617d444c82e1c13},
	affiliations = {Data Science Program, Worcester Polytechnic Institute, 100 Institute Road, Worcester, 01609, MA, United States},
	abstract = {We develop and implement a framework and a decision algorithm to determine the best feature extraction technique (FET) for supporting machine learning-based hate speech detection. Specifically, the contributions of this work are three-fold: (1) a seamless modular pipeline that automatically preprocesses, vectorizes, and classifies whether or not a text message is a hate speech; (2) a decision algorithm that determines the best FET approach among all the possible FET candidates with the linear time complexity O(N); and (3) a preliminary experimental evaluation on the tweets provided by Twitter Sentiment Analysis on Analytics Vidhya to demonstrate that our FET framework and decision algorithm are effective and produce the significant results. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Decision algorithm; Feature extraction framework; Hate speech detection; Machine learning classifier; Natural language processing},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th IEEE/ACIS International Summer Semi-Virtual Conference on Computer and Information Science, ICIS 2021; Conference date: 23 June 2021 through 25 June 2021; Conference code: 261609}
}

@CONFERENCE{Bunde20211264,
	author = {Bunde, Enrico},
	title = {AI-assisted and explainable hate speech detection for social media moderators - A design science approach},
	year = {2021},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2020-January},
	pages = {1264 – 1273},
	doi = {10.24251/hicss.2021.154},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108317775&doi=10.24251%2fhicss.2021.154&partnerID=40&md5=c2e0b073b31db0cbad8325f0c8c6f065},
	affiliations = {Freie Universität Berlin, Germany},
	abstract = {To date, the detection of hate speech is still primarily carried out by humans, yet there is great potential for combining human expertise with automated approaches. However, identified challenges include low levels of agreement between humans and machines due to the algorithms' missing expertise of, e.g., cultural, and social structures. In this work, a design science approach is used to derive design knowledge and develop an artifact, through which humans are integrated in the process of detecting and evaluating hate speech. For this purpose, explainable artificial intelligence (XAI) is utilized: the artifact will provide explanative information, why the deep learning model predicted whether a text contains hate. Results show that the instantiated design knowledge in form of a dashboard is perceived as valuable and that XAI features increase the perception of the artifact's usefulness, ease of use, trustworthiness as well as the intention to use it. © 2021 IEEE Computer Society. All rights reserved.},
	keywords = {Deep learning; Design; Speech recognition; Automated approach; Design knowledge; Design science; Ease-of-use; Human expertise; Intention to use; Learning models; Social media; Social structure; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 54th Annual Hawaii International Conference on System Sciences, HICSS 2021; Conference date: 4 January 2021 through 8 January 2021; Conference code: 169537; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Awal2021701,
	author = {Awal, Md Rabiul and Cao, Rui and Lee, Roy Ka-Wei and Mitrović, Sandra},
	title = {AngryBERT: Joint Learning Target and Emotion for Hate Speech Detection},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12712 LNAI},
	pages = {701 – 713},
	doi = {10.1007/978-3-030-75762-5_55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111172292&doi=10.1007%2f978-3-030-75762-5_55&partnerID=40&md5=0789256711cfdb2f88a21f03900e79e8},
	affiliations = {University of Saskatchewan, Saskatoon, SK, Canada; Singapore Management University, Singapore, 188065, Singapore; Singapore University of Technology and Design, Singapore, 487372, Singapore; Dalle Molle Institute for Artificial Intelligence, Lugano, Switzerland},
	abstract = {Automated hate speech detection in social media is a challenging task that has recently gained significant traction in the data mining and Natural Language Processing community. However, most of the existing methods adopt a supervised approach that depended heavily on the annotated hate speech datasets, which are imbalanced and often lack training samples for hateful content. This paper addresses the research gaps by proposing a novel multitask learning-based model, AngryBERT, which jointly learns hate speech detection with sentiment classification and target identification as secondary relevant tasks. We conduct extensive experiments to augment three commonly-used hate speech detection datasets. Our experiment results show that AngryBERT outperforms state-of-the-art single-task-learning and multitask learning baselines. We conduct ablation studies and case studies to empirically examine the strengths and characteristics of our AngryBERT model and show that the secondary tasks are able to improve hate speech detection. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Hate speech detection; Multitask learning; Social media},
	keywords = {Learning systems; Multi-task learning; Natural language processing systems; Speech; Speech recognition; Learning Based Models; NAtural language processing; Secondary tasks; Sentiment classification; Single task learning; Speech detection; State of the art; Target identification; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 25th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2021; Conference date: 11 May 2021 through 14 May 2021; Conference code: 260369}
}

@CONFERENCE{Beatty2020502,
	author = {Beatty, Matthew},
	title = {Graph-Based Methods to Detect Hate Speech Diffusion on Twitter},
	year = {2020},
	journal = {Proceedings of the 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020},
	pages = {502 – 506},
	doi = {10.1109/ASONAM49781.2020.9381473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103691343&doi=10.1109%2fASONAM49781.2020.9381473&partnerID=40&md5=d92ef529340310bec6142c429a6e2d16},
	affiliations = {Harvard University, Department of Computer Science, Cambridge, MA, United States},
	abstract = {In this paper, we investigate models to detect the spread of hate speech on Twitter based on its diffusion in the network graph. We experiment with a dataset of 10,000 tweets manually labelled as hate speech or not and show that classification based solely on the sharing graph yields strong F1 scores for our task and high hate speech detection precision. We also highlight the vulnerability of existing textual hate speech detection methods to adversarial attacks and demonstrate that while our methods do not outperform state-of-the-art text models, graph-based models provide robust detection mechanisms and are able to detect instances of hate speech that fool text classifiers. We find that graph convolutional networks produce the strongest hate speech F1 score of 0.58 and find other success with kernel methods. Finally, we also consider the effects of automated bots in the sharing of hate speech content and find they are insignificant in our experiments. © 2020 IEEE.},
	author_keywords = {graph classification; graph kernels; graph mining; hate speech; Twitter},
	keywords = {Classification (of information); Convolutional neural networks; Graphic methods; Social networking (online); Speech; Convolutional networks; Graph-based methods; Graph-based models; Robust detection; Sharing graphs; Speech detection; State of the art; Text classifiers; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020; Conference date: 7 December 2020 through 10 December 2020; Conference code: 168050}
}

@CONFERENCE{Wu2020585,
	author = {Wu, Ching Seh and Bhandary, Unnathi},
	title = {Detection of Hate Speech in Videos Using Machine Learning},
	year = {2020},
	journal = {Proceedings - 2020 International Conference on Computational Science and Computational Intelligence, CSCI 2020},
	pages = {585 – 590},
	doi = {10.1109/CSCI51800.2020.00104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113393583&doi=10.1109%2fCSCI51800.2020.00104&partnerID=40&md5=ef0469fd4eda70dd7f61e46d00909287},
	affiliations = {San Jose State University, Department of Computer Science, San Jose, CA, United States},
	abstract = {With the progression of the Internet and social media, people are given multiple platforms to share their thoughts and opinions about various subject matters freely. However, this freedom of speech is misused to direct hate towards individuals or group of people due to their race, religion, gender etc. The rise of hate speech has led to conflicts and cases of cyber bullying, causing many organizations to look for optimal solutions to solve this problem. Developments in the field of machine learning and deep learning have piqued the interest of researchers, leading them to research and implement solutions to solve the problem of hate speech. Currently, machine learning techniques are applied to ual data to detect hate speech. With the ample use of video sharing sites, there is a need to find a way to detect hate speech in videos. This research deals with classification of videos into normal or hateful categories based on the spoken content of the videos. The video dataset is built using a crawler to search and download videos based on offensive words that are specified as keywords. The audio is extracted from the videos and is converted into ual format using a Speech-to-Text converter to obtain a transcript of the videos. Experiments are conducted by training four models with three different feature sets extracted from the dataset. The models are evaluated by computing the specified evaluation metrics. The evaluated metrics indicate that Random Forrest Classifier model delivers the best results in classifying videos.  © 2020 IEEE.},
	author_keywords = {deep learning; Hate speech; machine learning},
	keywords = {Deep learning; Intelligent computing; Speech; Speech recognition; Classifier models; Cyber bullying; Evaluation metrics; Freedom of speech; Machine learning techniques; Multiple platforms; Optimal solutions; Subject matters; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; Conference name: 2020 International Conference on Computational Science and Computational Intelligence, CSCI 2020; Conference date: 16 December 2020 through 18 December 2020; Conference code: 170944}
}

@ARTICLE{Florio2020,
	author = {Florio, Komal and Basile, Valerio and Polignano, Marco and Basile, Pierpaolo and Patti, Viviana},
	title = {Time of your hate: The challenge of time in hate speech detection on social media},
	year = {2020},
	journal = {Applied Sciences (Switzerland)},
	volume = {10},
	number = {12},
	doi = {10.3390/APP10124180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087763770&doi=10.3390%2fAPP10124180&partnerID=40&md5=d4c6b8ba193ed062299bc19f02cb462e},
	affiliations = {Department of Computer Science, University of Turin, Turin, 10149, Italy; Department of Computer Science, University of Bari "Aldo Moro", Bari, 70126, Italy},
	abstract = {The availability of large annotated corpora from social media and the development of powerful classification approaches have contributed in an unprecedented way to tackle the challenge of monitoring users' opinions and sentiments in online social platforms across time. Such linguistic data are strongly affected by events and topic discourse, and this aspect is crucial when detecting phenomena such as hate speech, especially from a diachronic perspective. We address this challenge by focusing on a real case study: the "Contro l'odio" platform for monitoring hate speech against immigrants in the Italian Twittersphere. We explored the temporal robustness of a BERT model for Italian (AlBERTo), the current benchmark on non-diachronic detection settings. We tested different training strategies to evaluate how the classification performance is affected by adding more data temporally distant from the test set and hence potentially different in terms of topic and language use. Our analysis points out the limits that a supervised classification model encounters on data that are heavily influenced by events. Our results show how AlBERTo is highly sensitive to the temporal distance of the fine-tuning set. However, with an adequate time window, the performance increases, while requiring less annotated data than a traditional classifier. © 2020 by the authors.},
	author_keywords = {Diachronic analysis;microblogging data; Hate speechmonitoring; Supervisedmachine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Chaudhari2020940,
	author = {Chaudhari, Ajinkya and Parseja, Akshay and Patyal, Akshit},
	title = {CNN based hate-o-meter: A hate speech detecting tool},
	year = {2020},
	journal = {Proceedings of the 3rd International Conference on Smart Systems and Inventive Technology, ICSSIT 2020},
	pages = {940 – 944},
	doi = {10.1109/ICSSIT48917.2020.9214247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094865382&doi=10.1109%2fICSSIT48917.2020.9214247&partnerID=40&md5=e7f23ba16d8e25f455226fc4fe6d333c},
	affiliations = {Vishwakarma Institute of Technology, Department of Computer Engineering, Pune, India},
	abstract = {Hate Speech is a widespread problem that degrades a person or people based on their race, religion, gender or disability. This research work proposes a tool to raise awareness on the persistent hate speech in blogs, online-forums, and newspapers. The primary aim of this research work is to highlight the content that promotes violence or hatred against individuals or groups based on religion, gender, ethnicity or disability. A convolutional neural network architecture is used along with the natural language processing techniques. Using this algorithm, the tool identifies the percentage of hate and displays the bias of the statements. To host the proposed model, flask API and heroku platform is used. The proposed tool has the ability to detect hate speech with 80.15 percent accuracy and f1-score of 80.35 percent. The tool is made free and available for demo use to the public. © 2020 IEEE.},
	author_keywords = {CNN; Hate speech; Natural language processing; Text; Word2vec},
	keywords = {Convolutional neural networks; Natural language processing systems; Network architecture; F1 scores; NAtural language processing; Online forums; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 3rd International Conference on Smart Systems and Inventive Technology, ICSSIT 2020; Conference date: 20 August 2020 through 22 August 2020; Conference code: 163756}
}

@CONFERENCE{Mathew202114867,
	author = {Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh},
	title = {HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection},
	year = {2021},
	journal = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
	volume = {17A},
	pages = {14867 – 14875},
	doi = {10.1609/aaai.v35i17.17745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106194718&doi=10.1609%2faaai.v35i17.17745&partnerID=40&md5=e0801205b9be96b9e176c5a153169f69},
	affiliations = {Indian Institute of Technology, Kharagpur, India; Universität Hamburg, Germany},
	abstract = {Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public for other researchers2 Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved},
	keywords = {Artificial intelligence; Social networking (online); Speech recognition; ART model; Benchmark datasets; Interpretability; Labelings; Online social medias; Speech detection; State of the art; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 285; Conference name: 35th AAAI Conference on Artificial Intelligence, AAAI 2021; Conference date: 2 February 2021 through 9 February 2021; Conference code: 176953; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Aljero202092,
	author = {Aljero, Mona Khalifa A. and Dimililer, Nazife},
	title = {Hate Speech Detection Using Genetic Programming},
	year = {2020},
	journal = {3rd International Conference on Advanced Science and Engineering, ICOASE 2020},
	pages = {92 – 96},
	doi = {10.1109/ICOASE51841.2020.9436621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107800076&doi=10.1109%2fICOASE51841.2020.9436621&partnerID=40&md5=648521481df5f572eb9ae6df76338f6d},
	affiliations = {Applied Mathematics Computer, Eastern Mediterranean University, Famagusta, North Cyprus, Turkey; Information Technology, Eastern Mediterranean University, Famagusta, North Cyprus, Turkey},
	abstract = {There has been a steep increase in the use of social media in our everyday lives in recent years. Along with this, there has been an increase in hate speech disseminated on these platforms, due to the anonymity of the users as well as the ease of use. Social media platforms need to filter and prevent the spread of hate speech to protect their users and society. Due to the high traffic, automatic detection of hate speech is necessary. Hate speech detection is one of the most difficult classification challenges in text mining. Research in this domain focuses on the use of supervised machine learning approaches, such as support vector machine, logistic regression, convolutional neural network, and random forest. Ensemble techniques have also been employed. However, the performance of these approaches has not yet reached an acceptable level. In this paper, we propose the use of the Genetic Programming (GP) approach for binary classification of hate speech on social media platforms. Each individual in the GP framework represents a classifier that is evolved to optimize Fl-score. Experimental results show the effectiveness of our GP approach; the proposed approach outperforms the state-of-the-art using the same dataset HatEval.  © 2020 IEEE.},
	author_keywords = {classifier; genetic programming; hate speech; text classification},
	keywords = {Convolutional neural networks; Decision trees; Filtration; Genetic algorithms; Genetic programming; Logistic regression; Social networking (online); Speech; Support vector machines; Support vector regression; Text mining; Automatic Detection; Binary classification; Ensemble techniques; Social media; Social media platforms; Speech detection; State of the art; Supervised machine learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd International Conference on Advanced Science and Engineering, ICOASE 2020; Conference date: 24 January 2021 through 25 January 2021; Conference code: 169286}
}

@CONFERENCE{Gaikwad2021437,
	author = {Gaikwad, Saurabh and Ranasinghe, Tharindu and Zampieri, Marcos and Homan, Christopher M.},
	title = {Cross-lingual Offensive Language Identification for Low Resource Languages: The Case of Marathi},
	year = {2021},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {437 – 443},
	doi = {10.26615/978-954-452-072-4_050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113678248&doi=10.26615%2f978-954-452-072-4_050&partnerID=40&md5=d66f96d8a39181e620d792b79a023fdd},
	affiliations = {Rochester Institute of Technology, United States; University of Wolverhampton, United Kingdom},
	abstract = {The widespread presence of offensive language on social media motivated the development of systems capable of recognizing such content automatically. Apart from a few notable exceptions, most research on automatic offensive language identification has dealt with English. To address this shortcoming, we introduce MOLD, the Marathi Offensive Language Dataset. MOLD is the first dataset of its kind compiled for Marathi, thus opening a new domain for research in low-resource Indo-Aryan languages. We present results from several machine learning experiments on this dataset, including zero-short and other transfer learning experiments on state-of-the-art cross-lingual transformers from existing data in Bengali, English, and Hindi. © 2021 Incoma Ltd. All rights reserved.},
	keywords = {Molds; Bengalis; Cross-lingual; Language identification; Low resource languages; Offensive languages; On state; Social media; State of the art; Transfer learning; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 51; Conference name: International Conference on Recent Advances in Natural Language Processing: Deep Learning for Natural Language Processing Methods and Applications, RANLP 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 176177; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Febriana202029,
	author = {Febriana, Trisna and Budiarto, Arif},
	title = {Annotation System to Build Cyberbullying and Hate Speech Detection Model Training Dataset},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {29 – 30},
	doi = {10.1145/3431656.3432054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100372128&doi=10.1145%2f3431656.3432054&partnerID=40&md5=30fdb59fe81219c160870251e5371157},
	affiliations = {Bina Nusantara University, Information Systems Department, School of Information Systems, Jakarta, 11480, Indonesia; Bina Nusantara University, Computer Science Department, School of Computer Science, Jakarta, 11480, Indonesia},
	abstract = {During 2019, Indonesian people experienced the election period which triggers many hate speech and cyberbullying cases on Twitter. A detection tool to screen social media data can be used to avoid the spread of negative content. A supervised machine learning approach can be used to build this detection tool. However, it needs thousands of labeled data to develop the machine learning model with high accuracy. In the current study phase, an annotation system was proposed to help the researchers to label Twitter raw data collected in the previous phase. An open-source tool was utilized to build a user-friendly web-based system. Three main features are proposed including multi labels annotation, multi-users validation, and dashboard page. This system can help the annotators to perform labeling task for thousands of text data.  © 2020 Owner/Author.},
	keywords = {Computer crime; Human computer interaction; Indium compounds; Inspection equipment; Open systems; Social networking (online); Supervised learning; User experience; Annotation systems; Detection tools; Machine learning models; Open source tools; Social media datum; Speech detection; Supervised machine learning; Web-based system; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th International Human-Computer Interaction and User Experience Conference: Fostering Digital Innovation, CHIuXiD 2020; Conference date: 21 October 2020 through 23 October 2020; Conference code: 166740}
}

@CONFERENCE{Siino20212126,
	author = {Siino, Marco and Di Nuovo, Elisa and Tinnirello, Ilenia and la Cascia, Marco},
	title = {Detection of Hate Speech Spreaders using convolutional neural networks},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {2126 – 2136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113436218&partnerID=40&md5=d83cc24b6528803147f193d952bba04f},
	affiliations = {Università degli Studi di Palermo, Dipartimento di Ingegneria, Palermo, 90128, Italy; Università degli Studi di Torino, Dipartimento di Lingue e Letterature Straniere e Culture Moderne, Torino, 10124, Italy},
	abstract = {In this paper we describe a deep learning model based on a Convolutional Neural Network (CNN). The model was developed for the Profiling Hate Speech Spreaders (HSSs) task proposed by PAN 2021 organizers and hosted at the 2021 CLEF Conference. Our approach to the task of classifying an author as HSS or not (nHSS) takes advantage of a CNN based on a single convolutional layer. In this binary classification task, on the tests performed using a 5-fold cross validation, the proposed model reaches a maximum accuracy of 0.80 on the multilingual (i.e., English and Spanish) training set, and a minimum loss value of 0.51 on the same set. As announced by the task organizers, the trained model presented is able to reach an overall accuracy of 0.79 on the full test set. This overall accuracy is obtained averaging the accuracy achieved by the model on both languages. In particular, with regard to the Spanish test set, the organizers announced that our model achieves an accuracy of 0.85, while on the English test set the same model achieved - as announced by the organizers too - an accuracy of 0.73. Thanks to the model presented in this paper, our team won the 2021 PAN competition on profiling HSSs. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Author profiling; English; Hate speech; Spanish; Twitter},
	keywords = {Classification (of information); Convolution; Deep learning; Spreaders; Binary classification; Cross validation; Full tests; Learning models; Maximum accuracies; Minimum loss; Overall accuracies; Training sets; Convolutional neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Nozza2021907,
	author = {Nozza, Debora},
	title = {Exposing the limits of Zero-shot Cross-lingual Hate Speech Detection},
	year = {2021},
	journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
	volume = {2},
	pages = {907 – 914},
	doi = {10.18653/v1/2021.acl-short.114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113665063&doi=10.18653%2fv1%2f2021.acl-short.114&partnerID=40&md5=e0caea67229e4dc4b31c3bac44808c34},
	affiliations = {Bocconi University, Via Sarfatti 25, Milan, 20136, Italy},
	abstract = {Reducing and counter-acting hate speech on Social Media is a significant concern. Most of the proposed automatic methods are conducted exclusively on English and very few consistently labeled, non-English resources have been proposed. Learning to detect hate speech on English and transferring to unseen languages seems an immediate solution. This work is the first to shed light on the limits of this zero-shot, cross-lingual transfer learning framework for hate speech detection. We use benchmark data sets in English, Italian, and Spanish to detect hate speech towards immigrants and women. Investigating post-hoc explanations of the model, we discover that nonhateful, language-specific taboo interjections are misinterpreted as signals of hate speech. Our findings demonstrate that zero-shot, crosslingual models cannot be used as they are, but need to be carefully designed. © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Zero-shot learning; Automatic method; Benchmark data; Cross-lingual; Data set; Learning frameworks; Social media; Speech detection; Transfer learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 67; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173031; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Paul2021619,
	author = {Paul, Chayan and Bora, Pronami},
	title = {Detecting Hate Speech using Deep Learning Techniques},
	year = {2021},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {12},
	number = {2},
	pages = {619 – 623},
	doi = {10.14569/IJACSA.2021.0120278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102037804&doi=10.14569%2fIJACSA.2021.0120278&partnerID=40&md5=c299818371df8c0e24c11239a7c7b0c1},
	affiliations = {Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of Electronics and Communication Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India},
	abstract = {Social networking sites saw a steep rise in terms of number of users in last few years. As a result of this, the interaction among the users also increased considerably. Along with these posting racial comments based on cast, race, gender, religion, etc. also increased. This propagation of negative messages is collectively known as hate speeches. Often these posts containing negative comments in social networking sites create law and order situations in the society, leading to loss of human life and properties. Detecting hate speech is one of the major challenges faced in recent time. In recent past, there have been a considerable amount of research going on the field of detection of hate speech in the social networking sites. Researchers in the fields of Natural Language Processing and Machine Learning have done considerable amount research in in this area. This paper uses a simple up sampling method to make the data balanced and implements deep learning models like Long Short Term Memory (LSTM) and Bi-directional Long Short Term Memory (Bi-LSTM) for improved accuracy in detecting hate speech in social networking sites. LSTM was found to have better accuracy that Bi-LSTM for the data set considered. LSTM also had better values for precision and F1 score. Bi-LSTM only for higher values for recall. © 2021. All Rights Reserved.},
	author_keywords = {Bi-directional Long Short Term Memory (Bi-LSTM); deep learning; hate speech; Long Short Term Memory (LSTM); text classification},
	keywords = {Brain; Classification (of information); Learning algorithms; Natural language processing systems; Social networking (online); Speech; Speech recognition; Text processing; Bi-directional; Bi-directional long short term memory; Deep learning; Hate speech; Human lives; Learning techniques; Long short term memory; Machine-learning; Property; Simple++; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Tosev20212158,
	author = {Tosev, Darko and Gievska, Sonja},
	title = {Multi-level stacked ensemble learning for identifying Hate Speech Spreaders on Twitter},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2936},
	pages = {2158 – 2168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113460262&partnerID=40&md5=5f043861758a547874361bf4953a003b},
	affiliations = {Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, 16 Rugjer Boshkovikj St, Skopje, 1000, North Macedonia},
	abstract = {There are growing signs of discontent with the anti-social behavior expressed on social media platforms. Harnessing the power of machine learning for the purpose of detecting and mediating the spread of malicious behavior has received a heightened attention in the last decade. In this paper, we report on an experiment that examines the predictive power of a number of sparse and dense feature representations coupled with a multi-level ensemble classifier. To address the research questions, we have used PAN 2021 Profiling Hate Speech Spreaders on Twitter task for English language. The initial results are encouraging pointing out to the robustness of the proposed model when evaluated on the test dataset. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {English; Ensemble learning; Feature vector representation; Hate speech spreaders detection; Twitter},
	keywords = {Spreaders; Statistical tests; English languages; Ensemble classifiers; Ensemble learning; Feature representation; Malicious behavior; Predictive power; Research questions; Social media platforms; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 Working Notes of CLEF - Conference and Labs of the Evaluation Forum, CLEF-WN 2021; Conference date: 21 September 2021 through 24 September 2021; Conference code: 171327}
}

@CONFERENCE{Faal2021932,
	author = {Faal, Farshid and Yu, Jia Yuan and Schmitt, Ketra},
	title = {Domain adaptation multi-task deep neural network for mitigating unintended bias in toxic language detection},
	year = {2021},
	journal = {ICAART 2021 - Proceedings of the 13th International Conference on Agents and Artificial Intelligence},
	volume = {2},
	pages = {932 – 940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103861777&partnerID=40&md5=b56d461f6ffe99e18c0ce9d165fc20b6},
	affiliations = {Concordia Institute for Information System Engineering, Canada; Concordia University, Montreal, Canada},
	abstract = {As online communities have grown, so has the ability to exchange ideas, which includes an increase in the spread of toxic language, including racism, sexual harassment, and other negative behaviors that are not tolerated in polite society. Hence, toxic language detection within online conversations has become an essential application of natural language processing. In recent years, machine learning approaches for toxic language detection have primarily focused on many researchers in academics and industries. However, in many of these machine learning models, non-toxic comments containing specific identity terms, such as gay, Black, Muslim, and Jewish, were given unreasonably high toxicity scores. In this research, we propose a new approach based on the domain adaptation language model and multi-task deep neural network to identify and mitigate this form of unintended model bias in online conversations. We use six toxic language detection and identification tasks to train the model to detect toxic contents and mitigate unintended bias in model prediction. We evaluate our model and compare it with other state-of-the-art deep learning models using specific performance metrics to measure the model bias. In detailed experiments, we show our approach can identify the toxic language in conversations with considerably more robustness to model bias towards commonly-attacked identity groups presented in online conversations in social media. © 2021 by SCITEPRESS - Science and Technology Publications, Lda.},
	author_keywords = {Contextual language model; Deep neural network; Domain adaptation; Multi-task learning; Toxic language detection; Unintended bias},
	keywords = {Deep learning; Deep neural networks; Learning systems; Natural language processing systems; Social networking (online); Domain adaptation; Language detection; Machine learning approaches; Machine learning models; NAtural language processing; On-line communities; Performance metrics; Sexual harassment; Neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 13th International Conference on Agents and Artificial Intelligence, ICAART 2021; Conference date: 4 February 2021 through 6 February 2021; Conference code: 167493}
}

@ARTICLE{Durães2021106,
	author = {Durães, Dalila and Marcondes, Francisco S. and Gonçalves, Filipe and Fonseca, Joaquim and Machado, José and Novais, Paulo},
	title = {Detection violent behaviors: A survey},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1239 AISC},
	pages = {106 – 116},
	doi = {10.1007/978-3-030-58356-9_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091503158&doi=10.1007%2f978-3-030-58356-9_11&partnerID=40&md5=ed2f6cb833a6cc4d92e3dca5aabec4c0},
	affiliations = {CIICESI, ESTG, Instituto Politécnico do Porto, Felgueiras, Portugal; Algorithm Center, University of Minho, Braga, Portugal; Bosch Car Multimedia, Braga, Portugal},
	abstract = {Violence detection behavior is a particular problem regarding the great problem action recognition. In recent years, the detection and recognition of violence has been studied for several applications, namely in surveillance. In this paper, we conducted a recent systematic review of the literature on this subject, covering a selection of various researched papers. The selected works were classified into three main approaches for violence detection: video, audio, and multimodal audio and video. Our analysis provides a roadmap to guide future research to design automatic violence detection systems. Techniques related to the extraction and description of resources to represent behavior are also reviewed. Classification methods and structures for behavior modelling are also provided. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.},
	author_keywords = {Action recognition; Audio surveillance; Multimodal surveillance; Video surveillance; Violence detection},
	keywords = {Application programs; Artificial intelligence; Classification (of information); Action recognition; Audio and video; Behavior modelling; Classification methods; Multi-modal; Systematic Review; Violence detections; Violent behavior; Ambient intelligence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 11th International Symposium on Ambient Intelligence, ISAmI 2020; Conference date: 7 October 2020 through 9 October 2020; Conference code: 245169; All Open Access, Green Open Access}
}

@ARTICLE{Ekinci2020109,
	author = {Ekinci, Ekin and Omurca, Sevinc Ilhan and Sevim, Semih},
	title = {Improve offensive language detection with ensemble classifiers},
	year = {2020},
	journal = {International Journal of Intelligent Systems and Applications in Engineering},
	volume = {8},
	number = {2},
	pages = {109 – 115},
	doi = {10.18201/ijisae.2020261592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091535148&doi=10.18201%2fijisae.2020261592&partnerID=40&md5=df6a243922ca0f6b509f5adc3e4d5a4e},
	affiliations = {Dogus University, Faculty of Engineering / Software Engineering, Turkey; Kocaeli University, Faculty of Engineering, Computer Engineering, Turkey},
	abstract = {Sharing content easily on social media has become an important communication choice in the world we live. However, in addition to the conveniences it provides, some problems have been emerged because content sharing is not bounded by predefined rules. Consequently, offensive language has become a big problem for both social media and its users. In this article, it is aimed to detect offensive language in short text messages on Twitter. Since short texts do not contain sufficient statistical information, they have some drawbacks. To cope with these drawbacks of the short texts, semantic word expansion based on concept and word-embedding vectors are proposed. Then for classification task, decision tree and decision tree based ensemble classifiers such as Adaptive Boosting, Bootstrap Aggregating, Random Forest, Extremely Randomized Decision Tree and Extreme Gradient Boosting algorithms are used. Also the imbalanced dataset problem is solved by oversampling. Experiments on datasets have shown that the extremely randomized trees which takes word-embedding vectors as input are the most successful with an F-score of 85.66%. © 2020, Ismail Saritas. All rights reserved.},
	author_keywords = {BabelNet; Ensemble classifiers; Offensive language; Short text classification; Twitter; Word2Vec},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Maheshappa2020430,
	author = {Maheshappa, Poojitha and Mathew, Binny and Saha, Punyajoy},
	title = {Using Knowledge Graphs to improve Hate Speech Detection},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {430},
	doi = {10.1145/3430984.3431072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098846425&doi=10.1145%2f3430984.3431072&partnerID=40&md5=868ae83c2c40baed8bd0b1221e340b97},
	affiliations = {Iit Kharagpur, India},
	abstract = {With the increasing cases of online hate speech, there is an urgent demand for better hate speech detection systems. In this paper, we utilize Knowledge Graphs (KGs) to improve hate speech detection. Our initial results shows that incorporating information from KG helps the classifier to improve the performance. © 2021 Owner/Author.},
	author_keywords = {Hate Speech; Knowledge Graphs; Text Classification},
	keywords = {Classification (of information); Data Science; Knowledge representation; Online systems; Knowledge graphs; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 3rd ACM India Joint International Conference on Data Science and Management of Data, CODS-COMAD 2021; Conference date: 2 January 2021 through 4 January 2021; Conference code: 166135}
}

@BOOK{Ahuja2020515,
	author = {Ahuja, Ravinder and Banga, Alisha and Sharma, S.C.},
	title = {Detecting abusive comments using ensemble deep learning algorithms},
	year = {2020},
	journal = {Malware Analysis Using Artificial Intelligence and Deep Learning},
	pages = {515 – 534},
	doi = {10.1007/978-3-030-62582-5_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137173244&doi=10.1007%2f978-3-030-62582-5_20&partnerID=40&md5=bf220ec50d03e9e99e19a16ad3582a18},
	affiliations = {Indian Institute of Technology Roorkee Saharanpur Campus, Saharanpur, India},
	abstract = {Today, there is an avalanche of data on social networking sites. Technology has facilitated our way of Internet usage and provided us with great liberty to do what, when, and how we like. In just one click, we can share, like, comment any post on social media, but this liberty has caused a severe threat to humans; unfortunately, the online interaction among users with such ease involves harassment, abuse, and bullying actions. The concern over this problem has triggered to build up better models for classifying the abusive comments. In this chapter, we have applied four classification algorithms: Naive Bayes, Random Forest, Decision Tree, and Support Vector Machine, with Bag of Words features. Deep learning algorithms: Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and an ensemble of LSTM and CNN are applied using GloVe and fastText word embedding to classify the comments into six categories: toxic, severe toxic, obscene, threat, insult, and identity hate. We have taken data set from Kaggle competition. We conducted experiments by using Keras library and TensorFlow at the back end and taken accuracy as performance parameter. We found that CNN, LSTM blend with fastText word embedding performs better out of all the algorithms applied with an accuracy of 98.46%. © The Author(s), 2021. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Alshalan20201,
	author = {Alshalan, Raghad and Al-Khalifa, Hend},
	title = {A deep learning approach for automatic hate speech detection in the saudi twittersphere},
	year = {2020},
	journal = {Applied Sciences (Switzerland)},
	volume = {10},
	number = {23},
	pages = {1 – 16},
	doi = {10.3390/app10238614},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097289337&doi=10.3390%2fapp10238614&partnerID=40&md5=b659de729b6af3777825fc975a737c04},
	affiliations = {Department of Information Technology, College of Computer and Information Sciences, King Saud University, Riyadh P.O Box 12371, Saudi Arabia},
	abstract = {With the rise of hate speech phenomena in the Twittersphere, significant research efforts have been undertaken in order to provide automatic solutions for detecting hate speech, varying from simple machine learning models to more complex deep neural network models. Despite this, research works investigating hate speech problem in Arabic are still limited. This paper, therefore, aimed to investigate several neural network models based on convolutional neural network (CNN) and recurrent neural network (RNN) to detect hate speech in Arabic tweets. It also evaluated the recent language representation model bidirectional encoder representations from transformers (BERT) on the task of Arabic hate speech detection. To conduct our experiments, we firstly built a new hate speech dataset that contained 9316 annotated tweets. Then, we conducted a set of experiments on two datasets to evaluate four models: CNN, gated recurrent units (GRU), CNN + GRU, and BERT. Our experimental results in our dataset and an out-domain dataset showed that the CNN model gave the best performance, with an F1-score of 0.79 and area under the receiver operating characteristic curve (AUROC) of 0.89. © 2020, MDPI AG. All rights reserved.},
	author_keywords = {Abusive language; Arabic; Arabic tweets; Hate speech detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 88; All Open Access, Gold Open Access}
}

@ARTICLE{Luu2021415,
	author = {Luu, Son T. and Nguyen, Kiet Van and Nguyen, Ngan Luu-Thuy},
	title = {A Large-Scale Dataset for Hate Speech Detection on Vietnamese Social Media Texts},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12798 LNAI},
	pages = {415 – 426},
	doi = {10.1007/978-3-030-79457-6_35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112714728&doi=10.1007%2f978-3-030-79457-6_35&partnerID=40&md5=927bf93a9e763da1b12522149978dda4},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam},
	abstract = {In recent years, Vietnam witnesses the mass development of social network users on different social platforms such as Facebook, Youtube, Instagram, and Tiktok. On social media, hate speech has become a critical problem for social network users. To solve this problem, we introduce the ViHSD - a human-annotated dataset for automatically detecting hate speech on the social network. This dataset contains over 30,000 comments, each comment in the dataset has one of three labels: CLEAN, OFFENSIVE, or HATE. Besides, we introduce the data creation process for annotating and evaluating the quality of the dataset. Finally, we evaluate the dataset by deep learning and transformer models. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Hate speech detection; Machine learning; Social media texts; Text classification},
	keywords = {Deep learning; Intelligent systems; Social networking (online); Speech recognition; Critical problems; Data creation; Facebook; Large-scale dataset; Social media; Speech detection; Transformer models; Vietnamese; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; Conference name: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021; Conference date: 26 July 2021 through 29 July 2021; Conference code: 262819}
}

@ARTICLE{Paschalides2020,
	author = {Paschalides, Demetris and Stephanidis, DImosthenis and Andreou, Andreas and Orphanou, Kalia and Pallis, George and DIkaiakos, Marios D. and Markatos, Evangelos},
	title = {MANDOLA: A Big-Data Processing and Visualization Platform for Monitoring and Detecting Online Hate Speech},
	year = {2020},
	journal = {ACM Transactions on Internet Technology},
	volume = {20},
	number = {2},
	doi = {10.1145/3371276},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085531234&doi=10.1145%2f3371276&partnerID=40&md5=c5ec28d7dea78ba6ff13a6aa3f1857ff},
	affiliations = {Computer Science Department, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Crete, Heraklion, Crete, Greece},
	abstract = {In recent years, the increasing propagation of hate speech in online social networks and the need for effective counter-measures have drawn significant investment from social network companies and researchers. This has resulted in the development of many web platforms and mobile applications for reporting and monitoring online hate speech incidents. In this article, we present MANDOLA, a big-data processing system that monitors, detects, visualizes, and reports the spread and penetration of online hate-related speech using big-data approaches. MANDOLA consists of six individual components that intercommunicate to consume, process, store, and visualize statistical information regarding hate speech spread online. We also present a novel ensemble-based classification algorithm for hate speech detection that can significantly improve the performance of MANDOLA's ability to detect hate speech. To present the functionality and usability of our system, we present a use case scenario of real-life event annotation and data correlation. As shown from the performance of the individual modules, as well as the usability and functionality of the whole system, MANDOLA is a powerful system for reporting and monitoring online hate speech. © 2020 ACM.},
	author_keywords = {big-data processing platform; deep learning; Hate speech; online social networks; system approach},
	keywords = {Audio signal processing; Big data; Data handling; Data visualization; Monitoring; Social networking (online); Speech; Classification algorithm; Data processing systems; Individual components; Mobile applications; Monitoring on line; On-line social networks; Statistical information; Visualization platforms; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@CONFERENCE{Luu2020,
	author = {Luu, Son T. and Nguyen, Hung P. and Van Nguyen, Kiet and Luu-Thuy Nguyen, Ngan},
	title = {Comparison between Traditional Machine Learning Models and Neural Network Models for Vietnamese Hate Speech Detection},
	year = {2020},
	journal = {Proceedings - 2020 RIVF International Conference on Computing and Communication Technologies, RIVF 2020},
	doi = {10.1109/RIVF48685.2020.9140745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090275404&doi=10.1109%2fRIVF48685.2020.9140745&partnerID=40&md5=2a95e44e6c6ee606817663ecadd01062},
	affiliations = {University of Information Technology, Ho Chi Minh City, Viet Nam},
	abstract = {Hate-speech detection on social network language has become one of the main researching fields recently due to the spreading of social networks like Facebook and Twitter. In Vietnam, the threat of offensive and harassment cause bad impacts for online user. The VLSP - Shared task about Hate Speech Detection on social networks showed many proposed approaches for detecting whatever comment is clean or not. However, this problem still needs further researching. Consequently, we compare traditional machine learning and deep learning on a large dataset about the user's comments on social network in Vietnamese and find out what is the advantage and disadvantage of each model by comparing their accuracy on F1-score, then we pick two models in which has highest accuracy in traditional machine learning models and deep neural models respectively. Next, we compare these two models capable of predicting the right label by referencing their confusion matrices and considering the advantages and disadvantages of each model. Finally, from the comparison result, we propose our ensemble method that concentrates the abilities of traditional methods and deep learning methods. © 2020 IEEE.},
	author_keywords = {classification; comments; comparison; data; deep neural network; harassment; hate-speech detection; imbalance data; machine learning; offensive; social network},
	keywords = {Deep learning; E-learning; Large dataset; Neural networks; Social networking (online); Speech recognition; Comparison result; Confusion matrices; Ensemble methods; Learning methods; Machine learning models; Network language; Neural network model; Speech detection; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 2020 RIVF International Conference on Computing and Communication Technologies, RIVF 2020; Conference date: 14 October 2020 through 15 October 2020; Conference code: 161900; All Open Access, Green Open Access}
}

@ARTICLE{Pelicon20212,
	author = {Pelicon, Andraz and Shekhar, Ravi and Skrlj, Blaz and Purver, Matthew and Pollak, Senja},
	title = {Investigating cross-lingual training for offensive language detection},
	year = {2021},
	journal = {PeerJ Computer Science},
	volume = {7},
	pages = {2 – 39},
	doi = {10.7717/peerj-cs.559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110644824&doi=10.7717%2fpeerj-cs.559&partnerID=40&md5=56bae7c14f46a2b10ee973b40911e743},
	affiliations = {Jožef Stefan Institute, Ljubljana, Slovenia; Jožef Stefan International Postgraduate School, Ljubljana, Slovenia; Queen Mary University of London, London, United Kingdom},
	abstract = {Platforms that feature user-generated content (social media, online forums, newspaper comment sections etc.) have to detect and filter offensive speech within large, fast-changing datasets. While many automatic methods have been proposed and achieve good accuracies, most of these focus on the English language, and are hard to apply directly to languages in which few labeled datasets exist. Recent work has therefore investigated the use of cross-lingual transfer learning to solve this problem, training a model in a well-resourced language and transferring to a less-resourced target language; but performance has so far been significantly less impressive. In this paper, we investigate the reasons for this performance drop, via a systematic comparison of pre-trained models and intermediate training regimes on five different languages. We show that using a better pre-trained language model results in a large gain in overall performance and in zero-shot transfer, and that intermediate training on other languages is effective when little target-language data is available. We then use multiple analyses of classifier confidence and language model vocabulary to shed light on exactly where these gains come from and gain insight into the sources of the most typical mistakes. © 2021 Pelicon et al. All Rights Reserved.},
	author_keywords = {Cross-lingual models; Deep learning; Intermediate training; Offensive language detection; Transfer learning},
	keywords = {Computational linguistics; Large dataset; Social networking (online); Automatic method; English languages; Labeled datasets; Language model; Offensive languages; Online forums; Target language; User-generated content; Transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Khan202140,
	author = {Khan, Muhammad U. S. and Abbas, Assad and Rehman, Attiqa and Nawaz, Raheel},
	title = {HateClassify: A Service Framework for Hate Speech Identification on Social Media},
	year = {2021},
	journal = {IEEE Internet Computing},
	volume = {25},
	number = {1},
	pages = {40 – 49},
	doi = {10.1109/MIC.2020.3037034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097935638&doi=10.1109%2fMIC.2020.3037034&partnerID=40&md5=36f25be687570fdbd362ad310a88e72d},
	affiliations = {Comsats University Islamabad, Abbottabad, Pakistan; Manchester Metropolitan University, Manchester, United Kingdom},
	abstract = {It is indeed a challenge for the existing machine learning approaches to segregate the hateful content from the one that is merely offensive. One prevalent reason for low accuracy of hate detection with the current methodologies is that these techniques treat hate classification as a multiclass problem. In this article, we present the hate identification on the social media as a multilabel problem. To this end, we propose a CNN-based service framework called HateClassify for labeling the social media contents as the hate speech, offensive, or nonoffensive. Results demonstrate that the multiclass classification accuracy for the CNN-based approaches particularly sequential CNN (SCNN) is competitive and even higher than certain state-of-The-Art classifiers. Moreover, in the multilabel classification problem, sufficiently high performance is exhibited by the SCNN among other CNN-based techniques. The results have shown that using multilabel classification instead of multiclass classification, hate speech detection is increased up to 20%.  © 1997-2012 IEEE.},
	keywords = {Classifiers; Learning systems; Social networking (online); Machine learning approaches; Multi label classification; Multi-class classification; Multi-class problems; Multi-label problems; Service framework; Speech detection; State of the art; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; All Open Access, Green Open Access}
}

@ARTICLE{Putri202188,
	author = {Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},
	title = {Abusive Language and Hate Speech Detection for Indonesian-Local Language in Social Media Text},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {251},
	pages = {88 – 98},
	doi = {10.1007/978-3-030-79757-7_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111468836&doi=10.1007%2f978-3-030-79757-7_9&partnerID=40&md5=0138e5fcccfd676fdf435d049b3b0a38},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia},
	abstract = {In social media, people are free to express their feelings and thoughts. However, people can also use abusive language and hate speech to insult or humiliate individuals or groups on social media, such as Twitter. Various detection methods have been developed to control the spread of abusive language and hate speech in Indonesia, but the detection process is still focused on monolingual. As a country with various ethnicities and cultures, Indonesia also has a variety of local languages. This study examines abusive language and hate speech detection on Twitter, which also contains five local languages, including Javanese, Sundanese, Madurese, Minangkabau, and Musi. In this work, we present a preliminary evaluation to find the best performance of machine learning methods in detecting abusive language and hate speech on Twitter as preliminary study for each local language. We use several machine learning algorithms, such as Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) as classifiers and TF-IDF weighted word n-gram and character-n gram as feature extraction. The experiments use the 5-Fold cross-validation approach and evaluated by measuring the F-1-Score. After the experiment, we have obtained the SVM classifier with word n-gram features show the best F-1-Score for each dataset. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Abusive; Hate speech; Indonesian local languages; Machine learning; Twitter},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 17th International Conference on Computing and Information Technology, IC2IT 2021; Conference date: 13 May 2021 through 14 May 2021; Conference code: 261599}
}

@CONFERENCE{Hettiarachchi2020250,
	author = {Hettiarachchi, Nimali and Weerasinghe, Ruvan and Pushpanda, Randil},
	title = {Detecting hate speech in social media articles in romanized sinhala},
	year = {2020},
	journal = {20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020 - Proceedings},
	pages = {250 – 255},
	doi = {10.1109/ICTer51097.2020.9325465},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100450737&doi=10.1109%2fICTer51097.2020.9325465&partnerID=40&md5=31b5f443380336167e5ae5d78955b1f3},
	affiliations = {University of Colombo, School of Computing, Colombo, 00700, Sri Lanka},
	abstract = {The main aim of this research is to automatically identify the hate content of social media comments and documents written by the Romanized Sinhala Language. Also most of researched done the hate speech recognition study in English or their language but here identify the Sinhala words that's written in English letters that means Romanized Sinhala language. Hate words and other hated texts are growing issue, and to combat this they turn to machine learning and computer science. In this research compare the several features extraction method and four machine learning algorithms and difference N-gram values unigram, bigram and trigram and used the Min-Df value 3. This study will investigate and compare different features for the different classifier when classifying hate speech comments on Facebook. We have achieved a data set of nearly 2500 comments, some containing hate speech, and trained and tested our classifier with different features. © 2020 IEEE.},
	author_keywords = {And Random Forest Classifier; Bagof-words; BeautifulSoup; DataGram; False Negatives; False Positives; Linear SVM; Logistic Regression; MinDF; Multinomial Naive Bayes Classifier; Ngram; True Negatives; True Positives},
	keywords = {Learning algorithms; Machine learning; Social networking (online); Taxonomies; Data set; Facebook; Features extraction; N-grams; Social media; Tri grams; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 166665}
}

@CONFERENCE{Gomez20201459,
	author = {Gomez, Raul and Gibert, Jaume and Gomez, Lluis and Karatzas, Dimosthenis},
	title = {Exploring hate speech detection in multimodal publications},
	year = {2020},
	journal = {Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020},
	pages = {1459 – 1467},
	doi = {10.1109/WACV45572.2020.9093414},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085477979&doi=10.1109%2fWACV45572.2020.9093414&partnerID=40&md5=dcddaa004d3b3424c6db0467ca7224cb},
	affiliations = {Unitat de Tecnologies Audiovisuals, Eurecat, Centre Tecnològic de Catalunya, Barcelona, Spain; Universitat Autònoma de Barcelona, Computer Vision Center, Barcelona, Spain},
	abstract = {In this work we target the problem of hate speech detection in multimodal publications formed by a text and an image. We gather and annotate a large scale dataset from Twitter, MMHS150K, and propose different models that jointly analyze textual and visual information for hate speech detection, comparing them with unimodal detection. We provide quantitative and qualitative results and analyze the challenges of the proposed task. We find that, even though images are useful for the hate speech detection task, current multimodal models cannot outperform models analyzing only text. We discuss why and open the field and the dataset for further research. © 2020 IEEE.},
	keywords = {Computer vision; Large dataset; Modal analysis; Large-scale dataset; Multi-modal; Multimodal models; Speech detection; Unimodal; Visual information; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 163; Conference name: 2020 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2020; Conference date: 1 March 2020 through 5 March 2020; Conference code: 159803; All Open Access, Green Open Access}
}

@ARTICLE{Vashistha20211,
	author = {Vashistha, Neeraj and Zubiaga, Arkaitz},
	title = {Online multilingual hate speech detection: Experimenting with hindi and english social media},
	year = {2021},
	journal = {Information (Switzerland)},
	volume = {12},
	number = {1},
	pages = {1 – 16},
	doi = {10.3390/info12010005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098792520&doi=10.3390%2finfo12010005&partnerID=40&md5=0d8f6dc49f9a7e2d8299307ab128b873},
	affiliations = {School of Electronic Engineering and Computer Science, Queen Mary University of London, London, E1 4NS, United Kingdom},
	abstract = {The last two decades have seen an exponential increase in the use of the Internet and social media, which has changed basic human interaction. This has led to many positive outcomes. At the same time, it has brought risks and harms. The volume of harmful content online, such as hate speech, is not manageable by humans. The interest in the academic community to investigate automated means for hate speech detection has increased. In this study, we analyse six publicly available datasets by combining them into a single homogeneous dataset. Having classified them into three classes, abusive, hateful or neither, we create a baseline model and improve model performance scores using various optimisation techniques. After attaining a competitive performance score, we create a tool that identifies and scores a page with an effective metric in near-real-time and uses the same feedback to re-train our model. We prove the competitive performance of our multilingual model in two languages, English and Hindi. This leads to comparable or superior performance to most monolingual models. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Hate speech; Social media; Text classification},
	keywords = {Social networking (online); Academic community; Baseline models; Competitive performance; Exponential increase; Human interactions; Model performance; Optimisation techniques; Speech detection; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 54; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Akhtar2020151,
	author = {Akhtar, Sohail and Basile, Valerio and Patti, Viviana},
	title = {Modeling Annotator Perspective and Polarized Opinions to Improve Hate Speech Detection},
	year = {2020},
	journal = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
	volume = {8},
	pages = {151 – 154},
	doi = {10.1609/hcomp.v8i1.7473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175716859&doi=10.1609%2fhcomp.v8i1.7473&partnerID=40&md5=eee3c080b5895ec2be6a7182fb75e9d3},
	affiliations = {Computer Science Department, University of Turin, Italy},
	abstract = {In this paper we propose an approach to exploit the finegrained knowledge expressed by individual human annotators during a hate speech (HS) detection task, before the aggregation of single judgments in a gold standard dataset eliminates non-majority perspectives. We automatically divide the annotators into groups, aiming at grouping them by similar personal characteristics (ethnicity, social background, culture etc.). To serve a multi-lingual perspective, we performed classification experiments on three different Twitter datasets in English and Italian languages. We created different gold standards, one for each group, and trained a state-of-the-art deep learning model on them, showing that supervised models informed by different perspectives on the target phenomena outperform a baseline represented by models trained on fully aggregated data. Finally, we implemented an ensemble approach that combines the single perspective-aware classifiers into an inclusive model. The results show that this strategy further improves the classification performance, especially with a significant boost in the recall of HS prediction. © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Deep learning; Speech recognition; Aggregated datum; Classification performance; Detection tasks; Ensemble approaches; Gold standards; Learning models; Personal characteristics; Speech detection; State of the art; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; Conference name: 8th AAAI Conference on Human Computation and Crowdsourcing, HCOMP 2020; Conference date: 25 October 2020 through 29 October 2020; Conference code: 302689; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Faris2020453,
	author = {Faris, Hossam and Aljarah, Ibrahim and Habib, Maria and Castillo, Pedro A.},
	title = {Hate Speech Detection using Word Embedding and Deep Learning in the Arabic Language Context},
	year = {2020},
	journal = {International Conference on Pattern Recognition Applications and Methods},
	volume = {1},
	pages = {453 – 460},
	doi = {10.5220/0008954004530460},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126200463&doi=10.5220%2f0008954004530460&partnerID=40&md5=10c8807f89cb9a41df2999b75e6fd2b1},
	affiliations = {Department of Information Technology, King Abdullah II School for Information Technology, The University of Jordan, Amman, Jordan; Department of Computer Architecture and Technology, ETSIIT - CITIC, University of Granada, Spain},
	abstract = {Hate speech over online social networks is a worldwide problem that leads for diminishing the cohesion of civil societies. The rapid spread of social media websites is accompanied with an increasing number of social media users which showed a higher rate of hate speech, as well. The objective of this paper is to propose a smart deep learning approach for the automatic detection of cyber hate speech. Particularly, the detection of hate speech on Twitter on the Arabic region. Hence, a dataset is collected from Twitter that captures the hate expressions in different topics at the Arabic region. A set of features extracted from the dataset based on a word embedding mechanism. The word embeddings fed into a deep learning framework. The implemented deep learning approach is a hybrid of convolutional neural network (CNN) and long short-term memory (LSTM) network. The proposed approach achieved good results in classifying tweets as Hate or Normal regardingaccuracy, precision, recall, and F1 measure. © 2022 by SCITEPRESS Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Classification; Hate Speech; Machine Learning; Word Embedding},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 9th International Conference on Pattern Recognition Applications and Methods , ICPRAM 2020; Conference date: 22 February 2020 through 24 February 2020; Conference code: 301379}
}

@CONFERENCE{Röttger202141,
	author = {Röttger, Paul and Vidgen, Bertram and Nguyen, Dong and Waseem, Zeerak and Margetts, Helen and Pierrehumbert, Janet B.},
	title = {HATECHECK: Functional tests for hate speech detection models},
	year = {2021},
	journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
	pages = {41 – 58},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113860574&partnerID=40&md5=0402357b62679b6431cb22010bf1e138},
	affiliations = {University of Oxford, United Kingdom; The Alan Turing Institute; Utrecht University, Netherlands; University of Sheffield, United Kingdom},
	abstract = {Detecting online hate is a difficult task that even state-of-the-art models struggle with. Typically, hate speech detection models are evaluated by measuring their performance on held-out test data using metrics such as accuracy and F1 score. However, this approach makes it difficult to identify specific model weak points. It also risks overestimating generalisable model performance due to increasingly well-evidenced systematic gaps and biases in hate speech datasets. To enable more targeted diagnostic insights, we introduce HATECHECK, a suite of functional tests for hate speech detection models. We specify 29 model functionalities motivated by a review of previous research and a series of interviews with civil society stakeholders. We craft test cases for each functionality and validate their quality through a structured annotation process. To illustrate HATECHECK's utility, we test near-state-of-the-art transformer models as well as two popular commercial models, revealing critical model weaknesses. © 2021 Association for Computational Linguistics},
	keywords = {Computational linguistics; Electric transformer testing; Natural language processing systems; ART model; Detection models; F1 scores; Functional test; Modeling performance; Performance; Speech detection; State of the art; Test data; Weak points; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 125; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030}
}

@CONFERENCE{Glavaš20206350,
	author = {Glavaš, Goran and Karan, Mladen and Vulić, Ivan},
	title = {XHATE-999: Analyzing and Detecting Abusive Language Across Domains and Languages},
	year = {2020},
	journal = {COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference},
	pages = {6350 – 6365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134316016&partnerID=40&md5=f39facda818d37115b5190eb0982c670},
	affiliations = {Data and Web Science Group, University of Mannheim, Germany; Text Analysis and Knowledge Engineering Lab., University of Zagreb, Croatia; Language Technology Lab., TAL, University of Cambridge, United Kingdom},
	abstract = {We present XHATE-999, a multi-domain and multilingual evaluation data set for abusive language detection. By aligning test instances across six typologically diverse languages, XHATE-999 for the first time allows for disentanglement of the domain transfer and language transfer effects in abusive language detection. We conduct a series of domain- and language-transfer experiments with state-of-the-art monolingual and multilingual transformer models, setting strong baseline results and profiling XHATE-999 as a comprehensive evaluation resource for abusive language detection. Finally, we show that domain- and language-adaptation, via intermediate masked language modeling on abusive corpora in the target language, can lead to substantially improved abusive language detection in the target language in the zero-shot transfer setups. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.},
	keywords = {Chemical detection; Computational linguistics; Zero-shot learning; Baseline results; Data set; Domain language; Domain transfers; Language detection; Multi-domains; State of the art; Target language; Test instances; Transformer modeling; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886}
}

@CONFERENCE{Cao202011,
	author = {Cao, Rui and Lee, Roy Ka-Wei and Hoang, Tuan-Anh},
	title = {DeepHate: Hate Speech Detection via Multi-Faceted Text Representations},
	year = {2020},
	journal = {WebSci 2020 - Proceedings of the 12th ACM Conference on Web Science},
	pages = {11 – 20},
	doi = {10.1145/3394231.3397890},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088402502&doi=10.1145%2f3394231.3397890&partnerID=40&md5=25aca1880e4358e9112f65b02265b975},
	affiliations = {University of Electronic Science and Technology of China, China; University of Saskatchewan, Canada; Leibniz University of Hanover, Germany},
	abstract = {Online hate speech is an important issue that breaks the cohesiveness of online social communities and even raises public safety concerns in our societies. Motivated by this rising issue, researchers have developed many traditional machine learning and deep learning methods to detect hate speech in online social platforms automatically. However, most of these methods have only considered single type textual feature, e.g., term frequency, or using word embeddings. Such approaches neglect the other rich textual information that could be utilized to improve hate speech detection. In this paper, we propose DeepHate, a novel deep learning model that combines multi-faceted text representations such as word embeddings, sentiments, and topical information, to detect hate speech in online social platforms. We conduct extensive experiments and evaluate DeepHate on three large publicly available real-world datasets. Our experiment results show that DeepHate outperforms the state-of-the-art baselines on the hate speech detection task. We also perform case studies to provide insights into the salient features that best aid in detecting hate speech in online social platforms. © 2020 ACM.},
	author_keywords = {Hate Speech Detection; Online Toxic Content; Social Media},
	keywords = {Deep learning; Embeddings; Large dataset; Learning systems; Social networking (online); Speech; Learning methods; Online social communities; Real-world datasets; Speech detection; State of the art; Text representation; Textual features; Textual information; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 72; Conference name: 12th ACM Conference on Web Science, WebSci 2020; Conference date: 6 July 2020 through 10 July 2020; Conference code: 161377; All Open Access, Green Open Access}
}

@CONFERENCE{Kaur2021274,
	author = {Kaur, Simrat and Singh, Sarbjeet and Kaushal, Sakshi},
	title = {Abusive Content Detection in Online User-Generated Data: A survey},
	year = {2021},
	journal = {Procedia CIRP},
	volume = {189},
	pages = {274 – 281},
	doi = {10.1016/j.procs.2021.05.098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112803412&doi=10.1016%2fj.procs.2021.05.098&partnerID=40&md5=c775752eab5c75ee8e2bcb5b6d8ca375},
	affiliations = {University Institute of Engineering and Technology, Panjab University, Chandigarh, 160014, India},
	abstract = {The proliferation of social media platforms resulted in a remarkable increase in user-generated content. These platforms have empowered users to create, share and exchange content for interacting and communicating with each other. However, these have also opened new avenues to cyber-bullies and haters who can spread their negativity to a larger audience, often anonymously. Due to the pervasiveness and severity of this behavior, many automated approaches that employ natural language processing (NLP), machine learning and deep learning techniques have been proposed in the past. This survey offers an extensive overview of the state-of-the-art approaches proposed by research community to identify offensive content. Based on our comprehensive literature survey, a categorization of different approaches and features employed by the researchers in the detection process are presented. This survey also incorporates the major challenges that require considerable research efforts in this domain. Finally, future research directions with an aim of developing robust abusive content detection system for social media are also discussed. © 2021 Elsevier B.V.. All rights reserved.},
	author_keywords = {Abusive Content; Cyberbullying; Deep Learning; Machine Learning; Natural Language Processing; Social Media},
	keywords = {Deep learning; Learning algorithms; Natural language processing systems; Social networking (online); Abusive content; Content detection; Cyber bullying; Deep learning; Language processing; Machine-learning; Natural languages; Online users; Social media; User-generated; Surveys},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; Conference name: 5th International Conference on Artificial Intelligence in Computational Linguistics, ACLing 2021; Conference date: 4 June 2021 through 5 June 2021; Conference code: 170461; All Open Access, Gold Open Access}
}

@ARTICLE{Das2021578,
	author = {Das, Amit Kumar and Al Asif, Abdullah and Paul, Anik and Hossain, Md. Nur},
	title = {Bangla hate speech detection on social media using attention-based recurrent neural network},
	year = {2021},
	journal = {Journal of Intelligent Systems},
	volume = {30},
	number = {1},
	pages = {578 – 591},
	doi = {10.1515/jisys-2020-0060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106529744&doi=10.1515%2fjisys-2020-0060&partnerID=40&md5=1d4fc517c566b35ff2516680f803aff6},
	affiliations = {Computer Science and Engineering (CSE), East West University, Dhaka, Dhaka, Bangladesh},
	abstract = {Hate speech has spread more rapidly through the daily use of technology and, most notably, by sharing your opinions or feelings on social media in a negative aspect. Although numerous works have been carried out in detecting hate speeches in English, German, and other languages, very few works have been carried out in the context of the Bengali language. In contrast, millions of people communicate on social media in Bengali. The few existing works that have been carried out need improvements in both accuracy and interpretability. This article proposed encoder-decoder-based machine learning model, a popular tool in NLP, to classify user's Bengali comments from Facebook pages. A dataset of 7,425 Bengali comments, consisting of seven distinct categories of hate speeches, was used to train and evaluate our model. For extracting and encoding local features from the comments, 1D convolutional layers were used. Finally, the attention mechanism, LSTM, and GRU-based decoders have been used for predicting hate speech categories. Among the three encoder-decoder algorithms, attention-based decoder obtained the best accuracy (77%). © 2021 Amit Kumar Das et al., published by De Gruyter 2021.},
	author_keywords = {attention mechanism; Bangla hate speech detection; Bangla text classification; GRU; LSTM; RNN},
	keywords = {Contrast media; Decoding; Signal encoding; Social networking (online); Attention mechanisms; Bengali language; Encoder-decoder; Facebook pages; Interpretability; Local feature; Machine learning models; Speech detection; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 73; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ali202184296,
	author = {Ali, Muhammad Z. and Ehsan-Ul-Haq and Rauf, Sahar and Javed, Kashif and Hussain, Sarmad},
	title = {Improving Hate Speech Detection of Urdu Tweets Using Sentiment Analysis},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {84296 – 84305},
	doi = {10.1109/ACCESS.2021.3087827},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109128364&doi=10.1109%2fACCESS.2021.3087827&partnerID=40&md5=6c5090b5f1d6420ec15c4bef4e110a93},
	affiliations = {Center for Language Engineering, Al-Khawarizmi Institute of Computer Science, University of Engineering and Technology, Lahore, Pakistan},
	abstract = {Sentiment Analysis is a technique that is being used abundantly nowadays for customer reviews analysis, popularity analysis of electoral candidates, hate speech detection and similar applications. Sentiment analysis on tweets encounters challenges such as highly skewed classes, high dimensional feature vectors and highly sparse data. In this study, we have analyzed the improvement achieved by successively addressing these problems in order to determine their severity for sentiment analysis of tweets. Firstly, we prepared a comprehensive data set consisting of Urdu Tweets for sentiment analysis-based hate speech detection. To improve the performance of the sentiment classifier, we employed dynamic stop words filtering, Variable Global Feature Selection Scheme (VGFSS) and Synthetic Minority Optimization Technique (SMOTE) to handle the sparsity, dimensionality and class imbalance problems respectively. We used two machine learning algorithms i.e., Support Vector Machines (SVM) and Multinomial Naïve Bayes' (MNB) for investigating performance in our experiments. Our results show that addressing class skew along with alleviating the high dimensionality problem brings about the maximum improvement in the overall performance of the sentiment analysis-based hate speech detection. © 2013 IEEE.},
	author_keywords = {data sparsity; hate speech; high-dimensional feature vector; highly skewed classes; Sentiment analysis},
	keywords = {Learning algorithms; Sentiment analysis; Support vector machines; Class imbalance problems; Customer review; High dimensional feature; High dimensionality; Multinomials; Optimization techniques; Speech detection; Two machines; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Gold Open Access}
}

@ARTICLE{Saeed202171,
	author = {Saeed, Faisal and Al-Sarem, Mohammed and Alromema, Waseem},
	title = {Tuning Hyper-Parameters of Machine Learning Methods for Improving the Detection of Hate Speech},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1188},
	pages = {71 – 78},
	doi = {10.1007/978-981-15-6048-4_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096597539&doi=10.1007%2f978-981-15-6048-4_7&partnerID=40&md5=d7be8d5dbca7f136ad9670e18ad5459a},
	affiliations = {College of Computer Science and Engineering, Taibah University, Medina, Saudi Arabia; Computer Science and Information Department, Khayper Community College, Taibah University, Medina, Saudi Arabia},
	abstract = {Social media platforms have a main role in hate crimes worldwide. Detecting hate speech from social media is a big challenge. Many studies utilized machine learning methods for classifying the text as hate speech. However, the performance of machine learning method differs when using different parameters settings. Selecting the best values of parameters for machine learning method yields directly in the performance of the method. It is very time consuming for methods to find the best values manually. In this paper, grid search and random search hyper-parameters (HP) tuning methods were used with several machine learning methods in order to enhance the performance of detecting hate speech. The experimental results showed great improvements when HP methods were applied. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Hate speech; Hyper-parameters; Machine learning; Parameters tuning},
	keywords = {Machine learning; Social networking (online); Soft computing; Grid search; Hyper-parameter; Machine learning methods; Parameters setting; Random searches; Social media; Social media platforms; Tuning method; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 1st International Conference of Advanced Computing and Informatics, ICACIN 2020; Conference date: 13 April 2020 through 14 April 2020; Conference code: 250539}
}

@ARTICLE{Ahammad2021855,
	author = {Ahammad, Tanvir and Uddin, Md. Khabir and Yesmin, Tamanna and Karim, Abdul and Halder, Sajal and Hasan, Md. Mahmudul},
	title = {Identification of Abusive Behavior Towards Religious Beliefs and Practices on Social Media Platforms},
	year = {2021},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {12},
	number = {6},
	pages = {855 – 866},
	doi = {10.14569/IJACSA.2021.0120699},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109137513&doi=10.14569%2fIJACSA.2021.0120699&partnerID=40&md5=41882bf95181585f17a672aab61af269},
	affiliations = {Department of Computer Science and Engineering, Jagannath University, Bangladesh; Department of Computer Science and Engineering, Uttara University, Bangladesh; Department of Computer Science, RMIT University, Melbourne, Australia; Department of Computer Science and Engineering, Dhaka International University, Bangladesh},
	abstract = {The ubiquitous use of social media has enabled many people, including religious scholars and priests, to share their religious views. Unfortunately, exploiting people’s religious beliefs and practices, some extremist groups intentionally or unintentionally spread religious hatred among different communities and thus hamper social stability. This paper aims to propose an abusive behavior detection approach to identify hatred, violence, harassment, and extremist expressions against people of any religious belief on social media. For this, first religious posts from social media users’ activities are captured and then the abusive behaviors are identified through a number of sequential processing steps. In the experiment, Twitter has been chosen as an example of social media for collecting dataset of six major religions in English Twittersphere. In order to show the performance of the proposed approach, five classic classifiers on n-gram TF-IDF model have been used. Besides, Long Short-term Memory (LSTM) and Gated Recurrent Unit (GRU) classifiers on trained embedding and pre-trained GloVe word embedding models have been used. The experimental result showed 85% accuracy in terms of precision. However, to the best of our knowledge, this is the first work that will be able to distinguish between hateful and non-hateful contents in other application domains on social media in addition to religious context. © 2021. All Rights Reserved.},
	author_keywords = {classifier; feature extraction; religious abuse detection; religious hatred; religious keywords; Social media},
	keywords = {Embeddings; Long short-term memory; Social networking (online); Behavior detection; Detection approach; Embeddings; Features extraction; Religious abuse detection; Religious hatred; Religious keyword; Social media; Social media platforms; Social stability; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Arango20202475,
	author = {Arango, Aymé},
	title = {Language Agnostic Hate Speech Detection},
	year = {2020},
	journal = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {2475},
	doi = {10.1145/3397271.3401447},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090134875&doi=10.1145%2f3397271.3401447&partnerID=40&md5=9e02626a40e4ec0fd9a6c473957bd5b2},
	affiliations = {Universidad de Chile, Santiago de Chile, Chile},
	abstract = {The growth in social Web platforms in the past years has brought an increase in displays of online hate speech. This subject is considered as a critical matter in the Web community, since it can be related to potentially dangerous actions that affect individuals and groups in the physical world. The automatic detection of this type of expressions has been the center of several investigations over the past few years. However, most research on this subject has been done for the English language and on rather limited datasets. In addition, although some works approach the problem from a multilingual perspective, analyzing different language separately, across-lingual perspective of this problem has not been used so far. The main research proposal of this thesis is to characterize hate speech and other forms of online harassment from different perspectives and use this characterizations to create novel models for online hate speech detection across different languages and domains. © 2020 Owner/Author.},
	author_keywords = {experimental evaluation; hate speech classification; machine learning; social media},
	keywords = {Information retrieval; Automatic Detection; English languages; Physical world; Research proposals; Social webs; Speech detection; Web community; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 43rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2020; Conference date: 25 July 2020 through 30 July 2020; Conference code: 161956}
}

@CONFERENCE{D'Sa2020,
	author = {D'Sa, Ashwin Geet and Illina, Irina and Fohr, Dominique},
	title = {BERT and fastText Embeddings for Automatic Detection of Toxic Speech},
	year = {2020},
	journal = {Proceedings of 2020 International Multi-Conference on: Organization of Knowledge and Advanced Technologies, OCTA 2020},
	doi = {10.1109/OCTA49274.2020.9151853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091178128&doi=10.1109%2fOCTA49274.2020.9151853&partnerID=40&md5=d1720178812470b13ee9e8838bd2d3a8},
	affiliations = {Université de Lorraine, CNRS, Inria, LORIA, Nancy, F-54000, France},
	abstract = {With the expansion of Internet usage, catering to the dissemination of thoughts and expressions of an individual, there has been an immense increase in the spread of online hate speech. Social media, community forums, discussion platforms are few examples of common playground of online discussions where people are freely allowed to communicate. However, the freedom of speech may be misused by some people by arguing aggressively, offending others and spreading verbal violence. As there is no clear distinction between the terms offensive, abusive, hate and toxic speech, in this paper we consider the above mentioned terms as toxic speech. In many countries, online toxic speech is punishable by the law. Thus, it is important to automatically detect and remove toxic speech from online medias. Through this work, we propose automatic classification of toxic speech using embedding representations of words and deep-learning techniques. We perform binary and multi-class classification using a Twitter corpus and study two approaches: (a) a method which consists in extracting of word embeddings and then using a DNN classifier; (b) fine-tuning the pre-trained BERT model. We observed that BERT fine-tuning performed much better. Proposed methodology can be used for any other type of social media comments.  © 2020 IEEE.},
	author_keywords = {Classification; Deep neural network; Hate speech; Natural language processing},
	keywords = {Deep learning; Embeddings; Knowledge management; Learning systems; Social networking (online); Speech; Automatic classification; Automatic Detection; Freedom of speech; Internet usage; Learning techniques; Multi-class classification; Online discussions; Online media; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 61; Conference name: 2020 International Multi-Conference on: Organization of Knowledge and Advanced Technologies�, OCTA 2020; Conference date: 6 February 2020 through 8 February 2020; Conference code: 162064; All Open Access, Green Open Access}
}

@CONFERENCE{Kokatnoor202087,
	author = {Kokatnoor, Sujatha Arun and Krishnan, Balachandran},
	title = {Twitter Hate Speech Detection using Stacked Weighted Ensemble (SWE) Model},
	year = {2020},
	journal = {Proceedings - 2020 5th International Conference on Research in Computational Intelligence and Communication Networks, ICRCICN 2020},
	pages = {87 – 92},
	doi = {10.1109/ICRCICN50933.2020.9296199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099174302&doi=10.1109%2fICRCICN50933.2020.9296199&partnerID=40&md5=b15f7285ec5202571b2d033e37fd1ef1},
	affiliations = {CHRIST (Deemed to Be University), Department of Computer Science and Engineering, Bangalore, India},
	abstract = {Online Social Media has expanded the freedom of expression in the internet, which has become a disturbing problem if it has an impact on the situation or the interest of a country. Hate speech refers to the use of hostile, abusive or offensive language, directed at a certain group of people who share common property, whether it is their gender, ethnicity or race (i.e. racism), faith and religion. Therefore, auto detection of hate speeches has an increased importance in Online Social Media for filtering any message that has hatred language before posting it to the network. In this paper, a Stacked Weighted Ensemble (SWE) model is proposed for the detection of hate speeches. The model ensembles five standalone classifiers: Linear Regression, Naïve Bayes', Random Forest, Hard Voting and Soft Voting. The experimental results on a Twitter® dataset has shown an accuracy of 95.54% in binary classification of tweets into hateful speech and an improved performance is noted compared to the standalone classifiers. © 2020 IEEE.},
	author_keywords = {Anomaly Detection; Ensemble Classification; Hard Voting and Soft Voting; Hate Speech; Linear Regression Model; Naïve Bayes; Random Forest; Social Networking Services; Tweet Classification; Tweet Filtering},
	keywords = {Classification (of information); Decision trees; Intelligent computing; Auto-detection; Binary classification; Common property; Model ensembles; Offensive languages; Online social medias; Soft voting; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 5th International Conference on Research in Computational Intelligence and Communication Networks, ICRCICN 2020; Conference date: 26 November 2020 through 27 November 2020; Conference code: 166056}
}

@ARTICLE{Yin20211,
	author = {Yin, Wenjie and Zubiaga, Arkaitz},
	title = {Towards generalisable hate speech detection: a review on obstacles and solutions},
	year = {2021},
	journal = {PeerJ Computer Science},
	volume = {7},
	pages = {1 – 38},
	doi = {10.7717/PEERJ-CS.598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109430200&doi=10.7717%2fPEERJ-CS.598&partnerID=40&md5=6ea46b4788be9d6fda9d6d992cca2860},
	affiliations = {School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom},
	abstract = {Hate speech is one type of harmful online content which directly attacks or promotes hate towards a group or an individual member based on their actual or perceived aspects of identity, such as ethnicity, religion, and sexual orientation. With online hate speech on the rise, its automatic detection as a natural language processing task is gaining increasing interest. However, it is only recently that it has been shown that existing models generalise poorly to unseen data. This survey paper attempts to summarise how generalisable existing hate speech detection models are and the reasons why hate speech models struggle to generalise, sums up existing attempts at addressing the main obstacles, and then proposes directions of future research to improve generalisation in hate speech detection. © 2021. Yin and Zubiaga.},
	author_keywords = {Abusive language; Artificial Intelligence; Computational Linguistics; Data Mining and Machine Learning; Generalisation; Hate speech; Literature review; Natural Language and Speech; Social Computing; Social media; Text classification},
	keywords = {Natural language processing systems; Speech; Automatic Detection; Generalisation; NAtural language processing; On-line contents; Sexual orientations; Speech detection; Speech models; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 127; All Open Access, Gold Open Access, Green Open Access}
}@CONFERENCE{Gao20201936,
	author = {Gao, Zhiwei and Yada, Shuntaro and Wakamiya, Shoko and Aramaki, Eiji},
	title = {Offensive Language Detection on Video Live Streaming Chat},
	year = {2020},
	journal = {COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference},
	pages = {1936 – 1940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104364642&partnerID=40&md5=04e4291e14280cda0460a288830968bf},
	affiliations = {Nara Institute of Science and Technology, Japan},
	abstract = {This paper presents a prototype of a chat room that detects offensive expressions in a video live streaming chat in real time. Focusing on Twitch, one of the most popular live streaming platforms, we created a dataset for the task of detecting offensive expressions. We collected 2,000 chat posts across four popular game titles with genre diversity (e.g., competitive, violent, peaceful). To make use of the similarity in offensive expressions among different social media platforms, we adopted state-of-the-art models trained on offensive expressions from Twitter for our Twitch data (i.e., transfer learning). We investigated two similarity measurements to predict the transferability, textual similarity, and game-genre similarity. Our results show that the transfer of features from social media to live streaming is effective. However, the two measurements show less correlation in the transferability prediction. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.},
	keywords = {Computational linguistics; Social networking (online); ART model; Chat rooms; Language detection; Live streaming; Offensive languages; Real- time; Social media platforms; State of the art; Transfer learning; Video live streaming; Video streaming},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886}
}

@CONFERENCE{Rizwan20202512,
	author = {Rizwan, Hammad and Shakeel, Muhammad Haroon and Karim, Asim},
	title = {Hate-speech and offensive language detection in Roman Urdu},
	year = {2020},
	journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {2512 – 2522},
	doi = {10.18653/v1/2020.emnlp-main.197},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097830883&doi=10.18653%2fv1%2f2020.emnlp-main.197&partnerID=40&md5=082f93d13f1bf1d51387cc6a5ae667c6},
	affiliations = {Department of Computer Science, Lahore University of Management Sciences (LUMS), Lahore, Pakistan},
	abstract = {The task of automatic hate-speech and offensive language detection in social media content is of utmost importance due to its implications in unprejudiced society concerning race, gender, or religion. Existing research in this area, however, is mainly focused on the English language, limiting the applicability to particular demographics. Despite its prevalence, Roman Urdu (RU) lacks language resources, annotated datasets, and language models for this task. In this study, we: (1) Present a lexicon of hateful words in RU, (2) Develop an annotated dataset called RUHSOLD consisting of 10, 012 tweets in RU with both coarse-grained and fine-grained labels of hate-speech and offensive language, (3) Explore the feasibility of transfer learning of five existing embedding models to RU, (4) Propose a novel deep learning architecture called CNN-gram for hate-speech and offensive language detection and compare its performance with seven current baseline approaches on RUHSOLD dataset, and (5) Train domain-specific embeddings on more than 4.7 million tweets and make them publicly available. We conclude that transfer learning is more beneficial as compared to training embedding from scratch and that the proposed model exhibits greater robustness as compared to the baselines. © 2020 Association for Computational Linguistics},
	keywords = {Computational linguistics; Deep learning; Speech recognition; Transfer learning; Annotated datasets; Embeddings; English languages; Language detection; Language model; Language resources; Media content; Offensive languages; Social media; Transfer learning; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 58; Conference name: 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172724; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Dowlagar2020180,
	author = {Dowlagar, Suman and Mamidi, Radhika},
	title = {HASOCOne@FIRE-HASOC2020: Using BERT and multilingual BERT models for hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {180 – 187},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102929817&partnerID=40&md5=34aa8aaf5cbe158dc6b4a3c33f2be096},
	affiliations = {International Institute of Information Technology - Hyderabad (IIIT-Hyderabad), Gachibowli, Hyderabad, Telangana, 500032, India},
	abstract = {Hateful and Toxic content has become a significant concern in today’s world due to an exponential rise in social media. The increase in hate speech and harmful content motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. In this task, we propose an approach to automatically classify hate speech and offensive content. We have used the datasets obtained from FIRE 2019 and 2020 shared tasks. We perform experiments by taking advantage of transfer learning models. We observed that the pre-trained BERT model and the multilingual-BERT model gave the best results. The code is made publically available at https://github.com/suman101112/hasoc-fire-2020 © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; Hate speech; Label classification; Offensive content; Transfer learning},
	keywords = {Fires; Information retrieval; Transfer learning; Content identifications; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Jahan20201628,
	author = {Jahan, Md Saroar and Oussalah, Mourad},
	title = {Team Oulu at SemEval-2020 Task 12: Multilingual Identification of Offensive Language, Type and Target of Twitter Post Using Translated Datasets},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1628 – 1637},
	doi = {10.18653/v1/2020.semeval-1.212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123922951&doi=10.18653%2fv1%2f2020.semeval-1.212&partnerID=40&md5=961cd22a121cec44dd30e5e176d26da1},
	affiliations = {University of Oulu, Faculty of Information Tech., CMVS, PO Box 4500, Oulu, 90014, Finland},
	abstract = {With the proliferation of social media platforms, anonymous discussions together with easy online access, reports on offensive content have caused serious concern to both authorities and research communities. Although there is extensive research in identifying textual offensive language from online content, the dynamic discourse of social media content, as well as the emergence of new forms of offensive language, especially in a multilingual setting, calls for future research in the issue. In this work, we tackled Task A, B, and C of Offensive Language Challenge at SemEval2020. We handled offensive language in five languages: English, Greek, Danish, Arabic, and Turkish. Specifically, we pre-processed all provided datasets and developed an appropriate strategy to handle Tasks (A, B, & C) for identifying the presence/absence, type and the target of offensive language in social media. For this purpose, we used OLID2019, OLID2020 datasets, and generated new datasets, which we made publicly available. We used the provided unsupervised machine learning implementation for automated annotated datasets and the online Google translation tools to create new datasets as well. We discussed the limitations and the success of our machine learning-based approach for all the five different languages. Our results for identifying offensive posts (Task A) yielded satisfactory accuracy of 0.92 for English, 0.81 for Danish, 0.84 for Turkish, 0.85 for Greek, and 0.89 for Arabic. For the type detection (Task B), the results are significantly higher (.87 accuracy) compared to target detection (Task C), which yields.81 accuracy. Moreover, after using automated Google translation, the overall efficiency improved by 2% for Greek, Turkish, and Danish. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Computational linguistics; Learning algorithms; Semantics; Social networking (online); Translation (languages); Detection tasks; Google+; Offensive languages; On-line access; Online content; Research communities; Social media; Social media platforms; Turkishs; Twitter posts; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{de la Peña Sarracén20201605,
	author = {de la Peña Sarracén, Gretel Liz and Rosso, Paolo},
	title = {PRHLT-UPV at SemEval-2020 Task 12: BERT for Multilingual Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1605 – 1614},
	doi = {10.18653/v1/2020.semeval-1.209},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113601831&doi=10.18653%2fv1%2f2020.semeval-1.209&partnerID=40&md5=5aff91bf82e0df94f68afa8ad3008aba},
	affiliations = {Universitat Politècnica de València, València, Spain},
	abstract = {The present paper describes the system submitted by the PRHLT-UPV team for the task 12 of SemEval-2020: OffensEval 2020. The official title of the task is Multilingual Offensive Language Identification in Social Media, and aims to identify offensive language in texts. The languages included in the task are English, Arabic, Danish, Greek and Turkish. We propose a model based on the BERT architecture for the analysis of texts in English. The approach leverages knowledge within a pre-trained model and performs fine-tuning for the particular task. In the analysis of the other languages the Multilingual BERT is used, which has been pre-trained for a large number of languages. In the experiments, the proposed method for English texts is compared with other approaches to analyze the relevance of the architecture used. Furthermore, simple models for the other languages are evaluated to compare them with the proposed one. The experimental results show that the model based on BERT outperforms other approaches. The main contribution of this work lies in this study, despite not obtaining the first positions in most cases of the competition ranking. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Fine tuning; Language detection; Language identification; Model-based OPC; Offensive languages; Simple modeling; Social media; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ou2020121,
	author = {Ou, Xiaozhi and Li, Hongling},
	title = {YNU_OXZ at HASOC 2020: Multilingual hate speech and offensive content identification based on XLM-RoBERTa},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {121 – 127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102934695&partnerID=40&md5=ad79043b7fbcb984b03b7720bc12680c},
	affiliations = {School of Information Science and Engineering, Yunnan University, Kunming, Yunnan, 650500, China},
	abstract = {This article introduces the submission of subtask A in three languages (English, German, Hindi) that we participated in the HASOC 2020 shared task, which aims to target hate speech and offensive language in multiple languages for identification. To solve this task, we propose a system based on the multilingual model XLM-RoBERTa and Ordered Neurons LSTM (ON-LSTM). When evaluated on the official test set, our system show the effectiveness of our method on subtask A of three languages. The Macro average F1 score of English subtask A is 0.5006, the Macro average F1 score of German subtask A is 0.5177, the Macro average F1 score of Hindi subtask A is 0.5200. This final leaderboard result is calculated with approximately 15% of the private test data. © 2020 Copyright for this paper by its authors.},
	author_keywords = {English; German; Hate speech; Hindi; Identification; Multilingual; Offensive language},
	keywords = {Fires; Information retrieval; Long short-term memory; Content identifications; F1 scores; Multiple languages; Offensive languages; Subtask; Test data; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Dadu20202183,
	author = {Dadu, Tanvi and Pant, Kartikey},
	title = {Team Rouges at SemEval-2020 Task 12: Cross-lingual Inductive Transfer to Detect Offensive Language},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2183 – 2189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123959285&partnerID=40&md5=b1612559289a97ed1e86a1a9efcc7f6c},
	affiliations = {Netaji Subhas Institute of Technology, New Delhi International Institute of Information Technology, Hyderabad, India},
	abstract = {With the growing use of social media and its availability, many instances of the use of offensive language have been observed across multiple languages and domains. This phenomenon has given rise to the growing need to detect the offensive language used in social media crosslingually. In OffensEval 2020, the organizers have released the multilingual Offensive Language Identification Dataset (mOLID), which contains tweets in five different languages, to detect offensive language. In this work, we introduce a cross-lingual inductive approach to identify the offensive language in tweets using the contextual word embedding XLM-RoBERTa (XLM-R). We show that our model performs competitively on all five languages, obtaining the fourth position in the English task with an F1-score of 0.919 and eighth position in the Turkish task with an F1-score of 0.781. Further experimentation proves that our model works competitively in a zero-shot learning environment, and is extensible to other languages. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Computer aided instruction; Natural language processing systems; Semantics; Contextual words; Cross-lingual; Embeddings; F1 scores; Inductive transfer; Language identification; Multiple domains; Multiple languages; Offensive languages; Social media; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Kiela2020,
	author = {Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
	title = {The hateful memes challenge: Detecting hate speech in multimodal memes},
	year = {2020},
	journal = {Advances in Neural Information Processing Systems},
	volume = {2020-December},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107918265&partnerID=40&md5=4e0f406773a96075141399585b10f312},
	affiliations = {Facebook AI},
	abstract = {This work proposes a new challenge set for multimodal classification, focusing on detecting hate speech in multimodal memes. It is constructed such that unimodal models struggle and only multimodal models can succeed: difficult examples (“benign confounders”) are added to the dataset to make it hard to rely on unimodal signals. The task requires subtle reasoning, yet is straightforward to evaluate as a binary classification problem. We provide baseline performance numbers for unimodal models, as well as for multimodal models with various degrees of sophistication. We find that state-of-the-art methods perform poorly compared to humans, illustrating the difficulty of the task and highlighting the challenge that this important problem poses to the community. © 2020 Neural information processing systems foundation. All rights reserved.},
	keywords = {Base-line performance; Binary classification problems; Multi-modal; Multimodal models; State-of-the-art methods; Unimodal; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 271; Conference name: 34th Conference on Neural Information Processing Systems, NeurIPS 2020; Conference date: 6 December 2020 through 12 December 2020; Conference code: 169463}
}

@CONFERENCE{Uzan20202017,
	author = {Uzan, Moshe and HaCohen-Kerner, Yaakov},
	title = {JCT at SemEval-2020 Task 12: Offensive Language Detection in Tweets using Preprocessing Methods, Character and Word N-grams},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2017 – 2022},
	doi = {10.18653/v1/2020.semeval-1.266},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113533308&doi=10.18653%2fv1%2f2020.semeval-1.266&partnerID=40&md5=d72b6c846dd1b202530a5bf975294f74},
	affiliations = {Computer Science Department, Bar Ilan University, Ramat-Gan, 5290002, Israel; Jerusalem College of Technology, Lev Academic Center, Jerusalem, 9116001, Israel},
	abstract = {In this paper, we describe our submissions to SemEval-2020 contest. We tackled subtask 12 - “Multilingual Offensive Language Identification in Social Media”. We developed different models for four languages: Arabic, Danish, Greek, and Turkish. We applied three supervised machine learning methods using various combinations of character and word n-gram features. In addition, we applied various combinations of basic preprocessing methods. Our best submission was a model we built for offensive language identification in Danish using Random Forest. This model was ranked at the 6th position out of 39 submissions. Our result is lower by only 0.0025 than the result of the team that won the 4th place using entirely non-neural methods. Our experiments indicate that char ngram features are more helpful than word ngram features. This phenomenon probably occurs because tweets are more characterized by characters than by words, tweets are short, and contain various special sequences of characters, e.g., hashtags, shortcuts, slang words, and typos. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Decision trees; Learning algorithms; Natural language processing systems; Semantics; Language detection; Language identification; N-grams; Offensive languages; Pre-processing method; Social media; Subtask; Supervised machine learning; Turkishs; Word n-grams; Supervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Lavergne2020,
	author = {Lavergne, Eric and Saini, Rajkumar and Kovács, György and Murphy, Killian},
	title = {TheNorth @ HaSpeeDe 2: BERT-based language model fine-tuning for Italian hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097569258&partnerID=40&md5=e561b545d7c08e7d02d1605b1fc4c8e1},
	affiliations = {Luleå Tekniska Universitet, Sweden},
	abstract = {This report was written to describe the systems that were submitted by the team “TheNorth” for the HaSpeeDe 2 shared task organised within EVALITA 2020. To address the main task which is hate speech detection, we fine-tuned BERT-based models. We evaluated both multilingual and Italian language models trained with the data provided and additional data. We also studied the contributions of multitask learning considering both hate speech detection and stereotype detection tasks. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Computational linguistics; Natural language processing systems; Speech; Additional datum; Detection tasks; Fine tuning; Language model; Main tasks; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Bisconti2020,
	author = {Bisconti, Elia and Montagnani, Matteo},
	title = {Montanti @ HaSpeeDe2 EVALITA 2020: Hate speech detection in online contents},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097570199&partnerID=40&md5=187670fc00e234d66e0fd2df28011948},
	affiliations = {University of Pisa, Italy},
	abstract = {This report describes an approach to face a task regarding the identification of hate content and stereotypes within tweets. Two models will be shown, both presented to the HaSpeeDe competition proposed by EVALITA 2020. They are based on a Logistic Regression model that takes different types of embedding as input. The best system shows interesting results. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Logistic regression; Logistic Regression modeling; On-line contents; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Kumar2020384,
	author = {Kumar, Abhinav and Saumya, Sunil and Singh, Jyoti Prakash},
	title = {NITP-AI-NLP@HASOC-Dravidian-CodeMix-FIRE2020: A machine learning approach to identify offensive languages from Dravidian code-mixed text},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {384 – 390},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102925622&partnerID=40&md5=c76bcb529946b0adf429629577f36ed2},
	affiliations = {National Institute of Technology Patna, Patna, India; Indian Institute of Information Technology, Dharwad, Karnataka, India},
	abstract = {Hate speech in social media has posed a threat to society. Several models for a single language, mostly English hate speech is proposed recently. However, In countries where English is not the native language, communication involves scripts and constructs of more than one language yielding code mixed text. The current work classifies offensive and non-offensive tweets or YouTube comments written in code-mix Tamil, code-mixed Malayalam, and script-mixed Malayalam languages. We explored deep learning models such as attention-based Long Short Term Memory (LSTM), Convolution Neural Network (CNN), and machine learning models such as support vector machine, Logistic regression, Random forest, and Naive Bayes to identify offensive posts from the code-mixed and script-mixed posts. From the extensive experiments, we found that the use of character N-gram Term Frequency-Inverse Document Frequency (TF-IDF) features plays a promising role in identifying offensive social media posts. The character N-gram TF-IDF based Naive Bayes classifier performed best with the weighted precision, recall, and F1-score of 0.90 for Tamil code-mixed text. The Logistic regression classifier with character N-gram TF-IDF features performed best with the weighted precision, recall, and F1-score of 0.78 for Malayalam code-mixed text. The Dense Neural Network with character N-gram TF-IDF features performed best with the weighted precision of 0.96, recall of 0.95, and F1-score of 0.95 for Malayalam script-mixed text. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Code-mixed; Deep learning; Hate speech; Machine learning; Script-mixed},
	keywords = {Classifiers; Computational linguistics; Decision trees; Deep learning; Fires; Information retrieval; Learning systems; Logistic regression; Social networking (online); Support vector machines; Support vector regression; Text processing; Turing machines; Convolution neural network; Learning models; Logistic regression classifier; Machine learning approaches; Machine learning models; Naive Bayes classifiers; Offensive languages; Term frequencyinverse document frequency (TF-IDF); Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Balaji2020370,
	author = {Balaji, Nitin Nikamanth Appiah and Bharathi, B.},
	title = {SSNCSE_NLP@HASOC-Dravidian-CodeMixFIRE2020: Offensive language identification on multilingual code mixing text},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {370 – 376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102920054&partnerID=40&md5=6d58fe807621a80e244dfa54f1fc5106},
	affiliations = {Department of CSE, Sri Siva Subramaniya Nadar College of Engineering, Tamil Nadu, India},
	abstract = {The number of social media users is increasing rapidly. A myriad of people have started using native languages in Roman alphabets. Therefore, it has becomes a big concern to regulate the quality of the text content and messages that are being shared to the internet. In this paper we study the task of offensive message identification for Tamil-English and Malayalam-English code-mixed content. The char n-gram, TFIDF and fine-tuned BERT are compared in combination with machine learning models such as MLP, Random Forest and Naive Bayes. This work explains the submissions made by SSNCSE_NLP in HASOC Code-mix tasks for Hate Speech and Offensive language detection. We achieve F1 scores of 0.94 for task1-Malayalam, 0.75 for task2-Malayalam and 0.88 for task2-Tamil on the test-set. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT embedding; Hate Speech Detection; Machine Learning; NLP; Offensive language identification},
	keywords = {Decision trees; Information retrieval; Code-mixing; Machine learning models; Naive bayes; Native language; Offensive languages; Offensive messages; Social media; Text content; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Gambino2020,
	author = {Gambino, Giuseppe and Pirrone, Roberto},
	title = {CHILab @ HaSpeeDe 2: Enhancing hate speech detection with part-of-speech tagging},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	doi = {10.4000/books.aaccademia.7057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097531545&doi=10.4000%2fbooks.aaccademia.7057&partnerID=40&md5=b2687a5b74a135ae93fa2889c8eeef01},
	affiliations = {Dipartimento di Ingegneria, Università degli Studi di Palermo, Italy},
	abstract = {The present paper describes two neural network systems used for Hate Speech Detection tasks that make use not only of the pre-processed text but also of its Part-of-Speech (PoS) tag. The first system uses a Transformer Encoder block, a relatively novel neural network architecture that arises as a substitute for recurrent neural networks. The second system uses a Depth-wise Separable Convolutional Neural Network, a new type of CNN that has become known in the field of image processing thanks to its computational efficiency. These systems have been used for the participation to the HaSpeeDe 2 task of the EVALITA 2020 workshop with CHILab as the team name, where our best system, the one that uses Transformer, ranked first in two out of four tasks and ranked third in the other two tasks. The systems have also been tested on English, Spanish and German languages. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Computational linguistics; Convolutional neural networks; Image processing; Network architecture; Recurrent neural networks; Speech recognition; Detection tasks; First systems; Neural network systems; Novel neural network; Part of speech tagging; Part-of-speech tagger; Part-of-speech tags; Parts-of-speech tagging; Speech detection; System use; Computational efficiency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Cao20206327,
	author = {Cao, Rui and Lee, Roy Ka-Wei},
	title = {HateGAN: Adversarial Generative-Based Data Augmentation for Hate Speech Detection},
	year = {2020},
	journal = {COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference},
	pages = {6327 – 6338},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112692303&partnerID=40&md5=0218a3991df327500569277d2508cae0},
	affiliations = {Singapore Management University, Singapore; Singapore University of Technology and Design, Singapore},
	abstract = {Academia and industry have developed machine learning and natural language processing models to detect online hate speech automatically. However, most of these existing methods adopt a supervised approach that heavily depends on labeled datasets for training. This results in the methods’ poor detection performance of the hate speech class as the training datasets are highly imbalanced. In this paper, we propose HateGAN, a deep generative reinforcement learning model, which addresses the challenge of imbalance class by augmenting the dataset with hateful tweets. We conduct extensive experiments to augment two commonly-used hate speech detection datasets with the HateGAN generated tweets. Our experiment results show that HateGAN improves the detection performance of the hate speech class regardless of the classifiers and datasets used in the detection task. Specifically, we observe an average 5% improvement for the hate class F1 scores across all state-of-the-art hate speech classifiers. We also conduct case studies to empirically examine the HateGAN generated hate speeches and show that the generated tweets are diverse, coherent, and relevant to hate speech detection. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Deep learning; Learning algorithms; Learning systems; Natural language processing systems; Reinforcement learning; Data augmentation; Detection performance; Labeled dataset; Language processing; Learning languages; Machine-learning; Natural languages; Processing model; Speech detection; Training dataset; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886}
}

@ARTICLE{Salim2020213,
	author = {Salim, Calvin Erico Rudy and Suhartono, Derwin},
	title = {A systematic literature review of different machine learning methods on hate speech detection},
	year = {2020},
	journal = {International Journal on Informatics Visualization},
	volume = {4},
	number = {4},
	pages = {213 – 218},
	doi = {10.30630/joiv.4.4.476},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099055523&doi=10.30630%2fjoiv.4.4.476&partnerID=40&md5=97a37125b882ee395450d3fe5957bedb},
	affiliations = {Computer Science Department, Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia},
	abstract = {Hate speech is one of the most challenging problem internets is facing today. The most common practice to deal with online suspects of hate speech is by manually reporting the comment or the post which at the back end is reviewed by a person. This has a lot of limitations. it requires a lot of time as human intervention is required. Many countries have made laws so that companies have to deal with this type of content within a time frame. This systematic literature review examines hate speech detection problem and will be used to do an experimental approach on detecting hate speech and abusive language. This work also provides an overview of previous research, including methods, algorithms, and main features used. We observe 31,633 papers of current research about hate speech detection from online databases, after applying inclusion and exclusion criteria the result is 1,929 papers and then returned 15 papers after the full text analysis. These papers are for answering the research questions of this systematic literature review. We use two research questions in this literature review which will be the foundation of the next experimental research. Correctly classifying a piece of text as an actual hate speech requires a lot of correctly labelled data. Most common challenges are different languages, out of vocabulary words, long range dependencies and many more. © 2020, Politeknik Negeri Padang. All rights reserved.},
	author_keywords = {Artificial intelligence; Hate-speech; Natural language processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Li2020210,
	author = {Li, Junyi and Zhao, Tianzi},
	title = {Lee@HASOC2020: ALBERT-based max ensemble with self-training for identifying hate speech and offensive content in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {210 – 216},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102950641&partnerID=40&md5=12e3d072cad3a09afc9cb3351628c853},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {This paper describes the system submitted to HASOC 2020. This task aims to identify hate speech and offensive content in Indo-European languages . We only participate in the English part of subtask A, which aims to identify hate speech and offensive content in English. To solve this problem, we propose an ALBERT-based model, and use the self-training and max ensemble to improve model performance. Our model achieves a macro F1 score of 0.4976 (ranks 20/35) in subtask A. © 2020 Copyright for this paper by its authors.},
	author_keywords = {ALBERT; Hate Speech and Offensive Content; Indo-European Languages; Max Ensemble; Self-training},
	keywords = {Fires; Information retrieval; European languages; F1 scores; Model performance; Self training; Subtask; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@ARTICLE{Singh2020194027,
	author = {Singh, Ravinder and Subramani, Sudha and Du, Jiahua and Zhang, Yanchun and Wang, Hua and Ahmed, Khandakar and Chen, Zhenxiang},
	title = {Deep learning for multi-class antisocial behavior identification from Twitter},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {194027 – 194044},
	doi = {10.1109/ACCESS.2020.3030621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102819861&doi=10.1109%2fACCESS.2020.3030621&partnerID=40&md5=915adaa03d16193208319c442781b845},
	affiliations = {Institute for Sustainable Industries and Liveable Cities, Victoria University, Footscray, 3011, VIC, Australia; School of Information Science and Engineering, University of Jinan, Jinan, 250022, China},
	abstract = {Social Media has become an integral part of our daily life. Not only it enables collaboration and flow of information but has also become an imperative tool for businesses and governments around the world. All this makes a compelling case for everyone to be on some sort of online social media platform. However, this virtuousness is overshadowed by some of its shortcomings. The manifestation of antisocial behaviour online is a growing concern that hinders participation and cultivates numerous social problems. Antisocial behaviour exists in its various forms such as aggression, disregard for safety, lack of remorse, unlawful behaviour, etc. The paper introduces a deep learning-based approach to detect and classify online antisocial behaviour (ASB). The automatic content classification addresses the issue of scalability, which is imperative when dealing with online platforms. A benchmark dataset was created with multi-class annotation under the supervision of a domain expert. Extensive experiments were conducted with multiple deep learning algorithms and their superior results were validated against the results from the traditional machine learning algorithms. Visually enhanced interpretation of the classification process is presented for model and error analyses. Accuracy of up to 99% in class identification was achieved on the ground truth dataset for empirical validation. The study is an evidence of how the cutting-edge deep learning technology can be utilized to solve a real-world problem of curtailing antisocial behaviour, which is a public health threat and a social problem. © This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/},
	author_keywords = {Classification; Deep learning; Feature extraction; Information extraction; Knowledge discovery; Online antisocial behavior; Social media behavior},
	keywords = {Deep learning; Health risks; Social networking (online); Antisocial behavior; Classification process; Empirical validation; Ground-truth dataset; Learning technology; Learning-based approach; Online social medias; Real-world problem; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhang2020217,
	author = {Zhang, Zichen and Wu, Yuhang and Wu, Hao},
	title = {YUN_DE at HASOC2020 subtask A: Multi-model ensemble learning for identifying hate speech and offensive language},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {217 – 223},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102941145&partnerID=40&md5=4e9f3f0c7b179ef7c225d93ff9c18750},
	affiliations = {School of Information Science and Engineering, Yunnan University, Chenggong Campus, Kunming, China},
	abstract = {This paper describes our system in subtask A of HASOC2020: Hate Speech and Offensive Conte Identification in Indo-European Languages. We propose a method of multi-model ensemble learnin which includes BERT, ON-LSTM, and TextCNN models. The multi-model ensemble aims to make bett results about text classification than the single model. Our system achieves the Macro average F1-sco of 0.5017 and is ranked 11th on the final leader board of the competition among the 36 teams. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; Ensemble Learning; ON-LSTM; Text Classification; TextCNN},
	keywords = {Classification (of information); Fires; Information retrieval; Speech recognition; Text processing; European languages; Multi-model ensemble; Offensive languages; Single models; Subtask; Text classification; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Mothe2020260,
	author = {Mothe, Josiane and Parikh, Pratik and Ramiandrisoa, Faneva},
	title = {IRIT-PREVISION at HASOC 2020: Fine-tuning BERT for hate speech and offensive content identification},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {260 – 265},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102925630&partnerID=40&md5=f6721d530e74ae2859656693f9b2643c},
	affiliations = {IRIT, Université de Toulouse, France; ESPE, UT2J, France},
	abstract = {This paper describes the participation of the IRIT-PREVISION team at HASOC (Hate Speech and Offensive Content Identification in Indo-European Languages) 2020 shared task. Our approach is based on fine-tuning a pre-trained transformer based language model BERT (Bidirectional Encoder Representation from Transformer) [1]. We participated to the English sub-task A. We obtained a macro average F1 of 0.497 (self-computed). © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; Deep Learning; Hate Speech Detection; Information system; Social Media},
	keywords = {Fires; Information retrieval; Content identifications; European languages; Fine tuning; Language model; Subtasks; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Dong2020391,
	author = {Dong, Kunjie and Wang, Yao},
	title = {YUN@HASOC-Dravidian-CodeMix-FIRE2020: A multi-component sentiment analysis model for offensive language identification},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {391 – 396},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102943463&partnerID=40&md5=ff93ed2cdf8a17d064bb92390ff946a7},
	affiliations = {School of Information, Yunnan University, Yunnan, Kunming, 650504, China},
	abstract = {The research of discerning the offensive language formatted with code-mixed in social media has a wide range of applications in mining the available information to provide powerful assistance for sentiment analysis. This paper describes all of our work on the HASOC-Offensive Language Identification Dravidian Code-Mix FIRE 2020 tasks, which includes a message-level classification task that classifying a YouTube comment in Code-mixed Malayalam into the offensive (OFF) or Not-offensive (NOT) language, and another message-level label classification task that classifying a Tweet or YouTube comment in Tanglish and Manglish (Tamil and Malayalam using Roman Characters) into the offensive or Not-offensive language. As far as we know, this is the first shared task on offensive language in Dravidian Code-Mixed text. To achieve this goal, in this paper, we propose an ensemble model which makes full use of the information of rich sequential patterns. More precisely, the proposed model contains a self-attention based on the BiLSTM and the sub-word representation learning. Experimental results of our model on the Malayalam-English of subtask 1, Tamil-English and Malayalam-English of subtask 2 have achieved the F1 values of 0.93, 0.85 and 0.67, respectively, and ranked 3rd, 5th, 9th, respectively. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Code-mixed Text; Dravidian languages; Offensive language identification; Sentiment analysis},
	keywords = {Information retrieval; Sentiment analysis; Classification tasks; Ensemble modeling; Malayalams; Multicomponents; Offensive languages; Sequential patterns; Social media; Sub words; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Alonso20202197,
	author = {Alonso, Pedro and Saini, Rajkumar and Kovács, György},
	title = {TheNorth at SemEval-2020 Task 12: Hate Speech Detection using RoBERTa},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2197 – 2202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119198242&partnerID=40&md5=b8eabb5bf1a97aeed100cb226ea35636},
	affiliations = {EISLAB Machine Learning, Luleå University of Technology, Luleå, Sweden},
	abstract = {Hate speech detection on social media platforms is crucial as it helps to avoid severe harm to marginalized people and groups. The application of Natural Language Processing (NLP) and Deep Learning has garnered encouraging results in the task of hate speech detection. The expression of hate, however, is varied and ever-evolving. Thus better detection systems need to adapt to this variance. Because of this, researchers keep on collecting data and regularly come up with hate speech detection competitions. In this paper, we discuss our entry to one such competition, namely the English version of sub-task A for the OffensEval competition. Our contribution can be perceived through our results, that was first an F1-score of 0.9087, and with further refinements described here climb up to 0.9166. It serves to give more support to our hypothesis that one of the variants of BERT, namely RoBERTa can successfully differentiate between offensive and non-offensive tweets, given the proper preprocessing steps. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Speech; Speech recognition; Detection system; F1 scores; Pre-processing step; Social media platforms; Speech detection; Subtask; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Mohtaj2020298,
	author = {Mohtaj, Salar and Woloszyn, Vinicius and Möller, Sebastian},
	title = {TUB at HASOC 2020: Character based LSTM for hate speech detection in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {298 – 303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102947706&partnerID=40&md5=e9859ab684b81cd5ab4c491a2c921875},
	affiliations = {Quality and Usability Lab, Technische Universität Berlin, Berlin, Germany; German Research Centre for Artificial Intelligence (DFKI), Projektbüro Berlin, Berlin, Germany},
	abstract = {This paper presents TU Berlin team experiments and results on the task 1 of the shared task on hate speech and offensive content identification in Indo-European languages. Recently, hate speech has become an important problem that is seriously affecting online social media. Large scale social platforms are currently investing important resources to automatically detect and classify toxic language. The competition evaluates the success of different natural language processing models on detecting hate speech in different languages, automatically. Among the state-of-the-art deep learning models that have been used for the experiments, the character based LSTM achieved the best results on detecting hate speech contents in tweets. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Bert; Hate speech detection; LSTM; Offensive Content Identification},
	keywords = {Deep learning; Fires; Information retrieval; Long short-term memory; Natural language processing systems; Social networking (online); Speech; Content identifications; European languages; Learning models; NAtural language processing; Online social medias; Speech content; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Rajamanickam20204270,
	author = {Rajamanickam, Santhosh and Mishra, Pushkar and Yannakoudakis, Helen and Shutova, Ekaterina},
	title = {Joint modelling of emotion and abusive language detection},
	year = {2020},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {4270 – 4279},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098375592&partnerID=40&md5=4ad5b97a56a2e49433e2b3e1fe256ee4},
	affiliations = {ILLC, University of Amsterdam; Facebook AI; Dept.of Informatics, King's College London},
	abstract = {The rise of online communication platforms has been accompanied by some undesirable effects, such as the proliferation of aggressive and abusive behaviour online. Aiming to tackle this problem, the natural language processing (NLP) community has experimented with a range of techniques for abuse detection. While achieving substantial success, these methods have so far only focused on modelling the linguistic properties of the comments and the online communities of users, disregarding the emotional state of the users and how this might affect their language. The latter is, however, inextricably linked to abusive behaviour. In this paper, we present the first joint model of emotion and abusive language detection, experimenting in a multi-task learning framework that allows one task to inform the other. Our results demonstrate that incorporating affective features leads to significant improvements in abuse detection performance across datasets. © 2020 Association for Computational Linguistics},
	keywords = {Computational linguistics; Learning systems; Natural language processing systems; User profile; Communication platforms; Emotional state; Joint models; Language detection; Language processing; Linguistic properties; Natural languages; On-line communication; On-line communities; Undesirable effects; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172533}
}

@CONFERENCE{Luceri2020417,
	author = {Luceri, Luca and Giordano, Silvia and Ferrara, Emilio},
	title = {Detecting troll behavior via inverse reinforcement learning: A case study of Russian trolls in the 2016 us election},
	year = {2020},
	journal = {Proceedings of the 14th International AAAI Conference on Web and Social Media, ICWSM 2020},
	pages = {417 – 427},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098379270&partnerID=40&md5=ad763645c86b94609d89968748799ffa},
	affiliations = {University of Southern California, Information Sciences Institute, Marina del Rey, CA, United States; University of Applied Sciences and Arts of Southern Switzerland (SUPSI), Manno, Switzerland; University of Bern, Bern, Switzerland},
	abstract = {Since the 2016 US Presidential election, social media abuse has been eliciting massive concern in the academic community and beyond. Preventing and limiting the malicious activity of users, such as trolls and bots, in their manipulation campaigns is of paramount importance for the integrity of democracy, public health, and more. However, the automated detection of troll accounts is an open challenge. In this work, we propose an approach based on Inverse Reinforcement Learning (IRL) to capture troll behavior and identify troll accounts. We employ IRL to infer a set of online incentives that may steer user behavior, which in turn highlights behavioral differences between troll and non-troll accounts, enabling their accurate classification. As a study case, we consider the troll accounts identified by the US Congress during the investigation of Russian meddling in the 2016 US Presidential election. We report promising results: the IRL-based approach is able to accurately detect troll accounts (AUC=89.1%). The differences in the predictive features between the two classes of accounts enables a principled understanding of the distinctive behaviors reflecting the incentives trolls and non-trolls respond to. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Behavioral research; Social networking (online); Academic community; Automated detection; Inverse reinforcement learning; Malicious activities; Presidential election; Social media; US Congress; User behaviors; Reinforcement learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 52; Conference name: 14th International AAAI Conference on Web and Social Media, ICWSM 2020; Conference date: 8 June 2020 through 11 June 2020; Conference code: 166335}
}

@CONFERENCE{Chakravarthi2020112,
	author = {Chakravarthi, Bharathi Raja and Anand Kumar, M. and McCrae, John P. and Premjith, B. and Soman, K.P. and Mandl, Thomas},
	title = {Overview of the track on HASOC-offensive Language Identification-DravidianCodeMix},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {112 – 120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098437999&partnerID=40&md5=77d7364919304b8b8182d02edb6fa4db},
	affiliations = {Insight SFI Research Centre for Data Analytics, Data Science Institute, National University of Ireland, Galway, Ireland; Department of Information Technology, National Institute of Technology Karnataka, Surathkal, India; Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; Information Science, University of Hildesheim, Germany},
	abstract = {We present the results and main findings of the HASOC-Offensive Language Identification on code mixed Dravidian languages. The task featured two tasks. Task 1 is about offensive language identification in Malayalam language where the comment were written in both native script and Latin script. Task 2 is about offensive language identification in Tamil and Malayalam languages where the comments were written in Latin script (non-native script). For both the task, given a comment the participants should develop a system to classify the text into offensive or not-offensive. In total 96 participants participated and 12 participants submitted the papers. In this paper, we present the task, data, the results and discuss the system submission and methods used by participants. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Dravidian languages; Malayalam; Offensive language identification; Tamil},
	keywords = {Fires; Information retrieval; Malayalams; Non-native; Offensive languages; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Wang20201448,
	author = {Wang, Shuohuan and Liu, Jiaxiang and Ouyang, Xuan and Sun, Yu},
	title = {Galileo at SemEval-2020 Task 12: Multi-lingual Learning for Offensive Language Identification using Pre-trained Language Models},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1448 – 1455},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123931169&partnerID=40&md5=286e80fdce8d33b807296b01a35e22bb},
	affiliations = {Baidu Inc., China},
	abstract = {This paper describes Galileo's performance in SemEval-2020 Task 12 on detecting and categorizing offensive language in social media. For Offensive Language Identification, we proposed a multi-lingual method using Pre-trained Language Models, ERNIE and XLM-R. For offensive language categorization, we proposed a knowledge distillation method trained on soft labels generated by several supervised models. Our team participated in all three sub-tasks. In Sub-task A - Offensive Language Identification, we ranked first in terms of average F1 scores in all languages. We are also the only team which ranked among the top three across all languages. We also took the first place in Sub-task B - Automatic Categorization of Offense Types and Sub-task C - Offence Target Identification. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Distillation; Natural language processing systems; Semantics; Distillation method; F1 scores; GALILEO; Language identification; Language model; Offensive languages; Performance; Social media; Soft labels; Subtask; Crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Jorgensen2020,
	author = {Jorgensen, MacKenzie and Choi, Minho and Niemann, Marco and Brunk, Jens and Becker, Jörg},
	title = {Multi-class detection of abusive language using automated machine learning},
	year = {2020},
	journal = {Proceedings of the 15th International Conference on Business Information Systems 2020 "Developments, Opportunities and Challenges of Digitization", WIRTSCHAFTSINFORMATIK 2020},
	doi = {10.30844/wi_2020_r7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101716420&doi=10.30844%2fwi_2020_r7&partnerID=40&md5=ef398216ff183928a0cdc94ae2ca0cc1},
	affiliations = {Dept. of Computing Sciences, Villanova University, Villanova, United States; Dept. of Mathematical Sciences, Lewis and Clark College, Portland, United States; University of Münster - Ercis, Münster, Germany},
	abstract = {Abusive language detection online is a daunting task for moderators. We propose Automated Machine Learning (Auto-ML) to semi-automate abusive language detection and to assist moderators. In this paper, we show that multi-class classification powered by Auto-ML is successful in detecting abusive language in English and German as well as and better than the state-ofthe- art machine learning models. We also highlight how we combatted the imbalanced data problem in our data-sets through feature selection and undersampling methods. We propose Auto-ML as a promising approach to the field of abusive language detection, especially for small companies who may have little machine learning knowledge and computing resources. © Proceedings of the 15th International Conference on Business Information Systems 2020 "Developments, Opportunities and Challenges of Digitization", WIRTSCHAFTSINFORMATIK 2020.},
	author_keywords = {Abusive language detection; Automated-machine learning; Multi-class classification},
	keywords = {Information systems; Information use; Moderators; Automated machines; Computing resource; Imbalanced data problems; Language detection; Machine learning models; Multi-class classification; Small companies; Under-sampling; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th International Conference on Business Information Systems 2020: Developments, Opportunities and Challenges of Digitization, WIRTSCHAFTSINFORMATIK 2020; Conference date: 8 March 2020 through 11 March 2020; Conference code: 166591}
}

@CONFERENCE{Vaidya2020683,
	author = {Vaidya, Ameya and Mai, Feng and Ning, Yue},
	title = {Empirical analysis of multi-task learning for reducing identity bias in toxic comment detection},
	year = {2020},
	journal = {Proceedings of the 14th International AAAI Conference on Web and Social Media, ICWSM 2020},
	pages = {683 – 693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099543453&partnerID=40&md5=059eff799c14a6935e66caddfe51bfcd},
	affiliations = {Bridgewater-Raritan Regional High School, United States; School of Business, Stevens Institute of Technology, United States; Department of Computer Science, Stevens Institute of Technology, United States},
	abstract = {With the recent rise of toxicity in online conversations on social media platforms, using modern machine learning algorithms for toxic comment detection has become a central focus of many online applications. Researchers and companies have developed a variety of models to identify toxicity in online conversations, reviews, or comments with mixed successes. However, many existing approaches have learned to incorrectly associate non-toxic comments that have certain trigger-words (e.g. gay, lesbian, black, muslim) as a potential source of toxicity. In this paper, we evaluate several stateof- the-art models with the specific focus of reducing model bias towards these commonly-attacked identity groups. We propose a multi-task learning model with an attention layer that jointly learns to predict the toxicity of a comment as well as the identities present in the comments in order to reduce this bias. We then compare our model to an array of shallow and deep-learning models using metrics designed especially to test for unintended model bias within these identity groups. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Deep learning; Learning systems; Multi-task learning; Social networking (online); Toxicity; Empirical analysis; Learning models; Model bias; Modern machines; On-line applications; Potential sources; Social media platforms; State of the art; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 14th International AAAI Conference on Web and Social Media, ICWSM 2020; Conference date: 8 June 2020 through 11 June 2020; Conference code: 166335}
}

@CONFERENCE{Alami20202080,
	author = {Alami, Hamza and El Alaoui, Said Ouatik and Benlahbib, Abdessamad and En-Nahnahi, Noureddine},
	title = {LISAC FSDM-USMBA Team at SemEval-2020 Task 12: Overcoming AraBERT's pretrain-finetune discrepancy for Arabic offensive language identification},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2080 – 2085},
	doi = {10.18653/v1/2020.semeval-1.275},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123935005&doi=10.18653%2fv1%2f2020.semeval-1.275&partnerID=40&md5=e06e4bd404a497db2d5381fbcdc87167},
	affiliations = {LISAC Laboratory, Faculty of Sciences Dhar EL Mehraz (F.S.D.M), Sidi Mohamed Ben Abdellah University (U.S.M.B.A); Ibn Tofail University, National School of Applied Sciences, Kenitra, Morocco},
	abstract = {AraBERT is an Arabic version of the state-of-the-art Bidirectional Encoder Representations from Transformers (BERT) model. The latter has achieved good performance in a variety of Natural Language Processing (NLP) tasks. In this paper, we propose an effective AraBERT embeddings-based method for dealing with offensive Arabic language in Twitter. First, we pre-process tweets by handling emojis and including their Arabic meanings. Next, to overcome the pretrain-finetune discrepancy, we substitute each detected emojis by the special token [MASK] into both fine tuning and inference phases. Then, we represent tweets tokens by applying AraBERT model. Finally, we feed the tweet representation into a sigmoid function to decide whether a tweet is offensive or not. The proposed method achieved the best results on OffensEval 2020: Arabic task and reached a macro F1 score equal to 90.17%. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Arabic languages; Embeddings; Fine tuning; Language identification; Language processing; Natural languages; Offensive languages; Performance; State of the art; Transformer modeling; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Que2020283,
	author = {Que, Qinyu and Sun, Ruijie and Xie, Shasha},
	title = {Simon@HASOC 2020: Detecting hate speech and offensive content in German language with BERT and ensembles},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {283 – 289},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102944041&partnerID=40&md5=2e40b734ef4430ffdf30054696fa0c28},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {In this paper, we introduce the system for the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) 2020 Challenge, which is submitted by our team. We use a lot of social media in our daily life, but now social media is full of hate speech and offensive language, so the detection of hate speech and offensive language has become an essential task. The task is available in English, German, and Hindi, but there is a lot of work done in the English languages, with limited work reporting posts in Hindi and German, so we chose the German task to complete. The BERT-Ger model could not meet our requirements for semantic information characteristics, we modify the upper layer structure of BERT-Ger. Finally, our system wins second place in German subtask A and tenth in German subtask B. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; German; Hate Speech; Offensive},
	keywords = {Fires; Information retrieval; Semantics; Social networking (online); Content identifications; Daily lives; English languages; European languages; German language; Offensive languages; Semantic information; Social media; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{de Saa2020,
	author = {de Saa, Eranga and Ranathunga, Lochandaka},
	title = {Self-reflective and introspective feature model for hate content detection in Sinhala YouTube videos},
	year = {2020},
	journal = {2020 From Innovation to Impact, FITI 2020},
	doi = {10.1109/FITI52050.2020.9424875},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116149222&doi=10.1109%2fFITI52050.2020.9424875&partnerID=40&md5=00762c727c2c3f2b1b6723c2d838a7f4},
	affiliations = {Department of information Technology, University of Moratuwa, Katubedda, Sri Lanka},
	abstract = {YouTube is considered one of the most popular social media platforms, which provides users with the ability to interact with each other by sharing videos, commenting or liking or disliking. Its free nature has enabled the spread of offensive and hateful content within this environment, resulting in violence and discrimination within society. Therefore, identifying hate content is crucial to mitigating the spread of hatred. This study describes a system to detect hate in Sinhala content associated in YouTube videos by natural language processing techniques. The categorizations are done based on user comments, thumbnail text, and Meta-data, which includes the title, description and tags. Here, the features were derived through self-reflective and introspective data associated with the YouTube video. This system is capable of detecting hate expressions in Sinhala language YouTube videos with nearly 90 percent accuracy. © 2020 IEEE},
	author_keywords = {Hate detection; Sentiment analysis; Sinhala; YouTube},
	keywords = {Content detection; Feature models; Hate detection; Language processing techniques; Sentiment analysis; Sinhalum; Social media platforms; YouTube; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2020 From Innovation to Impact, FITI 2020; Conference date: 15 December 2020; Conference code: 171853}
}

@CONFERENCE{Han20207732,
	author = {Han, Xiaochuang and Tsvetkov, Yulia},
	title = {Fortifying toxic speech detectors against veiled toxicity},
	year = {2020},
	journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {7732 – 7739},
	doi = {10.18653/v1/2020.emnlp-main.622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103010034&doi=10.18653%2fv1%2f2020.emnlp-main.622&partnerID=40&md5=8dbc913ad88d96d2358f0761c09270e8},
	affiliations = {Carnegie Mellon University, United States},
	abstract = {Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector's training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity. Warning: this paper contains examples that may be offensive or upsetting. © 2020 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large dataset; Speech recognition; Annotated datasets; Offensive languages; Orders of magnitude; Surface ordering; Training data; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42; Conference name: 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172724; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Swaminathan2020241,
	author = {Swaminathan, Sridhar and Ganesan, Hari Krishnan and Pandiyarajan, Radhakrishnan},
	title = {HRS-TECHIE@Dravidian-CodeMix and HASOC-FIRE2020: Sentiment analysis and hate speech identification using machine learning, deep learning and ensemble models},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {241 – 252},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102961673&partnerID=40&md5=82a20fe065a320a05d4ace3a91679c5b},
	affiliations = {Department of Computer Science Engineering, Bennett University, Greater Noida, 201310, India; Department of Computer Science and Engineering, University College of Engineering, Trichy, 620024, India; Department of Information Technology, University College of Engineering, Trichy, 620024, India},
	abstract = {In this paper, we (HRS-TECHIE) present our submissions to challenges Dravidian-CodeMix and HASOC at FIRE 2020. Classification of sentiments from social media posts and comments is essential in this modern digital era. Dravidian-CodeMix (Sentiment analysis for Dravidian Languages in Code-Mixed Text) at FIRE 2020 is a challenge for classification of sentiments of YouTube comments posted in mix of Tamil-English (Task 1) and Malayalam-English (Task 2) languages. Our chosen task is to classify YouTube comments written in Tamil-English into one of five types of sentiment classes. Identification of hate speech, offensive and profane contents from social media posts and comments is essential in this modern digital era for preventing individuals in the digital media from the cyber harassment. HASOC 2020 (Hate Speech and Offensive Content Identification in Multiple Languages) at FIRE 2020 is a challenge of identifying the bullying content from Twitter comments posted in English, German and Hindi (subtask A) languages and further classifying the type of bullying present in that comment for each language (subtask B). We worked on both subtasks A and B for the English language to identify the bullying comment and type of bullying from Twitter comments. As part of these two challenges, we submitted different state-of-the-art machine learning and deep learning models for text classification. The models trained for sentiment classification task in Dravidian-CodeMix are Naïve Bayes, Decision tree, Random Forest, AdaBoost and Long Short Term Memory (LSTM). The models trained for hate speech and offensive content identification are Naïve Bayes, SVM, Decision tree, Random Forest, Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU). We have also developed an ensemble of Machine Learning classifiers for both challenges. In Dravidian-CodeMix, we have achieved the best weighted F1-score 61% for both Naïve Bayes and LSTM models where weighted average F1-score of 60% was achieved for ensemble approach. In HASOC, we have achieved the best Macro average F1-score of 50.02% from LSTM model for subtask A and Macro average F1-score of 24.26% from ensemble approach for subtask B on the private test data. © 2020 Copyright for this paper by its authors.},
	author_keywords = {AdaBoost; Cyber Bullying; Decision tree; Ensemble Learning; GRU; LSTM; Naïve Bayes; Random forest; Sentiment Analysis; TF-IDF; Word Embedding},
	keywords = {Adaptive boosting; Brain; Classification (of information); Decision trees; Digital storage; Fires; Information retrieval; Learning systems; Long short-term memory; Random forests; Sentiment analysis; Social networking (online); Speech recognition; Support vector machines; Content identifications; English languages; Ensemble approaches; Multiple languages; Sentiment classification; Speech identification; Text classification; Weighted averages; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Mandl202087,
	author = {Mandl, Thomas and Modha, Sandip and Shahi, Gautam Kishore and Jaiswal, Amit Kumar and Nandini, Durgesh and Patel, Daksh and Majumder, Prasenjit and Schäfer, Johannes},
	title = {Overview of the HASOC track at FIRE 2020: Hate speech and offensive content identification in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {87 – 111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100373672&partnerID=40&md5=d9185b922fe8c6619f1afd07567ed6be},
	affiliations = {University of Hildesheim, Germany; LDRP-ITR, Gandhinagar, India; University of Duisburg-Essen, Germany; University of Bedfordshire, United Kingdom; University of Leeds, United Kingdom; University of Bamberg, Germany; Dalhousie University, Halifax, Canada; DA-IICT, Gandhinagar, India},
	abstract = {With the growth of social media, the spread of hate speech is also increasing rapidly. Social media are widely used in many countries. Also Hate Speech is spreading in these countries. This brings a need for multilingual Hate Speech detection algorithms. Much research in this area is dedicated to English at the moment. The HASOC track intends to provide a platform to develop and optimize Hate Speech detection algorithms for Hindi, German and English. The dataset is collected from a Twitter archive and pre-classified by a machine learning system. HASOC has two sub-task for all three languages: task A is a binary classification problem (Hate and Not Offensive) while task B is a fine-grained classification problem for three classes (HATE) Hate speech, OFFENSIVE and PROFANITY. Overall, 252 runs were submitted by 40 teams. The performance of the best classification algorithms for task A are F1 measures of 0.51, 0.53 and 0.52 for English, Hindi, and German, respectively. For task B, the best classification algorithms achieved F1 measures of 0.26, 0.33 and 0.29 for English, Hindi, and German, respectively. This article presents the tasks and the data development as well as the results. The best performing algorithms were mainly variants of the transformer architecture BERT. However, also other systems were applied with good success. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; Evaluation; Hate speech; Machine Learning; Multilingual Text Classification; Offensive Language; Online Harm},
	keywords = {Fires; Information retrieval; Learning systems; Signal detection; Social networking (online); Speech; Turing machines; Binary classification problems; Classification algorithm; Content identifications; Data development; European languages; Fine grained; Social media; Speech detection algorithm; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Sai2020336,
	author = {Sai, Siva and Sharma, Yashvardhan},
	title = {Siva@HASOC-Dravidian-CodeMix-FIRE-2020: Multilingual offensive speech detection in code-mixed and romanized text},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {336 – 343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102927276&partnerID=40&md5=df6c62cc128c7cc51b53c2ea69289f19},
	affiliations = {Birla Institute of Technology and Science, Pilani Campus, Pilani, 333031, India},
	abstract = {Detecting and eliminating offensive and hate speech in social media content is an important concern as hate and offensive speech can have serious consequences in society ranging from ill-education among youth to hate crimes. Offensive speech identification in countries like India poses several additional challenges due to the usage of code-mixed and romanized variants of multiple languages by the users in their posts on social media. HASOC-Dravidian-CodeMix - FIRE 2020 extended the task of offensive speech identification to Dravidian languages. In this paper, we describe our approach in HASOC Dravidian Code-mixed 2020, which topped two out of three tasks(F1-weighted scores - 0.95 and 0.90) and stood second in the third task lagging the top model only by 0.01 points((F1-weighted score - 0.77). We propose a novel and flexible approach of selective translation and transliteration to be able to reap better results out of fine-tuning and ensembling multilingual transformer networks like XLM-RoBERTa and mBERT. Further, we implemented pre-trained, fine-tuned and ensembled versions of XLM-RoBERTa for offensive speech classification. We open source our work to facilitate further experimentation. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Offensive speech detection; Selective translation and transliteration; Transformer Neural Networks; XLM-RoBERTa},
	keywords = {Fires; Information retrieval; Social networking (online); Speech; Fine tuning; Multiple languages; Open sources; Social media; Speech classification; Speech detection; Speech identification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Ahn20201576,
	author = {Ahn, Hwijeen and Sun, Jimin and Park, Chan Young and Seo, Jungyun},
	title = {NLPDove at SemEval-2020 Task 12: Improving Offensive Language Detection with Cross-lingual Transfer},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1576 – 1586},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123936609&partnerID=40&md5=d0ed612bceb0063acc7fd611e010a246},
	affiliations = {Sogang University, South Korea; Seoul National University, South Korea; Language Technologies Institute, Carnegie Mellon University, United States},
	abstract = {This paper describes our approach to the task of identifying offensive languages in a multilingual setting. We investigate two data augmentation strategies: using additional semi-supervised labels with different thresholds and cross-lingual transfer with data selection. Leveraging the semi-supervised dataset resulted in performance improvements compared to the baseline trained solely with the manually-annotated dataset. We propose a new metric, Translation Embedding Distance, to measure the transferability of instances for cross-lingual data selection. We also introduce various preprocessing steps tailored for social media text along with methods to fine-tune the pre-trained multilingual BERT (mBERT) for offensive language identification. Our multilingual systems achieved competitive results in Greek, Danish, and Turkish at OffensEval 2020. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Semantics; Annotated datasets; Cross-lingual; Data augmentation; Data Selection; Embeddings; Language detection; Offensive languages; Performance; Pre-processing step; Semi-supervised; Data reduction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Schäfer2020391,
	author = {Schäfer, Johannes and De Smedt, Tom and Jaki, Sylvia},
	title = {HAU at the GermEval 2019 shared task on the identification of offensive language in microposts: System description of word list, statistical and hybrid approaches},
	year = {2020},
	journal = {Proceedings of the 15th Conference on Natural Language Processing, KONVENS 2019},
	pages = {391 – 397},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103435808&partnerID=40&md5=8da180303d810b9150f36a2d654fa19a},
	affiliations = {Institute for Information Science and Natural Language Processing, University of Hildesheim, Germany; Computational Linguistics Research Group, University of Antwerp, Germany; Department of Translation and Specialized Communication, University of Hildesheim, Germany},
	abstract = {This paper presents our contribution (HAU) for the three subtasks of GermEval 2019 Task 2. To detect offensive microposts, we have experimented with different approaches and a combination thereof, namely, a Convolutional Neural Network (CNN), a Random Forest, and a lexicon-based approach. In this paper, we report our methodology, demonstrate how it includes insights from GermEval 2018, and compare the different approaches for the different subtasks in view of future directions in the detection of offensive language and hate speech online. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.},
	keywords = {Convolutional neural networks; Decision trees; Hybrid approach; Lexicon-based; Offensive languages; Subtasks; System description; Word lists; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Conference on Natural Language Processing, KONVENS 2019; Conference date: 9 October 2019 through 11 October 2019; Conference code: 167846}
}

@CONFERENCE{Xu2020311,
	author = {Xu, Li and Zeng, Jun and Chen, Shi},
	title = {yasuo at HASOC2020: Fine-tune XML-RoBERTa for hate speech identification},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {311 – 318},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102961191&partnerID=40&md5=1f77ca348ce4009d19bdfb254a5d402d},
	affiliations = {School of Information Science and Engineering, Yunnan University, Kunming, China},
	abstract = {In recent years, people are more concerned about hate speech identification and identification than ever. This paper describes our system for English and German Sub-Task A in HASOC2020. For these subtasks, we fine-tune the XLM-RoBERTa pre-training model for sentence embedding and extract the layer with the best performance for slicing and splicing. In order to make full use of both English and German corpus, we propose a multi-task method to optimize two classification tasks at the same time. Our model has achieved 0.9076 for F1 score in English Sub-Task A and 0.8165 in German Sub-Task A. © 2020 Copyright for this paper by its authors},
	author_keywords = {Fine-tune; Hate speech; Slicing; Splicing; XLM-RoBERTa},
	keywords = {Fires; Information retrieval; Classification tasks; F1 scores; Pre-training; Speech identification; Subtasks; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Raj2020161,
	author = {Raj, Roushan and Srivastava, Shivangi and Saumya, Sunil},
	title = {NSIT & IIITDWD @ HASOC 2020: Deep learning model for hate-speech identification in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {161 – 167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102950857&partnerID=40&md5=e72bd35d05c27bc53d1aa2b1603e865b},
	affiliations = {Netaji Subhas Institute of Technology, Bihta, Patna, India; Indian Institute of Information Technology, Dharwad, India},
	abstract = {In current times, social media is the most widely used platform, and everyone has the right to express their speculations, ideas, thoughts, etc. In such a case, it is often seen that hate speech and offensive contents are spreading like wildfire, making a detrimental impact on the world. It is important to identify and eradicate such offensive content from social media. This paper is a contribution to the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) 2020 shared task. Our target is to present deep learning models to detect hate speech and offensive content in three languages English, Hindi, and German. Our team NSIT_ML_Geeks has developed models using Convolutional Neural Networks (CNN), Bi-directional long short term memory (BiLSTM), and hybrid models (CNN+BiLSTM). The word-embeddings used are GloVe and fastText to convert our corpus into vectors of real numbers to train models. Our best models for Hindi sub-task A and B secured First and Second positions by outperforming other models submitted in the competition with f1 macro-avg score of 0.5337 and 0.2667 respectively. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Bi-directional Long Short-Term Memory; CNN; FastText; GloVe; Hate Speech; Indo-European Languages; Offensive Content},
	keywords = {Convolutional neural networks; Fires; Information retrieval; Learning systems; Social networking (online); Speech recognition; Bi-directional; Content identifications; Developed model; European languages; Hybrid model; Learning models; Social media; Speech identification; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Singh20201331,
	author = {Singh, Abhishek and Parmar, Surya Pratap Singh},
	title = {Voice@SRIB at SemEval-2020 Tasks 9 and 12: Stacked Ensembling method for Sentiment and Offensiveness detection in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1331 – 1341},
	doi = {10.18653/v1/2020.semeval-1.180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098829946&doi=10.18653%2fv1%2f2020.semeval-1.180&partnerID=40&md5=d3726b93860041a21118b9bf8e1b36b3},
	affiliations = {Samsung R&D Bangalore, India},
	abstract = {In social-media platforms such as Twitter, Facebook, and Reddit, people prefer to use code-mixed language such as Spanish-English, Hindi-English to express their opinions. In this paper, we describe different models we used, using the external dataset to train embeddings, ensembling methods for Sentimix, and OffensEval tasks. The use of pre-trained embeddings usually helps in multiple tasks such as sentence classification, and machine translation. In this experiment, we have used our trained code-mixed embeddings and twitter pre-trained embeddings to SemEval tasks. We evaluate our models on macro F1-score, precision, accuracy, and recall on the datasets. We intend to show that hyper-parameter tuning and data pre-processing steps help a lot in improving the scores. In our experiments, we are able to achieve 0.886 F1-Macro on OffenEval Greek language subtask post-evaluation, whereas the highest is 0.852 during the Evaluation Period. We stood third in Spanglish competition with our best F1-score of 0.756. Codalab username is asking28. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Codes (symbols); Computational linguistics; Data handling; Machine translation; Semantics; Social networking (online); Embeddings; F1 scores; Facebook; Hyper-parameter; Machine translations; Multiple tasks; Parameter data; Sentence classifications; Social media; Social media platforms; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhao2020202,
	author = {Zhao, Yingjia and Tao, Xin},
	title = {ZYJ at HASOC 2020: ALBERT-based model for hate speech and offensive content identification},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {202 – 209},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102953848&partnerID=40&md5=308edfdc015a5dcec676ac170b99bf57},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {Online social media platforms provide convenience for people to communicate, but the harm caused by online hate speech and offensive language accompanying them is also significant. At the same time, it is a challenge to identify indirect insults such as metaphor and irony, so it is necessary to understand the semantic information of the text in depth. This paper describes the approach our team is using at HASOC2020: Hate Speech and Offensive Content Identification in Indo-European Languages. In Subtask A and Sub-task B for English, we fine-tune ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, and add a customized network structure that enables the model to take advantage of the semantic information extracted by ALBERT to complete the classification task, and use StratifiedKFold to ensemble. We achieve Marco F1 of 0.4994 and 0.2412 in Subtask A and Subtask B for English language, ranked 15th and 11th. © 2020 Copyright for this paper by its authors.},
	author_keywords = {ALBERT; Hate speech; Offensive language},
	keywords = {Classification (of information); Fires; Information retrieval; Semantics; Social networking (online); Classification tasks; Content identifications; English languages; European languages; Network structures; Offensive languages; Online social medias; Semantic information; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Balouchzahi2020145,
	author = {Balouchzahi, F. and Shashirekha, H.L.},
	title = {LAs for HASOC-Learning approaches for hate speech and offensive content identification},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {145 – 151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102959948&partnerID=40&md5=b22926629083b06a1392e6906e6b02bc},
	affiliations = {Department of Computer Science, Mangalore University, Mangalore, 574199, India},
	abstract = {Anti-social elements in social media take advantage of the anonymity in the cyber world and indulge in vulgar and offensive communications such as bullying, trolling, harassment etc. Many youths experiencing such victimization are reported to have psychological symptoms of anxiety, depression and loneliness. These issues have become a growing concern for society and hence, it is important to identify and remove such behaviors in the society at the earliest. In view of this, this paper describes the learning models proposed by our team MUCS, for identifying hate speech and offensive content. Three architectures based on different learning approaches namely Ensemble of Machine Learning (ML) algorithms, Transfer Learning (TL) and ML-TL - a hybrid combination of the first two approaches are proposed. Our team obtained macro f1-score of 0.4979, 0.2517, 0.5044 and 0.5182 for English Subtask A, Subtask B, German Subtask A and Hindi Subtask A respectively. © 2020 Copyright for this paper by its authors},
	author_keywords = {Ensemble; HASOC; Learning Approaches; Machine Learning; Transfer Learning; ULMFiT},
	keywords = {Fires; Information retrieval; Speech recognition; Transfer learning; Content identifications; F1 scores; Learning approach; Learning models; Social elements; Social media; Subtask; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Casula2020,
	author = {Casula, Camilla and Tonelli, Sara},
	title = {Hate speech detection with machine-translated data: The role of annotation scheme, class imbalance and undersampling},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2769},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097910280&partnerID=40&md5=e7f88623b984e3c8351c560d3c30a13c},
	affiliations = {Fondazione Bruno Kessler, Trento, Italy},
	abstract = {While using machine-translated data for supervised training can alleviate data sparseness problems when dealing with less-resourced languages, it is important that the source data are not only correctly translated, but also follow the same annotation scheme and possibly class balance as the smaller dataset in the target language. We therefore present an evaluation of hate speech detection in Italian using machine-translated data from English and comparing three settings, in order to understand the impact of training size, class distribution and annotation scheme. Copyright © 2020 for this paper by its authors.},
	keywords = {Artificial intelligence; Computational linguistics; Speech recognition; Annotation scheme; Class distributions; Class imbalance; Data sparseness problem; Speech detection; Supervised trainings; Target language; Under-sampling; Translation (languages)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th Italian Conference on Computational Linguistics, CLiC-it 2020; Conference date: 1 March 2021 through 3 March 2021; Conference code: 165694}
}

@CONFERENCE{Madhu2020152,
	author = {Madhu, Hiren and Satapara, Shrey and Rathod, Harsh},
	title = {Astralis@Hasoc 2020: Analysis on identification of hate speech in Indo-European languages with fine-tuned transformers.},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {152 – 160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102931897&partnerID=40&md5=728850c34bfc1db943d3ce5e65c67637},
	affiliations = {LDRP-ITR, Gandhinagar, India},
	abstract = {The detection of hate speech in online social media platforms is of great importance in text classification. There is a need to research languages other than English. In this paper, we describe our team Astralis’ combined effort in the shared task HASOC. We analyzed various models such as Naive Bayes, SVM, ANN, CNN, and embeddings such as TF-IDF, Multilingual BERT, and OPENAI-GPT2. Our relative performance was better in Subtask B for all languages, with our best-performed system ranked in second position in German Subtask B. © 2020 Copyright for this paper by its authors.},
	author_keywords = {CNN; Deep Learning; Hate Speech Detection; Text Classification; Transformers},
	keywords = {Classification (of information); Fires; Information retrieval; Social networking (online); Support vector machines; Text processing; European languages; Naive bayes; Online social medias; Relative performance; Subtask; Text classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Leonardelli2020,
	author = {Leonardelli, Elisa and Menini, Stefano and Tonelli, Sara},
	title = {DH-FBK @ HaSpeeDe2: Italian hate speech detection via self-training and oversampling},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097565527&partnerID=40&md5=124a46d9a1ad23c8860ff25222c7b1c0},
	affiliations = {Fondazione Bruno Kessler, Trento, Italy},
	abstract = {We describe in this paper the system submitted by the DH-FBK team to the HaSpeeDe evaluation task, and dealing with Italian hate speech detection (Task A). While we adopt a standard approach for fine-tuning AlBERTo, the Italian BERT model trained on tweets, we propose to improve the final classification performance by two additional steps, i.e. self-training and oversampling. Indeed, we extend the initial training data with additional silver data, carefully sampled from domain-specific tweets and obtained after first training our system only with the task training data. Then, we retrain the classifier by merging silver and task training data but oversampling the latter, so that the obtained model is more robust to possible inconsistencies in the silver data. With this configuration, we obtain a macro-averaged F1 of 0.753 on tweets, and 0.702 on news headlines. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Classification (of information); Natural language processing systems; Silver; Classification performance; Domain specific; Fine tuning; Over sampling; Self training; Speech detection; Task trainings; Training data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Ezike2020175,
	author = {Ezike, Tochukwu and Sivanesan, Manikandan},
	title = {Chrestotes@HASOC 2020: Bert fine-tuning for the identification of hate speech and offensive language in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {175 – 179},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102920807&partnerID=40&md5=f9686e388678431f3188ca7599fb4de2},
	affiliations = {Xend Tech, Nigeria; RedHat, Canada},
	abstract = {This article describes our team Chrestotes’ approach to the solution submitted to HASOC 2020: Hate Speech and Offensive Content Identification in Indo-European Languages. We demonstrate an end to end solution to the fine-grained detection of hate speech in tweets. Our solution is focused on the English Task which has been split into two subtasks. Our model achieved macro-average f1-scores of 0.4969 and 0.2652 on the subtasks A and B respectively. This solution places us in the middle of the leaderboard for subtask A and first place for subtask B. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Bert; Hate speech; Offensive language; Text Classification; Transformers},
	keywords = {Fires; Information retrieval; Content identifications; End-to-end solutions; European languages; F1 scores; Fine grained; Fine tuning; Offensive languages; Subtasks; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Montani2020418,
	author = {Montani, Joaquín Padilla and Schüller, Peter},
	title = {TUWienKBS19 at GermEval Task 2, 2019: Ensemble learning for German offensive language detection},
	year = {2020},
	journal = {Proceedings of the 15th Conference on Natural Language Processing, KONVENS 2019},
	pages = {418 – 422},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103464752&partnerID=40&md5=39222c4a7e2c6a7a29b813dc47562d19},
	affiliations = {TU Wien Institut für Logic and Computation, Favoritenstraße 9-11, 1040, Austria},
	abstract = {The TUWienKBS19 system for German offensive language detection in the GermEval 2019 shared task is a stacking ensemble system. Five disjoint sets of features are used: token and character n-grams, relatedness to the, according to tf-idf, most important tokens and character n-grams within each class, and the average of the embedding vectors of all tokens in a tweet. Several base classifiers are trained independently on each of these features, yielding meta-level features which one maximum entropy model uses to perform the final classification. Our system achieved a macro-averaged F1-score of 76,80% on subtask I, and 51,86% on subtask II. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.},
	keywords = {Natural language processing systems; Base classifiers; Disjoint sets; Ensemble learning; Ensemble systems; F1 scores; Maximum entropy modeling; Meta levels; Offensive languages; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th Conference on Natural Language Processing, KONVENS 2019; Conference date: 9 October 2019 through 11 October 2019; Conference code: 167846}
}

@ARTICLE{Roy2020204951,
	author = {Roy, Pradeep Kumar and Tripathy, Asis Kumar and Das, Tapan Kumar and Gao, Xiao-Zhi},
	title = {A framework for hate speech detection using deep convolutional neural network},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {204951 – 204962},
	doi = {10.1109/ACCESS.2020.3037073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102365982&doi=10.1109%2fACCESS.2020.3037073&partnerID=40&md5=1a95662abef67181429dcb2ff35bd723},
	affiliations = {School of Information Technology, Vellore Institute of Technology, Vellore, 632014, India; School of Computing, University of Eastern Finland, Kuopio, 70211, Finland; Indian Institute of Information Technology, Surat, 395007, India},
	abstract = {The rapid growth of Internet users led to unwanted cyber issues, including cyberbullying, hate speech, and many more. This article deals with the problems of hate speech on Twitter. Hate speech appears to be an inflammatory kind of interaction process that uses misconceptions to express a hate ideology. The hate speech focuses on various protected aspects, including gender, religion, race, and disability. Owing to hate speech, sometimes unwanted crimes are going to happen as someone or a group of people get disheartened. Hence, it is essential to monitor user's posts and filter the hate speech related post before it is spread. However, Twitter receives more than six hundred tweets per second and about 500 million tweets per day. Manually filtering any information from such a huge incoming traffic is almost impossible. Concerning to this aspect, an automated system is developed using the Deep Convolutional Neural Network (DCNN). The proposed DCNN model utilises the tweet text with GloVe embedding vector to capture the tweets' semantics with the help of convolution operation and achieved the precision, recall and F1-score value as 0.97, 0.88, 0.92 respectively for the best case and outperformed the existing models. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
	author_keywords = {Convolutional neural network; Hate speech; LSTM; Tf-Idf; Twitter},
	keywords = {Automation; Convolution; Deep neural networks; Information filtering; Semantics; Social networking (online); Speech; And filters; Automated systems; Cyber bullying; Incoming traffic; Interaction process; Internet users; Rapid growth; Speech detection; Convolutional neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 136; All Open Access, Gold Open Access}
}

@CONFERENCE{Kumari2020319,
	author = {Kumari, Kirti and Singh, Jyoti Prakash},
	title = {AI_ML_NIT_Patna @HASOC 2020: BERT models for hate speech identification in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {319 – 324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102944725&partnerID=40&md5=1fbe46942f1f0c2d12d5b81159d3b08c},
	affiliations = {Institute of Technical Education and Research (ITER), Siksha ‘O’ Anusandhan, Bhubaneswar, Odisha, India; National Institute of Technology, Patna, Bihar, India},
	abstract = {The current paper describes the system submitted by team AI_ML_NIT_Patna. The task aims to identify offensive language in code-mixed dataset of comments in Indo-European languages offered for English, German, Hindi collected from Twitter. We participated in both Sub-task A, which aims to classify comments into two class, namely: Hate and Offensive (HOF), and Non- Hate and offensive (NOT), and Sub-task B, which aims to identify discrimination between Hate (HATE), profane (PRFN) and offensive (OFFN) comments. In order to address these tasks, we utilized pre-trained multi-lingual transformer (BERT) based neural network models and their fine-tuning. This resulted in a better performance on the validation, and test set. Our model achieved 0.88 weighted F1-score for English language in Sub-task A on testing dataset, and got 3rd rank on the leaderboard private test data having F1 Macro average of 0.5078. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Abusive Language; HASOC; Hate Speech; Multi-lingual Text},
	keywords = {Fires; Information retrieval; English languages; European languages; F1 scores; Fine tuning; Neural network model; Offensive languages; Speech identification; Test sets; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Roy2020128,
	author = {Roy, Sayar Ghosh and Narayan, Ujwal and Raha, Tathagata and Abid, Zubair and Varma, Vasudeva},
	title = {Leveraging multilingual transformers for hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {128 – 138},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102924055&partnerID=40&md5=4a113cdd1adafd98e3a2d603d5386b22},
	affiliations = {Information Retrieval and Extraction Lab, International Institute of Information Technology, Hyderabad, India},
	abstract = {Detecting and classifying instances of hate in social media text has been a problem of interest in Natural Language Processing in the recent years. Our work leverages state of the art Transformer language models to identify hate speech in a multilingual setting. Capturing the intent of a post or a comment on social media involves careful evaluation of the language style, semantic content and additional pointers such as hashtags and emojis. In this paper, we look at the problem of identifying whether a Twitter post is hateful and offensive or not. We further discriminate the detected toxic content into one of the following three classes: (a) Hate Speech (HATE), (b) Offensive (OFFN) and (c) Profane (PRFN). With a pre-trained multilingual Transformer-based text encoder at the base, we are able to successfully identify and classify hate speech from multiple languages. On the provided testing corpora, we achieve Macro F1 scores of 90.29, 81.87 and 75.40 for English, German and Hindi respectively while performing hate speech detection and of 60.70, 53.28 and 49.74 during fine-grained classification. In our experiments, we show the efficacy of Perspective API features for hate speech classification and the effects of exploiting a multilingual training scheme. A feature selection study is provided to illustrate impacts of specific features upon the architecture’s classification head. © 2020 Copyright for this paper by its authors},
	author_keywords = {HASOC 2020; Hate Speech Detection; Perspective API; XLM-RoBERTa},
	keywords = {Fires; Information retrieval; Natural language processing systems; Semantics; Social networking (online); Speech; Language model; Multilingual trainings; Multiple languages; NAtural language processing; Semantic content; Speech classification; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Deng2020,
	author = {Deng, Tao and Bai, Yang and Dai, Hongbing},
	title = {By1510 @ HaSpeeDe 2: Identification of hate speech for Italian language in social media data},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097569691&partnerID=40&md5=5b56e2dd4886a32f3f698f9ab16d0f91},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {Hate speech detection has become a crucial mission in many fields. This paper introduces the system of team By1510. In this work, we participate in the HaSpeeDe 2 (Hate Speech Detection) shared task which is organized within Evalita 2020(The Final Workshop of the 7th evaluation campaign). In order to obtain more abundant semantic information, we combine the original output of BERT-Ita and the hidden state outputs of BERT-Ita. We take part in task A. Our model achieves an F1 score of 77.66% (6/27) in the tweets test set and our model achieves an F1 score of 66.38% (14/27) in the news headlines test set. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Natural language processing systems; Semantics; Speech; F1 scores; Hidden state; Semantic information; Social media datum; Speech detection; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Veena2020377,
	author = {Veena, P.V. and Ramanan, Praveena and Remmiya Devi, G.},
	title = {CENMates@HASOC-Dravidian-CodeMix-FIRE2020: Offensive language identification on code-mixed social media comments},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {377 – 383},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102937919&partnerID=40&md5=082ad8635216374caaf9a32542636d9c},
	abstract = {This paper presents the working methodology and results on offensive language identification on Dravidian code-mixed data for the shared task of FIRE 2020. This task aims at identifying whether the comments written on social media platforms are offensive or not. The shared task contains Malayalam code-mixed comments, and Manglish (Malayalam written in Roman script) and Tanglish (Tamil written in Roman script) comments. Identification of hate speech on social media data has become an interesting domain of research and hence there are several ongoing researches happening for the same. The dataset for the HASOC task 1 has been retrieved from YouTube and for task 2 from YouTube and Twitter. TF-IDF vectors along with character level n-grams are passed as features to the proposed system for system development. We developed and evaluated four systems consisting of Logistic regression, XGBoost, Long Short Term Memory networks, and Attention networks. Amongst the tasks performed, the best results were obtained with an F1 score of 0.93 for Task 2 Malayalam. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Attention network; Code-mix; Hate; LSTM; Machine Learning; Manglish; Offensive Language Identification; Speech Offense; Tanglish},
	keywords = {Fires; Information retrieval; Logistic regression; Natural language processing systems; Character level; Malayalams; Offensive languages; Short term memory; Social media; Social media datum; Social media platforms; System development; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Zhu2020397,
	author = {Zhu, Yueying and Zhou, Xiaobing},
	title = {Zyy1510@HASOC-Dravidian-CodeMix-FIRE2020: An ensemble model for offensive language identification},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {397 – 403},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102945899&partnerID=40&md5=dd47ebc4a32a90fc7f39e4a63bc94d64},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {This paper reports the zyy1510 team’s work in the HASOC-Offensive Language Identification-Dravidian Code-Mixed FIRE 2020 shared task, whose goal is to identify the offensive language of the code-mixed text of comments/posts in Dravidian Languages (Malayalam-English and Tamil-English) collected from social media. This task is a message-level label classification task. Given a tweet or YouTube comments code-mixed text, and systems accurately classify it into offensive or not-offensive. We propose an ensemble model combines with different models to improve the F-1 value of the framework. The ensemble model is a combination of a BiLSTM (Bidirectional LSTM), an LSTM+Convolution, and a CNN (Convolution Neural Network) model. The proposed model have achieved an F-1 of 0.93 (ranked 3rd) in Malayalam-English of task1, and F-1 of 0.87 (ranked 3rd) and 0.67 (ranked 9th) in Tamil-English and Malayalam-English of task2, respectively. © 2020 Copyright for this paper by its authors.},
	keywords = {Convolution; Fires; Information retrieval; Natural language processing systems; Classification tasks; Convolution neural network; Ensemble modeling; Malayalams; Offensive languages; Social media; YouTube; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{dos da Silva2020,
	author = {dos da Silva, Adriano S.R. and Roman, Norton T.},
	title = {No place for hate speech @ HaSpeeDe 2: Ensemble to identify hate speech in Italian},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097552444&partnerID=40&md5=08447abce0c6c1f9a954cdfb7c7f2638},
	affiliations = {Schoool of Arts, Sciences and Humanities, University of Sao Paulo, Sao Paulo, Brazil},
	abstract = {In this article, we present the results of applying a Stacking Ensemble method to the problem of hate speech classification proposed in the main task of HaSpeeDe 2 at EVALITA 2020. The model was then compared to a Logistic Regression classifier, along with two other benchmarks defined by the competition's organising committee (an SVM with a linear kernel and a majority class classifier). Results showed our Ensemble to outperform the benchmarks to various degrees, both when testing in the same domain as training and in a different domain. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Logistic regression; Natural language processing systems; Support vector machines; Different domains; Ensemble methods; Linear kernel; Logistic regression classifier; Main tasks; Speech classification; Speech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Mishra2020139,
	author = {Mishra, Ankit Kumar and Saumya, Sunil and Kumar, Abhinav},
	title = {IIIT_DWD@HASOC 2020: Identifying offensive content in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {139 – 144},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102923125&partnerID=40&md5=5109801e1d64fe9789f81ea5dad3cab5},
	affiliations = {Magadh University, Bodh Gaya, India; Indian Institute of Information Technology, Dharwad, Karnataka, India; National Institute of Technology Patna, Patna, India},
	abstract = {Human behaviour remains the same whether it is a physical or cyber world. They express their emotions like happy, sad, angry, frustrated, bullying, and so on at both places. To express these emotions in cyberspace one of the way is a text post. The impact of these posts lasts forever on social media sites like Twitter, Facebook, and so on. Some posts that contain hate and offensive content affect victims badly and drag them into mental illness. The current paper aims to identify such hate and offensive posts using deep learning-based models such as CNN, and LSTMs. The Twitter posts in English, Hindi, and German languages used in this study are a part of HASOC-2020 competition. The model submitted for English sub-task A outperformed all other models submitted in the competitions by securing the 1st rank and F1-macro average score of 0.5152. © 2020 Copyright for this paper by its authors},
	author_keywords = {Deep learning; Hate speech; Machine learning; Offensive},
	keywords = {Behavioral research; Deep learning; Diseases; Fires; Information retrieval; Cyberspaces; European languages; German language; Human behaviours; Learning Based Models; Mental illness; Social media; Twitter posts; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Saha2020290,
	author = {Saha, Baidya Nath and Senapati, Apurbalal},
	title = {Hate speech and offensive content identification: LSTM based deep learning approach @ HASOC 2020},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {290 – 297},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102949118&partnerID=40&md5=04eadc3747193d3780c45ce84980f026},
	affiliations = {Concordia University of Edmonton, 7128 Ada Blvd NW, Edmonton, T5B 4E4, AB, Canada; Central Institute of Technology, Kokrajhar, BTAD, Assam, 783370, India},
	abstract = {The use of hate speech and offensive words is growing around the world. It includes the way of expression in vocal or written form that attacks an individual or a community based on their caste, religion, gender, ethnic groups, physical appearance, etc. The popular social media like Twitter, Facebook, What-sApp. Print media and visual media are being exploited as a platform for hate speech and offensive and increasingly found in the web. It is a serious matter for a healthy democracy, social stability, and peace. As a consequence, the social media platforms are trying to identify such content in the post for their preventing measure. FIRE 2020 organizes a track aiming to develop a system that will identify hate speech and offensive content in the document. In our system we (CONCORDIA_CIT_TEAM) have used the Long Short Term Memory (LSTM) for automatic hate speech and offensive content identification. Experimental results demonstrate that LSTM can successfully identify hate speech and offensive content in the documents of various languages successfully. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Hate Speech; LSTM; Offensive Content},
	keywords = {Fires; Information retrieval; Long short-term memory; Social networking (online); Speech; Speech recognition; Community-based; Content identifications; Ethnic groups; Learning approach; Social media; Social media platforms; Social stability; Visual media; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Kalaivani2020188,
	author = {Kalaivani, A. and Thenmozhi, D.},
	title = {SSN_NLP_MLRG@HASOC-FIRE2020: Multilingual hate speech and offensive content detection in Indo-European languages using ALBERT},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {188 – 194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102936161&partnerID=40&md5=a16089ee6944124e2cbf51322d265b1d},
	affiliations = {Department of CSE, SSN College of Engineering, OMR, Kalavakkam, Tamil Nadu, 603110, India},
	abstract = {This paper presents our system submitted the runs to HASOC 2020: Hate Speech and Offensive Content Identification in Indo-European Languages. The detection of hate speech and offensive content in social media has much attention in recent studies. Moreover, the identification of hate speech content in various languages moves forward in the field of Natural language processing. We have participated in task1, task2 for the English, German, and Hindi (code-mixed) languages. We have adapted and fine-tuned the pre-trained ALBERT models for all the three languages. We also employed the ULMFiT framework to categorize the hate and offensive comments. We use cross-lingual translation to enrich the training data for Hindi and German languages. Our team achieved the macro-averaged F1-scores 0.88, 0.76, 0.41 in task1 for the English, German, Hindi, and 0.53, 0.50, 0.30 in task2 for the English, German, Hindi language. The final leaderboard decided to calculate the results by using 15% of private data. Our team obtained the macro-averaged F1-scores 0.4979, 0.5025, and 0.3971 in task1 for the English, German, Hindi, and 0.2305, 0.2920, 0.2063 in task2 for the English, German, Hindi language. Our team achieved the 2nd rank on the private leaderboard test data in task2 for the German language. © 2020 Copyright for this paper by its authors},
	author_keywords = {Cross-lingual translation; Hate speech detection; Language modeling; Offensive language detection; Transformers},
	keywords = {Fires; Information retrieval; Natural language processing systems; Content detection; Content identifications; Cross-lingual; European languages; German language; NAtural language processing; Speech content; Training data; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Nayel20202086,
	author = {Nayel, Hamada A.},
	title = {NAYEL at SemEval-2020 Task 12: TF/IDF-Based Approach for Automatic Offensive Language Detection in Arabic Tweets},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2086 – 2089},
	doi = {10.18653/v1/2020.semeval-1.276},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121935369&doi=10.18653%2fv1%2f2020.semeval-1.276&partnerID=40&md5=39b198effa26dd7bba8a3935f597c0e5},
	affiliations = {Department of Computer Science, Faculty of Computers and Artificial Intelligence, Benha University, Egypt},
	abstract = {In this paper, we present the system submitted to “SemEval-2020 Task 12”. The proposed system aims at automatically identify the Offensive Language in Arabic Tweets. A machine learning based approach has been used to design our system. We implemented a linear classifier with Stochastic Gradient Descent (SGD) as optimization algorithm. Our model reported 84.20%, 81.82% f1-score on development set and test set respectively. The best performed system and the system in the last rank reported 90.17% and 44.51% f1-score on test set respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Gradient methods; Stochastic systems; F1 scores; Language detection; Learning-based approach; Linear classifiers; Machine-learning; Offensive languages; Optimization algorithms; Stochastic gradient descent; Test sets; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Otiefy20202237,
	author = {Otiefy, Yasser and Abdelmalek, Ahmed and Hosary, Islam El},
	title = {WOLI at SemEval-2020 Task 12: Arabic Offensive Language Identification on Different Twitter Datasets},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2237 – 2243},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117313253&partnerID=40&md5=436eb7e48052b64abcf69723f0ec3d0d},
	affiliations = {WideBot},
	abstract = {Communicating through social platforms has become one of the principal means of personal communications and interactions. Unfortunately, healthy communication is often interfered by offensive language that can have damaging effects on the users. A key to fight offensive language on social media is the existence of an automatic offensive language detection system. This paper presents the results and the main findings of SemEval-2020, Task 12 OffensEval Sub-task A Zampieri et al. (2020), on Identifying and categorising Offensive Language in Social Media. The task was based on the Arabic OffensEval dataset Mubarak et al. (2020). In this paper, we describe the system submitted by WideBot AI Lab for the shared task which ranked 10th out of 52 participants with Macro-F1 86.9% on the golden dataset under CodaLab username "yasserotiefy". We experimented with various models and the best model is a linear SVM in which we use a combination of both character and word n-grams. We also introduced a neural network approach that enhanced the predictive ability of our system that includes CNN, highway network, Bi-LSTM, and attention layers. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Long short-term memory; Multilayer neural networks; Semantics; Support vector machines; Best model; Communication and interaction; Damaging effects; Detection system; Healthy communications; Language detection; Language identification; Offensive languages; Social media; Subtask; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Reddy2020274,
	author = {Reddy, Varsha and Telidevara, Surendra},
	title = {HateDetectors at HASOC 2020: Hate speech detection using classical machine learning and transfer learning based approaches},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {274 – 282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102952071&partnerID=40&md5=c6f183866102b83ef2f0e1af8fd1d826},
	abstract = {In this paper, we describe our models submitted to the HASOC shared task conducted as part of FIRE 2020. We have presented two directions to approach the problem of hate speech detection which are based on the advancements in the field of natural language processing. We present classical machine learning approaches using Support Vector Machine (SVM) and transfer learning approaches at sentence level using BERT. We have shown through experimental results that Transfer learning based approaches beat Machine learning based approaches in identifying the nuances of hate speech in a sentence. We have performed experiments on the English and Hindi datasets. On the public test dataset provided, we obtain a macro F1 score of 0.90 and 0.67 on English and Hindi languages respectively for subtask A and scores of 0.54 and 0.44 for subtask B. We also observe a difference of around 0.05 macro F1 score between BERT based models and SVM based models on English public test data, while we see only a difference of 0.01 on Hindi public test data in subtask A. We have highlighted the importance of a monolingual model over a multi lingual BERT based model for hate speech detection. We also highlight the importance of having a large, balanced training dataset on model performance for hate speech detection. © 2020 Copyright for this paper by its authors.},
	author_keywords = {BERT; CEUR-WS; Hate Speech Detection; Machine Learning; SVM; Transfer Learning},
	keywords = {Fires; Information retrieval; Large dataset; Natural language processing systems; Speech; Speech recognition; Statistical tests; Support vector machines; Transfer learning; Learning approach; Learning-based approach; Machine learning approaches; Model performance; NAtural language processing; Sentence level; Speech detection; Training dataset; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Rajalakshmi2020304,
	author = {Rajalakshmi, Ratnavel and Yashwanth Reddy, B.},
	title = {DLRG@HASOC 2020: A hybrid approach for hate and offensive content identification in multilingual tweets},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {304 – 310},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102959265&partnerID=40&md5=c026c999b8bb16cce486f9e3c91fb3bb},
	affiliations = {School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India},
	abstract = {In recent times, most of the people prefer social media platforms as a communication tool and express their views publicly and anonymously. Hate speech and posting offensive contents has become a major issue nowadays. To handle these problems, automated methods are necessary that can help to analyse the social media posts and to identify the hate speech. Existing methods do not focus more on multilingual posts and it poses more challenges, not only due to the linguistic properties but also due to the class imbalance problem. The task of identifying hate and offensive content posted in Hindi or German languages has the same issues. To address the problem of class imbalance, we have combined a over sampling technique with a suitable feature weighting method. In the proposed approach, Multi-class imbalance-based feature selection method is combined with an SVM classifier to classify the tweet as a hate speech or not. This work was submitted to Hate and Offensive Content Identification (HASOC) task@FIRE2020 and scored third rank. We have achieved an accuracy of 80% and 72% on the released German and Hindi language tweets respectively. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Class Imbalanced data; Hate Speech Detection; Multilingual Tweets; SVM},
	keywords = {Information retrieval; Social networking (online); Automated methods; Class imbalance problems; Communication tools; Content identifications; Feature selection methods; Feature weighting; Linguistic properties; Social media platforms; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Corazza2020943,
	author = {Corazza, Michele and Menini, Stefano and Cabrio, Elena and Tonelli, Sara and Villata, Serena},
	title = {Hybrid emoji-based masked language models for zero-shot abusive language detection},
	year = {2020},
	journal = {Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020},
	pages = {943 – 949},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107289845&partnerID=40&md5=551b8ee8ef4ff666688d5f9727a507a2},
	affiliations = {University of Bologna, Italy; Fondazione Bruno Kessler, Trento, Italy; Université Côte d’Azur, CNRS, Inria, I3S, France},
	abstract = {Recent studies have demonstrated the effectiveness of cross-lingual language model pretraining on different NLP tasks, such as natural language inference and machine translation. In our work, we test this approach on social media data, which are particularly challenging to process within this framework, since the limited length of the textual messages and the irregularity of the language make it harder to learn meaningful encodings. More specifically, we propose a hybrid emoji-based Masked Language Model (MLM) to leverage the common information conveyed by emojis across different languages and improve the learned cross-lingual representation of short text messages, with the goal to perform zero-shot abusive language detection. We compare the results obtained with the original MLM to the ones obtained by our method, showing improved performance on German, Italian and Spanish. © 2020 Association for Computational Linguistics},
	keywords = {Cross-lingual; Language detection; Language inference; Language model; Learn+; Machine translations; Natural languages; Pre-training; Short text messages; Social media datum; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: Findings of the Association for Computational Linguistics, ACL 2020: EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172733}
}

@CONFERENCE{Plaza-Del-Arco20201622,
	author = {Plaza-Del-Arco, Flor Miriam and Molina-González, M. Dolores and Ureña-López, L. Alfonso and Martín-Valdivia, M. Teresa},
	title = {SINAI at SemEval-2020 Task 12: Offensive language identification exploring transfer learning models},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1622 – 1627},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123610976&partnerID=40&md5=5cd204e700289fce7db92d39f95921cb},
	affiliations = {Department of Computer Science, Advanced Studies Center in ICT (CEATIC), Universidad de Jaén, Campus Las Lagunillas, Jaén, 23071, Spain},
	abstract = {This paper describes the participation of SINAI team at Task 12: OffensEval 2: Multilingual Offensive Language Identification in Social Media. In particular, the participation in Sub-task A in English which consists of identifying tweets as offensive or not offensive. We preprocess the dataset according to the language characteristics used on social media. Then, we select a small set from the training set provided by the organizers and fine-tune different Transformer-based models in order to test their effectiveness. Our team ranks 20th out of 85 participants in Subtask-A using the XLNet model. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Electric transformer testing; Natural language processing systems; Semantics; Language identification; Learning models; Offensive languages; Preprocess; Social media; Subtask; Training sets; Transfer learning; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Paul20201925,
	author = {Paul, Sayanta and Saha, Sriparna and Hasanuzzaman, Mohammed},
	title = {CyberTronics at SemEval-2020 Task 12: Multilingual Offensive Language Identification over Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1925 – 1931},
	doi = {10.18653/v1/2020.semeval-1.253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123928051&doi=10.18653%2fv1%2f2020.semeval-1.253&partnerID=40&md5=4f82d0a4a6d9d76a3445482064abdeb7},
	affiliations = {Dept. of CSE, IIT Patna, India; Dept. of CS, CIT Cork, Ireland},
	abstract = {The SemEval-2020 Task 12 (OffensEval) challenge focuses on detection of signs of offensiveness using posts or comments over social media. This task has been organized for several languages, e.g., Arabic, Danish, English, Greek and Turkish. It has featured three related sub-tasks for English language: sub-task A was to discriminate between offensive and non-offensive posts, the focus of sub-task B was on the type of offensive content in the post and finally, in sub-task C, proposed systems had to identify the target of the offensive posts. The corpus for each of the languages is developed using the posts and comments over Twitter, a popular social media platform. We have participated in this challenge and submitted results for different languages. The current work presents different machine learning and deep learning techniques and analyzes their performance for offensiveness prediction which involves various classifiers and feature engineering schemes. The experimental analysis on the training set shows that SVM using language specific pre-trained word embedding (Fasttext) outperforms the other methods. Our system achieves a macro-averaged F1 score of 0.45 for Arabic language, 0.43 for Greek language and 0.54 for Turkish language. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Deep learning; Learning systems; Social networking (online); 'current; English languages; Language identification; Learning techniques; Machine-learning; Offensive languages; Social media; Social media platforms; Subtask; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zampieri20201425,
	author = {Zampieri, Marcos and Nakov, Preslav and Rosenthal, Sara and Atanasova, Pepa and Karadzhov, Georgi and Mubarak, Hamdy and Derczynski, Leon and Pitenis, Zeses and Çöltekin, Çagrı},
	title = {SemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media (OffensEval 2020)},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1425 – 1447},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123932428&partnerID=40&md5=29f8e8b10a0914bcd2f754e9381bd9c6},
	affiliations = {Rochester Institute of Technology, United States; Qatar Computing Research Institute, Qatar; IBM Research, United States; University of Copenhagen, Denmark; University of Cambridge, United Kingdom; IT University, Copenhagen, Denmark; University of Wolverhampton, United Kingdom; University of Tübingen, Germany},
	abstract = {We present the results and the main findings of SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media (OffensEval-2020). The task included three subtasks corresponding to the hierarchical taxonomy of the OLID schema from OffensEval-2019, and it was offered in five languages: Arabic, Danish, English, Greek, and Turkish. OffensEval-2020 was one of the most popular tasks at SemEval-2020, attracting a large number of participants across all subtasks and languages: a total of 528 teams signed up to participate in the task, 145 teams submitted official runs on the test data, and 70 teams submitted system description papers. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Hierarchical taxonomy; Language identification; Offensive languages; Social media; Subtask; System description; Test data; Turkishs; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 194; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Ibrahim20201881,
	author = {Ibrahim, Mai and Torki, Marwan and El-Makky, Nagwa},
	title = {AlexU-BackTranslation-TL at SemEval-2020 Task 12: Improving Offensive Language Detection using Data Augmentation and Transfer Learning},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1881 – 1890},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123959101&partnerID=40&md5=15e0ffb473c50d567186b5008eb2bb72},
	affiliations = {Computer and Systems Engineering Department, Alexandria University, Alexandria, Egypt},
	abstract = {Social media platforms, online news commenting spaces, and many other public forums have become widely known for issues of abusive behavior such as cyber-bullying and personal attacks. In this paper, we use the annotated tweets of Offensive Language Identification Dataset (OLID) to train three levels of deep learning classifiers to solve the three sub-tasks associated with the dataset. Sub-task A is to determine if the tweet is toxic or not. Then, for offensive tweets, sub-task B requires determining whether the toxicity is targeted. Finally, for sub-task C, we predict the target of the offense; i.e. a group, individual or other entity. In our solution, we tackle the problem of class imbalance in the dataset by using back translation for data augmentation and utilizing fine-tuned BERT model in an ensemble of deep learning classifiers. We used this solution to participate in the three English sub-tasks of SemEval-2020 task 12. The proposed solution achieved 0.91393, 0.6300 and 0.57607 macro F1-average in sub-tasks A, B and C respectively. We achieved the 8th, 14th and 21st places for sub-tasks A, B and C respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Semantics; Translation (languages); Back translations; Data augmentation; Language detection; Learning classifiers; Offensive languages; Online news; Public forums; Social media platforms; Subtask; Transfer learning; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Anwar20202177,
	author = {Anwar, Talha and Beg, Mirza Omer},
	title = {TAC at SemEval-2020 Task 12: Ensembling Approach for Multilingual Offensive Language Identification in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2177 – 2182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123912333&partnerID=40&md5=6aaffabf8349e840b73d9bdc399d61ce},
	affiliations = {Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Pakistan},
	abstract = {Usage of offensive language on social media is getting more common these days, and there is a need of a mechanism to detect it and control it. This paper deals with offensive language detection in five different languages; English, Arabic, Danish, Greek and Turkish. We presented an almost similar ensemble pipeline comprised of machine learning and deep learning models for all five languages. Three machine learning and four deep learning models were used in the ensemble. In the OffensEval-2020 competition our model achieved F1-score of 0.85, 0.74, 0.68, 0.81, and 0.9 for Arabic, Turkish, Danish, Greek and English language tasks respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Deep learning; Semantics; Arabic languages; English languages; F1 scores; Language detection; Language identification; Learning models; Offensive languages; Social media; Turkish language; Turkishs; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Casula20201539,
	author = {Casula, Camilla and Aprosio, Alessio Palmero and Menini, Stefano and Tonelli, Sara},
	title = {FBK-DH at SemEval-2020 Task 12: Using Multi-channel BERT for Multilingual Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1539 – 1545},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123941534&partnerID=40&md5=adb052218b4010ad3cf57f0986176fad},
	affiliations = {Dept. of Linguistics and Philology, Uppsala University, Sweden; Fondazione Bruno Kessler (FBK), Trento, Italy},
	abstract = {In this paper we present our submission to subtask A at SemEval 2020 Task 12: Multilingual Offensive Language Identification in Social Media (OffensEval2). For Danish, Turkish, Arabic and Greek, we develop an architecture based on transfer learning and relying on a two-channel BERT model, in which the English BERT and the multilingual one are combined after creating a machine-translated parallel corpus for each language in the task. For English, instead, we adopt a more standard, single-channel approach. We find that, in a multilingual scenario, with some languages having small training data, using parallel BERT models with machine translated data can give systems more stability, especially when dealing with noisy data. The fact that machine translation on social media data may not be perfect does not hurt the overall classification performance. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Social networking (online); Translation (languages); Architecture-based; Language detection; Language identification; Multi channel; Offensive languages; Social media; Subtask; Transfer learning; Turkishs; Two channel; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Arora2020362,
	author = {Arora, Gaurav},
	title = {Gauravarora@HASOC-Dravidian-CodeMixFIRE2020: Pre-training ULMFiT on synthetically generated code-mixed data for hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {362 – 369},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102921999&partnerID=40&md5=1b6f644c0a6873ec1220d673d4b7d382},
	affiliations = {Jio Haptik Technologies Limited, India},
	abstract = {This paper describes the system submitted to Dravidian-Codemix-HASOC2020: Hate Speech and Offensive Content Identification in Dravidian languages (Tamil-English and Malayalam-English). The task aims to identify offensive language in code-mixed dataset of comments/posts in Dravidian languages collected from social media. We participated in both Sub-task A, which aims to identify offensive content in mixed-script (mixture of Native and Roman script) and Sub-task B, which aims to identify offensive content in Roman script, for Dravidian languages. In order to address these tasks, we proposed pre-training ULMFiT on synthetically generated code-mixed data, generated by modelling code-mixed data generation as a Markov process using Markov chains. Our model achieved 0.88 weighted F1-score for code-mixed Tamil-English language in Sub-task B and got 2nd rank on the leader-board. Additionally, our model achieved 0.91 weighted F1-score (4th Rank) for mixed-script Malayalam-English in Sub-task A and 0.74 weighted F1-score (5th Rank) for code-mixed Malayalam-English language in Sub-task B. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Code-mix data; Hate speech; Markov chains; Offensive language; ULMFiT},
	keywords = {Clustering algorithms; Fires; Information retrieval; Markov chains; Content identifications; English languages; Mixed data; Modelling codes; Offensive languages; Pre-training; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Krumbiegel2020429,
	author = {Krumbiegel, Theresa},
	title = {FKIE - Offensive language detection on Twitter at GermEval 2019},
	year = {2020},
	journal = {Proceedings of the 15th Conference on Natural Language Processing, KONVENS 2019},
	pages = {429 – 433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103439384&partnerID=40&md5=e508be717b436214cce6fb72f61fce78},
	affiliations = {Fraunhofer FKIE, Fraunhoferstraße 20, Wachtberg, 53343, Germany},
	abstract = {We describe our submissions to the Shared Task on Identification of Offensive Language at GermEval 2019. We take part in all three subtasks, utilizing a Support Vector Machine (SVM) for subtasks 1 and 2, and a Long short-term memory (LSTM) neural net as well as a Convolutional neural net (CNN) for subtask 3. We obtained a macro-F1 score of 75.21 for subtask 1, 55.42 for subtask 2 and 64.20 for subtask 3 on a development set that was split from the overall training set provided by the organisers. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.},
	keywords = {Convolutional neural networks; Long short-term memory; Support vector machines; F1 scores; Offensive languages; Subtask; Subtasks; Training sets; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th Conference on Natural Language Processing, KONVENS 2019; Conference date: 9 October 2019 through 11 October 2019; Conference code: 167846}
}

@CONFERENCE{Ray2020168,
	author = {Ray, Biswarup and Garain, Avishek},
	title = {JU at HASOC 2020: Deep learning with RoBERTa and random forest for hate speech and offensive content identification in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {168 – 174},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102944191&partnerID=40&md5=648249919dc95403cf192c5e28c35fd7},
	affiliations = {Department of Computer Science and Engineering, Jadavpur University, Kolkata, West Bengal, 700032, India},
	abstract = {The identification of Hate Speech in Social Media has received much attention in research recently. There has been an ever-growing increase in demand particularly for research in languages other than English. The Hate Speech and Offensive Content (HASOC) track has created resources for Hate Speech Identification in three different languages namely Hindi, German, and English. We have participated in both Sub-tasks A and B of the 2020 shared task on hate speech and offensive content identification in Indo-European languages. Our approach relies on a combined model of multilingual RoBERTa (a Robustly Optimized BERT Pretraining Approach) model with pre-trained vectors and a Random Forest model using Word2Vec, TF-IDF, and other textual features as input. Our system has achieved a maximum Macro F1-score of 50.28% for English Sub-task A which is quite satisfactory relative to the performance of other systems and secured 8th position among participating teams. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Hate Speech; Random Forest; RoBERTa; TF-IDF; Word2Vec},
	keywords = {Decision trees; Fires; Information retrieval; Random forests; Speech; Speech recognition; Combined model; Content identifications; European languages; Participating teams; Random forest modeling; Social media; Speech identification; Textual features; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Ranasinghe20205838,
	author = {Ranasinghe, Tharindu and Zampieri, Marcos},
	title = {Multilingual offensive language identification with cross-lingual embeddings},
	year = {2020},
	journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {5838 – 5844},
	doi = {10.18653/v1/2020.emnlp-main.470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112273024&doi=10.18653%2fv1%2f2020.emnlp-main.470&partnerID=40&md5=57ebd965c857966b392e39439d164969},
	affiliations = {University of Wolverhampton, Wolverhampton, United Kingdom; Rochester Institute of Technology, Rochester, NY, United States},
	abstract = {Offensive content is pervasive in social media and a reason for concern to companies and government organizations. Several studies have been recently published investigating methods to detect the various forms of such content (e.g. hate speech, cyberbulling, and cyberaggression). The clear majority of these studies deal with English partially because most annotated datasets available contain English data. In this paper, we take advantage of English data available by applying cross-lingual contextual word embeddings and transfer learning to make predictions in languages with less resources. We project predictions on comparable data in Bengali, Hindi, and Spanish and we report results of 0.8415 F1 macro for Bengali, 0.8568 F1 macro for Hindi, and 0.7513 F1 macro for Spanish. Finally, we show that our approach compares favorably to the best systems submitted to recent shared tasks on these three languages, confirming the robustness of cross-lingual contextual embeddings and transfer learning for this task. © 2020 Association for Computational Linguistics},
	keywords = {Computational linguistics; Annotated datasets; Bengalis; Contextual words; Cross-lingual; Embeddings; Government organizations; Language identification; Offensive languages; Social media; Transfer learning; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 91; Conference name: 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172724; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Li20202067,
	author = {Li, Junyi and Zhou, Xiaobing and Zhang, Zichen},
	title = {Lee at SemEval-2020 Task 12: A BERT model based on the maximum self-ensemble strategy for identifying offensive language},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2067 – 2072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123910947&partnerID=40&md5=8e3889a6ee5c099603e10f0da6438148},
	affiliations = {School of Information Science and Engineering, Yunnan University, Kunming, 65091, China},
	abstract = {This article describes the system submitted to SemEval 2020 Task 12: OffensEval 2020. This task aims to identify and classify offensive languages in different languages on social media. We only participate in the English part of subtask A, which aims to identify offensive languages in English. To solve this task, we propose a BERT model system based on the transform mechanism, and use the maximum self-ensemble to improve model performance. Our model achieved a macro F1 score of 0.913(ranked 13/82) in subtask A. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Ensemble strategies; F1 scores; Model-based OPC; Modeling performance; Modelling systems; Offensive languages; Social media; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Dai20202060,
	author = {Dai, Wenliang and Yu, Tiezheng and Liu, Zihan and Fung, Pascale},
	title = {Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-Task Learning for Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2060 – 2066},
	doi = {10.18653/v1/2020.semeval-1.272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123956589&doi=10.18653%2fv1%2f2020.semeval-1.272&partnerID=40&md5=5d4138439d7ea5ac11fc698471f84d04},
	affiliations = {Center for Artificial Intelligence Research (CAiRE), Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong},
	abstract = {Nowadays, offensive content in social media has become a serious problem, and automatically detecting offensive language is an essential task. In this paper, we build an offensive language detection system, which combines multi-task learning with BERT-based models. Using a pretrained language model such as BERT, we can effectively learn the representations for noisy text in social media. Besides, to boost the performance of offensive language detection, we leverage the supervision signals from other related tasks. In the OffensEval-2020 competition, our model achieves 91.51% F1 score in English Sub-task A, which is comparable to the first place (92.23% F1). An empirical analysis is provided to explain the effectiveness of our approaches. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Learning systems; Social networking (online); Detection system; F1 scores; Language detection; Language model; Learn+; Multitask learning; Offensive languages; Performance; Social media; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Renjit2020344,
	author = {Renjit, Sara and Idicula, Sumam Mary},
	title = {CUSATNLP@HASOC-Dravidian-CodeMix-FIRE2020: Identifying Offensive language from Manglish tweets},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {344 – 350},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102955251&partnerID=40&md5=80da04ecd9974a577efdb05efa76fd06},
	affiliations = {Department of Computer Science, Cochin University of Science and Technology, Kerala, India; Department of Computer Science, Cochin University of Science and Technology, Kerala, India},
	abstract = {With the popularity of social media, communications through blogs, Facebook, Twitter, and other platforms have increased. Initially, English was the only medium of communication. Fortunately, now we can communicate in any language. It has led to people using English and their own native or mother tongue language in a mixed form. Sometimes, comments in other languages have English transliterated format or other cases; people use the intended language scripts. Identifying sentiments and offensive content from such code mixed tweets is a necessary task in these times. We present a working model submitted for Task2 of the sub-track HASOC Offensive Language Identification- DravidianCodeMix in Forum for Information Retrieval Evaluation, 2020. It is a message level classification task. An embedding model-based classifier identifies offensive and not offensive comments in our approach. We applied this method in the Manglish dataset provided along with the sub-track. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Code-Mixed; Embeddings; Manglish; Offensive Language; Social Media Texts},
	keywords = {Information retrieval; Social networking (online); Classification tasks; Facebook; Model-based classifiers; Mother tongues; Offensive languages; Social media; Working models; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Bansal20201018,
	author = {Bansal, Srijan and Vishal, G. and Suhane, Ayush and Patro, Jasabanta and Mukherjee, Animesh},
	title = {Code-switching patterns can be an effective route to improve performance of downstream NLP applications: A case study of humour, sarcasm and hate speech detection},
	year = {2020},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {1018 – 1023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109954392&partnerID=40&md5=b1c2f684b6a1aa417efdf529871e7a0f},
	affiliations = {Indian Institute of Technology, West Bengal, Kharagpur, 721302, India},
	abstract = {In this paper we demonstrate how code-switching patterns can be utilised to improve various downstream NLP applications. In particular, we encode different switching features to improve humour, sarcasm and hate speech detection tasks. We believe that this simple linguistic observation can also be potentially helpful in improving other similar NLP applications. © 2020 Association for Computational Linguistics},
	keywords = {Codes (symbols); Computational linguistics; Speech recognition; Case-studies; Code-switching; Detection tasks; Down-stream; Improve performance; Simple++; Speech detection; Switching patterns; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172533}
}

@CONFERENCE{Wang20206366,
	author = {Wang, Kunze and Lu, Dong and Han, Soyeon Caren and Long, Siqu and Poon, Josiah},
	title = {Detect All Abuse! Toward Universal Abusive Language Detection Models},
	year = {2020},
	journal = {COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference},
	pages = {6366 – 6376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108814491&partnerID=40&md5=4cff7f9d66d87b9f8320720b7ac0c789},
	affiliations = {The University of Sydney, Sydney, Australia},
	abstract = {Online abusive language detection (ALD) has become a societal issue of increasing importance in recent years. Several previous works in online ALD focused on solving a single abusive language problem in a single domain, like Twitter, and have not been successfully transferable to the general ALD task or domain. In this paper, we introduce a new generic ALD framework, MACAS, which is capable of addressing several types of ALD tasks across different domains. Our generic framework covers multi-aspect abusive language embeddings that represent the target and content aspects of abusive language and applies a textual graph embedding that analyses the user’s linguistic behaviour. Then, we propose and use the cross-attention gate flow mechanism to embrace multiple aspects of abusive language. Quantitative and qualitative evaluation results show that our ALD algorithm rivals or exceeds the six state-of-the-art ALD algorithms across seven ALD datasets covering multiple aspects of abusive language and different online community domains. The code can be downloaded from https://github.com/usydnlp/MACAS. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.},
	keywords = {Computational linguistics; Social networking (online); Detection algorithm; Detection framework; Detection models; Detection tasks; Different domains; Generic frameworks; Language detection; Language problems; Single domains; Societal issues; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886}
}

@CONFERENCE{Huang2020232,
	author = {Huang, Bo and Bai, Yang},
	title = {Hub@HASOC 2020: Fine-tuning pre-trained transformer language models for hate speech and offensive content identification in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {232 – 240},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102948047&partnerID=40&md5=b63a7fab1a1442a6443b753821fcc358},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {This paper presents the system description of the Hub team participating in HASOC2020: Hate Speech and Offensive Content Identification in Indo-European Languages. The focus of this shared task research is to identify hateful or offensive content in English, German, and Hindi comments posted on Twitter. Each language consists of two tasks, the first of which can be seen as a coarse-grained binary classification task, and the other can be seen as a fine-grained quaternary classification task. We only participated in the English task and the German task. According to our analysis of the task description and data set, we use two fine-tuned pre-trained transformer models ALBERT and BERT for the English task and the German task. In this paper, we will discuss the experiments and results of the English task and the German task. © 2020 Copyright for this paper by its authors.},
	author_keywords = {ALBERT; BERT; Hate Speech; Offensive Content; Pre-trained transformer models},
	keywords = {Fires; Information retrieval; Binary classification; Classification tasks; Content identifications; European languages; Language model; System description; Task description; Transformer models; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Aroyehun2020331,
	author = {Aroyehun, Segun Taofeek and Gelbukh, Alexander},
	title = {NLP-CIC at HASOC 2020: Multilingual offensive language detection using all-in-one model},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {331 – 335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102960037&partnerID=40&md5=b1be936eb9a14d8209666cd2b1082cb1},
	affiliations = {CIC, Instituto Politécnico Nacional Mexico City, Mexico},
	abstract = {We describe our deep learning model submitted to the HASOC 2020 shared task on detection of offensive language in social media in three Indo-European languages: English, German, and Hindi. We fine-tune a pre-trained multilingual encoder on the combination of data provided for the competition. Our submission received a competitive macro- average F1 score of 0.4980 on the English Subtask A as well as comparatively strong performance on the German data. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Deep learning; Multilingual; Offensive content identification; Text classification},
	keywords = {Deep learning; Information retrieval; European languages; F1 scores; Learning models; Offensive languages; Social media; Subtask; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Kumar2020266,
	author = {Kumar, Abhinav and Saumya, Sunil and Singh, Jyoti Prakash},
	title = {NITP-AI-NLP@HASOC-FIRE2020: Fine tuned BERT for the Hate Speech and Offensive Content identification from social media},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {266 – 273},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102920278&partnerID=40&md5=a750dca0d7d28ca82b76b310cd3983ab},
	affiliations = {National Institute of Technology, Patna, India; Indian Institute of Information Technology, Dharwad, Karnataka, India; National Institute of Technology Patna, Patna, India},
	abstract = {The current paper identifies the offensive and hate content in three datasets of English, Hindi, and German. The dataset appeared in HASOC-2020 track. A fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model is proposed to identify hate and offensive contents from the social media posts. The experimental results show that the proposed BERT model achieved significant performance in identifying hate and offensive content. For English subtasks A and B F1-score reported were 0.5031 and 0.1623, for Hindi subtasks A and B F1-score reported were 0.5300 and 0.0940 and for German subtasks A and B F1-score reported were 0.5109 and 0.1214 respectively. © 2020 Copyright for this paper by its authors},
	author_keywords = {BERT; Hate speech; Offensive contents; Social media},
	keywords = {Fires; Information retrieval; Content identifications; F1 scores; Social media; Subtasks; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Sanguinetti2020,
	author = {Sanguinetti, Manuela and Comandini, Gloria and di Nuovo, Elisa and Frenda, Simona and Stranisci, Marco and Bosco, Cristina and Caselli, Tommaso and Patti, Viviana and Russo, Irene},
	title = {HaSpeeDe 2 @ EVALITA2020: Overview of the EVALITA 2020 hate speech detection task},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097562849&partnerID=40&md5=ed847f4164efc17fc626d71a06568252},
	affiliations = {Università degli Studi di Cagliari, Italy; Università degli Studi di Trento, Italy; Università degli Studi di Torino, Italy; University of Groningen, Netherlands; ILC-CNR Pisa, Italy},
	abstract = {The Hate Speech Detection (HaSpeeDe 2) task is the second edition of a shared task on the detection of hateful content in Italian Twitter messages. HaSpeeDe 2 is composed of a Main task (hate speech detection) and two Pilot tasks, (stereotype and nominal utterance detection). Systems were challenged along two dimensions: (i) time, with test data coming from a different time period than the training data, and (ii) domain, with test data coming from the news domain (i.e., news headlines). Overall, 14 teams participated in the Main task, the best systems achieved a macro F1-score of 0.8088 and 0.7744 on the in-domain in the out-of-domain test sets, respectively; 6 teams submitted their results for Pilot task 1 (stereotype detection), the best systems achieved a macro F1-score of 0.7719 and 0.7203 on in-domain and out-of-domain test sets. We did not receive any submission for Pilot task 2. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Natural language processing systems; Speech; Main tasks; News domain; Pilot tasks; Speech detection; Time-periods; Training data; Two-dimension; Utterance detections; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Anusha2020253,
	author = {Anusha, M.D. and Shashirekha, H.L.},
	title = {An ensemble model for hate speech and offensive content identification in Indo-European languages},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {253 – 259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102950900&partnerID=40&md5=1304e9b806f249cfb931ab9805faddcf},
	affiliations = {Department of Computer Science, Mangalore University, Mangalore, Karnataka, India},
	abstract = {Hate speech and offensive content is an attack that is coordinated towards a gathering of individuals or society based on their religion, gender, color, and so on and poses a threat to society. This type of content is increasing day by day with the increasing use of social media such as Facebook, WhatsApp, Instagram, etc. Identifying such texts at the earliest to avoid them getting viral on social media creating a negative impact on society is the need of the day. Analyzing these voluminous and every growing text manually is challenging, time-consuming, and error-prone. Further, much of the existing works to identify hate speech and offensive content focuses on high resource languages such as English, Spanish, etc. In this paper, we, team MUM, describe the work submitted to Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) 2020, a shared task in Forum for Information Retrieval Evaluation (FIRE) 2020. In the proposed methodology, we combine CountVectorizer and TF-IDF transformer with additional text-based features to build an ensemble of Gradient Boosting, Random Forest and XGBoost classifiers, with soft voting. The proposed approaches obtained 5th, 14th, 7th, 3rd, 13th and 6th rank for English, German and Hindi Subtasks A and B respectively. © 2020 Copyright for this paper by its authors},
	author_keywords = {Ensemble learning; Machine learning; Text Classification},
	keywords = {Decision trees; Fires; Information retrieval; Social networking (online); Content identifications; Ensemble modeling; Error prones; European languages; Gradient boosting; Social media; Soft voting; Text-based features; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Ghadery20202073,
	author = {Ghadery, Erfan and Moens, Marie-Francine},
	title = {LIIR at SemEval-2020 Task 12: A Cross-Lingual Augmentation Approach for Multilingual Offensive Language Identification},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2073 – 2079},
	doi = {10.18653/v1/2020.semeval-1.274},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123929160&doi=10.18653%2fv1%2f2020.semeval-1.274&partnerID=40&md5=d494974e8f573fcb53f66449f7807393},
	affiliations = {Department of Computer Science, KU Leuven, Belgium},
	abstract = {This paper presents our system entitled 'LIIR' for SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media (OffensEval 2). We have participated in Subtask A for English, Danish, Greek, Arabic, and Turkish languages. We adapt and fine-tune the BERT and multilingual Bert models made available by Google AI for English and non-English languages respectively. For the English language, we use a combination of two fine-tuned BERT models. For other languages, we propose a cross-lingual augmentation approach in order to enrich training data and we use multilingual BERT to obtain sentence representations. LIIR achieved rank 14/38, 18/47, 24/86, 24/54, and 25/40 in Greek, Turkish, English, Arabic, and Danish languages, respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Arabic languages; Cross-lingual; English languages; Google+; Language identification; Non-English languages; Offensive languages; Social media; Subtask; Turkish language; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ravikiran20201961,
	author = {Ravikiran, Manikandan and Muljibhai, Amin Ekant and Miyoshi, Toshinori and Ozaki, Hiroaki and Koreeda, Yuta and Sakata, Masayuki},
	title = {Hitachi at SemEval-2020 Task 12: Offensive Language Identification with Noisy Labels using Statistical Sampling and Post-Processing},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1961 – 1967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123913676&partnerID=40&md5=c326f2295d240c26c86f09d270f0872d},
	affiliations = {Research and Development Center, Hitachi India Pvt Ltd., Bangalore, India; Research and Development Group, Hitachi, Ltd., Tokyo, Japan},
	abstract = {In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A (English Language) which focuses on offensive language identification from noisy labels. To this end, we developed a hybrid system with the BERT classifier trained with tweets selected using Statistical Sampling Algorithm (SA) and Post-Processed (PP) using an offensive wordlist. Our developed system achieved 34th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over both offensive and non-offensive classes. We further show comprehensive results and error analysis to assist future research in offensive language identification with noisy labels. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Sampling; Semantics; English languages; F1 scores; Hitachi; Language identification; Noisy labels; Offensive languages; Post-processing; Sampling algorithm; Statistical sampling; Subtask; Hybrid systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{de la Peña Sarracén202023,
	author = {de la Peña Sarracén, Gretel Liz},
	title = {Multilingual and multimodal hate speech detection in social media; [Detección multilingüe y multimodal de mensajes de odio en redes sociales]},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2802},
	pages = {23 – 30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101222018&partnerID=40&md5=a8954aed6cad68fa43635400bd780582},
	affiliations = {Univeristat Politècnica de València, Spain},
	abstract = {En esta tesis doctoral proponemos el diseño y desarrollo de tecnologías para el tratamiento automático de mensajes de odio. La hipótesis en la que se sustenta el proyecto es que la detección de odio puede mejorar al incorporar, en el procesamiento de textos, otras fuentes de información como las imágenes, que en varias ocasiones son compartidas junto a dichos mensajes. De esta forma, pretendemos desarrollar estrategias para la detección automática de odio desde un enfoque multimodal. Por otra parte, en el marco del proyecto tendremos en cuenta el análisis multilingüe de mensajes de odio, haciendo uso de estrategias de transferencia de aprendizaje para el tratamiento en idiomas con poca información. Para el desarrollo de la investigación, nos planteamos construir un conjuno de datos que permita el procesamiento multilingüe y multimodal. En general, el trabajo estará enfocado en técnicas de aprendizaje profundo en la propuesta de aproximaciones para la detección de odio. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0) CEUR Workshop Proceedings (CEUR-WS.org)},
	author_keywords = {Aprendizaje por Transferencia; Aprendizaje Profundo; Detección de Mensajes de Odio; Sistema Multilingüe; Sistema Multimodal},
	keywords = {Social networking (online); Multi-modal; Social media; Speech detection; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 Doctoral Symposium on Natural Language Processing from the PLN.net Network, PLNnet-DS-2020; Conference date: 16 December 2020; Conference code: 167005}
}

@CONFERENCE{Pathak2020351,
	author = {Pathak, Varsha and Joshi, Manish and Joshi, Prasad and Mundada, Monica and Joshi, Tanmay},
	title = {KBCNMUJAL@HASOC-Dravidian-CodeMixFIRE2020: Using machine learning for detection of hate speech and offensive code-mixed social media text},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {351 – 361},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100377269&partnerID=40&md5=7f53a661bea728b0a3d0abecc88423ef},
	affiliations = {Institute of Management and Research, Jalgaon, Affil- KBC North Maharashtra University, Jalgaon MS, India; School of Computer Sciences, KBC North Maharashtra University, Jalgaon, MS, India; JET’s Z. B. College, DhuleAffil- KBC North Maharashtra University, Jalgaon, MS, India; Department of Dizitilization, Copenhagen Business School, Denmark; Brihan Maharashtra College of commerce, Pune, MS, India},
	abstract = {This paper describes the system submitted by our team, KBCNMUJAL, for Task 2 of the shared task “Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC)” at Forum for Information Retrieval Evaluation, December 16-20, 2020, Hyderabad, India. The datasets of two Dravidian languages viz Malayalam and Tamil of size 4000 observations, each were shared by the HASOC organizers. These datasets are used to train the machine using different machine learning algorithms, based on classification and regression models. The datasets consist of tweets or YouTube comments with two class labels “offensive” and “not offensive”. The machine is trained to classify such social media messages in these two categories. Appropriate n-gram feature sets are extracted to learn the specific characteristics of the Hate Speech text messages. These feature models are based on TFIDF weights of n-gram. The referred work and respective experiments show that the features such as word, character and combined model of word and character n-grams could be used to identify the term patterns of offensive text contents. As a part of the HASOC shared task, the test data sets are made available by the HASOC track organizers. The best performing classification models developed for both languages are applied on test datasets. The model which gives the highest accuracy result on training dataset for Malayalam language was experimented to predict the categories of respective test data. This system has obtained an F1 score of 0.77. Similarly the best performing model for Tamil language has obtained an F1 score of 0.87. This work has received 2nd and 3rd rank in this shared Task 2 for Malayalam and Tamil language respectively. The proposed system is named HASOC_kbcnmujal. © 2020 Copyright for this paper by its authors.},
	author_keywords = {LR; Multinomial Bayes; N-gram model; Random Forest Classifier; Support Vector Classifier; Text Classification},
	keywords = {Classification (of information); Computational linguistics; Fires; Information retrieval; Learning algorithms; Regression analysis; Search engines; Social networking (online); Speech recognition; Statistical tests; Classification models; Combined model; Content identifications; European languages; Hyderabad , India; Regression model; Training dataset; Word and characters; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Ou20202251,
	author = {Ou, Xiaozhi and Li, Hongling},
	title = {YNU oxz at SemEval-2020 Task 12: Bidirectional GRU with Capsule for Identifying Multilingual Offensive Language},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2251 – 2257},
	doi = {10.18653/v1/2020.semeval-1.300},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123916300&doi=10.18653%2fv1%2f2020.semeval-1.300&partnerID=40&md5=ecba717f42793c82769ba2626814c788},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {This article describes the system submitted to SemEval-2020 Task 12 OffensEval 2: Multilingual Offensive Language Recognition in Social Media. The task is to classify offensive language in social media. The shared task contains five languages (English, Greek, Arabic, Danish, and Turkish) and three subtasks. We only participated in subtask A of English to identify offensive language. To solve this task, we proposed a system based on a Bidirectional Gated Recurrent Unit (Bi-GRU) with a Capsule model. Finally, we used the K-fold approach for ensemble. Our model achieved a Macro-average F1 score of 0.90969 (ranked 27/85) in subtask A. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Social networking (online); F1 scores; Language recognition; Offensive languages; Social media; Subtask; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Singh2020325,
	author = {Singh, Pankaj and Bhattacharyya, Pushpak},
	title = {CFILT IIT Bombay at HASOC 2020: Joint multitask learning of multilingual hate speech and offensive content detection system},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {325 – 330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102929409&partnerID=40&md5=57bdf66af4f9d11202fc4692ead7cbf9},
	affiliations = {Indian Institute of Technololgy, Bombay, India},
	abstract = {This paper describes our system submitted to HASOC FIRE 2020. The goal of the shared tasks was to detected hate speech and offensive content in three languages namely Hindi, English, and German. The first subtask was a binary classification of a sentence into hate and offensive and normal. In the second subtask, a more granular classification of hate/offensive sentences was required. So overall there were 6 subtasks, 2 per language for 3 languages. We propose a system that performs all these tasks with a single model by jointly training a multilingual system on a combined corpus for all languages. It is relatively easy to fine-tune a model per task but it can pose various problems during deployment. These days most of the online platform supports multiple languages and it is not practical to deploy one model per language or per task. There are so many languages and tasks to cover and the online system will quickly run into memory and latency issues if there were multiple models handling the same task for different languages. Our system is capable of handling all subtasks for three languages with a single deep learning model. On the test set, we achieved a weighted average f1-score of 0.62, 0.85, 0.75 on subtask A and 0.35, 0.51, 0.43 on subtask B for Hindi, English, and German respectively. © 2020 Copyright for this paper by its authors},
	author_keywords = {BERT; Multi-task learning; Multilingual Hate Speech and Offensive Content Detection},
	keywords = {Deep learning; Fires; Information retrieval; Speech recognition; Binary classification; Content detection; Learning models; Multilingual system; Multiple languages; Online platforms; Single models; Weighted averages; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Baruah2020427,
	author = {Baruah, Arup and Das, Kaushik Amar and Barbhuiya, Ferdous Ahmed and Dey, Kuntal},
	title = {IIITG-ADBU@HASOC-Dravidian-CodeMix-FIRE2020: Offensive content detection in code-mixed dravidian text},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {427 – 433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100376457&partnerID=40&md5=24139e2e8ab478b2474ad67073973ea3},
	affiliations = {Indian Institute of Information Technology, Guwahati, India; Accenture Technology Labs, Bangalore, India},
	abstract = {This paper presents the results obtained by our SVM and XLM-RoBERTa based classifiers in the shared task “Dravidian-CodeMix-HASOC 2020”. The SVM classifier trained using TF-IDF features of character and word n-grams performed the best on the code-mixed Malayalam text. It obtained a weighted F1 score of 0.95 (1st Rank) and 0.76 (3rd Rank) on the YouTube and Twitter dataset respectively. The XLM-RoBERTa based classifier performed the best on the code-mixed Tamil text. It obtained a weighted F1 score of 0.87 (3rd Rank) on the code-mixed Tamil Twitter dataset. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Code-Mixed; Dravidian Language; Offensive Language; SVM; XLM-RoBERTa},
	keywords = {Information retrieval; Social networking (online); Support vector machines; Content detection; F1 scores; Malayalams; SVM classifiers; Word n-grams; YouTube; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Ranasinghe20201906,
	author = {Ranasinghe, Tharindu and Hettiarachchi, Hansi},
	title = {BRUMS at SemEval-2020 Task 12: Transformer based Multilingual Offensive Language Identification in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1906 – 1915},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123917078&partnerID=40&md5=f8e32dbfc5ba11a3bd8aff80351f2943},
	affiliations = {Research Group in Computational Linguistics, University of Wolverhampton, United Kingdom; School of Computing and Digital Technology, Birmingham City University, United Kingdom},
	abstract = {In this paper, we describe the team BRUMS entry to OffensEval 2: Multilingual Offensive Language Identification in Social Media in SemEval-2020. The OffensEval organizers provided participants with annotated datasets containing posts from social media in Arabic, Danish, English, Greek and Turkish. We present a multilingual deep learning model to identify offensive language in social media. Overall, the approach achieves acceptable evaluation scores, while maintaining flexibility between languages. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Deep learning; Natural language processing systems; Semantics; Annotated datasets; Language identification; Learning models; Offensive languages; Social media; Turkishs; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Chen20201947,
	author = {Chen, Weilong and Wang, Peng and Li, Jipeng and Zheng, Yuanshuai and Wang, Yan and Zhang, Yanru},
	title = {Ferryman at SemEval-2020 Task 12: BERT-Based Model with Advanced Improvement Methods for Multilingual Offensive Language Identification},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1947 – 1952},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123921711&partnerID=40&md5=9ad388b01bff30df2e2633998d0fbe96},
	affiliations = {University of Electronic Science and Technology of China, China},
	abstract = {Indiscriminately posting offensive remarks on social media may promote the occurrence of negative events such as violence, crime, and hatred. This paper examines different approaches and models for solving offensive tweet classification, which is a part of the OffensEval 2020 competition(Zampieri et al., 2020; Zampieri et al., 2019b). The dataset is Offensive Language Identification Dataset (OLID)(Zampieri et al., 2019a), which draws 14,200 annotated English Tweet comments(Rosenthal et al., 2020). The main challenge of data preprocessing is the unbalanced class distribution, abbreviation, and emoji. To overcome these issues, methods such as hashtag segmentation, abbreviation replacement, and emoji replacement have been adopted for data preprocessing approaches. The main task can be divided into three sub-tasks, and are solved by Term Frequency-Inverse Document Frequency(TF-IDF) vectorizer, Bidirectional Encoder Representation from Transformer (BERT), and Multi-dropout respectively. Meanwhile, we applied different learning rates for different languages and tasks based on BERT and non-BERTmodels in order to obtain better results. Our team Ferryman ranked the 18th, 8th, and 21st with F1-score of 0.91152 on the English Sub-task A, Sub-task B, and Sub-task C, respectively. Furthermore, our team also ranked in the top 20 on the Sub-task A of other languages(Çöltekin, 2020; Sigurbergsson and Derczynski, 2020; Mubarak et al., 2020; Pitenis et al., 2020). © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Semantics; Text processing; Class distributions; Data preprocessing; Hashtags; Improvement methods; Language identification; Negative events; Offensive languages; Preprocessing approaches; Social media; Subtask; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Dong20202244,
	author = {Dong, Xiangjue and Choi, Jinho D.},
	title = {XD at SemEval-2020 Task 12: Ensemble Approach to Offensive Language Identification in Social Media Using Transformer Encoders},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2244 – 2250},
	doi = {10.18653/v1/2020.semeval-1.299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123930394&doi=10.18653%2fv1%2f2020.semeval-1.299&partnerID=40&md5=118b06f6e806653e186e84eb4f58c0bd},
	affiliations = {Emory University, Atlanta, GA, United States},
	abstract = {This paper presents six document classification models using the latest transformer encoders and a high-performing ensemble model for a task of offensive language identification in social media. For the individual models, deep transformer layers are applied to perform multi-head attentions. For the ensemble model, the utterance representations taken from those individual models are concatenated and fed into a linear decoder to make the final decisions. Our ensemble model outperforms the individual models and shows up to 8.6% improvement over the individual models on the development set. On the test set, it achieves macro-F1 of 90.9% and becomes one of the high performing systems among 85 participants in the sub-task A of this shared task. Our analysis shows that although the ensemble model significantly improves the accuracy on the development set, the improvement is not as evident on the test set. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Information retrieval systems; Semantics; Signal encoding; Social networking (online); Classification models; Document Classification; Ensemble approaches; Ensemble models; Final decision; Individual modeling; Language identification; Offensive languages; Social media; Test sets; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hussein20202090,
	author = {Hussein, Omar and Sfar, Hachem and Mitrović, Jelena and Granitzer, Michael},
	title = {NLP_Passau at SemEval-2020 Task 12: Multilingual Neural Network for Offensive Language Detection in English, Danish and Turkish},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2090 – 2097},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123918440&partnerID=40&md5=5bb23e827697396e04dda6598266d0f0},
	affiliations = {Faculty of Computer Science and Mathematics, University of Passau, Germany},
	abstract = {This paper describes a neural network (NN) model that was used for participating in the OffensEval, Task 12 of the SemEval 2020 workshop. The aim of this task is to identify offensive speech in social media, specifically in tweets. The model we used, C-BiGRU, is composed of a Convolutional Neural Network (CNN) along with a bidirectional Recurrent Neural Network (RNN). A multidimensional numerical representation (embedding) for each of the words in the tweets, that were used by the model, was determined using fastText. This was utilized with a dataset of labeled tweets to train the model on detecting combinations of words that may convey an offensive meaning. The model was then used in the sub-task A of the English, Turkish and Danish competitions of the workshop, achieving F1 scores of 90.88%, 76.76% and 76.70%, respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Convolutional neural networks; Recurrent neural networks; Bidirectional recurrent neural networks; Convolutional neural network; Embeddings; Language detection; Neural network model; Neural-networks; Numerical representation; Offensive languages; Social media; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Safaya20202054,
	author = {Safaya, Ali and Abdullatif, Moutasem and Yuret, Deniz},
	title = {KUISAIL at SemEval-2020 Task 12: BERT-CNN for Offensive Speech Identification in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2054 – 2059},
	doi = {10.18653/v1/2020.semeval-1.271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118416740&doi=10.18653%2fv1%2f2020.semeval-1.271&partnerID=40&md5=2ffc02239d5ca30d94b6a4c6ccef8403},
	affiliations = {KUIS AI Lab, Koç University, Istanbul, Turkey},
	abstract = {In this paper, we describe our approach to utilize pre-trained BERT models with Convolutional Neural Networks for sub-task A of the Multilingual Offensive Language Identification shared task (OffensEval 2020), which is a part of the SemEval 2020. We show that combining CNN with BERT is better than using BERT on its own, and we emphasize the importance of utilizing pre-trained language models for downstream tasks. Our system, ranked 4th with macro averaged F1-Score of 0.897 in Arabic, 4th with score of 0.843 in Greek, and 3rd with score of 0.814 in Turkish. Additionally, we present ArabicBERT, a set of pre-trained transformer language models for Arabic that we share with the community. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Convolutional neural networks; Natural language processing systems; Social networking (online); Convolutional neural network; Down-stream; F1 scores; Language identification; Language model; Offensive languages; Social media; Speech identification; Subtask; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 236; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhou2020195,
	author = {Zhou, Siyao and Fu, Rui and Li, Jie},
	title = {Zeus at HASOC 2020: Hate speech detection based on ALBERT-DPCNN},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {195 – 201},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102935008&partnerID=40&md5=0972606b122015548bc94945aa32cab8},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {The use of social media has grown rapidly in the past few years. User generated data often contains objectionable content. Identifying hate speech, cyber-attacks and offensive language is a very challenging sentiment analysis task. In this paper, we participated in HASOC’s English hate speech and offensive content identification task and proposed the ALBERT-DPCNN model based on emotion analysis, which combined ALBERT and DPCNN obtained richer semantic features, ranking third in the task and achieving good results. © 2020 Copyright for this paper by its authors.},
	author_keywords = {ALBERT-DPCNN; HASOC; Hate speech; Offensive language; Sentiment analysis},
	keywords = {Fires; Information retrieval; Network security; Semantics; Sentiment analysis; Content identifications; Cyber-attacks; Emotion analysis; Model-based OPC; Offensive languages; Semantic features; Speech detection; User-generated; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Mosquera20201898,
	author = {Mosquera, Alejandro},
	title = {amsqr at SemEval-2020 Task 12: Offensive language detection using neural networks and anti-adversarial features},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1898 – 1905},
	doi = {10.18653/v1/2020.semeval-1.250},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115306813&doi=10.18653%2fv1%2f2020.semeval-1.250&partnerID=40&md5=525faf551928f48b0a05b7ce5b7a10bb},
	affiliations = {Symantec Enterprise Division, Broadcom Corporation},
	abstract = {This paper describes a method and system to solve the problem of detecting offensive language in social media using anti-adversarial features. Our submission to the SemEval-2020 task 12 challenge was generated by an stacked ensemble of neural networks fine-tuned on the OLID dataset and additional external sources. For Task-A (English), text normalisation filters were applied at both graphical and lexical level. The normalisation step effectively mitigates not only the natural presence of lexical variants but also intentional attempts to bypass moderation by introducing out of vocabulary words. Our approach provides strong F1 scores for both 2020 (0.9134) and 2019 (0.8258) challenges. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Feature extraction; External sources; F1 scores; Language detection; Lexical level; Neural-networks; Offensive languages; Outof-vocabulary words (OOV); Social media; Text Normalisation; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ranasinghe2020417,
	author = {Ranasinghe, Tharindu and Gupte, Sarthak and Zampieri, Marcos and Nwogu, Ifeoma},
	title = {WLV-RIT at HASOC-Dravidian-CodeMix-FIRE2020: Offensive language identification in code-switched youtube comments},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2826},
	pages = {417 – 426},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102928600&partnerID=40&md5=0a91ae66069ebe55e4b9af66da04dce9},
	affiliations = {University of Wolverhampton, United Kingdom; Rochester Institute of Technology, United States},
	abstract = {This paper describes the WLV-RIT entry to the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) shared task 2020. The HASOC 2020 organizers provided participants with annotated datasets containing social media posts of code-mixed in Dravidian languages (Malayalam-English and Tamil-English). We participated in task 1: Offensive comment identification in Code-mixed Malayalam Youtube comments. In our methodology, we take advantage of available English data by applying cross-lingual contextual word embeddings and transfer learning to make predictions to Malayalam data. We further improve the results using various fine tuning strategies. Our system achieved 0.89 weighted average F1 score for the test set and it ranked 5ℎ place out of 12 participants. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Code-switching; Hate speech; Offensive language identification; Text classification},
	keywords = {Information retrieval; Transfer learning; Annotated datasets; Content identifications; Contextual words; Cross-lingual; European languages; Offensive languages; Social media; Weighted averages; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Working Notes of FIRE - 12th Forum for Information Retrieval Evaluation, FIRE-WN 2020; Conference date: 16 December 2020 through 20 December 2020; Conference code: 167820}
}

@CONFERENCE{Klaus2020,
	author = {Klaus, Svea and Bartle, Anna-Sophie and Rossmann, Daniela},
	title = {Svandiela @ HaSpeeDe: Detecting hate speech in Italian twitter data with BERT},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	doi = {10.4000/books.aaccademia.7037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097537558&doi=10.4000%2fbooks.aaccademia.7037&partnerID=40&md5=576c454b6c9ae91695f114402ec925fe},
	affiliations = {Eberhard Karls Universität Tübingen, Germany},
	abstract = {This paper explains the system developed for the Hate Speech Detection (HaSpeeDe) shared task within the 7th evaluation campaign EVALITA 2020 (Basile et al., 2020). The task solution proposed in this work is based on a fine-tuned BERT model. In cross-corpus evaluation, our model reached an F1 score of 77,56% on the tweets test set, and 60,31% on the news headlines test set. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Cross-corpus evaluations; F1 scores; Speech detection; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Herath20201516,
	author = {Herath, Mahen and Atapattu, Thushari and Dung, Hoang Anh and Treude, Christoph and Falkner, Katrina},
	title = {AdelaideCyC at SemEval-2020 Task 12: Ensemble of Classifiers for Offensive Language Detection in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1516 – 1523},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123911007&partnerID=40&md5=5923d579abab6a8849b71795e186dea0},
	affiliations = {Department of Computer Science and Engineering, University of Moratuwa, Sri Lanka; School of Computer Science, University of Adelaide, Adelaide, 5005, SA, Australia},
	abstract = {This paper describes the systems our team (AdelaideCyC) has developed for SemEval Task 12 (OffensEval 2020) to detect offensive language in social media. The challenge focuses on three subtasks - offensive language identification (subtask A), offense type identification (subtask B), and offense target identification (subtask C). Our team has participated in all the three subtasks. We have developed machine learning and deep learning-based ensembles of models. We have achieved F1-scores of 0.906, 0.552, and 0.623 in subtask A, B, and C respectively. While our performance scores are promising for subtask A, the results demonstrate that subtask B and C still remain challenging to classify. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Crime; Deep learning; Natural language processing systems; Semantics; Ensemble of classifiers; Ensemble of models; F1 scores; Language detection; Language identification; Offensive languages; Performance; Social media; Subtask; Target's identifications; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}@CONFERENCE{Amrutha2019923,
	author = {Amrutha, B.R. and Bindu, K.R.},
	title = {Detecting hate speech in tweets using different deep neural network architectures},
	year = {2019},
	journal = {2019 International Conference on Intelligent Computing and Control Systems, ICCS 2019},
	pages = {923 – 926},
	doi = {10.1109/ICCS45141.2019.9065763},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084034758&doi=10.1109%2fICCS45141.2019.9065763&partnerID=40&md5=f4ed8e26fe69c44b19b6a190e1a43ea5},
	affiliations = {Dept of Computer Science and Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India},
	abstract = {One of the major problems, apparent in online social media, is the toxic online content. This has continued unabated, as people from diverse cultural backgrounds access the Internet, concealing their identity under the cloud of anonymity. Deep neural networks have been employed to detect hate speech from online content. This paper describes three different Deep Neural Network (DNN) Architectures for detection of hate words in Twitter - Gated Recurrent Unit (GRU), useful in capturing sequence orders, Convolution Neural Network (CNN), good for feature extraction, and Universal Language Model Fine-tuning (ULMFiT) model, which is based on transfer learning technique. ULMFiT model uses the DNN Architecture called Average-SGD Weight-Dropped Long Short Term Memory (AWD-LSTM). AWD -LSTM model was pre-trained using WikiText103 dataset. This method significantly outperformed the other Architectures. © 2019 IEEE.},
	author_keywords = {Classification; CNN; DNN; GRU; Hate words; ULMFiT},
	keywords = {Control systems; Deep neural networks; Feature extraction; Intelligent computing; Learning systems; Network architecture; Social networking (online); Speech recognition; Transfer learning; Convolution neural network; Cultural backgrounds; Fine tuning; Language model; Learning techniques; Model use; On-line contents; Online social medias; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 2019 International Conference on Intelligent Computing and Control Systems, ICCS 2019; Conference date: 15 May 2019 through 17 May 2019; Conference code: 159284}
}

@CONFERENCE{Dhillon201941,
	author = {Dhillon, Jasleen and Gupta, Varn and Govil, Rishabh and Varshney, Bhavya and Sinha, Adwitiya},
	title = {Crowdsourcing of Hate Speech for Detecting Abusive Behavior on Social Media},
	year = {2019},
	journal = {2019 International Conference on Signal Processing and Communication, ICSC 2019},
	pages = {41 – 46},
	doi = {10.1109/ICSC45622.2019.8938289},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077963696&doi=10.1109%2fICSC45622.2019.8938289&partnerID=40&md5=2011bf56acf0de10c23543e29024b3cd},
	affiliations = {Jaypee Institute of Information Technology, Computer Science Engineering, Noida, India},
	abstract = {Micro blogging sites nowadays provide a platform for a person to express their thoughts and opinions without risking anything. These social media platforms do not provide any religious or political restrictions for the user to restrict them from saying what they want. People use such platforms to express their opinions on current affairs, political campaigns, day to day activities, sports, and other services. One such platform is Twitter. This paper aims at targeting the tweets shared on twitter on the basis of emotion behind them-whether it falls under the category of hate speech or not. This paper identifies hate speech by employing various machine learning algorithms. The paper also derives the context in which various words are used and based on it identifies hate speech. It tries to keep the idea of freedom of speech intact and at the same time curtail hate speech which various other algorithms have failed to do. This paper focuses on applying the hate speech check on anti-national tweets. This can help in marking the users and to demote them to engage in such activities. © 2019 IEEE.},
	author_keywords = {Crowdsourcing; Cyber Bullying; Hate Speech; Sentimental Analysis; Social Communication; Social Media Networking},
	keywords = {Crowdsourcing; Learning algorithms; Machine learning; Signal processing; Social networking (online); Speech; Cyber bullying; Freedom of speech; Micro blogging; Political campaign; Sentimental Analysis; Social communications; Social media; Social media platforms; Speech communication},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 2019 International Conference on Signal Processing and Communication, ICSC 2019; Conference date: 7 March 2019 through 9 March 2019; Conference code: 156173}
}

@CONFERENCE{Alharbi20201532,
	author = {Alharbi, Abdullah I. and Lee, Mark},
	title = {BhamNLP at SemEval-2020 Task 12: An Ensemble of Different Word Embeddings and Emotion Transfer Learning for Arabic Offensive Language Identification in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1532 – 1538},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094754052&partnerID=40&md5=4c983653cbdb3f75b211feca331e2ed5},
	affiliations = {School of Computer Science, University of Birmingham, United Kingdom},
	abstract = {Social media platforms such as Twitter offer people an opportunity to publish short posts in which they can share their opinions and perspectives. While these applications can be valuable, they can also be exploited to promote negative opinions, insults, and hatred against a person, race, or group. These opinions can be spread to millions of people at the click of a mouse. As such, there is a need to develop mechanisms by which offensive language can be automatically detected in social media channels and managed in a timely manner. To help achieve this goal, SemEval 2020 offered a shared task (OffensEval 2020) that involved the detection of offensive text in Arabic. We propose an ensemble approach that combines different levels of word embedding models and transfer learning from other sources of emotion-related tasks. The proposed system ranked 9th out of the 52 entries within the Arabic Offensive language identification subtask. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Embeddings; Mammals; Natural language processing systems; Semantics; Embeddings; Ensemble approaches; Language identification; Media channel; Model learning; Offensive languages; Social media; Social media platforms; Subtask; Transfer learning; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Ombui2019,
	author = {Ombui, Edward and Muchemi, Lawrence and Wagacha, Peter},
	title = {Hate Speech Detection in Code-switched Text Messages},
	year = {2019},
	journal = {3rd International Symposium on Multidisciplinary Studies and Innovative Technologies, ISMSIT 2019 - Proceedings},
	doi = {10.1109/ISMSIT.2019.8932845},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078019843&doi=10.1109%2fISMSIT.2019.8932845&partnerID=40&md5=016ebe6666c7f7264ac6dde89e89217c},
	affiliations = {Africa Nazarene University, Computer and Information Technology Department, Nairobi, Kenya; University of Nairobi of Organization, School of Computing and Informatics, Nairobi, Kenya},
	abstract = {Not only does it happen in America, but also in Asia, in Africa and all over the world: Hate Speech. The exponential growth of user-generated content on social media bordering hate speech is increasingly alarming. Several efforts to monitor this phenomenon by social media network companies and the research community are on-going with various degrees of success. One gap in previous studies that this study addresses is the identification of hate speech in codeswitched text messages. The alternation of words in different languages within a message is a common occurrence among multilingual persons or communities. The study explored the performance of different features across various machine learning algorithms and established that character-level Term Frequency-Inverse Document Frequency, performed best given a codeswitched dataset of 25k annotated tweets using support vector machine algorithm as compared to six other conventional and two deep learning algorithms. © 2019 IEEE.},
	author_keywords = {Code-switching; Hate Speech; text classification},
	keywords = {Classification (of information); Deep learning; Machine learning; Social networking (online); Speech; Speech recognition; Support vector machines; Text processing; Code-switching; Exponential growth; Research communities; Social media networks; Support vector machine algorithm; Term frequency-inverse document frequencies; Text classification; User-generated content; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 3rd International Symposium on Multidisciplinary Studies and Innovative Technologies, ISMSIT 2019; Conference date: 11 October 2019 through 13 October 2019; Conference code: 156063}
}

@CONFERENCE{Syam2019305,
	author = {Syam, Syahrul Syafaat and Irawan, Budhi and Setianingsih, Casi},
	title = {Hate speech detection on twitter using long short-term memory (LSTM) method},
	year = {2019},
	journal = {2019 4th International Conference on Information Technology, Information Systems and Electrical Engineering, ICITISEE 2019},
	pages = {305 – 310},
	doi = {10.1109/ICITISEE48480.2019.9003992},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083458147&doi=10.1109%2fICITISEE48480.2019.9003992&partnerID=40&md5=8566c9740900a53d3a26f57cc1448cec},
	affiliations = {Telkom University, School of Electrical Engineering, Bandung, Indonesia},
	abstract = {Along with the development of the times, the use of social media, especially Twitter, is increasingly being used. Of course this makes more people communicate on social media. Due to communication, it is possible that there will be utterances of hate speech delivered to certain parties,, especially before presidential election in 2019. The number of certain parties spread hatred in social media especially on Twitter. Therefore, as technology develops, we create a system that can detect a tweet based on the search for hashtag on Twitter whether it is classified as hate speech or not using the LSTM method as a classifier. The result of this system is to provide a label in the form of 'hate speech' or 'non-hate speech' on every tweet that becomes an input on this system. © 2019 IEEE.},
	author_keywords = {Hate Speech; LSTM; Twitter},
	keywords = {Information systems; Information use; Long short-term memory; Social networking (online); Speech; Speech communication; Presidential election; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 4th International Conference on Information Technology, Information Systems and Electrical Engineering, ICITISEE 2019; Conference date: 20 November 2019 through 21 November 2019; Conference code: 158931}
}

@ARTICLE{Elouali202081,
	author = {Elouali, Aya and Elberrichi, Zakaria and Elouali, Nadia},
	title = {Hate speech detection on multilingual twitter using convolutional neural networks},
	year = {2020},
	journal = {Revue d'Intelligence Artificielle},
	volume = {34},
	number = {1},
	pages = {81 – 88},
	doi = {10.18280/ria.340111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082885737&doi=10.18280%2fria.340111&partnerID=40&md5=49a2d2aceb34d63ad8e7a048eec417ae},
	affiliations = {EEDIS Laboratory, Djillali Liabes University, Sidi Belabbes, 22000, Algeria; LabRi Laboratory, Ecole Superieure en Informatique, Sidi Bel Abbes, 22016, Algeria},
	abstract = {Hate speech detection on Twitter is often treated in monolingual (in English generally) ignoring the fact that Twitter is a global platform where everyone expresses himself with his natal language. In this paper, we created a model which, taking benefits of the advantages of neural networks, classifies tweets written in seven different languages (and even those that contains more than one language at the same time) to hate speech or non hate speech. We used Convolutional Neural Networks (CNN) and character level representation. We carried out several experiments in order to adjust the parameters according to our case study. Our best results were (in terms of accuracy) 0.8893 for a dataset containing five languages and 0.8300 for a dataset of seven languages. Our model solves properly the problem of hate speech on Twitter and its results are, compared to the state of the art, more than satisfactory. © 2020 Lavoisier. All rights reserved.},
	author_keywords = {Character level representation; Convolutional neural network; Hate speech; Multilingual; Neural networks; Text classification},
	keywords = {Classification (of information); Convolution; Neural networks; Social networking (online); Speech; Speech recognition; Text processing; Character level; Multilingual; Speech detection; State of the art; Text classification; Convolutional neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Bronze Open Access}
}

@CONFERENCE{Br Ginting2019105,
	author = {Br Ginting, Purnama Sari and Irawan, Budhi and Setianingsih, Casi},
	title = {Hate speech detection on twitter using multinomial logistic regression classification method},
	year = {2019},
	journal = {Proceedings - 2019 IEEE International Conference on Internet of Things and Intelligence System, IoTaIS 2019},
	pages = {105 – 111},
	doi = {10.1109/IoTaIS47347.2019.8980379},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081110955&doi=10.1109%2fIoTaIS47347.2019.8980379&partnerID=40&md5=eb4b61108c5eb54895ffda5bb8e1fbd1},
	affiliations = {School of Electrical Engineering, Telkom University, Bandung, Indonesia},
	abstract = {In today's social media, especially Twitter is very important for the success and destruction of one's image due to the many sentences of opinion that can compete the users. Examples of phrases that mean evil refer to hate speech to others. Evil perspectives can be categorized in hate speech, which hate speech is regulated in Article 28 of the ITE Law. Not a few people who intentionally and unintentionally oppose a social media that contains hate speech. Unfortunately social media does not have the ability to aggregate information about an existing conversation into a conclusion. One way to draw conclusion from aggregation results is to use text mining. In this paper to classify whether the text in the sentence contains elements of hate speech or not. The author hopes in this paper can make how to classify element of hate speech in text by computer, which later speech of the can be recognized. By using Multinomial Logistic Regression method. The author hopes after this application the computer can know and classify the existence of hate speech on a text from social media Twitter. From the results of tests that have been done the average precision of 80.02, recall 82%, and accuracy of 87.68%. © 2019 IEEE.},
	author_keywords = {Hate; Multinomial Logistic Regression; Twitter},
	keywords = {Character recognition; Internet of things; Social networking (online); Speech; Speech recognition; Text mining; Classification methods; Hate; Multinomial logistic regression; Social media; Speech detection; Twitter; Logistic regression},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 2019 IEEE International Conference on Internet of Things and Intelligence System, IoTaIS 2019; Conference date: 5 November 2019 through 7 November 2019; Conference code: 157521}
}

@ARTICLE{Fortuna2019,
	author = {Fortuna, Paula and Nunes, Sérgio},
	title = {A survey on automatic detection of hate speech in text},
	year = {2019},
	journal = {ACM Computing Surveys},
	volume = {51},
	number = {4},
	doi = {10.1145/3232676},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053245173&doi=10.1145%2f3232676&partnerID=40&md5=e92c863dbc8e557ce6410de00d4c4f3c},
	affiliations = {INESC TEC, Campus da FEUP, Rua Dr. Roberto Frias, 4200, Porto, 465, Portugal; Faculty of Engineering, University of Porto, Portugal},
	abstract = {The scientific study of hate speech, from a computer science point of view, is recent. This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used. This work also discusses the complexity of the concept of hate speech, defined in many platforms and contexts, and provides a unifying definition. This area has an unquestionable potential for societal impact, particularly in online communities and digital media platforms. The development and systematization of shared resources, such as guidelines, annotated datasets in multiple languages, and algorithms, is a crucial step in advancing the automatic detection of hate speech. © 2018 ACM.},
	author_keywords = {Hate speech; Literature review; Natural language processing; Opinion mining; Text mining},
	keywords = {Data mining; Digital storage; Speech recognition; Surveys; 'current; Automatic Detection; Hate speech; Language processing; Literature reviews; Natural language processing; Natural languages; Opinion mining; Scientific studies; Text-mining; Sentiment analysis},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 768; All Open Access, Green Open Access}
}

@CONFERENCE{Sap20201668,
	author = {Sap, Maarten and Card, Dallas and Gabriel, Saadia and Choi, Yejin and Smith, Noah A.},
	title = {The risk of racial bias in hate speech detection},
	year = {2020},
	journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {1668 – 1678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074361361&partnerID=40&md5=dadcd62be8e5ca4d023fa955ca2c6b14},
	affiliations = {Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, United States; Machine Learning Department, Carnegie Mellon University, Pittsburgh, United States; Allen Institute for Artificial Intelligence, Seattle, United States},
	abstract = {We investigate how annotators' insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose dialect and race priming as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet's dialect they are significantly less likely to label the tweet as offensive. © 2019 Association for Computational Linguistics},
	keywords = {Chemical detection; Computational linguistics; African American; Racial bias; Speech detection; Surface markers; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 516; Conference name: 57th Annual Meeting of the Association for Computational Linguistics, ACL 2019; Conference date: 28 July 2019 through 2 August 2019; Conference code: 159206}
}

@CONFERENCE{Tran2019422,
	author = {Tran, Khang and Nguyen, Duy and Nguyen, Hung},
	title = {Toward deep and handcraft features for detecting violent behaviors},
	year = {2019},
	journal = {Proceedings - 2019 6th NAFOSTED Conference on Information and Computer Science, NICS 2019},
	pages = {422 – 427},
	doi = {10.1109/NICS48868.2019.9023792},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082644342&doi=10.1109%2fNICS48868.2019.9023792&partnerID=40&md5=1f00b5e8073603ed7d1055c6e00353cf},
	affiliations = {Ho Chi Minh City University of Education, Ho Chi Minh City, Viet Nam},
	abstract = {Violent and abnormal behaviors detecting has been an interesting field recently. Many types of research have been done to accurately predict the behaviors of human whether it's violent or not. However, it requires a lot of modern and strong infrastructure to complete the task. To fill the gap, in this research, we propose a skeleton-based method that doesn't require much of infrastructure but very fast and accurate to detect violent behaviors. Our method contains two stages: extracting deep features from image frames to estimate human pose, and then we define four handcraft features to classify whether the act is violent or not. We tested our method on UT-Interaction [1] dataset which result is very tempting and promising. © 2019 IEEE.},
	author_keywords = {Action Recognition; Deep features; Handcrafted features; Skeleton-based; Violent Behaviors},
	keywords = {Musculoskeletal system; Action recognition; Deep features; Handcrafted features; Skeleton-based; Violent behavior; Behavioral research},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th NAFOSTED Conference on Information and Computer Science, NICS 2019; Conference date: 12 December 2019 through 13 December 2019; Conference code: 158383}
}

@CONFERENCE{Orabe20201932,
	author = {Orabe, Zoher and Haddad, Bushr and Al-Abood, Anas and Ghneim, Nada},
	title = {DoTheMath at SemEval-2020 Task 12: Deep Neural Networks with Self Attention for Arabic Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1932 – 1937},
	doi = {10.18653/v1/2020.semeval-1.254},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094769274&doi=10.18653%2fv1%2f2020.semeval-1.254&partnerID=40&md5=fc034eeb1fc3da00e522e765984152f4},
	affiliations = {Damascus University, Damascus, Syrian Arab Republic; AlSham Private University, Damascus, Syrian Arab Republic},
	abstract = {This paper describes our team work and submission for the SemEval 2020 (Sub-Task A) “Offensive Eval: Identifying and Categorizing Offensive Arabic Language in Arabic Social Media”. Our two baseline models were based on different levels of representation: character vs. word level. In word level based representation we implemented a convolutional neural network model and a bi-directional GRU model. In character level based representation we implemented a hyper CNN and LSTM model. All of these models have been further augmented with attention layers for a better performance on our task. We also experimented with three types of static word embeddings: word2vec, FastText, and Glove, in addition to emoji embeddings, and compared the performance of the different deep learning models on the dataset provided by this task. The bi-directional GRU model with attention has achieved the highest score (0.85% F1 score) among all other models. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Convolutional neural networks; Deep neural networks; Long short-term memory; Neural network models; Semantics; Arabic languages; Bi-directional; Embeddings; Language detection; Offensive languages; Performance; Social media; Subtask; Team work; Word level; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hassan20201891,
	author = {Hassan, Sabit and Samih, Younes and Mubarak, Hamdy and Abdelali, Ahmed},
	title = {ALT at SemEval-2020 Task 12: Arabic and English Offensive Language Identification in Social Media},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1891 – 1897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093101752&partnerID=40&md5=ebe6777258dcf9dd3ea4327a199de00e},
	affiliations = {Qatar Computing Research Institute, Doha, Qatar},
	abstract = {This paper describes the systems submitted by the Arabic Language Technology group (ALT) at SemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media. We focus on sub-task A (Offensive Language Identification) for two languages: Arabic and English. Our efforts for both languages achieved more than 90% macro-averaged F1-score on the official test set. For Arabic, the best results were obtained by a system combination of Support Vector Machine, Deep Neural Network, and fine-tuned Bidirectional Encoder Representations from Transformers (BERT). For English, the best results were obtained by fine-tuning BERT. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Deep neural networks; Natural language processing systems; Semantics; Support vector machines; Arabic languages; F1 scores; Language identification; Language technology; Offensive languages; Social media; Subtask; Support vectors machine; System combination; Test sets; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Sivanaiah20202190,
	author = {Sivanaiah, Rajalakshmi and Angel Deborah, S. and Rajendram, S. Milton and Mirnalinee, T.T.},
	title = {TECHSSN at SemEval-2020 Task 12: Offensive Language Detection Using BERT Embeddings},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2190 – 2196},
	doi = {10.18653/v1/2020.semeval-1.291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094784272&doi=10.18653%2fv1%2f2020.semeval-1.291&partnerID=40&md5=c79736f44b3e4bd158b6a391bafa780c},
	affiliations = {Department of Computer Science and Engineering, SSN College of Engineering, Tamil Nadu, Chennai, 603 110, India},
	abstract = {This paper describes the work of identifying the presence of offensive language in social media posts and categorizing a post as targeted to a particular person or not. The work developed by team TECHSSN for solving the Multilingual Offensive Language Identification in Social Media (Task 12) in SemEval-2020 involves the use of deep learning models with BERT embeddings. The dataset is preprocessed and given to a Bidirectional Encoder Representations from Transformers (BERT) model with pretrained weight vectors. The model is retrained and the weights are learned for the offensive language dataset. We have developed a system with the English language dataset. The results are better when compared to the model we developed in SemEval-2019 Task6. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Deep learning; Semantics; Social networking (online); Embeddings; English languages; Language detection; Language identification; Learning models; Offensive languages; Social media; Transformer modeling; Weight vector; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kurniawan20201998,
	author = {Kurniawan, Sandy and Budi, Indra and Ibrohim, Muhammad Okky},
	title = {IR3218-UI at SemEval-2020 Task 12: Emoji Effects on Offensive Language Identification},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1998 – 2005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094688102&partnerID=40&md5=7f24515a203259be47132a4f36842a23},
	affiliations = {Faculty of Computer Science, Universitas Indonesia Kampus UI, Depok, 16424, Indonesia},
	abstract = {In this paper, we present our approach and the results of our participation in OffensEval 2020. There are three sub-tasks in OffensEval 2020, namely offensive language identification (sub-task A), automatic categorization of offense types (sub-task B), and offense target identification (sub-task C). We participated in sub-task A of English OffensEval 2020. Our approach emphasizes on how the emoji affects offensive language identification. Our model used LSTM combined with GloVe pre-trained word vectors to identify offensive language on social media. The best model obtained macro F1-score of 0.88428. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Computational linguistics; Long short-term memory; Natural language processing systems; Semantics; Automatic categorization; Best model; F1 scores; Language identification; Offensive languages; Social media; Subtask; Target's identifications; Word vectors; Crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Arango201945,
	author = {Arango, Aymé and Pérez, Jorge and Poblete, Barbara},
	title = {Hate speech detection is not as easy as you may think: A closer look at model validation},
	year = {2019},
	journal = {SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {45 – 53},
	doi = {10.1145/3331184.3331262},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073801948&doi=10.1145%2f3331184.3331262&partnerID=40&md5=cde77a2e1066c66c99328e426770a98a},
	affiliations = {Department of Computer Science, University of Chile, IMFD, Chile},
	abstract = {Hate speech is an important problem that is seriously affecting the dynamics and usefulness of online social communities. Large scale social platforms are currently investing important resources into automatically detecting and classifying hateful content, without much success. On the other hand, the results reported by state-of-the-art systems indicate that supervised approaches achieve almost perfect performance but only within specific datasets. In this work, we analyze this apparent contradiction between existing literature and actual applications. We study closely the experimental methodology used in prior work and their generalizability to other datasets. Our findings evidence methodological issues, as well as an important dataset bias. As a consequence, performance claims of the current state-of-the-art have become significantly overestimated. The problems that we have found are mostly related to data overfitting and sampling issues. We discuss the implications for current research and re-conduct experiments to give a more accurate picture of the current state-of-the art methods. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Deep learning; Experimental evaluation; Hate speech classification; Social media},
	keywords = {Information retrieval; Social networking (online); Experimental evaluation; Experimental methodology; Model validation; Online social communities; Social media; Speech classification; State-of-the-art methods; State-of-the-art system; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 122; Conference name: 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019; Conference date: 21 July 2019 through 25 July 2019; Conference code: 149777; All Open Access, Bronze Open Access}
}

@ARTICLE{Omar2020247,
	author = {Omar, Ahmed and Mahmoud, Tarek M. and Abd-El-Hafeez, Tarek},
	title = {Comparative Performance of Machine Learning and Deep Learning Algorithms for Arabic Hate Speech Detection in OSNs},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1153 AISC},
	pages = {247 – 257},
	doi = {10.1007/978-3-030-44289-7_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082982625&doi=10.1007%2f978-3-030-44289-7_24&partnerID=40&md5=e28490a6adebca58f13d4f1d7785f8c3},
	affiliations = {Computer Science Department, Faculty of Science, Minia University, EL-Minia, Egypt; Deraya University, EL-Minia, Egypt},
	abstract = {Nowadays, Online Social Networks (OSNs) are the most popular and interactive media that used to express feelings, communicate and share information between people. However, along with useful and interesting content, sometimes unsuitable or abusive content can be published on these networks, such as hate speech and insults. Hate speech includes any type of online abuse concepts like cyberbullying, discrimination, abusive language, profanity, flaming, toxicity, and harassment. Most of the Hate speech detection attempts have concentrated on the English text, while work on the Arabic text is sparse. In this paper, we constructed a standard Arabic dataset that can be used for hate speech and abuse detection. In contrast to most previous work the datasets were collected from one platform, the proposed dataset is collected from more social network platforms (Facebook, Twitter, Instagram, and YouTube). To validate the effectiveness of the proposed datasets twelve machine learning algorithms and two deep learning architecture were used. Recurrent Neural Network (RNN) outperformed other classifiers with an accuracy of 98.7%. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Arabic hate speech; Arabic text classification; Hate speech detection; OSN},
	keywords = {Classification (of information); Learning systems; Recurrent neural networks; Social networking (online); Speech; Speech recognition; Text processing; Arabic texts; Comparative performance; Interactive media; Learning architectures; Network platforms; Online social networks (OSNs); Recurrent neural network (RNN); Speech detection; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; Conference name: 1st International Conference on Artificial Intelligence and Computer Visions, AICV 2020; Conference date: 8 April 2020 through 10 April 2020; Conference code: 238759}
}

@CONFERENCE{Wiedemann20201638,
	author = {Wiedemann, Gregor and Yimam, Seid Muhie and Biemann, Chris},
	title = {UHH-LT at SemEval-2020 Task 12: Fine-Tuning of Pre-Trained Transformer Networks for Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1638 – 1644},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094704198&partnerID=40&md5=0068d901301b9f7d4cddf60d05a8d4c1},
	affiliations = {Language Technology Group, Department of Informatics, University of Hamburg, Germany},
	abstract = {Fine-tuning of pre-trained transformer networks such as BERT yield state-of-the-art results for text classification tasks. Typically, fine-tuning is performed on task-specific training datasets in a supervised manner. One can also fine-tune in unsupervised manner beforehand by further pretraining the masked language modeling (MLM) task. Hereby, in-domain data for unsupervised MLM resembling the actual classification target dataset allows for domain adaptation of the model. In this paper, we compare current pre-trained transformer networks with and without MLM fine-tuning on their performance for offensive language detection. Our MLM fine-tuned RoBERTa-based classifier officially ranks 1st in the SemEval 2020 Shared Task 12 for the English language. Further experiments with the ALBERT model even surpass this result. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Modeling languages; Semantics; Domain adaptation; Fine tuning; Language detection; Language model; Modeling task; Offensive languages; Pre-training; State of the art; Training dataset; Yield state; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Mandl201914,
	author = {Mandl, Thomas and Modha, Sandip and Majumder, Prasenjit and Patel, Daksh and Dave, Mohana and Mandlia, Chintak and Patel, Aditya},
	title = {Overview of the HASOC track at FIRE 2019: Hate speech and offensive content identification in Indo-European languages},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {14 – 17},
	doi = {10.1145/3368567.3368584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077513450&doi=10.1145%2f3368567.3368584&partnerID=40&md5=17291fe349391962c78bbc02eaf55317},
	affiliations = {University of Hildesheim, Germany; DA-IICT, Gandhinagar, India; Dalhousie University, Halifax, Canada; LDRP-ITR, Gandhinagar, India; Analytica Consulting Pvt. Ltd, India},
	abstract = {The identification of Hate Speech in Social Media is of great importance and receives much attention in the text classification community. There is a huge demand for research for languages other than English. The HASOC track intends to stimulate development in Hate Speech for Hindi, German and English. Three datasets were developed from Twitter and Facebook and made available. Binary classification and more fine-grained subclasses were offered in 3 subtasks. For all subtasks, 321 experiments were submitted. The approaches used most often were LSTM networks processing word embedding input. The performance of the best system for identification of Hate Speech for English, Hindi, and German was a Marco-F1 score of 0.78, 0.81 and 0.61, respectively. © 2019 Copyright is held by the author(s). Publication rights licensed to ACM.},
	author_keywords = {Deep Learning; Evaluation; Hate Speech; Text Classification},
	keywords = {Classification (of information); Deep learning; Information retrieval; Long short-term memory; Social networking (online); Speech; Text processing; Binary classification; Content identifications; European languages; Evaluation; F1 scores; Fine grained; Social media; Text classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 273; Conference name: 11th Annual Meeting of the Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155944}
}

@CONFERENCE{Desrul2019320,
	author = {Desrul, Dhamir Raniah Kiasati and Romadhony, Ade},
	title = {Abusive Language Detection on Indonesian Online News Comments},
	year = {2019},
	journal = {2019 2nd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2019},
	pages = {320 – 325},
	doi = {10.1109/ISRITI48646.2019.9034620},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083310622&doi=10.1109%2fISRITI48646.2019.9034620&partnerID=40&md5=6e8128441bf66828f09a0c1bbc0e9515},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {Abusive language is an expression used by a person with insulting delivery of any person's aspect. In the modern era, the use of harsh words is often found on the internet, one of them is in the comment section of online news articles which contains harassment, insult, or a curse. An abusive language detection system is important to prevent the negative effect of such comments. Detecting abusive language in the online comment section is a challenge since abusive languages can be expressed in various words. Moreover, only a few studies have been conducted in Indonesian language. In this paper, we present an Indonesian abusive language detection system by tackling this problem as a classification task and solving it using the following classifiers: Naive Bayes, SVM, and KNN. We also performed feature selection procedure based on Mutual Information value between words. The experimental results show that SVM is the best classifier for detecting the abusive language in news comment with an accuracy score of 90,19% and the use of Mutual Information able to improve the classification accuracy by 1.63%. Mutual Information can increase the accuracy performance of the classifier. © 2019 IEEE.},
	author_keywords = {Abusive Language; Detection; Indonesian; Mutual Information; SVM},
	keywords = {Intelligent systems; Support vector machines; Classification accuracy; Classification tasks; Indonesian languages; Language detection; Mutual informations; Naive bayes; Online news; Selection procedures; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 2nd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2019; Conference date: 5 December 2019 through 6 December 2019; Conference code: 158597}
}

@ARTICLE{Gupta2020611,
	author = {Gupta, Bharat and Goel, Nikita and Jain, Dhruv and Gupta, Namita},
	title = {A Novel IN-Gram Technique for Improving the Hate Speech Detection for Larger Datasets},
	year = {2020},
	journal = {Lecture Notes in Networks and Systems},
	volume = {106},
	pages = {611 – 620},
	doi = {10.1007/978-981-15-2329-8_62},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085352563&doi=10.1007%2f978-981-15-2329-8_62&partnerID=40&md5=0ac84c8a1b8355e6bb15b711907810c6},
	affiliations = {Department of Computer Science and Engineering, Jaypee Institute of Information Technology, Noida, India; School of Business Management, Sharda University, Greater Noida, India},
	abstract = {Hate speech is a type of written or a spoken statement that is used to demean or humiliate a person or a community. In this era of new age socialism, this type of speech is prevalent on social media platforms, where certain groups of people display offensive behaviour towards some people that may be distributed over gender, religion, nationality, etc. These kinds of activities must be avoided or suspended on social media platforms. Therefore, it is necessary to automate the detection of hateful content that gets circulated on the social media. The research work provides an enhanced technique as compared to the existing techniques with improved performance. The proposed model of IN-Gram compares the performance of detection of hateful content on social media with the traditional TF-IDF, N-Gram and PMI techniques. The proposed approach improves the hate speech detection rate by 10–12% for larger datasets as compared to existing approaches. © Springer Nature Singapore Pte Ltd. 2020.},
	author_keywords = {Hate speech detection; Machine learning; N-Gram; NLP; PMI; TF-IDF},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Aulia2019164,
	author = {Aulia, Nofa and Budi, Indra},
	title = {Hate speech detection on Indonesian long text documents using machine learning approach},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {164 – 169},
	doi = {10.1145/3330482.3330491},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071108622&doi=10.1145%2f3330482.3330491&partnerID=40&md5=d4b5433867b6dd7bf0aba322cbc79b60},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia},
	abstract = {Due to the growth of hate speech on social media in recent years, it is important to understand this issue. An automatic hate speech detection system is needed to help to counter this problem. There have been many studies on detecting hate speech in short documents like Twitter data. But to our knowledge, research on long documents is rare, we suppose that the difficulty is increasing due to the possibility of the message of the text may be hidden. In this research, we explore in detecting hate speech on Indonesian long documents using machine learning approach. We build a new Indonesian hate speech dataset from Facebook. The experiment showed that the best performance obtained by Support Vector Machine (SVM) as its classifier algorithm using TF-IDF, char quad-gram, word unigram, and lexicon features that yield f1-score of 85%. © 2019 Association for Computing Machinery.},
	author_keywords = {Hate speech detection; Long documents; Machine learning; SVM},
	keywords = {Learning systems; Social networking (online); Speech; Support vector machines; Classifier algorithms; F1 scores; Facebook; Long documents; Machine learning approaches; Social media; Speech detection; Text document; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; Conference name: 5th International Conference on Computing and Artificial Intelligence, ICCAI 2019; Conference date: 19 April 2019 through 22 April 2019; Conference code: 149963}
}

@CONFERENCE{Kalaivani20202161,
	author = {Kalaivani, A. and Thenmozhi, D.},
	title = {SSN_NLP_MLRG at SemEval-2020 Task 12: Offensive Language Identification in English, Danish, Greek using BERT and Machine Learning Approach},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2161 – 2170},
	doi = {10.18653/v1/2020.semeval-1.287},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094804075&doi=10.18653%2fv1%2f2020.semeval-1.287&partnerID=40&md5=e7b3dfec87fca2da271dae7d4af01abd},
	affiliations = {Department of CSE, SSN College of Engineering, India},
	abstract = {Offensive language identification is to detect the hurtful tweets, derogatory comments, swear words on social media. As an emerging growth of social media communication, offensive language detection has received more attention in the last years. We focus to perform the task on English, Danish and Greek languages. We have investigated which can be effect more on pre-trained models BERT (Bidirectional Encoder Representation from Transformer) and Machine Learning Approaches. Our investigation shows the performance between the three languages and to identify the best performance is evaluated by the classification algorithms. In the shared task SemEval-2020, our team SSN_NLP_MLRG submitted for three languages that are Subtasks A, B, C in English, Subtask A in Danish and Subtask A in Greek. Our team SSN_NLP_MLRG obtained the F1 Scores as 0.90, 0.61, 0.52 for the Subtasks A, B, and C in English, 0.56 for the Subtask A in Danish and 0.67 for the Subtask A in Greek respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Computational linguistics; Learning algorithms; Machine learning; Semantics; Social networking (online); Classification algorithm; F1 scores; Language detection; Language identification; Machine learning approaches; Media communications; Offensive languages; Performance; Social media; Subtask; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sreelakshmi2020737,
	author = {Sreelakshmi, K. and Premjith, B. and Soman, K.P.},
	title = {Detection of Hate Speech Text in Hindi-English Code-mixed Data},
	year = {2020},
	journal = {Procedia Computer Science},
	volume = {171},
	pages = {737 – 744},
	doi = {10.1016/j.procs.2020.04.080},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086639646&doi=10.1016%2fj.procs.2020.04.080&partnerID=40&md5=cb5978f664e46158fbd5d775aa7dd218},
	affiliations = {Center for Computational Engineering and Networking (CEN) Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India},
	abstract = {Social media sites like Twitter, Facebook, being user-friendly and a free source, provide opportunities to people to air their voice. People, irrespective of the age group, use these sites to share every moment of their life making these sites flooded with data. Apart from these commendable features, these sites have down side as well. Due to lack of restrictions set by these sites for its users to express their views as they like, anybody can make adverse and unrealistic comments in abusive language against anybody with an ulterior motive to tarnish one's image and status in the society. So it became a huge responsibility for the Government and these sites to identify this hate content before it disseminates to mass. Automatic hate speech detection faces quite a lot of challenges due to the non-standard variations in spelling and grammar. Especially for a country like India with huge multilingual and bilingual population, this hate content would be in code-mixed form which makes the task demanding. So our paper projects a machine learning model to detect hate speech in Hindi-English code-mixed social media text. The methodology makes use of Facebook's pre-trained word embedding library, fastText to represent 10000 data samples collected from different sources as hate and non-hate. The performance of the proposed methodology is compared with word2vec and doc2vec features and it is observed that fastText features gave better feature representation with Support Vector Machine (SVM)-Radial Basis Funcrion (RBF) classifier. The paper also provides an insight to the researchers working in the field of code-mixed data that character level features provide best result for code-mixed data. © 2020 The Authors. Published by Elsevier B.V.},
	author_keywords = {Code-mixed; fastText; Hate speech; Natural Language Processing; Support Vector Machine},
	keywords = {Clustering algorithms; Social networking (online); Speech recognition; Support vector machines; Character level; Feature representation; Machine learning models; Radial basis; Social media; Speech detection; Standard variation; User friendly; Codes (symbols)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 98; Conference name: 3rd International Conference on Computing and Network Communications, CoCoNet 2019; Conference date: 18 December 2019 through 21 December 2019; Conference code: 160760; All Open Access, Gold Open Access}
}

@ARTICLE{Cécillon2019,
	author = {Cécillon, Noé and Labatut, Vincent and Dufour, Richard and Linarès, Georges},
	title = {Abusive Language Detection in Online Conversations by Combining Content- and Graph-Based Features},
	year = {2019},
	journal = {Frontiers in Big Data},
	volume = {2},
	doi = {10.3389/fdata.2019.00008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094779645&doi=10.3389%2ffdata.2019.00008&partnerID=40&md5=ed99c35180b212b4b6b56e35ab7e31fc},
	affiliations = {LIA, Avignon University, Avignon, France},
	abstract = {In recent years, online social networks have allowed world-wide users to meet and discuss. As guarantors of these communities, the administrators of these platforms must prevent users from adopting inappropriate behaviors. This verification task, mainly done by humans, is more and more difficult due to the ever growing amount of messages to check. Methods have been proposed to automatize this moderation process, mainly by providing approaches based on the textual content of the exchanged messages. Recent work has also shown that characteristics derived from the structure of conversations, in the form of conversational graphs, can help detecting these abusive messages. In this paper, we propose to take advantage of both sources of information by proposing fusion methods integrating content- and graph-based features. Our experiments on raw chat logs show not only that the content of the messages, but also their dynamics within a conversation contain partially complementary information, allowing performance improvements on an abusive message classification task with a final F-measure of 93.26%. Copyright © 2019 Cécillon, Labatut, Dufour and Linarès.},
	author_keywords = {automatic abuse detection; content analysis; conversational graph; online conversations; social networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Florio2019219,
	author = {Florio, Kamal and Basile, Valerio and Lai, Mirko and Patti, Viviana},
	title = {Leveraging Hate Speech Detection to Investigate Immigration-related Phenomena in Italy},
	year = {2019},
	journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019},
	pages = {219 – 225},
	doi = {10.1109/ACIIW.2019.8925079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077816299&doi=10.1109%2fACIIW.2019.8925079&partnerID=40&md5=29bcb996532367a991fd9ef77c0b27d4},
	affiliations = {Università degli Studi di Torino, Dipartimento di Informatica, Italy},
	abstract = {The presence and integration of immigrants is one of the most controversial issues in our society, and given current worldwide political instabilities, it will likely become ever more prominent in the cultural and political debate. Social media play an increasingly important role in how citizens debate opinions and react to local and global events. However, several studies point out the danger of social media as a breeding ground for online hate speech (or cyberhate). We propose a novel approach to the exploratory analysis of social phenomena based on the integration of automatic detection of cyberhate against immigrants with offline indicators. We gathered data from the Italian Twittersphere and from the main supplier of official statistical data in Italy (ISTAT). We developed a supervised classification model for hate speech detection, trained on a corpus of Italian tweets manually annotated for hate speech against immigrants, and use it to automatically annotate a large sample of geo-tagged tweets over a span of six years. We crossed this data with the ISTAT data, exploring three macro-indicators related to employment, education and crime. We found correlations suggesting an interplay between economical and cultural factors and the expression of hate online. © 2019 IEEE.},
	author_keywords = {Hate Speech Detection; NLP Applications and Tools; Social Sciences},
	keywords = {Intelligent computing; Social networking (online); Social sciences; Speech; Automatic Detection; Cultural factors; Exploratory analysis; Political debates; Political instability; Speech detection; Statistical datas; Supervised classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019; Conference date: 3 September 2019 through 6 September 2019; Conference code: 155963}
}

@CONFERENCE{Baruah20201562,
	author = {Baruah, Arup and Das, Kaushik Amar and Barbhuiya, Ferdous Ahmed and Dey, Kuntal},
	title = {IIITG-ADBU at SemEval-2020 Task 12: Comparison of BERT and BiLSTM in Detecting Offensive Language},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1562 – 1568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094685580&partnerID=40&md5=4b1ac815479b6a17d0d260890fbcf0b7},
	affiliations = {IIIT, Guwahati, India; Accenture Technology Labs, Bangalore, India},
	abstract = {Task 12 of SemEval 2020 consisted of 3 subtasks, namely offensive language identification (Subtask A), categorization of offense type (Subtask B), and offense target identification (Subtask C). This paper presents the results our classifiers obtained for the English language in the 3 subtasks. The classifiers used by us were BERT and BiLSTM. On the test set, our BERT classifier obtained a macro F1 score of 0.90707 for subtask A, and 0.65279 for subtask B. The BiLSTM classifier obtained a macro F1 score of 0.57565 for subtask C. The paper also performs an analysis of the errors made by our classifiers. We conjecture that the presence of a few misleading instances in the dataset is affecting the performance of the classifiers. Our analysis also discusses the need for temporal context and world knowledge to determine the offensiveness of a few comments. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Classification (of information); Computational linguistics; Semantics; English languages; F1 scores; Language identification; Offensive languages; Performance; Subtask; Target's identifications; Test sets; World knowledge; Crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@ARTICLE{Alonso202013,
	author = {Alonso, Pedro and Saini, Rajkumar and Kovács, György},
	title = {Hate Speech Detection Using Transformer Ensembles on the HASOC Dataset},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12335 LNAI},
	pages = {13 – 21},
	doi = {10.1007/978-3-030-60276-5_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092898876&doi=10.1007%2f978-3-030-60276-5_2&partnerID=40&md5=1490dc549c1cce871d9af6456a361dcf},
	affiliations = {Embedded Internet Systems Lab, Luleå University of Technology, Luleå, Sweden; MTA-SZTE Research Group on Artificial Intelligence, Szeged, Hungary},
	abstract = {With the ubiquity and anonymity of the Internet, the spread of hate speech has been a growing concern for many years now. The language used for the purpose of dehumanizing, defaming or threatening individuals and marginalized groups not only threatens the mental health of its targets, as well as their democratic access to the Internet, but also the fabric of our society. Because of this, much effort has been devoted to manual moderation. The amount of data generated each day, particularly on social media platforms such as Facebook and twitter, however makes this a Sisyphean task. This has led to an increased demand for automatic methods of hate speech detection. Here, to contribute towards solving the task of hate speech detection, we worked with a simple ensemble of transformer models on a twitter-based hate speech benchmark. Using this method, we attained a weighted-score of 0.8426, which we managed to further improve by leveraging more training data, achieving a weighted-score of 0.8504. Thus markedly outperforming the best performing system in the literature. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Ensemble; Hate speech detection; Natural Language Processing; RoBERTa; Transformers},
	keywords = {Social networking (online); Speech; Automatic method; Facebook; Mental health; Social media platforms; Speech detection; Training data; Transformer models; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; Conference name: 22nd International Conference on Speech and Computer, SPECOM 2020; Conference date: 7 October 2020 through 9 October 2020; Conference code: 249919}
}

@CONFERENCE{Chowdhury2019285,
	author = {Chowdhury, Arijit Ghosh and Didolkar, Aniket and Sawhney, Ramit and Shah, Rajiv Ratn},
	title = {Beyond hostile linguistic cues: The gravity of online milieu for hate speech detection in Arabic},
	year = {2019},
	journal = {HT 2019 - Proceedings of the 30th ACM Conference on Hypertext and Social Media},
	pages = {285 – 286},
	doi = {10.1145/3342220.3344930},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073359488&doi=10.1145%2f3342220.3344930&partnerID=40&md5=c7b42081e1fd84b35ea80b2d13f7a7bc},
	affiliations = {Manipal Institute of Technology, India; Netaji Subhas Institute of Technology, India; MIDAS, IIIT-Delhi, India},
	abstract = {Religious Hate speech poses grave dangers for the cohesion of a democratic society, the protection of human rights and the rule of law. While previous work has shown that linguistic features can be effectively used for text categorization in Arabic, employing information coming from users'social networks has not yet been explored for such complex user characteristics. Systems relying on language information tend to have low precision because they tend to rely on messages containing particular terms indicating hate speech. In this paper, we study the novel problem of exploiting social context for detection of religious hate speech in Arabic tweets, given information extracted from their online milieu by learning a low-dimensional vector representation of users. © 2019 Copyright held by the owner/author(s).},
	author_keywords = {Arabic-NLP; Hate Speech; Social Media; Social Networks},
	keywords = {Hypertext systems; Laws and legislation; Linguistics; Social networking (online); Speech; Arabic nlp; Language informations; Linguistic features; Low dimensional; Social media; Speech detection; Text categorization; User characteristics; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 30th ACM Conference on Hypertext and Social Media, HT 2019; Conference date: 17 September 2019 through 20 September 2019; Conference code: 151930}
}

@CONFERENCE{Pérez20201524,
	author = {Pérez, Juan Manuel and Arango, Aymé and Luque, Franco M.},
	title = {ANDES at SemEval-2020 Task 12: A jointly-trained BERT multilingual model for offensive language detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1524 – 1531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094717369&partnerID=40&md5=a86d310dbd5f6c6d3c4395d6f84efdb7},
	affiliations = {ICC, CONICET, Universidad de Buenos Aires, Argentina; University of Chile, IMFD, Chile; CONICET, Universidad Nacional de Córdoba, Argentina},
	abstract = {This paper describes our participation in SemEval-2020 Task 12: Multilingual Offensive Language Detection. We jointly-trained a single model by fine-tuning Multilingual BERT to tackle the task across all the proposed languages: English, Danish, Turkish, Greek and Arabic. Our single model had competitive results, with a performance close to top-performing systems in spite of sharing the same parameters across all languages. Zero-shot and few-shot experiments were also conducted to analyze the transference performance among these languages. We make our code public for further research. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Fine tuning; Language detection; Offensive languages; Performance; Single models; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Husain20202133,
	author = {Husain, Fatemah and Lee, Jooyeon and Henry, Sam and Uzuner, Özlem},
	title = {SalamNET at SemEval-2020 Task 12: Deep Learning Approach for Arabic Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2133 – 2139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094804382&partnerID=40&md5=8a6c76cd424ef26d86757e4bde6e9c57},
	affiliations = {Kuwait University, State of Kuwait, Kuwait; George Mason University, United States},
	abstract = {This paper describes SalamNET, an Arabic offensive language detection system that has been submitted to SemEval 2020 shared task 12: Multilingual Offensive Language Identification in Social Media. Our approach focuses on applying multiple deep learning models and conducting in depth error analysis of results to provide system implications for future development considerations. To pursue our goal, a Recurrent Neural Network (RNN), a Gated Recurrent Unit (GRU), and Long-Short Term Memory (LSTM) models with different design architectures have been developed and evaluated. The SalamNET, a Bi-directional Gated Recurrent Unit (Bi-GRU) based model, reports a macro-F1 score of 0.83. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Semantics; Depth errors; Detection system; Implications for futures; Language detection; Language identification; Learning approach; Learning models; Memory modeling; Offensive languages; Social media; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Putra Perdana2019143,
	author = {Putra Perdana, B.B. Sakti and Irawan, Budhi and Setianingsih, Casi},
	title = {Hate speech detection in Indonesian language on instagram comment section using deep neural network classification method},
	year = {2019},
	journal = {Proceedings - 2019 IEEE Asia Pacific Conference on Wireless and Mobile, APWiMob 2019},
	pages = {143 – 149},
	doi = {10.1109/APWiMob48441.2019.8964197},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079272600&doi=10.1109%2fAPWiMob48441.2019.8964197&partnerID=40&md5=c95afcf76b7bec6d86f80a5e8d805835},
	affiliations = {School of Electrical Engineering, Telkom University, Bandung, Indonesia},
	abstract = {Instagram is the second social media that is often used by people, especially in Indonesia. Instagram has a function to comment on photos or videos uploaded by users. Comments that submitted by a community, some of them are positive, some of them are negative. Which one is hate speech. Based on ITE constitution that prohibited acts are intentionally and without rights to disseminate information intended to incite hatred or hostility of certain individuals and/or groups of people based on ethnicity, religion, race, and intergroup. Authorities find it difficult to handle the hate speech because there are many variations of hate speech. Therefore, the system is made to detect hate speech using Deep Neural Network method. With this system, it can be to help the authorities to handle this case, especially on Instagram comment section. From the research results of this final task in classifying a hate speech from Instagram column comment section obtained accuracy with an average 97.19%. © 2019 IEEE.},
	author_keywords = {Deep Neural Network; Hate Speech; Instagram},
	keywords = {Information dissemination; Neural networks; Speech; Speech recognition; Indonesia; Indonesian languages; Instagram; Neural network classification; Neural network method; Research results; Social media; Speech detection; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 5th IEEE Asia Pacific Conference on Wireless and Mobile, APWiMob 2019; Conference date: 5 November 2019 through 7 November 2019; Conference code: 157082}
}

@CONFERENCE{Sohn2019551,
	author = {Sohn, Hajung and Lee, Hyunju},
	title = {MC-BERT4HATE: Hate speech detection using multi-channel bert for different languages and translations},
	year = {2019},
	journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
	volume = {2019-November},
	pages = {551 – 559},
	doi = {10.1109/ICDMW.2019.00084},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078732568&doi=10.1109%2fICDMW.2019.00084&partnerID=40&md5=87320568f4040e69775b28598cf39166},
	affiliations = {School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea},
	abstract = {The growth of social networking services (SNS) has altered the way and scale of communication in cyberspace. However, the amount of online hate speech is increasing because of the anonymity and mobility such services provide. As manual hate speech detection by human annotators is both costly and time consuming, there are needs to develop an algorithm for automatic recognition. Transferring knowledge by fine-tuning a pre-trained language model has been shown to be effective for improving many downstream tasks in the field of natural language processing. The Bidirectional Encoder Representations from Transformers (BERT) is a language model that is pre-trained to learn deep bidirectional representations from a large corpus. In this paper, we propose a multi-channel model with three versions of BERT (MC-BERT), the English, Chinese, and multilingual BERTs for hate speech detection. We also explored the usage of translations as additional input by translating training and test sentences to the corresponding languages required for different BERT models. We used three datasets in non-English languages to compare our model with previous approaches including the 2019 SemEval HatEval Spanish dataset, 2018 GermEval shared task on the identification of Offensive Language dataset, and 2018 EvalIta HaSpeeDe Italian dataset. Finally, we were able to achieve the state-of-the-art or comparable performance on these datasets by conducting thorough experiments. © 2019 IEEE.},
	author_keywords = {BERT; Deep learning; Hate speech Classification; Social networking services; Transfer learning},
	keywords = {Computational linguistics; Data mining; Deep learning; Natural language processing systems; Social networking (online); Speech; Translation (languages); Automatic recognition; BERT; Multi-channel model; NAtural language processing; Non-English languages; Social networking services; Speech classification; Transfer learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 59; Conference name: 19th IEEE International Conference on Data Mining Workshops, ICDMW 2019; Conference date: 8 November 2019 through 11 November 2019; Conference code: 156834}
}

@ARTICLE{Potharaju201920,
	author = {Potharaju, Yakaiah and Kamsali, Manjunathachari and Kesavari, Chennakesava Reddy},
	title = {Classification of ontological violence content detection through audio features and supervised learning},
	year = {2019},
	journal = {International Journal of Intelligent Engineering and Systems},
	volume = {12},
	number = {3},
	pages = {20 – 30},
	doi = {10.22266/IJIES2019.0630.03},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069989253&doi=10.22266%2fIJIES2019.0630.03&partnerID=40&md5=4bad0d3a665f31dca0dc2eaa4df27175},
	affiliations = {Department of Electronics and Communication Engineering, Rayalaseema University, Kurnool, Andhra Pradesh, 518002, India; Department of Electronics and Communication Engineering, Gitam University, SangaReddy, Telangana, India; Department of Electronics and Communication Engineering, Jawaharlal Nehru Technological University, Telangana, India},
	abstract = {Violence detection is one of the important aspects, which can be used in different applications. Based on the data format, the violence can be defined in many ways. This paper focused to develop an automatic violence detection framework from audio type data. To do this, a new and efficient set of features are extracted from the audio signals, which provides more discrimination between different types of violence types in audio signals. Considering both spatial and Mel frequency characteristics of audio signals, totally 12 statistical functionals are accomplished to define every signal. Furthermore, the violence is defined in an ontological fashion, such that the all possible violence types which signify the violent behavior are detected. Extensive simulations are carried out over the proposed detection framework by considering the audio signals extracted from different video clips ripped from different movies. The performance is analyzed through the Receiver Operating Characteristics like, Accuracy, Precision, Recall, and False Positive Rate and the obtained results verify the performance enhancement and show a better performance than the conventional approaches. © 2019 International Journal of Intelligent Engineering and Systems.},
	author_keywords = {Accuracy; Audio; False positive rate; Ontology; SVM; Violence detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Bronze Open Access}
}

@ARTICLE{Makhnytkina2020315,
	author = {Makhnytkina, Olesia and Matveev, Anton and Bogoradnikova, Darya and Lizunova, Inna and Maltseva, Anna and Shilkina, Natalia},
	title = {Detection of Toxic Language in Short Text Messages},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12335 LNAI},
	pages = {315 – 325},
	doi = {10.1007/978-3-030-60276-5_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092889926&doi=10.1007%2f978-3-030-60276-5_31&partnerID=40&md5=96e45c413a7755bd3909846b854328f7},
	affiliations = {ITMO University, Saint Petersburg, 197101, Russian Federation; Saint Petersburg State University, Saint Petersburg, 191124, Russian Federation},
	abstract = {The ever-increasing online communication landscape provides circumstances for people with significant differences in their views to cross paths unlike it was ever possible before. This leads to the raise of toxicity in online comments and discussions and makes the development of means to detect instances of such phenomenon critically important. The toxic language detection problem is fairly researched and some solutions produce highly accurate predictions when significantly large datasets are available for training. However, such datasets are not always available for various languages. In this paper, we review different ways to approach the problem targeting transferring knowledge from one language to another: machine translation, multi-lingual models, and domain adaptation. We also focus on the analysis of methods for word embedding such as Word2Vec, FastText, GloVe, BERT, and methods for classification of toxic comment: Naïve Bayes, Random Forest, Logistic regression, Support Vector Machine, Majority vote, and Recurrent Neural Networks. We demonstrate that for small datasets in the Russian language, traditional machine-learning techniques produce highly competitive results on par with deep learning methods, and also that machine translation of the dataset to the English language produces more accurate results than multi-lingual models. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Classification methods; Domain adaptation; Machine learning; Machine translation; Multi-lingual models; Natural language processing; Toxic language; Word embedding},
	keywords = {Computational linguistics; Computer aided language translation; Decision trees; Large dataset; Logistic regression; Recurrent neural networks; Support vector machines; Support vector regression; Domain adaptation; English languages; Language detection; Machine learning techniques; Machine translations; On-line communication; Russian languages; Short text messages; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 22nd International Conference on Speech and Computer, SPECOM 2020; Conference date: 7 October 2020 through 9 October 2020; Conference code: 249919}
}

@ARTICLE{Kocijan2020185,
	author = {Kocijan, Kristina and Košković, Lucija and Bajac, Petra},
	title = {Detecting Hate Speech Online: A Case of Croatian},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1153 CCIS},
	pages = {185 – 197},
	doi = {10.1007/978-3-030-38833-1_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078398785&doi=10.1007%2f978-3-030-38833-1_16&partnerID=40&md5=0b0ccb607a42911ac4ddadc26fdeec08},
	affiliations = {Department of Information and Communication Sciences, University of Zagreb, Zagreb, Croatia; Department of Linguistics, Faculty of Humanities and Social Sciences, University of Zagreb, Zagreb, Croatia},
	abstract = {This project proposes a NooJ algorithm with the task to find and categorize various slurs, insults and ultimately, hate speech in Croatian. The results also provide a more detailed insight into inappropriate language in Croatian. We strongly emphasize the ethical considerations of (mis) identifying hate speech and as a result, an unethical and undeserved censorship of inappropriate, but free speech. Thus, we tried to make a clear distinction between insults and hate speech. The test corpus consists of written online comments and remarks posted on five Croatian Facebook news pages during one week period. Given the differences between the standard Croatian grammar and syntax, and what is actually being used in informal on-line communication, the false negatives present the biggest difficulty since some variations (substandard usages of cases, spelling errors, colloquialisms) are impossible to predict, and therefore, extremely hard to implement into the algorithm. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Croatian; Hate speech; Information extraction; Insults; NooJ; Pattern detection; Syntactic grammars},
	keywords = {Information retrieval; Natural language processing systems; Speech; Syntactics; Croatians; Insults; NooJ; Pattern detection; Syntactic grammars; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 13th International Conference on Formalizing Natural Languages with NooJ and Its Natural Language Processing Applications, NooJ 2019; Conference date: 7 June 2019 through 9 June 2019; Conference code: 235979}
}

@CONFERENCE{Álvarez20201968,
	author = {Álvarez, Victoria Pachón and Vázquez, Jacinto Mata and Betanzos, J.M.L. and Fernández, José Luis Arjona},
	title = {I2C at SemEval-2020 Task 12: Simple but Effective Approaches to Offensive Speech Detection in Twitter},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1968 – 1977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094801832&partnerID=40&md5=690cac4cea5a72f0083ee95a906c72fb},
	affiliations = {Escuela Técnica Superior de Ingeniería, Universidad de Huelva, Spain},
	abstract = {This paper describes the systems developed for I2C Group to participate on Subtasks A and B in English, and Subtask A in Turkish and Arabic in OffensEval (Task 12 of SemEval 2020). In our experiments we compare three architectures we have developed, two based on Transformer and the other based on classical machine learning algorithms. In this paper, the proposed architectures are described, and the results obtained by our systems are presented. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Learning algorithms; Machine learning; Speech recognition; Effective approaches; Machine learning algorithms; Proposed architectures; Simple++; Speech detection; Subtask; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Basile201954,
	author = {Basile, Valerio and Bosco, Cristina and Fersini, Elisabetta and Nozza, Debora and Patti, Viviana and Rangel, Francisco and Rosso, Paolo and Sanguinetti, Manuela},
	title = {SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {54 – 63},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118567358&partnerID=40&md5=247347b71e0f4b687904119b3fc3c399},
	affiliations = {Dipartimento di Informatica, Università degli Studi di Torino, Italy; Università degli Studi di Milano Bicocca, Italy; Autoritas Consulting, Spain; PRHLT Research Center, Universitat Politècnica de València, Spain},
	abstract = {The paper describes the organization of the SemEval 2019 Task 5 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the task are described by showing how they have been collected and annotated. Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Semantics; Speech recognition; Fine grained; Subtask; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 773; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Altin202050,
	author = {Altin, Lutfiye Seda Mut},
	title = {Identification of offensive language in social media},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2633},
	pages = {50 – 55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089117870&partnerID=40&md5=9b211c73c9096362e0ea9d1aa83f497e},
	affiliations = {LaSTUS-TALN Research Group, DTIC, Universitat Pompeu Fabra, C/Tanger 122-140, Barcelona, 08018, Spain},
	abstract = {Recent work shows that offensive language in social media is a serious problem that affects especially vulnerable groups. Therefore, systems designed to detect offensive language automatically have been the focus of attention of several works. Various Machine Learning approaches have been utilised for the classification of offensive text data. Within the scope of this research we aim to develop a neural network system that will effectively classify offensive text considering different aspects of it. In addition, multilingual and multi-task learning experiments are planned. © 2020 CEUR-WS. All rights reserved.},
	author_keywords = {Bi-LSTM; Neural network; Offensive language; Social media},
	keywords = {Multi-task learning; Natural language processing systems; Social networking (online); Text processing; Focus of Attention; Machine learning approaches; Neural network systems; Offensive languages; Social media; Text data; Vulnerable groups; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Doctoral Symposium of the 35th International Conference of the Spanish Society for Natural Language Processing, SEPLN-DS 2019; Conference date: 25 September 2019; Conference code: 161642}
}

@CONFERENCE{Chakraborty2019,
	author = {Chakraborty, Puja and Seddiqui, Md. Hanif},
	title = {Threat and Abusive Language Detection on Social Media in Bengali Language},
	year = {2019},
	journal = {1st International Conference on Advances in Science, Engineering and Robotics Technology 2019, ICASERT 2019},
	doi = {10.1109/ICASERT.2019.8934609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078071483&doi=10.1109%2fICASERT.2019.8934609&partnerID=40&md5=ea5e98f3b93174f0320e04245818b849},
	affiliations = {University of Chittagong, Dept. of Computer Science and Engineering, Chittagong, 4331, Bangladesh},
	abstract = {Threat and abusive languages spread quickly through social media which can be controlled if we can detect and remove them. Since there exist many social media like Facebook, Twitter, Instagram etc and a huge number of social media users, we need a robust and effective automatic system to identify threat and abusive languages. In our proposed system Machine Learning and Natural Language Processing techniques have been implemented to build an automatic system. Previous research on Bengali abusive language detection used Multinomial Naive Bayes (MNB), Support Vector Machine(SVM) algorithms and considered Bengali Unicode characters to build their system. We considered both Unicode emoticons and Unicode Bengali characters as valid input in our proposed system. Besides MNB and SVM algorithm, we implemented Convolutional Neural Network (CNN) with Long Short Term Memory(LSTM). Among three algorithms, SVM with linear kernel performed best with 78% accuracy. © 2019 IEEE.},
	author_keywords = {Bengali Hate speech Identification; Bengali Text Classification; Convolutional Neural Network (CNN); Long Short Term Memory (LSTM); Multi-nomial Naive Bayes (MNB); Natural Language Processing (NLP); Support Vector Machine(SVM)},
	keywords = {Brain; Classification (of information); Classifiers; Convolution; Learning algorithms; Long short-term memory; Robotics; Social networking (online); Support vector machines; Text processing; Convolutional neural network; Naive bayes; NAtural language processing; Speech identification; Text classification; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49; Conference name: 1st International Conference on Advances in Science, Engineering and Robotics Technology, ICASERT 2019; Conference date: 3 May 2019 through 5 May 2019; Conference code: 156123}
}

@CONFERENCE{Briliani201998,
	author = {Briliani, Annisa and Irawan, Budhi and Setianingsih, Casi},
	title = {Hate speech detection in indonesian language on instagram comment section using K-nearest neighbor classification method},
	year = {2019},
	journal = {Proceedings - 2019 IEEE International Conference on Internet of Things and Intelligence System, IoTaIS 2019},
	pages = {98 – 104},
	doi = {10.1109/IoTaIS47347.2019.8980398},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081102964&doi=10.1109%2fIoTaIS47347.2019.8980398&partnerID=40&md5=25e62a7aa57f57bb34f9133640f81da0},
	affiliations = {School of Electrical Engineering, Telkom University, Bandung, Indonesia},
	abstract = {Instagram is a social media that is widely used by people in the world, especially Indonesia. Instagram has a feature in delivering opinions in the Instagram photo comment section. Comments given can be positive or negative comments. Negative comments on Instagram include hate speech. Hate speech is one of the big problems and very difficult to overcome by the authorities. Because of that, this research will create a system that will detect hate speech or not on the Instagram comment section with the K-Nearest Neighbor classification method. Accuracy generated from this research is 98.13%, 98% of precision, recall and f1-score using K-Nearest Neighbor with K=3. © 2019 IEEE.},
	author_keywords = {Hate speech; Instagram; K-Nearest Neighbor},
	keywords = {Internet of things; Motion compensation; Nearest neighbor search; Speech; F1 scores; Indonesia; Indonesian languages; Instagram; K-nearest neighbor classification; K-nearest neighbors; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; Conference name: 2019 IEEE International Conference on Internet of Things and Intelligence System, IoTaIS 2019; Conference date: 5 November 2019 through 7 November 2019; Conference code: 157521}
}

@CONFERENCE{Kim20191064,
	author = {Kim, Do Yeon and Li, Xiaohang and Wang, Sheng and Zhuo, Yunying and Lee, Roy Ka-Wei},
	title = {Topic enhanced word embedding for toxic content detection in Q&A sites},
	year = {2019},
	journal = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2019},
	pages = {1064 – 1071},
	doi = {10.1145/3341161.3345332},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078853445&doi=10.1145%2f3341161.3345332&partnerID=40&md5=9842526acefa4dbf0ec5fe4030a2611a},
	affiliations = {School of Information Systems, Singapore Management University, Singapore; Department of Computer Science, University of Saskatchewan, Canada},
	abstract = {Increasingly, users are adopting community question-and-answer (Q&A) sites to exchange information. Detecting and eliminating toxic and divisive content in these Q&A sites are paramount tasks to ensure a safe and constructive environment for the users. Insincere question, which is founded upon false premises, is one type of toxic content in Q&A sites. In this paper, we proposed a novel deep learning framework enhanced pre-trained word embeddings with topical information for insincere question classification. We evaluated our proposed framework on a large real-world dataset from Quora Q&A site and showed that the topically enhanced word embedding is able to achieve better results in toxic content classification. An empirical study was also conducted to analyze the topics of the insincere questions on Quora, and we found that topics on “religion”, “gender” and “politics” has a higher proportion of insincere questions. © 2019 Association for Computing Machinery.},
	author_keywords = {NLP; Sequence model; Text classification; Toxic content; Word embedding},
	keywords = {Deep learning; Embeddings; Large dataset; Text processing; Content classification; Content detection; Learning frameworks; Question classification; Sequence modeling; Text classification; Toxic content; Word embedding; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 11th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2019; Conference date: 27 August 2019 through 30 August 2019; Conference code: 156744}
}

@CONFERENCE{Jiang2019671,
	author = {Jiang, Lin and Suzuki, Yoshimi},
	title = {Detecting hate speech from tweets for sentiment analysis},
	year = {2019},
	journal = {2019 6th International Conference on Systems and Informatics, ICSAI 2019},
	pages = {671 – 676},
	doi = {10.1109/ICSAI48974.2019.9010578},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081958060&doi=10.1109%2fICSAI48974.2019.9010578&partnerID=40&md5=f4b46596221be722d3ca7459144ce0f0},
	affiliations = {University of Yamanashi, Kofu, Japan},
	abstract = {In the era of the popularity of Social Networking Service (SNS), people became increasingly inseparable from mobile phones and computers. People want to get information and real-time updates from social media, and they want to know how many Internet citizens have comments and opinions on many dynamic news. The interaction among users on social networking platforms is usually positive, advisory and motivating and influential. However, sometimes people will also reveal objectionable content, such as hate speech, abusive and bullying or discriminatory words. According to multiple methods, we will find out which method has the best accuracy of detecting hate speech from tweets. Many papers using types of data for experimentation. The major innovation of this article is that we used different ratios of data to compare with multiple methods at the same time. As a result, good performance is obtained by using machine learning when data is small. The good results can be obtained by using deep learning when we use more data for our experiments. Using BiRNN can get the best results, compared with other methods we used. Even if this method is superior to other models, we have to consider the type of data set in the future. © 2019 IEEE.},
	author_keywords = {BiRNN; Deep learning; LSTM; Machine learning; SNS; Social; Tweets},
	keywords = {Deep learning; Long short-term memory; Sentiment analysis; Social networking (online); Speech recognition; Technology transfer; Tin; BiRNN; LSTM; Multiple methods; Real-time updates; Social; Social media; Social networking services; Tweets; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; Conference name: 6th International Conference on Systems and Informatics, ICSAI 2019; Conference date: 2 November 2019 through 4 November 2019; Conference code: 158037}
}

@CONFERENCE{Susanty2019350,
	author = {Susanty, Meredita and Sahrul and Rahman, Ahmad Fauzan and Normansyah, Muhammad Dzaky and Irawan, Ade},
	title = {Offensive language detection using artificial neural network},
	year = {2019},
	journal = {Proceeding - 2019 International Conference of Artificial Intelligence and Information Technology, ICAIIT 2019},
	pages = {350 – 353},
	doi = {10.1109/ICAIIT.2019.8834452},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073149239&doi=10.1109%2fICAIIT.2019.8834452&partnerID=40&md5=fd88a4badb6c8ba2180b65ed78e47686},
	affiliations = {Computer Science, Universitas Pertamina, Jakarta, Indonesia},
	abstract = {Governments and social media providers put an effort to tackle offensive, abusive, and profanity in social media as an abuse of speech freedom. Considering the number of Internet user in Indonesia and the conflict caused by offensive content about religion, race, and inter-group issues in Indonesia, there is an urge to develop offensive content detection for posts written in Bahasa. This paper uses an artificial neural network model for not only classifying the words as (non)offensive words but also considering the structure of the sentence to get its context. The challenges are informal grammar and word abbreviation used in social media. Hence, there are noise elimination and normalization processes to address these challenges. The computer simulation results show excellence accuracy of 99.18% training, 94.28% validation, and 96.8% testing, only by utilizing the sigmoid activation function. This model can assist government enforcing the information and electronic transaction law and decreases the number of disputes due to aspiration freedom abuse in social media. © 2019 IEEE.},
	author_keywords = {Artificial intelligent; Machine learning; Natural language processing; Neural networks; Offensive content detection},
	keywords = {Distributed computer systems; Learning algorithms; Learning systems; Natural language processing systems; Neural networks; Artificial intelligent; Artificial neural network modeling; Content detection; Electronic transaction; NAtural language processing; Normalization process; Offensive languages; Sigmoid activation function; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 1st International Conference of Artificial Intelligence and Information Technology, ICAIIT 2019; Conference date: 13 March 2019 through 15 March 2019; Conference code: 151944}
}

@CONFERENCE{Ibrohim2019,
	author = {Ibrohim, Muhammad Okky and Setiadi, Muhammad Akbar and Budi, Indra},
	title = {Identification of hate speech and abusive language on Indonesian twitter using theword2vec, part of speech and emoji features},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3373477.3373495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117539901&doi=10.1145%2f3373477.3373495&partnerID=40&md5=731f0cd2c26ee67d6ba226ad77ae65b5},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia},
	abstract = {Freedom of speech for the people of Indonesia on social media makes the spread of hate speech and abusive language inevitable. If there is no proper handling, this will lead to social disharmony between individuals and communities. The identification of hate speech and abusive language on Twitter in the Indonesian language is quite challenging. Because of its ability to understand the meaning of a sentence, semantic features such as word embedding can be relied on to understand tweets that contain hateful and abusive words. In this study, word embedding (word2vec) feature and its combinations with part of speech and/or emoji were used to identify hate speech and abusive language on Twitter in the Indonesian language. Furthermore, some combinations of unigram with part of speech and/or emojis were also utilized during the experiment and the results were studied. The classification algorithms used in this study were Support Vector Machine, Random Forest Decision Tree, and Logistic Regression. The combination of unigram features, part of speech and emoji obtained the highest accuracy value of 79.85% with F-Measure of 87.51%. © 2019 Association for Computing Machinery.},
	author_keywords = {Abusive Language; Hate Speech; Machine Learning; Twitter},
	keywords = {Decision trees; Embeddings; Learning systems; Logistic regression; Semantics; Social networking (online); Speech; Support vector machines; Support vector regression; Abusive Language; Classification algorithm; Freedom of speech; Indonesian languages; Part Of Speech; Semantic features; Social media; Twitter; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 2019 International Conference on Advanced Information Science and System, AISS 2019; Conference date: 15 November 2019 through 17 November 2019; Conference code: 156850}
}

@CONFERENCE{Sajjad2019251,
	author = {Sajjad, Muhammad and Zulifqar, Fatima and Khan, Muhammad Usman Ghani and Azeem, Muhammad},
	title = {Hate Speech Detection using Fusion Approach},
	year = {2019},
	journal = {2019 International Conference on Applied and Engineering Mathematics, ICAEM 2019 - Proceedings},
	pages = {251 – 255},
	doi = {10.1109/ICAEM.2019.8853762},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073683949&doi=10.1109%2fICAEM.2019.8853762&partnerID=40&md5=257c449e779ae8e08bb443a2bd150daa},
	affiliations = {Al-Khawarizmi Institute of Computer Science (KICS), Pakistan},
	abstract = {Detection of hate speech in user-generated online content has become an issue of increasing importance in recent years and is discerning for applications such as disputed event identification and sentiment analysis. Text classification for online content is a bit challenging task due to the natural language complexity and hastily generated online user microblogs including a plethora of informality and mistakes. This work introduces a system to classify tweets in three categories (i.e., racism, sexism and none). In our classification strategy, we integrate deep features extracted from Convolutional Neural Network(CNN) trained on semantic word embedding with state-of-the-art syntactic and word n-gram features. We perform comprehensive experiments on a standard dataset containing 16k manually annotated tweets. Our proposed approach outperform all other state-of-the-art approaches with a significant increase in accuracy. © 2019 IEEE.},
	author_keywords = {convolutional neural network; deep learning; fusion approach; hate speech detection; logistic regression},
	keywords = {Classification (of information); Convolution; Deep learning; Deep neural networks; Neural networks; Semantics; Sentiment analysis; Convolutional neural network; Event identification; Logistic regressions; Natural languages; Speech detection; State-of-the-art approach; Text classification; Three categories; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; Conference name: 2019 International Conference on Applied and Engineering Mathematics, ICAEM 2019; Conference date: 27 August 2019 through 29 August 2019; Conference code: 152365}
}

@CONFERENCE{Hamdy20202098,
	author = {Hamdy, Ehab and Mitrović, Jelena and Granitzer, Michael},
	title = {nlpUP at SemEval-2020 Task 12: A Blazing Fast System for Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2098 – 2104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094805340&partnerID=40&md5=a05831147c13162ebe3352ba17955e03},
	affiliations = {Faculty of Computer Science and Mathematics, University of Passau, Germany},
	abstract = {In this paper, we introduce our submission for the SemEval Task 12, sub-tasks A and B for offensive language identification and categorization in English tweets. This year the dataset for Task A is significantly larger than in the previous year. Therefore, we have adapted the BlazingText algorithm to extract embedding representation and classify texts after filtering and sanitizing the dataset according to the conventional text patterns on social media. We have gained both advantages of a speedy training process and obtained a good F1 score of 90.88% on the test set. For sub-task B, we opted to fine-tune a Bidirectional Encoder Representation from a Transformer (BERT) to accommodate the limited data for categorizing offensive tweets. We have achieved an F1 score of only 56.86%, but after experimenting with various label assignment thresholds in the pre-processing steps, the F1 score improved to 64%. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Embeddings; F1 scores; Fast systems; Language detection; Language identification; Offensive languages; Previous year; Social media; Subtask; Training process; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@ARTICLE{Da Silva20201179,
	author = {Da Silva, Samuel Caetano and Ferreira, Thiago Castro and Ramos, Ricelli Moreira Silva and Paraboni, Ivandré},
	title = {Data-driven and psycholinguistics-motivated approaches to hate speech detection},
	year = {2020},
	journal = {Computacion y Sistemas},
	volume = {24},
	number = {3},
	pages = {1179 – 1188},
	doi = {10.13053/CYS-24-3-3478},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095689551&doi=10.13053%2fCYS-24-3-3478&partnerID=40&md5=8c39cabde027954be8adba947544fb75},
	affiliations = {University of São Paulo, School of Arts Sciences and Humanities, Brazil; Federal University of Minas Gerais, Arts Faculty, Brazil},
	abstract = {Computational models of hate speech detection and related tasks (e.g., detecting misogyny, racism, xenophobia, homophobia etc.) have emerged as major Natural Language Processing (NLP) research topics in recent years. In the present work, we investigate a range of alternative implementations of three of these tasks - namely, hate speech, aggressive behavior and target group recognition - by presenting a number of experiments involving different learning methods, including regularized logistic regression, convolutional neural networks (CNN) and deep bidirectional transformers (BERT), and using word embeddings, word n-grams, character n-grams and psycholinguistics-motivated (LIWC) features alike. Results suggest that a purely data-driven BERT model, and to some extent also a hybrid psycholinguisticly informed CNN model, generally outperform the alternatives under consideration for all tasks in both English and Spanish languages. © 2020 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {Aggressive language detection; Hate speech; Natural language processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Varade2020265,
	author = {Varade, Rahul S. and Pathak, Vikas B.},
	title = {Detection of hate speech in hinglish language},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1101},
	pages = {265 – 276},
	doi = {10.1007/978-981-15-1884-3_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083676377&doi=10.1007%2f978-981-15-1884-3_25&partnerID=40&md5=190a6cd3051b5dbec36303788b1be8a7},
	affiliations = {Vishwakarma Institute of Technology, Pune, India},
	abstract = {As mobile phones and Internet become more and more popular, the number of social media users in India continues to go up. Majority of Indian social media users use Hinglish as their medium of communication. The Hinglish language is a mixture of Hindi words (typed in English) and English words. However, with increasing numbers, there is also an increase in the amount of hate-filled messages, posts, and comments put up on social media platforms. Hate speech is usually done to target an individual or group of individuals on the basis of caste, community, ethnicity, religion, gender, or any other discriminating factor. It can have negative impacts on the individuals facing it and consequently on the society as well. As the amount in which such kind of content is generated is huge, it becomes necessary to automatically detect hate speech so that preventive measures can be taken to control it. Although there has been quite a lot of research on hate speech detection in English texts, not much work can be found on hate speech detection in Hinglish language. This paper presents an approach of detecting hate speech in Hinglish texts using long short-term memory (LSTM), which works on word embeddings generated by gensim’s word2vec model. © Springer Nature Singapore Pte Ltd 2020.},
	author_keywords = {Hate speech detection; Hinglish; Long short term memory; Transliteration; Word embedding},
	keywords = {Long short-term memory; Machine learning; Social networking (online); Speech; English word; Preventive measures; Social media; Social media platforms; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 1st International Conference on Machine Learning and Information Processing, ICMLIP 2019; Conference date: 27 December 2019 through 28 December 2019; Conference code: 238749}
}

@ARTICLE{Mozafari2020928,
	author = {Mozafari, Marzieh and Farahbakhsh, Reza and Crespi, Noël},
	title = {A BERT-Based Transfer Learning Approach for Hate Speech Detection in Online Social Media},
	year = {2020},
	journal = {Studies in Computational Intelligence},
	volume = {881 SCI},
	pages = {928 – 940},
	doi = {10.1007/978-3-030-36687-2_77},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076696813&doi=10.1007%2f978-3-030-36687-2_77&partnerID=40&md5=65223a1f5ddad71f8abb5cf0ae369869},
	affiliations = {CNRS UMR5157, Télécom SudParis, Institut Polytechnique de Paris, Évry, France},
	abstract = {Generated hateful and toxic content by a portion of users in social media is a rising phenomenon that motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. We not only need an efficient automatic hate speech detection model based on advanced machine learning and natural language processing, but also a sufficiently large amount of annotated data to train a model. The lack of a sufficient amount of labelled hate speech data, along with the existing biases, has been the main issue in this domain of research. To address these needs, in this study we introduce a novel transfer learning approach based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers). More specifically, we investigate the ability of BERT at capturing hateful context within social media content by using new fine-tuning methods based on transfer learning. To evaluate our proposed approach, we use two publicly available datasets that have been annotated for racism, sexism, hate, or offensive content on Twitter. The results show that our solution obtains considerable performance on these datasets in terms of precision and recall in comparison to existing approaches. Consequently, our model can capture some biases in data annotation and collection process and can potentially lead us to a more accurate model. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {BERT; Fine-tuning; Hate speech detection; Language modeling; NLP; Social media; Transfer learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 252; Conference name: 8th International Conference on Complex Networks and their Applications, COMPLEX NETWORKS 2019; Conference date: 10 December 2019 through 12 December 2019; Conference code: 234509}
}

@ARTICLE{Bisht2020243,
	author = {Bisht, Akanksha and Singh, Annapurna and Bhadauria, H.S. and Virmani, Jitendra and Kriti},
	title = {Detection of hate speech and offensive language in twitter data using LSTM model},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1124},
	pages = {243 – 264},
	doi = {10.1007/978-981-15-2740-1_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081544258&doi=10.1007%2f978-981-15-2740-1_17&partnerID=40&md5=b8940e9f71a5c7a54247620b6f1dd7cd},
	affiliations = {G B Pant Institute of Engineering and Technology, Pauri Garhwal, Uttarakhand, India; CSIR—Central Scientific Instruments Organization, Chandigarh, India; Thapar Institute of Engineering and Technology, Patiala, Punjab, India},
	abstract = {In today’s world, internet is an emerging technology with exponential user growth. A major concern with that is the increase of toxic online content by people of different backgrounds. With the expansion of deep learning, quite a lot of researches have inclined toward using their deep neural networks for abundant discipline. Even for natural language processing (NLP)-based tasks, deep networks, specifically recurrent neural network (RNN), and their types are lately being considered over the traditional shallow networks. This paper addresses the problem of hate speech hovering on social media. We propose an LTSM-based classification system that differentiates between hate speech and offensive language. This system describes a contemporary approach that employs word embeddings with LSTM and Bi-LSTM neural networks for the identification of hate speech on Twitter. The best performing LSTM network classifier achieved an accuracy of 86% with early stopping criterion based on loss function during training. © Springer Nature Singapore Pte Ltd. 2020.},
	author_keywords = {Bi-LSTM; Deep learning; Hate speech; LSTM; NLP; Offensive language; Sentiment analysis; Twitter},
	keywords = {Deep learning; Deep neural networks; Sentiment analysis; Social networking (online); Speech; Speech recognition; Classification system; Emerging technologies; LSTM; NAtural language processing; Network classifiers; Offensive languages; Recurrent neural network (RNN); Twitter; Long short-term memory},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 53}
}

@ARTICLE{Baratalipour2020695,
	author = {Baratalipour, Nasrin and Suen, Ching Y. and Ormandjieva, Olga},
	title = {Abusive Language Detection Using BERT Pre-trained Embedding},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12068 LNCS},
	pages = {695 – 701},
	doi = {10.1007/978-3-030-59830-3_60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092901706&doi=10.1007%2f978-3-030-59830-3_60&partnerID=40&md5=653ca3ee2c71e33f29ba392618c3748b},
	affiliations = {Concordia University, Montreal, Canada},
	abstract = {The rapid growth in social communication increases the importance of detecting toxic languages. However, detecting toxic language is difficult because of deliberately noisy words and lack of labeled data. These issues cause a low recall in toxic language detection. To address these, we utilized pre-trained BERT models for toxic language detection. We hypothesize pre-trained sub-words embeddings allow BERT models to quickly learn the meaning of obfuscation words and, hence improve the recall of the models on toxic language detection. Our results confirm this hypothesis and show that fine-tuned BERT models perform on a par with the state-of-the-art on the Twitter dataset and outperform the state-of-the-art on the Wikipedia dataset. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Abusive language in social media; BERT; Pre-trained word embedding},
	keywords = {Artificial intelligence; Embeddings; Language detection; Rapid growth; Social communications; State of the art; Sub words; Wikipedia; Pattern recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Pattern Recognition and Artificial Intelligence, ICPRAI 2020; Conference date: 19 October 2020 through 23 October 2020; Conference code: 249999}
}

@CONFERENCE{Febriana2019379,
	author = {Febriana, Trisna and Budiarto, Arif},
	title = {Twitter Dataset for Hate Speech and Cyberbullying Detection in Indonesian Language},
	year = {2019},
	journal = {Proceedings of 2019 International Conference on Information Management and Technology, ICIMTech 2019},
	pages = {379 – 382},
	doi = {10.1109/ICIMTech.2019.8843722},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073200667&doi=10.1109%2fICIMTech.2019.8843722&partnerID=40&md5=b0694f2889b8bfbb26550d8f362392fa},
	affiliations = {Information Systems Department, Bina Nusantara University, Jakarta, 11480, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, 11480, Indonesia},
	abstract = {During the 2019 election period in Indonesia, many hate speech and cyberbullying cases have occurred in social media platforms including Twitter. The government tries to filter every negative content to be spread out during this period. However, to detect hate speech is not an easy task. This paper presents the process of developing a dataset that can be used to build a hate speech detection model. More than 1 million tweets have been successfully collected from using Twitter API. The basic preprocessing and preliminary study using machine learning was implemented. Latent Dirichlet Allocation (LDA) algorithm was used to extract the topic for each tweet to see whether these topics can be associated with debate themes. Pretrained sentiment analysis was also applied to the dataset to generate a polarity score for each tweet. From 83,752 tweets included in the analysis step, the number of positive and negative tweets are almost the same. © 2019 IEEE.},
	author_keywords = {cyberbullying; election; hate speech; LDA; sentiment analysis; twitter},
	keywords = {Computer crime; Information management; Sentiment analysis; Social networking (online); Speech; Statistics; Cyber bullying; election; Indonesian languages; Latent dirichlet allocations; Social media platforms; Speech detection; Spread outs; twitter; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; Conference name: 4th International Conference on Information Management and Technology, ICIMTech 2019; Conference date: 19 August 2019 through 20 August 2019; Conference code: 152147}
}

@CONFERENCE{Sazany2019211,
	author = {Sazany, Erryan and Budi, Indra},
	title = {Hate speech identification in text written in Indonesian with recurrent neural network},
	year = {2019},
	journal = {2019 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2019},
	pages = {211 – 216},
	doi = {10.1109/ICACSIS47736.2019.8979959},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081087711&doi=10.1109%2fICACSIS47736.2019.8979959&partnerID=40&md5=bf8e902fb92fc8d79ab7973c467c989b},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Jakarta, Indonesia},
	abstract = {Some researches had succeeded in doing hate speech identification automatically from text with machine learning and deep learning approaches. However, it was still unclear how adaptive is a deep learning-based model if it is tested on a different set of text data with different domain. To address this issue, this research proposed some deep learning-based methods, using some variants of Recurrent Neural Network to identify hate speech in texts sourced from Twitter, and then used to predict other set of text data sourced from Facebook and Twitter. The experiment was done in order to measure the difference of model performance between training phase and testing phase. Experiment results showed that the proposed method outperformed the machine learning based methods, both in training phase, by GRU algorithm with 85.37% F1-score, and in testing phase, by LSTM algorithm with 76.30% F1-score. Then, in terms of adaptability of model performance, the proposed method gave comparable result against the baseline method. © 2019 IEEE.},
	author_keywords = {Adaptability; Deep learning; Hate speech; Recurrent neural network; Text classification},
	keywords = {Classification (of information); Deep learning; Deep neural networks; Information systems; Information use; Long short-term memory; Recurrent neural networks; Social networking (online); Speech recognition; Text processing; Adaptability; Different domains; Learning approach; Learning Based Models; Learning-based methods; Model performance; Speech identification; Text classification; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 11th International Conference on Advanced Computer Science and Information Systems, ICACSIS 2019; Conference date: 12 October 2019 through 13 October 2019; Conference code: 157525}
}

@CONFERENCE{Koushik2019,
	author = {Koushik, Garima and Rajeswari, K. and Muthusamy, Suresh Kannan},
	title = {Automated hate speech detection on Twitter},
	year = {2019},
	journal = {Proceedings - 2019 5th International Conference on Computing, Communication Control and Automation, ICCUBEA 2019},
	doi = {10.1109/ICCUBEA47591.2019.9128428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088167453&doi=10.1109%2fICCUBEA47591.2019.9128428&partnerID=40&md5=adbada3f5ac11b2f7deca847e3c1e00d},
	affiliations = {Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India; FCA-ICT Inbound Logistics and Supply Chain, System Technology Group, Michigan, United States},
	abstract = {With the sudden increase in micro-blogging websites such as Twitter, Facebook, and Tumbler, the communication between people becomes indirect and reliable; people from different educational backgrounds, cultures share their opinion on different aspects of life every day. This has resulted in conflicts among people. As a result, the use of hate speech becomes a very serious problem. Manual detection of such content from these websites is a very tedious task. Hate speech is the use of aggressive, violent or offensive language which targets a specific group of people sharing common property, this property can be their gender, ethnic group or their believes and regions. The proposed model is capable to detect hate content on Twitter automatically. This approach is based on a bag of words and TFIDF (term frequency-inverse document frequency) approach. These features are used to train machine learning classifiers. Exhaustive experiments are conducted on existing twitter dataset and the accuracy obtained by logistic regression classifier is equal to 94.11% on detecting whether a particular tweet is hateful or not. © 2019 IEEE.},
	author_keywords = {Bag of Words; Hate Speech; TFIDF},
	keywords = {Automation; Classification (of information); Learning systems; Logistic regression; Text processing; Websites; Bag of words; Common property; Ethnic groups; Logistic regression classifier; Micro blogging; Offensive languages; Speech detection; Term frequency-inverse document frequencies; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 5th International Conference on Computing, Communication, Control and Automation, ICCUBEA 2019; Conference date: 19 September 2019 through 21 September 2019; Conference code: 161542}
}

@CONFERENCE{Mohaouchane2019466,
	author = {Mohaouchane, Hanane and Mourhir, Asmaa and Nikolov, Nikola S.},
	title = {Detecting Offensive Language on Arabic Social Media Using Deep Learning},
	year = {2019},
	journal = {2019 6th International Conference on Social Networks Analysis, Management and Security, SNAMS 2019},
	pages = {466 – 471},
	doi = {10.1109/SNAMS.2019.8931839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077815967&doi=10.1109%2fSNAMS.2019.8931839&partnerID=40&md5=4c3517a82f61555ca08fe8e7e66af005},
	affiliations = {School of Science and Engineering, Al Akhawayn University, Ifrane, Morocco; University of Limerick, Department of Computer Science and Information Systems, Limerick, Ireland},
	abstract = {Offensive content on social media such as verbal attacks, demeaning comments or hate speech has many negative effects on its users. The automatic detection of offensive language on Arabic social media is an important step towards the regulation of such content for Arabic speaking users of social media. This paper presents the results of evaluating the performance of four different neural network architectures for this task: Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (Bi-LSTM), Bi-LSTM with attention mechanism, and a combined CNN-LSTM architecture. These networks are trained and tested on a labeled dataset of Arabic YouTube comments. We run this dataset through a series of pre-processing steps and use Arabic word embeddings to represent the comments. We also apply Bayesian optimization techniques to tune the hyperparameters of the neural network models. We train and test each network using 5-fold cross validation. The CNN-LSTM achieves the highest recall (83.46%), followed by the CNN (82.24%), the Bi-LSTM with attention (81.51%) and the Bi-LSTM (80.97%). © 2019 IEEE.},
	author_keywords = {Arabic language; attention model; convolutional neural network; deep learning; long short-term memory; offensive language detection; social media},
	keywords = {Bismuth compounds; Brain; Convolution; Deep learning; Deep neural networks; Memory architecture; Network architecture; Social networking (online); Arabic languages; Attention model; Convolutional neural network; Offensive languages; Social media; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68; Conference name: 6th International Conference on Social Networks Analysis, Management and Security, SNAMS 2019; Conference date: 22 October 2019 through 25 October 2019; Conference code: 156061}
}

@CONFERENCE{Alrehili2019,
	author = {Alrehili, Ahlam},
	title = {Automatic hate speech detection on social media: A brief survey},
	year = {2019},
	journal = {Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA},
	volume = {2019-November},
	doi = {10.1109/AICCSA47632.2019.9035228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082727526&doi=10.1109%2fAICCSA47632.2019.9035228&partnerID=40&md5=714595a6f57183ccedb083bd29ad2f96},
	affiliations = {Computer Science Department, Taibah University, El-Madina El-Monawara, Saudi Arabia},
	abstract = {Due to the advancement in technology and the explosion of the information age, people communicate with each other indirectly via using the online social networks (OSNs), such as Facebook Snapchat, Instagram, and Twitter. Users of OSNs can post anything without any control or constraint of the content, which leads to increase in spreading of hateful and offensive speech among users, thus resulting in an increase in crimes, murder, and terrorism. Hence, this paper provides a survey and state of the art natural language processing (NLP) technique that is used in automatic detection of the hate speech on OSNs, such as dictionaries, bag-of-words, N-gram etc. © 2019 IEEE.},
	author_keywords = {Automatic detection; Bag-of-words; Hate speech; Hateful dictionaries; N-gram; Offensive; Online social network; OSN},
	keywords = {Computational linguistics; Natural language processing systems; Social sciences computing; Speech recognition; Surveys; Automatic Detection; Bag of words; N-grams; Offensive; On-line social networks; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 16th ACS/IEEE International Conference on Computer Systems and Applications, AICCSA 2019; Conference date: 3 November 2019 through 7 November 2019; Conference code: 158567}
}

@CONFERENCE{Cisnero2020,
	author = {Cisnero, Mariano Jason Rodriguez and Bueno, Reynier Ortega},
	title = {UO @ HaSpeeDe2: Ensemble model for Italian hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097527651&partnerID=40&md5=e9e48f5add4dbe483599d8922e69d259},
	affiliations = {Universidad de Oriente, Santiago de Cuba, Cuba},
	abstract = {This document describes our participation in the Hate Speech Detection task at Evalita 2020. Our system is based on deep learning techniques, specifically RNNs and attention mechanism, mixed with transformer representations and linguistic features. In the training process a multi task learning was used to increase the system effectiveness. The results show how some of the selected features were not a good combination within the model. Nevertheless, the generalization level achieved yield encourage results. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Deep learning; Linguistics; Multi-task learning; Natural language processing systems; Speech recognition; Attention mechanisms; Ensemble modeling; Learning techniques; Linguistic features; Speech detection; System effectiveness; Training process; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@CONFERENCE{Yao20202203,
	author = {Yao, Yinnan and Su, Nan and Ma, Kun},
	title = {UJNLP at SemEval-2020 Task 12: Detecting Offensive Language Using Bidirectional Transformers},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2203 – 2208},
	doi = {10.18653/v1/2020.semeval-1.293},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094773205&doi=10.18653%2fv1%2f2020.semeval-1.293&partnerID=40&md5=77bbd9b044e2b027ae6c8e5106b3b7db},
	affiliations = {School of Information Science and Engineering, University of Jinan, China; Shandong Provincial Key Laboratory of Network Based Intelligent Computing, University of Jinan, China},
	abstract = {In this paper, we built several pre-trained models to participate SemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media. In the common task of Offensive Language Identification in Social Media, pre-trained models such as Bidirectional Encoder Representation from Transformer (BERT) have achieved good results. We preprocess the dataset by the language habits of users in social network. Considering the data imbalance in OffensEval, we screened the newly provided machine annotation samples to construct a new dataset. We use the dataset to fine-tune the Robustly Optimized BERT Pretraining Approach (RoBERTa). For the English subtask B, we adopted the method of adding Auxiliary Sentences (AS) to transform the single-sentence classification task into a relationship recognition task between sentences. Our team UJNLP wins the ranking 16th of 85 in English subtask A (Offensive language identification). © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Social networking (online); Classification tasks; Data imbalance; Language identification; Offensive languages; Pre-training; Preprocess; Sentence classifications; Social media; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jarquín-Vásquez2020282,
	author = {Jarquín-Vásquez, Horacio Jesús and Montes-y-Gómez, Manuel and Villaseñor-Pineda, Luis},
	title = {Not all swear words are used equal: Attention over word n-grams for abusive language identification},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12088 LNCS},
	pages = {282 – 292},
	doi = {10.1007/978-3-030-49076-8_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087275821&doi=10.1007%2f978-3-030-49076-8_27&partnerID=40&md5=c73af25dffc7f42d21e1de144444a03d},
	affiliations = {Instituto Nacional de Astrofísica, Óptica y Electrónica (INAOE), Puebla, Mexico},
	abstract = {The increasing propagation of abusive language in social media is a major concern for supplier companies and governments because of its negative social impact. A large number of methods have been developed for its automatic identification, ranging from dictionary-based methods to sophisticated deep learning approaches. A common problem in all these methods is to distinguish the offensive use of swear words from their everyday and humorous usage. To tackle this particular issue we propose an attention-based neural network architecture that captures the word n-grams importance according to their context. The obtained results in four standard collections from Twitter and Facebook are encouraging, they outperform the $$F:1$$ scores from state-of-the-art methods and allow identifying a set of inherently offensive swear words, and others in which its interpretation depends on its context. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Abusive language; Attention mechanism; Social media; Text classification},
	keywords = {Automation; Backpropagation; Deep learning; Network architecture; Pattern recognition; Social networking (online); Facebook; Language identification; Learning approach; Number of methods; Social impact; Social media; State-of-the-art methods; Word n-grams; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 12th Mexican Conference on Pattern Recognition, MCPR 2020; Conference date: 24 June 2020 through 27 June 2020; Conference code: 241229}
}

@CONFERENCE{Indurthi201970,
	author = {Indurthi, Vijayasaradhi and Syed, Bakhtiyar and Shrivastava, Manish and Chakravartula, Nikhil and Gupta, Manish and Varma, Vasudeva},
	title = {Fermi at SemEval-2019 task 5: Using sentence embeddings to identify hate speech against immigrants and women on Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {70 – 74},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118577215&partnerID=40&md5=8d149bd8fc58a3bd1f6251fc4ef78444},
	affiliations = {IIIT, Hyderabad, India; Microsoft, India; Teradata, India},
	abstract = {This paper describes our system (Fermi) for Task 5 of SemEval-2019: HatEval: Multilingual Detection of Hate Speech Against Immigrants and Women on Twitter. We participated in the subtask A for English and ranked first in the evaluation on the test set. We evaluate the quality of multiple sentence embeddings and explore multiple training models to evaluate the performance of simple yet effective embedding-ML combination algorithms. Our team - Fermi's model achieved an accuracy of 65.00% for English language in task A. Our models, which use pretrained Universal Encoder sentence embeddings for transforming the input and SVM (with RBF kernel) for classification, scored first position (among 68) in the leaderboard on the test set for Subtask A in English language. In this paper we provide a detailed description of the approach, as well as the results obtained in the task. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Quality control; Semantics; Social networking (online); Support vector machines; Embeddings; English languages; Performance; RBF kernels; Simple++; Subtask; Test sets; Training model; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Tanase20202222,
	author = {Tanase, Mircea-Adrian and Cercel, Dumitru-Clementin and Chiru, Costin-Gabriel},
	title = {UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection on Social Media by Fine-tuning a Variety of BERT-based Models},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2222 – 2231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094694774&partnerID=40&md5=c827304ef73fd82c17a5cfb6a5a10a5f},
	affiliations = {University Politehnica of Bucharest, Faculty of Automatic Control and Computers, Romania},
	abstract = {Offensive language detection is one of the most challenging problem in the natural language processing field, being imposed by the rising presence of this phenomenon in online social media. This paper describes our Transformer-based solutions for identifying offensive language on Twitter in five languages (i.e., English, Arabic, Danish, Greek, and Turkish), which was employed in Subtask A of the Offenseval 2020 shared task. Several neural architectures (i.e., BERT, mBERT, Roberta, XLM-Roberta, and ALBERT), pre-trained using both single-language and multilingual corpora, were fine-tuned and compared using multiple combinations of datasets. Finally, the highest-scoring models were used for our submissions in the competition, which ranked our team 21st of 85, 28th of 53, 19th of 39, 16th of 37, and 10th of 46 for English, Arabic, Danish, Greek, and Turkish, respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Fine tuning; Language detection; Neural architectures; Offensive languages; Online social medias; Scoring models; Social media; Subtask; Turkishs; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Santosh2019310,
	author = {Santosh, T.Y.S.S. and Aravind, K.V.S.},
	title = {Hate speech detection in Hindi-English code-mixed social media text},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {310 – 313},
	doi = {10.1145/3297001.3297048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061133003&doi=10.1145%2f3297001.3297048&partnerID=40&md5=229dff72ddd7c5b6f30d7aa1e5e63dd5},
	affiliations = {IIT Kharagpur, Kharagpur, West Bengal, India},
	abstract = {With the increase in user generated content, particularly on social media networks, the amount of hate speech is also steadily increasing. So, there is a need to automatically detect such hateful content and curb the wrongful activities. While relevant research has been done independently on code-mixed social media texts and hate speech detection, this paper deals with the task of identification of hate speech from code-mixed social media text. We perform experiments with available code-mixed dataset for hate speech detection using two architectures namely sub-word level LSTM model and Hierarchical LSTM model with attention based on phonemic sub-words. © 2019 Association for Computing Machinery.},
	author_keywords = {Code-mixing; Deep learning; Hate speech},
	keywords = {Codes (symbols); Deep learning; Long short-term memory; Social networking (online); Speech; Code-mixing; Social media; Social media networks; Speech detection; Sub words; User-generated content; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66; Conference name: ACM India Joint 6th ACM iKDD International Conference on Data Science and 24th International Conference on Management of Data, CoDS-COMAD 2019; Conference date: 3 January 2019 through 5 January 2019; Conference code: 144297}
}

@ARTICLE{Zhou2020128923,
	author = {Zhou, Yanling and Yang, Yanyan and Liu, Han and Liu, Xiufeng and Savage, Nick},
	title = {Deep Learning Based Fusion Approach for Hate Speech Detection},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {128923 – 128929},
	doi = {10.1109/ACCESS.2020.3009244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089240860&doi=10.1109%2fACCESS.2020.3009244&partnerID=40&md5=000cef0c78ad0a731ad7998db2d7b94d},
	affiliations = {School of Computer Science and Information Engineering, Hubei University, Hubei, China; School of Computing, University of Portsmouth, Portsmouth, United Kingdom; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Department of Management Engineering, Technical University of Denmark, Kongens Lyngby, Denmark},
	abstract = {In recent years, the increasing prevalence of hate speech in social media has been considered as a serious problem worldwide. Many governments and organizations have made significant investment in hate speech detection techniques, which have also attracted the attention of the scientific community. Although plenty of literature focusing on this issue is available, it remains difficult to assess the performances of each proposed method, as each has its own advantages and disadvantages. A general way to improve the overall results of classification by fusing the various classifiers results is a meaningful attempt. We first focus on several famous machine learning methods for text classification such as Embeddings from Language Models (ELMo), Bidirectional Encoder Representation from Transformers (BERT) and Convolutional Neural Network (CNN), and apply these methods to the data sets of the SemEval 2019 Task 5. We then adopt some fusion strategies to combine the classifiers to improve the overall classification performance. The results show that the accuracy and F1-score of the classification are significantly improved.  © 2013 IEEE.},
	author_keywords = {Bert; classifiers fusion; CNN; Hate speech; machine learning},
	keywords = {Classification (of information); Convolutional neural networks; Learning systems; Speech recognition; Text processing; Classification performance; Fusion strategies; Language model; Machine learning methods; Scientific community; Social media; Speech detection; Text classification; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 67; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Pradhan2020433,
	author = {Pradhan, Rahul and Chaturvedi, Ankur and Tripathi, Aprna and Sharma, Dilip Kumar},
	title = {A review on offensive language detection},
	year = {2020},
	journal = {Lecture Notes in Networks and Systems},
	volume = {94},
	pages = {433 – 439},
	doi = {10.1007/978-981-15-0694-9_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078255085&doi=10.1007%2f978-981-15-0694-9_41&partnerID=40&md5=1e374021cde8dff281b92b05c17c20d8},
	affiliations = {GLA University, Mathura, India},
	abstract = {Offensive language, hate speech, and bullying behavior is prevalent during textual communication happening online. Users usually misuse the anonymity available online social media, use this as an advantage, and engage in behavior that is not acceptable socially in actual world. Social media platforms, analytics companies, and online communities had shown much interest and involvement in this field to cope up with this problem by stopping its propagation in social media and its usage. In this paper, we will propose the work done by researchers to form effective strategies for tackling this problem of identifying offense, aggression, and hate speech in user’s textual posts, comments, microblogs, etc. © Springer Nature Singapore Pte Ltd. 2020.},
	author_keywords = {Antisocial behavior online; Hate speech; Machine learning; N-gram; Offensive language; Offensive language detection; tf-idf; Twitter},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Baruah2019371,
	author = {Baruah, Arup and Barbhuiya, Ferdous Ahmed and Dey, Kuntal},
	title = {ABARUAH at SemEval-2019 task 5: Bi-directional LSTM for hate speech detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {371 – 376},
	doi = {10.18653/v1/s19-2065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118557183&doi=10.18653%2fv1%2fs19-2065&partnerID=40&md5=5427104d703873aed46135f1f9a8c8d4},
	affiliations = {Dept. of Comp. Sc. and Engg., IIIT, Guwahati, India; IBM Research India, New Delhi, India},
	abstract = {In this paper, we present the results obtained using bi-directional long short-term memory (BiLSTM) with and without attention and Logistic Regression (LR) models for SemEval-2019 Task 5 titled”HatEval: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter”. This paper presents the results obtained for Subtask A for English language. The results of the BiLSTM and LR models are compared for two different types of preprocessing. One with no stemming performed and no stopwords removed. The other with stemming performed and stopwords removed. The BiLSTM model without attention performed the best for the first test, while the LR model with character n-grams performed the best for the second test. The BiLSTM model obtained an F1 score of 0.51 on the test set and obtained an official ranking of 8/71. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Semantics; Speech recognition; Bi-directional; English languages; F1 scores; Logistic Regression modeling; Memory modeling; N-grams; Speech detection; Subtask; Test sets; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Chopra2020386,
	author = {Chopra, Shivang and Sawhney, Ramit and Mathur, Puneet and Shah, Rajiv Ratn},
	title = {Hindi-english hate speech detection: Author profiling, debiasing, and practical perspectives},
	year = {2020},
	journal = {AAAI 2020 - 34th AAAI Conference on Artificial Intelligence},
	pages = {386 – 393},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094697484&partnerID=40&md5=1a91814526ef9daa73431e83a19c0f2b},
	affiliations = {Delhi Technological University, Delhi, India; Netaji Subhas Institute of Technology, Delhi, India; University of Maryland College Park, United States; IIIT Delhi, Delhi, India},
	abstract = {Code-switching in linguistically diverse, low resource languages is often semantically complex and lacks sophisticated methodologies that can be applied to real-world data for precisely detecting hate speech. In an attempt to bridge this gap, we introduce a three-tier pipeline that employs profanity modeling, deep graph embeddings, and author profiling to retrieve instances of hate speech in Hindi-English code-switched language (Hinglish) on social media platforms like Twitter. Through extensive comparison against several baselines on two real-world datasets, we demonstrate how targeted hate embeddings combined with social network-based features outperform state of the art, both quantitatively and qualitatively. Additionally, we present an expert-in-the-loop algorithm for bias elimination in the proposed model pipeline and study the prevalence and performance impact of the debiasing. Finally, we discuss the computational, practical, ethical, and reproducibility aspects of the deployment of our pipeline across the Web. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Embeddings; Modeling languages; Pipelines; Professional aspects; Social networking (online); Speech recognition; Graph embeddings; Low resource languages; Performance impact; Real-world datasets; Reproducibilities; Social media platforms; Speech detection; State of the art; Artificial intelligence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; Conference name: 34th AAAI Conference on Artificial Intelligence, AAAI 2020; Conference date: 7 February 2020 through 12 February 2020; Conference code: 166426}
}

@CONFERENCE{Moh2020,
	author = {Moh, Melody and Moh, Teng-Sheng and Khieu, Brian},
	title = {No "love" Lost: Defending Hate Speech Detection Models Against Adversaries},
	year = {2020},
	journal = {Proceedings of the 2020 14th International Conference on Ubiquitous Information Management and Communication, IMCOM 2020},
	doi = {10.1109/IMCOM48794.2020.9001767},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081120551&doi=10.1109%2fIMCOM48794.2020.9001767&partnerID=40&md5=70a320281024d597f896aca055cecbba},
	affiliations = {San José State University, Department of Computer Science, San José, CA, United States},
	abstract = {Although current state-of-the-art hate speech detection models achieve praiseworthy results, these models have shown themselves to be vulnerable to attacks. Easy-to-execute lexical evasion schemes such as removal of whitespace from a given text creates significant issues for word-based hate speech detection models. In this paper, we reproduce the results of five cutting-edge models as well as four significant evasion schemes from prior work. These schemes are required to maintain readability which enables us to recreate the original data. We present several new defenses that leverage this need for maintained meaning and readability, and these schemes perform on par with or exceed the results of adversarial retraining. Furthermore, we demonstrate that each lexical attack or evasion scheme can be overcome with our new defense mechanisms with some reducing the effectiveness of the scheme to a mere.1 to.01 drop in F-1 score. We also propose a new evasion scheme that outperforms those in previous work along with a corresponding defense. Using our results as a foundation, we contend that hate speech detection models can be defended against lexically morphed data without the need for significant retraining. Our work suggests that by utilizing the requirement for preserved meaning, one can create a suitable defense against evasion schemes with a high reversal rate. © 2020 IEEE.},
	author_keywords = {adversarial attacks; deep learning; lexical attacks; machine learning; social media},
	keywords = {Deep learning; Information management; Learning systems; Network security; adversarial attacks; Cutting edges; Defense mechanism; lexical attacks; Social media; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 14th International Conference on Ubiquitous Information Management and Communication, IMCOM 2020; Conference date: 3 January 2020 through 5 January 2020; Conference code: 157937}
}

@CONFERENCE{Badjatiya201949,
	author = {Badjatiya, Pinkesh and Gupta, Manish and Varma, Vasudeva},
	title = {Stereotypical bias removal for hate speech detection task using knowledge-based generalizations},
	year = {2019},
	journal = {The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019},
	pages = {49 – 59},
	doi = {10.1145/3308558.3313504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066895838&doi=10.1145%2f3308558.3313504&partnerID=40&md5=97a40f5d19024581350a6e709a0f6179},
	affiliations = {IIIT Hyderabad, Hyderabad, India},
	abstract = {With the ever-increasing cases of hate spread on social media platforms, it is critical to design abuse detection mechanisms to proactively avoid and control such incidents. While there exist methods for hate speech detection, they stereotype words and hence suffer from inherently biased training. Bias removal has been traditionally studied for structured datasets, but we aim at bias mitigation from unstructured text data. In this paper, we make two important contributions. First, we systematically design methods to quantify the bias for any model and propose algorithms for identifying the set of words which the model stereotypes. Second, we propose novel methods leveraging knowledge-based generalizations for bias-free learning. Knowledge-based generalization provides an effective way to encode knowledge because the abstraction they provide not only generalizes content but also facilitates retraction of information from the hate speech detection classifier, thereby reducing the imbalance. We experiment with multiple knowledge generalization policies and analyze their effect on general performance and in mitigating bias. Our experiments with two real-world datasets, a Wikipedia Talk Pages dataset (WikiDetox) of size ∼96k and a Twitter dataset of size ∼24k, show that the use of knowledge-based generalizations results in better performance by forcing the classifier to learn from generalized content. Our methods utilize existing knowledge-bases and can easily be extended to other tasks. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.},
	author_keywords = {Bias detection; Bias removal; Hate speech; Knowledge-based generalization; Natural language processing; Stereotypical bias},
	keywords = {Classification (of information); Knowledge management; Natural language processing systems; Social networking (online); Speech recognition; Bias removal; Detection mechanism; Knowledge based; NAtural language processing; Real-world datasets; Social media platforms; Stereotypical bias; Unstructured texts; Knowledge based systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 75; Conference name: 2019 World Wide Web Conference, WWW 2019; Conference date: 13 May 2019 through 17 May 2019; Conference code: 147966; All Open Access, Green Open Access}
}

@CONFERENCE{Prabowo2019,
	author = {Prabowo, Faizal Adhitama and Ibrohim, Muhammad Okky and Budi, Indra},
	title = {Hierarchical multi-label classification to identify hate speech and abusive language on Indonesian twitter},
	year = {2019},
	journal = {2019 6th International Conference on Information Technology, Computer and Electrical Engineering, ICITACEE 2019},
	doi = {10.1109/ICITACEE.2019.8904425},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076151137&doi=10.1109%2fICITACEE.2019.8904425&partnerID=40&md5=d902c0ac7637f0cce82dde8484adb610},
	affiliations = {University of Indonesia, Faculty of Computer Science, Depok, Indonesia},
	abstract = {Hate speech is one type of speech whose spread is banned in public spaces such as social media. Twitter is one of the social media used by some people to broadcast hate speech. The hate speech can be specified based on the target, category, and level. This paper discusses multi-label text classification using a hierarchical approach to identify targets, groups, and levels of speech hate on Indonesian-language Twitter. Identification is completed using classification algorithms such as the Random Forest Decision Tree (RFDT), Nave Bayes (NB), and Support Vector Machine (SVM). The feature extraction used for classification is the term frequency feature such as word n-gram and character n-gram. This research conducted five scenarios with different label hierarchy to find the highest accuracy that can possibly be reached by hierarchical classification. The experimental results show that the hierarchical approach with the SVM algorithm and word uni-gram feature has an accuracy of 68.43%. It proved that the hierarchical algorithm can increase data transformation or flat approach. © 2019 IEEE.},
	author_keywords = {Hate speech; Hierarchical classification; Machine learning; Multi-label text classification; NB; RFDT; SVM},
	keywords = {Computational linguistics; Decision trees; Learning systems; Metadata; Niobium; Social networking (online); Speech; Speech recognition; Support vector machines; Text processing; Classification algorithm; Hierarchical algorithm; Hierarchical approach; Hierarchical classification; Hierarchical multi-label classifications; Indonesian languages; Multi-label text classification; RFDT; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 6th International Conference on Information Technology, Computer and Electrical Engineering, ICITACEE 2019; Conference date: 26 September 2019 through 27 September 2019; Conference code: 155026}
}

@CONFERENCE{Risch2020405,
	author = {Risch, Julian and Stoll, Anke and Ziegele, Marc and Krestel, Ralf},
	title = {hpiDEDIS at GermEval 2019: Offensive language identification using a German BERT model},
	year = {2020},
	journal = {Proceedings of the 15th Conference on Natural Language Processing, KONVENS 2019},
	pages = {405 – 410},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093848551&partnerID=40&md5=9387f317a75ee9eda8479b6a13278320},
	affiliations = {Hasso Plattner Institute, University of Potsdam, Germany; Heinrich Heine University Düsseldorf, Germany; University of Passau, Germany},
	abstract = {Pre-training language representations on large text corpora, for example, with BERT, has recently shown to achieve impressive performance at a variety of downstream NLP tasks. So far, applying BERT to offensive language identification for German-language texts failed due to the lack of pre-trained, German-language models. In this paper, we fine-tune a BERT model that was pre-trained on 12 GB of German texts to the task of offensive language identification. This model significantly outperforms our baselines and achieves a macro F1 score of 76% on coarse-grained, 51% on fine-grained, and 73% on implicit/explicit classification. We analyze the strengths and weaknesses of the model and derive promising directions for future work. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.},
	keywords = {Coarse-grained; F1 scores; Fine grained; German language; Offensive languages; Pre-training; Text corpora; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 15th Conference on Natural Language Processing, KONVENS 2019; Conference date: 9 October 2019 through 11 October 2019; Conference code: 167846}
}

@CONFERENCE{Socha20202045,
	author = {Socha, Kasper},
	title = {KS@LTH at SemEval-2020 Task 12: Fine-tuning multi- and monolingual transformer models for offensive language detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2045 – 2053},
	doi = {10.18653/v1/2020.semeval-1.270},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094746983&doi=10.18653%2fv1%2f2020.semeval-1.270&partnerID=40&md5=542ae70e9c5fa1314bb8ff87ebee035b},
	affiliations = {Lund University, Lund, Sweden},
	abstract = {This paper describes the KS@LTH system for SemEval-2020 Task 12 OffensEval2: Multilingual Offensive Language Identification in Social Media. We compare mono- and multilingual models based on fine-tuning pre-trained transformer models for offensive language identification in Arabic, Greek, English and Turkish. For Danish, we explore the possibility of fine-tuning a model pre-trained on a similar language, Swedish, and additionally also cross-lingual training together with English. Overall we find that monolingual models achieve higher macro-averaged F1 score. With cross-lingual training of Danish together with English, we achieve better results than by training on the small Danish dataset alone. For Arabic, Danish, English, Greek, and Turkish, we obtained macro-averaged F1 scores of 0.890, 0.775, 0.916, 0.848, and 0.810 ranking 6th, 5th, 6th, 3rd and 4th for each language, respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Cross-lingual; F1 scores; Fine tuning; Language detection; Language identification; Model-based OPC; Offensive languages; Social media; Transformer modeling; Turkishs; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Plum2020423,
	author = {Plum, Alistair and Ranasinghe, Tharindu and Orasan, Constantin and Mitkov, Ruslan},
	title = {RGCL at GermEval 2019: Offensive language detection with deep learning},
	year = {2020},
	journal = {Proceedings of the 15th Conference on Natural Language Processing, KONVENS 2019},
	pages = {423 – 428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076905154&partnerID=40&md5=203d15d334e0b02c68f6e601eb5c4952},
	affiliations = {Research Group in Computational Linguistics, University of Wolverhampton, United Kingdom},
	abstract = {This paper describes the system submitted by the RGCL team to GermEval 2019 Shared Task 2: Identification of Offensive Language. We experimented with five different neural network architectures in order to classify Tweets in terms of offensive language. By means of comparative evaluation, we select the best performing for each of the three subtasks. Overall, we demonstrate that using only minimal preprocessing we are able to obtain competitive results. © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.},
	keywords = {Natural language processing systems; Network architecture; Comparative evaluations; Offensive languages; Subtasks; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 15th Conference on Natural Language Processing, KONVENS 2019; Conference date: 9 October 2019 through 11 October 2019; Conference code: 167846}
}

@ARTICLE{Akhter202091213,
	author = {Akhter, Muhammad Pervez and Jiangbin, Zheng and Naqvi, Irfan Raza and Abdelmajeed, Mohammed and Sadiq, Muhammad Tariq},
	title = {Automatic Detection of Offensive Language for Urdu and Roman Urdu},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {91213 – 91226},
	doi = {10.1109/ACCESS.2020.2994950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085578370&doi=10.1109%2fACCESS.2020.2994950&partnerID=40&md5=0f7382c159a39c432b22bf2c1f9b5441},
	affiliations = {School of Software and Microelectronics, Northwestern Polytechnical University, Xian, 710072, China; School of Computer Science and Technology, Northwestern Polytechnical University, Xian, 710072, China; School of Automation, Northwestern Polytechnical University, Xian, 710072, China},
	abstract = {In recent years, unethical behavior in the cyber-environment has been revealed. The presence of offensive language on social media platforms and automatic detection of such language is becoming a major challenge in modern society. The complexity of natural language constructs makes this task even more challenging. Until now, most of the research has focused on resource-rich languages like English. Roman Urdu and Urdu are two scripts of writing the Urdu language on social media. The Roman script uses the English language characters while the Urdu script uses Urdu language characters. Urdu and Hindi languages are similar with the only difference in their writing script but the Roman scripts of both languages are similar. This study is about the detection of offensive language from the user's comments presented in a resource-poor language Urdu. We propose the first offensive dataset of Urdu containing user-generated comments from social media. We use individual and combined n-grams techniques to extract features at character-level and word-level. We apply seventeen classifiers from seven machine learning techniques to detect offensive language from both Urdu and Roman Urdu text comments. Experiments show that the regression-based models using character n-grams show superior performance to process the Urdu language. Character-level tri-gram outperforms the other word and character n-grams. LogitBoost and SimpleLogistic outperform the other models and achieve 99.2% and 95.9% values of F-measure on Roman Urdu and Urdu datasets respectively. Our designed dataset is publically available on GitHub for future research. © 2013 IEEE.},
	author_keywords = {Machine learning; Natural language Processing; Offensive language detection; Social media; Text processing},
	keywords = {Learning systems; Social networking (online); Automatic Detection; English languages; Machine learning techniques; Natural languages; Offensive languages; Regression-based model; Social media platforms; Word and characters; Computational linguistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 79; All Open Access, Gold Open Access}
}

@CONFERENCE{Rodriguez2019169,
	author = {Rodriguez, Axel and Argueta, Carlos and Chen, Yi-Ling},
	title = {Automatic Detection of Hate Speech on Facebook Using Sentiment and Emotion Analysis},
	year = {2019},
	journal = {1st International Conference on Artificial Intelligence in Information and Communication, ICAIIC 2019},
	pages = {169 – 174},
	doi = {10.1109/ICAIIC.2019.8669073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063888192&doi=10.1109%2fICAIIC.2019.8669073&partnerID=40&md5=d7c8157e4a85fe414b6e3ed8d5e2bd65},
	affiliations = {Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Soul Hackers Labs, Hsinchu, Taiwan},
	abstract = {Hate speech has been an issue since the start of the Internet, but the advent of social media has brought it to unimaginable heights. To address such an important issue, in this paper, we explore a novel framework to effectively detect highly discussed topics that generate hate speech on Facebook. With the use of graph, sentiment, and emotion analysis techniques, we cluster and analyze posts on prominent Facebook pages. Consequently, the proposed framework is able to identify the pages that promote hate speech in the comment sections regarding sensitive topics automatically. © 2019 IEEE.},
	author_keywords = {clustering; Facebook; Hate speech; sentiment analysis},
	keywords = {Artificial intelligence; Sentiment analysis; Social networking (online); Speech; Automatic Detection; clustering; Emotion analysis; Facebook; Facebook pages; Social media; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65; Conference name: 1st International Conference on Artificial Intelligence in Information and Communication, ICAIIC 2019; Conference date: 11 February 2019 through 13 February 2019; Conference code: 146396}
}

@ARTICLE{Mutanga2020614,
	author = {Mutanga, Raymond T. and Naicker, Nalindren and Olugbara, Oludayo O.},
	title = {Hate speech detection in twitter using transformer methods},
	year = {2020},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {11},
	number = {9},
	pages = {614 – 620},
	doi = {10.14569/IJACSA.2020.0110972},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091942728&doi=10.14569%2fIJACSA.2020.0110972&partnerID=40&md5=3f536f9a921943cadaff10aacef8c0a9},
	affiliations = {ICT and Society Research Group, Department of Information Systems, Durban University of Technology, Durban, 4000, South Africa},
	abstract = {Social media networks such as Twitter are increasingly utilized to propagate hate speech while facilitating mass communication. Recent studies have highlighted a strong correlation between hate speech propagation and hate crimes such as xenophobic attacks. Due to the size of social media and the consequences of hate speech in society, it is essential to develop automated methods for hate speech detection in different social media platforms. Several studies have investigated the application of different machine learning algorithms for hate speech detection. However, the performance of these algorithms is generally hampered by inefficient sequence transduction. The Vanilla recurrent neural networks and recurrent neural networks with attention have been established as state-of-the-art methods for the assignments of sequence modeling and sequence transduction. Unfortunately, these methods suffer from intrinsic problems such as long-term dependency and lack of parallelization. In this study, we investigate a transformer-based method and tested it on a publicly available multiclass hate speech corpus containing 24783 labeled tweets. DistilBERT transformer method was compared against attention-based recurrent neural networks and other transformer baselines for hate speech detection in Twitter documents. The study results show that DistilBERT transformer outperformed the baseline algorithms while allowing parallelization. © 2020, Science and Information Organization.},
	author_keywords = {Attention transformer; Deep learning; Neural network; Recurrent network; Sequence transduction},
	keywords = {Backpropagation; Deep neural networks; Recurrent neural networks; Speech; Speech communication; Speech recognition; Speech transmission; Attention transformer; Deep learning; Mass communication; Neural-networks; Parallelizations; Recurrent networks; Sequence transduction; Social media networks; Speech detection; Strong correlation; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 54; All Open Access, Gold Open Access}
}

@CONFERENCE{Sandaruwan2019,
	author = {Sandaruwan, H.M.S.T. and Lorensuhewa, S.A.S. and Kalyani, M.A.L.},
	title = {Sinhala Hate Speech Detection in Social Media using Text Mining and Machine learning},
	year = {2019},
	journal = {19th International Conference on Advances in ICT for Emerging Regions, ICTer 2019 - Proceedings},
	doi = {10.1109/ICTer48817.2019.9023655},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082295647&doi=10.1109%2fICTer48817.2019.9023655&partnerID=40&md5=14bbe850e4d2db9ff3f76b8ed5018946},
	affiliations = {University of Ruhuna, Department of Computer Science, Matara, Sri Lanka},
	abstract = {With the rapid growth of Information technology and Computer Science, communication and presenting ideologies became easier than early decades. Since Social Media are available globally through the web, anyone can easily target a person or a group who belongs to a different culture or a different belief. Though everyone has a right to express his or her own ideas, it should not be harmful, as everyone has a right to be prevented from any kind of hate speeches. In Social Media, there are no automatic methods to detect a hate speech, so anyone can easily be targeted. Since social media service providers do not have good linguistic knowledge on some languages such as Sinhala, they may take a couple of days to remove hate related comments from the content once they noticed. Therefore, hate speech detection in Sinhala language is an urgent and important work to address. We propose lexicon based and machine learning based approaches to automatically detect Sinhala hate and offensive speeches that are being shared through Social Media. In our study, lexicon based approach was initiated with the lexicon generating process and corpus based lexicon gave 76.3% of accuracy for hate, offensive and neutral speech detection. Machine learning approach was begun with building a 3000 comments corpus which is evenly distributed among hate, offensive and neutral speeches. Using this comment corpus, we were able to identify best fitting feature groups and models for Sinhala hate speech detection. According to our experiments, character trigram with Multinomial Naïve Bayes gave the highest recall value as 0.84 with 92.33% accuracy. © 2019 IEEE.},
	author_keywords = {Hate speech detection; machine learning; Natural language processing; Sinhala},
	keywords = {Learning algorithms; Learning systems; Linguistics; Machine learning; Natural language processing systems; Social networking (online); Speech; Text mining; Automatic method; Fitting feature; Linguistic knowledge; Machine learning approaches; NAtural language processing; Sinhala; Social media services; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 19th International Conference on Advances in ICT for Emerging Regions, ICTer 2019; Conference date: 3 September 2019 through 4 September 2019; Conference code: 158293}
}

@CONFERENCE{Struß2020354,
	author = {Struß, Julia Maria and Siegel, Melanie and Ruppenhofer, Josef and Wiegand, Michael and Klenner, Manfred},
	title = {Overview of GermEval task 2, 2019 shared task on the identification of offensive language},
	year = {2020},
	journal = {Proceedings of the 15th Conference on Natural Language Processing, KONVENS 2019},
	pages = {354 – 365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095864412&partnerID=40&md5=4d0103dc33412a6860cf65c2b581ced8},
	affiliations = {Potsdam University of Applied Sciences, Kiepenheuerallee 5, Potsdam, 14469, Germany; Darmstadt University of Applied Sciences, Max-Planck-Str. 2, Dieburg, 64807, Germany; Leibniz Institute for German Language, R5, 6-13, Mannheim, 68161, Germany; Leibniz ScienceCampus, Heidelberg/Mannheim, Germany; University of Zurich, Andreasstrasse 15, Zurich, 8050, Switzerland},
	abstract = {We present the second edition of the GermEval Shared Task on the Identification of Offensive Language. This shared task deals with the classification of German tweets from Twitter. Two subtasks were continued from the first edition, namely a coarse-grained binary classification task and a fine-grained multi-class classification task. As a novel subtask, we introduce the classification of offensive tweets as explicit or implicit. The shared task had 13 participating groups submitting 28 runs for the coarse-grained task, another 28 runs for the fine-grained task, and 17 runs for the implicit-explicit task. We evaluate the results of the systems submitted to the shared task. The shared task homepage can be found at https://projects.fzai.h-da.de/iggsa/ © 2020 German Society for Computational Linguistics & Language Technology. All Rights Reserved.},
	keywords = {Classification (of information); Binary classification; Coarse-grained; Fine grained; Homepage; Implicit-explicit; Multi-class classification; Offensive languages; Subtasks; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; Conference name: 15th Conference on Natural Language Processing, KONVENS 2019; Conference date: 9 October 2019 through 11 October 2019; Conference code: 167846}
}

@CONFERENCE{Nascimento2019325,
	author = {Nascimento, Gabriel and Carvalho, Flavio and Da Cunha, Alexandre Martins and Viana, Carlos Roberto and Guedes, Gustavo Paiva},
	title = {Hate speech detection using Brazilian imageboards},
	year = {2019},
	journal = {Proceedings of the 25th Brazillian Symposium on Multimedia and the Web, WebMedia 2019},
	pages = {325 – 328},
	doi = {10.1145/3323503.3360619},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075626525&doi=10.1145%2f3323503.3360619&partnerID=40&md5=016fb7965ee6aac8a716fbc479580f28},
	affiliations = {CEFET/RJ, Rio de Janeiro, RJ, Brazil; CEFET/RJ - UFF, Rio de Janeiro, RJ, Brazil},
	abstract = {With the changes in human interaction prompted by the development of communications platforms over the internet, hate speech and offensive language emerged as a contemporary problem. Social networks allow users with different opinions and backgrounds to interact without direct eye-to-eye contact. It brings a sense of safety to promote hate speech, which is even more significant in anonymous environments. There are sites called imageboards, composed of different boards aggregating different topics. On some boards, anonymous users widely promote hate speech. However, only a few works in literature have focused on hate speech in imageboards content. This work aims to classify Brazilian Portuguese texts to detect hate speech, using data from the Brazilian 55chan imageboard to build a dataset with hate speech content. Three classifiers were trained to hate speech binary classification. The Linear Support Vector Classifier achieved the best result with 0.955 of F1-score. © 2019 Association for Computing Machinery.},
	author_keywords = {Hate speech detection; Imageboards; Text mining},
	keywords = {Classification (of information); Speech; Binary classification; Communications platform; Eye-to-eye contact; Imageboards; Offensive languages; Speech detection; Support vector classifiers; Text mining; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 25th Brazillian Symposium on Multimedia and the Web, WebMedia 2019; Conference date: 29 October 2019 through 1 November 2019; Conference code: 154262}
}

@CONFERENCE{Sotudeh20201555,
	author = {Sotudeh, Sajad and Xiang, Tong and Yao, Hao-Ren and MacAvaney, Sean and Yang, Eugene and Goharian, Nazli and Frieder, Ophir},
	title = {GUIR at SemEval-2020 Task 12: Domain-Tuned Contextualized Models for Offensive Language Detection},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1555 – 1561},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094757264&partnerID=40&md5=706b60b04253a927da7d29866acdbb58},
	affiliations = {Information Retrieval Lab, Georgetown University, United States},
	abstract = {Offensive language detection is an important and challenging task in natural language processing. We present our submissions to the OffensEval 2020 shared task, which includes three English sub-tasks: identifying the presence of offensive language (Sub-task A), identifying the presence of target in offensive language (Sub-task B), and identifying the categories of the target (Sub-task C). Our experiments explore using a domain-tuned contextualized language model (namely, BERT) for this task. We also experiment with different components and configurations (e.g., a multi-view SVM) stacked upon BERT models for specific sub-tasks. Our submissions achieve F1 scores of 91.7% in Sub-task A, 66.5% in Sub-task B, and 63.2% in Sub-task C. We perform an ablation study which reveals that domain tuning considerably improves the classification performance. Furthermore, error analysis shows common misclassification errors made by our model and outlines research directions for future. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {C (programming language); Computational linguistics; Error analysis; Natural language processing systems; Support vector machines; Classification performance; F1 scores; Language detection; Language model; Misclassification error; Multi-views; Offensive languages; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Englmeier202033,
	author = {Englmeier, Kurt},
	title = {The role of storylines in hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2606},
	pages = {33 – 39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092006243&partnerID=40&md5=79fb49e61cfbe13f26d9dd19ca85a3ec},
	affiliations = {Schmalkalden University of Applied Science, Blechhammer, Schmalkalden, 98574, Germany},
	abstract = {The paper explains why it is necessary to consider offensive statements in the context of their respective narratives if we want to achieve a more accurate classification of hate comments. By considering the narrative, text analysis is more sensitive to a person's affective state that, in turn, helps to reveal the true orientation of the statements in its close proximity. The approach present here is mainly built on named-entity recognition for identifying the different text features we can encounter in hate speech. First, the statements often exhibit a writing style that differs from a regular one in deliberate and unintentional misspellings, strange abbreviations and interpunctuations, and the use of symbols. Central to text analysis here is the identification of toxic terms that clearly evidence the offensive and aggressive character of each statement. However, the biggest challenge is the recognition of emotions and affective state of the writer. Analysis described here underpins the design of a prototype that operates on statements along storylines using a series of bags of words for names of persons, locations, and groups as well as insults, threats, and emotions. First results from this work-in-progress show hate speech analysis of German tweets that refer to the vitally discussed topic "refugees"in Germany. © 2020 for this paper by its authors.},
	author_keywords = {Hate speech detection; Named-entity recognition; Social anchoring; Storyline; Text anchor},
	keywords = {Character recognition; Machine learning; Signal detection; Social networking (online); Text mining; Affective state; Close proximity; Named entity recognition; Recognition of emotion; Speech detection; Use of symbols; Work in progress; Writing style; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 Workshop on Machine Learning for Trend and Weak Signal Detection in Social Networks and Social Media, TWSDetection 2020; Conference date: 27 February 2020 through 28 February 2020; Conference code: 161122}
}

@CONFERENCE{Jahan2019,
	author = {Jahan, Maliha and Ahamed, Istiak and Bishwas, Md. Rayanuzzaman and Shatabda, Swakkhar},
	title = {Abusive Comments Detection in Bangla-English Code-mixed and Transliterated Text},
	year = {2019},
	journal = {ICIET 2019 - 2nd International Conference on Innovation in Engineering and Technology},
	doi = {10.1109/ICIET48527.2019.9290630},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099333002&doi=10.1109%2fICIET48527.2019.9290630&partnerID=40&md5=10111b7ce131493da2a52978478aae11},
	affiliations = {Bangladesh University of Professionals, Department of Information and Communication Technology, Bangladesh; United International University, Department of Computer Science and Engineering, Bangladesh},
	abstract = {The comment section in public websites, while reflecting public opinion and enabling people to provide constructive criticism or to show appreciation, can be viewed by some people as a stage to use vulgar and offensive words without any consequences. With the rising popularity of micro-blogging websites like Facebook, Twitter etc., Bangla Language speakers' tendency to use code-mixing and transliteration is increasing as well. Manually checking and removing abusive comments from public websites can get tedious, which is undesirable in the present day of technological automation. In this paper, we propose a method to detect abusive comments using Machine Learning algorithms. This paper works not only with Bangla text but also with Bangla-English code-mixed text and transliterated Bangla text. The proposed method involves great amount of preprocessing as a result of people's disregard for correct spelling, grammar and punctuation when it comes to writing comments on the internet. For the dataset, we collected comments from public Facebook pages along with the number of likes they got. For features, we used Unigrams, Bigrams, number of likes, emojis along with their categories, sentiment scores, offensive and threatening words used in the comments, detected using our proposed algorithm, and the number of abusive words in each comment. The aforementioned algorithm can detect profanitypes too. After experimenting with three Machine Learning algorithms, namely Support Vector Machine, Random Forest, and Adaboost, the proposed method achieved a highest accuracy of 72.14%.  © 2019 IEEE.},
	author_keywords = {abusive words; adaboost; bangla text; code-mixing; comments; curse words; cyber-harassment; cyberbullying; cybercrime; hate speech; machine learning; profanitype; random forest; SVM; transliterated},
	keywords = {Adaptive boosting; Decision trees; Engineering research; Social aspects; Social networking (online); Support vector machines; Websites; Bigrams; Code-mixing; Facebook; Facebook pages; Micro blogging; Public opinions; Sentiment scores; Writing comments; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 2nd International Conference on Innovation in Engineering and Technology, ICIET 2019; Conference date: 23 December 2019 through 24 December 2019; Conference code: 166032}
}

@CONFERENCE{Vlad2020,
	author = {Vlad, George-Alexandru and Zaharia, George-Eduard and Cercel, Dumitru-Clementin and Dascalu, Mihai},
	title = {UPB @ DANKMEMES: Italian memes analysis - Employing visual models and graph convolutional networks for meme identification and hate speech detection},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097528967&partnerID=40&md5=404db6019b9e25173c494c8589282bd6},
	affiliations = {University Politehnica of Bucharest, Faculty of Automatic Control and Computers, Romania},
	abstract = {Certain events or political situations determine users from the online environment to express themselves by using different modalities. One of them is represented by Internet memes, which combine text with a representative image to entail a wide range of emotions, from humor to sarcasm and even hate. In this paper, we describe our approach for the DANKMEMES competition from EVALITA 2020 consisting of a multimodal multi-task learning architecture based on two main components. The first one is a Graph Convolutional Network combined with an Italian BERT for text encoding, while the second is varied between different image-based architectures (i.e., ResNet50, ResNet152, and VGG-16) for image representation. Our solution achieves good performance on the first two tasks of the current competition, ranking 3rd for both Task 1 (.8437 macroF1 score) and Task 2 (.8169 macro-F1 score), while exceeding by high margins the official baselines. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Convolution; Multi-task learning; Natural language processing systems; Network architecture; Convolutional networks; Image representations; Image-based; Multi-modal; Online environments; Speech detection; Text encoding; Visual model; Convolutional neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592}
}

@ARTICLE{Ridenhour2020202,
	author = {Ridenhour, Michael and Bagavathi, Arunkumar and Raisi, Elaheh and Krishnan, Siddharth},
	title = {Detecting Online Hate Speech: Approaches Using Weak Supervision and Network Embedding Models},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12268 LNCS},
	pages = {202 – 212},
	doi = {10.1007/978-3-030-61255-9_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094121110&doi=10.1007%2f978-3-030-61255-9_20&partnerID=40&md5=06e8d42626c20729e5a3c9b298b9556a},
	affiliations = {UNC Charlotte, Charlotte, United States; Oklahoma State University, Stillwater, United States; Brown University, Providence, United States},
	abstract = {The ubiquity of social media has transformed online interactions among individuals. Despite positive effects, it has also allowed anti-social elements to unite in alternative social media environments (e.g. Gab.com) like never before. Detecting such hateful speech using automated techniques can allow social media platforms to moderate their content and prevent nefarious activities like hate speech propagation. In this work, we propose a weak supervision deep learning model that - (i) quantitatively uncover hateful users and (ii) present a novel qualitative analysis to uncover indirect hateful conversations. This model scores content on the interaction level, rather than the post or user level, and allows for characterization of users who most frequently participate in hateful conversations. We evaluate our model on 19.2M posts and show that our weak supervision model outperforms the baseline models in identifying indirect hateful interactions. We also analyze a multilayer network, constructed from two types of user interactions in Gab (quote and reply) and interaction scores from the weak supervision model as edge weights, to predict hateful users. We utilize the multilayer network embedding methods to generate features for the prediction task and we show that considering user context from multiple networks help achieving better predictions of hateful users in Gab. We receive upto 7% performance gain compared to single layer or homogeneous network embedding models. © 2020, Springer Nature Switzerland AG.},
	keywords = {Deep learning; Embeddings; Forecasting; Multilayers; Network layers; Social networking (online); Automated techniques; Homogeneous network; Interaction levels; Multi-layer network; On-line interactions; Qualitative analysis; Social media platforms; Supervision models; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 13th International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation, SBP-BRiMS 2020; Conference date: 18 October 2020 through 21 October 2020; Conference code: 250059}
}

@CONFERENCE{HaCohen-Kerner2019426,
	author = {HaCohen-Kerner, Yaakov and Shayovitz, Elyashiv and Rochman, Shalom and Cahn, Eli and Didi, Gal and Ben-David, Ziv},
	title = {JCTDHS at SemEval-2019 task 5: Detection of hate speech in tweets using deep learning methods, character N-gram features, and preprocessing methods},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {426 – 430},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118526764&partnerID=40&md5=40a57351ca0bb018ac05c40d833d668b},
	affiliations = {Department of Computer Science, Jerusalem College of Technology, Lev Academic Center, 21 Havaad Haleumi St., P.O.B. 16031, Jerusalem, 9116001, Israel},
	abstract = {In this paper, we describe our submissions to SemEval-2019 contest. We tackled subtask A - “a binary classification where systems have to predict whether a tweet with a given target (women or immigrants) is hateful or not hateful”, a part of task 5 “Multilingual detection of hate speech against immigrants and women in Twitter (HatEval)”. Our system JCTDHS (Jerusalem College of Technology Detects Hate Speech) was developed for tweets written in English. We applied various supervised ML methods, various combinations of n-gram features using the TF-IDF scheme. In addition, we applied various combinations of eight basic preprocessing methods. Our best submission was a special bidirectional RNN, which was ranked at the 11th position out of 68 submissions. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Semantics; Speech recognition; Binary classification; Jerusalem college of technologies; Learning methods; N-grams; Pre-processing method; Subtask; TF-IDF scheme; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@ARTICLE{Singh2020484,
	author = {Singh, Ravinder and Du, Jiahua and Zhang, Yanchun and Wang, Hua and Miao, Yuan and Sianaki, Omid Ameri and Ulhaq, Anwaar},
	title = {A Framework for Early Detection of Antisocial Behavior on Twitter Using Natural Language Processing},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {993},
	pages = {484 – 495},
	doi = {10.1007/978-3-030-22354-0_43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068454460&doi=10.1007%2f978-3-030-22354-0_43&partnerID=40&md5=9ce3361dedadec7cb00f536b13fd9fab},
	affiliations = {Victoria University, Footscray Park, VIC, Australia; Victoria University, Sydney, NSW, Australia; Charles Sturt University, Sydney, NSW, Australia},
	abstract = {Online antisocial behavior is a social problem and a public health threat. A manifestation of such behavior may be fun for a perpetrator, however, can drive a victim into depression, self-confinement, low self-esteem, anxiety, anger, and suicidal ideation. Online platforms such as Twitter and Facebook can sometimes become breeding grounds for such behavior. These platforms may have measures in place to deter online antisocial behavior, however, such behavior still prevails. Most of the measures rely on users reporting to platforms for intervention. In this paper, we advocate a more proactive approach based on natural language processing and machine learning that can enable online platforms to actively look for signs of antisocial behavior and intervene before it gets out of control. By actively searching for such behavior, social media sites can possibly prevent dire situations that can lead to someone committing suicide. © 2020, Springer Nature Switzerland AG.},
	keywords = {Health risks; Learning algorithms; Social networking (online); Antisocial behavior; Breeding grounds; NAtural language processing; Online platforms; Pro-active approach; Self-confinement; Social problems; Suicidal ideation; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 13th International Conference on Complex, Intelligent, and Software Intensive Systems, CISIS 2019; Conference date: 3 July 2019 through 5 July 2019; Conference code: 227709}
}

@CONFERENCE{Parikh20202006,
	author = {Parikh, Apurva and Bisht, Abhimanyu Singh and Majumder, Prasenjit},
	title = {IRLab DAIICT at SemEval-2020 Task 12: Machine Learning and Deep Learning Methods for Offensive Language Identification},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2006 – 2011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094722448&partnerID=40&md5=114292b91e14708429e4f59224353e2b},
	affiliations = {DA-IICT, Gandhinagar, India},
	abstract = {The paper describes systems that our team IRLab DAIICT employed for shared task OffensEval 2020: Multilingual Offensive Language Identification in Social Media shared task. We conducted experiments on the English language dataset which contained weakly labelled data. There were three sub-tasks but we only participated in sub-tasks A and B. We employed Machine learning techniques like Logistic Regression, Support Vector Machine, Random Forest and Deep learning techniques like Convolutional Neural Network and BERT. Our best approach achieved a MacroF1 score of 0.91 for sub-task A and 0.64 for sub-task B. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Convolutional neural networks; Deep learning; Learning algorithms; Logistic regression; Natural language processing systems; Semantics; Support vector machines; English languages; Labeled data; Language identification; Learning methods; Logistics regressions; Machine learning techniques; Machine-learning; Offensive languages; Social media; Subtask; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@ARTICLE{Abro2020484,
	author = {Abro, Sindhu and Shaikh, Sarang and Ali, Zafar and Khan, Sajid and Mujtaba, Ghulam and Khand, Zahid Hussain},
	title = {Automatic hate speech detection using machine learning: A comparative study},
	year = {2020},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {11},
	number = {8},
	pages = {484 – 491},
	doi = {10.14569/IJACSA.2020.0110861},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091010688&doi=10.14569%2fIJACSA.2020.0110861&partnerID=40&md5=b2465cfc170789ba2418803f919a9210},
	affiliations = {Center for Excellence for Robotics, Artificial Intelligence and Blockchain, Department of Computer Science Sukkur IBA University, Sukkur, Pakistan; Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan},
	abstract = {The increasing use of social media and information sharing has given major benefits to humanity. However, this has also given rise to a variety of challenges including the spreading and sharing of hate speech messages. Thus, to solve this emerging issue in social media sites, recent studies employed a variety of feature engineering techniques and machine learning algorithms to automatically detect the hate speech messages on different datasets. However, to the best of our knowledge, there is no study to compare the variety of feature engineering techniques and machine learning algorithms to evaluate which feature engineering technique and machine learning algorithm outperform on a standard publicly available dataset. Hence, the aim of this paper is to compare the performance of three feature engineering techniques and eight machine learning algorithms to evaluate their performance on a publicly available dataset having three distinct classes. The experimental results showed that the bigram features when used with the support vector machine algorithm best performed with 79% off overall accuracy. Our study holds practical implication and can be used as a baseline study in the area of detecting automatic hate speech messages. Moreover, the output of different comparisons will be used as state-of-art techniques to compare future researches for existing automated text classification techniques. © 2020, Science and Information Organization.},
	author_keywords = {Hate speech; Machine learning; Natural language processing; Online social networks; Text classification},
	keywords = {Classification (of information); E-learning; Engineering education; Learning algorithms; Natural language processing systems; Speech recognition; Support vector machines; Text processing; Comparatives studies; Engineering techniques; Feature engineerings; Hate speech; Machine learning algorithms; Performance; Social information; Social media; Speech detection; Text classification; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 79; All Open Access, Gold Open Access}
}

@CONFERENCE{Özdemir20202171,
	author = {Özdemir, Anıl and Yeniterzi, Reyyan},
	title = {SU-NLP at SemEval-2020 Task 12: Offensive Language Identification in Turkish Tweets},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2171 – 2176},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094780638&partnerID=40&md5=66030526bd5332656c8a3bcdc3dc3ed3},
	affiliations = {Sabancı University, Istanbul, Turkey},
	abstract = {This paper summarizes our group's efforts in the offensive language identification shared task, which is organized as part of the International Workshop on Semantic Evaluation (Sem-Eval2020). Our final submission system is an ensemble of three different models, (1) CNN-LSTM, (2) BiLSTM-Attention and (3) BERT. Word embeddings, which were pre-trained on tweets, are used while training the first two models. BERTurk, which is the first BERT model for Turkish, is also explored. Our final submitted approach ranked as the second best model in the Turkish sub-task. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Long short-term memory; Semantics; Best model; Embeddings; International workshops; Language identification; Offensive languages; Semantic evaluations; Subtask; Turkishs; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Kumaresan2019,
	author = {Kumaresan, K. and Vidanage, K.},
	title = {HateSense: Tackling Ambiguity in Hate Speech Detection},
	year = {2019},
	journal = {2019 National Information Technology Conference, NITC 2019},
	doi = {10.1109/NITC48475.2019.9114528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087216841&doi=10.1109%2fNITC48475.2019.9114528&partnerID=40&md5=a4148b73495f4f62ddbc79b703787045},
	affiliations = {Informatics Institute of Technology, Department of Computer Science, Colombo, Sri Lanka},
	abstract = {Hate speech propagated online has been a long-trailing issue which induces several negative effects on society. The current efforts for the automated detection of hate speech online have utilized machine learning techniques in order to try and solve the issue as a classification problem. However, the significant drawback that has been identified in existing literature is that the inability of existing systems to tackle the ambiguity when it comes to hate speech detection, more specifically differentiating between hateful and offensive content. This research aims to tackle this issue of ambiguity in hopes of improving hate speech detection in general. The proposed system will utilize human reasoning techniques such as ontologies and fuzzy logics along with sentiment analysis in order to detect hate speech and deconstruct the ambiguity present. The results of the proposed approach show that the system can perform well when it comes to differentiating between hateful and offensive content and it is able to outperform existing systems in crucial factors. Yet, the deconstruction of ambiguity becomes difficult when there are a smaller number of hateful keywords present although the fuzzy control system was able to compensate in most cases. Thereby this research stresses the need for considering the disambiguation between hateful and offensive content when it comes to hate speech detection and utilization of human reasoning techniques to further facilitate this process. © 2019 IEEE.},
	author_keywords = {Fuzzy Control; Fuzzy Logic; Hate Speech; NLP; Ontology; Sentiment Analysis},
	keywords = {Fuzzy control; Fuzzy logic; Learning systems; Man machine systems; Sentiment analysis; Speech; Automated detection; Existing systems; Human reasoning; Machine learning techniques; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2019 National Information Technology Conference, NITC 2019; Conference date: 8 October 2019 through 10 October 2019; Conference code: 161056}
}

@CONFERENCE{Fernquist20194724,
	author = {Fernquist, Johan and Lindholm, Oskar and Kaati, Lisa and Akrami, Nazar},
	title = {A Study on the Feasibility to Detect Hate Speech in Swedish},
	year = {2019},
	journal = {Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019},
	pages = {4724 – 4729},
	doi = {10.1109/BigData47090.2019.9005534},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081324326&doi=10.1109%2fBigData47090.2019.9005534&partnerID=40&md5=7d21177b53e669467841f1c6494076f7},
	affiliations = {Decision Support Systems Swedish Defence Research Agency, Kista, Sweden; Uppsala University, Department of Psychology, Uppsala, Sweden},
	abstract = {Hate speech in digital environments is becoming a societal challenge. To deal with the problem, techniques that automatically detect hate speech have been developed by social media companies as well as researchers. Hate can be expressed in many different ways, which makes it difficult to detect automatically using algorithms. Also, how hate is expressed depends heavily on the language. The effectiveness of automatic detection techniques is still to be improved in many languages. In this paper, we attempt to detect hate speech in Swedish using machine learning. We compare different pre-trained language models that are fine-tuned on a corpus of hateful comments. To examine how well our models would work in a real scenario, we used a set of randomly selected comments from a Swedish discussion forum. The results showed that using pre-trained language models provides a better result than using a baseline SVM model, but it also reveals that detecting hate speech in the wild is challenge that need more research. © 2019 IEEE.},
	author_keywords = {digital hate; hate speech; language models; machine learning; transfer learning},
	keywords = {Big data; Computational linguistics; Learning systems; Speech; Transfer learning; Automatic Detection; Digital environment; digital hate; Discussion forum; Language model; Social media; SVM model; Swedishs; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 2019 IEEE International Conference on Big Data, Big Data 2019; Conference date: 9 December 2019 through 12 December 2019; Conference code: 157991}
}

@CONFERENCE{Ombui2019,
	author = {Ombui, Edward and Karani, Moses and Muchemi, Lawrence},
	title = {Annotation Framework for Hate Speech Identification in Tweets: Case Study of Tweets during Kenyan Elections},
	year = {2019},
	journal = {2019 IST-Africa Week Conference, IST-Africa 2019},
	doi = {10.23919/ISTAFRICA.2019.8764868},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069912751&doi=10.23919%2fISTAFRICA.2019.8764868&partnerID=40&md5=cfdd1eaf58dfe5c9d67f99b9b4b2a2d3},
	affiliations = {Africa Nazarene University, PO Box 53067, Nairobi, 00200, Kenya; University of Nairobi, PO Box 42000, Nairobi, 00100, Kenya},
	abstract = {Considering the colossal amount of user-generated content on social media, it has become increasingly difficult to monitor hateful content being published on public online spaces, especially during the electioneering periods, particularly in Kenya. In this regard, it is crucial to automate the identification of hate speech in order to manage the volume, variety, veracity and velocity of this content. In this research, we postulate a supervised machine learning approach whereby annotation of the training data set is critical in determining the performance of the trained classifier. Therefore, we develop an annotation framework based on Sternberg's (2003) hate theory and test its performance in classifying about 5k tweets using 3 human annotators per tweet. Preliminary results indicate an intercoder reliability score of 0.5027 based on Krippendorff's alpha. © 2019 The authors.},
	author_keywords = {Hate Speech; Machine learning; Text annotation},
	keywords = {Classification (of information); Electronic voting; Learning systems; Machine learning; Supervised learning; Krippendorff's alphas; Social media; Speech identification; Supervised machine learning; Text annotations; Training data sets; User-generated content; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 2019 IST-Africa Week Conference, IST-Africa 2019; Conference date: 8 May 2019 through 10 May 2019; Conference code: 149766}
}

@CONFERENCE{Hoffmann2020,
	author = {Hoffmann, Julia and Kruschwitz, Udo},
	title = {UR NLP @ HaSpeeDe 2 at EVALITA 2020: Towards robust hate speech detection with contextual embeddings},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2765},
	doi = {10.4000/books.aaccademia.6967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097530892&doi=10.4000%2fbooks.aaccademia.6967&partnerID=40&md5=af8daaf3f3767af03d1424531bda905a},
	affiliations = {University of Regensburg, Germany},
	abstract = {We describe our approach to address Task A of the EVALITA 2020 Hate Speech Detection (HaSpeeDe2) challenge. We submitted two runs that are both based on contextual embeddings - which we had chosen due to their effectiveness in solving a wide range of NLP problems. For our baseline run we use stacked embeddings that serve as features in a linear SVM. Our second run is a simple ensemble approach of three SVMs with majority voting. Both approaches outperform the official baselines by a large margin, and the ensemble classifier in particular demonstrates robust performance on different types of test data coming 6th (out of 27 runs) for news headlines and 10th (out of 27) for Twitter feeds. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Natural language processing systems; Speech recognition; Embeddings; Ensemble approaches; Ensemble-classifier; Large margins; Linear SVM; Robust performance; Simple++; Speech detection; Test data; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2020; Conference date: 17 December 2020; Conference code: 165592; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Rajanala2020293,
	author = {Rajanala, Sirisha and Jahir Pashapasha, M.},
	title = {Deploying hate speech detection model using flask},
	year = {2020},
	journal = {Journal of Advanced Research in Dynamical and Control Systems},
	volume = {12},
	number = {6 Special Issue},
	pages = {293 – 299},
	doi = {10.5373/JARDCS/V12SP6/SP20201035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087125333&doi=10.5373%2fJARDCS%2fV12SP6%2fSP20201035&partnerID=40&md5=f9038648dd3d934052d1780f420e7097},
	affiliations = {Computer Science and Engineeering department, Dr.K V.Subba Reddy College of Engineering for Women, Kurnool, India},
	abstract = {Now-a-days all individuals are expressing their thoughts which might be good or bad (hate speech) using online platforms like Facebook, twitter etc.Hate speech is some kind of sexual abusive or criminal words expressed in a thought. Through social media the spread of hate speech is increasing a lot which might indirectly affect the increase of hate crimes in the society. In order to remove these hate speeches from social media, automated detection of this hate speech content is very essential. In this paper, we automate the detection of hate speech in tweets with NLP by using logistic regression in machine learning and flask to deploy the model. This paper mainly emphasizes on how to deploy a hate speech model using flask. © 2020, Institute of Advanced Scientific Research, Inc. All rights reserved.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Graumas2019198,
	author = {Graumas, Leon and David, Roy and Caselli, Tommaso},
	title = {Twitter-based Polarised Embeddings for Abusive Language Detection},
	year = {2019},
	journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019},
	pages = {198 – 204},
	doi = {10.1109/ACIIW.2019.8925049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077810688&doi=10.1109%2fACIIW.2019.8925049&partnerID=40&md5=cd02226abc5858c3705326e364ef1514},
	affiliations = {CLCG, University of Groningen, Groningen, Netherlands},
	abstract = {We present a method to generate polarised word embeddings using controversial topics as search terms in Twitter as proxies for interactions among social media communities that may be liable to use abusive language. We investigate to what extent models trained with these embeddings perform with respect to generic embeddings across four data sets of abusive language, both in the same domain and out of domain, using simple linear classifiers. Our results show that the polarised embeddings are competitive in the same domain data sets, and perform better in out of domain one. © 2019 IEEE.},
	author_keywords = {abusive language detection; cross-domain; cross-test; polarised embeddings},
	keywords = {Classification (of information); Intelligent computing; Social networking (online); Controversial topics; Cross-domain; Language detection; Linear classifiers; Search terms; Social media; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019; Conference date: 3 September 2019 through 6 September 2019; Conference code: 155963; All Open Access, Green Open Access}
}

@CONFERENCE{Pratiwit2019128,
	author = {Pratiwit, Nur Indah and Budi, Indra and Jiwanggi, Meganingrum Arista},
	title = {Hate speech identification using the hate codes for Indonesian tweets},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {128 – 133},
	doi = {10.1145/3352411.3352432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072801330&doi=10.1145%2f3352411.3352432&partnerID=40&md5=50cee1a0d0cd91f4969bd7ce024d622a},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia},
	abstract = {The hate speech has become the major source of negativity spread in all over the social media. As the social media becomes aware of this issue, they gradually build several new regulations to handle the spread of hate speech e.g. by automatically blocking or suspending the accounts or posts containing hate speech. However, the social media users have become more creative in expressing the hate speech. To avoid the social media regulations regarding the hate speech, users usually use some special codes to interact with each other. This study aims to utilize the hate codes to identify the hate speech on the social media data. We used the Indonesian tweets as the dataset. We utilized Logistic Regression, Support Vector Machine, Naïve Bayes, and Random Forest Decision Tree as the classifiers. The highest F-Measure score for the hate speech identification was 80.71% by using the hate code feature combined with Logistic Regression as the classifier. © 2019 Association for Computing Machinery.},
	author_keywords = {Classification; Hate code; Hate speech; Twitter},
	keywords = {Classification (of information); Codes (symbols); Data Science; Decision trees; Logistic regression; Social networking (online); Speech; Support vector machines; Support vector regression; F-measure scores; Hate code; Social media; Social media datum; Speech identification; Twitter; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 2nd International Conference on Data Science and Information Technology, DSIT 2019; Conference date: 19 July 2019 through 21 July 2019; Conference code: 151535}
}

@CONFERENCE{Erizal2019533,
	author = {Erizal, Elvira and Irawan, Budhi and Setianingsih, Casi},
	title = {Hate speech detection in Indonesian language on instagram comment section using maximum entropy classification method},
	year = {2019},
	journal = {2019 International Conference on Information and Communications Technology, ICOIACT 2019},
	pages = {533 – 538},
	doi = {10.1109/ICOIACT46704.2019.8938593},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077966434&doi=10.1109%2fICOIACT46704.2019.8938593&partnerID=40&md5=8de939dff0279f21eeada44c7134f18a},
	affiliations = {Faculty of Electrical Engineering, Telkom University, Bandung, Indonesia},
	abstract = {Social media nowadays is a platform for many things and has become a place to delivers opinions. Opinions in a form of hate speech are one of the problems that authorities find hard to solve, because of its number and variations. Instagram, with almost 100 million users in Indonesia, is the object of this research because it is one of the most popular social media in Indonesia where people can share their photo and video, has become one of the most popular places to express hatred towards others. Because of that, a system will be made to detect hate speech on Instagram using Maximum Entropy classification algorithm. TF-IDF is also used as the feature extraction method, with the improvement from Part of Speech (POS) Tagging as the parameter. Accuracy generated from this research is 86,67% using Maximum Entropy with POS parameter TF-IDF and 80% when using TF-IDF without POS parameter. This system is expected to determine whether a comment on Instagram is a hate speech or not, and to see how TF IDF and POS Tagging improve the performance of Maximum Entropy Classifier. © 2019 IEEE},
	author_keywords = {Instagram; Keyword: Hate Speech; Maximum Entropy},
	keywords = {Computational linguistics; Social networking (online); Speech; Speech recognition; Classification algorithm; Classification methods; Feature extraction methods; Indonesian languages; Instagram; Part of speech tagging; Social media; Speech detection; Maximum entropy methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 2nd International Conference on Information and Communications Technology, ICOIACT 2019; Conference date: 24 July 2019 through 25 July 2019; Conference code: 156206}
}

@CONFERENCE{Abderrouaf20195595,
	author = {Abderrouaf, Cheniki and Oussalah, Mourad},
	title = {On Online Hate Speech Detection. Effects of Negated Data Construction},
	year = {2019},
	journal = {Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019},
	pages = {5595 – 5602},
	doi = {10.1109/BigData47090.2019.9006336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081376469&doi=10.1109%2fBigData47090.2019.9006336&partnerID=40&md5=877d5f6bbab87df614a2f48a9898afb6},
	affiliations = {University of Oulu, Faculty of Information Technology, CMVS, Oulu, 90014, Finland},
	abstract = {In the era of social media and mobile internet, the design of automatic tools for online detection of hate speech and/or abusive language becomes crucial for society and community empowerment. Nowadays of current technology in this respect is still limited and many service providers are still relying on the manual check. This paper aims to advance in this topic by leveraging novel natural language processing, machine learning, and feature engineering techniques. The proposed approach advocates a classification-like technique that makes use of a special data design procedure. The latter enforces a balanced training scheme by exploring the negativity of the original dataset. This generates new transfer learning paradigms, Two classification schemes using convolution neural network and LSTN architecture that use FastText embeddings as input features are contrasted with baseline models constituted of Logistic regression and Naives' Bayes classifiers. Wikipedia Comment dataset constituted of Personal Attack, Aggression and Toxicity data are employed to test the validity and usefulness of the proposal. © 2019 IEEE.},
	author_keywords = {Hate speech; NLP; text mining},
	keywords = {Big data; Learning algorithms; Learning systems; Logistic regression; Natural language processing systems; Statistical tests; Text mining; Transfer learning; Classification scheme; Community empowerments; Convolution neural network; Current technology; Feature engineerings; Learning paradigms; NAtural language processing; On-line detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 2019 IEEE International Conference on Big Data, Big Data 2019; Conference date: 9 December 2019 through 12 December 2019; Conference code: 157991; All Open Access, Green Open Access}
}

@CONFERENCE{Saroj20202012,
	author = {Saroj, Anita and Chanda, Supriya and Pal, Sukomal},
	title = {IRlab@IIT-BHU at SemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media using SVM},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {2012 – 2016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094753965&partnerID=40&md5=bbc5b0f3016e2fe9bd8b531fee2ec945},
	affiliations = {Department of Computer Science and Engineering, IIT(BHU), Varanasi, India},
	abstract = {This paper describes the IRlab@IIT-BHU system for the OffensEval 2020. We take the SVM with TF-IDF features to identify and categorize hate speech and offensive language in social media for two languages. In subtask A, we used a linear SVM classifier to detect abusive content in tweets, achieving a macro F1 score of 0.779 and 0.718 for Arabic and Greek, respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Computational linguistics; Semantics; Language identification; Linear SVM; Offensive languages; Social media; Subtask; SVM classifiers; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265}
}

@CONFERENCE{Faris2020453,
	author = {Faris, Hossam and Aljarah, Ibrahim and Habib, Maria and Castillo, Pedro A.},
	title = {Hate speech detection using word embedding and deep learning in the Arabic language context},
	year = {2020},
	journal = {ICPRAM 2020 - Proceedings of the 9th International Conference on Pattern Recognition Applications and Methods},
	pages = {453 – 460},
	doi = {10.5220/0008954004530460},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082995645&doi=10.5220%2f0008954004530460&partnerID=40&md5=e9077c0ccfc747bc8feda7edde7fbc4f},
	affiliations = {Department of Information Technology, King Abdullah II School for Information Technology, University of Jordan, Amman, Jordan; Department of Computer Architecture and Technology, ETSIIT - CITIC, University of Granada, Spain},
	abstract = {Hate speech over online social networks is a worldwide problem that leads for diminishing the cohesion of civil societies. The rapid spread of social media websites is accompanied with an increasing number of social media users which showed a higher rate of hate speech, as well. The objective of this paper is to propose a smart deep learning approach for the automatic detection of cyber hate speech. Particularly, the detection of hate speech on Twitter on the Arabic region. Hence, a dataset is collected from Twitter that captures the hate expressions in different topics at the Arabic region. A set of features extracted from the dataset based on a word embedding mechanism. The word embeddings fed into a deep learning framework. The implemented deep learning approach is a hybrid of convolutional neural network (CNN) and long short-term memory (LSTM) network. The proposed approach achieved good results in classifying tweets as Hate or Normal regarding accuracy, precision, recall, and F1 measure. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Classification; Hate Speech; Machine Learning; Word Embedding},
	keywords = {Convolutional neural networks; Long short-term memory; Social networking (online); Speech recognition; Arabic languages; Civil society; Embeddings; Hate speech; Learning approach; Machine-learning; Social media; Social media websites; Speech detection; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47; Conference name: 9th International Conference on Pattern Recognition Applications and Methods, ICPRAM 2020; Conference date: 22 February 2020 through 24 February 2020; Conference code: 158680}
}

@ARTICLE{Gupta20202953,
	author = {Gupta, Shailja and Kaur, Manpreet and Lakra, Sachin and Dixit, Yogesh},
	title = {Performance evaluation of supervised learning algorithms on hate speech detection},
	year = {2020},
	journal = {Journal of Advanced Research in Dynamical and Control Systems},
	volume = {12},
	number = {7 Special Issue},
	pages = {2953 – 2960},
	doi = {10.5373/JARDCS/V12SP7/20202440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088984880&doi=10.5373%2fJARDCS%2fV12SP7%2f20202440&partnerID=40&md5=a17e434ae40ba00c6ced7624933bfc41},
	affiliations = {Department of Computer Science Technology, Manav Rachna University, India},
	abstract = {In this paper, we test various machine learning algorithms to evaluate the performance of these algorithms on the hate speech detection task. These algorithms are applied to two publicly available standard datasets of hate speech detection. This experimental study has been conducted for the budding researchers to understand which machine learning algorithm works best in the area of natural language processing specifically to finding the solutions for the task of hate speech detection. The results obtained show that the Random Forest classification model and Naïve Bayes classification model outperforms all the other supervised machine learning classification algorithms. Towards the end, an evaluation of results and an error analysis has been carried out to identify the overall challenges that can be faced by the researchers for the task of detecting hateful content. © 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved.},
	author_keywords = {Classification; Hate; No-hate; Offensive; Supervised Machine Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}@CONFERENCE{Chakravartula2019404,
	author = {Chakravartula, Nikhil},
	title = {HATEMINER at SemEval-2019 task 5: Hate speech detection against immigrants and women in Twitter using a multinomial naive bayes classifier},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {404 – 408},
	doi = {10.18653/v1/s19-2071},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097508777&doi=10.18653%2fv1%2fs19-2071&partnerID=40&md5=ce326af3c2e503075a4edebd6e98b67d},
	affiliations = {Teradata, Hyderabad, India},
	abstract = {This paper describes our participation in the SemEval 2019 Task 5 - Multilingual Detection of Hate. This task aims to identify hate speech against two specific targets, immigrants and women. We compare and contrast the performance of different word and sentence level embeddings on the state-of-the-art classification algorithms. Our final submission is a Multinomial binarized Naive Bayes model for both the subtasks in the English version. © 2019 Association for Computational Linguistics},
	keywords = {Classifiers; Semantics; Speech recognition; Classification algorithm; Embeddings; Multinomial naive bayes; Multinomials; Naive Bayes classifiers; Performance; Sentence level; Speech detection; State of the art; Word level; Bayesian networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Sutejo201839,
	author = {Sutejo, Taufic Leonardo and Lestari, Dessi Puji},
	title = {Indonesia Hate Speech Detection Using Deep Learning},
	year = {2018},
	journal = {Proceedings of the 2018 International Conference on Asian Language Processing, IALP 2018},
	pages = {39 – 43},
	doi = {10.1109/IALP.2018.8629154},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062808932&doi=10.1109%2fIALP.2018.8629154&partnerID=40&md5=49b92f279d003675c5a5e9fa8cdabc4d},
	affiliations = {School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia},
	abstract = {Hate speech brings negative impacts not only to the target victim, but also to the listener. The spread of hate speech can be done not only through the social media postings, but also through the video, campaign or speech. In this research, we develop models to detect hate speech in Indonesian Language from input text and speech by using deep learning approach. We utilized both textual and acoustic features and compare their accuracies. Experiments result showed that hate speech detection using only textual features is better than that of using acoustic features and both of combined features model. The best model using textual feature obtained Fl-score 87.98% which is higher than the model of using acoustic feature only (Fl-score 82.5%), and the model of using acoustic and lexical features (Fl-score 86.98%). © 2018 IEEE.},
	author_keywords = {accoustic features; deep learning; hate speech; Indonesian Language; multi-features; textual features},
	keywords = {Deep learning; Speech recognition; Accoustic feature; Acoustic features; Deep learning; Hate speech; Indonesia; Indonesian languages; Multifeatures; Social media; Speech detection; Textual features; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 22nd International Conference on Asian Language Processing, IALP 2018; Conference date: 15 November 2018 through 17 November 2018; Conference code: 144702}
}

@CONFERENCE{Steimel20191151,
	author = {Steimel, Kenneth and Dakota, Daniel and Chen, Yue and Kübler, Sandra},
	title = {Investigating multilingual abusive language detection: A cautionary tale},
	year = {2019},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	volume = {2019-September},
	pages = {1151 – 1160},
	doi = {10.26615/978-954-452-056-4_132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076483217&doi=10.26615%2f978-954-452-056-4_132&partnerID=40&md5=c8e69278897e3f10e44f4b9f5e466fee},
	affiliations = {Indiana University, United States},
	abstract = {Abusive language detection has received much attention in the last years, and recent approaches perform the task in a number of different languages. We investigate which factors have an effect on multilingual settings, focusing on the compatibility of data and annotations. In the current paper, we focus on English and German. Our findings show large differences in performance between the two languages. We find that the best performance is achieved by different classification algorithms. Sampling to address class imbalance issues is detrimental for German and beneficial for English. The only similarity that we find is that neither data set shows clear topics when we compare the results of topic modeling to the gold standard. Based on our findings, we can conclude that a multilingual optimization of classifiers is not possible even in settings where comparable data sets are used. © 2019 Association for Computational Linguistics (ACL). All rights reserved.},
	keywords = {Classification (of information); Deep learning; Cautionary tales; Class imbalance; Classification algorithm; Data set; Gold standards; Language detection; Topic Modeling; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 12th International Conference on Recent Advances in Natural Language Processing, RANLP 2019; Conference date: 2 September 2019 through 4 September 2019; Conference code: 155296; All Open Access, Bronze Open Access}
}

@CONFERENCE{Swamy2019940,
	author = {Swamy, Steve Durairaj and Jamatia, Anupam and Gambäck, Björn},
	title = {Studying generalisability across abusive language detection datasets},
	year = {2019},
	journal = {CoNLL 2019 - 23rd Conference on Computational Natural Language Learning, Proceedings of the Conference},
	pages = {940 – 950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084333327&partnerID=40&md5=852fb0e5e164cde26839524936e8171a},
	affiliations = {Department of Computer Science, National Institute of Technology, Agartala, India; Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway; RISE SICS, Kista, Sweden},
	abstract = {Work on Abusive Language Detection has tackled a wide range of subtasks and domains. As a result of this, there exists a great deal of redundancy and non-generalisability between datasets. Through experiments on cross-dataset training and testing, the paper reveals that the preconceived notion of including more non-abusive samples in a dataset (to emulate reality) may have a detrimental effect on the generalisability of a model trained on that data. Hence a hierarchical annotation model is utilised here to reveal redundancies in existing datasets and to help reduce redundancy in future efforts. © 2019 Association for Computational Linguistics.},
	keywords = {Statistical tests; Language detection; Subtasks; Training and testing; Redundancy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69; Conference name: 23rd Conference on Computational Natural Language Learning, CoNLL 2019; Conference date: 3 November 2019 through 4 November 2019; Conference code: 159365}
}

@ARTICLE{Fauzi2018294,
	author = {Fauzi, M. Ali and Yuniarti, Anny},
	title = {Ensemble method for indonesian twitter hate speech detection},
	year = {2018},
	journal = {Indonesian Journal of Electrical Engineering and Computer Science},
	volume = {11},
	number = {1},
	pages = {294 – 299},
	doi = {10.11591/ijeecs.v11.i1.pp294-299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047137462&doi=10.11591%2fijeecs.v11.i1.pp294-299&partnerID=40&md5=ec4cdec1af31536eca081c71b08b7551},
	affiliations = {Faculty of Computer Science, Brawijaya University, Malang, Indonesia; Informatics Department, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia},
	abstract = {Due to the massive increase of user-generated web content, in particular on social media networks where anyone can give a statement freely without any limitations, the amount of hateful activities is also increasing. Social media and microblogging web services, such as Twitter, allowing to read and analyze user tweets in near real time. Twitter is a logical source of data for hate speech analysis since users of twitter are more likely to express their emotions of an event by posting some tweet. This analysis can help for early identification of hate speech so it can be prevented to be spread widely. The manual way of classifying out hateful contents in twitter is costly and not scalable. Therefore, the automatic way of hate speech detection is needed to be developed for tweets in Indonesian language. In this study, we used ensemble method for hate speech detection in Indonesian language. We employed five stand-alone classification algorithms, including Naïve Bayes, K-Nearest Neighbours, Maximum Entropy, Random Forest, and Support Vector Machines, and two ensemble methods, hard voting and soft voting, on Twitter hate speech dataset. The experiment results showed that using ensemble method can improve the classification performance. The best result is achieved when using soft voting with F1 measure 79.8% on unbalance dataset and 84.7% on balanced dataset. Although the improvement is not truly remarkable, using ensemble method can reduce the jeopardy of choosing a poor classifier to be used for detecting new tweets as hate speech or not. © 2018 Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Classifier ensemble; Hate speech; Indonesian language; Text classification; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66; All Open Access, Green Open Access}
}

@CONFERENCE{Chiril2019489,
	author = {Chiril, Patricia and Benamara, Farah and Moriceau, Véronique and Kumar, Abhishek},
	title = {The binary trio at SemEval-2019 task 5: Multitarget hate speech detection in Tweets},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {489 – 493},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101430009&partnerID=40&md5=510d308080ae788aa51769bb420c0e4f},
	affiliations = {IRIT, Toulouse University, France; IRIT, CNRS, Toulouse University, France; LIMSI-CNRS, Univ. Paris-Sud, France; Indian Institute of Science, India},
	abstract = {The massive growth of user-generated web content through blogs, online forums and most notably, social media networks, led to a large spreading of hatred or abusive messages which have to be moderated. This paper proposes a supervised approach to hate speech detection towards immigrants and women in English tweets. Several models have been developed ranging from feature-engineering approaches to neural ones. We also carried out a detailed error analysis to show main causes of misclassification. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Semantics; Social networking (online); Feature engineerings; Misclassifications; Multi-targets; Online forums; Social media networks; Speech detection; User-generated; Web content; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Ahmad Niam2018166,
	author = {Ahmad Niam, Ilham Maulana and Irawan, Budhi and Setianingsih, Casi and Putra, Bagas Prakoso},
	title = {Hate Speech Detection Using Latent Semantic Analysis (LSA) Method Based on Image},
	year = {2018},
	journal = {Proceedings - 2018 International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018},
	pages = {166 – 171},
	doi = {10.1109/ICCEREC.2018.8712111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066302849&doi=10.1109%2fICCEREC.2018.8712111&partnerID=40&md5=6ded1310e9e336d077ffa3c94e813f6e},
	affiliations = {Telkom University, Indonesia},
	abstract = {Hate speech are a words, actions which is prohibited because it leads to acts that trigger anarchism and violence attidudes toward other individuals or groups. Ethics in the internet are needed considering that internet is a matter that important use for today's society. However, more side are miss using the internet to spread such kind a hate speech, such as ethnicity, religion and race. The development of a system for detecting hate speech through images is quite rare for now a days. Therefore, this study study is classified to detect whether there is an element of hatred in the image that will be selected. In this final project, the author hopes to make how to classify the element of hate speech in an image performed by the machine learning, which later that machine learning can recognize any kind of hate speech on the image through the existing text. With using Latent Semantic Analysis (LSA) method, we get the result of this research is precision 67%, recall 76.84%, and accuracy 57.9%. After creation of this research, it is hoped the computer can know and classify the existence of hate speech in the image. © 2018 IEEE.},
	author_keywords = {Latent Semantic Analysis (LSA)},
	keywords = {Character recognition; Machine learning; Semantics; Speech; Latent Semantic Analysis; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 4th International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018; Conference date: 5 December 2018 through 7 December 2018; Conference code: 147977}
}

@CONFERENCE{Ranasinghe2019199,
	author = {Ranasinghe, Tharindu and Zampieri, Marcos and Hettiarachchi, Hansi},
	title = {BRUMS at HASOC 2019: Deep learning models for multilingual hate speech and offensive language identification},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {199 – 207},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076904036&partnerID=40&md5=07146564847821bbed17230aabac98a4},
	affiliations = {Research Group in Computational Linguistics, University of Wolverhampton, United Kingdom; College of Liberal Arts, Rochester Institute of Technology, United States; School of Computing and Digital Technology, Birmingham City University, United Kingdom},
	abstract = {In this paper, we describe the BRUMS entry to the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) shared task 2019. The HASOC organizers provided participants with annotated datasets containing posts from social media in English, German, and Hindi (including code-mixing). We present a multilingual deep learning model to identify hate speech and offensive language in social media. Our best performing system was ranked 3rd among 79 entries in the English track of the HASOC sub-task 1. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Deep Learning; Hate Speech; Offensive Language Identification; Text classification},
	keywords = {Classification (of information); Information retrieval; Natural language processing systems; Social networking (online); Speech recognition; Text processing; Annotated datasets; Code-mixing; Content identifications; European languages; Learning models; Offensive languages; Social media; Text classification; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Thenmozhi2019739,
	author = {Thenmozhi, D. and Kumar, B. Senthil and Aravindan, Chandrabose and Srinethe, S.},
	title = {SSN_NLP at SemEval-2019 task 6: Offensive language identification in social media using traditional and deep machine learning approaches},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {739 – 744},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091493118&partnerID=40&md5=7cf885ee7b06fc4ecbac8a8772bfa72b},
	affiliations = {Department of CSE, SSN College of Engineering, India},
	abstract = {Offensive language identification (OLI) in user generated text is automatic detection of any profanity, insult, obscenity, racism or vulgarity that degrades an individual or a group. It is helpful for hate speech detection, flame detection and cyber bullying. Due to immense growth of accessibility to social media, OLI helps to avoid abuse and hurts. In this paper, we present deep and traditional machine learning approaches for OLI. In deep learning approach, we have used bi-directional LSTM with different attention mechanisms to build the models and in traditional machine learning, TF-IDF weighting schemes with classifiers namely Multinomial Naive Bayes and Support Vector Machines with Stochastic Gradient Descent optimizer are used for model building. The approaches are evaluated on the OffensEval@SemEval2019 dataset and our team SSN NLP submitted runs for three tasks of OffensEval shared task. The best runs of SSN NLP obtained the F1 scores as 0.53, 0.48, 0.3 and the accuracies as 0.63, 0.84 and 0.42 for the tasks A, B and C respectively. Our approaches improved the base line F1 scores by 12%, 26% and 14% for Task A, B and C respectively. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Crime; Gradient methods; Learning algorithms; Long short-term memory; Natural language processing systems; Social networking (online); Stochastic models; Support vector machines; Automatic Detection; Cyber bullying; F1 scores; Flame detection; Language identification; Machine learning approaches; Offensive languages; Social media; Speech detection; User-generated; Stochastic systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Doostmohammadi2019617,
	author = {Doostmohammadi, Ehsan and Sameti, Hossein and Saffar, Ali},
	title = {Ghmerti at SemEval-2019 task 6: A deep word- And character-based approach to offensive language identification},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {617 – 621},
	doi = {10.18653/v1/s19-2110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097505815&doi=10.18653%2fv1%2fs19-2110&partnerID=40&md5=4cff168b5913e98c117ada984a494da6},
	affiliations = {Speech Processing Lab, Department of Computer Engineering, Sharif University of Technology, Tehran, Iran; NazarBin, Tehran, Iran},
	abstract = {This paper presents the models submitted by Ghmerti team for subtasks A and B of the OffensEval shared task at SemEval 2019. OffensEval addresses the problem of identifying and categorizing offensive language in social media in three subtasks; whether or not a content is offensive (subtask A), whether it is targeted (subtask B) towards an individual, a group, or other entities (subtask C). The proposed approach includes character-level Convolutional Neural Network, word-level Recurrent Neural Network, and some preprocessing. The performance achieved by the proposed model for subtask A is 77.93% macro-averaged F1-score. © 2019 Association for Computational Linguistics},
	keywords = {C (programming language); Computational linguistics; Semantics; Character level; Convolutional neural network; Language identification; Offensive languages; Performance; Social media; Subtask; Word and characters; Word level; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Rani2019668,
	author = {Rani, Priya and Ojha, Atul Kr},
	title = {KMI-Coling at SemEval-2019 task 6: Exploring N-grams for offensive language detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {668 – 671},
	doi = {10.18653/v1/s19-2119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085581462&doi=10.18653%2fv1%2fs19-2119&partnerID=40&md5=5a63144a0e4af05dc2857c0ab87dbc8c},
	affiliations = {Dr. Bhimrao Ambedkar University, Agra, India; Jawaharlal Nehru University, New Delhi, India},
	abstract = {In this paper, we present the system description of offensive language detection tool which is developed by the KMI-Coling Group under the OffensEval Shared task. The OffensEval Shared Task was conducted in SemEval 2019 workshop. To develop the system, we have explored n-grams up to 8-gram and trained three different systems namely A, B and C system for three different sub tasks within the OffensEval task which achieves the accuracy of 79.76%, 87.91% and 44.37% respectively. The task was completed using the data set provided to us by OffensEval organisers, which was the part of OLID data set. It consists of 13,240 tweets extracted from twitter and were annotated at three levels using crowd sourcing. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; C-systems; Crowd sourcing; Data set; Detection tools; Language detection; N-grams; Offensive languages; Subtask; System description; Three-level; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Rajalakshmi2019370,
	author = {Rajalakshmi, R. and Yashwant Reddy, B.},
	title = {DLRG@HASOC 2019: An enhanced ensemble classifier for hate and offensive content identification},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {370 – 379},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076913093&partnerID=40&md5=76ce3fd8efeb2ea0f37b4f0f79e0a791},
	affiliations = {School of Computing Science and Engineering, Vellore Institute of Technology, Chennai, India},
	abstract = {Recent advancements in the Internet technologies have made a tremendous change in the social media. Hate Speech is an attack that is directed towards a group of people based on their religion, gender, colour etc. The offensive content in social media poses a threat to democracy. As these kind of hate speech and offensive content on the web increases day by day, manually monitoring or controlling such hate crimes is a highly challenging task. Most of the existing methodologies focus on English language tweets and only limited work has been reported for Hindi and German language posts. Also, the importance of feature se- lection methods is not explored much for this problem. In this research work, an enhanced ensemble classifier approach is proposed to identify hate and offensive content posted in Hindi or German languages. In the proposed approach, CHI square based feature selection method is com- bined with a Random Forest Classifier to classify the tweets. This work was submitted to Hate and Offensive Content Identification (HASOC) task@FIRE2019. From the various experiments conducted on the re- leased HASOC dataset, it is shown that an accuracy of 81% and 64% was achieved on German and Hindi language tweets. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Chi Square Feature Selection; Ensemble Classifier; German; Hate Speech Identification; Hindi; Social Media},
	keywords = {Decision trees; Information retrieval; Social networking (online); Ensemble classifiers; German; Hindi; Social media; Speech identification; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Perelló2019508,
	author = {Perelló, Carlos and Tomás, David and Garcia-Garcia, Alberto and Garcia-Rodriguez, Jose and Camacho-Collados, Jose},
	title = {UA at SemEval-2019 task 5: Setting a strong linear baseline for hate speech detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {508 – 513},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097508523&partnerID=40&md5=d4bbb7a138f98213962e6676540524ea},
	affiliations = {University of Alicante, Spain; Cardiff University, United Kingdom},
	abstract = {This paper describes the system developed at the University of Alicante (UA) for the SemEval 2019 Task 5: Multilingual detection of hate speech against immigrants and women in Twitter. The purpose of this work is to build a strong baseline for hate speech detection by means of a traditional machine learning approach with standard textual features, which could serve as a reference to compare with deep learning systems. We participated in both task A (Hate Speech Detection against Immigrants and Women) and task B (Aggressive behavior and Target Classification) for both English and Spanish. Given the text of a tweet, task A consists of detecting hate speech against women or immigrants in the text, whereas task B consists of identifying the target harassed as individual or generic, and to classify hateful tweets as aggressive or not aggressive. Despite its simplicity, our system obtained a remarkable macro-F1 score of 72.5 (sixth highest) and an accuracy of 73.6 (second highest) in Spanish (task A), outperforming more complex neural models from a total of 40 participant systems. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Speech; Speech recognition; Behaviour classification; F1 scores; Machine learning approaches; Neural modelling; Speech detection; Target Classification; Textual features; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@ARTICLE{Ibrohim20191116,
	author = {Ibrohim, Muhammad Okky and Budi, Indra},
	title = {Translated vs non-translated method for multilingual hate speech identification in Twitter},
	year = {2019},
	journal = {International Journal on Advanced Science, Engineering and Information Technology},
	volume = {9},
	number = {4},
	pages = {1116 – 1123},
	doi = {10.18517/ijaseit.9.4.8123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070814400&doi=10.18517%2fijaseit.9.4.8123&partnerID=40&md5=25ca36f5bb4d0ec11378ebefb498aa8f},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Kampus UI, Depok, 16424, Indonesia},
	abstract = {Nowadays social media is often misused to spread hate speech. Spreading hate speech is an act that needs to be handled in a special way because it can undermine or discriminate other people and cause conflict that leading to both material and immaterial losses. There are several challenges in building a hate speech identification system; one of them is identifying hate speech in multilingual scope. In this paper, we adapt and compare two methods in multilingual text classification which are translated (with and without language identification) and non-translated method for multilingual hate speech identification (including Hindi, English, and Indonesian language) using machine learning approach. We use some classification algorithms (classifiers) namely Support Vector Machine (SVM), Naive Bayes (NB), and Random Forest Decision Tree (RFDT) with word n-grams and char n-grams (character n-grams) as feature extraction. Our experiment result shows that the non-translated method gives the best result. However, the use of non-translated method needs to be reconsidered because this method needs more cost for data collection and annotation. Meanwhile, translated without language identification method give a poor result. To address this problem, we combine translated method with monolingual hate speech identification, and the experiment result shows that this approach can increase the multilingual hate speech identification performance compared to translate without language identification. This paper discusses the advantages and disadvantages for all method and the future works to enhance the performance in multilingual hate speech identification. © 2019, Insight Society.},
	author_keywords = {Machine learning; Multilingual hate speech identification; Social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Manolescu2019498,
	author = {Manolescu, Mihai and Löfflad, Denise and Saber, Adham Nasser Mohamed and Tari, Masoumeh Moradipour},
	title = {TuEval at SemEval-2019 task 5: LSTM approach to hate speech detection in English and Spanish},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {498 – 502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102927802&partnerID=40&md5=604d0726e4da1492a72dbc462983be24},
	affiliations = {Eberhard-Karls University of Tübingen, Germany},
	abstract = {The detection of hate speech, especially in online platforms and forums, is quickly becoming a hot topic as anti-hate speech legislation begins to be applied to public discourse online. The HatEval shared task was created with this in mind; participants were expected to develop a model capable of determining whether or not input (in this case, Twitter posts in English and Spanish) could be considered hate speech (designated as Subtask A), if they were aggressive, and whether the tweet was targeting an individual, or speaking generally (Subtask B). We approached this Subtask by creating a LSTM model with an embedding layer. We found that our model performed considerably better on English language input when compared to Spanish language input. In English, we achieved an F1-Score of 0.466 for Subtask A and 0.462 for Subtask B; In Spanish, we achieved scores of 0.617 and 0.612 on Subtask A and Subtask B, respectively. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Speech; Speech recognition; Embeddings; English languages; F1 scores; Hot topics; Online forums; Online platforms; Spanish language; Speech detection; Subtask; Twitter posts; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@ARTICLE{Qaddoum2019465,
	author = {Qaddoum, Kefaya and Ahmad, Israr and Javed, Yasir and Rodan, Ali},
	title = {An Enhanced Model for Abusive Behavior Detection in Social Network},
	year = {2019},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {29},
	pages = {465 – 471},
	doi = {10.1007/978-3-030-12839-5_43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082317567&doi=10.1007%2f978-3-030-12839-5_43&partnerID=40&md5=5205111d7ff6acb7a60dcafaa04ca20a},
	affiliations = {Higher College of Technology, Al Ain Women’s College, Abu Dhabi, United Arab Emirates},
	abstract = {Due to the growing use of social media, incidents of online abuse are also on rise. Online abusive behavior is defined as the use of electronic devices connected through internet for offensive activities. It is mostly in the form of comments containing abusive words about others, which affect the target users’ psychology and depresses them. This paper is aimed at devising method for detecting abusive behavior using supervised learning techniques. Two hypotheses are presented to extract features for detection of offensive comments. The initial experiments show that using features using our proposed method has better accuracy than the traditional feature extraction techniques like TF-IDF. © 2019, Springer Nature Switzerland AG.},
	keywords = {Learning systems; Social networking (online); Supervised learning; Behavior detection; Electronic device; Feature extraction techniques; Social media; Feature extraction},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mitrović2019722,
	author = {Mitrović, Jelena and Birkeneder, Bastian and Granitzer, Michael},
	title = {nlpUP at SemEval-2019 task 6: A deep neural language model for offensive language detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {722 – 726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097485681&partnerID=40&md5=a36eabb39b280feaa224810bfef33feb},
	affiliations = {Faculty of Computer Science and Mathematics, University of Passau, Germany},
	abstract = {This paper presents our submission for the SemEval shared task 6, sub-task A on the identification of offensive language. Our proposed model, C-BiGRU, combines a Convolutional Neural Network (CNN) with a bidirectional Recurrent Neural Network (RNN). We utilize word2vec to capture the semantic similarities between words. This composition allows us to extract long term dependencies in tweets and distinguish between offensive and non-offensive tweets. In addition, we evaluate our approach on a different dataset and show that our model is capable of detecting online aggressiveness in both English and German tweets. Our model achieved a macro F1-score of 79.40% on the SemEval dataset. © 2019 Association for Computational Linguistics},
	keywords = {C (programming language); Computational linguistics; Convolutional neural networks; Semantics; Bidirectional recurrent neural networks; Convolutional neural network; F1 scores; Language detection; Language model; Long-term dependencies; Offensive languages; Semantic similarity; Subtask; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Wang2019191,
	author = {Wang, Bin and Ding, Yunxia and Liu, Shengyan and Zhou, Xiaobing},
	title = {YNU wb at HASOC 2019: Ordered neurons LSTM with attention for identifying hate speech and offensive language},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {191 – 198},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076923171&partnerID=40&md5=3a4c26d7b8396dc6015ec0e9e5a7c5a3},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {The paper describes the system submitted to HASOC2019: Hate Speech and Offensive Content Identification in Indo-European Lan- guages. The task aims to categorize offensive language in social media, we only participated in Sub-task A for English, which aims to identify offensive language and hate speech. In order to address this task, we pro- posed a system based on an ordered neurons LSTM with an attention model, and used a K-folding approach to ensemble. Our model achieved the Macro F1-score of 0.7882 and the Weighted F1-score of 0.8395 in the Subtask A for English language, and achieved the highest result. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Attention; Hate speech; Offensive language; Ordered neurons LSTM},
	keywords = {Information retrieval; Long short-term memory; Neurons; Attention; Attention model; Content identifications; English languages; F1 scores; Offensive languages; Ordered neurons LSTM; Social media; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Kumar2019285,
	author = {Kumar, Ritesh and Ojha, Atul Kr.},
	title = {KMI-Panlingua at HASOC 2019: SVM vs BERT for hate speech and offensive content detection},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {285 – 292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076893430&partnerID=40&md5=a8866cf7511112051ef0c3b32043c7a7},
	affiliations = {K.M. Institute of Hindi and Linguistics, Dr. Bhimrao Ambedkar University, India; Panlingua Language Processing LLP, India; Charles University, Czech Republic},
	abstract = {This paper presents KMI-Panlingua's system description which was submitted at the FIRE Shared Task 2019 on Hate Speech and Of- fensive Content Identification in Indo-European Languages. Our team submitted systems for all the 3 sub-tasks in two languages - English and Hindi. We experimented with 2 kinds of systems - classic machine learn- ing using SVM and BERT-based system. We discuss the systems and their results in this paper. © Copyright 2019 for this paper by its authors.},
	author_keywords = {BERT; English; Hate Speech; Hindi; Offensive Language; SVM},
	keywords = {Fires; Information retrieval; BERT; Content detection; Content identifications; English; European languages; Hindi; Offensive languages; System description; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Bojkovský2019464,
	author = {Bojkovský, Michal and Pikuliak, Matúš},
	title = {STUFIIT at SemEval-2019 task 5: Multilingual hate speech detection on Twitter with MUSE and ELMo embeddings},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {464 – 468},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087950884&partnerID=40&md5=27cf83bb102e3aa861ebaa01cdcc720a},
	affiliations = {Faculty of Informatics and Information, Technologies STU in Bratislava, Ilkovičova 2, Bratislava, Slovakia},
	abstract = {We evaluate the viability of multilingual learning for the task of hate speech detection. We also experiment with adversarial learning as a means of creating a multilingual model. Ultimately our multilingual models have had worse results than their monolignual counterparts. We find that the choice of word representations (word embeddings) is very crucial for deep learning as a simple switch between MUSE and ELMo embeddings has shown a 3-4% increase in accuracy. This also shows the importance of context when dealing with online content. © 2019 Association for Computational Linguistics},
	keywords = {Deep learning; Semantics; Speech recognition; Adversarial learning; Embeddings; Multilingual learning; Online content; Simple++; Speech detection; Word representations; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Sreelakshmi2019366,
	author = {Sreelakshmi, K. and Premjith, B. and Soman, K.P.},
	title = {Amrita CEN at HASOC 2019: Hate speech detection in roman and devanagiri scripted text},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {366 – 369},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076879710&partnerID=40&md5=cc98238f185af1831feb211641bbcdb8},
	affiliations = {Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India},
	abstract = {Nowadays the usage of social media sites like Facebook and Twitter has increased rapidly which has lead to hugeooding of data in the social media sites. Though these social media sites give free op- portunities to people to express and share their thoughts they also end up in spread of huge amount of hate content. In this paper we present a domain specific word embedding model for classification of English tweets to Non Hate-Offensive and Hate-Offensive and a fastText model for Hindi text classification. The classification is done using the dataset got from HASOC 2019 shared task. Deep learning algorithm is used as the classifier. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Convolutionl Neural Network; FastText; Hate speech; Long short term memory},
	keywords = {Deep learning; Information retrieval; Long short-term memory; Social networking (online); Text processing; Domain specific; Facebook; FastText; Social media; Speech detection; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@ARTICLE{Almatarneh201923,
	author = {Almatarneh, Sattam and Gamallo, Pablo and Pena, Francisco J. Ribadas and Alexeev, Alexey},
	title = {Supervised Classifiers to Identify Hate Speech on English and Spanish Tweets},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11853 LNCS},
	pages = {23 – 30},
	doi = {10.1007/978-3-030-34058-2_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076373137&doi=10.1007%2f978-3-030-34058-2_3&partnerID=40&md5=b8a6441d6de87389401741fddd4d9244},
	affiliations = {Centro Singular de Investigación en Tecnoloxí­as Intelixentes (CiTIUS), Universidad de Santiago de Compostela, Santiago, Spain; Computer Science Department, University of Vigo Escola Superior de Enxeñarí­a Informática, Campus As Lagoas, Ourense, 32004, Spain; ITMO University, Saint-Petersburg, Russian Federation},
	abstract = {Consistently with social and political concern about hatred and harassment through social media, in recent years, automatic hate-speech detection and offensive behavior in social media are gaining a lot of attention. In this paper, we examine the performance of several supervised classifiers in the process of identifying hate speech on Twitter. More precisely, we do an empirical study that analyzes the influence of two types of linguistic features (n-grams, word embeddings) when they are used to feed different supervised machine learning classifiers: Support Vector Machine (SVM), Gaussian Naive Bayes (GNB), Complement Naive Bayes (CNB), Decision Tree (DT), Nearest Neighbors (KN), Random Forest (RF) and Neural Network (NN). The experiments we have carried out show that CNB, SVM, and RF are better than the rest classifiers in English and Spanish languages by taking into account all features. © Springer Nature Switzerland AG, 2019.},
	author_keywords = {Classification; Hate speech; Linguistic features; Sentiment analysis; Supervised machine learning},
	keywords = {Classification (of information); Classifiers; Decision trees; Linguistics; Machine learning; Sentiment analysis; Social networking (online); Speech recognition; Supervised learning; Support vector machines; Empirical studies; Linguistic features; Nearest neighbors; Neural network (nn); Spanish language; Speech detection; Supervised classifiers; Supervised machine learning; Digital libraries},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 21st International Conference on Asia-Pacific Digital Libraries, ICADL 2019; Conference date: 4 November 2019 through 7 November 2019; Conference code: 233829; All Open Access, Green Open Access}
}

@CONFERENCE{Paetzold2019519,
	author = {Paetzold, Gustavo Henrique and Malmasi, Shervin and Zampieri, Marcos},
	title = {UTFPR at SemEval-2019 task 5: Hate speech identification with recurrent neural networks},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {519 – 523},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092725561&partnerID=40&md5=c597b9d1645913b598e8ade51a2b7fda},
	affiliations = {Universidade Tecnológica Federal do Paraná, PR, Toledo, Brazil; Harvard Medical School, Boston, United States; University of Wolverhampton, Wolverhampton, United Kingdom},
	abstract = {In this paper we revisit the problem of automatically identifying hate speech in posts from social media. We approach the task using a system based on minimalistic compositional Recurrent Neural Networks (RNN). We tested our approach on the SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (HatEval) shared task dataset. The dataset made available by the HatEval organizers contained English and Spanish posts retrieved from Twitter annotated with respect to the presence of hateful content and its target. In this paper we present the results obtained by our system in comparison to the other entries in the shared task. Our system achieved competitive performance ranking 7th in sub-task A out of 62 systems in the English track. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Recurrent neural networks; Semantics; Speech recognition; Competitive performance; Performance rankings; Social media; Speech identification; Subtask; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Siddiqua2019365,
	author = {Siddiqua, Umme Aymun and Chy, Abu Nowshed and Aono, Masaki},
	title = {KDEHatEval at SemEval-2019 task 5: A neural network model for detecting hate speech in Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {365 – 370},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097489478&partnerID=40&md5=c09ca9695dfa0b0d7ece10c2b822c264},
	affiliations = {Department of Computer Science and Engineering, Toyohashi University of Technology, Aichi, Toyohashi, Japan},
	abstract = {In the age of emerging volume of microblog platforms, especially twitter, hate speech propagation is now of great concern. However, due to the brevity of tweets and informal user generated contents, detecting and analyzing hate speech on twitter is a formidable task. In this paper, we present our approach for detecting hate speech in tweets defined in the SemEval-2019 Task 5. Our team KDEHatEval employs different neural network models including multi-kernel convolution (MKC), nested LSTMs (NLSTMs), and multi-layer perceptron (MLP) in a unified architecture. Moreover, we utilize the state-of-the-art pre-trained sentence embedding models including DeepMoji, InferSent, and BERT for effective tweet representation. We analyze the performance of our method and demonstrate the contribution of each component of our architecture. © 2019 Association for Computational Linguistics},
	keywords = {Backpropagation; Computational linguistics; Multilayer neural networks; Network architecture; Speech; Speech recognition; Embeddings; Kernel convolution; Micro-blog; Multi-kernel; Multilayers perceptrons; Neural network model; Performance; State of the art; Unified architecture; User-generated; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Ruwandika2018273,
	author = {Ruwandika, N.D.T. and Weerasinghe, A.R.},
	title = {Identification of hate speech in social media},
	year = {2018},
	journal = {18th International Conference on Advances in ICT for Emerging Regions, ICTer 2018 - Proceedings},
	pages = {273 – 278},
	doi = {10.1109/ICTER.8615517},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062081783&doi=10.1109%2fICTER.8615517&partnerID=40&md5=66686c610891d0bf80f839da43db5d0c},
	affiliations = {University of Colombo, School of Computing, 35, Reid Avenue, Colombo, 00700, Sri Lanka},
	abstract = {An exploration of different approaches to detect hate speech in social media is present in this paper. Due to the rapid growing of online content hate speech has become a common issue which can influence variety of hate crimes. So, there is a need to find an accurate and efficient technique to detect online hate content and flag them automatically. The experiment was carried out using a local English text dataset. Hate speech is defined as the usage of language to insult or spread hatred towards a group or individual based on religion, race, gender or social status for the experiment. Then a comparison of both supervised and unsupervised learning techniques with different feature types for the task of hate speech detection was done. From all the supervised and unsupervised models Naïve Bayes classifier with Tf-idf features performed best with an F-score of 0.719. © 2018 IEEE.},
	author_keywords = {Hate speech; Naïve Bayes Classifier; Supervised Learning; Tf-idf; Unsupervised Learning},
	keywords = {Social networking (online); Speech; Supervised learning; Group-based; Hate speech; Individual-based; Learning techniques; Naive Bayes classifiers; Online content; Social media; Social status; Supervised and unsupervised learning; Tf-idf; Unsupervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; Conference name: 18th International Conference on Advances in ICT for Emerging Regions, ICTer 2018; Conference date: 27 September 2018 through 28 September 2018; Conference code: 144402}
}

@CONFERENCE{Patwardhan20181,
	author = {Patwardhan, Amol S},
	title = {Hostile behavior detection from multiple view points using RGB-D sensor},
	year = {2018},
	journal = {2017 IEEE SmartWorld Ubiquitous Intelligence and Computing, Advanced and Trusted Computed, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People and Smart City Innovation, SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI 2017 - Conference Proceedings},
	pages = {1 – 6},
	doi = {10.1109/UIC-ATC.2017.8397461},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050207113&doi=10.1109%2fUIC-ATC.2017.8397461&partnerID=40&md5=387e9e8a39016abeb4aa31dd4edfc052},
	affiliations = {AssetMark Inc, Concord, United States},
	abstract = {This paper presents a novel method for the detection of hostile behavior by a person from multiple viewing directions. Three dimensional, kinematic and gesture frequency based features were extracted from video and depth input data streams. Silhouette based features were extracted to compensate for instances where sensor tracked data was unavailable. The features were used to train the supervised learning classifier using 10-fold cross validation. The hostile behavior detection method was evaluated using supervised classification techniques such as support vector machine, random forest, Naïve Bayes and Multilayer Perceptron. The method showed overall accuracy of 90.273% using Random Forest classification. The method was compared to existing state of the art and showed better precision for specific viewing directions (full frontal, left and right profile view). © 2017 IEEE.},
	author_keywords = {aggression; hostile; Kinect; kinematic; rgb-d; silhouette features},
	keywords = {Data mining; Decision trees; Image retrieval; Kinematics; Smart city; Supervised learning; Ubiquitous computing; 10-fold cross-validation; aggression; Behavior detection; hostile; Kinect; Random forest classification; silhouette features; Supervised classification; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2017 IEEE SmartWorld Ubiquitous Intelligence and Computing, Advanced and Trusted Computed, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People and Smart City Innovation, SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI 2017; Conference date: 4 April 2017 through 8 April 2017; Conference code: 137514}
}

@CONFERENCE{Benito2019396,
	author = {Benito, Diego and Araque, Oscar and Iglesias, Carlos A.},
	title = {GSI-UPM at SemEval-2019 task 5: Semantic similarity and word embeddings for multilingual detection of hate speech against immigrants and women on Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {396 – 403},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087960046&partnerID=40&md5=cd5202c410f5e1029e129983fc3d3fc3},
	affiliations = {Intelligent Systems Group, Universidad Politécnica de Madrid, Avenida Complutense, 30, Madrid, Spain},
	abstract = {This paper describes the GSI-UPM system for SemEval-2019 Task 5, which tackles multilingual detection of hate speech on Twitter. The main contribution of the paper is the use of a method based on word embeddings and semantic similarity combined with traditional paradigms, such as n-grams, TF-IDF and POS. This combination of several features is fine-tuned through ablation tests, demonstrating the usefulness of different features. While our approach outperforms baseline classifiers on different sub-tasks, the best of our submitted runs reached the 5th position on the Spanish sub-task A. © 2019 Association for Computational Linguistics},
	keywords = {Embeddings; Social networking (online); Speech recognition; Embeddings; N-grams; Semantic similarity; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@ARTICLE{Kawano2019302,
	author = {Kawano, Atsuki and Zin, Thi Thi},
	title = {A study on violence behavior detection system between two persons},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {744},
	pages = {302 – 311},
	doi = {10.1007/978-981-13-0869-7_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048601938&doi=10.1007%2f978-981-13-0869-7_34&partnerID=40&md5=b0b7c1928ace29b6bd13d689da9c6a58},
	affiliations = {Graduate School of Engineering, University of Miyazaki, Miyazaki, Japan; Faculty of Engineering, University of Miyazaki, Miyazaki, Japan},
	abstract = {Lately, surveillance cameras have been widely used for security concerns to monitor human behavior analysis by using image processing technologies. In order to take into accounts for human rights, costs effectiveness, accuracy of performance the systems so that an automatic—human behavior analytic system shall be developed. –In particular, this paper focused on the action of two person violence and detecting two person fighting each other will be considered. Some experimental results are presented to confirm the proposed method by using ICPR 2010 Contest on Semantic Description of Human Activities (SDHA 2010) dataset. © 2019, Springer Nature Singapore Pte Ltd.},
	author_keywords = {Action detection; Morphology processing; Security camera; Violence detection},
	keywords = {Behavioral research; Cameras; Deep learning; Image processing; Information analysis; Network security; Security systems; Semantics; Behavior detection; Human behavior analysis; Image processing technology; Morphology processing; Security cameras; Semantic descriptions; Surveillance cameras; Violence detections; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Big Data Analysis and Deep Learning, ICBDL 2018; Conference date: 14 May 2018 through 15 May 2018; Conference code: 214169}
}

@CONFERENCE{Pratiwi2018447,
	author = {Pratiwi, Nur Indah and Budi, Indra and Alfina, Ika},
	title = {Hate speech detection on Indonesian instagram comments using FastText approach},
	year = {2018},
	journal = {2018 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2018},
	pages = {447 – 450},
	doi = {10.1109/ICACSIS.2018.8618182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062426275&doi=10.1109%2fICACSIS.2018.8618182&partnerID=40&md5=5de15e70687f920a3e5df1a11eb0307b},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia},
	abstract = {Instagram is one of social media hype, potentially used to spread hatred. The objective of our study is to conduct hate speech detection on Instagram comments for Indonesian language. We used FastText as the classifier and word representation. The experiment results showed that FastText is better than Random Forest Decision Tree and Logistic Regression. The highest result achieved when FastText is combined with bigram feature with F-measure of 65.7%. © 2018 IEEE.},
	author_keywords = {FastText; Hate speech detection; Instagram},
	keywords = {Speech recognition; Decision tree regression; Fasttext; Hate speech detection; Indonesian languages; Instagram; Logistics regressions; Random forests; Social media; Speech detection; Word representations; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 10th International Conference on Advanced Computer Science and Information Systems, ICACSIS 2018; Conference date: 27 October 2018 through 28 October 2018; Conference code: 144485}
}

@CONFERENCE{Zhang2019564,
	author = {Zhang, Yaojie and Xu, Bing and Zhao, Tiejun},
	title = {CN-HIT-MI.T at SemEval-2019 task 6: Offensive language identification based on BiLSTM with double attention},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {564 – 570},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113562960&partnerID=40&md5=e2432f99d83be5dedad74dcf5d755c21},
	affiliations = {Laboratory of Machine Intelligence and Translation, Harbin Institute of Technology, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China},
	abstract = {Offensive language has become pervasive in social media. In Offensive Language Identification tasks, it may be difficult to predict accurately only according to the surface words. So we try to dig deeper semantic information of text. This paper presents use an attention-based two layers bidirectional long-short memory neural network (BiLSTM) for semantic feature extraction. Additionally, a residual connection mechanism is used to synthesize two different deep features, and an emoji attention mechanism is used to extract semantic information of emojis in text. We participated in three sub-tasks of SemEval 2019 Task 6 as CN-HIT-MI.T team. Our macro-averaged F1-score in sub-task A is 0.768, ranking 28/103. We got 0.638 in subtask B, ranking 30/75. In sub-task C, we got 0.549, ranking 22/65. We also tried some other methods of not submitting results. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Multilayer neural networks; Semantics; Attention mechanisms; Language identification; Neural-networks; Offensive languages; Semantic feature extractions; Semantics Information; Short memory; Social media; Subtask; Two-layer; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Pamungkas2019363,
	author = {Pamungkas, Endangwahyu and Patti, Viviana},
	title = {Cross-domain and Cross-lingual abusive language detection: A hybrid approach with deep learning and a multilingual lexicon},
	year = {2019},
	journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Student Research Workshop},
	pages = {363 – 370},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083980606&partnerID=40&md5=b5b3556599f71f1155dd2245f3013740},
	affiliations = {Dipartimento di Informatica, University of Turin, Italy},
	abstract = {The development of computational methods to detect abusive language in social media within variable and multilingual contexts has recently gained significant traction. The growing interest is confirmed by the large number of benchmark corpora for different languages developed in the latest years. However, abusive language behaviour is multifaceted and available datasets are featured by different topical focuses. This makes abusive language detection a domain-dependent task, and building a robust system to detect general abusive content a first challenge. Moreover, most resources are available for English, which makes detecting abusive language in low-resource languages a further challenge. We address both challenges by considering ten publicly available datasets across different domains and languages. A hybrid approach with deep learning and a multilingual lexicon to cross-domain and cross-lingual detection of abusive content is proposed and compared with other simpler models. We show that training a system on general abusive language datasets will produce a cross-domain robust system, which can be used to detect other more specific types of abusive content. We also found that using the domain-independent lexicon HurtLex is useful to transfer knowledge between domains and languages. In the cross-lingual experiment, we demonstrate the effectiveness of our jointlearning model also in out-domain scenarios. © 2019 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Dependent tasks; Different domains; Domain independents; Hybrid approach; Language detection; Low resource languages; Multilingual context; Multilingual lexicons; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 81; Conference name: 57th Annual Meeting of the Association for Computational Linguistics, ACL 2019 - Student Research Workshop, SRW 2019; Conference date: 28 July 2019 through 2 August 2019; Conference code: 159210}
}

@CONFERENCE{Winter2019431,
	author = {Winter, Kevin and Kern, Roman},
	title = {Know-Center at SemEval-2019 task 5: Multilingual hate speech detection on Twitter using CNNs},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {431 – 435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097505320&partnerID=40&md5=6e41c194aa0084bedcb2a5d10f7f4ff3},
	affiliations = {Know-Center GmbH, Inffeldgasse 13, Graz, 8010, Austria},
	abstract = {This paper presents the Know-Center system submitted for task 5 of the SemEval-2019 workshop. Given a Twitter message in either English or Spanish, the task is to first detect whether it contains hateful speech and second, to determine the target and level of aggression used. For this purpose our system utilizes word embeddings and a neural network architecture, consisting of both dilated and traditional convolution layers. We achieved average F1-scores of 0.57 and 0.74 for English and Spanish respectively. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Multilayer neural networks; Network architecture; Semantics; Speech recognition; Embeddings; F1 scores; Neural network architecture; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Awal2018163,
	author = {Awal, Md. Abdul and Rahman, Md. Shamimur and Rabbi, Jakaria},
	title = {Detecting Abusive Comments in Discussion Threads Using Naïve Bayes},
	year = {2018},
	journal = {2018 International Conference on Innovations in Science, Engineering and Technology, ICISET 2018},
	pages = {163 – 167},
	doi = {10.1109/ICISET.2018.8745565},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069164215&doi=10.1109%2fICISET.2018.8745565&partnerID=40&md5=9465710c39240e056e0774546374eb3c},
	affiliations = {Department of Computer Science and Engineering, Khulna University of Engineering Technology, Khulna, 9203, Bangladesh},
	abstract = {Comments are supported by various websites and provide a simple approach to increment user involvement. Users can generally comment on different types of media such as: social networks, blogs, forums and news articles. As discussions increasingly move toward online forums, the issue of insulting and abusive comments is becoming prevalent. In addition, a lots of comments are available due to these social media. Hence, it is not feasible for a human moderator to check each comments one by one and flag them as abusive or not abusive. For this reason, an automated classifier which is quick and efficient is necessary to detect such type of comments. To fulfill above purpose, in this paper a Naïve Bayes classifier is designed to detect abusive comments expressed in Bangla. Using a training corpus collected from 'Youtube.com', the Naïve Bayes classifier is employed to categorize comments as abusive or not abusive. Finally, the performance is evaluated by using 10-fold cross-validation on unprocessed data. © 2018 IEEE.},
	author_keywords = {10-fold cross-validation; Abusive comments; machine learning; Naïve Bayes; text classification},
	keywords = {Learning systems; Social networking (online); Text processing; 10-fold cross-validation; Abusive comments; Automated classifiers; Bayes Classifier; Simple approach; Text classification; Training corpus; User involvement; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; Conference name: 2nd International Conference on Innovations in Science, Engineering and Technology, ICISET 2018; Conference date: 27 October 2018 through 28 October 2018; Conference code: 149080}
}

@CONFERENCE{Pavlopoulos2019571,
	author = {Pavlopoulos, John and Androutsopoulos, Ion and Thain, Nithum and Dixon, Lucas},
	title = {ConvAI at SemEval-2019 task 6: Offensive language identification and categorization with perspective and BERT},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {571 – 576},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095171614&partnerID=40&md5=db79022eafb9e4929f126097ab96d3c7},
	affiliations = {Department of Informatics, Athens University of Economics and Business, Greece; Jigsaw},
	abstract = {This paper presents the application of two strong baseline systems for toxicity detection and evaluates their performance in identifying and categorizing offensive language in social media. Perspective is an API, that serves multiple machine learning models for the improvement of conversations online, as well as a toxicity detection system, trained on a wide variety of comments from platforms across the Internet. BERT is a recently popular language representation model, fine tuned per task and achieving state of the art performance in multiple NLP tasks. Perspective performed better than BERT in detecting toxicity, but BERT was much better in categorizing the offensive type. Both baselines were ranked surprisingly high in the SEMEVAL-2019 OFFENSE-VAL competition, Perspective in detecting an offensive post (12th) and BERT in categorizing it (11th). The main contribution of this paper is the assessment of two strong baselines for the identification (Perspective) and the categorization (BERT) of offensive language with little or no additional training data. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Baseline systems; Detection system; Language identification; Machine learning models; Offensive languages; Performance; Representation model; Social media; State-of-the-art performance; Toxicity detection; Toxicity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Zhang2019441,
	author = {Zhang, Huangpan and Wojatzki, Michael and Horsmann, Tobias and Zesch, Torsten},
	title = {ltl.uni-due at SemEval-2019 task 5: Simple but effective lexico-semantic features for detecting hate speech in Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {441 – 446},
	doi = {10.18653/v1/s19-2078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092701646&doi=10.18653%2fv1%2fs19-2078&partnerID=40&md5=1d36330fe8b7d42a07882189723131af},
	affiliations = {Language Technology Lab, University of Duisburg-Essen, Germany},
	abstract = {In this paper, we present our contribution to SemEval 2019 Task 5 Multilingual Detection of Hate, specifically in the Subtask A (English and Spanish). We compare different configurations of shallow and deep learning approaches on the English data and use the system that performs best in both sub-tasks. The resulting SVM-based system with lexico-semantic features (n-grams and embeddings) is ranked 23rd out of 69 on the English data and beats the baseline system. On the Spanish data our system is ranked 25th out of 39. © 2019 Association for Computational Linguistics},
	keywords = {Deep learning; Baseline systems; Embeddings; Learning approach; Lexico-semantic; N-grams; Semantic features; Simple++; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737; All Open Access, Green Open Access}
}

@ARTICLE{Zhang2019925,
	author = {Zhang, Ziqi and Luo, Lei},
	title = {Hate speech detection: A solved problem? The challenging case of long tail on Twitter},
	year = {2019},
	journal = {Semantic Web},
	volume = {10},
	number = {5},
	pages = {925 – 945},
	doi = {10.3233/SW-180338},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072407649&doi=10.3233%2fSW-180338&partnerID=40&md5=97d656f7f9383969f0fca639a19fac4b},
	affiliations = {Information School, University of Sheffield, Regent Court, 211 Portobello, Sheffield, S1 4DP, United Kingdom; College of Pharmaceutical Science, Southwest University, Chongqing, 400716, China},
	abstract = {In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and researchers. A large number of methods have been developed for automated hate speech detection online. This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech. However, we notice significant difference between the performance of the two (i.e., non-hate vs. hate). In this work, we argue for a focus on the latter problem for practical reasons. We show that it is a much more challenging task, as our analysis of the language in the typical datasets shows that hate speech lacks unique, discriminative features and therefore is found in the â€ long tail' in a dataset that is difficult to discover. We then propose Deep Neural Network structures serving as feature extractors that are particularly effective for capturing the semantics of hate speech. Our methods are evaluated on the largest collection of hate speech datasets based on Twitter, and are shown to be able to outperform the best performing method by up to 5 percentage points in macro-average F1, or 8 percentage points in the more challenging case of identifying hateful content. © 2019 - IOS Press and the authors. All rights reserved.},
	author_keywords = {classification; CNN; deep learning; GRU; Hate speech; natural language processing; neural network; skipped CNN},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 178; All Open Access, Green Open Access}
}

@CONFERENCE{Garain2019494,
	author = {Garain, Avishek and Basu, Arpan},
	title = {The Titans at SemEval-2019 task 5: Detection of hate speech against immigrants and women in Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {494 – 497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071193233&partnerID=40&md5=3462ecbcd87f936bb30d69e6f18a3e52},
	affiliations = {Computer Science and Engineering, Jadavpur University, Kolkata, India},
	abstract = {This system paper is a description of the system submitted to “SemEval-2019 Task 5” Task B for the English language, where we had to primarily detect hate speech and then detect aggressive behaviour and its target audience in Twitter. There were two specific target audiences, immigrants and women. The language of the tweets was English. We were required to first detect whether a tweet is containing hate speech. Thereafter we were required to find whether the tweet was showing aggressive behaviour, and then we had to find whether the targeted audience was an individual or a group of people. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Speech recognition; English languages; Target audience; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Saha2019352,
	author = {Saha, Urmi and Dubey, Abhijeet and Bhattacharyya, Pushpak},
	title = {IIT Bombay at HASOC 2019: Supervised hate speech and offensive content detection in indo-european languages},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {352 – 358},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076920445&partnerID=40&md5=ae659512be975bf1c8b6afb58538130a},
	affiliations = {Indian Institute of Technology, India; United States},
	abstract = {Text classification is a classical problem in NLP and has impactful applications. An essential business application is hate speech detection from online data. With the enormous amount of social me- dia data getting generated continuously across the world, detection of hate speech is considered a very challenging task in NLP. In this pa- per, we describe our approaches for three shared tasks on hate speech and offensive content identification in Indo-European languages (Mandl et al. [9]). We describe statistical machine learning-based approaches as well as deep learning-based approaches and present their comparisons. We observe that convolutional neural networks perform quite well in the classification task. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Feature engineering; Hate speech; Machine learning; Neural networks; Word embeddings},
	keywords = {Classification (of information); Deep learning; Information retrieval; Learning systems; Machine learning; Natural language processing systems; Neural networks; Speech; Text processing; Business applications; Classification tasks; Content identifications; Convolutional neural network; Feature engineerings; Learning-based approach; Statistical machine learning; Text classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Nayel2019336,
	author = {Nayel, Hamada A. and Shashirekha, H.L.},
	title = {DEEP at HASOC2019 : A machine learning framework for hate speech and offensive language detection},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {336 – 343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076886369&partnerID=40&md5=4468a3e281a6319e90d9cea5c8fd5a12},
	affiliations = {Department of Computer Science, Faculty of Computers and Artificial Intelligence, Benha University, Egypt; Department of Computer Science, Mangalore University, India},
	abstract = {In this paper, we describe the system submitted by our team for Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) shared task held at FIRE 2019. Hate speech and offensive language detection have become an important task due to the overwhelming usage of social media platforms in our daily life. This task has been applied for three languages namely, English, Germany and Hindi. The proposed model uses classical machine learning approaches to create classifiers that are used to classify the given post according to different subtasks. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Hate Speech and Offensive Detection; Multi-lingual Text Analysis; Multi-task Classification},
	keywords = {Deep learning; Fires; Information retrieval; Machine learning; Text processing; Content identifications; Daily lives; European languages; Machine learning approaches; Model use; Offensive languages; Social media platforms; Text analysis; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Parizi2019514,
	author = {Parizi, Ali Hakimi and King, Milton and Cook, Paul},
	title = {UNBNLP at SemEval-2019 task 5 and 6: Using language models to detect hate speech and offensive language},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {514 – 518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096961035&partnerID=40&md5=7093efe80e2a1855a199c0e018edfae6},
	affiliations = {Faculty of Computer Science, University of New Brunswick, Fredericton, E3B 5A3, NB, Canada},
	abstract = {In this paper we apply a range of approaches to language modeling - including word-level n-gram and neural language models, and character-level neural language models - to the problem of detecting hate speech and offensive language. Our findings indicate that language models are able to capture knowledge of whether text is hateful or offensive. However, our findings also indicate that more-conventional approaches to text classification often perform similarly or better. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Modeling languages; Semantics; Speech recognition; Character level; Conventional approach; Language model; N-grams; Offensive languages; Word level; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Francesconi2019,
	author = {Francesconi, Chiara and Bosco, Cristina and Poletto, Fabio and Sanguinetti, Manuela},
	title = {Error analysis in a hate speech detection task: The case of Haspeede-TW at Evalita 2018},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074825424&partnerID=40&md5=ea099ea55bdd480a9918a43b58623980},
	affiliations = {Dipartimento di Lingue e Letterature Straniere e Culture Moderne, University of Turin, Italy; Dipartimento di Informatica, University of Turin, Italy},
	abstract = {Taking as a case study the Hate Speech Detection task at EVALITA 2018, the paper discusses the distribution and typology of the errors made by the five best-scoring systems. The focus is on the sub-task where Twitter data was used both for training and testing (HaSpeeDe-TW). In order to highlight the complexity of hate speech and the reasons beyond the failures in its automatic detection, the annotation provided for the task is enriched with orthogonal categories annotated in the original reference corpus, such as aggressiveness, offensiveness, irony and the presence of stereotypes. Copyright © 2019 for this paper by its authors.},
	keywords = {Computational linguistics; Automatic Detection; Scoring systems; Speech detection; Subtasks; Training and testing; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 6th Italian Conference on Computational Linguistics, CLiC-it 2019; Conference date: 13 November 2019 through 15 November 2019; Conference code: 152977}
}

@CONFERENCE{Ribeiro2019420,
	author = {Ribeiro, Alison P. and da Silva, Nádia F.F.},
	title = {INF-HatEval at SemEval-2019 task 5: Convolutional neural networks for hate speech detection against women and immigrants on Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {420 – 425},
	doi = {10.18653/v1/s19-2074},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102023504&doi=10.18653%2fv1%2fs19-2074&partnerID=40&md5=0c6f45e7a79166e89b7a1611d9f3a6a6},
	affiliations = {Institute of Informatics, Federal University of Goiás, Goiânia, Goiás, Brazil},
	abstract = {In this paper, we describe our approach to detect hate speech against women and immigrants on Twitter in a multilingual context, English and Spanish. This challenge was proposed by the SemEval-2019 Task 5, where participants should develop models for hate speech detection, a two-class classification where systems have to predict whether a tweet in English or in Spanish with a given target (women or immigrants) is hateful or not hateful (Task A), and whether the hate speech is directed at a specific person or a group of individuals (Task B). For this, we implemented a Convolutional Neural Networks (CNN) using pre-trained word embeddings (GloVe and FastText) with 300 dimensions. Our proposed model obtained in Task A 0.488 and 0.696 F1-score for English and Spanish, respectively. For Task B, the CNN obtained 0.297 and 0.430 EMR for English and Spanish, respectively. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Convolution; Neural networks; Social networking (online); Convolutional neural network; Embeddings; F1 scores; Multilingual context; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sahi2018533,
	author = {Sahi, Havvanur and Kilic, Yasemin and Saglam, Rahime Belen},
	title = {Automated Detection of Hate Speech towards Woman on Twitter},
	year = {2018},
	journal = {UBMK 2018 - 3rd International Conference on Computer Science and Engineering},
	pages = {533 – 536},
	doi = {10.1109/UBMK.2018.8566304},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060603099&doi=10.1109%2fUBMK.2018.8566304&partnerID=40&md5=408aa7f277a89c310141a584af4441c8},
	affiliations = {Computer Science Ankara Yildirim Beyazit University, Ankara, Turkey},
	abstract = {Given the steadily growing body of social media content, hate speech towards women is increasing. Such kind of contents have the potential to cause harm and suffering on an individual basis, and they may lead to social tension and disorder beyond cyber space. To support the automatic detection of cyber hate online, specifically on Twitter, we build a supervised learning model which is developed to classify cyber hate towards woman on Twitter. Turkish tweets, with a hashtag specific to choice of clothing for women, have been collected and five machine learning based classification algorithms were applied including Support Vector Machines (using polynomial and RBF Kernel), J48, Naive Bayes, Random Forest and Random Tree. Preliminary results showed that hateful contents can be detected with high precision however more sophisticated approaches are necessary to improve recall. © 2018 IEEE.},
	author_keywords = {classification; Hate speech recognition; machine learning; tf-idf},
	keywords = {Classification (of information); Decision trees; Learning systems; Machine learning; Social networking (online); Automated detection; Automatic Detection; Classification algorithm; Growing bodies; High-precision; Random forests; Social tensions; tf-idf; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 3rd International Conference on Computer Science and Engineering, UBMK 2018; Conference date: 20 September 2018 through 23 September 2018; Conference code: 143560}
}

@CONFERENCE{Corazza2019,
	author = {Corazza, Michele and Menini, Stefano and Cabrio, Elena and Tonelli, Sara and Villata, Serena},
	title = {Cross-platform evaluation for Italian hate speech detection},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074839808&partnerID=40&md5=93adb7b3bd0ba9306e461c3014ada28d},
	affiliations = {Université Côte d’Azur, CNRS, Inria, I3S, France; Fondazione Bruno Kessler, Trento, Italy},
	abstract = {Despite the number of approaches recently proposed in NLP for detecting abusive language on social networks, the issue of developing hate speech detection systems that are robust across different platforms is still an unsolved problem. In this paper we perform a comparative evaluation on datasets for hate speech detection in Italian, extracted from four different social media platforms, i.e. Facebook, Twitter, Instagram and WhatsApp. We show that combining such platform-dependent datasets to take advantage of training data developed for other platforms is beneficial, although their impact varies depending on the social network under consideration.1 Copyright © 2019 for this paper by its authors.},
	keywords = {Computational linguistics; Social networking (online); Comparative evaluations; Cross-platform; Facebook; Social media platforms; Speech detection; Training data; Unsolved problems; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Italian Conference on Computational Linguistics, CLiC-it 2019; Conference date: 13 November 2019 through 15 November 2019; Conference code: 152977}
}

@CONFERENCE{Gröndahl20182,
	author = {Gröndahl, Tommi and Pajola, Luca and Juuti, Mika and Conti, Mauro and Asokan, N.},
	title = {All you need is “love”: Evading hate speech detection},
	year = {2018},
	journal = {Proceedings of the ACM Conference on Computer and Communications Security},
	pages = {2 – 12},
	doi = {10.1145/3270101.3270103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056726309&doi=10.1145%2f3270101.3270103&partnerID=40&md5=48b720daddfece5c46b62783e83fe113},
	affiliations = {Aalto University, Finland; University of Padua, Italy},
	abstract = {With the spread of social networks and their unfortunate use for hate speech, automatic detection of the latter has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are brittle against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective – a cutting-edge solution from industry. Our experiments demonstrate that adversarial training does not completely mitigate the attacks, and using character-level features makes the models systematically more attack-resistant than using word-level features. Copyright © 2018 held by the owner/author(s). Publication rights licensed to ACM.},
	keywords = {Artificial intelligence; Speech; Attack resistants; Automatic Detection; Character level; Cutting edges; Model architecture; Proposed detection techniques; Speech detection; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 158; Conference name: 11th ACM Workshop on Artificial Intelligence and Security, AISec 2018, co-located with CCS 2018; Conference date: 19 October 2018; Conference code: 141187}
}

@CONFERENCE{Raiyani2019524,
	author = {Raiyani, Kashyap and Gonçalves, Teresa and Quaresma, Paulo and Nogueira, Vitor Beires},
	title = {Vista.ue at SemEval-2019 task 5: Single multilingual hate speech detection model},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {524 – 528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084702768&partnerID=40&md5=2b4e1ccdc6fe749bb8b6beecde7ecc50},
	affiliations = {Computer Science Department, University of Évora, Portugal},
	abstract = {This paper shares insight from participating in SemEval-2019 Task 5. The main propose of this system-description paper is to facilitate the reader with replicability and to provide insightful analysis of the developed system. Here in Vista.ue, we proposed a single multilingual hate speech detection model. This model was ranked 46/70 for English Task A and 31/43 for English Task B. Vista.ue was able to rank 38/41 for Spanish Task A and 22/25 for Spanish Task B. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Detection models; Replicability; Speech detection; System description; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Kumari2019328,
	author = {Kumari, Kirti and Singh, Jyoti Prakash},
	title = {AI ML NIT Patna at HASOC 2019: Deep learning approach for identification of abusive content},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {328 – 335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076932770&partnerID=40&md5=b1eec35825b5cda1fb138b498f764b88},
	affiliations = {National Institute of Technology Patna, Patna, India},
	abstract = {Social media is a globally open place for online users to ex- press their thoughts and opinions. There are numerous advantages of social media but some severe challenges are also associated with it. Anti- social and abusive conduct has become more common due to the emer- gence of social media. Identification of Hate Speech, Cyber-aggression, and Offensive language is a very challenging task. The nature of struc- tures of the natural language makes this task even more tedious. Being a challenging task, we are fascinated to propose a deep learning system based on Convolutional Neural Networks to identify Hate Speech, Offen- sive language, and Profanity.We have done experiments with three differ- ent embeddings. These experiments have been associated with comments of code-mixed Hindi-English and multi-domain social media text. We have found that One-hot embedding performed better than pre-trained fastText embedding for the code-mixed Hindi dataset. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Convolutional Neural Network; FastText; GloVe; Hate Speech; Offensive Language},
	keywords = {Convolution; Embeddings; Information retrieval; Neural networks; Social networking (online); Speech recognition; Convolutional neural network; FastText; GloVe; Learning approach; Multi domains; Natural languages; Offensive languages; Online users; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Raufi2018,
	author = {Raufi, Bujar and Xhaferri, Ildi},
	title = {Application of machine learning techniques for hate speech detection in mobile applications},
	year = {2018},
	journal = {2018 International Conference on Information Technologies, InfoTech 2018 - Proceedings},
	doi = {10.1109/InfoTech.2018.8510738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057109253&doi=10.1109%2fInfoTech.2018.8510738&partnerID=40&md5=91a2eba5fd642595aeb0ee7bd64acc07},
	affiliations = {Contemporary Sciences and Technologies, South East European University (SEEU), Tetovo, North Macedonia; Faculty of Engineering, Canadian Institute of Technology (CIT), Tirana, Albania},
	abstract = {The proliferation of data through various platforms and applications is in constant increase. The versatility of data and its omnipresence makes it very hard to detect the trustworthiness and intention of the source. This is very evident in dynamic environments such as mobile applications. As a result, designing mobile applications that will monitor, control and block any type of malintents is important. This paper makes an attempt in this direction by implementing a lightweight machine learning classification scheme for hate speech detection in Albanian Language for mobile applications. Initial testing and evaluations indicate good classifier accuracy in mobile environments where frequent and real-time training of the algorithm is required. © 2018 IEEE.},
	author_keywords = {artificial neural networks (ANNs); automatic hate speech detection; machine learning},
	keywords = {Mobile computing; Neural networks; Speech recognition; Albanian languages; Dynamic environments; Lightweight machines; Machine learning techniques; Mobile applications; Mobile environments; Speech detection; Testing and evaluation; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 2018 International Conference on Information Technologies, InfoTech 2018; Conference date: 20 September 2018 through 21 September 2018; Conference code: 141717}
}

@CONFERENCE{Almatarneh2019387,
	author = {Almatarneh, Sattam and Gamallo, Pablo and Ribadas Pena, Francisco J.},
	title = {CiTIUS-COLE at SemEval-2019 task 5: Combining linguistic features to identify hate speech against immigrants and women on multilingual tweets},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {387 – 390},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070522599&partnerID=40&md5=b64eb6bbafd0158a2c7b6be676c0a93f},
	affiliations = {CiTIUS, Universidade de Santiago de Compostela, Spain; University of Vigo, Spain; Department of Computer Science, University of Vigo, Spain},
	abstract = {This article describes the strategy submitted by the CiTIUS-COLE team to SemEval 2019 Task 5, a task which consists of binary classification where the system predicts whether a tweet in English or in Spanish is hateful against women or immigrants or not. The proposed strategy relies on combining linguistic features to improve the classifier's performance. More precisely, the method combines textual and lexical features, embedding words with the bag of words in Term Frequency-Inverse Document Frequency (TF-IDF) representation. The system performance reaches about 81% F1 when it is applied to the training dataset, but its F1 drops to 36% on the official test dataset for the English and 64% for the Spanish language concerning the hate speech class. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Inverse problems; Speech recognition; Text processing; Bag of words; Binary classification; Classifier performance; Feature embedding; Lexical features; Linguistic features; Systems performance; Term frequencyinverse document frequency (TF-IDF); Textual features; Training dataset; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Nourbakhsh2019484,
	author = {Nourbakhsh, Aria and Vermeer, Frida and Wiltvank, Gijs and van der Goot, Rob},
	title = {sthruggle at SemEval-2019 task 5: An ensemble approach to hate speech detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {484 – 488},
	doi = {10.18653/v1/s19-2086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092909425&doi=10.18653%2fv1%2fs19-2086&partnerID=40&md5=e93487c886c0ea514278b7de9eb4b934},
	affiliations = {University of Groningen, Groningen, Netherlands},
	abstract = {In this paper, we present our approach to detection of hate speech against women and immigrants in tweets for our participation in the SemEval-2019 Task 5. We trained an SVM and an RF classifier using character bi- and trigram features and a BiLSTM pre-initialized with external word embeddings. We combined the predictions of the SVM, RF and BiLSTM in two different ensemble models. The first was a majority vote of the binary values, and the second used the average of the confidence scores. For development, we got the highest accuracy (75%) by the final ensemble model with majority voting. For testing, all models scored substantially lower and the scores between the classifiers varied more. We believe that these large differences between the higher accuracies in the development phase and the lower accuracies we obtained in the testing phase have partly to do with differences between the training, development and testing data. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Bigrams; Binary values; Confidence score; Embeddings; Ensemble approaches; Ensemble models; High-accuracy; Majority voter; Speech detection; Tri grams; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Jiang2019254,
	author = {Jiang, Aiqi},
	title = {QMUL-NLP at HASOC 2019: Offensive content detection and classification in social media},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {254 – 262},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076891506&partnerID=40&md5=f49a81b1e0fc1aceb7ac2f7a40127605},
	affiliations = {Queen Mary University of London, London, E1 4NS, United Kingdom},
	abstract = {With the development of the Internet, the Web has become an information dissemination platform, an information amplifier, and a new social media. The information load and participation of the Internet far exceeds the existing traditional media, and various problems have emerged. There has been significant work in several languages in partic- ular for English. However, there is a lack of research in this recent and relevant topic for most other languages. This track intends to develop data and evaluation resources for several languages. The objectives are to stimulate research for these languages and to find out the quality of hate speech detection technology in other languages. The paper mainly describes the organization of the HASOC 2019 Task, a Shared Task on Hate Speech and Offensive Content Identification in Indo-European Lan- guages. The task is organized in three related classification subtasks: sub- task A is a coarse-grained binary classification to identify hate speech and offensive language, a fine-grained classification subtask B is to further classify the data from the subtask A into three categories, and subtask C will check the type of offense. This paper mainly focuses on English of- fensive language detection and shows the experimental result in subtask A and subtask B. © Copyright 2019 for this paper by its authors.},
	author_keywords = {HASOC; Hate speech detection; LSTM; Offensive language; Text classification; Word embed- ding},
	keywords = {C (programming language); Classification (of information); Information dissemination; Information retrieval; Long short-term memory; Social networking (online); Text processing; HASOC; LSTM; Offensive languages; Speech detection; Text classification; Word embed- ding; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Wu2019551,
	author = {Wu, Zhenghao and Zheng, Hao and Wang, Jianming and Su, Weifeng and Fong, Jefferson},
	title = {BNU-HKBU UIC NLP team 2 at SemEval-2019 task 6: Detecting offensive language using BERT model},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {551 – 555},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091389212&partnerID=40&md5=b699db38c803b90ce2d600ef9d183481},
	affiliations = {Computer Science and Technology, Division of Science and Technology, BNU-HKBU United International College, Guangdong, Zhuhai, China},
	abstract = {In this study we deal with the problem of identifying and categorizing offensive language in social media. Our group, BNU-HKBU UIC NLP Team2, use supervised classification along with multiple version of data generated by different ways of pre-processing the data. We then use the state-of-the-art model Bidirectional Encoder Representations from Transformers, or BERT (Devlin et al. (2018)), to capture linguistic, syntactic and semantic features. Long range dependencies between each part of a sentence can be captured by BERT's bidirectional encoder representations. Our results show 85.12% accuracy and 80.57% F1 scores in Subtask A (offensive language identification), 87.92% accuracy and 50% F1 scores in Subtask B (categorization of offense types), and 69.95% accuracy and 50.47% F1 score in Subtask C (offense target identification). Analysis of the results shows that distinguishing between targeted and untargeted offensive language is not a simple task. More work needs to be done on the unbalance data problem in Subtasks B and C. Some future work is also discussed. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Crime; Data handling; Semantics; Signal encoding; ART model; F1 scores; Linguistic features; Offensive languages; Pre-processing; Social media; State of the art; Subtask; Supervised classification; Syntactic features; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Kapil2019587,
	author = {Kapil, Prashant and Ekbal, Asif and Das, Dipankar},
	title = {NLP at SemEval-2019 task 6: Detecting offensive language using neural networks},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {587 – 592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093416785&partnerID=40&md5=3601f5a8bf5fec23d5fabd061f3e334f},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology, Patna, India; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India},
	abstract = {In this paper we built several deep learning architectures to participate in shared task OffensEval: Identifying and categorizing Offensive language in Social media by semEval-2019 (Zampieri et al., 2019b). The dataset was annotated with three level annotation schemes and task was to detect between offensive and not offensive, categorization and target identification in offensive contents. Deep learning models with POS information as feature were also leveraged for classification. The three best models that performed best on individual sub tasks are stacking of CNN-BiLSTM with Attention, BiLSTM with POS information added with word features and BiLSTM for third task. Our models achieved a Macro F1 score of 0.7594, 0.5378 and 0.4588 in Task(A,B,C) respectively with rank of 33rd, 54th and 52nd out of 103, 75 and 65 submissions. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Semantics; Annotation scheme; Best model; Learning architectures; Learning models; Neural-networks; Offensive languages; Social media; Subtask; Target's identifications; Three-level; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Mujadia2019271,
	author = {Mujadia, Vandan and Mishra, Pruthwik and Sharma, Dipti Misra},
	title = {IIIT-Hyderabad at HASOC 2019: Hate speech detection},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {271 – 278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076911324&partnerID=40&md5=960fb6fffe7835ea5c149c3453bb371d},
	affiliations = {MT and NLP Lab, LTRC, India},
	abstract = {Automatic identification of offensive language in various so- cial media platforms especially Twitter poses a great challenge to the AI community. The repercussions of such writings are hazardous to in- dividuals, communities, organizations and nations. The HASOC shared task attempts for automatic detection of abusive language on Twitter in English, German and Hindi languages. As a part of this task, we (team A3-108) submitted different machine learning and neural network based models for all the languages. Our best performing model was an ensemble model of SVM, Random Forest and Adaboost classifiers with majority voting. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Adaboost; Linear SVM; LSTM; Machine Learning; Neural Networks; Random Forest; TF-IDF},
	keywords = {Adaptive boosting; Automation; Decision trees; Information retrieval; Learning systems; Machine learning; Neural networks; Social networking (online); Ada boost classifiers; Automatic Detection; Automatic identification; Linear SVM; LSTM; Offensive languages; Random forests; TF-IDF; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Setyadi2018159,
	author = {Setyadi, Nabiila Adani and Nasrun, Muhammad and Setianingsih, Casi},
	title = {Text Analysis for Hate Speech Detection Using Backpropagation Neural Network},
	year = {2018},
	journal = {Proceedings - 2018 International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018},
	pages = {159 – 165},
	doi = {10.1109/ICCEREC.2018.8712109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066331486&doi=10.1109%2fICCEREC.2018.8712109&partnerID=40&md5=39235f407d2fe721c78ed1b92edfbcb8},
	affiliations = {Computer Engineering, School of Electrical Engineering, Telkom University, Indonesia},
	abstract = {In today's social media, especially twitter is very important for the success and destruction of one's image due to the many sentences of opinion that can compete the users. Examples of phrases that mean evil refer to hate speech to others. Evil perspectives can be categorized in hate speech, which hate speech is regulated in Article 28 of the ITE Law. Not a few people who intentionally and unintentionally oppose a social media that contains hate speech. Unfortunately, social media do not have the ability to aggregate information about an existing conversation into a conclusion. One way to draw conclusions from aggregation results is to use text mining. In this Final Project to classify whether the text in the sentence contains elements of hate speech or not. The author hopes in this final project can make how to classify element of hate speech in text by computer, which later speech of hate can be recognized. By using an Artificial Neural Network method optimized with Backpropagation algorithm. The author hopes after this application the computer can know and classify the existence of hate speech on a text from social media twitter. From the results of tests that have been done the average precision of 80.664%, recall 90.07%, and Accuracy of 89.47%. © 2018 IEEE.},
	author_keywords = {Backpropagation Neural Network; Hate Speech; Sentiment Analysis; Text Mining},
	keywords = {Backpropagation algorithms; Character recognition; Data mining; Neural networks; Sentiment analysis; Social networking (online); Speech; Artificial neural network methods; Back propagation neural networks; Social media; Speech detection; Text analysis; Text mining; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 4th International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018; Conference date: 5 December 2018 through 7 December 2018; Conference code: 147977}
}

@CONFERENCE{Polignano2019,
	author = {Polignano, Marco and Basile, Pierpaolo and de Gemmis, Marco and Semeraro, Giovanni},
	title = {Hate speech detection through Alberto Italian language understanding model},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077505100&partnerID=40&md5=84ade660e54f6ce4fc0a7171623bfab3},
	affiliations = {University of Bari, Dept. Computer Science, E.Orabona 4, Bari, 70125, Italy},
	abstract = {The task of identifying hate speech in social networks has recently attracted considerable interest in the community of natural language processing. This challenge has great importance for identifying cyberattacks on minors, bullying activities, misogyny, or other kinds of hate discriminations that can cause diseases. Identifying them quickly and accurately can, therefore, help to solve situations that are dangerous for the health of the attacked people. Numerous national and international initiatives have addressed this problem by providing many resources and solutions to the problem. In particular, we focus on the Hate Speech Detection evaluation campaign (HaSpeeDe) held at Evalita 2018. It proposes an evaluation campaign with the aim of developing strategies for identifying hate speeches on Twitter and Facebook written in the Italian language. The dataset released for the task has been used by the classification approach proposed in this work for demonstrating that it is possible to solve the task efficiently and accurately. Our solution is based on an Italian Language Understanding model trained with a BERT architecture and 200M of Italian Tweets (AlBERTo). We used AlBERTo for fine-tuning a classification model of hate speech, obtaining state of the art results considering the best systems presented at the HaSpeeDe workshop. In this regard, AlBERTo is here proposed as one of the most versatile resources to be used for the task of classification of Social Media Textual contents in the Italian Language. The claim is supported by the similar results obtained by AlBERTo in the task of sentiment analysis, and irony detection demonstrated in previous works. The resources need for fine-tuning AlBERTo in these classification tasks are available at: https://github.com/marcopoli/AlBERTo-it Copyright © 2019 for this paper by its authors.},
	author_keywords = {AlBERTo; Classification; Deep Learning; Hate Speech; Language understanding model; Machine Learning},
	keywords = {Artificial intelligence; Classification (of information); Deep learning; Learning algorithms; Learning systems; Sentiment analysis; Social networking (online); Speech; AlBERTo; Classification approach; Classification models; Classification tasks; Developing strategy; Language understanding; NAtural language processing; State of the art; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd Workshop on Natural Language for Artificial Intelligence, NL4AI 2019; Conference date: 19 November 2019 through 22 November 2019; Conference code: 155861}
}

@CONFERENCE{Parikh2019315,
	author = {Parikh, Apurva and Desai, Harsh and Singh Bisht, Abhimanyu},
	title = {DA Master at HASOC 2019: Identification of hate speech using machine learning and deep learning approaches for social media post},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {315 – 319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076898776&partnerID=40&md5=da384e46208581ceaeafd904a9b5c1d1},
	affiliations = {DA-IICT, Gujarat, India},
	abstract = {This paper describes the research that our team, DA Master, did on the shared task HASOC, conducted by FIRE-2019, which involves identification of hate and offensive language in Twitter and Facebook posts. The task is divided into three sub-tasks. Our team conducted our experiments on an English dataset. We employed Machine Learning techniques like Logistic Regression and Navies Bayes classifier and a Deep Learning based approach which utilizes Convolutional Neural Networks. Our best model obtained Macro F1 score of 0.6472 for SubTask-A, 0.4068 for SubTask-B and 0.4303 for SubTask-C. © Copyright 2019 for this paper by its authors.},
	keywords = {Fires; Information retrieval; Learning algorithms; Machine learning; Neural networks; Social networking (online); Warships; Bayes Classifier; Convolutional neural network; Learning approach; Learning-based approach; Logistic regressions; Machine learning techniques; Offensive languages; Social media; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Liu201987,
	author = {Liu, Ping and Li, Wen and Zou, Liang},
	title = {NULI at SemEval-2019 task 6: Transfer learning for offensive language detection using bidirectional transformers},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {87 – 91},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095245040&partnerID=40&md5=1d0c1336019ec35968f230091f75bf3b},
	affiliations = {Department of Computer Science, Illinois Institute of Technology, United States; Department of Linguistics, Indiana University, United States; Department of Mathematics, New York University, United States},
	abstract = {Transfer learning and domain adaptive learning have been applied to various fields including computer vision (e.g., image recognition) and natural language processing (e.g., text classification). One of the benefits of transfer learning is to learn effectively and efficiently from limited labeled data with a pre-trained model. In the shared task of identifying and categorizing offensive language in social media, we preprocess the dataset according to the language behaviors on social media, and then adapt and fine-tune the Bidirectional Encoder Representation from Transformer (BERT) pre-trained by Google AI Language team1. Our team NULI wins the first place (1st) in Sub-task A - Offensive Language Identification and is ranked 4th and 18th in Sub-task B - Automatic Categorization of Offense Types and Sub-task C - Offense Target Identification respectively. © 2019 Association for Computational Linguistics},
	keywords = {C (programming language); Character recognition; Classification (of information); Computational linguistics; Crime; Image recognition; Natural language processing systems; Semantics; Social networking (online); Adaptive learning; Labeled data; Language detection; Learn+; Offensive languages; Preprocess; Social media; Subtask; Transfer domains; Transfer learning; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 141; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@ARTICLE{Watanabe201813825,
	author = {Watanabe, Hajime and Bouazizi, Mondher and Ohtsuki, Tomoaki},
	title = {Hate Speech on Twitter: A Pragmatic Approach to Collect Hateful and Offensive Expressions and Perform Hate Speech Detection},
	year = {2018},
	journal = {IEEE Access},
	volume = {6},
	pages = {13825 – 13835},
	doi = {10.1109/ACCESS.2018.2806394},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042110053&doi=10.1109%2fACCESS.2018.2806394&partnerID=40&md5=dd0b43494c36879b644237f21a6b3b31},
	affiliations = {Graduate School of Science and Technology, Keio University, Yokohama, 223-8522, Japan},
	abstract = {With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more 'cyber' conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. Hate speech refers to the use of aggressive, violent or offensive language, targeting a specific group of people sharing a common property, whether this property is their gender (i.e., sexism), their ethnic group or race (i.e., racism) or their believes and religion. While most of the online social networks and microblogging websites forbid the use of hate speech, the size of these networks and websites makes it almost impossible to control all of their content. Therefore, arises the necessity to detect such speech automatically and filter any content that presents hateful language or language inciting to hatred. In this paper, we propose an approach to detect hate expressions on Twitter. Our approach is based on unigrams and patterns that are automatically collected from the training set. These patterns and unigrams are later used, among others, as features to train a machine learning algorithm. Our experiments on a test set composed of 2010 tweets show that our approach reaches an accuracy equal to 87.4% on detecting whether a tweet is offensive or not (binary classification), and an accuracy equal to 78.4% on detecting whether a tweet is hateful, offensive, or clean (ternary classification). © 2018 IEEE.},
	author_keywords = {hate speech; machine learning; sentiment analysis; Twitter},
	keywords = {Artificial intelligence; Classification (of information); Learning algorithms; Learning systems; Social networking (online); Speech; Websites; Binary classification; Common property; Offensive languages; On-line social networks; Sentiment analysis; Speech detection; Training sets; Twitter; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 308; All Open Access, Gold Open Access}
}

@CONFERENCE{Saroj2019308,
	author = {Saroj, Anita and Mundotiya, Rajesh Kumar and Pal, Sukomal},
	title = {IRLab@IITBHU at HASOC 2019: Traditional machine learning for hate speech and offensive content identification},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {308 – 314},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076902577&partnerID=40&md5=acd7b5a1b8893ffee9998df51e40d95e},
	affiliations = {Indian Institute of Technology (BHU) India, Varanasi, UP, India},
	abstract = {In this paper, the results obtained from the Support Vec- tor Machine, XGBoost method by IRLab@IIT(BHU) on HASOC shared task-organized at FIRE-2019 are reported. The HASOC shared task has three subtasks, namely Hate speech identification, Offensive language identification and Fine-grained classification for the English, Hindi and German languages. The best result for English is obtained after apply- ing Support Vector Machine, XGBoost with a frequency-based feature for hate speech and offensive content identification. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Hate Speech; Language; Offensive; Social Media},
	keywords = {Fires; Information retrieval; Machine learning; Support vector machines; Content identifications; Fine grained; German language; Language; Offensive; Offensive languages; Social media; Speech identification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Mishra20192145,
	author = {Mishra, Pushkar and Tredici, Marco Del and Yannakoudakis, Helen and Shutova, Ekaterina},
	title = {Abusive language detection with graph convolutional networks},
	year = {2019},
	journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
	volume = {1},
	pages = {2145 – 2150},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084304758&partnerID=40&md5=4a4c834e1c89bdce2478baf780f8b2b0},
	affiliations = {Facebook AI, London, United Kingdom; ILLC, University of Amsterdam, Netherlands; ALTA Institute, Dept. of CS and Technology, University of Cambridge, United Kingdom},
	abstract = {Abuse on the Internet represents a significant societal problem of our time. Previous research on automated abusive language detection in Twitter has shown that community-based profiling of users is a promising technique for this task. However, existing approaches only capture shallow properties of online communities by modeling follower-following relationships. In contrast, working with graph convolutional networks (GCNs), we present the first approach that captures not only the structure of online communities but also the linguistic behavior of the users within them. We show that such a heterogeneous graph-structured modeling of communities significantly advances the current state of the art in abusive language detection. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Convolution; Convolutional neural networks; Graph structures; Online systems; Social networking (online); Community-based; Convolutional networks; Heterogeneous graph; Language detection; On-line communities; Societal problems; State of the art; Structured model; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; Conference name: 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 2 June 2019 through 7 June 2019; Conference code: 159851}
}

@CONFERENCE{Mishra2019208,
	author = {Mishra, Shubhanshu and Mishra, Sudhanshu},
	title = {3Idiots at HASOC 2019: Fine-tuning transformer neural networks for hate speech identification in indo-european languages},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {208 – 213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076887135&partnerID=40&md5=cb3f1051042ce8214b41f99d8ea5489e},
	affiliations = {I-School, University of Illinois at Urbana-Champaign, Champaign, 61820, IL, United States; IIT Kanpur, 208016, UP, India},
	abstract = {We describe our team 3Idiots's approach for participating in the 2019 shared task on hate speech and offensive content (HASOC) identification in Indo-European languages. Our approach relies on fine- tuning pre-trained monolingual and multilingual transformer (BERT) based neural network models. Furthermore, we also investigate an ap- proach based on labels joined from all sub-tasks. This resulted in good performance on the test set. Among the eight shared tasks, our solution won the first place for English sub-tasks A and B, and Hindi sub-task B. Additionally, it was within the top 5 for 7 of the 8 tasks, being within 1% of the best solution for 5 out of the 8 sub-tasks. We open source our approach at https://github.com/socialmediaie/HASOC2019. © Copyright 2019 for this paper by its authors.},
	author_keywords = {BERT; Deep Learning; Hate Speech Identification; Neural Networks; Offensive Content Identifica- tion; Transformers},
	keywords = {Deep learning; Deep neural networks; Electric transformers; Information retrieval; Neural networks; BERT; European languages; Fine tuning; Neural network model; Offensive Content Identifica- tion; Open sources; Speech identification; Test sets; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Wiegand2019602,
	author = {Wiegand, Michael and Ruppenhofer, Josef and Kleinbauer, Thomas},
	title = {Detection of abusive language: The problem of biased datasets},
	year = {2019},
	journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
	volume = {1},
	pages = {602 – 608},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075069349&partnerID=40&md5=d769f651f6939fd7205d3fabaa1dcb8d},
	affiliations = {Spoken Language Systems, Saarland University, Saarbrücken, Germany; Leibniz ScienceCampus, Heidelberg/Mannheim, Germany; Institute for German Language, Mannheim, Germany},
	abstract = {We discuss the impact of data bias on abusive language detection. We show that classification scores on popular datasets reported in previous work are much lower under realistic settings in which this bias is reduced. Such biases are most notably observed on datasets that are created by focused sampling instead of random sampling. Datasets with a higher proportion of implicit abuse are more affected than datasets with a lower proportion. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Language detection; Random sampling; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 183; Conference name: 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 2 June 2019 through 7 June 2019; Conference code: 159851}
}

@CONFERENCE{Mulki2019503,
	author = {Mulki, Hala and Ali, Chedi Bechikh and Haddad, Hatem and Babaoğlu, Ismail},
	title = {Tw-StAR at SemEval-2019 task 5: N-gram embeddings for hate speech detection in multilingual tweets},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {503 – 507},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097506427&partnerID=40&md5=638daffed37a9d45ecd32e74aca8f74f},
	affiliations = {Department of Computer Engineering, Selcuk University, Turkey; LISI Laboratory, INSAT, Carthage University, Tunisia; RIADI Laboratory, National School of Computer Sciences, University of Manouba, Tunisia; iCompass Consulting, Tunisia},
	abstract = {In this paper, we describe our contribution in SemEval-2019: subtask A of task 5 “Multilingual detection of hate speech against immigrants and women in Twitter (HatEval)”. We developed two hate speech detection model variants through Tw-StAR framework. While the first model adopted one-hot encoding n-grams to train an NB classifier, the second generated and learned n-gram embeddings within a feedforward neural network. For both models, specific terms, selected via MWT patterns, were tagged in the input data. With two feature types employed, we could investigate the ability of n-gram embeddings to rival one-hot n-grams. Our results showed that in English, n-gram embeddings outperformed one-hot n-grams. However, representing Spanish tweets by one-hot n-grams yielded a slightly better performance compared to that of n-gram embeddings. The official ranking indicated that Tw-StAR ranked 9th for English and 20th for Spanish. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Feedforward neural networks; Semantics; Speech recognition; Stars; Detection models; Embeddings; Feature types; Input datas; N-grams; Performance; Speech detection; Subtask; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Modha2019167,
	author = {Modha, Sandip and Mandl, Thomas and Majumder, Prasenjit and Patel, Daksh},
	title = {Overview of the HASOC track at FIRE 2019: Hate speech and offensive content identification in indo-european languages},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {167 – 190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076914543&partnerID=40&md5=8ec4836a894c8567dab16a0c3611e6fc},
	affiliations = {DA-IICT, Gandhinagar, India; University of Hildesheim, Germany; LDRP-ITR, Gandhinagar, India},
	abstract = {The identification of Hate Speech in Social Media has re- ceived much attention in research recently. There is a particular demand for research for languages other than English. The first edition of the HASOC track creates resources for Hate Speech Identification in Hindi, German, and English. Three datasets were developed from Twitter, and Facebook and made available. HASOC intends to stimulate research and development for Hate Speech classification for different languages. The datasets allow the development and testing of supervised machine learn- ing systems. Binary classification and more fine-grained sub-classes were offered in 3 sub tasks. For all sub-tasks, 321 experiments were submitted. For the classification task, models based on deep learning methods have proved to be adequate. The approaches used most often were Long-Short- Term memory (LSTM) networks with distributed word representation of the text. The performance of the best system for identification of Hate Speech for English, Hindi, and German was a Marco-F1 score of 0.78, 0.81, and 0.61, respectively. This overview provides details insights and analyzes the results. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Deep Learning; Evaluation; Hate Speech; Text Classification},
	keywords = {Classification (of information); Deep learning; Fires; Information retrieval; Long short-term memory; Social networking (online); Speech; Text processing; Binary classification; Content identifications; Development and testing; Evaluation; Research and development; Speech classification; Speech identification; Text classification; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Nina-Alcocer2019214,
	author = {Nina-Alcocer, Victor},
	title = {Vito at HASOC 2019: Detecting hate speech and offensive content through ensembles},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {214 – 220},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076895661&partnerID=40&md5=36fe7e69d890fa8bcdf0d1ce8cc3c980},
	affiliations = {Department of Computer Systems and Computation, Universitat Politecnica de Valencia, Cami de Vera s/n, Valencia, 46022, Spain},
	abstract = {This paper describes our participation in the shared task \Hate Speech and Offensive Content Identification in Indo-European Languages' (HASOC) at the Forum for Information Retrieval Evaluation (FIRE) 2019. This work studies the detection of hate or offensive content on English posts published on Facebook or Twitter. For a finegrained study of the task, we analyzed two different approaches: the first one regards the design of two architectures using convolutional and recurrent neural networks. Meanwhile, the second approach examines a range of paradigms based on classical machine algorithms, neural networks, and transformers. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Convolutional Neural Networks; Facebook; Hate Speech; Offensive Content; Recurrent Neural Networks; Transformers; Twitter},
	keywords = {Convolution; Electric transformers; Fires; Information retrieval; Social networking (online); Speech recognition; Content identifications; Convolutional neural network; European languages; Facebook; Machine algorithm; Offensive Content; Twitter; Work study; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Reich2019,
	author = {Reich, Devin and Todoki, Ariel and Dowsley, Rafael and de Cock, Martine and Nascimento, Anderson},
	title = {Privacy-preserving classification of personal text messages with secure multi-party computation: An application to hate-speech detection},
	year = {2019},
	journal = {Advances in Neural Information Processing Systems},
	volume = {32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090169969&partnerID=40&md5=fe656efb384d785464996734fb9f7ecc},
	affiliations = {School of Engineering and Technology, University of Washington Tacoma, Tacoma, 98402, WA, United States; Department of Computer Science, Bar-Ilan University, Ramat-Gan, 5290002, Israel; Dept. of Applied Mathematics, Computer Science, and Statistics, Ghent University, Belgium},
	abstract = {Classification of personal text messages has many useful applications in surveillance, e-commerce, and mental health care, to name a few. Giving applications access to personal texts can easily lead to (un)intentional privacy violations. We propose the first privacy-preserving solution for text classification that is provably secure. Our method, which is based on Secure Multiparty Computation (SMC), encompasses both feature extraction from texts, and subsequent classification with logistic regression and tree ensembles. We prove that when using our secure text classification method, the application does not learn anything about the text, and the author of the text does not learn anything about the text classification model used by the application beyond what is given by the classification result itself. We perform end-to-end experiments with an application for detecting hate speech against women and immigrants, demonstrating excellent runtime results without loss of accuracy. © 2019 Neural information processing systems foundation. All rights reserved.},
	keywords = {Classification (of information); Data privacy; Logistic regression; Speech recognition; Classification results; Privacy preserving solutions; Privacy violation; Privacy-preserving classification; Secure multi-party computation; Text classification; Text classification methods; Text classification models; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 33rd Annual Conference on Neural Information Processing Systems, NeurIPS 2019; Conference date: 8 December 2019 through 14 December 2019; Conference code: 161263}
}

@CONFERENCE{Alonso2019293,
	author = {Alonso, Pedro and Saini, Rajkumar and Kovács, György},
	title = {TheNorth at HASOC 2019: Hate speech detection in social media data},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {293 – 299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076905278&partnerID=40&md5=78620076fb56a0b8ebc3f6a00f4360ca},
	affiliations = {Lulea University of Technology, Sweden},
	abstract = {The detection of hate speech in social media is a crucial task. The uncontrolled spread of hate speech can be detrimental to maintaining the peace and harmony in society. Particularly when hate speech is spread with the intention to defame people, or spoil the image of a person, a community, or a nation. A major ground for spreading hate speech is that of social media. This significantly contributes to the difficulty of the task, as social media posts not only include paralinguistic tools (e.g. emoticons, and hashtags), their linguistic content contains plenty of poorly written text that does not adhere to grammar rules. With the recent development in Natural Language Processing (NLP), particularly with deep architecture, it is now possible to anlayze unstructured composite natural language text. For this reason, we propose a deep NLP model for the detection of automatic hate speech in social media data. We have applied our model on the HASOC2019 hate speech corpus, and attained a macro F1 score of 0:63 in the detection of hate speech. © Copyright 2019 for this paper by its authors.},
	keywords = {Information retrieval; Linguistics; Natural language processing systems; Social networking (online); Speech; Deep architectures; NAtural language processing; Natural language text; Paralinguistic; Social media datum; Speech corpora; Speech detection; Written texts; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Mishra2019344,
	author = {Mishra, Akanksha and Pal, Sukomal},
	title = {IIT Varanasi at HASOC 2019 : Hate speech and offensive content identification in indo-european languages},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {344 – 351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076889661&partnerID=40&md5=0ebb19120cb703233a3d9b0e939597c1},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology (BHU), Varanasi, 221005, India},
	abstract = {The track aims to develop a system that identifies hate speech and offensive content in the document and further classifies them into hate speech, offensive content, or usage of profane words. Also, it deter- mines whether hate speech is targetted to some individual or a group. We use bidirectional long short term memory along with attention across all languages (English, German, and Hindi) in the track. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Attention; Bidirectional LSTM; Hate Speech; Indo-European Languages; Offensive Content},
	keywords = {Information retrieval; Long short-term memory; Speech; Attention; Bidirectional LSTM; Content identifications; European languages; Offensive Content; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Wang2019818,
	author = {Wang, Bin and Zhou, Xiaobing and Zhang, Xuejie},
	title = {YNUWB at SemEval-2019 task 6: K-max pooling CNN with average meta-embedding for identifying offensive language},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {818 – 822},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093403100&partnerID=40&md5=94e5d405f72e8c038a76e70af2069f90},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {This paper describes the system submitted to SemEval 2019 Task 6: OffensEval 2019. The task aims to identify and categorize offensive language in social media, we only participate in Sub-task A, which aims to identify offensive language. In order to address this task, we propose a system based on a K-max pooling convolutional neural network model, and use an argument for averaging as a valid meta-embedding technique to get a meta-embedding. Finally, we use a cyclic learning rate policy to improve model performance. Our model achieves a Macro F1-score of 0.802 (ranked 9/103) in the Sub-task A. © 2019 Association for Computational Linguistics},
	keywords = {Convolutional neural networks; Semantics; Convolutional neural network; Embedding technique; Embeddings; Learning rates; Max-pooling; Modeling performance; Neural network model; Offensive languages; Social media; Subtask; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Oberstrass2019628,
	author = {Oberstrass, Alexander and Romberg, Julia and Stoll, Anke and Conrad, Sefan},
	title = {HHU at SemEval-2019 task 6: Context does matter - Tackling offensive language identification and categorization with ELMo},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {628 – 634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093372920&partnerID=40&md5=12c538a80817c5aa557e5b79714edc26},
	affiliations = {Institute of Computer Science, Heinrich Heine University Düsseldorf, Germany; Department of Social Sciences, Heinrich Heine University Düsseldorf, Germany},
	abstract = {We present our results for OffensEval: Identifying and Categorizing Offensive Language in Social Media (SemEval 2019 - Task 6). Our results show that context embeddings are important features for the three different sub-tasks in connection with classical machine and with deep learning. Our best model reached place 3 of 75 in sub-task B with a macro F1 of 0.719. Our approaches for sub-task A and C perform less well but could also deliver promising results. © 2019 Association for Computational Linguistics},
	keywords = {Natural language processing systems; Semantics; Best model; Embeddings; Important features; Language identification; Offensive languages; Social media; Subtask; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Saksesi2018242,
	author = {Saksesi, Arum Sucia and Nasrun, Muhammad and Setianingsih, Casi},
	title = {Analysis Text of Hate Speech Detection Using Recurrent Neural Network},
	year = {2018},
	journal = {Proceedings - 2018 International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018},
	pages = {242 – 248},
	doi = {10.1109/ICCEREC.2018.8712104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066322130&doi=10.1109%2fICCEREC.2018.8712104&partnerID=40&md5=9058777814d2435567191a17b2f2cf6b},
	affiliations = {Computer Engineering, School of Electrical Engineering, Telkom Unhiversity, Indonesia},
	abstract = {In today's social media, especially Twitter is very important for the success and destruction of one's image due to the many sentences of opinion that can compete the users. Examples of phrases that mean evil refer to hate speech to others. Evil perspectives can be categorized in hate speech, which hates speech is regulated in Article 28 of the ITE Law. Not a few people who intentionally and unintentionally oppose social media that contain hate speech. Unfortunately, social media does not have the ability to aggregate information about an existing conversation into a conclusion. One way to draw conclusions from aggregation results is to use text mining. In this paper to classify whether the text in the sentence contains elements of hate speech or not. The author hopes in this paper can make how to classify element of hate speech in the text by a computer, which later speech of hate can be recognized. By using Deep Learning method with Recurrent Neural Network (RNN) algorithm. After the creation of this program, it is hoped the computer can know and classify the existence of hate speech in the sentence. From the results of tests that have been done the average precision of 91%, recall 90% and accuracy 91% © 2018 IEEE.},
	author_keywords = {Analysis text; Deep Learning; Hate Speech; LSTM; Recurrent Neural Network; RNN},
	keywords = {Character recognition; Data mining; Deep learning; Long short-term memory; Recurrent neural networks; Social networking (online); Speech; Analysis text; Learning methods; LSTM; Recurrent neural network (RNN); Social media; Speech detection; Text mining; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; Conference name: 4th International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018; Conference date: 5 December 2018 through 7 December 2018; Conference code: 147977}
}

@CONFERENCE{Sazany2018114,
	author = {Sazany, Erryan and Budi, Indra},
	title = {Deep Learning-Based Implementation of Hate Speech Identification on Texts in Indonesian: Preliminary Study},
	year = {2018},
	journal = {Proceedings of ICAITI 2018 - 1st International Conference on Applied Information Technology and Innovation: Toward A New Paradigm for the Design of Assistive Technology in Smart Home Care},
	pages = {114 – 117},
	doi = {10.1109/ICAITI.2018.8686725},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064767689&doi=10.1109%2fICAITI.2018.8686725&partnerID=40&md5=8757065d91433a267bfee2c4a6a9d7e4},
	affiliations = {Faculty of Computer Science, University of Indonesia, Depok, Indonesia},
	abstract = {This paper presents an implementation of hate speech identification task for text data written in Indonesian language. There are some studies purposed for similar problem, but all of them use classical machine learning approach, whose heavily depends on the feature engineering. Switching the domain of data set means that the feature engineering should be redone. To address this issue, this preliminary research proposes another method based on deep learning approach which needs no feature engineering and is also adaptive to the varying context. Using data sets sourced from Twitter posts, the proposed method gives better result of 94.5% F1-score at a minimum. © 2018 IEEE.},
	author_keywords = {abusive; deep learning; hate speech; machine learning; word embedding},
	keywords = {Automation; Engineering education; Engineering research; Learning systems; Machine learning; Speech recognition; abusive; Feature engineerings; Indonesian languages; Learning approach; Machine learning approaches; Speech identification; Twitter posts; word embedding; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 1st International Conference on Applied Information Technology and Innovation, ICAITI 2018; Conference date: 4 September 2018 through 5 September 2018; Conference code: 147304}
}

@CONFERENCE{Bashar2019237,
	author = {Bashar, Md Abul and Nayak, Richi},
	title = {QutNocturnal@HASOC'19: CNN for hate speech and offensive content identification in Hindi language},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {237 – 245},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076908308&partnerID=40&md5=deec288900b75e7f4a87c4bbbb2c85c2},
	affiliations = {School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Australia},
	abstract = {We describe our top-team solution to Task 1 for Hindi in the HASOC contest organised by FIRE 2019. The task is to identify hate speech and offensive language in Hindi. More specifically, it is a binary classification problem where a system is required to classify tweets into two classes: (a) Hate and Offensive (HOF) and (b) Not Hate or Offensive (NOT). In contrast to the popular idea of pretraining word vectors (a.k.a. word embedding) with a large corpus from a general domain such as Wikipedia, we used a relatively small collection of relevant tweets (i.e. random and sarcasm tweets in Hindi and Hinglish) for pretraining. We trained a Convolutional Neural Network (CNN) on top of the pretrained word vectors. This approach allowed us to be ranked first for this task out of all teams. Our approach could easily be adapted to other applications where the goal is to predict class of a text when the provided context is limited. © Copyright 2019 for this paper by its authors.},
	author_keywords = {CNN; Deep Learning; Hate Speech; Hindi; Offensive Content},
	keywords = {Deep learning; Fires; Information retrieval; Neural networks; Binary classification problems; Content identifications; Convolutional neural network; Hindi; Large corpora; Offensive Content; Offensive languages; Pre-training; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Machova2019450,
	author = {Machova, Kristina and Birka, Jan},
	title = {Sentiment analysis of web trends for the antisocial behaviour detection},
	year = {2019},
	journal = {IC3K 2019 - Proceedings of the 11th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management},
	volume = {1},
	pages = {450 – 457},
	doi = {10.5220/0008349104500457},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074186787&doi=10.5220%2f0008349104500457&partnerID=40&md5=e69d10ff87ac97d37dd5392ef74ea751},
	affiliations = {Department of Cybernetics and Artificial Intelligence, Technical University of Kosice, Letna 9, Kosice, Slovakia},
	abstract = {The paper presents an approach to extraction of current web trends for research into automated recognition of antisocial behaviour in online discussions. Antisocial behaviour is a drawback of online discussions as compared to their advantages such as wisdom of crowds and collective intelligence. The first step to recognition of antisocial behaviour is the identification of web trends connected with it. These are studied in dynamic conditions using sentiment analysis as a webometric. A new sentiment analysis method based on a lexicon was developed. Two modifications of the lexicon sentiment analysis method were designed and tested involving NLP (natural language processing) and an original technique for negations and intensifications processing. The most effective sentiment classification method was used for the extraction of web trends. Extracted web trends were analysed in a dynamic way and findings of this analysis were compared to known historical events. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved},
	author_keywords = {Antisocial Behaviour; Lexicon Approach; Online Discussion; Sentiment Analysis; Web Trends},
	keywords = {Extraction; Knowledge management; Sentiment analysis; Social networking (online); Antisocial Behaviour; Automated recognition; Collective intelligences; Lexicon Approach; Nlp (natural language processing); Online discussions; Sentiment classification; Web Trends; Behavioral research},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 11th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K 2019; Conference date: 17 September 2019 through 19 September 2019; Conference code: 152660; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Mensonides2019279,
	author = {Mensonides, Jean-Christophe and Jean, Pierre-Antoine and Tchechmedjiev, Andon and Harispe, Sebastien},
	title = {IMT mines ales at HASOC 2019: Automatic hate speech detection},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {279 – 284},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076924972&partnerID=40&md5=476a48a0b49a218ec832e6a4078e1efe},
	affiliations = {LGI2P, IMT Mines Ales, Univ Montpellier, Ales, France},
	abstract = {This paper presents the contribution of the LGI2P (Laboratoire de Génie Informatique et d'Ingénierie de Production) team from IMT Mines Ales to the Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) 2019 shared task. This challenge aims at automatically identifying hate speech content in social media through three sub-tasks, each available in three different languages (English, German and Hindi). We are interested in sub-tasks A and B, requiring to (A) classify tweets as offensive or as non offensive, and (B) to further classify offensive tweets from sub-task A as hate speech, offensive speech or profane. We trained a fastText model for each proposed language and obtained promising results on the Hindi dataset for both sub-tasks A and B. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Hate Speech Identification and Offensive Detection1; Tweet Classification},
	keywords = {Information retrieval; Speech; Content identifications; European languages; Social media; Speech content; Speech detection; Speech identification; Subtasks; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Bauwelinck2019436,
	author = {Bauwelinck, Nina and Jacobs, Gilles and Hoste, Véronique and Lefever, Els},
	title = {LT3 at SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter (hatEval)},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {436 – 440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096499063&partnerID=40&md5=4fd01014ab2c0a61b9e6321a046ea847},
	affiliations = {LT3, Language and Translation Technology Team, Department of Translation, Interpreting and Communication, Ghent University, Groot-Brittanniëlaan 45, Ghent, 9000, Belgium},
	abstract = {This paper describes our contribution to the SemEval-2019 Task 5 on the detection of hate speech against immigrants and women in Twitter (hatEval). We considered a supervised classification-based approach to detect hate speech in English tweets, which combines a variety of standard lexical and syntactic features with specific features for capturing offensive language. Our experimental results show good classification performance on the training data, but a considerable drop in recall on the held-out test set. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Semantics; Speech; Speech recognition; Classification performance; Lexical features; Offensive languages; Supervised classification; Syntactic features; Test sets; Training data; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Khan2018,
	author = {Khan, Mahrukh and Tahir, Muhammad Atif and Ahmed, Zeeshan},
	title = {Detection of Violent Content in Cartoon Videos Using Multimedia Content Detection Techniques},
	year = {2018},
	journal = {Proceedings of the 21st International Multi Topic Conference, INMIC 2018},
	doi = {10.1109/INMIC.2018.8595563},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061507951&doi=10.1109%2fINMIC.2018.8595563&partnerID=40&md5=2c66709c911e8871f6f597c83a28f02b},
	affiliations = {Dept. of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan},
	abstract = {Children are the most vulnerable to ideas presented in Cartoon videos and TV. Cartoons have become one of the most important source of entertainment, but it also introduce a lot of ideas that are not suitable for them. Violence is one of the unwanted feature that is prevalent in cartoons to put element of fantasy and enchantment. In order to stop children from viewing violent intense cartoons, the best strategy is to make them inaccessible. Therefore, some sort of filters should be placed at certain hubs to perform this task. The challenge is that how a filter will know that a particular cartoon video has violent content in it. The meta-data telling the world about the video does not inform that the video consists of violent material. Certain frames/snapshots/images of video, if analyzed using image processing techniques, can help in concluding that a particular video has intense material in it. The aim of this work is to classify social media videos especially related to animated cartoons with violent / nonviolent behaviors. It addresses the problem of content based image matching algorithms based on key point descriptors. The basic goal is to extract general information from an image without any specific query. First SIFT-descriptors are extracted from a large set of images. This set of descriptors are then defined as a means of providing fast and accurate comparisons between images and distinguish between violent and nonviolent images in combination with Machine Learning algorithms. The results are then compared for each classifier with varying parameters. © 2018 IEEE.},
	keywords = {Learning algorithms; Machine learning; Content based images; Descriptors; General information; Image processing technique; Multimedia contents; SIFT descriptors; Social media; Varying parameters; Image processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 21st International Multi Topic Conference, INMIC 2018; Conference date: 1 November 2018 through 2 November 2018; Conference code: 144133}
}

@CONFERENCE{Saha2019246,
	author = {Saha, Punyajoy and Mathew, Binny and Goyal, Pawan and Mukherjee, Animesh},
	title = {HateMonitors: Language agnostic abuse detection in social media},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {246 – 253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076907283&partnerID=40&md5=445ba1148e83d65cce9b8c66afb1f4fb},
	affiliations = {Indian Institute of Technology, Kharagpur, 721302, West Bengal, India},
	abstract = {Reducing hateful and offensive content in online social media pose a dual problem for the moderators. On the one hand, rigid censorship on social media cannot be imposed. On the other, the freeow of such content cannot be allowed. Hence, we require efficient abusive language detection system to detect such harmful content in social media. In this paper, we present our machine learning model, HateMonitor, developed for Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) [20], a shared task at FIRE 2019. We have used Gradient Boosting model, along with BERT and LASER embeddings, to make the system language agnostic. Our model came at First position for the German sub-task A. We have also made our model public 1. © Copyright 2019 for this paper by its authors.},
	author_keywords = {BERT embeddings; Classification; Hate speech; LASER embeddings; Multilingual; Offensive language},
	keywords = {Classification (of information); Embeddings; Fires; Information retrieval; Content identifications; European languages; Gradient boosting; Language detection; Machine learning models; Multilingual; Offensive languages; Online social medias; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@CONFERENCE{Ramakrishnan2019806,
	author = {Ramakrishnan, Murugesan and Zadrozny, Wlodek and Tabari, Narges},
	title = {UVA Wahoos at SemEval-2019 task 6: Hate speech identification using ensemble machine learning},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {806 – 811},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076919825&partnerID=40&md5=b7ed61317fd7c1cc2f747a8f8f2833a9},
	affiliations = {Data Science Institute, University of Virginia, United States; UNC-Charlotte, United States},
	abstract = {With the growth in the usage of social media, it has become increasingly common for people to hide behind a mask and abuse others. We have attempted to detect such tweets and comments that are malicious in intent, which either targets an individual or a group. Our best classifier for identifying offensive tweets for SubTask A (Classifying offensive vs. non-offensive) has an accuracy of 83.14% and a f1-score of 0.7565 on the actual test data. For SubTask B, to identify if an offensive tweet is targeted (If targeted towards an individual or a group), the classifier performs with an accuracy of 89.17% and f1-score of 0.5885. The paper talks about how we generated linguistic and semantic features to build an ensemble machine learning model. By training with more extracts from different sources (Face-book, and more tweets), the paper shows how the accuracy changes with additional training data. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Machine learning; F1 scores; Linguistic features; Machine learning models; Semantic features; Social media; Speech identification; Subtask; Test data; Training data; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Lekea20181084,
	author = {Lekea, Ioanna K. and Karampelas, Panagiotis},
	title = {Detecting hate speech within the terrorist argument: A Greek case},
	year = {2018},
	journal = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018},
	pages = {1084 – 1091},
	doi = {10.1109/ASONAM.2018.8508270},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057304459&doi=10.1109%2fASONAM.2018.8508270&partnerID=40&md5=f35bedaf2386eb71e8b5a3389baf0324},
	affiliations = {Division of of Leadership Command, Human Sciences and Physiology, Hellenic Air Force Academy, Dekelia, Greece; Division of Informatics and Computer, Hellenic Air Force Academy, Dekelia, Greece},
	abstract = {This paper presents a methodology for automatically detecting the presence of hate speech within the terrorist argument. Hate speech can be used by a terrorist group as a means of judging possible targets' guilt and deciding on their punishment, as well as a means of making people to accept acts of terror or even as propaganda for possibly attracting new members. In this paper, we examine both ideology expressed and practices employed by the Revolutionary Organization 17 November (hereafter 17N) that operated in Greece between the years of 1975 and 2002. Within this line of thought, we will focus on the ideological justification, ethical standing and deployment of the terrorist operations as presented in the communiqués published by 17N, emphasizing on the use of hate speech as a means of justifying their choices and actions, as well as a way of reaching out to Greek people. To decide on how the automatic classification will be performed, we experimented with different text analyzing techniques such as critical discourse and content analysis and based on the preliminary results of these techniques a classification algorithm is proposed that can classify the communiqués in three categories depending on the presence of hate speech. The methodology was tested over the existing dataset with all the communiqués and the corresponding results are discussed. © 2018 IEEE.},
	author_keywords = {content analysis; critical discourse analysis; ethics; Greek terrorism; hate speech; ideology; tactics; targets},
	keywords = {Philosophical aspects; Speech; Targets; Terrorism; Text processing; Content analysis; Critical discourse analysis; ethics; ideology; tactics; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 10th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018; Conference date: 28 August 2018 through 31 August 2018; Conference code: 141485}
}

@CONFERENCE{Capozzi2019,
	author = {Capozzi, Arthur T.E. and Lai, Mirko and Basile, Valerio and Poletto, Fabio and Sanguinetti, Manuela and Bosco, Cristina and Patti, Viviana and Ruffo, Giancarlo and Musto, Cataldo and Polignano, Marco and Semeraro, Giovanni and Stranisci, Marco},
	title = {Computational linguistics against hate: Hate speech detection and visualization on social media in the “Contro L’Odio” project},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074835007&partnerID=40&md5=33f1b7fa6c44b60e72de73bbf7864ab8},
	affiliations = {University of Turin, Italy; University of Bari “Aldo Moro”, Italy; ACMOS, Italy},
	abstract = {The paper describes the Web platform built within the project “Contro l’odio”, for monitoring and contrasting discrimination and hate speech against immigrants in Italy. It applies a combination of computational linguistics techniques for hate speech detection and data visualization tools on data drawn from Twitter. It allows users to access a huge amount of information through interactive maps, also tuning their view, e.g., visualizing the most viral tweets and interactively reducing the inherent complexity of data. Educational courses for high school students and citizenship has been developed which are centered on the platform and focused on the deconstruction of negative stereotypes against immigrants, Roma, and religious minorities, and on the creation of positive narratives. Copyright © 2019 for this paper by its authors.},
	keywords = {Computational linguistics; Data visualization; Social networking (online); Visualization; Amount of information; Data visualization tools; High school students; Inherent complexity; Interactive maps; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 6th Italian Conference on Computational Linguistics, CLiC-it 2019; Conference date: 13 November 2019 through 15 November 2019; Conference code: 152977}
}

@CONFERENCE{Wiedemann2019782,
	author = {Wiedemann, Gregor and Ruppert, Eugen and Biemann, Chris},
	title = {UHH-LT at SemEval-2019 task 6: Supervised vs. Unsupervised transfer learning for offensive language detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {782 – 787},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097487128&partnerID=40&md5=beed5d01ffe4cf567e11cfafdb23101d},
	affiliations = {Language Technology Group, Base.Camp, Department of Informatics, University of Hamburg, Germany},
	abstract = {We present a neural network based approach of transfer learning for offensive language detection. For our system, we compare two types of knowledge transfer: supervised and unsupervised pre-training. Supervised pre-training of our bidirectional GRU-3-CNN architecture is performed as multi-task learning of parallel training of five different tasks. The selected tasks are supervised classification problems from public NLP resources with some overlap to offensive language such as sentiment detection, emoji classification, and aggressive language classification. Unsupervised transfer learning is performed with a thematic clustering of 40M unlabeled tweets via LDA. Based on this dataset, pre-training is performed by predicting the main topic of a tweet. Results indicate that unsupervised transfer from large datasets performs slightly better than supervised training on small 'near target category' datasets. In the SemEval Task, our system ranks 14 out of 103 participants. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Knowledge management; Semantics; Transfer learning; Clusterings; Language detection; Large datasets; Network-based approach; Neural-networks; Offensive languages; Parallel training; Pre-training; Supervised classification; Unsupervised transfer learning; Large dataset},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Kebriaei2019600,
	author = {Kebriaei, Emad and Karimi, Samaneh and Sabri, Nazanin and Shakery, Azadeh},
	title = {Emad at SemEval-2019 task 6: Offensive language identification using traditional machine learning and deep learning approaches},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {600 – 603},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093396867&partnerID=40&md5=59a2643ec6c832c99b55610c493ee340},
	affiliations = {School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Iran; School of Computer Science, Institute for Research in Fundamental Sciences (IPM)},
	abstract = {In this paper, the used methods and the results obtained by our team, entitled Emad, on the OffensEval 2019 shared task organized at SemEval 2019 are presented. The OffensEval shared task includes three sub-tasks namely Offensive language identification, Automatic categorization of offense types and Offense target identification. We participated in sub-task A and tried various methods including traditional machine learning methods, deep learning methods and also a combination of the first two sets of methods. We also proposed a data augmentation method using word embedding to improve the performance of our methods. The results show that the augmentation approach outperforms other methods in terms of macro-f1. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Crime; Deep learning; Semantics; Augmentation methods; Automatic categorization; Data augmentation; Language identification; Learning approach; Learning methods; Machine learning methods; Offensive languages; Subtask; Target's identifications; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Gertner2019453,
	author = {Gertner, Abigail S. and Henderson, John C. and Marsh, Amy and Merkhofer, Elizabeth M. and Wellner, Ben and Zarrella, Guido},
	title = {MITRE at SemEval-2019 task 5: Transfer learning for multilingual hate speech detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {453 – 459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092725730&partnerID=40&md5=f0ffd5dcdaae62e6cdf7e83df45e8e15},
	affiliations = {The MITRE Corporation, 202 Burlington Road, Bedford, 01730-1420, MA, United States},
	abstract = {This paper describes MITRE's participation in SemEval-2019 Task 5, HatEval: Multilingual detection of hate speech against immigrants and women in Twitter. The techniques explored range from simple bag-of-ngrams classifiers to neural architectures with varied attention mechanisms. We describe several styles of transfer learning from auxiliary tasks, including a novel method for adapting pre-trained BERT models to Twitter data. Logistic regression ties the systems together into an ensemble submitted for evaluation. The resulting system was used to produce predictions for all four HatEval subtasks, achieving the best mean rank of all teams that participated in all four conditions. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Social networking (online); Attention mechanisms; Condition; Mean-ranks; N-grams; Neural architectures; Novel methods; Simple++; Speech detection; Subtask; Transfer learning; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Rohmawati2018646,
	author = {Rohmawati, Umu Amanah Nur and Sihwi, Sari Widya and Cahyani, Denis Eka},
	title = {SEMAR: An interface for Indonesian hate speech detection using machine learning},
	year = {2018},
	journal = {2018 International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2018},
	pages = {646 – 651},
	doi = {10.1109/ISRITI.2018.8864484},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074209554&doi=10.1109%2fISRITI.2018.8864484&partnerID=40&md5=5dfca41069ecf58a84a070ca73c27019},
	affiliations = {Informatics Department FMIPA, Sebelas Maret University, Surakarta, Indonesia},
	abstract = {Hate Speech has become government and public's concern because of the high number of hate speech cases on social media that occur in Indonesia, which are getting increased in recent years. Because of that, Indonesian hate speech detection becomes crucial. This research proposes SEMAR, an engine to detect Indonesian hate speech built using machine learning technique. This study tested and compared popular supervised algorithms including Naive Bayes Classifier (NBC), Decision Tree (DT), K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Logistic Regression (LR) to determine which of the method is most suitable for solving Indonesian hate speech issue. It also compared two vectorizers, which are Hashing vectorizer and Term Frequency Inverse Document Frequency (TF-IDF). SEMAR interfaces were successfully developed, they are Application Programming Interface (API) and anti-hate comment WordPress plugin. SEMAR API was implemented using SVM with TF-IDF model, due to the highest accuracy with average score is (0.870726276). API allows web developer to use machine learning model by accessing endpoint URL from where the API is served and do not need training the model every time they use it, while WordPress is chosen because it is the most widely used Content Management System (CMS) for creating websites in the world (31,7%). Not only detecting hate comment automatically, but the system also designed to make training data continues to grow. It allows user to give feedback on prediction given by engine, feedback stored into database as new training data. The System will perform self-training daily using both old and new training data so the model's performance will improve time by time. © 2018 IEEE.},
	author_keywords = {API; Hate speech; Machine Learning; Plugin; SEMAR},
	keywords = {Application programming interfaces (API); Classifiers; Decision trees; Engines; Intelligent systems; Learning systems; Machine learning; Nearest neighbor search; Speech; Support vector machines; Text processing; Content management system; K nearest neighbor (KNN); Machine learning models; Machine learning techniques; Naive Bayes classifiers; Plug-ins; SEMAR; Term frequencyinverse document frequency (TF-IDF); Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 2018 International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2018; Conference date: 21 November 2018 through 22 November 2018; Conference code: 152781}
}

@CONFERENCE{Baruah2019229,
	author = {Baruah, Arup and Barbhuiya, Ferdous Ahmed and Dey, Kuntal},
	title = {IIITG-ADBU at HASOC 2019: Automated hate speech and offensive content detection in english and code-mixed Hindi text},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {229 – 236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076903908&partnerID=40&md5=f1393cebd374fe9ee91dea79f93d8d0d},
	affiliations = {Dept. of Comp. Sc. and Engg., IIIT Guwahati, India; IBM Research India, New Delhi, India},
	abstract = {This paper presents the results obtained by using Logistic Regression (LR), Support Vector Machine (SVM), bi-directional long short-term memory (BiLSTM) and Neural Network (NN) models for subtask A of the shared task \Hate Speech and Offensive Content Iden- tification in Indo-European Languages' (HASOC). This paper presents the results for English and code-mixed Hindi language. Embeddings from Language Models (ELMo), Glove and fastText embeddings, and TF-IDF features of character and word n-grams have been used to train the models. Our best models for Hindi and English language obtained F1 score of 81.05 and 74.62 respectively on the official run. The models obtained the 4th and 8th position in the official ranking. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Bi-directional Long Short-Term Memory; ELMo; FastText; Glove; Hate Speech; Logistic Regression; Support Vector Machine},
	keywords = {Bismuth compounds; Brain; Embeddings; Information retrieval; Long short-term memory; Regression analysis; Bi-directional; ELMo; FastText; Glove; Logistic regressions; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@ARTICLE{Uban2019688,
	author = {Uban, Ana-Sabina and Dinu, Liviu P.},
	title = {On Transfer Learning for Detecting Abusive Language Online},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11506 LNCS},
	pages = {688 – 700},
	doi = {10.1007/978-3-030-20521-8_57},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067445781&doi=10.1007%2f978-3-030-20521-8_57&partnerID=40&md5=3b02dd3d9f942f3e121cd57451368878},
	affiliations = {Faculty of Mathematics and Computer Science, University of Bucharest, Bucharest, Romania; Human Language Technologies Research Center, University of Bucharest, Bucharest, Romania},
	abstract = {Abusive language online has become a growing social issue in our age of social media. Given the massive amounts of data being generated daily on social platforms, manually detecting and regulating such behavior has become unfeasible, so automatic solutions are necessary, and tasks related to identifying abusive language, in its various forms, from hate speech to bullying, have come into the focus of the natural language processing research community. In this paper, we focus on two subtypes of abusive language: aggressive language and offensive language, for which we implement a deep learning model based on convolutional neural networks. We further propose a new approach using transfer learning to boost performance of abusive language detection by leveraging data annotated with a different type of label, related to sentiment. We show how transferring knowledge between these tasks affects performance of detecting abusive language, offering insights into how these tasks are related, and how the more traditional task of sentiment analysis can be leveraged to help with solving the newer and less data rich task of abusive language detection. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Abusive language; Convolutional neural network; Deep learning; Sentiment analysis; Transfer learning; Tweet},
	keywords = {Convolution; Data mining; E-learning; Knowledge management; Neural networks; Sentiment analysis; Abusive language; Convolutional neural network; Language detection; NAtural language processing; Offensive languages; Research communities; Transfer learning; Tweet; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 15th International Work-Conference on Artificial Neural Networks, IWANN 2019; Conference date: 12 June 2019 through 14 June 2019; Conference code: 226879}
}

@CONFERENCE{Plaza-Del-Arco2019476,
	author = {Plaza-Del-Arco, Flor Miriam and Molina-González, M. Dolores and Martín-Valdivia, M. Teresa and Ureña-López, L. Alfonso},
	title = {SINAI at SemEval-2019 task 5: Ensemble learning to detect hate speech against inmigrants and women in English and Spanish tweets},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {476 – 479},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097501554&partnerID=40&md5=d3ff2d563a3097d43942e3ccf0248fa7},
	affiliations = {Department of Computer Science, Advanced Studies Center in ICT (CEATIC), Universidad de Jaén, Campus Las Lagunillas, Jaén, 23071, Spain},
	abstract = {Misogyny and xenophobia are some of the most important social problems. With the increase in the use of social media, this feeling of hatred towards women and immigrants can be more easily expressed, therefore it can cause harmful effects on social media users. For this reason, it is important to develop systems capable of detecting hateful comments automatically. In this paper, we describe our system to analyze the hate speech in English and Spanish tweets against Immigrants and Women as part of our participation in SemEval-2019 Task 5: hatEval. Our main contribution is the integration of three individual algorithms of prediction in a model based on Vote ensemble classifier. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Semantics; Speech recognition; Ensemble learning; Ensemble-classifier; Harmful effects; Model-based OPC; Social media; Social problems; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Garain2019759,
	author = {Garain, Avishek and Basu, Arpan},
	title = {The Titans at SemEval-2019 task 6: Offensive language identification, categorization and target identification},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {759 – 762},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097494953&partnerID=40&md5=7ccb795fb786142432488bec5f2923cc},
	affiliations = {Computer Science and Engineering, Jadavpur University, Kolkata, India},
	abstract = {This system paper is a description of the system submitted to “SemEval-2019 Task 6”, where we had to detect offensive language in Twitter. There were two specific target audiences, immigrants and women. The language of the tweets was English. We were required to first detect whether a tweet contains offensive content, and then we had to find out whether the tweet was targeted against some individual, group or other entity. Finally we were required to classify the targeted audience. © 2019 Association for Computational Linguistics},
	keywords = {Language identification; Offensive languages; Target audience; Target's identifications; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Wang2019529,
	author = {Wang, Bin and Ding, Haiyan},
	title = {YNU NLP at SemEval-2019 task 5: Attention and capsule ensemble for identifying hate speech},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {529 – 534},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097508221&partnerID=40&md5=a3f5eade62e6d6bfc414c6470f187c51},
	affiliations = {School of Information Science and Engineering, Yunnan University, Yunnan, China},
	abstract = {This paper describes the system submitted to SemEval 2019 Task 5: Multilingual detection of hate speech against immigrants and women in Twitter (hatEval). Its main purpose is to conduct hate speech detection on Twitter, which mainly includes two specific different targets, immigrants and women. We participate in both subtask A and subtask B for English. In order to address this task, we develope an ensemble of an attention-LSTM model based on HAN and a BiGRU-capsule model. Both models use fastText pre-trained embeddings, and we use this model in both subtasks. In comparison to other participating teams, our system is ranked 16th in the Subtask A for English, and 12th in the Subtask B for English. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Social networking (online); Speech recognition; Embeddings; Model use; Model-based OPC; Participating teams; Speech detection; Subtask; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@CONFERENCE{Vega2019447,
	author = {Vega, Luis Enrique Argota and Reyes-Magaña, Jorge and Gómez-Adorno, Helena and Bel-Enguix, Gemma},
	title = {MineriaUNAM at SemEval-2019 task 5: Detecting hate speech in Twitter using multiple features in a combinatorial framework},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {447 – 452},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097495804&partnerID=40&md5=b6e00ad8ef799b23ea3d97de851191dc},
	affiliations = {Posgrado en Ciencia e Ingeniería de la Computación, Universidad Nacional Autónoma de México, Ciudad de México, Mexico; Facultad de Matemáticas, Universidad Autónoma de Yucatán, Mérida, Yucatán, Mexico; Universidad Nacional Autónoma de México, Ciudad de México, Mexico; Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas, Universidad Nacional Autónoma de México, Ciudad de México, Mexico; Grupo de Ingeniería Lingüística, Instituto de Ingeniería, Universidad Nacional Autónoma de México, Ciudad de México, Mexico},
	abstract = {This paper presents our approach to the Task 5 of Semeval-2019, which aims at detecting hate speech against immigrants and women in Twitter. The task consists of two subtasks, in Spanish and English: (A) detection of hate speech and (B) classification of hateful tweets as aggressive or not, and identification of the target harassed as individual or group. We used linguistically motivated features and several types of n-grams (words, characters, functional words, punctuation symbols, POS, among others). For task A, we trained a Support Vector Machine using a combinatorial framework, whereas for task B we followed a multi-labeled approach using the Random Forest classifier. Our approach achieved the highest F1-score in sub-task A for the Spanish language. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Decision trees; Semantics; Speech recognition; Support vector machines; F1 scores; Functional word; Multiple features; N-grams; Random forest classifier; Spanish language; Subtask; Support vectors machine; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}

@ARTICLE{Pitsilis20184730,
	author = {Pitsilis, Georgios K. and Ramampiaro, Heri and Langseth, Helge},
	title = {Effective hate-speech detection in Twitter data using recurrent neural networks},
	year = {2018},
	journal = {Applied Intelligence},
	volume = {48},
	number = {12},
	pages = {4730 – 4742},
	doi = {10.1007/s10489-018-1242-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050686216&doi=10.1007%2fs10489-018-1242-y&partnerID=40&md5=ffe49268af1d6b3969852a2bfaa42e8c},
	affiliations = {Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, NO-7491, Norway},
	abstract = {This paper addresses the important problem of discerning hateful content in social media. We propose a detection scheme that is an ensemble of Recurrent Neural Network (RNN) classifiers, and it incorporates various features associated with user-related information, such as the users’ tendency towards racism or sexism. This data is fed as input to the above classifiers along with the word frequency vectors derived from the textual content. We evaluate our approach on a publicly available corpus of 16k tweets, and the results demonstrate its effectiveness in comparison to existing state-of-the-art solutions. More specifically, our scheme can successfully distinguish racism and sexism messages from normal text, and achieve higher classification quality than current state-of-the-art algorithms. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Deep learning; Hate-speech; Micro-blogging; Recurrent neural networks; Text classification; Twitter},
	keywords = {Classification (of information); Deep learning; Social networking (online); Text processing; Classification quality; Micro blogging; Recurrent neural network (RNN); Speech detection; State-of-the-art algorithms; Text classification; Twitter; Word frequencies; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 190; All Open Access, Green Open Access}
}

@ARTICLE{Nova201985,
	author = {Nova, David and Ferreira, André and Cortez, Paulo},
	title = {A Machine Learning Approach to Detect Violent Behaviour from Video},
	year = {2019},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {273},
	pages = {85 – 94},
	doi = {10.1007/978-3-030-16447-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065039355&doi=10.1007%2f978-3-030-16447-8_9&partnerID=40&md5=ebbbf249c2ee403304df3246ded165ab},
	affiliations = {ALGORITMI Centre, Department of Information Systems, University of Minho, Guimarães, 4804-533, Portugal; Department of Informatics, University of Minho, Braga, 4710-057, Portugal},
	abstract = {The automatic classification of violent actions performed by two or more persons is an important task for both societal and scientific purposes. In this paper, we propose a machine learning approach, based a Support Vector Machine (SVM), to detect if a human action, captured on a video, is or not violent. Using a pose estimation algorithm, we focus mostly on feature engineering, to generate the SVM inputs. In particular, we hand-engineered a set of input features based on keypoints (angles, velocity and contact detection) and used them, under distinct combinations, to study their effect on violent behavior recognition from video. Overall, an excellent classification was achieved by the best performing SVM model, which used keypoints, angles and contact features computed over a 60 frame image input range. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2019.},
	author_keywords = {Action recognition; Machine learning; Pose estimation; Support Vector Machine; Video analysis},
	keywords = {Learning systems; Machine learning; Support vector machines; Action recognition; Automatic classification; Contact detection; Feature engineerings; Machine learning approaches; Pose estimation; Pose estimation algorithm; Video analysis; Behavioral research},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 10th International Conference on Intelligent Technologies for Interactive Entertainment, INTETAIN 2018; Conference date: 21 November 2018 through 23 November 2018; Conference code: 225079}
}

@CONFERENCE{Goel2019796,
	author = {Goel, Bharti and Sharma, Ravi},
	title = {USF at SemEval-2019 task 6: Offensive language detection using LSTM with word embeddings},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {796 – 800},
	doi = {10.18653/v1/s19-2139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093369663&doi=10.18653%2fv1%2fs19-2139&partnerID=40&md5=cf0440e0a4e60b9972e0bb8ea4be984d},
	affiliations = {Department of Computer Science and Engineering, University of South Florida, United States},
	abstract = {In this paper, we present a system description for the SemEval-2019 Task 6 submitted by our team. For the task, our system takes tweet as an input and determine if the tweet is offensive or non-offensive (Sub-task A). In case a tweet is offensive, our system identifies if a tweet is targeted (insult or threat) or non-targeted like swearing (Sub-task B). In targeted tweets, our system identifies the target as an individual or group (Sub-task C). We used data pre-processing techniques like splitting hashtags into words, removing special characters, stop-word removal, stemming, lemmatization, capitalization, and offensive word dictionary. Later, we used keras tokenizer and word embeddings for feature extraction. For classification, we used the LSTM (Long short-term memory) model of keras framework. Our accuracy scores for Sub-task A, B and C are 0.8128, 0.8167 and 0.3662 respectively. Our results indicate that fine-grained classification to identify offense target was difficult for the system. Lastly, in the future scope section, we will discuss the ways to improve system performance. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Data handling; Embeddings; Semantics; Data preprocessing; Embeddings; Language detection; Non-targeted; Offensive languages; Pre-processing techniques; Splittings; Subtask; System description; System identify; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kim2019,
	author = {Kim, Kwangsoo and Kim, Ungtae and Kwak, Sooyeong},
	title = {Real-time detection of violent behaviors with amotion descriptor},
	year = {2019},
	journal = {Journal of Imaging Science and Technology},
	volume = {63},
	number = {2},
	doi = {10.2352/J.ImagingSci.Technol.2019.63.2.020505},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074156234&doi=10.2352%2fJ.ImagingSci.Technol.2019.63.2.020505&partnerID=40&md5=bf1319718502539375bfcb620967f99b},
	affiliations = {Hanbat National University, Department of Electronics and Control Engineering, Dongseodaero 125, Yuseong-gu, Daejeon, 34158, South Korea; Eintelligence, Hoam-ro 51, Buk-gu, Daegu, 41585, South Korea},
	abstract = {A real-time violent behavior detection algorithm based on a new descriptor is proposed. This descriptor reflects a common observation that the changes in both the magnitude and direction of movement in violent images are more abrupt than non-violent ones. During several frames, descriptor feature vectors consisting of descriptor values are generated, and they are inputs to the Support Vector Machine (SVM) classifier for discriminating violent actions from non-violent actions. Comparison experiments among the Motion Binary Pattern (MBP), the Violent Flow (ViF) and the proposed algorithm were conducted with three different types of datasets. In all datasets, the proposed algorithm was above 80% in the F-measure and outperformed the other methods in every case. © 2019 Society for Imaging Science and Technology.},
	keywords = {Signal detection; Binary patterns; Descriptors; F measure; Feature vectors; Real time; Real-time detection; Violent behavior; Support vector machines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Lu2019221,
	author = {Lu, Zhibin and Nie, Jian-Yun},
	title = {RALIGRAPH at HASOC 2019: VGCN-BERT: Augmenting BERT with graph embedding for offensive language detection},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2517},
	pages = {221 – 228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076904689&partnerID=40&md5=cdb76207ce829969045dbf62c54160ea},
	affiliations = {University of Montreal, Canada},
	abstract = {Hate speech and offensive language detection are receiving more and more attention in recent years. The RALIGRAPH team participated in the Shared Task on the Identification of Offensive content for Indo-European languages within the FIRE conference. This paper describes our approach VGCN-BERT model for all three sub-tasks of hate language and offensive language detection in English. VGCN-BERT takes into account both local and global information, by combining the Graph Convolutional Networks (GCN) and the Self-Attention Encoder (BERT). Our approach produced good results in the experiments. © Copyright 2019 for this paper by its authors.},
	author_keywords = {Graph Convolutional Networks; Graph Embedding; Offensive Language Detection; Self-Attention Encoder},
	keywords = {Convolution; Embeddings; Information retrieval; Signal encoding; Convolutional networks; European languages; Global informations; Graph embeddings; Offensive languages; Self-Attention Encoder; Subtasks; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 11th Forum for Information Retrieval Evaluation, FIRE 2019; Conference date: 12 December 2019 through 15 December 2019; Conference code: 155705}
}

@ARTICLE{Hosam2019219,
	author = {Hosam, Osama},
	title = {Toxic comments identification in arabic social media},
	year = {2019},
	journal = {International Journal of Computer Information Systems and Industrial Management Applications},
	volume = {11},
	pages = {219 – 226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083278653&partnerID=40&md5=c18fe6f044c3e10271d331660509ba05},
	affiliations = {The collage of computer science and engineering in Yanbu, Tiabah University, Saudi Arabia; As with SRTA-City, IRI institute, Alexandria, Egypt},
	abstract = {The usage of social media increases day by day. Both individuals and organizations use social media for different purposes. Problems increase in association with social media technologies. Toxic comments bots create a negative impression about people, companies and products. These kinds of toxic comment bots are created by the attackers. This research work is carried out to identify these toxic comments in Arabic social media. For that, Machine learning techniques are used. Mainly gradient boosting technique (XGBoost algorithm) has been utilized to effectively identify the comments created by the toxic comment bots. XGBoost can efficiently divide toxic comments into the following categories, toxic, severe toxic, obscene, threat, insult, and identity hate. The accuracy achieved by the proposed method is 99.54 %. © 2019 MIR Labs.},
	author_keywords = {Adaboost; Classification; Clustering; Machine learning; Malware detection; XGBoost},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Liebeskind2018,
	author = {Liebeskind, Chaya and Liebeskind, Shmuel},
	title = {Identifying Abusive Comments in Hebrew Facebook},
	year = {2018},
	journal = {2018 IEEE International Conference on the Science of Electrical Engineering in Israel, ICSEE 2018},
	doi = {10.1109/ICSEE.2018.8646190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063144098&doi=10.1109%2fICSEE.2018.8646190&partnerID=40&md5=1639aedcce6c3c0b004c800277ef721b},
	affiliations = {Department of Computer Science, Jerusalem College of Technology, Jerusalem, Israel},
	abstract = {In this study, we aim to classify comments as abusive or non-Abusive. We develop a Hebrew corpus of user comments annotated for abusive language. Then, we investigate highly sparse n-grams representations as well as denser character n-grams representations for comment abuse classification. Since the comments in social media are usually short, we also investigate four dimension reduction methods, which produce word vectors that collapse similar words into groups. We show that the character n-grams representations outperform all the other representation for the task of identifying abusive comments. © 2018 IEEE.},
	author_keywords = {abusive comments; dimension reduction; n-grams; n-grams characters; semantic analysis; word embedding},
	keywords = {Computational linguistics; Social networking (online); Abusive comment; Dimension reduction; Embeddings; Facebook; N-gram character; N-grams; Semantic analysis; Social media; Word embedding; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2018 IEEE International Conference on the Science of Electrical Engineering in Israel, ICSEE 2018; Conference date: 12 December 2018 through 14 December 2018; Conference code: 145540}
}

@CONFERENCE{Ameer2019382,
	author = {Ameer, Iqra and Siddiqui, Muhammad Hammad Fahim and Sidorov, Grigori and Gelbukh, Alexander},
	title = {CIC at SemEval-2019 task 5: Simple yet very efficient approach to hate speech detection, aggressive behavior detection, and target classification in Twitter},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {382 – 386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092907687&partnerID=40&md5=d50f7a965ea3b44ae685c7fc87abfda1},
	affiliations = {Instituto Politécnico Nacional (IPN), Center for Computing Research (CIC), Av. Juan Dios Batiz, s/n, Zacatenco, Mexico City, 07738, Mexico},
	abstract = {In recent years, the use of social media has increased incredibly. Social media permits Inter-net users a friendly platform to express their views and opinions. Along with these nice and distinct communication chances, it also allows bad things like usage of hate speech. Online automatic hate speech detection in various aspects is a significant scientific problem. This paper presents the Instituto Politécnico Nacional (Mexico) approach for the Semeval 2019 Task-5 [Hateval 2019] (Basile et al., 2019) competition for Multilingual Detection of Hate Speech on Twitter. The goal of this paper is to detect (A) Hate speech against immigrants and women, (B) Aggressive behavior and target classification, both for English and Spanish. In the proposed approach, we used a bag of words model with preprocessing (stemming and stop words removal). We submitted two different systems with names: (i) CIC-1 and (ii) CIC-2 for Hateval 2019 shared task. We used TF values in the first system and TF-IDF for the second system. The first system, CIC-1 got 2nd rank in subtask B for both English and Spanish languages with EMR score of 0.568 for English and 0.675 for Spanish. The second system, CIC-2 was ranked 4th in subtask A and 1st in subtask B for Spanish language with a macro-F1 score of 0.727 and EMR score of 0.705 respectively. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Information retrieval; Natural language processing systems; Semantics; Speech; Speech communication; Speech recognition; Behavior detection; Behaviour classification; First systems; Me-xico; Simple++; Social media; Spanish language; Speech detection; Subtask; Target Classification; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737}
}@CONFERENCE{Sahlgren2018115,
	author = {Sahlgren, Magnus and Isbister, Tim and Olsson, Fredrik},
	title = {Learning Representations for Detecting Abusive Language},
	year = {2018},
	journal = {2nd Workshop on Abusive Language Online - Proceedings of the Workshop, co-located with EMNLP 2018},
	pages = {115 – 123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121995633&partnerID=40&md5=cf43ee0c0524054e80b1faff77619ba4},
	affiliations = {RISE AI, FOI, Box 1263, Kista, 164 29, Sweden; FOI, Stockholm, 164 90, Sweden},
	abstract = {This paper discusses the question whether it is possible to learn a generic representation that is useful for detecting various types of abusive language. The approach is inspired by recent advances in transfer learning and word embeddings, and we learn representations from two different datasets containing various degrees of abusive language. We compare the learned representation with two standard approaches; one based on lexica, and one based on data-specific n-grams. Our experiments show that learned representations do contain useful information that can be used to improve detection performance when training data is limited. © 2018 Association for Computational Linguistics},
	keywords = {Detection performance; Embeddings; Generic representation; Learn+; N-grams; Training data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 2nd Workshop on Abusive Language Online, ALW 2018, co-located with EMNLP 2018; Conference date: 31 October 2018; Conference code: 173717}
}

@CONFERENCE{Bai2018,
	author = {Bai, Xiaoyu and Merenda, Flavio and Zaghi, Claudia and Caselli, Tommaso and Nissim, Malvina},
	title = {Rug @ Evalita 2018: Hate speech detection in Italian social media},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	doi = {10.4000/books.aaccademia.4824},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212614047&doi=10.4000%2fbooks.aaccademia.4824&partnerID=40&md5=b987da7e8ee39a8b1216f22d3ebb7027},
	affiliations = {Rikjuniversiteit Groningen, Groningen, Netherlands; Università degli Studi di Salerno, Salerno, Italy},
	abstract = {We describe the systems the RuG Team developed in the context of the Hate Speech Detection Task in Italian Social Media at EVALITA 2018. We submitted a total of eight runs, participating in all four subtasks. The best macro-F1 score in all subtasks was obtained by a Linear SVM, using hate-rich embeddings. Our best system obtains competitive results, by ranking 6th (out of 14) in HaSpeeDe-FB, 3rd (out of 15) in HaSpeeDe-TW, 8th (out of 13) in Cross-HaSpeeDe FB, and 6th (out of 13) in Cross-HaSpeeDe TW. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Computational linguistics; Embeddings; Natural language processing systems; Speech recognition; Detection tasks; Embeddings; F1 scores; Linear SVM; Social media; Speech detection; Subtask; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Razavi201016,
	author = {Razavi, Amir H. and Inkpen, Diana and Uritsky, Sasha and Matwin, Stan},
	title = {Offensive language detection using multi-level classification},
	year = {2010},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {6085 LNAI},
	pages = {16 – 27},
	doi = {10.1007/978-3-642-13059-5_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953734118&doi=10.1007%2f978-3-642-13059-5_5&partnerID=40&md5=f6db6b7107994b16dcb0fb1f2bbf82fb},
	affiliations = {School of Information Technology and Engineering (SITE), University of Ottawa, Ottawa, ON K1N 6N5, Canada; Natural Semantic Modules co., Toronto, ON M2M 4A7, 5 Tangreen Court, Canada; Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland},
	abstract = {Text messaging through the Internet or cellular phones has become a major medium of personal and commercial communication. In the same time, flames (such as rants, taunts, and squalid phrases) are offensive/abusive phrases which might attack or offend the users for a variety of reasons. An automatic discriminative software with a sensitivity parameter for flame or abusive language detection would be a useful tool. Although a human could recognize these sorts of useless annoying texts among the useful ones, it is not an easy task for computer programs. In this paper, we describe an automatic flame detection method which extracts features at different conceptual levels and applies multi-level classification for flame detection. While the system is taking advantage of a variety of statistical models and rule-based patterns, there is an auxiliary weighted pattern repository which improves accuracy by matching the text to its graded entries. © 2010 Springer-Verlag Berlin Heidelberg.},
	author_keywords = {Filtering; Flame detection; Information extraction; Information retrieval; Multi-level classification; Offensive language detection},
	keywords = {Artificial intelligence; Information retrieval; Linguistics; Cellular Phone; Commercial communication; Computer program; Conceptual levels; Flame detection; Information Extraction; Language detection; Multi-level; Offensive languages; Pattern repository; Rule based; Sensitivity parameters; Statistical models; Text messaging; Flammability},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 181; Conference name: 23rd Canadian Conference on Artificial Intelligence, Canadian AI 2010; Conference date: 31 May 2010 through 2 June 2010; Conference code: 80650}
}

@CONFERENCE{Acar201373,
	author = {Acar, Esra and Hopfgartner, Frank and Albayrak, Sahin},
	title = {Detecting violent content in Hollywood movies by mid-level audio representations},
	year = {2013},
	journal = {Proceedings - International Workshop on Content-Based Multimedia Indexing},
	pages = {73 – 78},
	doi = {10.1109/CBMI.2013.6576556},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883419695&doi=10.1109%2fCBMI.2013.6576556&partnerID=40&md5=6dbb49237a81f8115c868692913c0ade},
	affiliations = {DAI Laboratory, Technische Universität Berlin, 10587 Berlin, Ernst-Reuter-Platz 7, TEL 14, Germany},
	abstract = {Movie violent content detection e.g., for providing automated youth protection services is a valuable video content analysis functionality. Choosing discriminative features for the representation of video segments is a key issue in designing violence detection algorithms. In this paper, we employ mid-level audio features which are based on a Bag-of-Audio Words (BoAW) method using Mel-Frequency Cepstral Coefficients (MFCCs). BoAW representations are constructed with two different methods, namely the vector quantization-based (VQ-based) method and the sparse coding-based (SC-based) method. We choose two-class support vector machines (SVMs) for classifying video shots as (non-)violent. Our experiments on detecting violent video shots in Hollywood movies show that the mid-level audio features provide promising results. Additionally, we establish that the SC-based method outperforms the VQ-based one. More importantly, the SC-based method outperforms the unimodal submissions in the MediaEval Violent Scenes Detection (VSD) task, except one vision-based method in terms of average precision. © 2013 IEEE.},
	keywords = {Indexing (of information); Support vector machines; Vector quantization; Video signal processing; Audio representation; Content detection; Discriminative features; Mel-frequency cepstral coefficients; Two-class support vector machines; Video-content analysis; Violence detections; Vision-based methods; Motion pictures},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 2013 11th International Workshop on Content-Based Multimedia Indexing, CBMI 2013; Conference date: 17 June 2013 through 19 June 2013; Conference code: 99030}
}

@CONFERENCE{Park20182799,
	author = {Park, Ji Ho and Shin, Jamin and Fung, Pascale},
	title = {Reducing gender bias in abusive language detection},
	year = {2018},
	journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
	pages = {2799 – 2804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081743005&partnerID=40&md5=677523ad526eee71c5b0d5b5d93e7465},
	affiliations = {Centre for Artificial Intelligence Research (CAiRE), Hong Kong University of Science and Technology, Hong Kong},
	abstract = {Abusive language detection models tend to have a problem of being biased toward identity words of a certain group of people because of imbalanced training datasets. For example, “You are a good woman” was considered “sexist” when trained on an existing dataset. Such model bias is an obstacle for models to be robust enough for practical use. In this work, we measure gender biases on models trained with different abusive language datasets, while analyzing the effect of different pre-trained word embeddings and model architectures. We also experiment with three bias mitigation methods: (1) debiased word embeddings, (2) gender swap data augmentation, and (3) fine-tuning with a larger corpus. These methods can effectively reduce gender bias by 90-98% and can be extended to correct model bias in other scenarios. © 2018 Association for Computational Linguistics},
	keywords = {Embeddings; Correct models; Data augmentation; Fine tuning; Language detection; Mitigation methods; Model architecture; Practical use; Training data sets; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 191; Conference name: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; Conference date: 31 October 2018 through 4 November 2018; Conference code: 158085}
}

@CONFERENCE{Olteanu2017405,
	author = {Olteanu, Alexandra and Talamadupula, Kartik and Varshney, Kush R.},
	title = {The limits of abstract evaluation metrics: The case of hate speech detection},
	year = {2017},
	journal = {WebSci 2017 - Proceedings of the 2017 ACM Web Science Conference},
	pages = {405 – 406},
	doi = {10.1145/3091478.3098871},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026782700&doi=10.1145%2f3091478.3098871&partnerID=40&md5=38fbb9d4f5a03438fea79c90b2f662a3},
	affiliations = {IBM Research, United States},
	abstract = {Wagstaff (2012) draws attention to the pervasiveness of abstract evaluation metrics that explicitly ignore or remove problem specifics. While such metrics allow practitioners to compare numbers across application domains, they offer limited insight into the impact of algorithmic decisions on humans and their perception of the algorithm's correctness. Even for problems that are mathematically the same, both the real-cost of (mathematically) identical errors, as well as their perceived-cost by users, may significantly vary according to the specifics of each problem domain, as well as of the user perceiving the result. While the real-cost of errors has been considered previously, little attention has been paid to the perceived-cost issue. We advocate for the inclusion of human-centered metrics that elicit error costs from humans from two perspectives: the nature of the error, and the user context. Focusing on hate speech detection on social media, we demonstrate that even when fixing the performance as measured by an abstract metric such as precision, user perception of correctness varies greatly depending on the nature of errors and user characteristics. © 2017 Copyright held by the owner/author(s).},
	author_keywords = {Evaluation metrics; Hate speech; Human-centered metrics},
	keywords = {Costs; Errors; Evaluation metrics; Human-centered metrics; Perceived costs; Problem domain; Speech detection; User characteristics; User context; User perceptions; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 9th ACM Web Science Conference, WebSci 2017; Conference date: 25 June 2017 through 28 June 2017; Conference code: 128765}
}

@CONFERENCE{Köffer201883,
	author = {Köffer, Sebastian and Riehle, Dennis M. and Höhenberger, Steffen and Becker, Jörg},
	title = {Discussing the value of automatic hate speech detection in online debates},
	year = {2018},
	journal = {MKWI 2018 - Multikonferenz Wirtschaftsinformatik},
	volume = {2018-March},
	pages = {83 – 94},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048566074&partnerID=40&md5=284bc6e4fef35ca57b3d07d20c8beee5},
	affiliations = {University of Münster, European Research Center for Information Systems, Münster, Germany},
	abstract = {This study discusses the potential value of automatic analytics of German texts to detect hate speech. In the course of a preliminary study, we collected a dataset of user comments on news articles, focused on the refugee crisis in 2015/16. A crowdsourcing approach was used to label a subset of the data as hateful and non-hateful to be used as training and evaluation data. Furthermore, a vocabulary was created containing the words that are indicating hate and no hate. The best performing combination of feature groups was a Word2Vec approach and Extended 2-grams. Our study builds upon previous research for English texts and demonstrates its transferability to German. The paper discusses the results with respect to the potential for media organizations and considerations about moderation techniques and algorithmic transparency. © 2018 Universitatsverlag Gottingen. All rights reserved.},
	author_keywords = {Hate Speech; Natural Language Processing (NLP); Text Analytics},
	keywords = {Natural language processing systems; Feature groups; News articles; Potential values; Speech detection; Text analytics; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; Conference name: Multikonferenz Wirtschaftsinformatik, MKWI 2018 - Multiconference on Business Informatics, MKWI 2018; Conference date: 6 March 2018 through 9 March 2018; Conference code: 135376}
}

@CONFERENCE{Bianchini2018,
	author = {Bianchini, Giulio and Ferri, Lorenzo and Giorni, Tommaso},
	title = {Text analysis for hate speech detection in Italian messages on Twitter and Facebook},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	doi = {10.4000/books.aaccademia.4832},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212605214&doi=10.4000%2fbooks.aaccademia.4832&partnerID=40&md5=3aa5cd9978ffd4748e7def6779f1c051},
	affiliations = {University of Perugia, Italy},
	abstract = {In this paper, we present a system able to classify hate speeches in Italian messages from Facebook and Twitter platforms. The system combines several typical techniques from Natural Language Processing with a classifier based on Artificial Neural Networks. It has been trained and tested on a corpus of 3000 messages from the Twitter platform and 3000 messages from the Facebook platform. The system has been submitted to the HaSpeeDe task within the EVALITA 2018 competition and the experimental results obtained in the evaluation phase of the competition are presented and discussed. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Computational linguistics; Neural networks; Social networking (online); Speech recognition; Evaluation phase; Facebook; Language processing; Natural languages; Speech detection; Text analysis; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Lee2018101,
	author = {Lee, Younghun and Yoon, Seunghyun and Jung, Kyomin},
	title = {Comparative Studies of Detecting Abusive Language on Twitter},
	year = {2018},
	journal = {2nd Workshop on Abusive Language Online - Proceedings of the Workshop, co-located with EMNLP 2018},
	pages = {101 – 106},
	doi = {10.18653/v1/w18-5113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087011227&doi=10.18653%2fv1%2fw18-5113&partnerID=40&md5=33613757be7ccb5a2b243996db64094a},
	affiliations = {Dept. of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea},
	abstract = {The context-dependent nature of online aggression makes annotating large collections of data extremely difficult. Previously studied datasets in abusive language detection have been insufficient in size to efficiently train deep learning models. Recently, Hate and Abusive Speech on Twitter, a dataset much greater in size and reliability, has been released. However, this dataset has not been comprehensively studied to its potential. In this paper, we conduct the first comparative study of various learning models on Hate and Abusive Speech on Twitter, and discuss the possibility of using additional features and context data for improvements. Experimental results show that bidirectional GRU networks trained on word-level features, with Latent Topic Clustering modules, is the most accurate model scoring 0.805 F1. © 2018 Association for Computational Linguistics},
	keywords = {Computational linguistics; Deep learning; Accurate modeling; Comparatives studies; Context data; Context dependent; Feature data; Language detection; Learning models; Online aggressions; Topic clustering; Word level; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; Conference name: 2nd Workshop on Abusive Language Online, ALW 2018, co-located with EMNLP 2018; Conference date: 31 October 2018; Conference code: 173717; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Chandrasekharan20173175,
	author = {Chandrasekharan, Eshwar and Samory, Mattia and Srinivasan, Anirudh and Gilbert, Eric},
	title = {The bag of communities: Identifying abusive behavior online with preexisting internet data},
	year = {2017},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	volume = {2017-May},
	pages = {3175 – 3187},
	doi = {10.1145/3025453.3026018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029490388&doi=10.1145%2f3025453.3026018&partnerID=40&md5=358478da3a537a81e63d7df1201fd03e},
	affiliations = {Georgia Institute of Technology, Atlanta, 30332, GA, United States; University of Padua, Padua, 35122, Italy},
	abstract = {Since its earliest days, harassment and abuse have plagued the Internet. Recent research has focused on in-domain methods to detect abusive content and faces several challenges, most notably the need to obtain large training corpora. In this paper, we introduce a novel computational approach to address this problem called Bag of Communities (BoC) - a technique that leverages large-scale, preexisting data from other Internet communities. We then apply BoC toward identifying abusive behavior within a major Internet community. Specifically, we compute a post's similarity to 9 other communities from 4chan, Reddit, Voat and MetaFilter. We show that a BoC model can be used on communities "off the shelf" with roughly 75% accuracy - no training examples are needed from the target community. A dynamic BoC model achieves 91.18% accuracy after seeing 100, 000 human-moderated posts, and uniformly outperforms in-domain methods. Using this conceptual and empirical work, we argue that the BoC approach may allow communities to deal with a range of common problems, like abusive behavior, faster and with fewer engineering resources. © 2017 ACM.},
	author_keywords = {Abusive behavior; Machine learning; Moderation; Online communities; Social computing},
	keywords = {Human engineering; Learning systems; Abusive behavior; Computational approach; Engineering resources; Internet communities; Moderation; On-line communities; Recent researches; Social computing; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 103; Conference name: 2017 ACM SIGCHI Conference on Human Factors in Computing Systems, CHI 2017; Conference date: 6 May 2017 through 11 May 2017; Conference code: 127654}
}

@ARTICLE{Kurniasih201862,
	author = {Kurniasih, Nuning and Abdillah, Leon Andretti and Ketut Sudarsana, I. and Wayan Lali Yogantara, I. and Nyoman Temon Astawa, I. and Nanuru, Ricardo Freedom and Miagina, Aveanty and Sabarua, Jefrey Oxianus and Jamil, Mohamad and Tandisalla, Johana and Duan, Electronita and Rupilele, Frits Gerit John and Utama, Mutiara Dara and Laisila, Maya and Ahmar, Ansari Saleh and Rahim, Robbi},
	title = {Prototype application hate speech detection website using string matching and searching algorithm},
	year = {2018},
	journal = {International Journal of Engineering and Technology(UAE)},
	volume = {7},
	number = {2.5 Special Issue  5},
	pages = {62 – 64},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067271029&partnerID=40&md5=3f3223099aae5145a400df79913ceeed},
	affiliations = {Faculty of Communication Science, Library and Information Science Program, Universitas Padjadjaran, Bandung, Indonesia; Department of Information System, Universitas Bina Darma, Palembang, Indonesia; Institut Hindu Dharma Negeri, Denpasar, Indonesia; Universitas Halmahera, Tobelo, Indonesia; Universitas Khairun, Ternate, Indonesia; Politeknik Perdamaian Halmahera, Tobelo, Indonesia; Universitas Victory Sorong, Sorong, Indonesia; Universitas Kristen Indonesia Maluku, Ambon, Indonesia; Department Statistics, Universitas Negeri Makassar, Makassar, Indonesia; School of Computer and Communication Engineering, Universiti Malaysia Perlis, Perlis, Malaysia},
	abstract = {Hate speech is now a problem for social media users such as Facebook, Twitter, Whatsapp and also Telegram. The current social media users are also a lot to post, share the content both consciously and unconsciously to various social media as well as even some hate speech postings are shared by irresponsible parties to gain profit from the chaos that he created, denigrating religion, vilify certain individuals even as an act of provocation. Prototype hate speech detection application created to detect hate speech on Facebook and it can give notification to users to be more aware of social media content and also careful in reading, share content that can trigger unpleasant actions. © 2018 Authors.},
	author_keywords = {Facebook social media; Hate speech detection; Prototype application},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Serrà201736,
	author = {Serrà, Joan and Stringhini, Gianluca and Leontiadis, Ilias and Blackburn, Jeremy and Spathis, Dimitris and Vakali, Athena},
	title = {Class-based prediction errors to detect hate speech with out-of-vocabulary words},
	year = {2017},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {36 – 40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121298655&partnerID=40&md5=674f4abe370591af265e71a6d6abb94b},
	affiliations = {Telefónica Research, Barcelona, Spain; University College London, United Kingdom; Aristotle University, Thessaloniki, Greece},
	abstract = {Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. A paradigmatic example of this situation is abusive online behavior, with social networks and media platforms struggling to effectively combat uncommon or non-blacklisted hate words. To better deal with these issues in those fast-paced environments, we propose using the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the ability to describe seen documents to the ability to predict unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%. © 2017 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Forecasting; Text processing; Class-based; Embeddings; Error signal; Media platforms; N-grams; Network platforms; Online behaviours; Outof-vocabulary words (OOV); Prediction errors; Text categorization; Errors},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 1st Workshop on Abusive Language Online, ALW 2017 at the 55th Annual Meeting of the Association for Computational Linguistic, ACL 2017 - Proceedings of the Workshop; Conference date: 4 August 2017; Conference code: 173144}
}

@CONFERENCE{Bohra201836,
	author = {Bohra, Aditya and Vijay, Deepanshu and Singh, Vinay and Akhtar, Syed S. and Shrivastava, Manish},
	title = {A dataset of Hindi-English code-mixed social media text for hate speech detection},
	year = {2018},
	journal = {Proceedings of the 2nd Workshop on Computational Modeling of PFople's Opinions, PersonaLity, and Emotions in Social Media, PEOPLES 2018 at the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HTL 2018},
	pages = {36 – 41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118842378&partnerID=40&md5=e1330a7b8c6a8077a914afa16368102b},
	affiliations = {International Institute of Information Technology, Telangana, Hyderabad, India},
	abstract = {Hate speech detection in social media texts is an important Natural language Processing task, which has several crucial applications like sentiment analysis, investigating cyber bullying and examining socio-political controversies. While relevant research has been done independently on code-mixed social media texts and hate speech detection, our work is the first attempt in detecting hate speech in Hindi-English code-mixed social media text. In this paper, we analyze the problem of hate speech detection in code-mixed texts and present a Hindi-English code-mixed dataset consisting of tweets posted online on Twitter. The tweets are annotated with the language at word level and the class they belong to (Hate Speech or Normal Speech). We also propose a supervised classification system for detecting hate speech in the text using various character level, word level, and lexicon based features. © 2018 Association for Computational Linguistics.},
	keywords = {Classification (of information); Codes (symbols); Computational linguistics; Sentiment analysis; Speech; Speech recognition; Character level; Classification system; Cyber bullying; Lexicon-based; Political controversies; Sentiment analysis; Social media; Speech detection; Supervised classification; Word level; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 193; Conference name: 2nd Workshop on Computational Modeling of PFople's Opinions, PersonaLity, and Emotions in Social Media, PEOPLES 2018 at the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HTL 2018; Conference date: 6 June 2018; Conference code: 173174}
}

@CONFERENCE{Van Den Broek2009,
	author = {Van Den Broek, Bert and Burghouts, Gertjan and Van Den Broek, Sebastiaan and Smith, Arthur and Hagen, Ronald and Anitori, Laura and Van Rossum, Wim},
	title = {Automatic detection of hostile behaviour},
	year = {2009},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {7480},
	doi = {10.1117/12.829468},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-71549163464&doi=10.1117%2f12.829468&partnerID=40&md5=b52878224bac247511ba42516112bb79},
	affiliations = {TNO Defence, Security and Safety, 2509 JG, The Hague, P.O. Box 96864, Netherlands},
	abstract = {In current military operations threats should be monitored accurately. The use of sensors is indispensable for this purpose, for example with camera and radar systems. Using data from such systems we have studied automated procedures for extracting observable behavioral features of persons and groups, which can be associated with threats. We have analysed algorithms for identifying animals versus humans, and for determining the activity of detected humans. Secondly, geospatial algorithms are studied to determine people in suspicious places. © 2009 Copyright SPIE - The International Society for Optical Engineering.},
	author_keywords = {Hostile behaviour; Sensor fusion; Target recognition},
	keywords = {Animals; Feature extraction; Fluorine containing polymers; Military operations; Radar systems; Automated procedures; Automatic Detection; Behavioral features; Geo-spatial; Sensor fusion; Sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Unmanned/Unattended Sensors and Sensor Networks VI Conference; Conference date: 1 September 2009 through 3 September 2009; Conference code: 78790}
}

@CONFERENCE{Alfina2017233,
	author = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},
	title = {Hate speech detection in the Indonesian language: A dataset and preliminary study},
	year = {2017},
	journal = {2017 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2017},
	volume = {2018-January},
	pages = {233 – 237},
	doi = {10.1109/ICACSIS.2017.8355039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047165416&doi=10.1109%2fICACSIS.2017.8355039&partnerID=40&md5=4bf8ba5527eca90f6ec73c8484d55980},
	affiliations = {Machine Learning and Computer Vision Laboratory, Faculty of Computer Science Universitas Indonesia, Depok, Indonesia},
	abstract = {The objective of our work is to detect hate speech in the Indonesian language. As far as we know, the research on this subject is still very rare. The only research we found has created a dataset for hate speech against religion, but the quality of this dataset is inadequate. Our research aimed to create a new dataset that covers hate speech in general, including hatred for religion, race, ethnicity, and gender. In addition, we also conducted a preliminary study using machine learning approach. Machine learning so far is the most frequently used approach in classifying text. We compared the performance of several features and machine learning algorithms for hate speech detection. Features that extracted were word n-gram with n=l and n=2, character n-gram with n=3 and n=4, and negative sentiment. The classification was performed using Naïve Bayes, Support Vector Machine, Bayesian Logistic Regression, and Random Forest Decision Tree. An F-measure of 93.5% was achieved when using word n-gram feature with Random Forest Decision Tree algorithm. Results also show that word n-gram feature outperformed character n-gram. © 2017 IEEE.},
	author_keywords = {building dataset; classification; hate speech detection; machine learning},
	keywords = {Computational linguistics; Decision trees; Learning algorithms; Speech recognition; Support vector machines; Building dataset; Hate speech detection; Indonesian languages; Machine learning approaches; Machine-learning; N-grams; Performance; Random forests; Speech detection; Word n-grams; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 157; Conference name: 9th International Conference on Advanced Computer Science and Information Systems, ICACSIS 2017; Conference date: 28 October 2017 through 29 October 2017; Conference code: 136300}
}

@ARTICLE{Yusuf20111055,
	author = {Yusuf, Bidemi and Omigbodun, Olayinka and Adedokun, Babatunde and Akinyemi, Odunayo},
	title = {Identifying predictors of violent behaviour among students using the conventional logistic and multilevel logistic models},
	year = {2011},
	journal = {Journal of Applied Statistics},
	volume = {38},
	number = {5},
	pages = {1055 – 1061},
	doi = {10.1080/02664761003759008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952726033&doi=10.1080%2f02664761003759008&partnerID=40&md5=d1f8f1db0dcbe4e8a08305ef4808e687},
	affiliations = {Department of Epidemiology and Medical Statistics, College of Medicine, University of Ibadan, Nigeria; Department of Psychiatry, College of Medicine, University of Ibadan, Nigeria},
	abstract = {Analysing individual-, school- and class-level observations is a good and efficient approach in epidemiologic research. Using data on violent behaviour among secondary school students we compared results from the conventional logistic modelling with multilevel logistic modelling approach using the gllamm command in Stata. We illustrated the advantage of multilevel modelling over the conventional logistic modelling through an example of data from violence experience among secondary school students. We constructed a logistic model with a random intercept on the school and class levels to account for unexplained heterogeneity between schools and classes. In the multilevel model, we estimated that, in an average school, the odds of experiencing violence are 3 (OR = 2.99, 95% CI: 1.86, 4.81,p < 0.0001) times higher for students who use drugs as opposed to the odds of experiencing violence for students who do not use drugs. However, the estimates in the conventional logistic model are slightly lower. We estimated that a normally distributed random intercept for schools and classes that accounts for any unexplained heterogeneity between schools and classes has variances 0.017 and 0.035, respectively. We therefore recommend the multilevel logistic modelling when data are clustered. © 2011 Taylor & Francis.},
	author_keywords = {Class; Logistic models; Multilevel models; Secondary school; Violence},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Guermazi2007773,
	author = {Guermazi, Radhouane and Hammami, Mohamed and Hamadou, Abdelmajid Ben},
	title = {Combining classifiers for web violent content detection and filtering},
	year = {2007},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {4489 LNCS},
	number = {PART 3},
	pages = {773 – 780},
	doi = {10.1007/978-3-540-72588-6_126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149119036&doi=10.1007%2f978-3-540-72588-6_126&partnerID=40&md5=849932dd2d687aadf4af94f3dc033f86},
	affiliations = {Miracl-Isims, Sfax, Route Mharza Km 1, Tunisia; Miracl-Fss., 3018 Sfax, Route Sokra Km 3, Tunisia},
	abstract = {Keeping people away from litigious information becomes one of the most important research area in network information security. Indeed, Web filtering is used to prevent access to undesirable Web pages. In this paper we review some existing solutions, then we propose a violent Web content detection and filtering system called "WebAngels filter" which uses textual and structural analysis. "WebAngels filter" has the advantage of combining several data-mining algorithms for Web site classification. We discuss how the combination learning based methods can improve filtering performances. Our preliminary results show that it can detect and filter violent content effectively. © Springer-Verlag Berlin Heidelberg 2007.},
	author_keywords = {Data-mining; Violent website filtering; Web classification and categorization; Web textual and structural content},
	keywords = {Adaptive filters; Algorithms; Data mining; Security of data; Structural analysis; Violent website filtering; Web classification and categorization; Web textual and structural content; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 7th International Conference on Computational Science, ICCS 2007; Conference date: 27 May 2007 through 30 May 2007; Conference code: 70823; All Open Access, Bronze Open Access}
}

@CONFERENCE{Waseem201778,
	author = {Waseem, Zeerak and Davidson, Thomas and Warmsley, Dana and Weber, Ingmar},
	title = {Understanding abuse: A typology of abusive language detection subtasks},
	year = {2017},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {78 – 84},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121317031&partnerID=40&md5=9185a44271f7b676502fb909fa351194},
	affiliations = {Department of Computer Science, University of Sheffield, United Kingdom; Department of Sociology, Cornell University, Ithica, NY, United States; Department for Applied Mathematics, Cornell University, Ithica, NY, United States; Qatar Computing Research Institute, HBKU, Doha, Qatar},
	abstract = {As the body of research on abusive language detection and analysis grows, there is a need for critical consideration of the relationships between different subtasks that have been grouped under this label. Based on work on hate speech, cyberbullying, and online abuse we propose a typology that captures central similarities and differences between subtasks and we discuss its implications for data annotation and feature construction. We emphasize the practical actions that can be taken by researchers to best approach their abusive language detection subtask of interest. © 2017 Association for Computational Linguistics},
	keywords = {Cyber bullying; Data annotation; Data feature; Feature construction; Language analysis; Language detection; Subtask},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 251; Conference name: 1st Workshop on Abusive Language Online, ALW 2017 at the 55th Annual Meeting of the Association for Computational Linguistic, ACL 2017 - Proceedings of the Workshop; Conference date: 4 August 2017; Conference code: 173144}
}

@ARTICLE{Hu2018330,
	author = {Hu, Han and Phan, NhatHai and Geller, James and Vo, Huy and Manasi, Bhole and Huang, Xueqi and Di Lorio, Sophie and Dinh, Thang and Chun, Soon Ae},
	title = {Deep self-taught learning for detecting drug abuse risk behavior in tweets},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11280 LNCS},
	pages = {330 – 342},
	doi = {10.1007/978-3-030-04648-4_28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059080385&doi=10.1007%2f978-3-030-04648-4_28&partnerID=40&md5=812006a4cdfabaaf822366660d0480d9},
	affiliations = {New Jersey Institute of Technology, Newark, 07102, NJ, United States; The City College of New York, New York, 10031, NY, United States; Virginia Commonwealth University, Richmond, 23284, VA, United States; City University of New York, Staten Island, 10314, NY, United States},
	abstract = {Drug abuse continues to accelerate toward becoming the most severe public health problem in the United States. The ability to detect drug abuse risk behavior at a population scale, such as among the population of Twitter users, can help us to monitor the trend of drug-abuse incidents. Unfortunately, traditional methods do not effectively detect drug abuse risk behavior, given tweets. This is because: (1) Tweets usually are noisy and sparse; and (2) The availability of labeled data is limited. To address these challenging problems, we proposed a deep self-taught learning system to detect and monitor drug abuse risk behaviors in the Twitter sphere, by leveraging a large amount of unlabeled data. Our models automatically augment annotated data: (i) To improve the classification performance, and (ii) To capture the evolving picture of drug abuse on online social media. Our extensive experiment has been conducted on 3 million drug abuse-related tweets with geo-location information. Results show that our approach is highly effective in detecting drug abuse risk behaviors. © Springer Nature Switzerland AG 2018.},
	author_keywords = {Deep learning; Drug abuse; Self-taught learning; Tweets},
	keywords = {Social networking (online); Classification performance; Drug abuse; Large amounts; Online social medias; Risk behavior; Self-taught learning; Tweets; Unlabeled data; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 7th International Conference on Computational Data and Social Networks, CSoNet 2018; Conference date: 18 December 2018 through 20 December 2018; Conference code: 221969}
}

@CONFERENCE{Kshirsagar201826,
	author = {Kshirsagar, Rohan and Cukuvac, Tyrus and McKeown, Kathleen and McGregor, Susan},
	title = {Predictive Embeddings for Hate Speech Detection on Twitter},
	year = {2018},
	journal = {2nd Workshop on Abusive Language Online - Proceedings of the Workshop, co-located with EMNLP 2018},
	pages = {26 – 32},
	doi = {10.18653/v1/w18-5104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122009757&doi=10.18653%2fv1%2fw18-5104&partnerID=40&md5=43a385be64d0998e0202415b98b80599},
	affiliations = {Department of Computer Science, Columbia University, United States; School of Journalism, Columbia University, United States},
	abstract = {We present a neural-network based approach to classifying online hate speech in general, as well as racist and sexist speech in particular. Using pre-trained word embeddings and max/mean pooling from simple, fully-connected transformations of these embeddings, we are able to predict the occurrence of hate speech on three commonly used publicly available datasets. Our models match or outperform state of the art F1 performance on all three datasets using significantly fewer parameters and minimal feature preprocessing compared to previous methods. © 2018 Association for Computational Linguistics},
	keywords = {Computational linguistics; Speech recognition; Embeddings; Network-based approach; Neural-networks; Performance; Simple++; Speech detection; State of the art; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; Conference name: 2nd Workshop on Abusive Language Online, ALW 2018, co-located with EMNLP 2018; Conference date: 31 October 2018; Conference code: 173717; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Del Vigna201786,
	author = {Del Vigna, Fabio and Cimino, Andrea and Dell'Orletta, Felice and Petrocchi, Marinella and Tesconi, Maurizio},
	title = {Hate me, hate me not: Hate speech detection on Facebook},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1816},
	pages = {86 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017337270&partnerID=40&md5=a02af00703e18b26b0b7bd78c9ad9d87},
	affiliations = {Istituto di Informatica e Telematica, CNR, Pisa, Italy; University of Pisa, Pisa, Italy; Istituto di Linguistica Computazionale, CNR, Pisa, Italy},
	abstract = {While favouring communications and easing information sharing, Social Network Sites are also used to launch harmful campaigns against specific groups and individuals. Cyberbullism, incitement to self-harm practices, sexual predation are just some of the severe effects of massive online offensives. Moreover, attacks can be carried out against groups of victims and can degenerate in physical violence. In this work, we aim at containing and preventing the alarming diffusion of such hate campaigns. Using Facebook as a benchmark, we consider the textual content of comments appeared on a set of public Italian pages. We first propose a variety of hate categories to distinguish the kind of hate. Crawled comments are then annotated by up to five distinct human annotators, according to the defined taxonomy. Leveraging morpho-syntactical features, sentiment polarity and word embedding lexicons, we design and implement two classifiers for the Italian language, based on different learning algorithms: the first based on Support Vector Machines (SVM) and the second on a particular Recurrent Neural Network named Long Short Term Memory (LSTM). We test these two learning algorithms in order to verify their classification performances on the task of hate speech recognition. The results show the effectiveness of the two classification approaches tested over the first manually annotated Italian Hate Speech Corpus of social media text. Copyright © 2017 for this paper by its authors.},
	keywords = {Face recognition; Learning algorithms; Long short-term memory; Recurrent neural networks; Social networking (online); Support vector machines; Text processing; Classification approach; Classification performance; Design and implements; Information sharing; Social Network Sites; Speech corpora; Speech detection; Textual content; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 273; Conference name: 1st Italian Conference on Cybersecurity, ITASEC 2017; Conference date: 17 January 2017 through 20 January 2017; Conference code: 126936}
}

@CONFERENCE{Qian2018118,
	author = {Qian, Jing and ElSherief, Mai and Belding, Elizabeth M. and Wang, William Yang},
	title = {Leveraging intra-user and inter-user representation learning for automated hate speech detection},
	year = {2018},
	journal = {NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
	volume = {2},
	pages = {118 – 123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077197808&partnerID=40&md5=95cc6aa8d10cefea332706aa1e3f46c2},
	affiliations = {Department of Computer Science, University of California Santa Barbara, Santa Barbara, 93106, CA, United States},
	abstract = {Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP). Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the accuracy is still poor. The central problem is that social media posts are short and noisy, and most existing hate speech detection solutions take each post as an isolated input instance, which is likely to yield high false positive and negative rates. In this paper, we radically improve automated hate speech detection by presenting a novel model that leverages intra-user and inter-user representation learning for robust hate speech detection on Twitter. In addition to the target Tweet, we collect and analyze the user's historical posts to model intrauser Tweet representations. To suppress the noise in a single Tweet, we also model the similar Tweets posted by all other users with reinforced inter-user representation learning techniques. Experimentally, we show that leveraging these two representations can significantly improve the f-score of a strong bidirectional LSTM baseline model by 10.1%. © 2018 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Learning systems; Long short-term memory; Natural language processing systems; Social networking (online); Speech; Baseline models; Central problems; False positive; Learning techniques; NAtural language processing; Negative rates; Social media; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; Conference name: 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2018; Conference date: 1 June 2018 through 6 June 2018; Conference code: 158892}
}

@CONFERENCE{Bosco2018,
	author = {Bosco, Cristina and Sanguinetti, Manuela and Dell’Orletta, Felice and Poletto, Fabio and Tesconi, Maurizio},
	title = {Overview of the EVALITA 2018 hate speech detection task},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212631028&partnerID=40&md5=a03145e00303691bc67918043fae64f5},
	affiliations = {University of Torino, Italy; ILC-CNR, Pisa, Italy; Acmos, Torino, Italy; IIT-CNR, Pisa, Italy},
	abstract = {The Hate Speech Detection (HaSpeeDe) task is a shared task on Italian social media (Facebook and Twitter) for the detection of hateful content, and it has been proposed for the first time at EVALITA 2018. Providing two datasets from two different online social platforms differently featured from the linguistic and communicative point of view, we organized the task in three tasks where systems must be trained and tested on the same resource or using one in training and the other in testing: HaSpeeDe-FB, HaSpeeDe-TW and Cross-HaSpeeDe (further subdivided into Cross-HaSpeeDe FB and Cross-HaSpeeDe TW sub-tasks). Overall, 9 teams participated in the task, and the best system achieved a macro F1-score of 0.8288 for HaSpeeDe-FB, 0.7993 for HaSpeeDe-TW, 0.6541 for Cross-HaSpeeDe FB and 0.6985 for Cross-HaSpeeDe TW. In this report, we describe the datasets released and the evaluation measures, and we discuss results. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Online systems; Social networking (online); Detection tasks; Evaluation measures; F1 scores; Facebook; Social media; Speech detection; Subtask; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825}
}

@CONFERENCE{Ahluwalia2018,
	author = {Ahluwalia, Resham and Soni, Himani and Callow, Edward and Nascimento, Anderson and De Cock, Martine},
	title = {Detecting hate speech against women in English tweets},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212627570&partnerID=40&md5=c3d3749672a280c4ad53b66489756983},
	affiliations = {School of Engineering and Technology, University of Washington, Tacoma, United States},
	abstract = {Hate speech is prevalent in social media platforms. Systems that can automatically detect offensive content are of great value to assist human curators with removal of hateful language. In this paper, we present machine learning models developed at UW Tacoma for detection of misogyny, i.e. hate speech against women, in English tweets, and the results obtained with these models in the shared task for Automatic Misogyny Identification (AMI) at EVALITA2018. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Natural language processing systems; Machine learning models; Social media platforms; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825}
}

@ARTICLE{Zhang2018745,
	author = {Zhang, Ziqi and Robinson, David and Tepper, Jonathan},
	title = {Detecting Hate Speech on Twitter Using a Convolution-GRU Based Deep Neural Network},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10843 LNCS},
	pages = {745 – 760},
	doi = {10.1007/978-3-319-93417-4_48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048501410&doi=10.1007%2f978-3-319-93417-4_48&partnerID=40&md5=17f91e1f6c292aaa2ee3efe97f1bdf60},
	affiliations = {University of Sheffield, Sheffield, United Kingdom; Nottingham Trent University, Nottingham, United Kingdom},
	abstract = {In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and empirical research. Despite a large number of emerging scientific studies to address the problem, a major limitation of existing work is the lack of comparative evaluations, which makes it difficult to assess the contribution of individual works. This paper introduces a new method based on a deep neural network combining convolutional and gated recurrent networks. We conduct an extensive evaluation of the method against several baselines and state of the art on the largest collection of publicly available Twitter datasets to date, and show that compared to previously reported results on these datasets, our proposed method is able to capture both word sequence and order information in short texts, and it sets new benchmark by outperforming on 6 out of 7 datasets by between 1 and 13% in F1. We also extend the existing dataset collection on this task by creating a new dataset covering different topics. © 2018, Springer International Publishing AG, part of Springer Nature.},
	keywords = {Convolution; Recurrent neural networks; Semantic Web; Social networking (online); Comparative evaluations; Empirical research; Recurrent networks; Scientific studies; Short texts; Social media; State of the art; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 452; Conference name: 15th International Conference on Extended Semantic Web Conference, ESWC 2018; Conference date: 3 June 2018 through 7 June 2018; Conference code: 214029}
}

@CONFERENCE{Dahlbom20132033,
	author = {Dahlbom, Anders and Nordlund, Per-Johan},
	title = {Detection of hostile aircraft behaviors using dynamic Bayesian networks},
	year = {2013},
	journal = {Proceedings of the 16th International Conference on Information Fusion, FUSION 2013},
	pages = {2033 – 2040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890828056&partnerID=40&md5=b180cde452082096a9b7048af9682849},
	affiliations = {Informatics Research Centre, University of Skövde, Skövde, SE-541 28, P.O. Box 408, Sweden; Aeronautics, Saab AB, Bröderna Ugglas Gata, SE-581 88, Linköping, Sweden},
	abstract = {Aircraft Combat Survivability in military air operations is concerned with survival of the own aircraft. This entails analysis of information, detection and estimation of threats, and the implementation of actions to counteract detected threats. Beyond visual range weapons can today be fired from one hundred kilometers away, making them difficult to detect and track. One approach for providing early warnings of such threats is to analyze the kinematic behavior of enemy aircraft in order to detect situations that may point to malicious intent. In this paper we investigate the use of dynamic Bayesian networks for detecting hostile aircraft behaviors. © 2013 ISIF ( Intl Society of Information Fusi.},
	author_keywords = {behavior detection; behavior recognition; situation detection; situation recognition; threat assessment},
	keywords = {Aircraft; Bayesian networks; Behavioral research; Information fusion; Military engineering; Behavior detection; Behavior recognition; Situation detection; Situation recognition; Threat assessment; Aircraft detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 16th International Conference of Information Fusion, FUSION 2013; Conference date: 9 July 2013 through 12 July 2013; Conference code: 101417}
}

@CONFERENCE{Hassner20121,
	author = {Hassner, Tal and Itcher, Yossi and Kliper-Gross, Orit},
	title = {Violent flows: Real-time detection of violent crowd behavior},
	year = {2012},
	journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	pages = {1 – 6},
	doi = {10.1109/CVPRW.2012.6239348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864980012&doi=10.1109%2fCVPRW.2012.6239348&partnerID=40&md5=7cccef9df2ff72f07faffb004bf1b7ec},
	affiliations = {Open University of Israel, Israel; Weizmann Institute of Science, Israel},
	abstract = {Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness. © 2012 IEEE.},
	keywords = {Classification (of information); Computer vision; Security systems; Signal detection; Statistical tests; Video cameras; Crowd behavior; Data sets; Descriptors; Empirical test; Frame sequences; Linear SVM; Real-time detection; Surveillance video; Video screens; Behavioral research},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 503; Conference name: 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2012; Conference date: 16 June 2012 through 21 June 2012; Conference code: 91784}
}

@CONFERENCE{Malmasi2017467,
	author = {Malmasi, Shervin and Zampieri, Marcos},
	title = {Detecting hate speech in social media},
	year = {2017},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	volume = {2017-September},
	pages = {467 – 472},
	doi = {10.26615/978-954-452-049-6_062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045732994&doi=10.26615%2f978-954-452-049-6_062&partnerID=40&md5=3d052526d58340a3561a5d8844cc6683},
	affiliations = {Harvard Medical School, Boston, MA, United States; University of Wolverhampton, Wolverhampton, United Kingdom},
	abstract = {In this paper we examine methods to detect hate speech in social media, while distinguishing this from general profanity. We aim to establish lexical baselines for this task by applying supervised classification methods using a recently released dataset annotated for this purpose. As features, our system uses character n-grams, word n-grams and word skip-grams. We obtain results of 78% accuracy in identifying posts across three classes. Results demonstrate that the main challenge lies in discriminating profanity and hate speech from each other. A number of directions for future work are discussed. © 2018 Association for Computational Linguistics (ACL). All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Social networking (online); Speech recognition; Classification methods; N-grams; Social media; Supervised classification; System use; Word n-grams; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 162; Conference name: 11th International Conference on Recent Advances in Natural Language Processing, RANLP 2017; Conference date: 2 September 2017 through 8 September 2017; Conference code: 135740; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Park201741,
	author = {Park, Ji Ho and Fung, Pascale},
	title = {One-step and two-step classification for abusive language detection on twitter},
	year = {2017},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {41 – 45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104639200&partnerID=40&md5=539a390cf141f9aacb1422555b8c77dd},
	affiliations = {Human Language Technology Center, Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong},
	abstract = {Automatic abusive language detection is a difficult but important task for online social media. Our research explores a two-step approach of performing classification on abusive language and then classifying into specific types and compares it with one-step approach of doing one multi-class classification for detecting sexist and racist languages. With a public English Twitter corpus of 20 thousand tweets in the type of sexism and racism, our approach shows a promising performance of 0.827 F-measure by using HybridCNN in one-step and 0.824 F-measure by using logistic regression in two-steps. © 2017 Association for Computational Linguistics},
	keywords = {Computational linguistics; Social networking (online); F measure; Language detection; Logistics regressions; Multi-class classification; Online social medias; Performance; Two-step approach; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 156; Conference name: 1st Workshop on Abusive Language Online, ALW 2017 at the 55th Annual Meeting of the Association for Computational Linguistic, ACL 2017 - Proceedings of the Workshop; Conference date: 4 August 2017; Conference code: 173144}
}

@CONFERENCE{Santucci2018239,
	author = {Santucci, Valentino and Spina, Stefania and Milani, Alfredo and Biondi, Giulio and Di Bari, Gabriele},
	title = {Detecting hate speech for Italian language in social media},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	pages = {239 – 243},
	doi = {10.4000/books.aaccademia.4799},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058615767&doi=10.4000%2fbooks.aaccademia.4799&partnerID=40&md5=c89caa48cc1baac535863339cfffdd47},
	affiliations = {University for Foreigners of Perugia, Italy; University of Perugia, Italy; University of Florence, Italy},
	abstract = {English. In this report we describe the hate speech detection system for the Italian language developed by a joint team of researchers from the two universities of Perugia (University for Foreigners of Perugia and University of Perugia). The experimental results obtained in the HaSpeeDe task of the Evalita 2018 evaluation campaign are analyzed. Finally, a suggestion for future research directions is provided in the conclusion. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Speech recognition; Detection system; Future research directions; Social media; Speech detection; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ibrohim2018222,
	author = {Ibrohim, Muhammad Okky and Budi, Indra},
	title = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},
	year = {2018},
	journal = {Procedia Computer Science},
	volume = {135},
	pages = {222 – 229},
	doi = {10.1016/j.procs.2018.08.169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053148853&doi=10.1016%2fj.procs.2018.08.169&partnerID=40&md5=d6042264de0c5754d46053aba46f8706},
	affiliations = {Faculty of Computer Science, Universitas Indonesia, Kampus UI, Depok, 16424, Indonesia},
	abstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study. © 2018 The Authors. Published by Elsevier Ltd.},
	author_keywords = {abusive language; machine learning; twitter},
	keywords = {Artificial intelligence; Classifiers; Decision trees; Learning systems; Social networking (online); abusive language; Decision tree classifiers; Language detection; Machine learning approaches; Naive Bayes classifiers; Offensive languages; Random forests; twitter; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 94; Conference name: 3rd International Conference on Computer Science and Computational Intelligence, ICCSCI 2018; Conference date: 7 September 2018 through 8 September 2018; Conference code: 138963; All Open Access, Gold Open Access}
}

@CONFERENCE{Corazza2018,
	author = {Corazza, Michele and Menini, Stefano and Arslan, Pinar and Sprugnoli, Rachele and Cabrio, Elena and Tonelli, Sara and Villata, Serena},
	title = {Comparing different supervised approaches to hate speech detection},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	doi = {10.4000/books.aaccademia.4772},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212639523&doi=10.4000%2fbooks.aaccademia.4772&partnerID=40&md5=c464007e8d85d13e60afbf917feb49ed},
	affiliations = {Université Côte d’Azur, CNRS, Inria, I3S, France; Fondazione Bruno Kessler, Trento, Italy},
	abstract = {English. This paper reports on the systems the InriaFBK Team submitted to the EVALITA 2018 - Shared Task on Hate Speech Detection in Italian Twitter and Facebook posts (HaSpeeDe). Our submissions were based on three separate classes of models: a model using a recurrent layer, an ngram-based neural network and a LinearSVC. For the Facebook task and the two cross-domain tasks we used the recurrent model and obtained promising results, especially in the cross-domain setting. For Twitter, we used an ngram-based neural network and the LinearSVC-based model. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Computational linguistics; Multilayer neural networks; Social networking (online); Speech recognition; Cross-domain; Facebook; N-grams; Neural-networks; Recurrent layers; Recurrent models; Speech detection; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Schmidt20171,
	author = {Schmidt, Anna and Wiegand, Michael},
	title = {A Survey on Hate Speech Detection using Natural Language Processing},
	year = {2017},
	journal = {SocialNLP 2017 - 5th International Workshop on Natural Language Processing for Social Media, Proceedings of the Workshop AFNLP SIG SocialNLP},
	pages = {1 – 10},
	doi = {10.18653/v1/w17-1101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118862322&doi=10.18653%2fv1%2fw17-1101&partnerID=40&md5=67d99c7db95852a633dbc88e5b887ce1},
	affiliations = {Spoken Language Systems, Saarland University, Saarbrücken, D-66123, Germany},
	abstract = {This paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing. Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing. We also discuss limits of those approaches. © 2017 Association for Computational Linguistics Sood et al. (2012a) work on detecting (personal) insults, profanity and user posts that are characterized by malicious intent, while Razavi et al. (2010) refer to offensive language. Xiang et al. (2012) focus on vulgar language and profanity-related offensive content. Xu et al. (2012)2 further look into jokingly formulated teasing in messages that represent (possibly less severe) bullying episodes. Finally, Burnap and Williams (2014) specifically look into othering language, characterized by an us-them dichotomy in racist communication.},
	keywords = {Natural language processing systems; Speech recognition; Growing bodies; Language processing; Media content; Natural languages; Social media; Speech detection; Surveys},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 963; Conference name: 5th International Workshop on Natural Language Processing for Social Media, SocialNLP 2017, associated with EACL 2017; Conference date: 3 April 2017; Conference code: 173856; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Mubarak201752,
	author = {Mubarak, Hamdy and Darwish, Kareem and Magdy, Walid},
	title = {Abusive language detection on Arabic social media},
	year = {2017},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {52 – 56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112829351&partnerID=40&md5=d596d72bf7b0048b5277568d0b66557e},
	affiliations = {Qatar Computing Research Institute, HBKU, Doha, Qatar; School of Informatics, University of Edinburgh, United Kingdom},
	abstract = {In this paper, we present our work on detecting abusive language on Arabic social media. We extract a list of obscene words and hashtags using common patterns used in offensive and rude communications. We also classify Twitter users according to whether they use any of these words or not in their tweets. We expand the list of obscene words using this classification, and we report results on a newly created dataset of classified Arabic tweets (obscene, offensive, and clean). We make this dataset freely available for research, in addition to the list of obscene words and hashtags. We are also publicly releasing a large corpus of classified user comments that were deleted from a popular Arabic news site due to violations the site's rules and guidelines. © 2017 Association for Computational Linguistics},
	keywords = {Computational linguistics; Social networking (online); Classifieds; Hashtags; Language detection; Large corpora; Social media; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 231; Conference name: 1st Workshop on Abusive Language Online, ALW 2017 at the 55th Annual Meeting of the Association for Computational Linguistic, ACL 2017 - Proceedings of the Workshop; Conference date: 4 August 2017; Conference code: 173144}
}

@CONFERENCE{Waseem201688,
	author = {Waseem, Zeerak and Hovy, Dirk},
	title = {Hateful symbols or hateful people? predictive features for hate speech detection on twitter},
	year = {2016},
	journal = {HLT-NAACL 2016 - 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Student Research Workshop},
	pages = {88 – 93},
	doi = {10.18653/v1/n16-2013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118858548&doi=10.18653%2fv1%2fn16-2013&partnerID=40&md5=16158ed87344160646862d50f6325a6a},
	affiliations = {University of Copenhagen, Copenhagen, Denmark},
	abstract = {Hate speech in the form of racist and sexist remarks are a common occurrence on social media. For that reason, many social media services address the problem of identifying hate speech, but the definition of hate speech varies markedly and is largely a manual effort (BBC, 2015; Lomas, 2015). We provide a list of criteria founded in critical race theory, and use them to annotate a publicly available corpus of more than 16k tweets. We analyze the impact of various extra-linguistic features in conjunction with character n-grams for hatespeech detection. We also present a dictionary based the most indicative words in our data. © 2016 HLT-NAACL 2016 - 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Student Research Workshop. All rights reserved.},
	keywords = {Computation theory; Social networking (online); Speech recognition; Linguistics; Linguistic features; N-grams; Social media; Social media services; Speech detection; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1287; Conference name: 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, HLT-NAACL 2016; Conference date: 12 June 2016 through 17 June 2016; Conference code: 173166; All Open Access, Bronze Open Access}
}

@CONFERENCE{Djuric201529,
	author = {Djuric, Nemanja and Zhou, Jing and Morris, Robin and Grbovic, Mihajlo and Radosavljevic, Vladan and Bhamidipati, Narayan},
	title = {Hate speech detection with comment embeddings},
	year = {2015},
	journal = {WWW 2015 Companion - Proceedings of the 24th International Conference on World Wide Web},
	pages = {29 – 30},
	doi = {10.1145/2740908.2742760},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944091702&doi=10.1145%2f2740908.2742760&partnerID=40&md5=d14008f92ae1764839dd86b0a7a3aaa4},
	affiliations = {Yahoo Labs, 701 First Ave, Sunnyvale, CA, United States},
	abstract = {We address the problem of hate speech detection in online user comments. Hate speech, defined as an abusive speech targeting specific group characteristics, such as ethnicity, religion, or gender, is an important problem plaguing websites that allow users to leave feedback, having a negative impact on their online business and overall user experience. We propose to learn distributed low-dimensional representations of comments using recently proposed neural language models, that can then be fed as inputs to a classification algorithm. Our approach addresses issues of high-dimensionality and sparsity that impact the current state-of-the-art, resulting in highly efficient and effiective hate speech detectors.},
	keywords = {Speech; User interfaces; World Wide Web; Classification algorithm; High dimensionality; Language model; Low-dimensional representation; Online business; Speech detection; State of the art; User experience; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 519; Conference name: 24th International Conference on World Wide Web, WWW 2015; Conference date: 18 May 2015 through 22 May 2015; Conference code: 119451}
}

@CONFERENCE{Liu2018102,
	author = {Liu, Yingjie and Wert, Gregory and Greenawald, Benjamin and Boni, Mohammad Al and Brown, Donald E.},
	title = {Predicting violent behavior using language agnostic models},
	year = {2018},
	journal = {IC3K 2018 - Proceedings of the 10th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management},
	volume = {1},
	pages = {102 – 109},
	doi = {10.5220/0006933701020109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059034476&doi=10.5220%2f0006933701020109&partnerID=40&md5=9af8079398381db0ef86eb0834334ca2},
	affiliations = {Data Science Institute, University of Virginia, United States; Department of Systems and Information Engineering, University of Virginia, United States},
	abstract = {Groups advocating violence have caused significant destruction to individuals and societies. To combat this, governmental and non-governmental organizations must quickly identify violent groups and limit their exposure. While some groups are well-known for their violence, smaller, less recognized groups are difficult to classify. However, using texts from these groups, we may be able to identify them. This paper applies text analysis techniques to differentiate violent and non-violent groups using discourses from various value-motivated groups. Significantly, the algorithms are constructed to be language-agnostic. The results show that deep learning models outperform traditional models. Our models achieve high accuracy when fairly trained only on data from other groups. Additionally, the results indicate that the models achieve better performance by removing groups with a large amount of documents that can bias the classification. This study shows promise in using scalable, language-independent techniques to effectively identify violent value-motivated groups. Copyright 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved},
	author_keywords = {Bidirectional recurrent neural networks; Convolutional neural networks; Natural language processing; Text analysis},
	keywords = {Deep learning; Information retrieval systems; Knowledge engineering; Knowledge management; Natural language processing systems; Bidirectional recurrent neural networks; Convolutional neural network; Language independents; NAtural language processing; Nongovernmental organizations; Text analysis; Traditional models; Violent behavior; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 10th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K 2018; Conference date: 18 September 2018 through 20 September 2018; Conference code: 143001; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Derzon199777,
	author = {Derzon, James H.},
	title = {Some visual displays of two-by-two data: Predicting later violent behavior},
	year = {1997},
	journal = {New Directions for Evaluation},
	volume = {1997},
	number = {73},
	pages = {77 – 84},
	doi = {10.1002/ev.1063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040424948&doi=10.1002%2fev.1063&partnerID=40&md5=924146265dcbcafc02f5a9de504fb9d9},
	affiliations = {Vanderbilt Institute for Public Policy Studies, Nashville, TN, United States},
	abstract = {A two-by-two table effectively presents the relationship between a predictor and an outcome. Using fewer cells in the table focuses the reader's attention on the contingent relationship. Copyright © 1997 Wiley Periodicals, Inc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mangaonkar2015611,
	author = {Mangaonkar, Amrita and Hayrapetian, Allenoush and Raje, Rajeev},
	title = {Collaborative detection of cyberbullying behavior in Twitter data},
	year = {2015},
	journal = {IEEE International Conference on Electro Information Technology},
	volume = {2015-June},
	pages = {611 – 616},
	doi = {10.1109/EIT.2015.7293405},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975721175&doi=10.1109%2fEIT.2015.7293405&partnerID=40&md5=19b6eb52827cbd0f6e2404d30661dbfa},
	affiliations = {Department of Computer and Information Science, Indiana University-Purdue University Indianapolis, Indianapolis, United States},
	abstract = {As the size of Twitter© data is increasing, so are undesirable behaviors of its users. One of such undesirable behavior is cyberbullying, which may even lead to catastrophic consequences. Hence, it is critical to efficiently detect cyberbullying behavior by analyzing tweets, if possible in realtime. Prevalent approaches to identify cyberbullying are mainly stand-alone and thus, are time-consuming. This research improves detection task using the principles of collaborative computing. Different collaborative paradigms are suggested and discussed in this paper. Preliminary results indicate an improvement in time and accuracy of the detection mechanism over the stand-alone paradigm. © 2015 IEEE.},
	author_keywords = {Cyberbullying; machine learning algorithms; Twitter},
	keywords = {Artificial intelligence; Learning algorithms; Learning systems; Social networking (online); Catastrophic consequences; Collaborative detection; Cyber bullying; Detection mechanism; Detection tasks; Real time; Stand -alone; Twitter; Computer crime},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 64; Conference name: IEEE International Conference on Electro/Information Technology, EIT 2015; Conference date: 21 May 2015 through 23 May 2015; Conference code: 118441; All Open Access, Green Open Access}
}

@ARTICLE{Munezero20143,
	author = {Munezero, Myriam and Montero, Calkin Suero and Kakkonen, Tuomo and Sutinen, Erkki and Mozgovoy, Maxim and Klyuev, Vitaly},
	title = {Automatic detection of antisocial behaviour in texts},
	year = {2014},
	journal = {Informatica (Slovenia)},
	volume = {38},
	number = {1},
	pages = {3 – 10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897972344&partnerID=40&md5=75ec83cf5e440654e6d9963093bbc8e4},
	affiliations = {School of Computing, University of Eastern Finland, FI-80101, Joensuu, P.O.Box 111, Finland; University of Aizu, Tsuruga, Ikki-machi Aizu-Wakamatsu, Fukushima, 965-8580, Japan},
	abstract = {A considerable amount of effort has been made to reduce the physical manifestation of antisocial behaviour (ASB) in communities. However, the key to the early detection of ASB is, in many cases, in observing its manifestations in written language, which has not been studied in detail. In this work, we search for linguistic features that pertain to ASB in order to use those features for the automatic identification of ASB in texts. We use an ASB text corpus we have collected as a machine learning resource and approach the detection of ASB in texts as a binary classification problem where discriminating features are taken from the linguistic representation of texts in the form bag-of-words and ontology-based emotion descriptors. Results from preliminary experiments show that by exploiting the emotional information together with Bag-of-Words (BoW) over 90% accuracy in the classification of ASB in texts is reached. Our findings have positive implications in the early detection of potentially harmful behaviour.},
	author_keywords = {Antisocial behaviour; Emotion detection; Language analysis; Machine learning},
	keywords = {Automation; Learning systems; Linguistics; Antisocial behaviour; Automatic identification; Binary classification problems; Emotion detection; Emotional information; Language analysis; Linguistic features; Linguistic representations; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Sorge2015477,
	author = {Sorge, Geoff Brian and Skilling, Tracey A. and Toplak, Maggie E.},
	title = {Intelligence, Executive Functions, and Decision Making as Predictors of Antisocial Behavior in an Adolescent Sample of Justice-Involved Youth and a Community Comparison Group},
	year = {2015},
	journal = {Journal of Behavioral Decision Making},
	volume = {28},
	number = {5},
	pages = {477 – 490},
	doi = {10.1002/bdm.1864},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978745613&doi=10.1002%2fbdm.1864&partnerID=40&md5=c9ca26a312a635af32767fe1b0f36ed2},
	affiliations = {Department of Psychology, York University, LaMarsh Centre for Child and Youth Research, Toronto, ON, Canada; Child, Youth, and Family Services, Centre for Addiction and Mental Health, Toronto, ON, Canada; Department of Psychology, University of Toronto, LaMarsh Centre for Child and Youth Research, Toronto, ON, Canada},
	abstract = {A clinical sample of justice-involved male adolescents and a community comparison group were compared on a battery of cognitive ability tasks (intelligence and executive functions), decision making measures, and other individual difference measures, including ratings of self-control, recognition of morally debatable behaviors, and antisocial beliefs. The clinical sample displayed lower performance on cognitive abilities and decision making than the community comparison group. In particular, the clinical group displayed less otherside thinking and more hostile attribution biases in unintentional situations compared with the community comparison group. Cognitive abilities and the decision making performance predicted group membership. Then, group membership, ratings of self-control, attitudes about morally debatable behaviors, and antisocial beliefs predicted ratings of antisocial behavior in the full sample. These findings suggest that measures of cognitive ability and decision making make separate contributions to explaining antisocial behaviors. In addition, the predictors of group membership and antisocial behavior did not overlap, suggesting that antisocial behavior engagement in clinical samples may be separable from the continuum of antisocial behavior across the full sample. Cognitive science models of decision making can provide a framework for understanding antisocial behavior in clinical and community samples of adolescents. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.},
	author_keywords = {antisocial behavior; decision making; executive functions; intelligence; offending youth; rational thinking},
	keywords = {adolescent; antisocial behavior; attributional bias; community sample; consensus development; controlled study; decision making; disease model; executive function; human; human experiment; human tissue; intelligence; justice; male; recognition; self control; social belief},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@CONFERENCE{Marsden2017,
	author = {Marsden, Mark and McGuinness, Kevin and Little, Suzanne and O'Connor, Noel E.},
	title = {ResnetCrowd: A residual deep learning architecture for crowd counting, violent behaviour detection and crowd density level classification},
	year = {2017},
	journal = {2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance, AVSS 2017},
	doi = {10.1109/AVSS.2017.8078482},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039898700&doi=10.1109%2fAVSS.2017.8078482&partnerID=40&md5=1aafdbb8720a85fe5c9023425c8eb7bc},
	affiliations = {Insight Centre for Data Analytics, Dublin City University, Ireland},
	abstract = {In this paper we propose ResnetCrowd, a deep residual architecture for simultaneous crowd counting, violent behaviour detection and crowd density level classification. To train and evaluate the proposed multi-objective technique, a new 100 image dataset referred to as Multi Task Crowd is constructed. This new dataset is the first computer vision dataset fully annotated for crowd counting, violent behaviour detection and density level classification. Our experiments show that a multi-task approach boosts individual task performance for all tasks and most notably for violent behaviour detection which receives a 9% boost in ROC curve AUC (Area under the curve). The trained ResnetCrowd model is also evaluated on several additional benchmarks highlighting the superior generalisation of crowd analysis models trained for multiple objectives. © 2017 IEEE.},
	keywords = {Classification (of information); Deep learning; Security systems; Area under the curves; Behaviour detections; Density levels; Image datasets; Learning architectures; Multi objective; Multiple-objectives; Task performance; Behavioral research},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 115; Conference name: 14th IEEE International Conference on Advanced Video and Signal Based Surveillance, AVSS 2017; Conference date: 29 August 2017 through 1 September 2017; Conference code: 131495; All Open Access, Green Open Access}
}

@CONFERENCE{Merenda2018,
	author = {Merenda, Flavio and Zaghi, Claudia and Caselli, Tommaso and Nissim, Malvina},
	title = {Source-driven representations for hate speech detection},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2253},
	doi = {10.4000/books.aaccademia.3463},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057719069&doi=10.4000%2fbooks.aaccademia.3463&partnerID=40&md5=9a7f0bac108438e8f756f349f498f755},
	affiliations = {Rikjuniversiteit Groningen, Groningen, Netherlands; Università degli Studi di Salerno, Salerno, Italy},
	abstract = {Sources, in the form of selected Facebook pages, can be used as indicators of hate-rich content. Polarized distributed representations created over such content prove superior to generic embeddings in the task of hate speech detection. The same content seems to carry a too weak signal to proxy silver labels in a distant supervised setting. However, this signal is stronger than gold labels which come from a different distribution, leading to re-think the process of annotation in the context of highly subjective judgments. © 2018 CEUR-WS. All rights reserved.},
	keywords = {Computational linguistics; Different distributions; Distributed representation; Facebook pages; Speech detection; Weak signals; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th Italian Conference on Computational Linguistics, CLiC-it 2018; Conference date: 10 December 2018 through 12 December 2018; Conference code: 142380; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Haidar2017275,
	author = {Haidar, Batoul and Chamoun, Maroun and Serhrouchni, Ahmed},
	title = {A multilingual system for cyberbullying detection: Arabic content detection using machine learning},
	year = {2017},
	journal = {Advances in Science, Technology and Engineering Systems},
	volume = {2},
	number = {6},
	pages = {275 – 284},
	doi = {10.25046/aj020634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062384507&doi=10.25046%2faj020634&partnerID=40&md5=fb0d6e9326930c3d1d40ea0f74357372},
	affiliations = {Saint Joseph University, Lebanon; Telecom ParisTech, France},
	abstract = {With the abundance of Internet and electronic devices bullying has moved its place from schools and backyards into cyberspace; to be now known as Cyberbullying. Cyberbullying is affecting a lot of children around the world, especially Arab countries. Thus, concerns from cyberbullying are rising. A lot of research is ongoing with the purpose of diminishing cyberbullying. The current research efforts are focused around detection and mitigation of cyberbullying. Previously, researches dealt with the psychological effects of cyberbullying on the victim and the predator. A lot of research work proposed solutions for detecting cyberbullying in English language and a few more languages, but none till now covered cyberbullying in Arabic language. Several techniques contribute in cyberbullying detection, mainly Machine Learning (ML) and Natural Language Processing (NLP). This journal extends on a previous paper to elaborate on a solution for detecting and stopping cyberbullying. It first presents a thorough survey for the previous work done in cyberbullying detection. Then a solution that focuses on detecting cyberbullying in Arabic content is displayed and assessed. © 2017 ASTES Publishers. All rights reserved.},
	author_keywords = {Arabic Natural Language Processing; Cyberbullying; Machine Learning; Natural Language Processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 89; All Open Access, Gold Open Access}
}

@CONFERENCE{Lloyd2016,
	author = {Lloyd, K. and Rosin, P.L. and Marshall, A.D. and Moore, S.C.},
	title = {Violent behaviour detection using local trajectory response},
	year = {2016},
	journal = {IET Seminar Digest},
	volume = {2016},
	number = {6},
	doi = {10.1049/ic.2016.0082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047194391&doi=10.1049%2fic.2016.0082&partnerID=40&md5=6a1b6f191e4c8f83f46e958b00aff801},
	affiliations = {School of Computer Science, Cardiff University, United Kingdom; Violence and Society Research Group, School of Dentistry, Cardiff University, United Kingdom},
	abstract = {Surveillance systems in the United Kingdom are prominent, and the number of installed cameras is estimated to be around 1.8 million. It is common for a single person to watch multiple live video feeds when conducting active surveillance, and past research has shown that a person's effectiveness at successfully identifying an event of interest diminishes the more monitors they must observe. We propose using computer vision techniques to produce a system that can accurately identify scenes of violent behaviour. In this paper we outline three measures of motion trajectory that when combined produce a response map that highlights regions within frames that contain behaviour typical of violence based on local information. Our proposed method demonstrates state-of-the-art classification ability when given the task of distinguishing between violent and non-violent behaviour across a wide variety of violent data, including real-world surveillance footage obtained from local police organisations. © 2016 Institution of Engineering and Technology. All rights reserved.},
	author_keywords = {Detection; Surveillance; Trajectories; Violence},
	keywords = {Error detection; Monitoring; Space surveillance; Trajectories; Behaviour detections; Classification ability; Computer vision techniques; Local information; Motion trajectories; State of the art; Surveillance systems; Violence; Security systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 7th International Conference on Imaging for Crime Detection and Prevention, ICDP 2016; Conference date: 23 November 2016 through 25 November 2016; Conference code: 133725; All Open Access, Green Open Access}
}

@CONFERENCE{Polignano2018,
	author = {Polignano, Marco and Basile, Pierpaolo},
	title = {Hansel: Italian hate speech detection through ensemble learning and deep neural networks},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	doi = {10.4000/books.aaccademia.4766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212652138&doi=10.4000%2fbooks.aaccademia.4766&partnerID=40&md5=78d06f19538c1fae302c5e56f144bc22},
	affiliations = {University of Bari Aldo Moro, Dept. Computer Science, via E. Orabona 4, Bari, 70125, Italy},
	abstract = {The detection of hate speeches, over social media and online forums, is a relevant task for the research area of natural language processing. This interest is motivated by the complexity of the task and the social impact of its use in real scenarios. The task solution proposed in this work is based on an ensemble of three classification strategies, mediated by a majority vote algorithm: Support Vector Machine (Hearst et al., 1998) (SVM with RBF kernel), Random Forest (Breiman, 2001), Deep Multilayer Perceptron (Kolmogorov, 1992) (MLP). Each classifier has been tuned using a greedy strategy of hyper-parameters optimization over the”F1” score calculated on a 5-fold random subdivision of the training set. Each sentence has been pre-processed to transform it into word embeddings and TF-IDF bag of words. The results obtained on the cross-validation over the training sets have shown an F1 value of 0.8034 for Facebook sentences and 0.7102 for Twitter. The code of the system proposed can be downloaded from GitHub: https: //github.com/marcopoli/ haspeede_hate_detect. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Classification (of information); Computational complexity; Deep neural networks; Learning algorithms; Natural language processing systems; Social networking (online); Speech recognition; Support vector machines; Ensemble learning; Language processing; Majority voter; Natural languages; Online forums; Research areas; Social impact; Social media; Speech detection; Training sets; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Unsvåg201875,
	author = {Unsvåg, Elise Fehn and Gambäck, Björn},
	title = {The Effects of User Features on Twitter Hate Speech Detection},
	year = {2018},
	journal = {2nd Workshop on Abusive Language Online - Proceedings of the Workshop, co-located with EMNLP 2018},
	pages = {75 – 85},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090911870&partnerID=40&md5=997802f3336e03a773b784f7841eb840},
	affiliations = {Department of Computer Science, Norwegian University of Science and Technology, Trondheim, NO-7491, Norway},
	abstract = {The paper investigates the potential effects user features have on hate speech classification. A quantitative analysis of Twitter data was conducted to better understand user characteristics, but no correlations were found between hateful text and the characteristics of the users who had posted it. However, experiments with a hate speech classifier based on datasets from three different languages showed that combining certain user features with textual features gave slight improvements of classification performance. While the incorporation of user features resulted in varying impact on performance for the different datasets used, user network-related features provided the most consistent improvements. © 2018 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Speech recognition; Classification performance; Performance; Potential effects; Speech classification; Speech detection; Textual features; User characteristics; User feature; User networks; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66; Conference name: 2nd Workshop on Abusive Language Online, ALW 2018, co-located with EMNLP 2018; Conference date: 31 October 2018; Conference code: 173717}
}

@CONFERENCE{Shende2017,
	author = {Shende, Snehal B. and Deshpande, Leena},
	title = {A computational framework for detecting offensive language with support vector machine in social communities},
	year = {2017},
	journal = {8th International Conference on Computing, Communications and Networking Technologies, ICCCNT 2017},
	doi = {10.1109/ICCCNT.2017.8204020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041412142&doi=10.1109%2fICCCNT.2017.8204020&partnerID=40&md5=7209ec80bb8079e7e5df1ae883d59b51},
	affiliations = {Department of Computer Engineering, Vishwakarma Institute of Information Technology, Pune, India},
	abstract = {The use of the social media sites are growing rapidly to interact with the communities and to share the ideas among others. It may happen that most of the people dislike the ideas of others person views and make the use of the offensive language in their posts. Due to these offensive terms, many people especially youth and teenagers try to adopt such language and spread over the social media sites which may significantly affect the others people innocent minds. As offensive terms increasingly use by the people in highly manner, it is difficult to find or classify such offensive terms in real day to day life. To overcome from these problem, the proposed system analyze the offensive language and can classify the offensive sentence on a particular topic discussion using the support vector machine (SVM) as supervised classification in the data mining. The proposed system also can find the potential user by means of whom the offensive language spread among others and define the comparative analysis of SVM with Naive Bayes technique. © 2017 IEEE.},
	author_keywords = {Feature Extraction; Offensive Content Detection; Potential User Detection; Social Media; Supervised Classification},
	keywords = {Data mining; Feature extraction; Social networking (online); Supervised learning; Comparative analysis; Computational framework; Content detection; Offensive languages; Potential users; Social communities; Social media; Supervised classification; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 8th International Conference on Computing, Communications and Networking Technologies, ICCCNT 2017; Conference date: 3 July 2017 through 5 July 2017; Conference code: 133025}
}

@ARTICLE{Gitari2015215,
	author = {Gitari, Njagi Dennis and Zuping, Zhang and Damien, Hanyurwimfura and Long, Jun},
	title = {A lexicon-based approach for hate speech detection},
	year = {2015},
	journal = {International Journal of Multimedia and Ubiquitous Engineering},
	volume = {10},
	number = {4},
	pages = {215 – 230},
	doi = {10.14257/ijmue.2015.10.4.21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932167746&doi=10.14257%2fijmue.2015.10.4.21&partnerID=40&md5=ac29614db6e830ca48482ab33e4a664a},
	affiliations = {School of Information Science and Engineering, Central South University, Changsha, 410083, China; College of Information Science and Engineering, Hunan University, China},
	abstract = {We explore the idea of creating a classifier that can be used to detect presence of hate speech in web discourses such as web forums and blogs. In this work, hate speech problem is abstracted into three main thematic areas of race, nationality and religion. The goal of our research is to create a model classifier that uses sentiment analysis techniques and in particular subjectivity detection to not only detect that a given sentence is subjective but also to identify and rate the polarity of sentiment expressions. We begin by whittling down the document size by removing objective sentences. Then, using subjectivity and semantic features related to hate speech, we create a lexicon that is employed to build a classifier for hate speech detection. Experiments with a hate corpus show significant practical application for a real-world web discourse. © 2015 SERSC.},
	author_keywords = {Hate speech; Lexicon; Subjectivity analysis},
	keywords = {Semantics; Social networking (online); Speech; Lexicon; Lexicon-based; Real world web; Semantic features; Sentiment analysis; Speech detection; Subjectivity analysis; Web Forums; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 358; All Open Access, Bronze Open Access}
}

@CONFERENCE{Alakrot2018315,
	author = {Alakrot, Azalden and Murray, Liam and Nikolov, Nikola S.},
	title = {Towards Accurate Detection of Offensive Language in Online Communication in Arabic},
	year = {2018},
	journal = {Procedia Computer Science},
	volume = {142},
	pages = {315 – 320},
	doi = {10.1016/j.procs.2018.10.491},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065740828&doi=10.1016%2fj.procs.2018.10.491&partnerID=40&md5=a30a2253ad04307fe2b3537c87c1f311},
	affiliations = {Department of Computer Science and Information Systems, University of Limerick, Ireland; School of Languages, University of Limerick, Ireland},
	abstract = {We present the results of predictive modelling for the detection of anti-social behaviour in online communication in Arabic, such as comments which contain obscene or offensive words and phrases. We collected and labelled a large dataset of YouTube comments in Arabic which contains a broad range of both offensive and inoffensive comments. We used this dataset to train a Support Vector Machine classifier and experimented with combinations of word-level features, N-gram features and a variety of pre-processing techniques. We summarise the pre-processing steps and features that allow training a classifier which is more precise, with 90.05% accuracy, than classifiers reported by previous studies on Arabic text. © 2018 The Authors. Published by Elsevier B.V.},
	author_keywords = {Anti-social behaviour online; Arabic dataset; harassment detection; offensive language detection; SVM for offensive language detection in Arabic; text mining},
	keywords = {Computational linguistics; Data mining; Large dataset; Natural language processing systems; Support vector machines; Text processing; Arabic dataset; Offensive languages; On-line communication; Pre-processing step; Predictive modelling; Social behaviour; Support vector machine classifiers; Text mining; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 85; Conference name: 4th Arabic Computational Linguistics, ACLing 2018; Conference date: 17 November 2018 through 19 November 2018; Conference code: 147807; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhong20163952,
	author = {Zhong, Haoti and Li, Hao and Squicciarini, Anna and Rajtmajer, Sarah and Griffin, Christopher and Miller, David and Caragea, Cornelia},
	title = {Content-driven detection of cyberbullying on the instagram social network},
	year = {2016},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	volume = {2016-January},
	pages = {3952 – 3958},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006115794&partnerID=40&md5=d4329c18eb81d9a937070a9de40ec5bb},
	affiliations = {Dept. of Electrical Eng., Pennsylvania State University, United States; Information Sciences and Technology, Pennsylvania State University, United States; Dept. of Mathematics, Pennsylvania State University, United States; Dept. of Mathematics, United States Naval Academy, United States; Dept. of Computer Science, University of North Texas, United States},
	abstract = {We study detection of cyberbullying in photosharing networks, with an eye on developing earlywarning mechanisms for the prediction of posted images vulnerable to attacks. Given the overwhelming increase in media accompanying text in online social networks, we investigate use of posted images and captions for improved detection of bullying in response to shared content. We validate our approaches on a dataset of over 3000 images along with peer-generated comments posted on the Instagram photo-sharing network, running comprehensive experiments using a variety of classifiers and feature sets. In addition to standard image and text features, we leverage several novel features including topics determined from image captions and a pretrained convolutional neural network on image pixels. We identify the importance of these advanced features in assisting detection of cyberbullying in posted comments. We also provide results on classification of images and captions themselves as potential targets for cyberbullies.},
	keywords = {Artificial intelligence; Classification (of information); Computer crime; Neural networks; Convolutional neural network; Cyber bullying; Early-warning mechanisms; On-line social networks; Photo sharing; Potential targets; Shared contents; Standard images; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 136; Conference name: 25th International Joint Conference on Artificial Intelligence, IJCAI 2016; Conference date: 9 July 2016 through 15 July 2016; Conference code: 125002}
}

@ARTICLE{Acar2015291,
	author = {Acar, Esra and Irrgang, Melanie and Maniry, Dominique and Hopfgartner, Frank},
	title = {Detecting violent content in hollywood movies and user-generated videos},
	year = {2015},
	journal = {Advances in Computer Vision and Pattern Recognition},
	volume = {66},
	pages = {291 – 314},
	doi = {10.1007/978-3-319-14178-7_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935912268&doi=10.1007%2f978-3-319-14178-7_11&partnerID=40&md5=ebc7bda5582ac4e470f7d76df95734af},
	affiliations = {Technische Universität Berlin, Berlin, Germany},
	abstract = {Detecting violent scenes in videos is an important content understanding functionality, e.g., for providing automated youth protection services. The key issues in designing violence detection algorithms are the choice of discriminative features and learning effective models. We employ low and mid-level audio-visual features and evaluate their discriminative power within the context of the MediaEval Violent Scenes Detection (VSD) task. The audio-visual cues are fused at the decision level. As audio features, Mel-Frequency Cepstral Coefficients (MFCC), and as visual features dense histogram of oriented gradient (HoG), histogram of oriented optical flow (HoF),Violent Flows (ViF), and affect-related color descriptors are used.We perform feature space partitioning of the violence training samples through k-means clustering and train a different model for each cluster. These models are then used to predict the violence level of videos by employing two-class support vector machines (SVMs). The experimental results in Hollywood movies and short web videos show that mid-level audio features aremore discriminative than the visual features, and that the performance is further enhanced by fusing the audio-visual cues at the decision level. © Springer International Publishing Switzerland 2015.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Wang2018216,
	author = {Wang, Xiaofei and Yang, Longcheng and Hu, Jun and Dai, Hao},
	title = {A violent behavior detection algorithm combining streakline model with variational model},
	year = {2018},
	journal = {Communications in Computer and Information Science},
	volume = {879},
	pages = {216 – 224},
	doi = {10.1007/978-981-13-3095-7_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057088719&doi=10.1007%2f978-981-13-3095-7_17&partnerID=40&md5=864a5652a937b9297773518d463ae7d8},
	affiliations = {College of Computer Science, Chengdu Normal University, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China},
	abstract = {Violent behavior detection has become a hot topic within computer vision. The problems such as diversity of monitoring scene, different crowd density and mutual occlusion among crowds etc. result in a low recognition rate for violent behavior detection. In order to solve these problems, this work proposes an improved method to detect violence sequences. Features which are obtained by combining a streakline model with a variational model are used to discriminate fight and non-fight sequences. Finally, the validity and accuracy of the algorithm are verified via a large amount of challenging real-world surveillance videos. © Springer Nature Singapore Pte Ltd. 2018.},
	author_keywords = {Streak flow; Streakline; Support vector machine; Violent behavior detection},
	keywords = {Security systems; Support vector machines; Crowd density; Large amounts; Recognition rates; Streak flow; Streakline; Surveillance video; Variational modeling; Violent behavior; Signal detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 1st International Conference on Frontiers in Cyber Security, FCS 2018; Conference date: 5 November 2018 through 7 November 2018; Conference code: 220959}
}

@ARTICLE{Dani201752,
	author = {Dani, Harsh and Li, Jundong and Liu, Huan},
	title = {Sentiment Informed Cyberbullying Detection in Social Media},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10534 LNAI},
	pages = {52 – 67},
	doi = {10.1007/978-3-319-71249-9_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040252235&doi=10.1007%2f978-3-319-71249-9_4&partnerID=40&md5=3c1633a656965498094a7ab5afe3c2de},
	affiliations = {Computer Science and Engineering, Arizona State University, Tempe, AZ, United States},
	abstract = {Cyberbullying is a phenomenon which negatively affects the individuals, the victims suffer from various mental issues, ranging from depression, loneliness, anxiety to low self-esteem. In parallel with the pervasive use of social media, cyberbullying is becoming more and more prevalent. Traditional mechanisms to fight against cyberbullying include the use of standards and guidelines, human moderators, and blacklists based on the profane words. However, these mechanisms fall short in social media and cannot scale well. Therefore, it is necessary to develop a principled learning framework to automatically detect cyberbullying behaviors. However, it is a challenging task due to short, noisy and unstructured content information and intentional obfuscation of the abusive words or phrases by social media users. Motivated by sociological and psychological findings on bullying behaviors and the correlation with emotions, we propose to leverage sentiment information to detect cyberbullying behaviors in social media by proposing a sentiment informed cyberbullying detection framework. Experimental results on two real-world, publicly available social media datasets show the superiority of the proposed framework. Further studies validate the effectiveness of leveraging sentiment information for cyberbullying detection. © 2017, Springer International Publishing AG.},
	author_keywords = {Cyberbullying detection; Sentiment information; Social media},
	keywords = {Artificial intelligence; Computer crime; Learning systems; Content information; Cyber bullying; Detection framework; Learning frameworks; Self esteem; Sentiment information; Social media; Standards and guidelines; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65; Conference name: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017; Conference date: 18 September 2017 through 22 September 2017; Conference code: 209269}
}

@CONFERENCE{Nobata2016145,
	author = {Nobata, Chikashi and Tetreault, Joel and Thomas, Achint and Mehdad, Yashar and Chang, Yi},
	title = {Abusive language detection in online user content},
	year = {2016},
	journal = {25th International World Wide Web Conference, WWW 2016},
	pages = {145 – 153},
	doi = {10.1145/2872427.2883062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026388191&doi=10.1145%2f2872427.2883062&partnerID=40&md5=4a0b08dc5f67eef6236b523116858c22},
	affiliations = {Yahoo Labs, Sunnyvale, CA, United States; Yahoo Labs, New York, NY, United States; Embibe, Bangalore, India},
	abstract = {Detection of abusive language in user generated online con-tent has become an issue of increasing importance in recent years. Most current commercial methods make use of black-lists and regular expressions, however these measures fall short when contending with more subtle, less ham-fisted ex-amples of hate speech. In this work, we develop a machine learning based method to detect hate speech on online user comments from two domains which outperforms a state-of-the-Art deep learning approach. We also develop a corpus of user comments annotated for abusive language, the first of its kind. Finally, we use our detection tool to analyze abu-sive language over time and in different settings to further enhance our knowledge of this behavior.},
	author_keywords = {Abusive Language; Discourse Classification; Hate Speech; NLP; Stylistic Classifica-Tion},
	keywords = {Learning systems; Object oriented programming; Abusive Language; Detection tools; Language detection; Learning approach; Regular expressions; State of the art; Stylistic Classifica-Tion; User-generated; World Wide Web},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 859; Conference name: 25th International World Wide Web Conference, WWW 2016; Conference date: 11 April 2016 through 15 April 2016; Conference code: 132813}
}

@CONFERENCE{De la Peña Sarracén2018,
	author = {De la Peña Sarracén, Gretel Liz and Pons, Reynaldo Gil and Cuza, Carlos Enrique Muñiz and Rosso, Paolo},
	title = {Hate speech detection using attention-based LSTM},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212654301&partnerID=40&md5=e7a4d2282b6b8b49113cdab57116ed2e},
	affiliations = {PRHLT Research Center, Universitat Politècnica de València, Spain; CERPAMID, Cuba},
	abstract = {This paper describes the system we developed for EVALITA 2018, the 6th evaluation campaign of Natural Language Processing and Speech tools for Italian, on Hate Speech Detection (HaSpeeDe). The task consists in automatically annotating Italian messages from two popular micro-blogging platforms, Twitter and Facebook, with a boolean value indicating the presence or not of hate speech. We propose an Attention-based in Long Short-Term Memory Recurrent Neural Network where the attention layer helps to calculate the contribution of each part of the text towards targeted hateful messages. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Multilayer neural networks; Natural language processing systems; Network layers; Social networking (online); Speech recognition; Boolean values; Facebook; Micro-blogging platforms; Natural Language Processing Tools; Speech detection; Speech tool; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2018; Conference date: 12 December 2018 through 13 December 2018; Conference code: 142825}
}

@CONFERENCE{Gao2017260,
	author = {Gao, Lei and Huang, Ruihong},
	title = {Detecting online hate speech using context aware models},
	year = {2017},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	volume = {2017-September},
	pages = {260 – 266},
	doi = {10.26615/978-954-452-049-6_036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045726744&doi=10.26615%2f978-954-452-049-6_036&partnerID=40&md5=2bf06db766517b848297803b6c456a4b},
	affiliations = {Texas A and M University, United States},
	abstract = {In the wake of a polarizing election, the cyber world is laden with hate speech. Context accompanying a hate speech text is useful for identifying hate speech, which however has been largely overlooked in existing datasets and hate speech detection models. In this paper, we provide an annotated corpus of hate speech with context information well kept. Then we propose two types of hate speech detection models that incorporate context information, a logistic regression model with context features and a neural network model with learning components for context. Our evaluation shows that both models outperform a strong baseline by around 3% to 4% in Fl score and combining these two models further improve the performance by another 7% in Fl score. © 2018 Association for Computational Linguistics (ACL). All rights reserved.},
	keywords = {Learning algorithms; Natural language processing systems; Regression analysis; Speech recognition; Context features; Context information; Context-aware models; Detection models; Logistic Regression modeling; Neural network model; Performance; Speech detection; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 123; Conference name: 11th International Conference on Recent Advances in Natural Language Processing, RANLP 2017; Conference date: 2 September 2017 through 8 September 2017; Conference code: 135740; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Wu2018149,
	author = {Wu, Zhelun and Kambhatla, Nishant and Sarkar, Anoop},
	title = {Decipherment for Adversarial Offensive Language Detection},
	year = {2018},
	journal = {2nd Workshop on Abusive Language Online - Proceedings of the Workshop, co-located with EMNLP 2018},
	pages = {149 – 159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100287898&partnerID=40&md5=16f8296b670f7acd7f1844a667462faa},
	affiliations = {School of Computing Science, Simon Fraser University, Burnaby, BC, Canada},
	abstract = {Automated filters are commonly used by online services to stop users from sending age-inappropriate, bullying messages, or asking others to expose personal information. Previous work has focused on rules or classifiers to detect and filter offensive messages, but these are vulnerable to cleverly disguised plaintext and unseen expressions especially in an adversarial setting where the users can repeatedly try to bypass the filter. In this paper, we model the disguised messages as if they are produced by encrypting the original message using an invented cipher. We apply automatic decipherment techniques to decode the disguised malicious text, which can be then filtered using rules or classifiers. We provide experimental results on three different datasets and show that decipherment is an effective tool for this task. © 2018 Association for Computational Linguistics},
	keywords = {Cryptography; And filters; Effective tool; Language detection; Offensive languages; Offensive messages; On-line service; Personal information; Plaintext; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2nd Workshop on Abusive Language Online, ALW 2018, co-located with EMNLP 2018; Conference date: 31 October 2018; Conference code: 173717}
}

@ARTICLE{Shu201431,
	author = {Shu, Guang and Fu, Gaojing and Li, Peng and Geng, Haiyu},
	title = {Violent behavior detection based on SVM in the elevator},
	year = {2014},
	journal = {International Journal of Security and its Applications},
	volume = {8},
	number = {5},
	pages = {31 – 40},
	doi = {10.14257/ijsia.2014.8.5.04},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907808281&doi=10.14257%2fijsia.2014.8.5.04&partnerID=40&md5=612b1bdf01667df36fa33fc6a88cbf9f},
	affiliations = {Department of Computer Science and Technology, Harbin University of Science and Technology, Harbin, 150080, China},
	abstract = {To avoid fighting and violence occurred in the elevator, this paper proposed an abnormal behavior detection method based on SVM to achieve real-time monitoring. Firstly, the corners of the video sequences were detected and the Lucas-Kanade algorithm was used to calculate the optical flow to obtain velocity vector information. Secondly, this algorithm established a feature vector combining the corner kinetic energy with movement characteristics of targets (including change rate of area, change rate of external rectangle length-width ratio, distance between the targets and the angle difference of target movement direction) as the basis of violent behavior detection. Finally, SVM classifier was constructed to identify the violent behavior. The experiment results showed that the method could detect violent behavior in the elevator effectively and the algorithm was with less complex calculation and higher detection rate thus it could alarm real-time. © 2014 SERSC.},
	author_keywords = {Corner kinetic energy; SVM; Velocity vector information; Video sequence},
	keywords = {SVM; Velocity vectors; Video sequences; Violent behavior},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Bronze Open Access}
}

@CONFERENCE{Karan2018132,
	author = {Karan, Mladen and Šnajder, Jan},
	title = {Cross-Domain Detection of Abusive Language Online},
	year = {2018},
	journal = {2nd Workshop on Abusive Language Online - Proceedings of the Workshop, co-located with EMNLP 2018},
	pages = {132 – 137},
	doi = {10.18653/v1/w18-5117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097107192&doi=10.18653%2fv1%2fw18-5117&partnerID=40&md5=bf0715e6db6a7526a2024c9320e2cdbd},
	affiliations = {Text Analysis and Knowledge Engineering Lab, Faculty of Electrical Engineering and Computing, University of Zagreb, Unska 3, Zagreb, 10000, Croatia},
	abstract = {We investigate to what extent the models trained to detect general abusive language generalize between different datasets labeled with different abusive language types. To this end, we compare the cross-domain performance of simple classification models on nine different datasets, finding that the models fail to generalize to out-domain datasets and that having at least some in-domain data is important. We also show that using the frustratingly simple domain adaptation (Daume III, 2007) in most cases improves the results over in-domain training, especially when used to augment a smaller dataset with a larger one. © 2018 Association for Computational Linguistics},
	keywords = {Computational linguistics; Classification models; Cross-domain; Domain adaptation; Domain detections; Performance; Simple++; Small data set; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; Conference name: 2nd Workshop on Abusive Language Online, ALW 2018, co-located with EMNLP 2018; Conference date: 31 October 2018; Conference code: 173717; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Robinson201846,
	author = {Robinson, David and Zhang, Ziqi and Tepper, Jonathan},
	title = {Hate speech detection on twitter: Feature engineering v.s. feature selection},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11155 LNCS},
	pages = {46 – 49},
	doi = {10.1007/978-3-319-98192-5_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051682006&doi=10.1007%2f978-3-319-98192-5_9&partnerID=40&md5=bbd512e97b3ee8d9f2894c6fd2f25b12},
	affiliations = {Nottigham Trent University, Nottingham, United Kingdom; University of Sheffield, Sheffield, United Kingdom},
	abstract = {The increasing presence of hate speech on social media has drawn significant investment from governments, companies, and empirical research. Existing methods typically use a supervised text classification approach that depends on carefully engineered features. However, it is unclear if these features contribute equally to the performance of such methods. We conduct a feature selection analysis in such a task using Twitter as a case study, and show findings that challenge conventional perception of the importance of manual feature engineering: automatic feature selection can drastically reduce the carefully engineered features by over 90% and selects predominantly generic features often used by many other language related tasks; nevertheless, the resulting models perform better using automatically selected features than carefully crafted task-specific features. © 2018, Springer Nature Switzerland AG.},
	keywords = {Classification (of information); Semantic Web; Social networking (online); Text processing; Automatic feature selection; Empirical research; Feature engineerings; Generic features; Social media; Speech detection; Text classification; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40; Conference name: 15th Extended Semantic Web Conference, ESWC 2018; Conference date: 3 June 2018 through 7 June 2018; Conference code: 216719}
}

@CONFERENCE{Davidson2017512,
	author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},
	title = {Automated hate speech detection and the problem of offensive language},
	year = {2017},
	journal = {Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017},
	pages = {512 – 515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026777430&partnerID=40&md5=ad994c163581a2305060fd1c8e79b1c9},
	affiliations = {Department of Sociology, Cornell University, Ithaca, NY, United States; Department of Applied Mathematics, Cornell University, Ithaca, NY, United States; Department of Information Science, Cornell University, Ithaca, NY, United States; Qatar Computing Research Institute, HBKU, Doha, Qatar},
	abstract = {A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories.We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Social networking (online); Speech; Detection methods; Multi-class classifier; Offensive languages; Social media; Speech detection; Three categories; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1671; Conference name: 11th International Conference on Web and Social Media, ICWSM 2017; Conference date: 15 May 2017 through 18 May 2017; Conference code: 129605}
}

@ARTICLE{Chen2017187,
	author = {Chen, Hao and McKeever, Susan and Delany, Sarah Jane},
	title = {Harnessing the power of text mining for the detection of abusive content in social media},
	year = {2017},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {513},
	pages = {187 – 205},
	doi = {10.1007/978-3-319-46562-3_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988646719&doi=10.1007%2f978-3-319-46562-3_12&partnerID=40&md5=5cba64fbc0642ead5b6f024cf7721820},
	affiliations = {Dublin Institute of Technology, Dublin, Ireland},
	abstract = {The issues of cyberbullying and online harassment have gained considerable coverage in the last number of years. Social media providers need to be able to detect abusive content both accurately and efficiently in order to protect their users. Our aim is to investigate the application of core text mining techniques for the automatic detection of abusive content across a range of social media sources include blogs, forums, media-sharing, Q&A and chat—using datasets from Twitter, YouTube, MySpace, Kongregate, Formspring and Slashdot. Using supervised machine learning, we compare alternative text representations and dimension reduction approaches, including feature selection and feature enhancement, demonstrating the impact of these techniques on detection accuracies. In addition, we investigate the need for sampling on imbalanced datasets. Our conclusions are: (1) Dataset balancing boosts accuracies significantly for social media abusive content detection; (2) Feature reduction, important for large feature sets that are typical of social media datasets, improves efficiency whilst maintaining detection accuracies; (3) The use of generic structural features common across all our datasets proved to be of limited use in the automatic detection of abusive content. Our findings can support practitioners in selecting appropriate text mining strategies in this area. © Springer International Publishing AG 2017.},
	keywords = {Artificial intelligence; Data mining; Learning systems; Social networking (online); Supervised learning; Automatic Detection; Dimension reduction; Feature enhancement; Imbalanced Data-sets; Structural feature; Supervised machine learning; Text mining techniques; Text representation; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 16th UK Workshop on Computational Intelligence, UKCI 2016; Conference date: 7 September 2016 through 9 September 2016; Conference code: 181569}
}

@CONFERENCE{Badjatiya2017759,
	author = {Badjatiya, Pinkesh and Gupta, Shashank and Gupta, Manish and Varma, Vasudeva},
	title = {Deep learning for hate speech detection in tweets},
	year = {2017},
	journal = {26th International World Wide Web Conference 2017, WWW 2017 Companion},
	pages = {759 – 760},
	doi = {10.1145/3041021.3054223},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044462256&doi=10.1145%2f3041021.3054223&partnerID=40&md5=90af25631122622ba346d01feedb8918},
	affiliations = {IIIT-H, Hyderabad, India; Microsoft, India},
	abstract = {Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ∼18 F1 points. © 2017 International World Wide Web Conference Committee (IW3C2), published under Creative Commons CC BY 4.0 License.},
	keywords = {Learning systems; Semantics; Sentiment analysis; Speech recognition; World Wide Web; Benchmark datasets; Content recommendations; Event extraction; Learning architectures; Learning methods; Natural languages; Speech detection; State of the art; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 875; Conference name: 26th International World Wide Web Conference, WWW 2017 Companion; Conference date: 3 April 2017 through 7 April 2017; Conference code: 143622; All Open Access, Green Open Access}
}

@CONFERENCE{Chen201271,
	author = {Chen, Ying and Zhou, Yilu and Zhu, Sencun and Xu, Heng},
	title = {Detecting offensive language in social media to protect adolescent online safety},
	year = {2012},
	journal = {Proceedings - 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust and 2012 ASE/IEEE International Conference on Social Computing, SocialCom/PASSAT 2012},
	pages = {71 – 80},
	doi = {10.1109/SocialCom-PASSAT.2012.55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873615388&doi=10.1109%2fSocialCom-PASSAT.2012.55&partnerID=40&md5=789b175e3bd2d7f3cacd29500400f56e},
	affiliations = {Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA, United States; Department of Information Systems and Technology Management, George Washington University, Washington, DC, United States; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States},
	abstract = {Since the textual contents on online social media are highly unstructured, informal, and often misspelled, existing research on message-level offensive language detection cannot accurately detect offensive content. Meanwhile, user-level offensiveness detection seems a more feasible approach but it is an under researched area. To bridge this gap, we propose the Lexical Syntactic Feature (LSF) architecture to detect offensive content and identify potential offensive users in social media. We distinguish the contribution of pejoratives/profanities and obscenities in determining offensive content, and introduce hand-authoring syntactic rules in identifying name-calling harassments. In particular, we incorporate a user's writing style, structure and specific cyber bullying content as features to predict the user's potentiality to send out offensive content. Results from experiments showed that our LSF framework performed significantly better than existing methods in offensive content detection. It achieves precision of 98.24% and recall of 94.34% in sentence offensive detection, as well as precision of 77.9% and recall of 77.8% in user offensive detection. Meanwhile, the processing speed of LSF is approximately 10msec per sentence, suggesting the potential for effective deployment in social media. © 2012 IEEE.},
	author_keywords = {adolescent safety; cyberbullying; offensive languages; social media},
	keywords = {Safety engineering; Content detection; Cyber bullying; Offensive languages; Online social medias; Processing speed; Social media; Syntactic features; Syntactic rules; Textual content; Writing style; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 486; Conference name: 2012 ASE/IEEE International Conference on Social Computing, SocialCom 2012 and the 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust, PASSAT 2012; Conference date: 3 September 2012 through 5 September 2012; Conference code: 95460; All Open Access, Green Open Access}
}

@CONFERENCE{Waseem2016138,
	author = {Waseem, Zeerak},
	title = {Are You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter},
	year = {2016},
	journal = {NLP + CSS 2016 - EMNLP 2016 Workshop on Natural Language Processing and Computational Social Science, Proceedings of the Workshop},
	pages = {138 – 142},
	doi = {10.18653/v1/w16-5618},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092735980&doi=10.18653%2fv1%2fw16-5618&partnerID=40&md5=d5f64b342efc9949e0a4112e7ba2e894},
	affiliations = {University of Copenhagen, Copenhagen, Denmark},
	abstract = {Hate speech in the form of racism and sexism is commonplace on the internet (Waseem and Hovy, 2016). For this reason, there has been both an academic and an industry interest in detection of hate speech. The volume of data to be reviewed for creating data sets encourages a use of crowd sourcing for the annotation efforts. In this paper, we provide an examination of the influence of annotator knowledge of hate speech on classification models by comparing classification results obtained from training on expert and amateur annotations. We provide an evaluation on our own data set and run our models on the data set released by Waseem and Hovy (2016). We find that amateur annotators are more likely than expert annotators to label items as hate speech, and that systems trained on expert annotations outperform systems trained on amateur annotations.  ©2016 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Classification models; Classification results; Crowd sourcing; Data set; Expert annotations; Speech detection; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 440; Conference name: EMNLP 2016 1st Workshop on Natural Language Processing and Computational Social Science, NLP + CSS 2016; Conference date: 5 November 2016 through 5 November 2016; Conference code: 174026; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Chen2018117,
	author = {Chen, Hao and McKeever, Susan and Delany, Sarah Jane},
	title = {A comparison of classical versus deep learning techniques for abusive content detection on social media sites},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11185 LNCS},
	pages = {117 – 133},
	doi = {10.1007/978-3-030-01129-1_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057310941&doi=10.1007%2f978-3-030-01129-1_8&partnerID=40&md5=2f2e8d2ee9695b2cfe94df61fc74ea9e},
	affiliations = {Dublin Institute of Technology, Dublin, Ireland},
	abstract = {The automated detection of abusive content on social media websites faces a variety of challenges including imbalanced training sets, the identification of an appropriate feature representation and the selection of optimal classifiers. Classifiers such as support vector machines (SVM), combined with bag of words or ngram feature representation, have traditionally dominated in text classification for decades. With the recent emergence of deep learning and word embeddings, an increasing number of researchers have started to focus on deep neural networks. In this paper, our aim is to explore cutting-edge techniques in automated abusive content detection. We use two deep learning approaches: Convolutional neural networks (CNNs) and recurrent neural networks (RNNs). We apply these to 9 public datasets derived from various social media websites. Firstly, we show that word embeddings pre-trained on the same data source as the subsequent classification task improves the prediction accuracy of deep learning models. Secondly, we investigate the impact of different levels of training set imbalances on classifier types. In comparison to the traditional SVM classifier, we identify that although deep learning models can outperform the classification results of the traditional SVM classifier when the associated training dataset is seriously imbalanced, the performance of the SVM classifier can be dramatically improved through the use of oversampling, surpassing the deep learning models. Our work can inform researchers in selecting appropriate text classification strategies in the detection of abusive content, including scenarios where the training datasets suffer from class imbalance. © Springer Nature Switzerland AG 2018.},
	author_keywords = {Abuse detection; Deep learning; Text classification},
	keywords = {Deep learning; Deep neural networks; Recurrent neural networks; Social networking (online); Support vector machines; Text processing; Classification results; Classification tasks; Convolutional neural network; Feature representation; Optimal classifiers; Recurrent neural network (RNNs); Social media websites; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; Conference name: 10th Conference on Social Informatics, SocInfo 2018; Conference date: 25 September 2018 through 28 September 2018; Conference code: 218899}
}

@CONFERENCE{Andrusyak201877,
	author = {Andrusyak, Bohdan and Rimel, Mykhailo and Kern, Roman},
	title = {Detection of abusive speech for mixed sociolects of Russian and Ukrainian languages},
	year = {2018},
	journal = {Recent Advances in Slavonic Natural Language Processing},
	volume = {2018-December},
	pages = {77 – 84},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062199692&partnerID=40&md5=2caa9a5c8d1c577d455459941c5b4a6d},
	affiliations = {Know Center, Inffeldgasse 13, Graz, 8010, Austria; Grenoble INP, 46 Avenue F lix Viallet, Grenoble, 38031, France},
	abstract = {                             Uncontrolled use of abusive language is a problem in modern society. Development of automatic tools for detecting abusive and hate speech has been an active research topic in the past decade. However, very little research has been done on this topic for Russian and Ukrainian languages. To our best knowledge, no research considered surzhyk                              3                             . We propose to use unsupervised probabilistic technique with a seed dictionary for detecting abusive comments in social media in Russian and Ukrainian languages. We demonstrate that this approach is feasible and is able to detect abusive terms that are not present in the seed dictionary.                          © 2018 Tribun EU s. r. o. KG. All rights reserved.},
	author_keywords = {Abusive speech; Russian; Ukrainian},
	keywords = {Natural language processing systems; Automatic tools; Probabilistic technique; Research topics; Russian; Social media; Ukrainian; Speech recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 12th Workshop on Recent Advances in Slavonic Natural Language Processing, RASLAN 2018; Conference date: 7 December 2018 through 9 December 2018; Conference code: 143897}
}